# Define variables
LOGS_DIR=/fast/najroldi/logs/algoperf
EXE=/home/najroldi/algorithmic-efficiency/script/lawa/auto_run.sh

workload=librispeech_deepspeech
framework=pytorch

# ## NadamW
# submission=prize_qualification_baselines/external_tuning/pytorch_nadamw_full_budget.py
# search_space=script/lawa/nadam/nadamw_trial_5_lr_sweep_2.json
# num_tuning_trials=6
# study=1
# name=nadamw_lr_sweep_03
# rng_seed=$(study)
# allow_tf_32=1
# num_jobs=$(num_tuning_trials)

## LAWA
submission=submissions/lawa_queue/lawa_queue.py
search_space=script/lawa/queue/lawa_trial_5_lr_sweep_2.json
num_tuning_trials=6
study=1
name=lawa_queue_lr_sweep_03
rng_seed=$(study)
allow_tf_32=1
num_jobs=$(num_tuning_trials)

# Args
executable = $(EXE)
arguments = \
  $(workload) \
  $(framework) \
  $(submission) \
  $(search_space) \
  $(num_tuning_trials) \
  $(study) \
  $(name) \
  $(rng_seed) \
  $(allow_tf_32) \
  $(Cluster) \
  $(Process)

# Logs
error = $(LOGS_DIR)/err/job.$(Cluster).$(Process).err
output = $(LOGS_DIR)/out/job.$(Cluster).$(Process).out
log = $(LOGS_DIR)/log/job.$(Cluster).$(Process).log

# Specs
request_memory = 500000
request_cpus = 36
request_gpus = 4
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-40GB")

requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB")
# requirements = (TARGET.CUDACapability >= 8.0)
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB") && (TARGET.Machine != "g102.internal.cluster.is.localnet")

queue $(num_jobs)