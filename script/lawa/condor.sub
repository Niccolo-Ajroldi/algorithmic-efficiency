# Define variables
LOGS_DIR=/fast/najroldi/logs/algoperf
EXE=/home/najroldi/algorithmic-efficiency/script/lawa/auto_run.sh

workload=ogbg
framework=pytorch

# ## NadamW
# submission=prize_qualification_baselines/external_tuning/pytorch_nadamw_full_budget.py
# search_space=script/lawa/nadam/nadamw_trial_5_lr_sweep_01.json
# num_tuning_trials=6
# study=1
# name=lr_sweep_nadamw_01
# rng_seed=$(study)
# allow_tf_32=1
# run_until_the_end=1
# target_setting=0
# num_jobs=$(num_tuning_trials)

## LAWA
submission=submissions/lawa_ema/lawa_ema.py
search_space=script/lawa/ema/lawa_trial_5_lr_sweep_01.json
num_tuning_trials=7
study=3
name=lr_sweep_ema_01
rng_seed=$(study)
allow_tf_32=1
run_until_the_end=1
target_setting=0
num_jobs=$(num_tuning_trials)

# Args
executable = $(EXE)
arguments = \
  $(workload) \
  $(framework) \
  $(submission) \
  $(search_space) \
  $(num_tuning_trials) \
  $(study) \
  $(name) \
  $(rng_seed) \
  $(allow_tf_32) \
  $(run_until_the_end) \
  $(target_setting) \
  $(Cluster) \
  $(Process)

# Logs
error = $(LOGS_DIR)/err/job.$(Cluster).$(Process).err
output = $(LOGS_DIR)/out/job.$(Cluster).$(Process).out
log = $(LOGS_DIR)/log/job.$(Cluster).$(Process).log

# Specs
request_memory = 300000
request_cpus = 16
request_gpus = 4
requirements = TARGET.CUDACapability >= 8.0
# requirements = TARGET.CUDACapability >= 8.0 && (TARGET.Machine != "g147.internal.cluster.is.localnet")
# requirements = (TARGET.CUDACapability >= 8.0) && (TARGET.Machine != "g100.internal.cluster.is.localnet") && (TARGET.Machine != "g143.internal.cluster.is.localnet")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-40GB")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB") && (TARGET.Machine != "g102.internal.cluster.is.localnet")

queue $(num_jobs)