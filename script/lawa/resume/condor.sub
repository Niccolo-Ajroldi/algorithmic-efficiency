# Define variables
LOGS_DIR=/fast/najroldi/logs/algoperf
EXE=/home/najroldi/algorithmic-efficiency/script/lawa/resume/run.sh

workload=criteo1tb
framework=pytorch

# ## NadamW
# submission=submissions/nadamw_mod/nadamw_mod.py
# search_space=script/lawa/resume/nadamw_mod/trial_5.json

## LAWA
submission=submissions/lawa_queue/lawa_queue.py
search_space=script/lawa/resume/lawa/trial_5_h100_01.json

num_tuning_trials=1
study=1

# checkpoint=63600
# name=nadamw_resume_$(checkpoint)
name=lawa_h100_01
# name=nadamw_save_ckpt_01_study_1

resume_experiment_name=nadamw_save_ckpt_01_study_1/$(workload)_pytorch/trial_1/checkpoint_$(checkpoint)
resume_last_run=False
eval_every_n_steps=20
save_checkpoints=False
save_intermediate_checkpoints=False

rng_seed=$(study)
allow_tf_32=True
run_until_the_end=True
num_jobs=$(num_tuning_trials)

# Args
executable = $(EXE)
arguments = \
  $(workload) \
  $(framework) \
  $(submission) \
  $(search_space) \
  $(num_tuning_trials) \
  $(study) \
  $(name) \
  $(resume_experiment_name) \
  $(resume_last_run) \
  $(eval_every_n_steps) \
  $(save_checkpoints) \
  $(save_intermediate_checkpoints) \
  $(rng_seed) \
  $(allow_tf_32) \
  $(run_until_the_end) \
  $(Cluster) \
  $(Process)

# Logs
error = $(LOGS_DIR)/err/job.$(Cluster).$(Process).err
output = $(LOGS_DIR)/out/job.$(Cluster).$(Process).out
log = $(LOGS_DIR)/log/job.$(Cluster).$(Process).log

# Specs
request_memory = 500000
request_cpus = 36
request_gpus = 4
requirements = (TARGET.CUDACapability >= 8.0) && (TARGET.Machine != "g100.internal.cluster.is.localnet") && (TARGET.Machine != "g143.internal.cluster.is.localnet")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-40GB")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB")
# requirements = (TARGET.CUDADeviceName == "NVIDIA A100-SXM4-80GB") && (TARGET.Machine != "g102.internal.cluster.is.localnet")

queue $(num_jobs)