python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification/study_4 --overwrite=true --save_checkpoints=false --num_tuning_trials=5 --rng_seed=813120851 --max_global_steps=36189 2>&1 | tee -a /logs/fastmri_jax_02-04-2024-17-47-54.log
I0204 17:48:14.018692 139681449744192 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification/study_4/fastmri_jax.
I0204 17:48:15.771249 139681449744192 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0204 17:48:15.772289 139681449744192 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0204 17:48:15.772542 139681449744192 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0204 17:48:15.773887 139681449744192 submission_runner.py:542] Using RNG seed 813120851
I0204 17:48:21.396522 139681449744192 submission_runner.py:551] --- Tuning run 1/5 ---
I0204 17:48:21.396754 139681449744192 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1.
I0204 17:48:21.396970 139681449744192 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1/hparams.json.
I0204 17:48:21.583309 139681449744192 submission_runner.py:206] Initializing dataset.
I0204 17:48:28.064023 139681449744192 submission_runner.py:213] Initializing model.
I0204 17:48:34.850386 139681449744192 submission_runner.py:255] Initializing optimizer.
I0204 17:48:35.702136 139681449744192 submission_runner.py:262] Initializing metrics bundle.
I0204 17:48:35.702329 139681449744192 submission_runner.py:280] Initializing checkpoint and logger.
I0204 17:48:35.703238 139681449744192 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1 with prefix checkpoint_
I0204 17:48:35.703406 139681449744192 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1/meta_data_0.json.
I0204 17:48:35.703593 139681449744192 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 17:48:35.703655 139681449744192 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 17:48:36.158288 139681449744192 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 17:48:36.574475 139681449744192 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1/flags_0.json.
I0204 17:48:36.583788 139681449744192 submission_runner.py:314] Starting training loop.
2024-02-04 17:49:43.668729: E external/xla/xla/service/rendezvous.cc:31] This thread has been waiting for 10 seconds and may be stuck:
2024-02-04 17:49:46.379651: E external/xla/xla/service/rendezvous.cc:36] Thread is unstuck! Warning above was a false-positive. Perhaps the timeout is too short.
I0204 17:49:47.897688 139519009478400 logging_writer.py:48] [0] global_step=0, grad_norm=5.605435371398926, loss=1.0139427185058594
I0204 17:49:47.911684 139681449744192 spec.py:321] Evaluating on the training split.
I0204 17:51:17.812547 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 17:52:19.017834 139681449744192 spec.py:349] Evaluating on the test split.
I0204 17:53:16.239843 139681449744192 submission_runner.py:408] Time since start: 279.66s, 	Step: 1, 	{'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 71.32777667045593, 'total_duration': 279.655978679657, 'accumulated_submission_time': 71.32777667045593, 'accumulated_eval_time': 208.3280806541443, 'accumulated_logging_time': 0}
I0204 17:53:16.258388 139487501866752 logging_writer.py:48] [1] accumulated_eval_time=208.328081, accumulated_logging_time=0, accumulated_submission_time=71.327777, global_step=1, preemption_count=0, score=71.327777, test/loss=1.032399, test/num_examples=3581, test/ssim=0.212846, total_duration=279.655979, train/loss=1.032718, train/ssim=0.197546, validation/loss=1.037087, validation/num_examples=3554, validation/ssim=0.189760
I0204 17:53:37.926089 139487493474048 logging_writer.py:48] [100] global_step=100, grad_norm=0.8439900875091553, loss=0.47173410654067993
I0204 17:54:02.080782 139487501866752 logging_writer.py:48] [200] global_step=200, grad_norm=0.19660556316375732, loss=0.3609205186367035
I0204 17:54:26.281414 139487493474048 logging_writer.py:48] [300] global_step=300, grad_norm=0.16759155690670013, loss=0.3407624065876007
I0204 17:54:36.252903 139681449744192 spec.py:321] Evaluating on the training split.
I0204 17:54:38.024706 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 17:54:39.346040 139681449744192 spec.py:349] Evaluating on the test split.
I0204 17:54:40.664800 139681449744192 submission_runner.py:408] Time since start: 364.08s, 	Step: 333, 	{'train/ssim': 0.6802842276436942, 'train/loss': 0.32911596979413715, 'validation/ssim': 0.6573601735060847, 'validation/loss': 0.34868460823192177, 'validation/num_examples': 3554, 'test/ssim': 0.6765431241927883, 'test/loss': 0.3496438723907428, 'test/num_examples': 3581, 'score': 151.29912686347961, 'total_duration': 364.08095121383667, 'accumulated_submission_time': 151.29912686347961, 'accumulated_eval_time': 212.7399332523346, 'accumulated_logging_time': 0.028414011001586914}
I0204 17:54:40.683909 139487501866752 logging_writer.py:48] [333] accumulated_eval_time=212.739933, accumulated_logging_time=0.028414, accumulated_submission_time=151.299127, global_step=333, preemption_count=0, score=151.299127, test/loss=0.349644, test/num_examples=3581, test/ssim=0.676543, total_duration=364.080951, train/loss=0.329116, train/ssim=0.680284, validation/loss=0.348685, validation/num_examples=3554, validation/ssim=0.657360
I0204 17:55:01.598745 139487493474048 logging_writer.py:48] [400] global_step=400, grad_norm=0.07975911349058151, loss=0.3675090968608856
I0204 17:55:38.247593 139487501866752 logging_writer.py:48] [500] global_step=500, grad_norm=0.0887204110622406, loss=0.2435935139656067
I0204 17:56:00.988731 139681449744192 spec.py:321] Evaluating on the training split.
I0204 17:56:02.358677 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 17:56:03.678904 139681449744192 spec.py:349] Evaluating on the test split.
I0204 17:56:04.998300 139681449744192 submission_runner.py:408] Time since start: 448.41s, 	Step: 564, 	{'train/ssim': 0.7045314652579171, 'train/loss': 0.3065744127546038, 'validation/ssim': 0.6825660100195202, 'validation/loss': 0.32483030371808175, 'validation/num_examples': 3554, 'test/ssim': 0.700672003717537, 'test/loss': 0.32667249622574, 'test/num_examples': 3581, 'score': 231.5786828994751, 'total_duration': 448.4144470691681, 'accumulated_submission_time': 231.5786828994751, 'accumulated_eval_time': 216.74945425987244, 'accumulated_logging_time': 0.06387090682983398}
I0204 17:56:05.019575 139487493474048 logging_writer.py:48] [564] accumulated_eval_time=216.749454, accumulated_logging_time=0.063871, accumulated_submission_time=231.578683, global_step=564, preemption_count=0, score=231.578683, test/loss=0.326672, test/num_examples=3581, test/ssim=0.700672, total_duration=448.414447, train/loss=0.306574, train/ssim=0.704531, validation/loss=0.324830, validation/num_examples=3554, validation/ssim=0.682566
I0204 17:56:14.549923 139487501866752 logging_writer.py:48] [600] global_step=600, grad_norm=0.11685214191675186, loss=0.36731991171836853
I0204 17:56:51.007297 139487493474048 logging_writer.py:48] [700] global_step=700, grad_norm=0.19322443008422852, loss=0.32410624623298645
I0204 17:57:25.050482 139681449744192 spec.py:321] Evaluating on the training split.
I0204 17:57:26.421435 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 17:57:27.739985 139681449744192 spec.py:349] Evaluating on the test split.
I0204 17:57:29.061596 139681449744192 submission_runner.py:408] Time since start: 532.48s, 	Step: 795, 	{'train/ssim': 0.7191570145743233, 'train/loss': 0.293259859085083, 'validation/ssim': 0.6973806884628235, 'validation/loss': 0.3110030415223164, 'validation/num_examples': 3554, 'test/ssim': 0.7146922614580424, 'test/loss': 0.31336499139337826, 'test/num_examples': 3581, 'score': 311.58346366882324, 'total_duration': 532.4777381420135, 'accumulated_submission_time': 311.58346366882324, 'accumulated_eval_time': 220.76053142547607, 'accumulated_logging_time': 0.10216903686523438}
I0204 17:57:29.080380 139487501866752 logging_writer.py:48] [795] accumulated_eval_time=220.760531, accumulated_logging_time=0.102169, accumulated_submission_time=311.583464, global_step=795, preemption_count=0, score=311.583464, test/loss=0.313365, test/num_examples=3581, test/ssim=0.714692, total_duration=532.477738, train/loss=0.293260, train/ssim=0.719157, validation/loss=0.311003, validation/num_examples=3554, validation/ssim=0.697381
I0204 17:57:29.550568 139487493474048 logging_writer.py:48] [800] global_step=800, grad_norm=0.1701880842447281, loss=0.25184354186058044
I0204 17:58:04.977845 139487501866752 logging_writer.py:48] [900] global_step=900, grad_norm=0.09580772370100021, loss=0.31866455078125
I0204 17:58:36.527914 139487493474048 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.11593685299158096, loss=0.2629987597465515
I0204 17:58:49.098053 139681449744192 spec.py:321] Evaluating on the training split.
I0204 17:58:50.468973 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 17:58:51.788120 139681449744192 spec.py:349] Evaluating on the test split.
I0204 17:58:53.106650 139681449744192 submission_runner.py:408] Time since start: 616.52s, 	Step: 1054, 	{'train/ssim': 0.7251708166939872, 'train/loss': 0.2865138053894043, 'validation/ssim': 0.7035528299978897, 'validation/loss': 0.30433327627101503, 'validation/num_examples': 3554, 'test/ssim': 0.7205648627303826, 'test/loss': 0.3066303644124372, 'test/num_examples': 3581, 'score': 391.5698597431183, 'total_duration': 616.5227851867676, 'accumulated_submission_time': 391.5698597431183, 'accumulated_eval_time': 224.7690806388855, 'accumulated_logging_time': 0.1421968936920166}
I0204 17:58:53.129890 139487501866752 logging_writer.py:48] [1054] accumulated_eval_time=224.769081, accumulated_logging_time=0.142197, accumulated_submission_time=391.569860, global_step=1054, preemption_count=0, score=391.569860, test/loss=0.306630, test/num_examples=3581, test/ssim=0.720565, total_duration=616.522785, train/loss=0.286514, train/ssim=0.725171, validation/loss=0.304333, validation/num_examples=3554, validation/ssim=0.703553
I0204 17:59:02.392215 139487493474048 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.4225981831550598, loss=0.265933632850647
I0204 17:59:26.542482 139487501866752 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.21053403615951538, loss=0.25425198674201965
I0204 17:59:50.375885 139487493474048 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.20077039301395416, loss=0.3659557104110718
I0204 18:00:13.291375 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:00:14.664275 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:00:15.982465 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:00:17.303290 139681449744192 submission_runner.py:408] Time since start: 700.72s, 	Step: 1398, 	{'train/ssim': 0.731006281716483, 'train/loss': 0.2799362965992519, 'validation/ssim': 0.7094610468618107, 'validation/loss': 0.2978182112694323, 'validation/num_examples': 3554, 'test/ssim': 0.7265395244650587, 'test/loss': 0.29966195965905124, 'test/num_examples': 3581, 'score': 471.7077603340149, 'total_duration': 700.7194221019745, 'accumulated_submission_time': 471.7077603340149, 'accumulated_eval_time': 228.78094816207886, 'accumulated_logging_time': 0.1752948760986328}
I0204 18:00:17.319418 139487501866752 logging_writer.py:48] [1398] accumulated_eval_time=228.780948, accumulated_logging_time=0.175295, accumulated_submission_time=471.707760, global_step=1398, preemption_count=0, score=471.707760, test/loss=0.299662, test/num_examples=3581, test/ssim=0.726540, total_duration=700.719422, train/loss=0.279936, train/ssim=0.731006, validation/loss=0.297818, validation/num_examples=3554, validation/ssim=0.709461
I0204 18:00:17.559181 139487493474048 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.22171379625797272, loss=0.27175143361091614
I0204 18:00:39.452847 139487501866752 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.25691208243370056, loss=0.33666521310806274
I0204 18:01:03.230787 139487493474048 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.4118705987930298, loss=0.1931799054145813
I0204 18:01:27.152187 139487501866752 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.20768581330776215, loss=0.3358802795410156
I0204 18:01:37.446349 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:01:38.816059 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:01:40.133490 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:01:41.454077 139681449744192 submission_runner.py:408] Time since start: 784.87s, 	Step: 1744, 	{'train/ssim': 0.7316139766148159, 'train/loss': 0.27979694093976704, 'validation/ssim': 0.7091029418876618, 'validation/loss': 0.2986845189289357, 'validation/num_examples': 3554, 'test/ssim': 0.7262638180457623, 'test/loss': 0.30030496784243227, 'test/num_examples': 3581, 'score': 551.8113622665405, 'total_duration': 784.8702282905579, 'accumulated_submission_time': 551.8113622665405, 'accumulated_eval_time': 232.7886414527893, 'accumulated_logging_time': 0.20101261138916016}
I0204 18:01:41.472681 139487493474048 logging_writer.py:48] [1744] accumulated_eval_time=232.788641, accumulated_logging_time=0.201013, accumulated_submission_time=551.811362, global_step=1744, preemption_count=0, score=551.811362, test/loss=0.300305, test/num_examples=3581, test/ssim=0.726264, total_duration=784.870228, train/loss=0.279797, train/ssim=0.731614, validation/loss=0.298685, validation/num_examples=3554, validation/ssim=0.709103
I0204 18:01:52.786491 139487501866752 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.19418689608573914, loss=0.2780333161354065
I0204 18:02:16.567989 139487493474048 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.07349250465631485, loss=0.21703636646270752
I0204 18:02:41.062465 139487501866752 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.07117865234613419, loss=0.3356460928916931
I0204 18:03:01.560503 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:03:02.930383 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:03:04.250796 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:03:05.571644 139681449744192 submission_runner.py:408] Time since start: 868.99s, 	Step: 2086, 	{'train/ssim': 0.7330848830086845, 'train/loss': 0.27615112917763845, 'validation/ssim': 0.7116767226408625, 'validation/loss': 0.29396547436647086, 'validation/num_examples': 3554, 'test/ssim': 0.7289850213147515, 'test/loss': 0.2955346809223157, 'test/num_examples': 3581, 'score': 631.8748698234558, 'total_duration': 868.9877972602844, 'accumulated_submission_time': 631.8748698234558, 'accumulated_eval_time': 236.79975581169128, 'accumulated_logging_time': 0.23016881942749023}
I0204 18:03:05.587132 139487493474048 logging_writer.py:48] [2086] accumulated_eval_time=236.799756, accumulated_logging_time=0.230169, accumulated_submission_time=631.874870, global_step=2086, preemption_count=0, score=631.874870, test/loss=0.295535, test/num_examples=3581, test/ssim=0.728985, total_duration=868.987797, train/loss=0.276151, train/ssim=0.733085, validation/loss=0.293965, validation/num_examples=3554, validation/ssim=0.711677
I0204 18:03:06.916654 139487501866752 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.17710307240486145, loss=0.28989267349243164
I0204 18:03:30.841665 139487493474048 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.7798890471458435, loss=0.2944459617137909
I0204 18:03:54.859806 139487501866752 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.10385426878929138, loss=0.22358007729053497
I0204 18:04:18.787904 139487493474048 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.17266252636909485, loss=0.28450483083724976
I0204 18:04:25.577063 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:04:26.945951 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:04:28.265346 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:04:29.584779 139681449744192 submission_runner.py:408] Time since start: 953.00s, 	Step: 2429, 	{'train/ssim': 0.7360131399972099, 'train/loss': 0.2751845802579607, 'validation/ssim': 0.713600927212296, 'validation/loss': 0.29331084913126054, 'validation/num_examples': 3554, 'test/ssim': 0.7307537966219282, 'test/loss': 0.29507499978183466, 'test/num_examples': 3581, 'score': 711.8415286540985, 'total_duration': 953.0009279251099, 'accumulated_submission_time': 711.8415286540985, 'accumulated_eval_time': 240.80744862556458, 'accumulated_logging_time': 0.25550317764282227}
I0204 18:04:29.600199 139487501866752 logging_writer.py:48] [2429] accumulated_eval_time=240.807449, accumulated_logging_time=0.255503, accumulated_submission_time=711.841529, global_step=2429, preemption_count=0, score=711.841529, test/loss=0.295075, test/num_examples=3581, test/ssim=0.730754, total_duration=953.000928, train/loss=0.275185, train/ssim=0.736013, validation/loss=0.293311, validation/num_examples=3554, validation/ssim=0.713601
I0204 18:04:44.541281 139487493474048 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.0974951907992363, loss=0.2578752040863037
I0204 18:05:08.208005 139487501866752 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.3117121160030365, loss=0.2537671625614166
I0204 18:05:32.068272 139487493474048 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.117869533598423, loss=0.29415905475616455
I0204 18:05:49.885932 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:05:51.256013 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:05:52.575561 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:05:53.895494 139681449744192 submission_runner.py:408] Time since start: 1037.31s, 	Step: 2776, 	{'train/ssim': 0.7387440545218331, 'train/loss': 0.27338411126817974, 'validation/ssim': 0.7164845206325618, 'validation/loss': 0.29148267961715674, 'validation/num_examples': 3554, 'test/ssim': 0.7335982632949944, 'test/loss': 0.2931648601669401, 'test/num_examples': 3581, 'score': 792.1041221618652, 'total_duration': 1037.3116459846497, 'accumulated_submission_time': 792.1041221618652, 'accumulated_eval_time': 244.81696820259094, 'accumulated_logging_time': 0.2803800106048584}
I0204 18:05:53.911582 139487501866752 logging_writer.py:48] [2776] accumulated_eval_time=244.816968, accumulated_logging_time=0.280380, accumulated_submission_time=792.104122, global_step=2776, preemption_count=0, score=792.104122, test/loss=0.293165, test/num_examples=3581, test/ssim=0.733598, total_duration=1037.311646, train/loss=0.273384, train/ssim=0.738744, validation/loss=0.291483, validation/num_examples=3554, validation/ssim=0.716485
I0204 18:05:57.533920 139487493474048 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.16608166694641113, loss=0.3505792021751404
I0204 18:06:21.397997 139487501866752 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.3225710690021515, loss=0.2264912724494934
I0204 18:06:45.156932 139487493474048 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.12707304954528809, loss=0.2601647675037384
I0204 18:07:09.090852 139487501866752 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.10115210711956024, loss=0.2391882985830307
I0204 18:07:13.950777 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:07:15.320551 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:07:16.638359 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:07:17.960855 139681449744192 submission_runner.py:408] Time since start: 1121.38s, 	Step: 3120, 	{'train/ssim': 0.7408569880894252, 'train/loss': 0.27269210134233746, 'validation/ssim': 0.7182428964283202, 'validation/loss': 0.2912389855070871, 'validation/num_examples': 3554, 'test/ssim': 0.7353520397366309, 'test/loss': 0.2928364872765987, 'test/num_examples': 3581, 'score': 872.119637966156, 'total_duration': 1121.3769915103912, 'accumulated_submission_time': 872.119637966156, 'accumulated_eval_time': 248.82698583602905, 'accumulated_logging_time': 0.3063969612121582}
I0204 18:07:17.977358 139487493474048 logging_writer.py:48] [3120] accumulated_eval_time=248.826986, accumulated_logging_time=0.306397, accumulated_submission_time=872.119638, global_step=3120, preemption_count=0, score=872.119638, test/loss=0.292836, test/num_examples=3581, test/ssim=0.735352, total_duration=1121.376992, train/loss=0.272692, train/ssim=0.740857, validation/loss=0.291239, validation/num_examples=3554, validation/ssim=0.718243
I0204 18:07:34.979632 139487501866752 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.11259565502405167, loss=0.27411264181137085
I0204 18:07:59.094021 139487493474048 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10494702309370041, loss=0.307945191860199
I0204 18:08:22.851611 139487501866752 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.08049614727497101, loss=0.37732958793640137
I0204 18:08:38.158188 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:08:39.527807 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:08:40.848262 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:08:42.167696 139681449744192 submission_runner.py:408] Time since start: 1205.58s, 	Step: 3465, 	{'train/ssim': 0.7407792636326381, 'train/loss': 0.27193306173597065, 'validation/ssim': 0.7179621415790307, 'validation/loss': 0.29063742685398497, 'validation/num_examples': 3554, 'test/ssim': 0.7351641448574071, 'test/loss': 0.29226359878961883, 'test/num_examples': 3581, 'score': 952.2769184112549, 'total_duration': 1205.583834886551, 'accumulated_submission_time': 952.2769184112549, 'accumulated_eval_time': 252.83643865585327, 'accumulated_logging_time': 0.33269166946411133}
I0204 18:08:42.183738 139487493474048 logging_writer.py:48] [3465] accumulated_eval_time=252.836439, accumulated_logging_time=0.332692, accumulated_submission_time=952.276918, global_step=3465, preemption_count=0, score=952.276918, test/loss=0.292264, test/num_examples=3581, test/ssim=0.735164, total_duration=1205.583835, train/loss=0.271933, train/ssim=0.740779, validation/loss=0.290637, validation/num_examples=3554, validation/ssim=0.717962
I0204 18:08:48.443857 139487501866752 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.104770727455616, loss=0.32274526357650757
I0204 18:09:12.230063 139487493474048 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.15814092755317688, loss=0.28800177574157715
I0204 18:09:36.138604 139487501866752 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1639419049024582, loss=0.22571998834609985
I0204 18:09:59.861505 139487493474048 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.1075543612241745, loss=0.2551840543746948
I0204 18:10:02.326327 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:10:03.697607 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:10:05.018040 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:10:06.338081 139681449744192 submission_runner.py:408] Time since start: 1289.75s, 	Step: 3811, 	{'train/ssim': 0.7399152347019741, 'train/loss': 0.2725422552653721, 'validation/ssim': 0.7170441068822102, 'validation/loss': 0.29134511867130347, 'validation/num_examples': 3554, 'test/ssim': 0.7342503048860305, 'test/loss': 0.2929896120584334, 'test/num_examples': 3581, 'score': 1032.3964014053345, 'total_duration': 1289.7542309761047, 'accumulated_submission_time': 1032.3964014053345, 'accumulated_eval_time': 256.84815645217896, 'accumulated_logging_time': 0.3579692840576172}
I0204 18:10:06.354022 139487501866752 logging_writer.py:48] [3811] accumulated_eval_time=256.848156, accumulated_logging_time=0.357969, accumulated_submission_time=1032.396401, global_step=3811, preemption_count=0, score=1032.396401, test/loss=0.292990, test/num_examples=3581, test/ssim=0.734250, total_duration=1289.754231, train/loss=0.272542, train/ssim=0.739915, validation/loss=0.291345, validation/num_examples=3554, validation/ssim=0.717044
I0204 18:10:25.572551 139487493474048 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.31707319617271423, loss=0.28003185987472534
I0204 18:10:49.511836 139487501866752 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.3328216075897217, loss=0.22416572272777557
I0204 18:11:13.383043 139487493474048 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.17416371405124664, loss=0.2928449809551239
I0204 18:11:26.429568 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:11:27.800894 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:11:29.120158 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:11:30.440176 139681449744192 submission_runner.py:408] Time since start: 1373.86s, 	Step: 4156, 	{'train/ssim': 0.7418276923043388, 'train/loss': 0.2715973513466971, 'validation/ssim': 0.7188788023837578, 'validation/loss': 0.2905141543859032, 'validation/num_examples': 3554, 'test/ssim': 0.7362064296591385, 'test/loss': 0.29198206326576026, 'test/num_examples': 3581, 'score': 1112.4486014842987, 'total_duration': 1373.8563287258148, 'accumulated_submission_time': 1112.4486014842987, 'accumulated_eval_time': 260.85873436927795, 'accumulated_logging_time': 0.3834872245788574}
I0204 18:11:30.456321 139487501866752 logging_writer.py:48] [4156] accumulated_eval_time=260.858734, accumulated_logging_time=0.383487, accumulated_submission_time=1112.448601, global_step=4156, preemption_count=0, score=1112.448601, test/loss=0.291982, test/num_examples=3581, test/ssim=0.736206, total_duration=1373.856329, train/loss=0.271597, train/ssim=0.741828, validation/loss=0.290514, validation/num_examples=3554, validation/ssim=0.718879
I0204 18:11:39.171828 139487493474048 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.10764672607183456, loss=0.23598811030387878
I0204 18:12:03.175411 139487501866752 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.24453964829444885, loss=0.31755751371383667
I0204 18:12:27.402695 139487493474048 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.13072890043258667, loss=0.258809894323349
I0204 18:12:50.514455 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:12:51.884057 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:12:53.205631 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:12:54.528578 139681449744192 submission_runner.py:408] Time since start: 1457.94s, 	Step: 4497, 	{'train/ssim': 0.7427105222429548, 'train/loss': 0.2710503510066441, 'validation/ssim': 0.7198047369601154, 'validation/loss': 0.2898978607400992, 'validation/num_examples': 3554, 'test/ssim': 0.7369858934306059, 'test/loss': 0.2915290293497801, 'test/num_examples': 3581, 'score': 1192.4837381839752, 'total_duration': 1457.9447252750397, 'accumulated_submission_time': 1192.4837381839752, 'accumulated_eval_time': 264.8728246688843, 'accumulated_logging_time': 0.4092543125152588}
I0204 18:12:54.545207 139487501866752 logging_writer.py:48] [4497] accumulated_eval_time=264.872825, accumulated_logging_time=0.409254, accumulated_submission_time=1192.483738, global_step=4497, preemption_count=0, score=1192.483738, test/loss=0.291529, test/num_examples=3581, test/ssim=0.736986, total_duration=1457.944725, train/loss=0.271050, train/ssim=0.742711, validation/loss=0.289898, validation/num_examples=3554, validation/ssim=0.719805
I0204 18:12:54.854774 139487493474048 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.13050469756126404, loss=0.26363828778266907
I0204 18:13:16.977271 139487501866752 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1490282565355301, loss=0.23350392282009125
I0204 18:13:40.607897 139487493474048 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.08572905510663986, loss=0.2536160945892334
I0204 18:14:04.426157 139487501866752 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.2735617160797119, loss=0.26640456914901733
I0204 18:14:14.573573 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:14:15.945667 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:14:17.266318 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:14:18.586008 139681449744192 submission_runner.py:408] Time since start: 1542.00s, 	Step: 4844, 	{'train/ssim': 0.7410882541111538, 'train/loss': 0.2719627789088658, 'validation/ssim': 0.719926257715778, 'validation/loss': 0.29002298796250703, 'validation/num_examples': 3554, 'test/ssim': 0.7367711369467328, 'test/loss': 0.291571639763247, 'test/num_examples': 3581, 'score': 1272.489012479782, 'total_duration': 1542.002141237259, 'accumulated_submission_time': 1272.489012479782, 'accumulated_eval_time': 268.8852117061615, 'accumulated_logging_time': 0.4353601932525635}
I0204 18:14:18.601413 139487493474048 logging_writer.py:48] [4844] accumulated_eval_time=268.885212, accumulated_logging_time=0.435360, accumulated_submission_time=1272.489012, global_step=4844, preemption_count=0, score=1272.489012, test/loss=0.291572, test/num_examples=3581, test/ssim=0.736771, total_duration=1542.002141, train/loss=0.271963, train/ssim=0.741088, validation/loss=0.290023, validation/num_examples=3554, validation/ssim=0.719926
I0204 18:14:29.955277 139487501866752 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.12747564911842346, loss=0.3681790232658386
I0204 18:14:53.837061 139487493474048 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.07534246891736984, loss=0.2966163158416748
I0204 18:15:17.465191 139487501866752 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.08109989762306213, loss=0.24019689857959747
I0204 18:15:38.623764 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:15:39.995144 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:15:41.313335 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:15:42.637441 139681449744192 submission_runner.py:408] Time since start: 1626.05s, 	Step: 5191, 	{'train/ssim': 0.7438113348824638, 'train/loss': 0.2707222359521048, 'validation/ssim': 0.7214453015088632, 'validation/loss': 0.28883728473858683, 'validation/num_examples': 3554, 'test/ssim': 0.7386012030726403, 'test/loss': 0.2904303965372801, 'test/num_examples': 3581, 'score': 1352.4867494106293, 'total_duration': 1626.053575515747, 'accumulated_submission_time': 1352.4867494106293, 'accumulated_eval_time': 272.89883518218994, 'accumulated_logging_time': 0.461669921875}
I0204 18:15:42.652921 139487493474048 logging_writer.py:48] [5191] accumulated_eval_time=272.898835, accumulated_logging_time=0.461670, accumulated_submission_time=1352.486749, global_step=5191, preemption_count=0, score=1352.486749, test/loss=0.290430, test/num_examples=3581, test/ssim=0.738601, total_duration=1626.053576, train/loss=0.270722, train/ssim=0.743811, validation/loss=0.288837, validation/num_examples=3554, validation/ssim=0.721445
I0204 18:15:43.394765 139487501866752 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.05621347203850746, loss=0.3119509518146515
I0204 18:16:07.096190 139487493474048 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.2020932286977768, loss=0.1988612562417984
I0204 18:16:31.141093 139487501866752 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.10814071446657181, loss=0.2390769124031067
I0204 18:16:55.328461 139487493474048 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.17414399981498718, loss=0.2711107134819031
I0204 18:17:02.813531 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:17:04.182018 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:17:05.501213 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:17:06.821789 139681449744192 submission_runner.py:408] Time since start: 1710.24s, 	Step: 5532, 	{'train/ssim': 0.7429601124354771, 'train/loss': 0.27090322971343994, 'validation/ssim': 0.7198999476821891, 'validation/loss': 0.2898524879537141, 'validation/num_examples': 3554, 'test/ssim': 0.7371778107328609, 'test/loss': 0.2914324571086987, 'test/num_examples': 3581, 'score': 1432.6245748996735, 'total_duration': 1710.2379422187805, 'accumulated_submission_time': 1432.6245748996735, 'accumulated_eval_time': 276.9070551395416, 'accumulated_logging_time': 0.4866147041320801}
I0204 18:17:06.837506 139487501866752 logging_writer.py:48] [5532] accumulated_eval_time=276.907055, accumulated_logging_time=0.486615, accumulated_submission_time=1432.624575, global_step=5532, preemption_count=0, score=1432.624575, test/loss=0.291432, test/num_examples=3581, test/ssim=0.737178, total_duration=1710.237942, train/loss=0.270903, train/ssim=0.742960, validation/loss=0.289852, validation/num_examples=3554, validation/ssim=0.719900
I0204 18:17:21.037409 139487493474048 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.1460079848766327, loss=0.2242097705602646
I0204 18:17:44.808120 139487501866752 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.16605675220489502, loss=0.29131728410720825
I0204 18:18:08.655910 139487493474048 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.1703988015651703, loss=0.43703511357307434
I0204 18:18:26.950608 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:18:28.320852 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:18:29.641240 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:18:30.960356 139681449744192 submission_runner.py:408] Time since start: 1794.38s, 	Step: 5878, 	{'train/ssim': 0.7389003208705357, 'train/loss': 0.2728471074785505, 'validation/ssim': 0.71665186068954, 'validation/loss': 0.29093432493537214, 'validation/num_examples': 3554, 'test/ssim': 0.7340223903064786, 'test/loss': 0.29241372379834546, 'test/num_examples': 3581, 'score': 1512.7141561508179, 'total_duration': 1794.376507282257, 'accumulated_submission_time': 1512.7141561508179, 'accumulated_eval_time': 280.91675758361816, 'accumulated_logging_time': 0.5123147964477539}
I0204 18:18:30.976088 139487501866752 logging_writer.py:48] [5878] accumulated_eval_time=280.916758, accumulated_logging_time=0.512315, accumulated_submission_time=1512.714156, global_step=5878, preemption_count=0, score=1512.714156, test/loss=0.292414, test/num_examples=3581, test/ssim=0.734022, total_duration=1794.376507, train/loss=0.272847, train/ssim=0.738900, validation/loss=0.290934, validation/num_examples=3554, validation/ssim=0.716652
I0204 18:18:34.186601 139487493474048 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.0932672768831253, loss=0.28128528594970703
I0204 18:18:57.994526 139487501866752 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.13415592908859253, loss=0.23604866862297058
I0204 18:19:22.507321 139487493474048 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.19888070225715637, loss=0.3355318009853363
I0204 18:19:46.560287 139487501866752 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17175522446632385, loss=0.2325909584760666
I0204 18:19:51.004911 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:19:52.376055 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:19:53.697089 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:19:55.018246 139681449744192 submission_runner.py:408] Time since start: 1878.43s, 	Step: 6220, 	{'train/ssim': 0.7431642668587821, 'train/loss': 0.2703012909208025, 'validation/ssim': 0.7207949009918402, 'validation/loss': 0.2887784134623839, 'validation/num_examples': 3554, 'test/ssim': 0.7380594713199874, 'test/loss': 0.29025184186068836, 'test/num_examples': 3581, 'score': 1592.7204446792603, 'total_duration': 1878.43439412117, 'accumulated_submission_time': 1592.7204446792603, 'accumulated_eval_time': 284.9300625324249, 'accumulated_logging_time': 0.5374350547790527}
I0204 18:19:55.034449 139487493474048 logging_writer.py:48] [6220] accumulated_eval_time=284.930063, accumulated_logging_time=0.537435, accumulated_submission_time=1592.720445, global_step=6220, preemption_count=0, score=1592.720445, test/loss=0.290252, test/num_examples=3581, test/ssim=0.738059, total_duration=1878.434394, train/loss=0.270301, train/ssim=0.743164, validation/loss=0.288778, validation/num_examples=3554, validation/ssim=0.720795
I0204 18:20:11.982042 139487501866752 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.25503793358802795, loss=0.28284305334091187
I0204 18:20:36.058727 139487493474048 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.17906813323497772, loss=0.2862549424171448
I0204 18:21:00.244424 139487501866752 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.06954017281532288, loss=0.2493172287940979
I0204 18:21:15.110613 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:21:16.483954 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:21:17.805149 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:21:19.126010 139681449744192 submission_runner.py:408] Time since start: 1962.54s, 	Step: 6563, 	{'train/ssim': 0.7439885820661273, 'train/loss': 0.2698183059692383, 'validation/ssim': 0.720698522461487, 'validation/loss': 0.2887259651317178, 'validation/num_examples': 3554, 'test/ssim': 0.7378159442849413, 'test/loss': 0.2902247075493926, 'test/num_examples': 3581, 'score': 1672.7735142707825, 'total_duration': 1962.5421574115753, 'accumulated_submission_time': 1672.7735142707825, 'accumulated_eval_time': 288.94540882110596, 'accumulated_logging_time': 0.563525915145874}
I0204 18:21:19.143947 139487493474048 logging_writer.py:48] [6563] accumulated_eval_time=288.945409, accumulated_logging_time=0.563526, accumulated_submission_time=1672.773514, global_step=6563, preemption_count=0, score=1672.773514, test/loss=0.290225, test/num_examples=3581, test/ssim=0.737816, total_duration=1962.542157, train/loss=0.269818, train/ssim=0.743989, validation/loss=0.288726, validation/num_examples=3554, validation/ssim=0.720699
I0204 18:21:25.879142 139487501866752 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.10342173278331757, loss=0.3104647099971771
I0204 18:21:49.765577 139487493474048 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.17055049538612366, loss=0.26020359992980957
I0204 18:22:13.572685 139487501866752 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.19084909558296204, loss=0.2772902846336365
I0204 18:22:37.363108 139487493474048 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.07121153920888901, loss=0.31384986639022827
I0204 18:22:39.155748 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:22:40.526400 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:22:41.847223 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:22:43.168488 139681449744192 submission_runner.py:408] Time since start: 2046.58s, 	Step: 6909, 	{'train/ssim': 0.7427389962332589, 'train/loss': 0.2705033676964896, 'validation/ssim': 0.7205512412290729, 'validation/loss': 0.2888722159450619, 'validation/num_examples': 3554, 'test/ssim': 0.7378185349980801, 'test/loss': 0.29024720584770314, 'test/num_examples': 3581, 'score': 1752.762172460556, 'total_duration': 2046.5846438407898, 'accumulated_submission_time': 1752.762172460556, 'accumulated_eval_time': 292.95811128616333, 'accumulated_logging_time': 0.5912113189697266}
I0204 18:22:43.185542 139487501866752 logging_writer.py:48] [6909] accumulated_eval_time=292.958111, accumulated_logging_time=0.591211, accumulated_submission_time=1752.762172, global_step=6909, preemption_count=0, score=1752.762172, test/loss=0.290247, test/num_examples=3581, test/ssim=0.737819, total_duration=2046.584644, train/loss=0.270503, train/ssim=0.742739, validation/loss=0.288872, validation/num_examples=3554, validation/ssim=0.720551
I0204 18:23:02.933412 139487493474048 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.18182966113090515, loss=0.22660502791404724
I0204 18:23:26.941635 139487501866752 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.08052671700716019, loss=0.24121055006980896
I0204 18:23:50.827260 139487493474048 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.18994653224945068, loss=0.2360651195049286
I0204 18:24:03.394626 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:24:04.766151 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:24:06.084603 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:24:07.406639 139681449744192 submission_runner.py:408] Time since start: 2130.82s, 	Step: 7254, 	{'train/ssim': 0.7382341793605259, 'train/loss': 0.27244414602007183, 'validation/ssim': 0.7179365871860931, 'validation/loss': 0.29044181896718485, 'validation/num_examples': 3554, 'test/ssim': 0.7345816434611491, 'test/loss': 0.2919200565920832, 'test/num_examples': 3581, 'score': 1832.9484798908234, 'total_duration': 2130.8227894306183, 'accumulated_submission_time': 1832.9484798908234, 'accumulated_eval_time': 296.9700815677643, 'accumulated_logging_time': 0.6176929473876953}
I0204 18:24:07.423244 139487501866752 logging_writer.py:48] [7254] accumulated_eval_time=296.970082, accumulated_logging_time=0.617693, accumulated_submission_time=1832.948480, global_step=7254, preemption_count=0, score=1832.948480, test/loss=0.291920, test/num_examples=3581, test/ssim=0.734582, total_duration=2130.822789, train/loss=0.272444, train/ssim=0.738234, validation/loss=0.290442, validation/num_examples=3554, validation/ssim=0.717937
I0204 18:24:16.298661 139487493474048 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.1224910244345665, loss=0.24767981469631195
I0204 18:24:39.878875 139487501866752 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.283060222864151, loss=0.2586438059806824
I0204 18:25:04.199014 139487493474048 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.13872165977954865, loss=0.19056834280490875
I0204 18:25:27.440189 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:25:28.811105 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:25:30.130272 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:25:31.451058 139681449744192 submission_runner.py:408] Time since start: 2214.87s, 	Step: 7598, 	{'train/ssim': 0.744854313986642, 'train/loss': 0.26909659590039936, 'validation/ssim': 0.722372472588105, 'validation/loss': 0.28758535991576395, 'validation/num_examples': 3554, 'test/ssim': 0.7394905676225216, 'test/loss': 0.2890893956929803, 'test/num_examples': 3581, 'score': 1912.9425868988037, 'total_duration': 2214.8672075271606, 'accumulated_submission_time': 1912.9425868988037, 'accumulated_eval_time': 300.9809060096741, 'accumulated_logging_time': 0.643923282623291}
I0204 18:25:31.468492 139487501866752 logging_writer.py:48] [7598] accumulated_eval_time=300.980906, accumulated_logging_time=0.643923, accumulated_submission_time=1912.942587, global_step=7598, preemption_count=0, score=1912.942587, test/loss=0.289089, test/num_examples=3581, test/ssim=0.739491, total_duration=2214.867208, train/loss=0.269097, train/ssim=0.744854, validation/loss=0.287585, validation/num_examples=3554, validation/ssim=0.722372
I0204 18:25:31.704068 139487493474048 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.3288284242153168, loss=0.2535865306854248
I0204 18:25:53.491275 139487501866752 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.19552575051784515, loss=0.24291446805000305
I0204 18:26:17.434205 139487493474048 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.07382109761238098, loss=0.3508869707584381
I0204 18:26:40.984107 139487501866752 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.18304966390132904, loss=0.29106763005256653
I0204 18:26:51.537405 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:26:52.909860 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:26:54.228571 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:26:55.547427 139681449744192 submission_runner.py:408] Time since start: 2298.96s, 	Step: 7945, 	{'train/ssim': 0.7442718233380999, 'train/loss': 0.2691159078053066, 'validation/ssim': 0.7212834570202589, 'validation/loss': 0.28783448089960256, 'validation/num_examples': 3554, 'test/ssim': 0.7386821969465582, 'test/loss': 0.28917294619170625, 'test/num_examples': 3581, 'score': 1992.9886183738708, 'total_duration': 2298.9635775089264, 'accumulated_submission_time': 1992.9886183738708, 'accumulated_eval_time': 304.9908983707428, 'accumulated_logging_time': 0.6710951328277588}
I0204 18:26:55.564115 139487493474048 logging_writer.py:48] [7945] accumulated_eval_time=304.990898, accumulated_logging_time=0.671095, accumulated_submission_time=1992.988618, global_step=7945, preemption_count=0, score=1992.988618, test/loss=0.289173, test/num_examples=3581, test/ssim=0.738682, total_duration=2298.963578, train/loss=0.269116, train/ssim=0.744272, validation/loss=0.287834, validation/num_examples=3554, validation/ssim=0.721283
I0204 18:27:06.538568 139487501866752 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.28002041578292847, loss=0.2651427686214447
I0204 18:27:30.158955 139487493474048 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.17096905410289764, loss=0.2571753263473511
I0204 18:27:53.920000 139487501866752 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.06882552802562714, loss=0.3218650817871094
I0204 18:28:15.578894 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:28:16.950530 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:28:18.270410 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:28:19.592118 139681449744192 submission_runner.py:408] Time since start: 2383.01s, 	Step: 8291, 	{'train/ssim': 0.7449304035731724, 'train/loss': 0.26954868861607145, 'validation/ssim': 0.7218863895654544, 'validation/loss': 0.2882051226391038, 'validation/num_examples': 3554, 'test/ssim': 0.7391878632452528, 'test/loss': 0.2895576670928163, 'test/num_examples': 3581, 'score': 2072.9793784618378, 'total_duration': 2383.0082693099976, 'accumulated_submission_time': 2072.9793784618378, 'accumulated_eval_time': 309.0040822029114, 'accumulated_logging_time': 0.6984851360321045}
I0204 18:28:19.609026 139487493474048 logging_writer.py:48] [8291] accumulated_eval_time=309.004082, accumulated_logging_time=0.698485, accumulated_submission_time=2072.979378, global_step=8291, preemption_count=0, score=2072.979378, test/loss=0.289558, test/num_examples=3581, test/ssim=0.739188, total_duration=2383.008269, train/loss=0.269549, train/ssim=0.744930, validation/loss=0.288205, validation/num_examples=3554, validation/ssim=0.721886
I0204 18:28:20.352320 139487501866752 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.3469003736972809, loss=0.29607686400413513
I0204 18:28:43.514635 139487493474048 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.10297743231058121, loss=0.23231863975524902
I0204 18:29:07.496306 139487501866752 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.1377429962158203, loss=0.27613139152526855
I0204 18:29:31.790261 139487493474048 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.20796748995780945, loss=0.1959422528743744
I0204 18:29:39.596510 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:29:40.969262 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:29:42.288134 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:29:43.608898 139681449744192 submission_runner.py:408] Time since start: 2467.03s, 	Step: 8634, 	{'train/ssim': 0.746199539729527, 'train/loss': 0.2686595065253122, 'validation/ssim': 0.7233574158298748, 'validation/loss': 0.2872973577856816, 'validation/num_examples': 3554, 'test/ssim': 0.7405721221813041, 'test/loss': 0.28873610423284346, 'test/num_examples': 3581, 'score': 2152.9430842399597, 'total_duration': 2467.0250334739685, 'accumulated_submission_time': 2152.9430842399597, 'accumulated_eval_time': 313.0164098739624, 'accumulated_logging_time': 0.7257647514343262}
I0204 18:29:43.626118 139487501866752 logging_writer.py:48] [8634] accumulated_eval_time=313.016410, accumulated_logging_time=0.725765, accumulated_submission_time=2152.943084, global_step=8634, preemption_count=0, score=2152.943084, test/loss=0.288736, test/num_examples=3581, test/ssim=0.740572, total_duration=2467.025033, train/loss=0.268660, train/ssim=0.746200, validation/loss=0.287297, validation/num_examples=3554, validation/ssim=0.723357
I0204 18:29:57.731958 139487493474048 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.11488094925880432, loss=0.2677917778491974
I0204 18:30:21.643610 139487501866752 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.10549074411392212, loss=0.25988781452178955
I0204 18:30:45.462482 139487493474048 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.14557380974292755, loss=0.29211339354515076
I0204 18:31:03.688493 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:31:05.057043 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:31:06.377519 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:31:07.699026 139681449744192 submission_runner.py:408] Time since start: 2551.12s, 	Step: 8978, 	{'train/ssim': 0.7457756996154785, 'train/loss': 0.2681561027254377, 'validation/ssim': 0.7230410771753658, 'validation/loss': 0.2870447505506559, 'validation/num_examples': 3554, 'test/ssim': 0.7401969460128107, 'test/loss': 0.28850501943852974, 'test/num_examples': 3581, 'score': 2232.981694459915, 'total_duration': 2551.1151769161224, 'accumulated_submission_time': 2232.981694459915, 'accumulated_eval_time': 317.02690291404724, 'accumulated_logging_time': 0.753577470779419}
I0204 18:31:07.715751 139487501866752 logging_writer.py:48] [8978] accumulated_eval_time=317.026903, accumulated_logging_time=0.753577, accumulated_submission_time=2232.981694, global_step=8978, preemption_count=0, score=2232.981694, test/loss=0.288505, test/num_examples=3581, test/ssim=0.740197, total_duration=2551.115177, train/loss=0.268156, train/ssim=0.745776, validation/loss=0.287045, validation/num_examples=3554, validation/ssim=0.723041
I0204 18:31:11.014440 139487493474048 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.17351561784744263, loss=0.33173075318336487
I0204 18:31:34.867932 139487501866752 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.1911807358264923, loss=0.28395384550094604
I0204 18:31:58.509393 139487493474048 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.22900693118572235, loss=0.22577853500843048
I0204 18:32:22.666956 139487501866752 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.05235941708087921, loss=0.42702293395996094
I0204 18:32:27.794818 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:32:29.166365 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:32:30.487101 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:32:31.808290 139681449744192 submission_runner.py:408] Time since start: 2635.22s, 	Step: 9322, 	{'train/ssim': 0.7460549899509975, 'train/loss': 0.2680826868329729, 'validation/ssim': 0.7233535002374085, 'validation/loss': 0.28688019262516706, 'validation/num_examples': 3554, 'test/ssim': 0.7405238531049287, 'test/loss': 0.2883283737084613, 'test/num_examples': 3581, 'score': 2313.0366671085358, 'total_duration': 2635.2244424819946, 'accumulated_submission_time': 2313.0366671085358, 'accumulated_eval_time': 321.0403423309326, 'accumulated_logging_time': 0.7809731960296631}
I0204 18:32:31.825382 139487493474048 logging_writer.py:48] [9322] accumulated_eval_time=321.040342, accumulated_logging_time=0.780973, accumulated_submission_time=2313.036667, global_step=9322, preemption_count=0, score=2313.036667, test/loss=0.288328, test/num_examples=3581, test/ssim=0.740524, total_duration=2635.224442, train/loss=0.268083, train/ssim=0.746055, validation/loss=0.286880, validation/num_examples=3554, validation/ssim=0.723354
I0204 18:32:48.398514 139487501866752 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.1410551369190216, loss=0.23464781045913696
I0204 18:33:12.257910 139487493474048 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.07675515860319138, loss=0.26939094066619873
I0204 18:33:35.920374 139487501866752 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.23619399964809418, loss=0.32392263412475586
I0204 18:33:52.017671 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:33:53.391084 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:33:54.709733 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:33:56.028982 139681449744192 submission_runner.py:408] Time since start: 2719.45s, 	Step: 9668, 	{'train/ssim': 0.7457577160426548, 'train/loss': 0.268416234425136, 'validation/ssim': 0.7224750336328785, 'validation/loss': 0.28726536327355623, 'validation/num_examples': 3554, 'test/ssim': 0.7397892495767593, 'test/loss': 0.28868507400167553, 'test/num_examples': 3581, 'score': 2393.2060899734497, 'total_duration': 2719.44512963295, 'accumulated_submission_time': 2393.2060899734497, 'accumulated_eval_time': 325.05160641670227, 'accumulated_logging_time': 0.8076949119567871}
I0204 18:33:56.046995 139487493474048 logging_writer.py:48] [9668] accumulated_eval_time=325.051606, accumulated_logging_time=0.807695, accumulated_submission_time=2393.206090, global_step=9668, preemption_count=0, score=2393.206090, test/loss=0.288685, test/num_examples=3581, test/ssim=0.739789, total_duration=2719.445130, train/loss=0.268416, train/ssim=0.745758, validation/loss=0.287265, validation/num_examples=3554, validation/ssim=0.722475
I0204 18:34:01.744291 139487501866752 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.20126289129257202, loss=0.3238584101200104
I0204 18:34:25.871919 139487493474048 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.22759610414505005, loss=0.2310619056224823
I0204 18:34:49.911259 139487501866752 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.15093447268009186, loss=0.24885313212871552
I0204 18:35:13.637627 139487493474048 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.14696919918060303, loss=0.30946657061576843
I0204 18:35:16.130378 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:35:17.500905 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:35:18.820652 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:35:20.142792 139681449744192 submission_runner.py:408] Time since start: 2803.56s, 	Step: 10012, 	{'train/ssim': 0.7463709967476981, 'train/loss': 0.26774992261614117, 'validation/ssim': 0.7230605177484877, 'validation/loss': 0.2868000088478651, 'validation/num_examples': 3554, 'test/ssim': 0.7403182322937029, 'test/loss': 0.2882206204948862, 'test/num_examples': 3581, 'score': 2473.2667071819305, 'total_duration': 2803.558928966522, 'accumulated_submission_time': 2473.2667071819305, 'accumulated_eval_time': 329.06395959854126, 'accumulated_logging_time': 0.8351755142211914}
I0204 18:35:20.159509 139487501866752 logging_writer.py:48] [10012] accumulated_eval_time=329.063960, accumulated_logging_time=0.835176, accumulated_submission_time=2473.266707, global_step=10012, preemption_count=0, score=2473.266707, test/loss=0.288221, test/num_examples=3581, test/ssim=0.740318, total_duration=2803.558929, train/loss=0.267750, train/ssim=0.746371, validation/loss=0.286800, validation/num_examples=3554, validation/ssim=0.723061
I0204 18:35:39.067080 139487493474048 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.17122690379619598, loss=0.25396108627319336
I0204 18:36:02.958330 139487501866752 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.14113210141658783, loss=0.36653268337249756
I0204 18:36:26.760192 139487493474048 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.14858299493789673, loss=0.24215583503246307
I0204 18:36:40.248323 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:36:41.620988 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:36:42.940928 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:36:44.259177 139681449744192 submission_runner.py:408] Time since start: 2887.68s, 	Step: 10358, 	{'train/ssim': 0.7464085987636021, 'train/loss': 0.2682306596211025, 'validation/ssim': 0.7235777881216587, 'validation/loss': 0.2870103173800647, 'validation/num_examples': 3554, 'test/ssim': 0.7408877119476054, 'test/loss': 0.2883491335019024, 'test/num_examples': 3581, 'score': 2553.332664489746, 'total_duration': 2887.675325155258, 'accumulated_submission_time': 2553.332664489746, 'accumulated_eval_time': 333.07476782798767, 'accumulated_logging_time': 0.8613989353179932}
I0204 18:36:44.276661 139487501866752 logging_writer.py:48] [10358] accumulated_eval_time=333.074768, accumulated_logging_time=0.861399, accumulated_submission_time=2553.332664, global_step=10358, preemption_count=0, score=2553.332664, test/loss=0.288349, test/num_examples=3581, test/ssim=0.740888, total_duration=2887.675325, train/loss=0.268231, train/ssim=0.746409, validation/loss=0.287010, validation/num_examples=3554, validation/ssim=0.723578
I0204 18:36:52.216776 139487493474048 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.16423696279525757, loss=0.29299411177635193
I0204 18:37:16.254678 139487501866752 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.15924812853336334, loss=0.33367201685905457
I0204 18:37:39.819519 139487493474048 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.11851860582828522, loss=0.2940508723258972
I0204 18:38:03.877967 139487501866752 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.11298089474439621, loss=0.22881750762462616
I0204 18:38:04.528205 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:38:05.899018 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:38:07.220674 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:38:08.541906 139681449744192 submission_runner.py:408] Time since start: 2971.96s, 	Step: 10703, 	{'train/ssim': 0.7456763812473842, 'train/loss': 0.268431510244097, 'validation/ssim': 0.7229905866409327, 'validation/loss': 0.2871879616277434, 'validation/num_examples': 3554, 'test/ssim': 0.7402850302595294, 'test/loss': 0.28853927821095715, 'test/num_examples': 3581, 'score': 2633.5612363815308, 'total_duration': 2971.9580538272858, 'accumulated_submission_time': 2633.5612363815308, 'accumulated_eval_time': 337.0884153842926, 'accumulated_logging_time': 0.8884561061859131}
I0204 18:38:08.559507 139487493474048 logging_writer.py:48] [10703] accumulated_eval_time=337.088415, accumulated_logging_time=0.888456, accumulated_submission_time=2633.561236, global_step=10703, preemption_count=0, score=2633.561236, test/loss=0.288539, test/num_examples=3581, test/ssim=0.740285, total_duration=2971.958054, train/loss=0.268432, train/ssim=0.745676, validation/loss=0.287188, validation/num_examples=3554, validation/ssim=0.722991
I0204 18:38:29.611136 139487501866752 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.2554861903190613, loss=0.3248260021209717
I0204 18:38:53.792618 139487493474048 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.12552696466445923, loss=0.2659246325492859
I0204 18:39:17.758635 139487501866752 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.06889285892248154, loss=0.26784080266952515
I0204 18:39:28.578864 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:39:29.948713 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:39:31.268930 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:39:32.591628 139681449744192 submission_runner.py:408] Time since start: 3056.01s, 	Step: 11047, 	{'train/ssim': 0.7449214799063546, 'train/loss': 0.2691765342439924, 'validation/ssim': 0.721823053139948, 'validation/loss': 0.2880697255732977, 'validation/num_examples': 3554, 'test/ssim': 0.7390198759512008, 'test/loss': 0.289556201294593, 'test/num_examples': 3581, 'score': 2713.557804107666, 'total_duration': 3056.007774591446, 'accumulated_submission_time': 2713.557804107666, 'accumulated_eval_time': 341.10114550590515, 'accumulated_logging_time': 0.9152963161468506}
I0204 18:39:32.610171 139487493474048 logging_writer.py:48] [11047] accumulated_eval_time=341.101146, accumulated_logging_time=0.915296, accumulated_submission_time=2713.557804, global_step=11047, preemption_count=0, score=2713.557804, test/loss=0.289556, test/num_examples=3581, test/ssim=0.739020, total_duration=3056.007775, train/loss=0.269177, train/ssim=0.744921, validation/loss=0.288070, validation/num_examples=3554, validation/ssim=0.721823
I0204 18:39:43.036630 139487501866752 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.05323885381221771, loss=0.2870485484600067
I0204 18:40:06.873161 139487493474048 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.24418456852436066, loss=0.277126282453537
I0204 18:40:30.874555 139487501866752 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.24172449111938477, loss=0.33409106731414795
I0204 18:40:52.779940 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:40:54.151171 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:40:55.469201 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:40:56.791634 139681449744192 submission_runner.py:408] Time since start: 3140.21s, 	Step: 11393, 	{'train/ssim': 0.7457105772835868, 'train/loss': 0.26866160120282856, 'validation/ssim': 0.7226912842483821, 'validation/loss': 0.28738107933512413, 'validation/num_examples': 3554, 'test/ssim': 0.7398553809384599, 'test/loss': 0.2887941566601508, 'test/num_examples': 3581, 'score': 2793.704563856125, 'total_duration': 3140.2077860832214, 'accumulated_submission_time': 2793.704563856125, 'accumulated_eval_time': 345.11279916763306, 'accumulated_logging_time': 0.943565845489502}
I0204 18:40:56.809531 139487493474048 logging_writer.py:48] [11393] accumulated_eval_time=345.112799, accumulated_logging_time=0.943566, accumulated_submission_time=2793.704564, global_step=11393, preemption_count=0, score=2793.704564, test/loss=0.288794, test/num_examples=3581, test/ssim=0.739855, total_duration=3140.207786, train/loss=0.268662, train/ssim=0.745711, validation/loss=0.287381, validation/num_examples=3554, validation/ssim=0.722691
I0204 18:40:57.406800 139487501866752 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.09332793951034546, loss=0.3052286207675934
I0204 18:41:20.126135 139487493474048 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.12549428641796112, loss=0.2635774612426758
I0204 18:41:44.099855 139487501866752 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.2131815403699875, loss=0.23597149550914764
I0204 18:42:07.831448 139487493474048 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.11091858148574829, loss=0.29667097330093384
I0204 18:42:16.922942 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:42:18.296841 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:42:19.615317 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:42:20.936101 139681449744192 submission_runner.py:408] Time since start: 3224.35s, 	Step: 11739, 	{'train/ssim': 0.7449744769505092, 'train/loss': 0.26911633355276926, 'validation/ssim': 0.7231983878200618, 'validation/loss': 0.28746392502835716, 'validation/num_examples': 3554, 'test/ssim': 0.7401566536058364, 'test/loss': 0.28885237952911197, 'test/num_examples': 3581, 'score': 2873.7954342365265, 'total_duration': 3224.352249622345, 'accumulated_submission_time': 2873.7954342365265, 'accumulated_eval_time': 349.1259129047394, 'accumulated_logging_time': 0.970717191696167}
I0204 18:42:20.953714 139487501866752 logging_writer.py:48] [11739] accumulated_eval_time=349.125913, accumulated_logging_time=0.970717, accumulated_submission_time=2873.795434, global_step=11739, preemption_count=0, score=2873.795434, test/loss=0.288852, test/num_examples=3581, test/ssim=0.740157, total_duration=3224.352250, train/loss=0.269116, train/ssim=0.744974, validation/loss=0.287464, validation/num_examples=3554, validation/ssim=0.723198
I0204 18:42:34.042093 139487493474048 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.12116339802742004, loss=0.31342676281929016
I0204 18:42:57.944298 139487501866752 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.34354162216186523, loss=0.2747596502304077
I0204 18:43:21.890231 139487493474048 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.10549306124448776, loss=0.25544485449790955
I0204 18:43:41.126045 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:43:42.496243 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:43:43.814013 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:43:45.136345 139681449744192 submission_runner.py:408] Time since start: 3308.55s, 	Step: 12081, 	{'train/ssim': 0.7475405420575824, 'train/loss': 0.26773977279663086, 'validation/ssim': 0.7239450294782288, 'validation/loss': 0.28714703681701076, 'validation/num_examples': 3554, 'test/ssim': 0.7412144826864004, 'test/loss': 0.28849942895228287, 'test/num_examples': 3581, 'score': 2953.9432995319366, 'total_duration': 3308.552498102188, 'accumulated_submission_time': 2953.9432995319366, 'accumulated_eval_time': 353.13616919517517, 'accumulated_logging_time': 0.9994661808013916}
I0204 18:43:45.154384 139487501866752 logging_writer.py:48] [12081] accumulated_eval_time=353.136169, accumulated_logging_time=0.999466, accumulated_submission_time=2953.943300, global_step=12081, preemption_count=0, score=2953.943300, test/loss=0.288499, test/num_examples=3581, test/ssim=0.741214, total_duration=3308.552498, train/loss=0.267740, train/ssim=0.747541, validation/loss=0.287147, validation/num_examples=3554, validation/ssim=0.723945
I0204 18:43:47.536754 139487493474048 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.16336150467395782, loss=0.29279208183288574
I0204 18:44:11.334409 139487501866752 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.15437328815460205, loss=0.2586873173713684
I0204 18:44:35.206611 139487493474048 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.13122451305389404, loss=0.2864898443222046
I0204 18:44:58.836266 139487501866752 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.13041751086711884, loss=0.2571451961994171
I0204 18:45:05.274275 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:45:06.645095 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:45:07.966140 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:45:09.287000 139681449744192 submission_runner.py:408] Time since start: 3392.70s, 	Step: 12428, 	{'train/ssim': 0.7480308668954032, 'train/loss': 0.2676975556782314, 'validation/ssim': 0.7251667630222988, 'validation/loss': 0.28655677842637695, 'validation/num_examples': 3554, 'test/ssim': 0.7423336707623569, 'test/loss': 0.28791709799767873, 'test/num_examples': 3581, 'score': 3034.0391058921814, 'total_duration': 3392.7031519412994, 'accumulated_submission_time': 3034.0391058921814, 'accumulated_eval_time': 357.14885449409485, 'accumulated_logging_time': 1.0281689167022705}
I0204 18:45:09.305094 139487493474048 logging_writer.py:48] [12428] accumulated_eval_time=357.148854, accumulated_logging_time=1.028169, accumulated_submission_time=3034.039106, global_step=12428, preemption_count=0, score=3034.039106, test/loss=0.287917, test/num_examples=3581, test/ssim=0.742334, total_duration=3392.703152, train/loss=0.267698, train/ssim=0.748031, validation/loss=0.286557, validation/num_examples=3554, validation/ssim=0.725167
I0204 18:45:24.547388 139487501866752 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.11639455705881119, loss=0.29915788769721985
I0204 18:45:48.555915 139487493474048 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.19761471450328827, loss=0.30106955766677856
I0204 18:46:12.578749 139487501866752 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.2445715069770813, loss=0.27184873819351196
I0204 18:46:29.494491 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:46:30.865278 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:46:32.189032 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:46:33.510771 139681449744192 submission_runner.py:408] Time since start: 3476.93s, 	Step: 12772, 	{'train/ssim': 0.7462588718959263, 'train/loss': 0.2679569721221924, 'validation/ssim': 0.7233728721159257, 'validation/loss': 0.2866768737689927, 'validation/num_examples': 3554, 'test/ssim': 0.740602392619031, 'test/loss': 0.28806333693669717, 'test/num_examples': 3581, 'score': 3114.203953027725, 'total_duration': 3476.9269206523895, 'accumulated_submission_time': 3114.203953027725, 'accumulated_eval_time': 361.1650941371918, 'accumulated_logging_time': 1.0573818683624268}
I0204 18:46:33.528658 139487493474048 logging_writer.py:48] [12772] accumulated_eval_time=361.165094, accumulated_logging_time=1.057382, accumulated_submission_time=3114.203953, global_step=12772, preemption_count=0, score=3114.203953, test/loss=0.288063, test/num_examples=3581, test/ssim=0.740602, total_duration=3476.926921, train/loss=0.267957, train/ssim=0.746259, validation/loss=0.286677, validation/num_examples=3554, validation/ssim=0.723373
I0204 18:46:38.247529 139487501866752 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.29666221141815186, loss=0.2536059021949768
I0204 18:47:02.850032 139487493474048 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.13392886519432068, loss=0.20886360108852386
I0204 18:47:26.751757 139487501866752 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.16261295974254608, loss=0.30218398571014404
I0204 18:47:50.811968 139487493474048 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.3381967544555664, loss=0.2557099163532257
I0204 18:47:53.607598 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:47:54.979899 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:47:56.300016 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:47:57.622503 139681449744192 submission_runner.py:408] Time since start: 3561.04s, 	Step: 13113, 	{'train/ssim': 0.7472739900861468, 'train/loss': 0.2680355651038034, 'validation/ssim': 0.724447667900605, 'validation/loss': 0.28695208152895507, 'validation/num_examples': 3554, 'test/ssim': 0.7415505936278274, 'test/loss': 0.28836062126937306, 'test/num_examples': 3581, 'score': 3194.259214401245, 'total_duration': 3561.0386533737183, 'accumulated_submission_time': 3194.259214401245, 'accumulated_eval_time': 365.1799545288086, 'accumulated_logging_time': 1.085845947265625}
I0204 18:47:57.640647 139487501866752 logging_writer.py:48] [13113] accumulated_eval_time=365.179955, accumulated_logging_time=1.085846, accumulated_submission_time=3194.259214, global_step=13113, preemption_count=0, score=3194.259214, test/loss=0.288361, test/num_examples=3581, test/ssim=0.741551, total_duration=3561.038653, train/loss=0.268036, train/ssim=0.747274, validation/loss=0.286952, validation/num_examples=3554, validation/ssim=0.724448
I0204 18:48:16.484806 139487493474048 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.221483051776886, loss=0.23002296686172485
I0204 18:48:40.278133 139487501866752 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.16687257587909698, loss=0.348749577999115
I0204 18:49:04.012691 139487493474048 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.24717985093593597, loss=0.4083702266216278
I0204 18:49:17.643536 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:49:19.014273 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:49:20.336378 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:49:21.660660 139681449744192 submission_runner.py:408] Time since start: 3645.08s, 	Step: 13458, 	{'train/ssim': 0.7458792413984027, 'train/loss': 0.26855465344020296, 'validation/ssim': 0.7230923233504502, 'validation/loss': 0.28733264963883126, 'validation/num_examples': 3554, 'test/ssim': 0.7403828637688494, 'test/loss': 0.2886832332318137, 'test/num_examples': 3581, 'score': 3274.239005088806, 'total_duration': 3645.07679104805, 'accumulated_submission_time': 3274.239005088806, 'accumulated_eval_time': 369.19701194763184, 'accumulated_logging_time': 1.113793134689331}
I0204 18:49:21.678779 139487501866752 logging_writer.py:48] [13458] accumulated_eval_time=369.197012, accumulated_logging_time=1.113793, accumulated_submission_time=3274.239005, global_step=13458, preemption_count=0, score=3274.239005, test/loss=0.288683, test/num_examples=3581, test/ssim=0.740383, total_duration=3645.076791, train/loss=0.268555, train/ssim=0.745879, validation/loss=0.287333, validation/num_examples=3554, validation/ssim=0.723092
I0204 18:49:29.605901 139487493474048 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.1000213548541069, loss=0.3285757601261139
I0204 18:49:53.345553 139487501866752 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.16654954850673676, loss=0.19771981239318848
I0204 18:50:17.262210 139487493474048 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.11486679315567017, loss=0.3166792392730713
I0204 18:50:40.999058 139487501866752 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.2848975360393524, loss=0.2645243704319
I0204 18:50:41.857653 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:50:43.229827 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:50:44.550644 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:50:45.872887 139681449744192 submission_runner.py:408] Time since start: 3729.29s, 	Step: 13805, 	{'train/ssim': 0.7467846189226423, 'train/loss': 0.26799471037728445, 'validation/ssim': 0.7235428912624859, 'validation/loss': 0.28704847723295934, 'validation/num_examples': 3554, 'test/ssim': 0.7408170127495811, 'test/loss': 0.28847887368882646, 'test/num_examples': 3581, 'score': 3354.3945803642273, 'total_duration': 3729.289011478424, 'accumulated_submission_time': 3354.3945803642273, 'accumulated_eval_time': 373.212171792984, 'accumulated_logging_time': 1.1418728828430176}
I0204 18:50:45.891034 139487493474048 logging_writer.py:48] [13805] accumulated_eval_time=373.212172, accumulated_logging_time=1.141873, accumulated_submission_time=3354.394580, global_step=13805, preemption_count=0, score=3354.394580, test/loss=0.288479, test/num_examples=3581, test/ssim=0.740817, total_duration=3729.289011, train/loss=0.267995, train/ssim=0.746785, validation/loss=0.287048, validation/num_examples=3554, validation/ssim=0.723543
I0204 18:51:06.489923 139487501866752 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.10292225331068039, loss=0.23444828391075134
I0204 18:51:30.801707 139487493474048 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.15645857155323029, loss=0.2172679752111435
I0204 18:51:54.876470 139487501866752 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.15074694156646729, loss=0.24408842623233795
I0204 18:52:05.974881 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:52:07.346770 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:52:08.667516 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:52:09.988624 139681449744192 submission_runner.py:408] Time since start: 3813.40s, 	Step: 14147, 	{'train/ssim': 0.7473293713160923, 'train/loss': 0.2674491916384016, 'validation/ssim': 0.7241186207442318, 'validation/loss': 0.2863896444532129, 'validation/num_examples': 3554, 'test/ssim': 0.7413705390646816, 'test/loss': 0.28778790322404707, 'test/num_examples': 3581, 'score': 3434.455368757248, 'total_duration': 3813.404773712158, 'accumulated_submission_time': 3434.455368757248, 'accumulated_eval_time': 377.22587037086487, 'accumulated_logging_time': 1.1696898937225342}
I0204 18:52:10.010974 139487493474048 logging_writer.py:48] [14147] accumulated_eval_time=377.225870, accumulated_logging_time=1.169690, accumulated_submission_time=3434.455369, global_step=14147, preemption_count=0, score=3434.455369, test/loss=0.287788, test/num_examples=3581, test/ssim=0.741371, total_duration=3813.404774, train/loss=0.267449, train/ssim=0.747329, validation/loss=0.286390, validation/num_examples=3554, validation/ssim=0.724119
I0204 18:52:20.711457 139487501866752 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.11549185961484909, loss=0.35532626509666443
I0204 18:52:44.899217 139487493474048 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.18369732797145844, loss=0.33056360483169556
I0204 18:53:09.119877 139487501866752 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.1463012397289276, loss=0.28794437646865845
I0204 18:53:30.064278 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:53:31.434536 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:53:32.752774 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:53:34.074185 139681449744192 submission_runner.py:408] Time since start: 3897.49s, 	Step: 14488, 	{'train/ssim': 0.7461852346147809, 'train/loss': 0.2679217542920794, 'validation/ssim': 0.723222568320906, 'validation/loss': 0.2866953526176491, 'validation/num_examples': 3554, 'test/ssim': 0.7404717661355068, 'test/loss': 0.2880733248176138, 'test/num_examples': 3581, 'score': 3514.4844086170197, 'total_duration': 3897.490335702896, 'accumulated_submission_time': 3514.4844086170197, 'accumulated_eval_time': 381.2357349395752, 'accumulated_logging_time': 1.2031478881835938}
I0204 18:53:34.092872 139487493474048 logging_writer.py:48] [14488] accumulated_eval_time=381.235735, accumulated_logging_time=1.203148, accumulated_submission_time=3514.484409, global_step=14488, preemption_count=0, score=3514.484409, test/loss=0.288073, test/num_examples=3581, test/ssim=0.740472, total_duration=3897.490336, train/loss=0.267922, train/ssim=0.746185, validation/loss=0.286695, validation/num_examples=3554, validation/ssim=0.723223
I0204 18:53:35.050638 139487501866752 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.10743937641382217, loss=0.3414536714553833
I0204 18:53:58.707910 139487493474048 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.2253311723470688, loss=0.2121095359325409
I0204 18:54:22.900291 139487501866752 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.16534323990345, loss=0.2609677016735077
I0204 18:54:47.018797 139487493474048 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.09461503475904465, loss=0.34032154083251953
I0204 18:54:54.212002 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:54:55.584762 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:54:56.905240 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:54:58.226426 139681449744192 submission_runner.py:408] Time since start: 3981.64s, 	Step: 14832, 	{'train/ssim': 0.7476575715201241, 'train/loss': 0.2674539940697806, 'validation/ssim': 0.7245439090417487, 'validation/loss': 0.28643901870032007, 'validation/num_examples': 3554, 'test/ssim': 0.7417353523806199, 'test/loss': 0.28783964931016126, 'test/num_examples': 3581, 'score': 3594.580799818039, 'total_duration': 3981.6425681114197, 'accumulated_submission_time': 3594.580799818039, 'accumulated_eval_time': 385.2501049041748, 'accumulated_logging_time': 1.2313237190246582}
I0204 18:54:58.245398 139487501866752 logging_writer.py:48] [14832] accumulated_eval_time=385.250105, accumulated_logging_time=1.231324, accumulated_submission_time=3594.580800, global_step=14832, preemption_count=0, score=3594.580800, test/loss=0.287840, test/num_examples=3581, test/ssim=0.741735, total_duration=3981.642568, train/loss=0.267454, train/ssim=0.747658, validation/loss=0.286439, validation/num_examples=3554, validation/ssim=0.724544
I0204 18:55:12.409999 139487493474048 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.1742783635854721, loss=0.35185936093330383
I0204 18:55:36.381868 139487501866752 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.13250169157981873, loss=0.21882326900959015
I0204 18:56:00.771446 139487493474048 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.1088746041059494, loss=0.1962190419435501
I0204 18:56:18.299162 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:56:19.668679 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:56:20.990053 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:56:22.312852 139681449744192 submission_runner.py:408] Time since start: 4065.73s, 	Step: 15175, 	{'train/ssim': 0.7454748834882464, 'train/loss': 0.2678097827093942, 'validation/ssim': 0.7224384881031936, 'validation/loss': 0.2868108969427054, 'validation/num_examples': 3554, 'test/ssim': 0.7397276178747207, 'test/loss': 0.28818574813250486, 'test/num_examples': 3581, 'score': 3674.611796617508, 'total_duration': 4065.728991985321, 'accumulated_submission_time': 3674.611796617508, 'accumulated_eval_time': 389.26374077796936, 'accumulated_logging_time': 1.2599167823791504}
I0204 18:56:22.331494 139487501866752 logging_writer.py:48] [15175] accumulated_eval_time=389.263741, accumulated_logging_time=1.259917, accumulated_submission_time=3674.611797, global_step=15175, preemption_count=0, score=3674.611797, test/loss=0.288186, test/num_examples=3581, test/ssim=0.739728, total_duration=4065.728992, train/loss=0.267810, train/ssim=0.745475, validation/loss=0.286811, validation/num_examples=3554, validation/ssim=0.722438
I0204 18:56:26.242252 139487493474048 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.2102811634540558, loss=0.25783735513687134
I0204 18:56:50.023923 139487501866752 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.21451425552368164, loss=0.24168778955936432
I0204 18:57:13.780425 139487493474048 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.10146688669919968, loss=0.2743886709213257
I0204 18:57:37.568589 139487501866752 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.12290342152118683, loss=0.25597909092903137
I0204 18:57:42.527679 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:57:43.901883 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:57:45.222936 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:57:46.543929 139681449744192 submission_runner.py:408] Time since start: 4149.96s, 	Step: 15522, 	{'train/ssim': 0.7466159548078265, 'train/loss': 0.26793583801814486, 'validation/ssim': 0.7230707532445836, 'validation/loss': 0.28724020387459553, 'validation/num_examples': 3554, 'test/ssim': 0.7403652741901704, 'test/loss': 0.28855615193469003, 'test/num_examples': 3581, 'score': 3754.784963130951, 'total_duration': 4149.960080385208, 'accumulated_submission_time': 3754.784963130951, 'accumulated_eval_time': 393.27994561195374, 'accumulated_logging_time': 1.2880818843841553}
I0204 18:57:46.562378 139487493474048 logging_writer.py:48] [15522] accumulated_eval_time=393.279946, accumulated_logging_time=1.288082, accumulated_submission_time=3754.784963, global_step=15522, preemption_count=0, score=3754.784963, test/loss=0.288556, test/num_examples=3581, test/ssim=0.740365, total_duration=4149.960080, train/loss=0.267936, train/ssim=0.746616, validation/loss=0.287240, validation/num_examples=3554, validation/ssim=0.723071
I0204 18:58:03.286827 139487501866752 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.1556546986103058, loss=0.2758311927318573
I0204 18:58:27.375667 139487493474048 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.3067699372768402, loss=0.20804110169410706
I0204 18:58:51.161718 139487501866752 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.11060603708028793, loss=0.24947164952754974
I0204 18:59:06.740289 139681449744192 spec.py:321] Evaluating on the training split.
I0204 18:59:08.114277 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 18:59:09.433991 139681449744192 spec.py:349] Evaluating on the test split.
I0204 18:59:10.755887 139681449744192 submission_runner.py:408] Time since start: 4234.17s, 	Step: 15867, 	{'train/ssim': 0.7471408843994141, 'train/loss': 0.26690876483917236, 'validation/ssim': 0.7238568943004361, 'validation/loss': 0.28590577683156304, 'validation/num_examples': 3554, 'test/ssim': 0.7412455712440659, 'test/loss': 0.28724566014643255, 'test/num_examples': 3581, 'score': 3834.939851999283, 'total_duration': 4234.172024965286, 'accumulated_submission_time': 3834.939851999283, 'accumulated_eval_time': 397.2954897880554, 'accumulated_logging_time': 1.3162243366241455}
I0204 18:59:10.774826 139487493474048 logging_writer.py:48] [15867] accumulated_eval_time=397.295490, accumulated_logging_time=1.316224, accumulated_submission_time=3834.939852, global_step=15867, preemption_count=0, score=3834.939852, test/loss=0.287246, test/num_examples=3581, test/ssim=0.741246, total_duration=4234.172025, train/loss=0.266909, train/ssim=0.747141, validation/loss=0.285906, validation/num_examples=3554, validation/ssim=0.723857
I0204 18:59:16.524051 139487501866752 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.44088080525398254, loss=0.21032650768756866
I0204 18:59:40.381217 139487493474048 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.20339614152908325, loss=0.23548650741577148
I0204 19:00:03.954268 139487501866752 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.13822513818740845, loss=0.36448171734809875
I0204 19:00:28.160069 139487493474048 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.1211075410246849, loss=0.2259497195482254
I0204 19:00:30.927182 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:00:32.299409 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:00:33.619387 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:00:34.940257 139681449744192 submission_runner.py:408] Time since start: 4318.36s, 	Step: 16213, 	{'train/ssim': 0.7476457868303571, 'train/loss': 0.26713415554591585, 'validation/ssim': 0.7246648115459693, 'validation/loss': 0.2859542752224606, 'validation/num_examples': 3554, 'test/ssim': 0.7419904012714674, 'test/loss': 0.28726873794636626, 'test/num_examples': 3581, 'score': 3915.0690200328827, 'total_duration': 4318.356410264969, 'accumulated_submission_time': 3915.0690200328827, 'accumulated_eval_time': 401.30852031707764, 'accumulated_logging_time': 1.3447983264923096}
I0204 19:00:34.961262 139487501866752 logging_writer.py:48] [16213] accumulated_eval_time=401.308520, accumulated_logging_time=1.344798, accumulated_submission_time=3915.069020, global_step=16213, preemption_count=0, score=3915.069020, test/loss=0.287269, test/num_examples=3581, test/ssim=0.741990, total_duration=4318.356410, train/loss=0.267134, train/ssim=0.747646, validation/loss=0.285954, validation/num_examples=3554, validation/ssim=0.724665
I0204 19:00:53.692925 139487493474048 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.15293775498867035, loss=0.24439404904842377
I0204 19:01:17.627947 139487501866752 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.12044055759906769, loss=0.23146352171897888
I0204 19:01:41.262569 139487493474048 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.10600627213716507, loss=0.27470719814300537
I0204 19:01:54.972181 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:01:56.346917 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:01:57.666031 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:01:58.986788 139681449744192 submission_runner.py:408] Time since start: 4402.40s, 	Step: 16560, 	{'train/ssim': 0.7480151993887765, 'train/loss': 0.2664672647203718, 'validation/ssim': 0.7246860381788126, 'validation/loss': 0.28579505830248486, 'validation/num_examples': 3554, 'test/ssim': 0.7418862955092851, 'test/loss': 0.2871150336629084, 'test/num_examples': 3581, 'score': 3995.056948661804, 'total_duration': 4402.402938842773, 'accumulated_submission_time': 3995.056948661804, 'accumulated_eval_time': 405.32308530807495, 'accumulated_logging_time': 1.3752338886260986}
I0204 19:01:59.006138 139487501866752 logging_writer.py:48] [16560] accumulated_eval_time=405.323085, accumulated_logging_time=1.375234, accumulated_submission_time=3995.056949, global_step=16560, preemption_count=0, score=3995.056949, test/loss=0.287115, test/num_examples=3581, test/ssim=0.741886, total_duration=4402.402939, train/loss=0.266467, train/ssim=0.748015, validation/loss=0.285795, validation/num_examples=3554, validation/ssim=0.724686
I0204 19:02:06.382427 139487493474048 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.13000425696372986, loss=0.23354440927505493
I0204 19:02:30.341290 139487501866752 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.2694467008113861, loss=0.32104095816612244
I0204 19:02:54.015231 139487493474048 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.4187803864479065, loss=0.29702451825141907
I0204 19:03:17.958351 139487501866752 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.05569814518094063, loss=0.3304740786552429
I0204 19:03:19.131523 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:03:20.502521 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:03:21.825340 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:03:23.145726 139681449744192 submission_runner.py:408] Time since start: 4486.56s, 	Step: 16906, 	{'train/ssim': 0.7479713984898159, 'train/loss': 0.2666489567075457, 'validation/ssim': 0.7247964304085186, 'validation/loss': 0.2857232724406039, 'validation/num_examples': 3554, 'test/ssim': 0.7420793036381248, 'test/loss': 0.2871182720543319, 'test/num_examples': 3581, 'score': 4075.1593718528748, 'total_duration': 4486.561875104904, 'accumulated_submission_time': 4075.1593718528748, 'accumulated_eval_time': 409.3372468948364, 'accumulated_logging_time': 1.4041290283203125}
I0204 19:03:23.165516 139487493474048 logging_writer.py:48] [16906] accumulated_eval_time=409.337247, accumulated_logging_time=1.404129, accumulated_submission_time=4075.159372, global_step=16906, preemption_count=0, score=4075.159372, test/loss=0.287118, test/num_examples=3581, test/ssim=0.742079, total_duration=4486.561875, train/loss=0.266649, train/ssim=0.747971, validation/loss=0.285723, validation/num_examples=3554, validation/ssim=0.724796
I0204 19:03:43.500779 139487501866752 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.3606228828430176, loss=0.2225833535194397
I0204 19:04:07.381236 139487493474048 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.1591242551803589, loss=0.31060782074928284
I0204 19:04:31.529791 139487501866752 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.08833836019039154, loss=0.2568208575248718
I0204 19:04:43.300568 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:04:44.671371 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:04:45.989386 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:04:47.310468 139681449744192 submission_runner.py:408] Time since start: 4570.73s, 	Step: 17249, 	{'train/ssim': 0.7486212594168526, 'train/loss': 0.2669464349746704, 'validation/ssim': 0.7252796282577729, 'validation/loss': 0.28607277341551773, 'validation/num_examples': 3554, 'test/ssim': 0.742540450576829, 'test/loss': 0.28740488673947573, 'test/num_examples': 3581, 'score': 4155.271572828293, 'total_duration': 4570.726595163345, 'accumulated_submission_time': 4155.271572828293, 'accumulated_eval_time': 413.34709000587463, 'accumulated_logging_time': 1.4336450099945068}
I0204 19:04:47.330098 139487493474048 logging_writer.py:48] [17249] accumulated_eval_time=413.347090, accumulated_logging_time=1.433645, accumulated_submission_time=4155.271573, global_step=17249, preemption_count=0, score=4155.271573, test/loss=0.287405, test/num_examples=3581, test/ssim=0.742540, total_duration=4570.726595, train/loss=0.266946, train/ssim=0.748621, validation/loss=0.286073, validation/num_examples=3554, validation/ssim=0.725280
I0204 19:04:57.473793 139487501866752 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.30954504013061523, loss=0.2542024552822113
I0204 19:05:21.703832 139487493474048 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.29264384508132935, loss=0.2346084713935852
I0204 19:05:45.736623 139487501866752 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.1706673949956894, loss=0.2513233721256256
I0204 19:06:07.339103 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:06:08.710470 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:06:10.030178 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:06:11.350640 139681449744192 submission_runner.py:408] Time since start: 4654.77s, 	Step: 17592, 	{'train/ssim': 0.7479096140180316, 'train/loss': 0.2669038772583008, 'validation/ssim': 0.7240776100652434, 'validation/loss': 0.28649799301842993, 'validation/num_examples': 3554, 'test/ssim': 0.7413886740566532, 'test/loss': 0.2877851079809236, 'test/num_examples': 3581, 'score': 4235.25742316246, 'total_duration': 4654.7667927742, 'accumulated_submission_time': 4235.25742316246, 'accumulated_eval_time': 417.3585879802704, 'accumulated_logging_time': 1.4628279209136963}
I0204 19:06:11.369971 139487493474048 logging_writer.py:48] [17592] accumulated_eval_time=417.358588, accumulated_logging_time=1.462828, accumulated_submission_time=4235.257423, global_step=17592, preemption_count=0, score=4235.257423, test/loss=0.287785, test/num_examples=3581, test/ssim=0.741389, total_duration=4654.766793, train/loss=0.266904, train/ssim=0.747910, validation/loss=0.286498, validation/num_examples=3554, validation/ssim=0.724078
I0204 19:06:12.039491 139487501866752 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.23132199048995972, loss=0.30205878615379333
I0204 19:06:34.805617 139487493474048 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.17654789984226227, loss=0.2615209221839905
I0204 19:06:58.571622 139487501866752 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.2658666968345642, loss=0.2879962623119354
I0204 19:07:22.295540 139487493474048 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.1340922713279724, loss=0.20781683921813965
I0204 19:07:31.466780 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:07:32.838204 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:07:34.158803 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:07:35.478138 139681449744192 submission_runner.py:408] Time since start: 4738.89s, 	Step: 17940, 	{'train/ssim': 0.7473158836364746, 'train/loss': 0.26705946241106304, 'validation/ssim': 0.7240636650604952, 'validation/loss': 0.2861336196616049, 'validation/num_examples': 3554, 'test/ssim': 0.7414530328251536, 'test/loss': 0.2874236694097319, 'test/num_examples': 3581, 'score': 4315.329802036285, 'total_duration': 4738.894271850586, 'accumulated_submission_time': 4315.329802036285, 'accumulated_eval_time': 421.36989307403564, 'accumulated_logging_time': 1.4926958084106445}
I0204 19:07:35.496865 139487501866752 logging_writer.py:48] [17940] accumulated_eval_time=421.369893, accumulated_logging_time=1.492696, accumulated_submission_time=4315.329802, global_step=17940, preemption_count=0, score=4315.329802, test/loss=0.287424, test/num_examples=3581, test/ssim=0.741453, total_duration=4738.894272, train/loss=0.267059, train/ssim=0.747316, validation/loss=0.286134, validation/num_examples=3554, validation/ssim=0.724064
I0204 19:07:47.772965 139487493474048 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.22700448334217072, loss=0.3144530951976776
I0204 19:08:11.656714 139487501866752 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.13544800877571106, loss=0.2690656781196594
I0204 19:08:35.188392 139487493474048 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.10828209668397903, loss=0.213507741689682
I0204 19:08:55.522432 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:08:56.894829 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:08:58.215753 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:08:59.536567 139681449744192 submission_runner.py:408] Time since start: 4822.95s, 	Step: 18286, 	{'train/ssim': 0.7483020509992327, 'train/loss': 0.2668248585292271, 'validation/ssim': 0.7248403949555079, 'validation/loss': 0.2860413799811832, 'validation/num_examples': 3554, 'test/ssim': 0.7421564796189961, 'test/loss': 0.28731458675125665, 'test/num_examples': 3581, 'score': 4395.332178592682, 'total_duration': 4822.952711105347, 'accumulated_submission_time': 4395.332178592682, 'accumulated_eval_time': 425.3839862346649, 'accumulated_logging_time': 1.5210142135620117}
I0204 19:08:59.556423 139487501866752 logging_writer.py:48] [18286] accumulated_eval_time=425.383986, accumulated_logging_time=1.521014, accumulated_submission_time=4395.332179, global_step=18286, preemption_count=0, score=4395.332179, test/loss=0.287315, test/num_examples=3581, test/ssim=0.742156, total_duration=4822.952711, train/loss=0.266825, train/ssim=0.748302, validation/loss=0.286041, validation/num_examples=3554, validation/ssim=0.724840
I0204 19:09:00.856281 139487493474048 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.10475260764360428, loss=0.25567588210105896
I0204 19:09:25.027771 139487501866752 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.19158479571342468, loss=0.22087877988815308
I0204 19:09:48.877189 139487493474048 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.1622047871351242, loss=0.33679816126823425
I0204 19:10:12.784918 139487501866752 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.20196983218193054, loss=0.25860029458999634
I0204 19:10:19.679126 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:10:21.050087 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:10:22.372874 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:10:23.692128 139681449744192 submission_runner.py:408] Time since start: 4907.11s, 	Step: 18630, 	{'train/ssim': 0.7485624722072056, 'train/loss': 0.26614345823015484, 'validation/ssim': 0.7246146644845597, 'validation/loss': 0.28574046326542274, 'validation/num_examples': 3554, 'test/ssim': 0.7419122708173346, 'test/loss': 0.28709925076576026, 'test/num_examples': 3581, 'score': 4475.431641340256, 'total_duration': 4907.1082763671875, 'accumulated_submission_time': 4475.431641340256, 'accumulated_eval_time': 429.3969392776489, 'accumulated_logging_time': 1.5507056713104248}
I0204 19:10:23.711400 139487493474048 logging_writer.py:48] [18630] accumulated_eval_time=429.396939, accumulated_logging_time=1.550706, accumulated_submission_time=4475.431641, global_step=18630, preemption_count=0, score=4475.431641, test/loss=0.287099, test/num_examples=3581, test/ssim=0.741912, total_duration=4907.108276, train/loss=0.266143, train/ssim=0.748562, validation/loss=0.285740, validation/num_examples=3554, validation/ssim=0.724615
I0204 19:10:38.237616 139487501866752 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.21994800865650177, loss=0.2892061769962311
I0204 19:11:02.134133 139487493474048 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.30876174569129944, loss=0.2627803683280945
I0204 19:11:26.214897 139487501866752 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.11272207647562027, loss=0.24469035863876343
I0204 19:11:43.877135 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:11:45.250293 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:11:46.570747 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:11:47.892848 139681449744192 submission_runner.py:408] Time since start: 4991.31s, 	Step: 18976, 	{'train/ssim': 0.7473161561148507, 'train/loss': 0.2668733426502773, 'validation/ssim': 0.7237860701630205, 'validation/loss': 0.28600273926605585, 'validation/num_examples': 3554, 'test/ssim': 0.741142760838453, 'test/loss': 0.28730824632173274, 'test/num_examples': 3581, 'score': 4555.57452249527, 'total_duration': 4991.308980464935, 'accumulated_submission_time': 4555.57452249527, 'accumulated_eval_time': 433.4125940799713, 'accumulated_logging_time': 1.5795207023620605}
I0204 19:11:47.912660 139487493474048 logging_writer.py:48] [18976] accumulated_eval_time=433.412594, accumulated_logging_time=1.579521, accumulated_submission_time=4555.574522, global_step=18976, preemption_count=0, score=4555.574522, test/loss=0.287308, test/num_examples=3581, test/ssim=0.741143, total_duration=4991.308980, train/loss=0.266873, train/ssim=0.747316, validation/loss=0.286003, validation/num_examples=3554, validation/ssim=0.723786
I0204 19:11:51.455657 139487501866752 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.06887855380773544, loss=0.28069400787353516
I0204 19:12:15.106946 139487493474048 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.10079820454120636, loss=0.274189293384552
I0204 19:12:39.168830 139487501866752 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.13554780185222626, loss=0.23201818764209747
I0204 19:13:02.742843 139487493474048 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.4514857828617096, loss=0.2572658061981201
I0204 19:13:07.903661 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:13:09.276721 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:13:10.595687 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:13:11.916615 139681449744192 submission_runner.py:408] Time since start: 5075.33s, 	Step: 19323, 	{'train/ssim': 0.748532772064209, 'train/loss': 0.2665856054850987, 'validation/ssim': 0.7251577640290869, 'validation/loss': 0.28578102742948086, 'validation/num_examples': 3554, 'test/ssim': 0.7423779855923625, 'test/loss': 0.28715089458688214, 'test/num_examples': 3581, 'score': 4635.542121648788, 'total_duration': 5075.3327651023865, 'accumulated_submission_time': 4635.542121648788, 'accumulated_eval_time': 437.42550253868103, 'accumulated_logging_time': 1.6093058586120605}
I0204 19:13:11.936516 139487501866752 logging_writer.py:48] [19323] accumulated_eval_time=437.425503, accumulated_logging_time=1.609306, accumulated_submission_time=4635.542122, global_step=19323, preemption_count=0, score=4635.542122, test/loss=0.287151, test/num_examples=3581, test/ssim=0.742378, total_duration=5075.332765, train/loss=0.266586, train/ssim=0.748533, validation/loss=0.285781, validation/num_examples=3554, validation/ssim=0.725158
I0204 19:13:28.756342 139487493474048 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.3324187397956848, loss=0.24505959451198578
I0204 19:13:52.686665 139487501866752 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.7945953607559204, loss=0.22781573235988617
I0204 19:14:16.745972 139487493474048 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.21605725586414337, loss=0.34352731704711914
I0204 19:14:32.040686 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:14:33.412201 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:14:34.735009 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:14:36.054910 139681449744192 submission_runner.py:408] Time since start: 5159.47s, 	Step: 19666, 	{'train/ssim': 0.7492211205618722, 'train/loss': 0.26595864977155415, 'validation/ssim': 0.7252296872801772, 'validation/loss': 0.2857543224019151, 'validation/num_examples': 3554, 'test/ssim': 0.7424777280482058, 'test/loss': 0.2870662191732407, 'test/num_examples': 3581, 'score': 4715.623168230057, 'total_duration': 5159.4710512161255, 'accumulated_submission_time': 4715.623168230057, 'accumulated_eval_time': 441.4396963119507, 'accumulated_logging_time': 1.6389601230621338}
I0204 19:14:36.074842 139487501866752 logging_writer.py:48] [19666] accumulated_eval_time=441.439696, accumulated_logging_time=1.638960, accumulated_submission_time=4715.623168, global_step=19666, preemption_count=0, score=4715.623168, test/loss=0.287066, test/num_examples=3581, test/ssim=0.742478, total_duration=5159.471051, train/loss=0.265959, train/ssim=0.749221, validation/loss=0.285754, validation/num_examples=3554, validation/ssim=0.725230
I0204 19:14:42.094002 139487493474048 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.31780922412872314, loss=0.2029457539319992
I0204 19:15:06.225468 139487501866752 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.18930278718471527, loss=0.22042016685009003
I0204 19:15:29.980766 139487493474048 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.11534003913402557, loss=0.31495705246925354
I0204 19:15:53.808076 139487501866752 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.2014675736427307, loss=0.24188964068889618
I0204 19:15:56.152042 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:15:57.523146 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:15:58.843366 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:16:00.163272 139681449744192 submission_runner.py:408] Time since start: 5243.58s, 	Step: 20011, 	{'train/ssim': 0.747901439666748, 'train/loss': 0.2665020397731236, 'validation/ssim': 0.7244954106508511, 'validation/loss': 0.2856981817362479, 'validation/num_examples': 3554, 'test/ssim': 0.7418216640341385, 'test/loss': 0.28692676381204624, 'test/num_examples': 3581, 'score': 4795.6775233745575, 'total_duration': 5243.579426765442, 'accumulated_submission_time': 4795.6775233745575, 'accumulated_eval_time': 445.45088481903076, 'accumulated_logging_time': 1.6683268547058105}
I0204 19:16:00.185731 139487493474048 logging_writer.py:48] [20011] accumulated_eval_time=445.450885, accumulated_logging_time=1.668327, accumulated_submission_time=4795.677523, global_step=20011, preemption_count=0, score=4795.677523, test/loss=0.286927, test/num_examples=3581, test/ssim=0.741822, total_duration=5243.579427, train/loss=0.266502, train/ssim=0.747901, validation/loss=0.285698, validation/num_examples=3554, validation/ssim=0.724495
I0204 19:16:19.355359 139487501866752 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.13708698749542236, loss=0.3850686252117157
I0204 19:16:43.395285 139487493474048 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.17794755101203918, loss=0.35859426856040955
I0204 19:17:07.584431 139487501866752 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.0860825777053833, loss=0.2691366970539093
I0204 19:17:20.189944 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:17:21.560873 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:17:22.881633 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:17:24.201250 139681449744192 submission_runner.py:408] Time since start: 5327.62s, 	Step: 20354, 	{'train/ssim': 0.7483769825526646, 'train/loss': 0.2666335957390921, 'validation/ssim': 0.7248445853263928, 'validation/loss': 0.28595743517427546, 'validation/num_examples': 3554, 'test/ssim': 0.7420431018308433, 'test/loss': 0.2872837368119066, 'test/num_examples': 3581, 'score': 4875.658908843994, 'total_duration': 5327.617372274399, 'accumulated_submission_time': 4875.658908843994, 'accumulated_eval_time': 449.4621365070343, 'accumulated_logging_time': 1.7000653743743896}
I0204 19:17:24.225261 139487493474048 logging_writer.py:48] [20354] accumulated_eval_time=449.462137, accumulated_logging_time=1.700065, accumulated_submission_time=4875.658909, global_step=20354, preemption_count=0, score=4875.658909, test/loss=0.287284, test/num_examples=3581, test/ssim=0.742043, total_duration=5327.617372, train/loss=0.266634, train/ssim=0.748377, validation/loss=0.285957, validation/num_examples=3554, validation/ssim=0.724845
I0204 19:17:33.100839 139487501866752 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.16476577520370483, loss=0.23533514142036438
I0204 19:17:57.584956 139487493474048 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.34767505526542664, loss=0.23347224295139313
I0204 19:18:21.720914 139487501866752 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.2987670600414276, loss=0.36532604694366455
I0204 19:18:44.292535 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:18:45.663289 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:18:46.983274 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:18:48.306099 139681449744192 submission_runner.py:408] Time since start: 5411.72s, 	Step: 20696, 	{'train/ssim': 0.7491252762930733, 'train/loss': 0.2660750320979527, 'validation/ssim': 0.7255758393931134, 'validation/loss': 0.2855740162383054, 'validation/num_examples': 3554, 'test/ssim': 0.7427288226926836, 'test/loss': 0.28693354738987015, 'test/num_examples': 3581, 'score': 4955.702982664108, 'total_duration': 5411.722235918045, 'accumulated_submission_time': 4955.702982664108, 'accumulated_eval_time': 453.47565054893494, 'accumulated_logging_time': 1.7338788509368896}
I0204 19:18:48.326258 139487493474048 logging_writer.py:48] [20696] accumulated_eval_time=453.475651, accumulated_logging_time=1.733879, accumulated_submission_time=4955.702983, global_step=20696, preemption_count=0, score=4955.702983, test/loss=0.286934, test/num_examples=3581, test/ssim=0.742729, total_duration=5411.722236, train/loss=0.266075, train/ssim=0.749125, validation/loss=0.285574, validation/num_examples=3554, validation/ssim=0.725576
I0204 19:18:48.705560 139487501866752 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.13825753331184387, loss=0.253195583820343
I0204 19:19:11.126016 139487493474048 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.12117964774370193, loss=0.23596787452697754
I0204 19:19:34.416996 139487501866752 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.1827930510044098, loss=0.3054274618625641
I0204 19:19:58.075728 139487493474048 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.22901596128940582, loss=0.31042948365211487
I0204 19:20:08.330005 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:20:09.700796 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:20:11.020662 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:20:12.342404 139681449744192 submission_runner.py:408] Time since start: 5495.76s, 	Step: 21044, 	{'train/ssim': 0.7485916273934501, 'train/loss': 0.2661369187491281, 'validation/ssim': 0.7251855853439786, 'validation/loss': 0.28551524800400957, 'validation/num_examples': 3554, 'test/ssim': 0.7424461622539095, 'test/loss': 0.2868228625798485, 'test/num_examples': 3581, 'score': 5035.683332443237, 'total_duration': 5495.758540868759, 'accumulated_submission_time': 5035.683332443237, 'accumulated_eval_time': 457.4879927635193, 'accumulated_logging_time': 1.763725996017456}
I0204 19:20:12.362288 139487501866752 logging_writer.py:48] [21044] accumulated_eval_time=457.487993, accumulated_logging_time=1.763726, accumulated_submission_time=5035.683332, global_step=21044, preemption_count=0, score=5035.683332, test/loss=0.286823, test/num_examples=3581, test/ssim=0.742446, total_duration=5495.758541, train/loss=0.266137, train/ssim=0.748592, validation/loss=0.285515, validation/num_examples=3554, validation/ssim=0.725186
I0204 19:20:23.547326 139487493474048 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.053816914558410645, loss=0.27026262879371643
I0204 19:20:47.316744 139487501866752 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.15267068147659302, loss=0.2205599844455719
I0204 19:21:11.272350 139487493474048 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.29017990827560425, loss=0.27343252301216125
I0204 19:21:32.381017 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:21:33.752890 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:21:35.072312 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:21:36.392515 139681449744192 submission_runner.py:408] Time since start: 5579.81s, 	Step: 21390, 	{'train/ssim': 0.7477847508021763, 'train/loss': 0.26690781116485596, 'validation/ssim': 0.7248390210634145, 'validation/loss': 0.2859515789592273, 'validation/num_examples': 3554, 'test/ssim': 0.7419769704691427, 'test/loss': 0.28725404587580283, 'test/num_examples': 3581, 'score': 5115.678194522858, 'total_duration': 5579.808661937714, 'accumulated_submission_time': 5115.678194522858, 'accumulated_eval_time': 461.4994411468506, 'accumulated_logging_time': 1.7938733100891113}
I0204 19:21:36.413247 139487501866752 logging_writer.py:48] [21390] accumulated_eval_time=461.499441, accumulated_logging_time=1.793873, accumulated_submission_time=5115.678195, global_step=21390, preemption_count=0, score=5115.678195, test/loss=0.287254, test/num_examples=3581, test/ssim=0.741977, total_duration=5579.808662, train/loss=0.266908, train/ssim=0.747785, validation/loss=0.285952, validation/num_examples=3554, validation/ssim=0.724839
I0204 19:21:37.225043 139487493474048 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.10703954845666885, loss=0.257878839969635
I0204 19:22:00.678594 139487501866752 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.2501167953014374, loss=0.21533694863319397
I0204 19:22:25.294133 139487493474048 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.11260508000850677, loss=0.22329586744308472
I0204 19:22:49.343969 139487501866752 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.1793462485074997, loss=0.3020963668823242
I0204 19:22:56.564583 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:22:57.934949 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:22:59.253250 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:23:00.574994 139681449744192 submission_runner.py:408] Time since start: 5663.99s, 	Step: 21731, 	{'train/ssim': 0.7492568152291434, 'train/loss': 0.26653306824820383, 'validation/ssim': 0.7260055241453293, 'validation/loss': 0.28577091214894307, 'validation/num_examples': 3554, 'test/ssim': 0.7431472910412594, 'test/loss': 0.287159791641214, 'test/num_examples': 3581, 'score': 5195.80691409111, 'total_duration': 5663.9911460876465, 'accumulated_submission_time': 5195.80691409111, 'accumulated_eval_time': 465.50981426239014, 'accumulated_logging_time': 1.823737382888794}
I0204 19:23:00.594960 139487493474048 logging_writer.py:48] [21731] accumulated_eval_time=465.509814, accumulated_logging_time=1.823737, accumulated_submission_time=5195.806914, global_step=21731, preemption_count=0, score=5195.806914, test/loss=0.287160, test/num_examples=3581, test/ssim=0.743147, total_duration=5663.991146, train/loss=0.266533, train/ssim=0.749257, validation/loss=0.285771, validation/num_examples=3554, validation/ssim=0.726006
I0204 19:23:15.155644 139487501866752 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.3550007939338684, loss=0.2470146268606186
I0204 19:23:38.926221 139487493474048 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.21410317718982697, loss=0.34957969188690186
I0204 19:24:02.540940 139487501866752 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.17676419019699097, loss=0.28611573576927185
I0204 19:24:20.682184 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:24:22.053359 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:24:23.373391 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:24:24.695236 139681449744192 submission_runner.py:408] Time since start: 5748.11s, 	Step: 22078, 	{'train/ssim': 0.7461775371006557, 'train/loss': 0.26683105741228375, 'validation/ssim': 0.7226040421004502, 'validation/loss': 0.28612309221343907, 'validation/num_examples': 3554, 'test/ssim': 0.7400780459150726, 'test/loss': 0.28738392241605, 'test/num_examples': 3581, 'score': 5275.870712280273, 'total_duration': 5748.111387014389, 'accumulated_submission_time': 5275.870712280273, 'accumulated_eval_time': 469.5228455066681, 'accumulated_logging_time': 1.8534579277038574}
I0204 19:24:24.715280 139487493474048 logging_writer.py:48] [22078] accumulated_eval_time=469.522846, accumulated_logging_time=1.853458, accumulated_submission_time=5275.870712, global_step=22078, preemption_count=0, score=5275.870712, test/loss=0.287384, test/num_examples=3581, test/ssim=0.740078, total_duration=5748.111387, train/loss=0.266831, train/ssim=0.746178, validation/loss=0.286123, validation/num_examples=3554, validation/ssim=0.722604
I0204 19:24:27.954246 139487501866752 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.24765878915786743, loss=0.2708148658275604
I0204 19:24:51.820221 139487493474048 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.05999771133065224, loss=0.2820257246494293
I0204 19:25:15.701608 139487501866752 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.1453428566455841, loss=0.3292086124420166
I0204 19:25:39.404528 139487493474048 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.11247184872627258, loss=0.2535272240638733
I0204 19:25:44.903181 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:25:46.273087 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:25:47.591565 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:25:48.910171 139681449744192 submission_runner.py:408] Time since start: 5832.33s, 	Step: 22424, 	{'train/ssim': 0.7486978939601353, 'train/loss': 0.2662124293191092, 'validation/ssim': 0.7253482541678391, 'validation/loss': 0.28544057696873243, 'validation/num_examples': 3554, 'test/ssim': 0.7425572902122313, 'test/loss': 0.28676562827247976, 'test/num_examples': 3581, 'score': 5356.035150527954, 'total_duration': 5832.326321363449, 'accumulated_submission_time': 5356.035150527954, 'accumulated_eval_time': 473.52979373931885, 'accumulated_logging_time': 1.8833134174346924}
I0204 19:25:48.931429 139487501866752 logging_writer.py:48] [22424] accumulated_eval_time=473.529794, accumulated_logging_time=1.883313, accumulated_submission_time=5356.035151, global_step=22424, preemption_count=0, score=5356.035151, test/loss=0.286766, test/num_examples=3581, test/ssim=0.742557, total_duration=5832.326321, train/loss=0.266212, train/ssim=0.748698, validation/loss=0.285441, validation/num_examples=3554, validation/ssim=0.725348
I0204 19:26:04.920103 139487493474048 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.16958288848400116, loss=0.30943870544433594
I0204 19:26:28.863740 139487501866752 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.1340176910161972, loss=0.2241572141647339
I0204 19:26:53.279436 139487493474048 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.3400879204273224, loss=0.2127426415681839
I0204 19:27:08.981491 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:27:10.354091 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:27:11.675246 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:27:12.996606 139681449744192 submission_runner.py:408] Time since start: 5916.41s, 	Step: 22767, 	{'train/ssim': 0.749427046094622, 'train/loss': 0.2666067055293492, 'validation/ssim': 0.7262519316922833, 'validation/loss': 0.28577135866387343, 'validation/num_examples': 3554, 'test/ssim': 0.7433064153693103, 'test/loss': 0.28724923942116376, 'test/num_examples': 3581, 'score': 5436.060939788818, 'total_duration': 5916.412758111954, 'accumulated_submission_time': 5436.060939788818, 'accumulated_eval_time': 477.544869184494, 'accumulated_logging_time': 1.9157905578613281}
I0204 19:27:13.016633 139487501866752 logging_writer.py:48] [22767] accumulated_eval_time=477.544869, accumulated_logging_time=1.915791, accumulated_submission_time=5436.060940, global_step=22767, preemption_count=0, score=5436.060940, test/loss=0.287249, test/num_examples=3581, test/ssim=0.743306, total_duration=5916.412758, train/loss=0.266607, train/ssim=0.749427, validation/loss=0.285771, validation/num_examples=3554, validation/ssim=0.726252
I0204 19:27:18.974117 139487493474048 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.2145126461982727, loss=0.23309992253780365
I0204 19:27:42.634884 139487501866752 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.17857900261878967, loss=0.21045078337192535
I0204 19:28:06.370748 139487493474048 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.07399293780326843, loss=0.2757946252822876
I0204 19:28:30.035413 139487501866752 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.08298526704311371, loss=0.2670891284942627
I0204 19:28:33.107771 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:28:34.477901 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:28:35.798687 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:28:37.120678 139681449744192 submission_runner.py:408] Time since start: 6000.54s, 	Step: 23114, 	{'train/ssim': 0.7493207114083427, 'train/loss': 0.26572132110595703, 'validation/ssim': 0.7254548681942882, 'validation/loss': 0.28535773127549946, 'validation/num_examples': 3554, 'test/ssim': 0.7426980068416643, 'test/loss': 0.2866858615784697, 'test/num_examples': 3581, 'score': 5516.128949642181, 'total_duration': 6000.536830663681, 'accumulated_submission_time': 5516.128949642181, 'accumulated_eval_time': 481.5577425956726, 'accumulated_logging_time': 1.9451351165771484}
I0204 19:28:37.141261 139487493474048 logging_writer.py:48] [23114] accumulated_eval_time=481.557743, accumulated_logging_time=1.945135, accumulated_submission_time=5516.128950, global_step=23114, preemption_count=0, score=5516.128950, test/loss=0.286686, test/num_examples=3581, test/ssim=0.742698, total_duration=6000.536831, train/loss=0.265721, train/ssim=0.749321, validation/loss=0.285358, validation/num_examples=3554, validation/ssim=0.725455
I0204 19:28:55.647584 139487501866752 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.05614875257015228, loss=0.3042714595794678
I0204 19:29:19.784851 139487493474048 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.3258994519710541, loss=0.24107253551483154
I0204 19:29:43.515465 139487501866752 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.11187605559825897, loss=0.29346999526023865
I0204 19:29:57.311902 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:29:58.683143 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:30:00.002021 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:30:01.321759 139681449744192 submission_runner.py:408] Time since start: 6084.74s, 	Step: 23459, 	{'train/ssim': 0.7489502089364188, 'train/loss': 0.2658481938498361, 'validation/ssim': 0.7253882344277575, 'validation/loss': 0.28523621051983683, 'validation/num_examples': 3554, 'test/ssim': 0.7426928254153867, 'test/loss': 0.2865019891222773, 'test/num_examples': 3581, 'score': 5596.276057720184, 'total_duration': 6084.737917661667, 'accumulated_submission_time': 5596.276057720184, 'accumulated_eval_time': 485.5675754547119, 'accumulated_logging_time': 1.9756977558135986}
I0204 19:30:01.343863 139487493474048 logging_writer.py:48] [23459] accumulated_eval_time=485.567575, accumulated_logging_time=1.975698, accumulated_submission_time=5596.276058, global_step=23459, preemption_count=0, score=5596.276058, test/loss=0.286502, test/num_examples=3581, test/ssim=0.742693, total_duration=6084.737918, train/loss=0.265848, train/ssim=0.748950, validation/loss=0.285236, validation/num_examples=3554, validation/ssim=0.725388
I0204 19:30:09.173354 139487501866752 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.15962597727775574, loss=0.2426842451095581
I0204 19:30:33.006927 139487493474048 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.19010260701179504, loss=0.2837781310081482
I0204 19:30:56.982215 139487501866752 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.09305254369974136, loss=0.33548304438591003
I0204 19:31:21.319734 139487493474048 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.13914689421653748, loss=0.21118393540382385
I0204 19:31:21.325709 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:31:22.643013 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:31:23.960813 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:31:25.282454 139681449744192 submission_runner.py:408] Time since start: 6168.70s, 	Step: 23801, 	{'train/ssim': 0.7496252059936523, 'train/loss': 0.2658059937613351, 'validation/ssim': 0.7260273003350098, 'validation/loss': 0.2852406241481869, 'validation/num_examples': 3554, 'test/ssim': 0.7432441019006563, 'test/loss': 0.28660053848654354, 'test/num_examples': 3581, 'score': 5676.2350878715515, 'total_duration': 6168.698595523834, 'accumulated_submission_time': 5676.2350878715515, 'accumulated_eval_time': 489.52425837516785, 'accumulated_logging_time': 2.007225275039673}
I0204 19:31:25.303737 139487501866752 logging_writer.py:48] [23801] accumulated_eval_time=489.524258, accumulated_logging_time=2.007225, accumulated_submission_time=5676.235088, global_step=23801, preemption_count=0, score=5676.235088, test/loss=0.286601, test/num_examples=3581, test/ssim=0.743244, total_duration=6168.698596, train/loss=0.265806, train/ssim=0.749625, validation/loss=0.285241, validation/num_examples=3554, validation/ssim=0.726027
I0204 19:31:46.808499 139487493474048 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.13517224788665771, loss=0.2845945954322815
I0204 19:32:10.759579 139487501866752 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.10590868443250656, loss=0.18721294403076172
I0204 19:32:34.976320 139487493474048 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.16843482851982117, loss=0.2931446433067322
I0204 19:32:45.381111 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:32:46.752787 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:32:48.072782 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:32:49.393817 139681449744192 submission_runner.py:408] Time since start: 6252.81s, 	Step: 24146, 	{'train/ssim': 0.7498554502214704, 'train/loss': 0.2652804510934012, 'validation/ssim': 0.7258368101962578, 'validation/loss': 0.2851335979541098, 'validation/num_examples': 3554, 'test/ssim': 0.7430751601333426, 'test/loss': 0.2864032693163572, 'test/num_examples': 3581, 'score': 5756.289666891098, 'total_duration': 6252.809968471527, 'accumulated_submission_time': 5756.289666891098, 'accumulated_eval_time': 493.53691935539246, 'accumulated_logging_time': 2.037910223007202}
I0204 19:32:49.414662 139487501866752 logging_writer.py:48] [24146] accumulated_eval_time=493.536919, accumulated_logging_time=2.037910, accumulated_submission_time=5756.289667, global_step=24146, preemption_count=0, score=5756.289667, test/loss=0.286403, test/num_examples=3581, test/ssim=0.743075, total_duration=6252.809968, train/loss=0.265280, train/ssim=0.749855, validation/loss=0.285134, validation/num_examples=3554, validation/ssim=0.725837
I0204 19:33:00.162628 139487493474048 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.1023378074169159, loss=0.2704727053642273
I0204 19:33:23.965795 139487501866752 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.11958076059818268, loss=0.2485354095697403
I0204 19:33:47.704512 139487493474048 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.3841971158981323, loss=0.28383171558380127
I0204 19:34:09.540883 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:34:10.915449 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:34:12.235186 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:34:13.556709 139681449744192 submission_runner.py:408] Time since start: 6336.97s, 	Step: 24492, 	{'train/ssim': 0.7493213926042829, 'train/loss': 0.2656843491962978, 'validation/ssim': 0.7257174189733399, 'validation/loss': 0.28517500362707515, 'validation/num_examples': 3554, 'test/ssim': 0.7429374432770176, 'test/loss': 0.2864860016951445, 'test/num_examples': 3581, 'score': 5836.392609119415, 'total_duration': 6336.972864627838, 'accumulated_submission_time': 5836.392609119415, 'accumulated_eval_time': 497.5527238845825, 'accumulated_logging_time': 2.0684311389923096}
I0204 19:34:13.577763 139487501866752 logging_writer.py:48] [24492] accumulated_eval_time=497.552724, accumulated_logging_time=2.068431, accumulated_submission_time=5836.392609, global_step=24492, preemption_count=0, score=5836.392609, test/loss=0.286486, test/num_examples=3581, test/ssim=0.742937, total_duration=6336.972865, train/loss=0.265684, train/ssim=0.749321, validation/loss=0.285175, validation/num_examples=3554, validation/ssim=0.725717
I0204 19:34:14.247702 139487493474048 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.1429729461669922, loss=0.3372782766819
I0204 19:34:37.325840 139487501866752 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.22230264544487, loss=0.2220269739627838
I0204 19:35:00.900463 139487493474048 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.0948779508471489, loss=0.2718642055988312
I0204 19:35:24.854816 139487501866752 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.08653542399406433, loss=0.2714363932609558
I0204 19:35:33.637044 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:35:35.006658 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:35:36.327290 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:35:37.649528 139681449744192 submission_runner.py:408] Time since start: 6421.07s, 	Step: 24837, 	{'train/ssim': 0.7498811313084194, 'train/loss': 0.26557925769260954, 'validation/ssim': 0.7261310978826674, 'validation/loss': 0.28510529577698546, 'validation/num_examples': 3554, 'test/ssim': 0.743295916163432, 'test/loss': 0.2864755024892663, 'test/num_examples': 3581, 'score': 5916.42840719223, 'total_duration': 6421.065683841705, 'accumulated_submission_time': 5916.42840719223, 'accumulated_eval_time': 501.56517338752747, 'accumulated_logging_time': 2.099144697189331}
I0204 19:35:37.670614 139487493474048 logging_writer.py:48] [24837] accumulated_eval_time=501.565173, accumulated_logging_time=2.099145, accumulated_submission_time=5916.428407, global_step=24837, preemption_count=0, score=5916.428407, test/loss=0.286476, test/num_examples=3581, test/ssim=0.743296, total_duration=6421.065684, train/loss=0.265579, train/ssim=0.749881, validation/loss=0.285105, validation/num_examples=3554, validation/ssim=0.726131
I0204 19:35:50.595028 139487501866752 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.2418009638786316, loss=0.27559563517570496
I0204 19:36:14.925308 139487493474048 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.10262667387723923, loss=0.29372045397758484
I0204 19:36:38.923794 139487501866752 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.10886836796998978, loss=0.3340153098106384
I0204 19:36:57.710787 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:36:59.081394 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:37:00.403424 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:37:01.723469 139681449744192 submission_runner.py:408] Time since start: 6505.14s, 	Step: 25180, 	{'train/ssim': 0.7501208441598075, 'train/loss': 0.2650695528302874, 'validation/ssim': 0.7260279185864519, 'validation/loss': 0.28501975382051914, 'validation/num_examples': 3554, 'test/ssim': 0.7432925755070162, 'test/loss': 0.2863555456532742, 'test/num_examples': 3581, 'score': 5996.445634841919, 'total_duration': 6505.139622926712, 'accumulated_submission_time': 5996.445634841919, 'accumulated_eval_time': 505.57781767845154, 'accumulated_logging_time': 2.1298437118530273}
I0204 19:37:01.744842 139487493474048 logging_writer.py:48] [25180] accumulated_eval_time=505.577818, accumulated_logging_time=2.129844, accumulated_submission_time=5996.445635, global_step=25180, preemption_count=0, score=5996.445635, test/loss=0.286356, test/num_examples=3581, test/ssim=0.743293, total_duration=6505.139623, train/loss=0.265070, train/ssim=0.750121, validation/loss=0.285020, validation/num_examples=3554, validation/ssim=0.726028
I0204 19:37:04.398286 139487501866752 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.11032737046480179, loss=0.28985118865966797
I0204 19:37:28.072793 139487493474048 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.09964887797832489, loss=0.2821522653102875
I0204 19:37:51.679864 139487501866752 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.30837690830230713, loss=0.21645255386829376
I0204 19:38:15.639473 139487493474048 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.09389299154281616, loss=0.25941354036331177
I0204 19:38:21.775985 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:38:23.148793 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:38:24.469812 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:38:25.790782 139681449744192 submission_runner.py:408] Time since start: 6589.21s, 	Step: 25527, 	{'train/ssim': 0.7498316083635602, 'train/loss': 0.26556406702314106, 'validation/ssim': 0.7260694788222777, 'validation/loss': 0.2852243950478334, 'validation/num_examples': 3554, 'test/ssim': 0.7433385265768989, 'test/loss': 0.28652288526904146, 'test/num_examples': 3581, 'score': 6076.453567028046, 'total_duration': 6589.206932544708, 'accumulated_submission_time': 6076.453567028046, 'accumulated_eval_time': 509.5925693511963, 'accumulated_logging_time': 2.1610045433044434}
I0204 19:38:25.812206 139487501866752 logging_writer.py:48] [25527] accumulated_eval_time=509.592569, accumulated_logging_time=2.161005, accumulated_submission_time=6076.453567, global_step=25527, preemption_count=0, score=6076.453567, test/loss=0.286523, test/num_examples=3581, test/ssim=0.743339, total_duration=6589.206933, train/loss=0.265564, train/ssim=0.749832, validation/loss=0.285224, validation/num_examples=3554, validation/ssim=0.726069
I0204 19:38:40.958344 139487493474048 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.11161760240793228, loss=0.34925180673599243
I0204 19:39:04.969347 139487501866752 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.1658303290605545, loss=0.24136924743652344
I0204 19:39:28.800261 139487493474048 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.10141673684120178, loss=0.253939151763916
I0204 19:39:46.076200 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:39:47.445179 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:39:48.768266 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:39:50.089553 139681449744192 submission_runner.py:408] Time since start: 6673.51s, 	Step: 25872, 	{'train/ssim': 0.7498658725193569, 'train/loss': 0.2655244214194162, 'validation/ssim': 0.7262190956712508, 'validation/loss': 0.28506074732585646, 'validation/num_examples': 3554, 'test/ssim': 0.743424156463802, 'test/loss': 0.28636764701069883, 'test/num_examples': 3581, 'score': 6156.694766283035, 'total_duration': 6673.505701780319, 'accumulated_submission_time': 6156.694766283035, 'accumulated_eval_time': 513.6058740615845, 'accumulated_logging_time': 2.1919939517974854}
I0204 19:39:50.112123 139487501866752 logging_writer.py:48] [25872] accumulated_eval_time=513.605874, accumulated_logging_time=2.191994, accumulated_submission_time=6156.694766, global_step=25872, preemption_count=0, score=6156.694766, test/loss=0.286368, test/num_examples=3581, test/ssim=0.743424, total_duration=6673.505702, train/loss=0.265524, train/ssim=0.749866, validation/loss=0.285061, validation/num_examples=3554, validation/ssim=0.726219
I0204 19:39:54.718749 139487493474048 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.11826235055923462, loss=0.2146669328212738
I0204 19:40:18.968591 139487501866752 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.11593978106975555, loss=0.32389041781425476
I0204 19:40:43.118506 139487493474048 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.06832032650709152, loss=0.2930457890033722
I0204 19:41:07.146304 139487501866752 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.0697108805179596, loss=0.2808392643928528
I0204 19:41:10.230461 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:41:11.603834 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:41:12.923138 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:41:14.245445 139681449744192 submission_runner.py:408] Time since start: 6757.66s, 	Step: 26214, 	{'train/ssim': 0.7502429825919015, 'train/loss': 0.26492088181631906, 'validation/ssim': 0.7258607159186832, 'validation/loss': 0.28504517082424735, 'validation/num_examples': 3554, 'test/ssim': 0.7430811596795588, 'test/loss': 0.2863786575415387, 'test/num_examples': 3581, 'score': 6236.789935827255, 'total_duration': 6757.661597251892, 'accumulated_submission_time': 6236.789935827255, 'accumulated_eval_time': 517.6208217144012, 'accumulated_logging_time': 2.224311351776123}
I0204 19:41:14.266534 139487493474048 logging_writer.py:48] [26214] accumulated_eval_time=517.620822, accumulated_logging_time=2.224311, accumulated_submission_time=6236.789936, global_step=26214, preemption_count=0, score=6236.789936, test/loss=0.286379, test/num_examples=3581, test/ssim=0.743081, total_duration=6757.661597, train/loss=0.264921, train/ssim=0.750243, validation/loss=0.285045, validation/num_examples=3554, validation/ssim=0.725861
I0204 19:41:32.747631 139487501866752 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.09539934247732162, loss=0.25783464312553406
I0204 19:41:56.274367 139487493474048 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.07995586842298508, loss=0.40771469473838806
I0204 19:42:20.339123 139487501866752 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.12902206182479858, loss=0.20719760656356812
I0204 19:42:34.356619 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:42:35.728130 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:42:37.047311 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:42:38.366574 139681449744192 submission_runner.py:408] Time since start: 6841.78s, 	Step: 26559, 	{'train/ssim': 0.7503128732953753, 'train/loss': 0.2651557922363281, 'validation/ssim': 0.7263939234401379, 'validation/loss': 0.28492397636795685, 'validation/num_examples': 3554, 'test/ssim': 0.7435952798842851, 'test/loss': 0.2862669500815938, 'test/num_examples': 3581, 'score': 6316.855994939804, 'total_duration': 6841.782725572586, 'accumulated_submission_time': 6316.855994939804, 'accumulated_eval_time': 521.6307320594788, 'accumulated_logging_time': 2.2558205127716064}
I0204 19:42:38.389372 139487493474048 logging_writer.py:48] [26559] accumulated_eval_time=521.630732, accumulated_logging_time=2.255821, accumulated_submission_time=6316.855995, global_step=26559, preemption_count=0, score=6316.855995, test/loss=0.286267, test/num_examples=3581, test/ssim=0.743595, total_duration=6841.782726, train/loss=0.265156, train/ssim=0.750313, validation/loss=0.284924, validation/num_examples=3554, validation/ssim=0.726394
I0204 19:42:46.110606 139487501866752 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.1973508596420288, loss=0.30983778834342957
I0204 19:43:09.832364 139487493474048 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.12537874281406403, loss=0.3269108831882477
I0204 19:43:33.602724 139487501866752 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.09974972903728485, loss=0.2605341970920563
I0204 19:43:57.134758 139487493474048 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.11820266395807266, loss=0.22982969880104065
I0204 19:43:58.508714 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:43:59.881285 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:44:01.201449 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:44:02.522183 139681449744192 submission_runner.py:408] Time since start: 6925.94s, 	Step: 26907, 	{'train/ssim': 0.7502010890415737, 'train/loss': 0.26542275292532785, 'validation/ssim': 0.7263083986573228, 'validation/loss': 0.28511231980031304, 'validation/num_examples': 3554, 'test/ssim': 0.743497310021642, 'test/loss': 0.28640947339255796, 'test/num_examples': 3581, 'score': 6396.952573060989, 'total_duration': 6925.938338279724, 'accumulated_submission_time': 6396.952573060989, 'accumulated_eval_time': 525.6441569328308, 'accumulated_logging_time': 2.287712812423706}
I0204 19:44:02.543944 139487501866752 logging_writer.py:48] [26907] accumulated_eval_time=525.644157, accumulated_logging_time=2.287713, accumulated_submission_time=6396.952573, global_step=26907, preemption_count=0, score=6396.952573, test/loss=0.286409, test/num_examples=3581, test/ssim=0.743497, total_duration=6925.938338, train/loss=0.265423, train/ssim=0.750201, validation/loss=0.285112, validation/num_examples=3554, validation/ssim=0.726308
I0204 19:44:23.316783 139487493474048 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.08488054573535919, loss=0.2218913733959198
I0204 19:44:47.197279 139487501866752 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.25142642855644226, loss=0.2829168140888214
I0204 19:45:11.112052 139487493474048 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.11502063274383545, loss=0.354324609041214
I0204 19:45:22.557528 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:45:23.931737 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:45:25.251724 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:45:26.574152 139681449744192 submission_runner.py:408] Time since start: 7009.99s, 	Step: 27249, 	{'train/ssim': 0.7506561960492816, 'train/loss': 0.26484290191105436, 'validation/ssim': 0.7264343845622889, 'validation/loss': 0.2849978745889315, 'validation/num_examples': 3554, 'test/ssim': 0.7435778948355907, 'test/loss': 0.2863592271929978, 'test/num_examples': 3581, 'score': 6476.943389892578, 'total_duration': 7009.990304231644, 'accumulated_submission_time': 6476.943389892578, 'accumulated_eval_time': 529.6607377529144, 'accumulated_logging_time': 2.3188319206237793}
I0204 19:45:26.595973 139487501866752 logging_writer.py:48] [27249] accumulated_eval_time=529.660738, accumulated_logging_time=2.318832, accumulated_submission_time=6476.943390, global_step=27249, preemption_count=0, score=6476.943390, test/loss=0.286359, test/num_examples=3581, test/ssim=0.743578, total_duration=7009.990304, train/loss=0.264843, train/ssim=0.750656, validation/loss=0.284998, validation/num_examples=3554, validation/ssim=0.726434
I0204 19:45:36.732385 139487493474048 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.16816677153110504, loss=0.2208198606967926
I0204 19:46:00.298780 139487501866752 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.0811988040804863, loss=0.2593952417373657
I0204 19:46:24.215866 139487493474048 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.09464562684297562, loss=0.3366723954677582
I0204 19:46:46.629604 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:46:48.000578 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:46:49.320891 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:46:50.642852 139681449744192 submission_runner.py:408] Time since start: 7094.06s, 	Step: 27596, 	{'train/ssim': 0.7495948246547154, 'train/loss': 0.2651593174253191, 'validation/ssim': 0.7254652410795934, 'validation/loss': 0.2850242189698227, 'validation/num_examples': 3554, 'test/ssim': 0.7427244593863446, 'test/loss': 0.2862810285622033, 'test/num_examples': 3581, 'score': 6556.95263504982, 'total_duration': 7094.058998584747, 'accumulated_submission_time': 6556.95263504982, 'accumulated_eval_time': 533.6739375591278, 'accumulated_logging_time': 2.35146427154541}
I0204 19:46:50.664701 139487501866752 logging_writer.py:48] [27596] accumulated_eval_time=533.673938, accumulated_logging_time=2.351464, accumulated_submission_time=6556.952635, global_step=27596, preemption_count=0, score=6556.952635, test/loss=0.286281, test/num_examples=3581, test/ssim=0.742724, total_duration=7094.058999, train/loss=0.265159, train/ssim=0.749595, validation/loss=0.285024, validation/num_examples=3554, validation/ssim=0.725465
I0204 19:46:51.044154 139487493474048 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.06760711222887039, loss=0.29902637004852295
I0204 19:47:13.426171 139487501866752 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.06919422000646591, loss=0.3700447380542755
I0204 19:47:37.409153 139487493474048 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.08763060718774796, loss=0.3127360939979553
I0204 19:48:01.576075 139487501866752 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.04549720138311386, loss=0.3045402467250824
I0204 19:48:10.658493 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:48:12.030625 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:48:13.350893 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:48:14.672627 139681449744192 submission_runner.py:408] Time since start: 7178.09s, 	Step: 27939, 	{'train/ssim': 0.750136307307652, 'train/loss': 0.265045166015625, 'validation/ssim': 0.7260886446169809, 'validation/loss': 0.28485966104433386, 'validation/num_examples': 3554, 'test/ssim': 0.7433330724439752, 'test/loss': 0.28614869766214046, 'test/num_examples': 3581, 'score': 6636.923789262772, 'total_duration': 7178.088750839233, 'accumulated_submission_time': 6636.923789262772, 'accumulated_eval_time': 537.6880068778992, 'accumulated_logging_time': 2.3826534748077393}
I0204 19:48:14.695203 139487493474048 logging_writer.py:48] [27939] accumulated_eval_time=537.688007, accumulated_logging_time=2.382653, accumulated_submission_time=6636.923789, global_step=27939, preemption_count=0, score=6636.923789, test/loss=0.286149, test/num_examples=3581, test/ssim=0.743333, total_duration=7178.088751, train/loss=0.265045, train/ssim=0.750136, validation/loss=0.284860, validation/num_examples=3554, validation/ssim=0.726089
I0204 19:48:27.195077 139487501866752 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.09160371869802475, loss=0.2110712081193924
I0204 19:48:51.459640 139487493474048 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.18793019652366638, loss=0.21857139468193054
I0204 19:49:15.281314 139487501866752 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.09927772730588913, loss=0.36755460500717163
I0204 19:49:34.707369 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:49:36.080397 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:49:37.402293 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:49:38.723610 139681449744192 submission_runner.py:408] Time since start: 7262.14s, 	Step: 28283, 	{'train/ssim': 0.7500929151262555, 'train/loss': 0.2648871626172747, 'validation/ssim': 0.7258392145074212, 'validation/loss': 0.284950715742825, 'validation/num_examples': 3554, 'test/ssim': 0.7430446851656312, 'test/loss': 0.2862953115727974, 'test/num_examples': 3581, 'score': 6716.911543369293, 'total_duration': 7262.139762163162, 'accumulated_submission_time': 6716.911543369293, 'accumulated_eval_time': 541.7042119503021, 'accumulated_logging_time': 2.416171073913574}
I0204 19:49:38.746452 139487493474048 logging_writer.py:48] [28283] accumulated_eval_time=541.704212, accumulated_logging_time=2.416171, accumulated_submission_time=6716.911543, global_step=28283, preemption_count=0, score=6716.911543, test/loss=0.286295, test/num_examples=3581, test/ssim=0.743045, total_duration=7262.139762, train/loss=0.264887, train/ssim=0.750093, validation/loss=0.284951, validation/num_examples=3554, validation/ssim=0.725839
I0204 19:49:40.735887 139487501866752 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.09790351986885071, loss=0.26382023096084595
I0204 19:50:04.711796 139487493474048 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.09889130294322968, loss=0.22896267473697662
I0204 19:50:28.442266 139487501866752 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.07606694847345352, loss=0.29534244537353516
I0204 19:50:52.341998 139487493474048 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.07063542306423187, loss=0.31223052740097046
I0204 19:50:58.725145 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:51:00.097298 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:51:01.417121 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:51:02.737030 139681449744192 submission_runner.py:408] Time since start: 7346.15s, 	Step: 28628, 	{'train/ssim': 0.7504279272896903, 'train/loss': 0.26495582716805594, 'validation/ssim': 0.7262554351171215, 'validation/loss': 0.28491415303948897, 'validation/num_examples': 3554, 'test/ssim': 0.7434871516990715, 'test/loss': 0.28625201939271505, 'test/num_examples': 3581, 'score': 6796.866130590439, 'total_duration': 7346.153185129166, 'accumulated_submission_time': 6796.866130590439, 'accumulated_eval_time': 545.7160577774048, 'accumulated_logging_time': 2.4494388103485107}
I0204 19:51:02.758811 139487501866752 logging_writer.py:48] [28628] accumulated_eval_time=545.716058, accumulated_logging_time=2.449439, accumulated_submission_time=6796.866131, global_step=28628, preemption_count=0, score=6796.866131, test/loss=0.286252, test/num_examples=3581, test/ssim=0.743487, total_duration=7346.153185, train/loss=0.264956, train/ssim=0.750428, validation/loss=0.284914, validation/num_examples=3554, validation/ssim=0.726255
I0204 19:51:17.970314 139487493474048 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.06482242792844772, loss=0.29391828179359436
I0204 19:51:41.526460 139487501866752 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.12354587018489838, loss=0.2698131501674652
I0204 19:52:05.808779 139487493474048 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.07861461490392685, loss=0.3034987449645996
I0204 19:52:22.740313 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:52:24.111370 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:52:25.432940 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:52:26.753257 139681449744192 submission_runner.py:408] Time since start: 7430.17s, 	Step: 28972, 	{'train/ssim': 0.7505592618669782, 'train/loss': 0.2649299076625279, 'validation/ssim': 0.7264863863780248, 'validation/loss': 0.28486613551082407, 'validation/num_examples': 3554, 'test/ssim': 0.7436901817971586, 'test/loss': 0.28614573197736315, 'test/num_examples': 3581, 'score': 6876.82315993309, 'total_duration': 7430.169394493103, 'accumulated_submission_time': 6876.82315993309, 'accumulated_eval_time': 549.7289471626282, 'accumulated_logging_time': 2.482147455215454}
I0204 19:52:26.776654 139487501866752 logging_writer.py:48] [28972] accumulated_eval_time=549.728947, accumulated_logging_time=2.482147, accumulated_submission_time=6876.823160, global_step=28972, preemption_count=0, score=6876.823160, test/loss=0.286146, test/num_examples=3581, test/ssim=0.743690, total_duration=7430.169394, train/loss=0.264930, train/ssim=0.750559, validation/loss=0.284866, validation/num_examples=3554, validation/ssim=0.726486
I0204 19:52:31.345252 139487493474048 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.10796649754047394, loss=0.2254178673028946
I0204 19:52:55.178111 139487501866752 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.13958995044231415, loss=0.18494342267513275
I0204 19:53:19.809800 139487493474048 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.11617730557918549, loss=0.18821373581886292
I0204 19:53:43.666410 139487501866752 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.0918627455830574, loss=0.29090049862861633
I0204 19:53:46.755776 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:53:48.125699 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:53:49.446717 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:53:50.768824 139681449744192 submission_runner.py:408] Time since start: 7514.18s, 	Step: 29314, 	{'train/ssim': 0.7498602867126465, 'train/loss': 0.26512367384774344, 'validation/ssim': 0.7258943762749719, 'validation/loss': 0.2850154947550295, 'validation/num_examples': 3554, 'test/ssim': 0.7430681379372033, 'test/loss': 0.28638704327090897, 'test/num_examples': 3581, 'score': 6956.778971672058, 'total_duration': 7514.184953689575, 'accumulated_submission_time': 6956.778971672058, 'accumulated_eval_time': 553.7419407367706, 'accumulated_logging_time': 2.5154223442077637}
I0204 19:53:50.791089 139487493474048 logging_writer.py:48] [29314] accumulated_eval_time=553.741941, accumulated_logging_time=2.515422, accumulated_submission_time=6956.778972, global_step=29314, preemption_count=0, score=6956.778972, test/loss=0.286387, test/num_examples=3581, test/ssim=0.743068, total_duration=7514.184954, train/loss=0.265124, train/ssim=0.749860, validation/loss=0.285015, validation/num_examples=3554, validation/ssim=0.725894
I0204 19:54:09.552896 139487501866752 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.1592010259628296, loss=0.2793925106525421
I0204 19:54:33.432378 139487493474048 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.09381958842277527, loss=0.21323323249816895
I0204 19:54:57.163992 139487501866752 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.09913959354162216, loss=0.2541665732860565
I0204 19:55:10.834554 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:55:12.204875 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:55:13.527200 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:55:14.847996 139681449744192 submission_runner.py:408] Time since start: 7598.26s, 	Step: 29658, 	{'train/ssim': 0.7504299027579171, 'train/loss': 0.2647002935409546, 'validation/ssim': 0.7261024522325197, 'validation/loss': 0.2848177229881823, 'validation/num_examples': 3554, 'test/ssim': 0.7433210051748813, 'test/loss': 0.2861635942626885, 'test/num_examples': 3581, 'score': 7036.799525976181, 'total_duration': 7598.264146327972, 'accumulated_submission_time': 7036.799525976181, 'accumulated_eval_time': 557.7553491592407, 'accumulated_logging_time': 2.5471506118774414}
I0204 19:55:14.870584 139487493474048 logging_writer.py:48] [29658] accumulated_eval_time=557.755349, accumulated_logging_time=2.547151, accumulated_submission_time=7036.799526, global_step=29658, preemption_count=0, score=7036.799526, test/loss=0.286164, test/num_examples=3581, test/ssim=0.743321, total_duration=7598.264146, train/loss=0.264700, train/ssim=0.750430, validation/loss=0.284818, validation/num_examples=3554, validation/ssim=0.726102
I0204 19:55:22.730365 139487501866752 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.07673579454421997, loss=0.3058329224586487
I0204 19:55:46.842091 139487493474048 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.12396376579999924, loss=0.2855879068374634
I0204 19:56:10.515982 139487501866752 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.11671576648950577, loss=0.2424253225326538
I0204 19:56:34.495810 139487493474048 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.060431379824876785, loss=0.2956383228302002
I0204 19:56:34.916921 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:56:36.289771 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:56:37.612022 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:56:38.934052 139681449744192 submission_runner.py:408] Time since start: 7682.35s, 	Step: 30003, 	{'train/ssim': 0.7505853516714913, 'train/loss': 0.26493951252528597, 'validation/ssim': 0.7266091436365715, 'validation/loss': 0.2848703602290113, 'validation/num_examples': 3554, 'test/ssim': 0.7437669487180606, 'test/loss': 0.2862120337807177, 'test/num_examples': 3581, 'score': 7116.821959257126, 'total_duration': 7682.350178480148, 'accumulated_submission_time': 7116.821959257126, 'accumulated_eval_time': 561.7724099159241, 'accumulated_logging_time': 2.5802698135375977}
I0204 19:56:38.960570 139487501866752 logging_writer.py:48] [30003] accumulated_eval_time=561.772410, accumulated_logging_time=2.580270, accumulated_submission_time=7116.821959, global_step=30003, preemption_count=0, score=7116.821959, test/loss=0.286212, test/num_examples=3581, test/ssim=0.743767, total_duration=7682.350178, train/loss=0.264940, train/ssim=0.750585, validation/loss=0.284870, validation/num_examples=3554, validation/ssim=0.726609
I0204 19:56:59.764744 139487493474048 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.06707991659641266, loss=0.2360043227672577
I0204 19:57:23.612385 139487501866752 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.09871995449066162, loss=0.27850341796875
I0204 19:57:48.070767 139487493474048 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.07962841540575027, loss=0.2186564952135086
I0204 19:57:59.051092 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:58:00.421488 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:58:01.742084 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:58:03.063119 139681449744192 submission_runner.py:408] Time since start: 7766.48s, 	Step: 30348, 	{'train/ssim': 0.7509135518755231, 'train/loss': 0.26484443460192, 'validation/ssim': 0.726777857585643, 'validation/loss': 0.2848333166634426, 'validation/num_examples': 3554, 'test/ssim': 0.7439271638726962, 'test/loss': 0.28620661373612466, 'test/num_examples': 3581, 'score': 7196.888969659805, 'total_duration': 7766.479268789291, 'accumulated_submission_time': 7196.888969659805, 'accumulated_eval_time': 565.7843985557556, 'accumulated_logging_time': 2.616807460784912}
I0204 19:58:03.087018 139487501866752 logging_writer.py:48] [30348] accumulated_eval_time=565.784399, accumulated_logging_time=2.616807, accumulated_submission_time=7196.888970, global_step=30348, preemption_count=0, score=7196.888970, test/loss=0.286207, test/num_examples=3581, test/ssim=0.743927, total_duration=7766.479269, train/loss=0.264844, train/ssim=0.750914, validation/loss=0.284833, validation/num_examples=3554, validation/ssim=0.726778
I0204 19:58:13.510945 139487493474048 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.13999903202056885, loss=0.25127243995666504
I0204 19:58:37.537661 139487501866752 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.1447068154811859, loss=0.22538167238235474
I0204 19:59:01.386920 139487493474048 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.07626015692949295, loss=0.32217150926589966
I0204 19:59:23.100414 139681449744192 spec.py:321] Evaluating on the training split.
I0204 19:59:24.472374 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 19:59:25.794943 139681449744192 spec.py:349] Evaluating on the test split.
I0204 19:59:27.118021 139681449744192 submission_runner.py:408] Time since start: 7850.53s, 	Step: 30693, 	{'train/ssim': 0.7508979524884906, 'train/loss': 0.264484030859811, 'validation/ssim': 0.726506582591798, 'validation/loss': 0.28481655517990295, 'validation/num_examples': 3554, 'test/ssim': 0.7436694560920483, 'test/loss': 0.28615278826183327, 'test/num_examples': 3581, 'score': 7276.879731178284, 'total_duration': 7850.534174203873, 'accumulated_submission_time': 7276.879731178284, 'accumulated_eval_time': 569.8019735813141, 'accumulated_logging_time': 2.6498525142669678}
I0204 19:59:27.140094 139487501866752 logging_writer.py:48] [30693] accumulated_eval_time=569.801974, accumulated_logging_time=2.649853, accumulated_submission_time=7276.879731, global_step=30693, preemption_count=0, score=7276.879731, test/loss=0.286153, test/num_examples=3581, test/ssim=0.743669, total_duration=7850.534174, train/loss=0.264484, train/ssim=0.750898, validation/loss=0.284817, validation/num_examples=3554, validation/ssim=0.726507
I0204 19:59:27.736776 139487493474048 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.09227602183818817, loss=0.29077139496803284
I0204 19:59:50.312589 139487501866752 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.1457601934671402, loss=0.35622018575668335
I0204 20:00:13.893647 139487493474048 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.06108871102333069, loss=0.21006104350090027
I0204 20:00:37.761459 139487501866752 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.058954935520887375, loss=0.27542242407798767
I0204 20:00:47.184040 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:00:48.554990 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:00:49.874917 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:00:51.197747 139681449744192 submission_runner.py:408] Time since start: 7934.61s, 	Step: 31041, 	{'train/ssim': 0.7510170936584473, 'train/loss': 0.26465255873543875, 'validation/ssim': 0.7267936573447172, 'validation/loss': 0.284739548528067, 'validation/num_examples': 3554, 'test/ssim': 0.7439709332894093, 'test/loss': 0.2860615678886833, 'test/num_examples': 3581, 'score': 7356.900419712067, 'total_duration': 7934.61389875412, 'accumulated_submission_time': 7356.900419712067, 'accumulated_eval_time': 573.8156337738037, 'accumulated_logging_time': 2.681325674057007}
I0204 20:00:51.219868 139487493474048 logging_writer.py:48] [31041] accumulated_eval_time=573.815634, accumulated_logging_time=2.681326, accumulated_submission_time=7356.900420, global_step=31041, preemption_count=0, score=7356.900420, test/loss=0.286062, test/num_examples=3581, test/ssim=0.743971, total_duration=7934.613899, train/loss=0.264653, train/ssim=0.751017, validation/loss=0.284740, validation/num_examples=3554, validation/ssim=0.726794
I0204 20:01:03.314822 139487501866752 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.10891128331422806, loss=0.20000122487545013
I0204 20:01:26.914630 139487493474048 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.08716727048158646, loss=0.21530862152576447
I0204 20:01:51.000017 139487501866752 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.1991642415523529, loss=0.338730126619339
I0204 20:02:11.212029 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:02:12.583156 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:02:13.902520 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:02:15.225539 139681449744192 submission_runner.py:408] Time since start: 8018.64s, 	Step: 31385, 	{'train/ssim': 0.7506763594491142, 'train/loss': 0.26465151991162983, 'validation/ssim': 0.726357583994267, 'validation/loss': 0.28475655044272297, 'validation/num_examples': 3554, 'test/ssim': 0.7435804173720678, 'test/loss': 0.2860809982372242, 'test/num_examples': 3581, 'score': 7436.869582891464, 'total_duration': 8018.64168548584, 'accumulated_submission_time': 7436.869582891464, 'accumulated_eval_time': 577.8291063308716, 'accumulated_logging_time': 2.7132408618927}
I0204 20:02:15.248701 139487493474048 logging_writer.py:48] [31385] accumulated_eval_time=577.829106, accumulated_logging_time=2.713241, accumulated_submission_time=7436.869583, global_step=31385, preemption_count=0, score=7436.869583, test/loss=0.286081, test/num_examples=3581, test/ssim=0.743580, total_duration=8018.641685, train/loss=0.264652, train/ssim=0.750676, validation/loss=0.284757, validation/num_examples=3554, validation/ssim=0.726358
I0204 20:02:16.718215 139487501866752 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.1413731873035431, loss=0.21948513388633728
I0204 20:02:40.893841 139487493474048 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.13820691406726837, loss=0.2609127461910248
I0204 20:03:04.956918 139487501866752 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.12083399295806885, loss=0.2185874581336975
I0204 20:03:28.844507 139487493474048 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.07631230354309082, loss=0.235279843211174
I0204 20:03:35.401475 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:03:36.773591 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:03:38.093718 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:03:39.414681 139681449744192 submission_runner.py:408] Time since start: 8102.83s, 	Step: 31729, 	{'train/ssim': 0.7512480872017997, 'train/loss': 0.2642843893596104, 'validation/ssim': 0.726590664787915, 'validation/loss': 0.2847422276176491, 'validation/num_examples': 3554, 'test/ssim': 0.7437989235723261, 'test/loss': 0.28608750910840197, 'test/num_examples': 3581, 'score': 7516.999427556992, 'total_duration': 8102.830830574036, 'accumulated_submission_time': 7516.999427556992, 'accumulated_eval_time': 581.842268705368, 'accumulated_logging_time': 2.745941162109375}
I0204 20:03:39.436974 139487501866752 logging_writer.py:48] [31729] accumulated_eval_time=581.842269, accumulated_logging_time=2.745941, accumulated_submission_time=7516.999428, global_step=31729, preemption_count=0, score=7516.999428, test/loss=0.286088, test/num_examples=3581, test/ssim=0.743799, total_duration=8102.830831, train/loss=0.264284, train/ssim=0.751248, validation/loss=0.284742, validation/num_examples=3554, validation/ssim=0.726591
I0204 20:03:54.186147 139487493474048 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.23740048706531525, loss=0.21858559548854828
I0204 20:04:17.958969 139487501866752 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.10717293620109558, loss=0.3054483234882355
I0204 20:04:41.876021 139487493474048 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.1267552673816681, loss=0.1903482973575592
I0204 20:04:59.445749 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:05:00.817623 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:05:02.139533 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:05:03.458716 139681449744192 submission_runner.py:408] Time since start: 8186.87s, 	Step: 32075, 	{'train/ssim': 0.750896862574986, 'train/loss': 0.2644829750061035, 'validation/ssim': 0.7264721665948579, 'validation/loss': 0.2847329194987162, 'validation/num_examples': 3554, 'test/ssim': 0.7436901817971586, 'test/loss': 0.2860553979008133, 'test/num_examples': 3581, 'score': 7596.9842693805695, 'total_duration': 8186.874871730804, 'accumulated_submission_time': 7596.9842693805695, 'accumulated_eval_time': 585.8551957607269, 'accumulated_logging_time': 2.778761148452759}
I0204 20:05:03.481653 139487501866752 logging_writer.py:48] [32075] accumulated_eval_time=585.855196, accumulated_logging_time=2.778761, accumulated_submission_time=7596.984269, global_step=32075, preemption_count=0, score=7596.984269, test/loss=0.286055, test/num_examples=3581, test/ssim=0.743690, total_duration=8186.874872, train/loss=0.264483, train/ssim=0.750897, validation/loss=0.284733, validation/num_examples=3554, validation/ssim=0.726472
I0204 20:05:07.406903 139487493474048 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.09658695012331009, loss=0.3270512819290161
I0204 20:05:31.330754 139487501866752 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.07374916970729828, loss=0.321612685918808
I0204 20:05:54.891049 139487493474048 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.08625912666320801, loss=0.29519617557525635
I0204 20:06:19.022158 139487501866752 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.06459736824035645, loss=0.2684552073478699
I0204 20:06:23.639690 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:06:25.009650 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:06:26.330685 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:06:27.649596 139681449744192 submission_runner.py:408] Time since start: 8271.07s, 	Step: 32419, 	{'train/ssim': 0.751089368547712, 'train/loss': 0.26451969146728516, 'validation/ssim': 0.7267552570607062, 'validation/loss': 0.2846938666159609, 'validation/num_examples': 3554, 'test/ssim': 0.7439336406555431, 'test/loss': 0.28602935441610233, 'test/num_examples': 3581, 'score': 7677.118875980377, 'total_duration': 8271.065751314163, 'accumulated_submission_time': 7677.118875980377, 'accumulated_eval_time': 589.8650617599487, 'accumulated_logging_time': 2.8115787506103516}
I0204 20:06:27.672409 139487493474048 logging_writer.py:48] [32419] accumulated_eval_time=589.865062, accumulated_logging_time=2.811579, accumulated_submission_time=7677.118876, global_step=32419, preemption_count=0, score=7677.118876, test/loss=0.286029, test/num_examples=3581, test/ssim=0.743934, total_duration=8271.065751, train/loss=0.264520, train/ssim=0.751089, validation/loss=0.284694, validation/num_examples=3554, validation/ssim=0.726755
I0204 20:06:44.873118 139487501866752 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.05966538190841675, loss=0.24925629794597626
I0204 20:07:08.959387 139487493474048 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.11873021721839905, loss=0.23357197642326355
I0204 20:07:32.892260 139487501866752 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.07827825844287872, loss=0.24712657928466797
I0204 20:07:47.840214 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:07:49.211254 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:07:50.532045 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:07:51.855488 139681449744192 submission_runner.py:408] Time since start: 8355.27s, 	Step: 32765, 	{'train/ssim': 0.7514265605381557, 'train/loss': 0.2642244781766619, 'validation/ssim': 0.7267815670942952, 'validation/loss': 0.28469903588496237, 'validation/num_examples': 3554, 'test/ssim': 0.7439089607040631, 'test/loss': 0.2860738396877618, 'test/num_examples': 3581, 'score': 7757.2637186050415, 'total_duration': 8355.271630525589, 'accumulated_submission_time': 7757.2637186050415, 'accumulated_eval_time': 593.8802864551544, 'accumulated_logging_time': 2.8437328338623047}
I0204 20:07:51.878252 139487493474048 logging_writer.py:48] [32765] accumulated_eval_time=593.880286, accumulated_logging_time=2.843733, accumulated_submission_time=7757.263719, global_step=32765, preemption_count=0, score=7757.263719, test/loss=0.286074, test/num_examples=3581, test/ssim=0.743909, total_duration=8355.271631, train/loss=0.264224, train/ssim=0.751427, validation/loss=0.284699, validation/num_examples=3554, validation/ssim=0.726782
I0204 20:07:58.159789 139487501866752 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.05249223858118057, loss=0.2324681580066681
I0204 20:08:21.967143 139487493474048 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.08020089566707611, loss=0.21377190947532654
I0204 20:08:45.931766 139487501866752 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.07077670097351074, loss=0.2141522467136383
I0204 20:09:09.900938 139487493474048 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.054861582815647125, loss=0.23445037007331848
I0204 20:09:11.858574 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:09:13.229698 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:09:14.548188 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:09:15.868542 139681449744192 submission_runner.py:408] Time since start: 8439.28s, 	Step: 33109, 	{'train/ssim': 0.7512797628130231, 'train/loss': 0.2643719060080392, 'validation/ssim': 0.7268199673783061, 'validation/loss': 0.28465397222429834, 'validation/num_examples': 3554, 'test/ssim': 0.7439951360042586, 'test/loss': 0.2859970045901983, 'test/num_examples': 3581, 'score': 7837.2211084365845, 'total_duration': 8439.284693956375, 'accumulated_submission_time': 7837.2211084365845, 'accumulated_eval_time': 597.8902106285095, 'accumulated_logging_time': 2.8761162757873535}
I0204 20:09:15.891853 139487501866752 logging_writer.py:48] [33109] accumulated_eval_time=597.890211, accumulated_logging_time=2.876116, accumulated_submission_time=7837.221108, global_step=33109, preemption_count=0, score=7837.221108, test/loss=0.285997, test/num_examples=3581, test/ssim=0.743995, total_duration=8439.284694, train/loss=0.264372, train/ssim=0.751280, validation/loss=0.284654, validation/num_examples=3554, validation/ssim=0.726820
I0204 20:09:35.492203 139487493474048 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.0667034462094307, loss=0.2887684404850006
I0204 20:09:59.469676 139487501866752 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.07140900194644928, loss=0.3217845857143402
I0204 20:10:23.247063 139487493474048 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.048520371317863464, loss=0.2638678252696991
I0204 20:10:35.925294 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:10:37.297892 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:10:38.620882 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:10:39.939695 139681449744192 submission_runner.py:408] Time since start: 8523.36s, 	Step: 33454, 	{'train/ssim': 0.7510183198111398, 'train/loss': 0.26439785957336426, 'validation/ssim': 0.726607151493036, 'validation/loss': 0.28465589567322913, 'validation/num_examples': 3554, 'test/ssim': 0.7438003552822187, 'test/loss': 0.2859811535163886, 'test/num_examples': 3581, 'score': 7917.2318749427795, 'total_duration': 8523.35584950447, 'accumulated_submission_time': 7917.2318749427795, 'accumulated_eval_time': 601.9045717716217, 'accumulated_logging_time': 2.9088120460510254}
I0204 20:10:39.963401 139487501866752 logging_writer.py:48] [33454] accumulated_eval_time=601.904572, accumulated_logging_time=2.908812, accumulated_submission_time=7917.231875, global_step=33454, preemption_count=0, score=7917.231875, test/loss=0.285981, test/num_examples=3581, test/ssim=0.743800, total_duration=8523.355850, train/loss=0.264398, train/ssim=0.751018, validation/loss=0.284656, validation/num_examples=3554, validation/ssim=0.726607
I0204 20:10:48.874007 139487493474048 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.04832332581281662, loss=0.22225621342658997
I0204 20:11:13.263145 139487501866752 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.04796484112739563, loss=0.2981351912021637
I0204 20:11:37.152889 139487493474048 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.07815903425216675, loss=0.24874553084373474
I0204 20:12:00.066597 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:12:01.438118 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:12:02.759122 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:12:04.082227 139681449744192 submission_runner.py:408] Time since start: 8607.50s, 	Step: 33796, 	{'train/ssim': 0.7513384137834821, 'train/loss': 0.26416003704071045, 'validation/ssim': 0.7267140402979038, 'validation/loss': 0.2846327284178039, 'validation/num_examples': 3554, 'test/ssim': 0.7438691455337196, 'test/loss': 0.28599066416067437, 'test/num_examples': 3581, 'score': 7997.312318086624, 'total_duration': 8607.498377799988, 'accumulated_submission_time': 7997.312318086624, 'accumulated_eval_time': 605.9201576709747, 'accumulated_logging_time': 2.9417948722839355}
I0204 20:12:04.105960 139487501866752 logging_writer.py:48] [33796] accumulated_eval_time=605.920158, accumulated_logging_time=2.941795, accumulated_submission_time=7997.312318, global_step=33796, preemption_count=0, score=7997.312318, test/loss=0.285991, test/num_examples=3581, test/ssim=0.743869, total_duration=8607.498378, train/loss=0.264160, train/ssim=0.751338, validation/loss=0.284633, validation/num_examples=3554, validation/ssim=0.726714
I0204 20:12:04.485905 139487493474048 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.06830640882253647, loss=0.2381819188594818
I0204 20:12:26.713974 139487501866752 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.08424095809459686, loss=0.2858424484729767
I0204 20:12:50.674448 139487493474048 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.07741934061050415, loss=0.3971374034881592
I0204 20:13:14.643992 139487501866752 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.08501410484313965, loss=0.21735326945781708
I0204 20:13:24.180608 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:13:25.552939 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:13:26.874563 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:13:28.195259 139681449744192 submission_runner.py:408] Time since start: 8691.61s, 	Step: 34141, 	{'train/ssim': 0.7514914103916713, 'train/loss': 0.26423702921186176, 'validation/ssim': 0.7269534409951814, 'validation/loss': 0.28462163423914955, 'validation/num_examples': 3554, 'test/ssim': 0.744121058298136, 'test/loss': 0.28595476914836987, 'test/num_examples': 3581, 'score': 8077.364030599594, 'total_duration': 8691.611410140991, 'accumulated_submission_time': 8077.364030599594, 'accumulated_eval_time': 609.9347627162933, 'accumulated_logging_time': 2.9749035835266113}
I0204 20:13:28.219419 139487493474048 logging_writer.py:48] [34141] accumulated_eval_time=609.934763, accumulated_logging_time=2.974904, accumulated_submission_time=8077.364031, global_step=34141, preemption_count=0, score=8077.364031, test/loss=0.285955, test/num_examples=3581, test/ssim=0.744121, total_duration=8691.611410, train/loss=0.264237, train/ssim=0.751491, validation/loss=0.284622, validation/num_examples=3554, validation/ssim=0.726953
I0204 20:13:40.234397 139487501866752 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.07030004262924194, loss=0.3114910125732422
I0204 20:14:03.996086 139487493474048 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.06262372434139252, loss=0.235240176320076
I0204 20:14:27.783676 139487501866752 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.0704558789730072, loss=0.2064395546913147
I0204 20:14:48.207612 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:14:49.581147 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:14:50.901543 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:14:52.221692 139681449744192 submission_runner.py:408] Time since start: 8775.64s, 	Step: 34487, 	{'train/ssim': 0.7512409346444267, 'train/loss': 0.2642880848475865, 'validation/ssim': 0.7267562187851716, 'validation/loss': 0.2846199512213351, 'validation/num_examples': 3554, 'test/ssim': 0.7439071881108629, 'test/loss': 0.2859628139944324, 'test/num_examples': 3581, 'score': 8157.329024076462, 'total_duration': 8775.637843370438, 'accumulated_submission_time': 8157.329024076462, 'accumulated_eval_time': 613.9488220214844, 'accumulated_logging_time': 3.0089025497436523}
I0204 20:14:52.245523 139487493474048 logging_writer.py:48] [34487] accumulated_eval_time=613.948822, accumulated_logging_time=3.008903, accumulated_submission_time=8157.329024, global_step=34487, preemption_count=0, score=8157.329024, test/loss=0.285963, test/num_examples=3581, test/ssim=0.743907, total_duration=8775.637843, train/loss=0.264288, train/ssim=0.751241, validation/loss=0.284620, validation/num_examples=3554, validation/ssim=0.726756
I0204 20:14:53.307860 139487501866752 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.07577721774578094, loss=0.23875127732753754
I0204 20:15:17.610635 139487493474048 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.05101844668388367, loss=0.24254077672958374
I0204 20:15:41.472842 139487501866752 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.2631334960460663, loss=0.3489072620868683
I0204 20:16:05.701225 139487493474048 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.04987189546227455, loss=0.3138940930366516
I0204 20:16:12.425395 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:16:13.796485 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:16:15.116374 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:16:16.439258 139681449744192 submission_runner.py:408] Time since start: 8859.86s, 	Step: 34829, 	{'train/ssim': 0.751697267804827, 'train/loss': 0.26422337123325895, 'validation/ssim': 0.7271451676368177, 'validation/loss': 0.2846372794353633, 'validation/num_examples': 3554, 'test/ssim': 0.7442693425370008, 'test/loss': 0.28600201557482197, 'test/num_examples': 3581, 'score': 8237.486559867859, 'total_duration': 8859.855407238007, 'accumulated_submission_time': 8237.486559867859, 'accumulated_eval_time': 617.962637424469, 'accumulated_logging_time': 3.041879415512085}
I0204 20:16:16.463749 139487501866752 logging_writer.py:48] [34829] accumulated_eval_time=617.962637, accumulated_logging_time=3.041879, accumulated_submission_time=8237.486560, global_step=34829, preemption_count=0, score=8237.486560, test/loss=0.286002, test/num_examples=3581, test/ssim=0.744269, total_duration=8859.855407, train/loss=0.264223, train/ssim=0.751697, validation/loss=0.284637, validation/num_examples=3554, validation/ssim=0.727145
I0204 20:16:31.422445 139487493474048 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.08058839291334152, loss=0.17860914766788483
I0204 20:16:55.324639 139487501866752 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.05877336114645004, loss=0.24018439650535583
I0204 20:17:19.322162 139487493474048 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.09137310087680817, loss=0.22024743258953094
I0204 20:17:36.607770 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:17:37.980746 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:17:39.301858 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:17:40.621898 139681449744192 submission_runner.py:408] Time since start: 8944.04s, 	Step: 35174, 	{'train/ssim': 0.7514427730015346, 'train/loss': 0.2641376086643764, 'validation/ssim': 0.7268877689531162, 'validation/loss': 0.2845476158026168, 'validation/num_examples': 3554, 'test/ssim': 0.7440546542297891, 'test/loss': 0.28590031303995916, 'test/num_examples': 3581, 'score': 8317.607504606247, 'total_duration': 8944.038051128387, 'accumulated_submission_time': 8317.607504606247, 'accumulated_eval_time': 621.9767315387726, 'accumulated_logging_time': 3.076141119003296}
I0204 20:17:40.646375 139487501866752 logging_writer.py:48] [35174] accumulated_eval_time=621.976732, accumulated_logging_time=3.076141, accumulated_submission_time=8317.607505, global_step=35174, preemption_count=0, score=8317.607505, test/loss=0.285900, test/num_examples=3581, test/ssim=0.744055, total_duration=8944.038051, train/loss=0.264138, train/ssim=0.751443, validation/loss=0.284548, validation/num_examples=3554, validation/ssim=0.726888
I0204 20:17:44.833326 139487493474048 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.08064503222703934, loss=0.21726390719413757
I0204 20:18:08.706054 139487501866752 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.04946749284863472, loss=0.28993237018585205
I0204 20:18:32.412206 139487493474048 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.054633624851703644, loss=0.2459360957145691
I0204 20:18:56.376216 139487501866752 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.04756692796945572, loss=0.31861960887908936
I0204 20:19:00.671850 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:19:02.043697 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:19:03.362364 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:19:04.683481 139681449744192 submission_runner.py:408] Time since start: 9028.10s, 	Step: 35519, 	{'train/ssim': 0.7515405927385602, 'train/loss': 0.2641528333936419, 'validation/ssim': 0.7270060610623593, 'validation/loss': 0.28454136459359175, 'validation/num_examples': 3554, 'test/ssim': 0.7441674866046495, 'test/loss': 0.28588320069791084, 'test/num_examples': 3581, 'score': 8397.610383033752, 'total_duration': 9028.099632501602, 'accumulated_submission_time': 8397.610383033752, 'accumulated_eval_time': 625.9883260726929, 'accumulated_logging_time': 3.109600782394409}
I0204 20:19:04.707380 139487493474048 logging_writer.py:48] [35519] accumulated_eval_time=625.988326, accumulated_logging_time=3.109601, accumulated_submission_time=8397.610383, global_step=35519, preemption_count=0, score=8397.610383, test/loss=0.285883, test/num_examples=3581, test/ssim=0.744167, total_duration=9028.099633, train/loss=0.264153, train/ssim=0.751541, validation/loss=0.284541, validation/num_examples=3554, validation/ssim=0.727006
I0204 20:19:21.769129 139487501866752 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.09252141416072845, loss=0.20179902017116547
I0204 20:19:46.188400 139487493474048 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.0759972557425499, loss=0.20891420543193817
I0204 20:20:09.990542 139487501866752 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.10385867953300476, loss=0.23491090536117554
I0204 20:20:24.775430 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:20:26.145136 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:20:27.463490 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:20:28.786134 139681449744192 submission_runner.py:408] Time since start: 9112.20s, 	Step: 35862, 	{'train/ssim': 0.7511764253888812, 'train/loss': 0.264157908303397, 'validation/ssim': 0.7266679462181697, 'validation/loss': 0.2845379298633582, 'validation/num_examples': 3554, 'test/ssim': 0.7438509423650865, 'test/loss': 0.2858744911293982, 'test/num_examples': 3581, 'score': 8477.655651330948, 'total_duration': 9112.202283859253, 'accumulated_submission_time': 8477.655651330948, 'accumulated_eval_time': 629.9989938735962, 'accumulated_logging_time': 3.143000602722168}
I0204 20:20:28.809982 139487493474048 logging_writer.py:48] [35862] accumulated_eval_time=629.998994, accumulated_logging_time=3.143001, accumulated_submission_time=8477.655651, global_step=35862, preemption_count=0, score=8477.655651, test/loss=0.285874, test/num_examples=3581, test/ssim=0.743851, total_duration=9112.202284, train/loss=0.264158, train/ssim=0.751176, validation/loss=0.284538, validation/num_examples=3554, validation/ssim=0.726668
I0204 20:20:35.889561 139487501866752 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.07099701464176178, loss=0.19004493951797485
I0204 20:20:59.629603 139487493474048 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.05814105644822121, loss=0.3018646240234375
I0204 20:21:23.679454 139487501866752 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.059343427419662476, loss=0.24438658356666565
I0204 20:21:44.784608 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:21:46.156549 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:21:47.477151 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:21:48.798640 139681449744192 submission_runner.py:408] Time since start: 9192.21s, 	Step: 36189, 	{'train/ssim': 0.7514442716326032, 'train/loss': 0.26414341585976736, 'validation/ssim': 0.7268797316843697, 'validation/loss': 0.2845460530003605, 'validation/num_examples': 3554, 'test/ssim': 0.7440562222930047, 'test/loss': 0.2858859788968689, 'test/num_examples': 3581, 'score': 8553.608373880386, 'total_duration': 9192.214786529541, 'accumulated_submission_time': 8553.608373880386, 'accumulated_eval_time': 634.0129742622375, 'accumulated_logging_time': 3.176217794418335}
I0204 20:21:48.824350 139487493474048 logging_writer.py:48] [36189] accumulated_eval_time=634.012974, accumulated_logging_time=3.176218, accumulated_submission_time=8553.608374, global_step=36189, preemption_count=0, score=8553.608374, test/loss=0.285886, test/num_examples=3581, test/ssim=0.744056, total_duration=9192.214787, train/loss=0.264143, train/ssim=0.751444, validation/loss=0.284546, validation/num_examples=3554, validation/ssim=0.726880
I0204 20:21:48.845874 139487501866752 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8553.608374
I0204 20:21:48.912018 139681449744192 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 20:21:49.171446 139681449744192 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1/checkpoint_36189
I0204 20:21:49.172739 139681449744192 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_1/checkpoint_36189.
I0204 20:21:49.696255 139681449744192 submission_runner.py:583] Tuning trial 1/5
I0204 20:21:49.696521 139681449744192 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0204 20:21:49.702025 139681449744192 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 71.32777667045593, 'total_duration': 279.655978679657, 'accumulated_submission_time': 71.32777667045593, 'accumulated_eval_time': 208.3280806541443, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (333, {'train/ssim': 0.6802842276436942, 'train/loss': 0.32911596979413715, 'validation/ssim': 0.6573601735060847, 'validation/loss': 0.34868460823192177, 'validation/num_examples': 3554, 'test/ssim': 0.6765431241927883, 'test/loss': 0.3496438723907428, 'test/num_examples': 3581, 'score': 151.29912686347961, 'total_duration': 364.08095121383667, 'accumulated_submission_time': 151.29912686347961, 'accumulated_eval_time': 212.7399332523346, 'accumulated_logging_time': 0.028414011001586914, 'global_step': 333, 'preemption_count': 0}), (564, {'train/ssim': 0.7045314652579171, 'train/loss': 0.3065744127546038, 'validation/ssim': 0.6825660100195202, 'validation/loss': 0.32483030371808175, 'validation/num_examples': 3554, 'test/ssim': 0.700672003717537, 'test/loss': 0.32667249622574, 'test/num_examples': 3581, 'score': 231.5786828994751, 'total_duration': 448.4144470691681, 'accumulated_submission_time': 231.5786828994751, 'accumulated_eval_time': 216.74945425987244, 'accumulated_logging_time': 0.06387090682983398, 'global_step': 564, 'preemption_count': 0}), (795, {'train/ssim': 0.7191570145743233, 'train/loss': 0.293259859085083, 'validation/ssim': 0.6973806884628235, 'validation/loss': 0.3110030415223164, 'validation/num_examples': 3554, 'test/ssim': 0.7146922614580424, 'test/loss': 0.31336499139337826, 'test/num_examples': 3581, 'score': 311.58346366882324, 'total_duration': 532.4777381420135, 'accumulated_submission_time': 311.58346366882324, 'accumulated_eval_time': 220.76053142547607, 'accumulated_logging_time': 0.10216903686523438, 'global_step': 795, 'preemption_count': 0}), (1054, {'train/ssim': 0.7251708166939872, 'train/loss': 0.2865138053894043, 'validation/ssim': 0.7035528299978897, 'validation/loss': 0.30433327627101503, 'validation/num_examples': 3554, 'test/ssim': 0.7205648627303826, 'test/loss': 0.3066303644124372, 'test/num_examples': 3581, 'score': 391.5698597431183, 'total_duration': 616.5227851867676, 'accumulated_submission_time': 391.5698597431183, 'accumulated_eval_time': 224.7690806388855, 'accumulated_logging_time': 0.1421968936920166, 'global_step': 1054, 'preemption_count': 0}), (1398, {'train/ssim': 0.731006281716483, 'train/loss': 0.2799362965992519, 'validation/ssim': 0.7094610468618107, 'validation/loss': 0.2978182112694323, 'validation/num_examples': 3554, 'test/ssim': 0.7265395244650587, 'test/loss': 0.29966195965905124, 'test/num_examples': 3581, 'score': 471.7077603340149, 'total_duration': 700.7194221019745, 'accumulated_submission_time': 471.7077603340149, 'accumulated_eval_time': 228.78094816207886, 'accumulated_logging_time': 0.1752948760986328, 'global_step': 1398, 'preemption_count': 0}), (1744, {'train/ssim': 0.7316139766148159, 'train/loss': 0.27979694093976704, 'validation/ssim': 0.7091029418876618, 'validation/loss': 0.2986845189289357, 'validation/num_examples': 3554, 'test/ssim': 0.7262638180457623, 'test/loss': 0.30030496784243227, 'test/num_examples': 3581, 'score': 551.8113622665405, 'total_duration': 784.8702282905579, 'accumulated_submission_time': 551.8113622665405, 'accumulated_eval_time': 232.7886414527893, 'accumulated_logging_time': 0.20101261138916016, 'global_step': 1744, 'preemption_count': 0}), (2086, {'train/ssim': 0.7330848830086845, 'train/loss': 0.27615112917763845, 'validation/ssim': 0.7116767226408625, 'validation/loss': 0.29396547436647086, 'validation/num_examples': 3554, 'test/ssim': 0.7289850213147515, 'test/loss': 0.2955346809223157, 'test/num_examples': 3581, 'score': 631.8748698234558, 'total_duration': 868.9877972602844, 'accumulated_submission_time': 631.8748698234558, 'accumulated_eval_time': 236.79975581169128, 'accumulated_logging_time': 0.23016881942749023, 'global_step': 2086, 'preemption_count': 0}), (2429, {'train/ssim': 0.7360131399972099, 'train/loss': 0.2751845802579607, 'validation/ssim': 0.713600927212296, 'validation/loss': 0.29331084913126054, 'validation/num_examples': 3554, 'test/ssim': 0.7307537966219282, 'test/loss': 0.29507499978183466, 'test/num_examples': 3581, 'score': 711.8415286540985, 'total_duration': 953.0009279251099, 'accumulated_submission_time': 711.8415286540985, 'accumulated_eval_time': 240.80744862556458, 'accumulated_logging_time': 0.25550317764282227, 'global_step': 2429, 'preemption_count': 0}), (2776, {'train/ssim': 0.7387440545218331, 'train/loss': 0.27338411126817974, 'validation/ssim': 0.7164845206325618, 'validation/loss': 0.29148267961715674, 'validation/num_examples': 3554, 'test/ssim': 0.7335982632949944, 'test/loss': 0.2931648601669401, 'test/num_examples': 3581, 'score': 792.1041221618652, 'total_duration': 1037.3116459846497, 'accumulated_submission_time': 792.1041221618652, 'accumulated_eval_time': 244.81696820259094, 'accumulated_logging_time': 0.2803800106048584, 'global_step': 2776, 'preemption_count': 0}), (3120, {'train/ssim': 0.7408569880894252, 'train/loss': 0.27269210134233746, 'validation/ssim': 0.7182428964283202, 'validation/loss': 0.2912389855070871, 'validation/num_examples': 3554, 'test/ssim': 0.7353520397366309, 'test/loss': 0.2928364872765987, 'test/num_examples': 3581, 'score': 872.119637966156, 'total_duration': 1121.3769915103912, 'accumulated_submission_time': 872.119637966156, 'accumulated_eval_time': 248.82698583602905, 'accumulated_logging_time': 0.3063969612121582, 'global_step': 3120, 'preemption_count': 0}), (3465, {'train/ssim': 0.7407792636326381, 'train/loss': 0.27193306173597065, 'validation/ssim': 0.7179621415790307, 'validation/loss': 0.29063742685398497, 'validation/num_examples': 3554, 'test/ssim': 0.7351641448574071, 'test/loss': 0.29226359878961883, 'test/num_examples': 3581, 'score': 952.2769184112549, 'total_duration': 1205.583834886551, 'accumulated_submission_time': 952.2769184112549, 'accumulated_eval_time': 252.83643865585327, 'accumulated_logging_time': 0.33269166946411133, 'global_step': 3465, 'preemption_count': 0}), (3811, {'train/ssim': 0.7399152347019741, 'train/loss': 0.2725422552653721, 'validation/ssim': 0.7170441068822102, 'validation/loss': 0.29134511867130347, 'validation/num_examples': 3554, 'test/ssim': 0.7342503048860305, 'test/loss': 0.2929896120584334, 'test/num_examples': 3581, 'score': 1032.3964014053345, 'total_duration': 1289.7542309761047, 'accumulated_submission_time': 1032.3964014053345, 'accumulated_eval_time': 256.84815645217896, 'accumulated_logging_time': 0.3579692840576172, 'global_step': 3811, 'preemption_count': 0}), (4156, {'train/ssim': 0.7418276923043388, 'train/loss': 0.2715973513466971, 'validation/ssim': 0.7188788023837578, 'validation/loss': 0.2905141543859032, 'validation/num_examples': 3554, 'test/ssim': 0.7362064296591385, 'test/loss': 0.29198206326576026, 'test/num_examples': 3581, 'score': 1112.4486014842987, 'total_duration': 1373.8563287258148, 'accumulated_submission_time': 1112.4486014842987, 'accumulated_eval_time': 260.85873436927795, 'accumulated_logging_time': 0.3834872245788574, 'global_step': 4156, 'preemption_count': 0}), (4497, {'train/ssim': 0.7427105222429548, 'train/loss': 0.2710503510066441, 'validation/ssim': 0.7198047369601154, 'validation/loss': 0.2898978607400992, 'validation/num_examples': 3554, 'test/ssim': 0.7369858934306059, 'test/loss': 0.2915290293497801, 'test/num_examples': 3581, 'score': 1192.4837381839752, 'total_duration': 1457.9447252750397, 'accumulated_submission_time': 1192.4837381839752, 'accumulated_eval_time': 264.8728246688843, 'accumulated_logging_time': 0.4092543125152588, 'global_step': 4497, 'preemption_count': 0}), (4844, {'train/ssim': 0.7410882541111538, 'train/loss': 0.2719627789088658, 'validation/ssim': 0.719926257715778, 'validation/loss': 0.29002298796250703, 'validation/num_examples': 3554, 'test/ssim': 0.7367711369467328, 'test/loss': 0.291571639763247, 'test/num_examples': 3581, 'score': 1272.489012479782, 'total_duration': 1542.002141237259, 'accumulated_submission_time': 1272.489012479782, 'accumulated_eval_time': 268.8852117061615, 'accumulated_logging_time': 0.4353601932525635, 'global_step': 4844, 'preemption_count': 0}), (5191, {'train/ssim': 0.7438113348824638, 'train/loss': 0.2707222359521048, 'validation/ssim': 0.7214453015088632, 'validation/loss': 0.28883728473858683, 'validation/num_examples': 3554, 'test/ssim': 0.7386012030726403, 'test/loss': 0.2904303965372801, 'test/num_examples': 3581, 'score': 1352.4867494106293, 'total_duration': 1626.053575515747, 'accumulated_submission_time': 1352.4867494106293, 'accumulated_eval_time': 272.89883518218994, 'accumulated_logging_time': 0.461669921875, 'global_step': 5191, 'preemption_count': 0}), (5532, {'train/ssim': 0.7429601124354771, 'train/loss': 0.27090322971343994, 'validation/ssim': 0.7198999476821891, 'validation/loss': 0.2898524879537141, 'validation/num_examples': 3554, 'test/ssim': 0.7371778107328609, 'test/loss': 0.2914324571086987, 'test/num_examples': 3581, 'score': 1432.6245748996735, 'total_duration': 1710.2379422187805, 'accumulated_submission_time': 1432.6245748996735, 'accumulated_eval_time': 276.9070551395416, 'accumulated_logging_time': 0.4866147041320801, 'global_step': 5532, 'preemption_count': 0}), (5878, {'train/ssim': 0.7389003208705357, 'train/loss': 0.2728471074785505, 'validation/ssim': 0.71665186068954, 'validation/loss': 0.29093432493537214, 'validation/num_examples': 3554, 'test/ssim': 0.7340223903064786, 'test/loss': 0.29241372379834546, 'test/num_examples': 3581, 'score': 1512.7141561508179, 'total_duration': 1794.376507282257, 'accumulated_submission_time': 1512.7141561508179, 'accumulated_eval_time': 280.91675758361816, 'accumulated_logging_time': 0.5123147964477539, 'global_step': 5878, 'preemption_count': 0}), (6220, {'train/ssim': 0.7431642668587821, 'train/loss': 0.2703012909208025, 'validation/ssim': 0.7207949009918402, 'validation/loss': 0.2887784134623839, 'validation/num_examples': 3554, 'test/ssim': 0.7380594713199874, 'test/loss': 0.29025184186068836, 'test/num_examples': 3581, 'score': 1592.7204446792603, 'total_duration': 1878.43439412117, 'accumulated_submission_time': 1592.7204446792603, 'accumulated_eval_time': 284.9300625324249, 'accumulated_logging_time': 0.5374350547790527, 'global_step': 6220, 'preemption_count': 0}), (6563, {'train/ssim': 0.7439885820661273, 'train/loss': 0.2698183059692383, 'validation/ssim': 0.720698522461487, 'validation/loss': 0.2887259651317178, 'validation/num_examples': 3554, 'test/ssim': 0.7378159442849413, 'test/loss': 0.2902247075493926, 'test/num_examples': 3581, 'score': 1672.7735142707825, 'total_duration': 1962.5421574115753, 'accumulated_submission_time': 1672.7735142707825, 'accumulated_eval_time': 288.94540882110596, 'accumulated_logging_time': 0.563525915145874, 'global_step': 6563, 'preemption_count': 0}), (6909, {'train/ssim': 0.7427389962332589, 'train/loss': 0.2705033676964896, 'validation/ssim': 0.7205512412290729, 'validation/loss': 0.2888722159450619, 'validation/num_examples': 3554, 'test/ssim': 0.7378185349980801, 'test/loss': 0.29024720584770314, 'test/num_examples': 3581, 'score': 1752.762172460556, 'total_duration': 2046.5846438407898, 'accumulated_submission_time': 1752.762172460556, 'accumulated_eval_time': 292.95811128616333, 'accumulated_logging_time': 0.5912113189697266, 'global_step': 6909, 'preemption_count': 0}), (7254, {'train/ssim': 0.7382341793605259, 'train/loss': 0.27244414602007183, 'validation/ssim': 0.7179365871860931, 'validation/loss': 0.29044181896718485, 'validation/num_examples': 3554, 'test/ssim': 0.7345816434611491, 'test/loss': 0.2919200565920832, 'test/num_examples': 3581, 'score': 1832.9484798908234, 'total_duration': 2130.8227894306183, 'accumulated_submission_time': 1832.9484798908234, 'accumulated_eval_time': 296.9700815677643, 'accumulated_logging_time': 0.6176929473876953, 'global_step': 7254, 'preemption_count': 0}), (7598, {'train/ssim': 0.744854313986642, 'train/loss': 0.26909659590039936, 'validation/ssim': 0.722372472588105, 'validation/loss': 0.28758535991576395, 'validation/num_examples': 3554, 'test/ssim': 0.7394905676225216, 'test/loss': 0.2890893956929803, 'test/num_examples': 3581, 'score': 1912.9425868988037, 'total_duration': 2214.8672075271606, 'accumulated_submission_time': 1912.9425868988037, 'accumulated_eval_time': 300.9809060096741, 'accumulated_logging_time': 0.643923282623291, 'global_step': 7598, 'preemption_count': 0}), (7945, {'train/ssim': 0.7442718233380999, 'train/loss': 0.2691159078053066, 'validation/ssim': 0.7212834570202589, 'validation/loss': 0.28783448089960256, 'validation/num_examples': 3554, 'test/ssim': 0.7386821969465582, 'test/loss': 0.28917294619170625, 'test/num_examples': 3581, 'score': 1992.9886183738708, 'total_duration': 2298.9635775089264, 'accumulated_submission_time': 1992.9886183738708, 'accumulated_eval_time': 304.9908983707428, 'accumulated_logging_time': 0.6710951328277588, 'global_step': 7945, 'preemption_count': 0}), (8291, {'train/ssim': 0.7449304035731724, 'train/loss': 0.26954868861607145, 'validation/ssim': 0.7218863895654544, 'validation/loss': 0.2882051226391038, 'validation/num_examples': 3554, 'test/ssim': 0.7391878632452528, 'test/loss': 0.2895576670928163, 'test/num_examples': 3581, 'score': 2072.9793784618378, 'total_duration': 2383.0082693099976, 'accumulated_submission_time': 2072.9793784618378, 'accumulated_eval_time': 309.0040822029114, 'accumulated_logging_time': 0.6984851360321045, 'global_step': 8291, 'preemption_count': 0}), (8634, {'train/ssim': 0.746199539729527, 'train/loss': 0.2686595065253122, 'validation/ssim': 0.7233574158298748, 'validation/loss': 0.2872973577856816, 'validation/num_examples': 3554, 'test/ssim': 0.7405721221813041, 'test/loss': 0.28873610423284346, 'test/num_examples': 3581, 'score': 2152.9430842399597, 'total_duration': 2467.0250334739685, 'accumulated_submission_time': 2152.9430842399597, 'accumulated_eval_time': 313.0164098739624, 'accumulated_logging_time': 0.7257647514343262, 'global_step': 8634, 'preemption_count': 0}), (8978, {'train/ssim': 0.7457756996154785, 'train/loss': 0.2681561027254377, 'validation/ssim': 0.7230410771753658, 'validation/loss': 0.2870447505506559, 'validation/num_examples': 3554, 'test/ssim': 0.7401969460128107, 'test/loss': 0.28850501943852974, 'test/num_examples': 3581, 'score': 2232.981694459915, 'total_duration': 2551.1151769161224, 'accumulated_submission_time': 2232.981694459915, 'accumulated_eval_time': 317.02690291404724, 'accumulated_logging_time': 0.753577470779419, 'global_step': 8978, 'preemption_count': 0}), (9322, {'train/ssim': 0.7460549899509975, 'train/loss': 0.2680826868329729, 'validation/ssim': 0.7233535002374085, 'validation/loss': 0.28688019262516706, 'validation/num_examples': 3554, 'test/ssim': 0.7405238531049287, 'test/loss': 0.2883283737084613, 'test/num_examples': 3581, 'score': 2313.0366671085358, 'total_duration': 2635.2244424819946, 'accumulated_submission_time': 2313.0366671085358, 'accumulated_eval_time': 321.0403423309326, 'accumulated_logging_time': 0.7809731960296631, 'global_step': 9322, 'preemption_count': 0}), (9668, {'train/ssim': 0.7457577160426548, 'train/loss': 0.268416234425136, 'validation/ssim': 0.7224750336328785, 'validation/loss': 0.28726536327355623, 'validation/num_examples': 3554, 'test/ssim': 0.7397892495767593, 'test/loss': 0.28868507400167553, 'test/num_examples': 3581, 'score': 2393.2060899734497, 'total_duration': 2719.44512963295, 'accumulated_submission_time': 2393.2060899734497, 'accumulated_eval_time': 325.05160641670227, 'accumulated_logging_time': 0.8076949119567871, 'global_step': 9668, 'preemption_count': 0}), (10012, {'train/ssim': 0.7463709967476981, 'train/loss': 0.26774992261614117, 'validation/ssim': 0.7230605177484877, 'validation/loss': 0.2868000088478651, 'validation/num_examples': 3554, 'test/ssim': 0.7403182322937029, 'test/loss': 0.2882206204948862, 'test/num_examples': 3581, 'score': 2473.2667071819305, 'total_duration': 2803.558928966522, 'accumulated_submission_time': 2473.2667071819305, 'accumulated_eval_time': 329.06395959854126, 'accumulated_logging_time': 0.8351755142211914, 'global_step': 10012, 'preemption_count': 0}), (10358, {'train/ssim': 0.7464085987636021, 'train/loss': 0.2682306596211025, 'validation/ssim': 0.7235777881216587, 'validation/loss': 0.2870103173800647, 'validation/num_examples': 3554, 'test/ssim': 0.7408877119476054, 'test/loss': 0.2883491335019024, 'test/num_examples': 3581, 'score': 2553.332664489746, 'total_duration': 2887.675325155258, 'accumulated_submission_time': 2553.332664489746, 'accumulated_eval_time': 333.07476782798767, 'accumulated_logging_time': 0.8613989353179932, 'global_step': 10358, 'preemption_count': 0}), (10703, {'train/ssim': 0.7456763812473842, 'train/loss': 0.268431510244097, 'validation/ssim': 0.7229905866409327, 'validation/loss': 0.2871879616277434, 'validation/num_examples': 3554, 'test/ssim': 0.7402850302595294, 'test/loss': 0.28853927821095715, 'test/num_examples': 3581, 'score': 2633.5612363815308, 'total_duration': 2971.9580538272858, 'accumulated_submission_time': 2633.5612363815308, 'accumulated_eval_time': 337.0884153842926, 'accumulated_logging_time': 0.8884561061859131, 'global_step': 10703, 'preemption_count': 0}), (11047, {'train/ssim': 0.7449214799063546, 'train/loss': 0.2691765342439924, 'validation/ssim': 0.721823053139948, 'validation/loss': 0.2880697255732977, 'validation/num_examples': 3554, 'test/ssim': 0.7390198759512008, 'test/loss': 0.289556201294593, 'test/num_examples': 3581, 'score': 2713.557804107666, 'total_duration': 3056.007774591446, 'accumulated_submission_time': 2713.557804107666, 'accumulated_eval_time': 341.10114550590515, 'accumulated_logging_time': 0.9152963161468506, 'global_step': 11047, 'preemption_count': 0}), (11393, {'train/ssim': 0.7457105772835868, 'train/loss': 0.26866160120282856, 'validation/ssim': 0.7226912842483821, 'validation/loss': 0.28738107933512413, 'validation/num_examples': 3554, 'test/ssim': 0.7398553809384599, 'test/loss': 0.2887941566601508, 'test/num_examples': 3581, 'score': 2793.704563856125, 'total_duration': 3140.2077860832214, 'accumulated_submission_time': 2793.704563856125, 'accumulated_eval_time': 345.11279916763306, 'accumulated_logging_time': 0.943565845489502, 'global_step': 11393, 'preemption_count': 0}), (11739, {'train/ssim': 0.7449744769505092, 'train/loss': 0.26911633355276926, 'validation/ssim': 0.7231983878200618, 'validation/loss': 0.28746392502835716, 'validation/num_examples': 3554, 'test/ssim': 0.7401566536058364, 'test/loss': 0.28885237952911197, 'test/num_examples': 3581, 'score': 2873.7954342365265, 'total_duration': 3224.352249622345, 'accumulated_submission_time': 2873.7954342365265, 'accumulated_eval_time': 349.1259129047394, 'accumulated_logging_time': 0.970717191696167, 'global_step': 11739, 'preemption_count': 0}), (12081, {'train/ssim': 0.7475405420575824, 'train/loss': 0.26773977279663086, 'validation/ssim': 0.7239450294782288, 'validation/loss': 0.28714703681701076, 'validation/num_examples': 3554, 'test/ssim': 0.7412144826864004, 'test/loss': 0.28849942895228287, 'test/num_examples': 3581, 'score': 2953.9432995319366, 'total_duration': 3308.552498102188, 'accumulated_submission_time': 2953.9432995319366, 'accumulated_eval_time': 353.13616919517517, 'accumulated_logging_time': 0.9994661808013916, 'global_step': 12081, 'preemption_count': 0}), (12428, {'train/ssim': 0.7480308668954032, 'train/loss': 0.2676975556782314, 'validation/ssim': 0.7251667630222988, 'validation/loss': 0.28655677842637695, 'validation/num_examples': 3554, 'test/ssim': 0.7423336707623569, 'test/loss': 0.28791709799767873, 'test/num_examples': 3581, 'score': 3034.0391058921814, 'total_duration': 3392.7031519412994, 'accumulated_submission_time': 3034.0391058921814, 'accumulated_eval_time': 357.14885449409485, 'accumulated_logging_time': 1.0281689167022705, 'global_step': 12428, 'preemption_count': 0}), (12772, {'train/ssim': 0.7462588718959263, 'train/loss': 0.2679569721221924, 'validation/ssim': 0.7233728721159257, 'validation/loss': 0.2866768737689927, 'validation/num_examples': 3554, 'test/ssim': 0.740602392619031, 'test/loss': 0.28806333693669717, 'test/num_examples': 3581, 'score': 3114.203953027725, 'total_duration': 3476.9269206523895, 'accumulated_submission_time': 3114.203953027725, 'accumulated_eval_time': 361.1650941371918, 'accumulated_logging_time': 1.0573818683624268, 'global_step': 12772, 'preemption_count': 0}), (13113, {'train/ssim': 0.7472739900861468, 'train/loss': 0.2680355651038034, 'validation/ssim': 0.724447667900605, 'validation/loss': 0.28695208152895507, 'validation/num_examples': 3554, 'test/ssim': 0.7415505936278274, 'test/loss': 0.28836062126937306, 'test/num_examples': 3581, 'score': 3194.259214401245, 'total_duration': 3561.0386533737183, 'accumulated_submission_time': 3194.259214401245, 'accumulated_eval_time': 365.1799545288086, 'accumulated_logging_time': 1.085845947265625, 'global_step': 13113, 'preemption_count': 0}), (13458, {'train/ssim': 0.7458792413984027, 'train/loss': 0.26855465344020296, 'validation/ssim': 0.7230923233504502, 'validation/loss': 0.28733264963883126, 'validation/num_examples': 3554, 'test/ssim': 0.7403828637688494, 'test/loss': 0.2886832332318137, 'test/num_examples': 3581, 'score': 3274.239005088806, 'total_duration': 3645.07679104805, 'accumulated_submission_time': 3274.239005088806, 'accumulated_eval_time': 369.19701194763184, 'accumulated_logging_time': 1.113793134689331, 'global_step': 13458, 'preemption_count': 0}), (13805, {'train/ssim': 0.7467846189226423, 'train/loss': 0.26799471037728445, 'validation/ssim': 0.7235428912624859, 'validation/loss': 0.28704847723295934, 'validation/num_examples': 3554, 'test/ssim': 0.7408170127495811, 'test/loss': 0.28847887368882646, 'test/num_examples': 3581, 'score': 3354.3945803642273, 'total_duration': 3729.289011478424, 'accumulated_submission_time': 3354.3945803642273, 'accumulated_eval_time': 373.212171792984, 'accumulated_logging_time': 1.1418728828430176, 'global_step': 13805, 'preemption_count': 0}), (14147, {'train/ssim': 0.7473293713160923, 'train/loss': 0.2674491916384016, 'validation/ssim': 0.7241186207442318, 'validation/loss': 0.2863896444532129, 'validation/num_examples': 3554, 'test/ssim': 0.7413705390646816, 'test/loss': 0.28778790322404707, 'test/num_examples': 3581, 'score': 3434.455368757248, 'total_duration': 3813.404773712158, 'accumulated_submission_time': 3434.455368757248, 'accumulated_eval_time': 377.22587037086487, 'accumulated_logging_time': 1.1696898937225342, 'global_step': 14147, 'preemption_count': 0}), (14488, {'train/ssim': 0.7461852346147809, 'train/loss': 0.2679217542920794, 'validation/ssim': 0.723222568320906, 'validation/loss': 0.2866953526176491, 'validation/num_examples': 3554, 'test/ssim': 0.7404717661355068, 'test/loss': 0.2880733248176138, 'test/num_examples': 3581, 'score': 3514.4844086170197, 'total_duration': 3897.490335702896, 'accumulated_submission_time': 3514.4844086170197, 'accumulated_eval_time': 381.2357349395752, 'accumulated_logging_time': 1.2031478881835938, 'global_step': 14488, 'preemption_count': 0}), (14832, {'train/ssim': 0.7476575715201241, 'train/loss': 0.2674539940697806, 'validation/ssim': 0.7245439090417487, 'validation/loss': 0.28643901870032007, 'validation/num_examples': 3554, 'test/ssim': 0.7417353523806199, 'test/loss': 0.28783964931016126, 'test/num_examples': 3581, 'score': 3594.580799818039, 'total_duration': 3981.6425681114197, 'accumulated_submission_time': 3594.580799818039, 'accumulated_eval_time': 385.2501049041748, 'accumulated_logging_time': 1.2313237190246582, 'global_step': 14832, 'preemption_count': 0}), (15175, {'train/ssim': 0.7454748834882464, 'train/loss': 0.2678097827093942, 'validation/ssim': 0.7224384881031936, 'validation/loss': 0.2868108969427054, 'validation/num_examples': 3554, 'test/ssim': 0.7397276178747207, 'test/loss': 0.28818574813250486, 'test/num_examples': 3581, 'score': 3674.611796617508, 'total_duration': 4065.728991985321, 'accumulated_submission_time': 3674.611796617508, 'accumulated_eval_time': 389.26374077796936, 'accumulated_logging_time': 1.2599167823791504, 'global_step': 15175, 'preemption_count': 0}), (15522, {'train/ssim': 0.7466159548078265, 'train/loss': 0.26793583801814486, 'validation/ssim': 0.7230707532445836, 'validation/loss': 0.28724020387459553, 'validation/num_examples': 3554, 'test/ssim': 0.7403652741901704, 'test/loss': 0.28855615193469003, 'test/num_examples': 3581, 'score': 3754.784963130951, 'total_duration': 4149.960080385208, 'accumulated_submission_time': 3754.784963130951, 'accumulated_eval_time': 393.27994561195374, 'accumulated_logging_time': 1.2880818843841553, 'global_step': 15522, 'preemption_count': 0}), (15867, {'train/ssim': 0.7471408843994141, 'train/loss': 0.26690876483917236, 'validation/ssim': 0.7238568943004361, 'validation/loss': 0.28590577683156304, 'validation/num_examples': 3554, 'test/ssim': 0.7412455712440659, 'test/loss': 0.28724566014643255, 'test/num_examples': 3581, 'score': 3834.939851999283, 'total_duration': 4234.172024965286, 'accumulated_submission_time': 3834.939851999283, 'accumulated_eval_time': 397.2954897880554, 'accumulated_logging_time': 1.3162243366241455, 'global_step': 15867, 'preemption_count': 0}), (16213, {'train/ssim': 0.7476457868303571, 'train/loss': 0.26713415554591585, 'validation/ssim': 0.7246648115459693, 'validation/loss': 0.2859542752224606, 'validation/num_examples': 3554, 'test/ssim': 0.7419904012714674, 'test/loss': 0.28726873794636626, 'test/num_examples': 3581, 'score': 3915.0690200328827, 'total_duration': 4318.356410264969, 'accumulated_submission_time': 3915.0690200328827, 'accumulated_eval_time': 401.30852031707764, 'accumulated_logging_time': 1.3447983264923096, 'global_step': 16213, 'preemption_count': 0}), (16560, {'train/ssim': 0.7480151993887765, 'train/loss': 0.2664672647203718, 'validation/ssim': 0.7246860381788126, 'validation/loss': 0.28579505830248486, 'validation/num_examples': 3554, 'test/ssim': 0.7418862955092851, 'test/loss': 0.2871150336629084, 'test/num_examples': 3581, 'score': 3995.056948661804, 'total_duration': 4402.402938842773, 'accumulated_submission_time': 3995.056948661804, 'accumulated_eval_time': 405.32308530807495, 'accumulated_logging_time': 1.3752338886260986, 'global_step': 16560, 'preemption_count': 0}), (16906, {'train/ssim': 0.7479713984898159, 'train/loss': 0.2666489567075457, 'validation/ssim': 0.7247964304085186, 'validation/loss': 0.2857232724406039, 'validation/num_examples': 3554, 'test/ssim': 0.7420793036381248, 'test/loss': 0.2871182720543319, 'test/num_examples': 3581, 'score': 4075.1593718528748, 'total_duration': 4486.561875104904, 'accumulated_submission_time': 4075.1593718528748, 'accumulated_eval_time': 409.3372468948364, 'accumulated_logging_time': 1.4041290283203125, 'global_step': 16906, 'preemption_count': 0}), (17249, {'train/ssim': 0.7486212594168526, 'train/loss': 0.2669464349746704, 'validation/ssim': 0.7252796282577729, 'validation/loss': 0.28607277341551773, 'validation/num_examples': 3554, 'test/ssim': 0.742540450576829, 'test/loss': 0.28740488673947573, 'test/num_examples': 3581, 'score': 4155.271572828293, 'total_duration': 4570.726595163345, 'accumulated_submission_time': 4155.271572828293, 'accumulated_eval_time': 413.34709000587463, 'accumulated_logging_time': 1.4336450099945068, 'global_step': 17249, 'preemption_count': 0}), (17592, {'train/ssim': 0.7479096140180316, 'train/loss': 0.2669038772583008, 'validation/ssim': 0.7240776100652434, 'validation/loss': 0.28649799301842993, 'validation/num_examples': 3554, 'test/ssim': 0.7413886740566532, 'test/loss': 0.2877851079809236, 'test/num_examples': 3581, 'score': 4235.25742316246, 'total_duration': 4654.7667927742, 'accumulated_submission_time': 4235.25742316246, 'accumulated_eval_time': 417.3585879802704, 'accumulated_logging_time': 1.4628279209136963, 'global_step': 17592, 'preemption_count': 0}), (17940, {'train/ssim': 0.7473158836364746, 'train/loss': 0.26705946241106304, 'validation/ssim': 0.7240636650604952, 'validation/loss': 0.2861336196616049, 'validation/num_examples': 3554, 'test/ssim': 0.7414530328251536, 'test/loss': 0.2874236694097319, 'test/num_examples': 3581, 'score': 4315.329802036285, 'total_duration': 4738.894271850586, 'accumulated_submission_time': 4315.329802036285, 'accumulated_eval_time': 421.36989307403564, 'accumulated_logging_time': 1.4926958084106445, 'global_step': 17940, 'preemption_count': 0}), (18286, {'train/ssim': 0.7483020509992327, 'train/loss': 0.2668248585292271, 'validation/ssim': 0.7248403949555079, 'validation/loss': 0.2860413799811832, 'validation/num_examples': 3554, 'test/ssim': 0.7421564796189961, 'test/loss': 0.28731458675125665, 'test/num_examples': 3581, 'score': 4395.332178592682, 'total_duration': 4822.952711105347, 'accumulated_submission_time': 4395.332178592682, 'accumulated_eval_time': 425.3839862346649, 'accumulated_logging_time': 1.5210142135620117, 'global_step': 18286, 'preemption_count': 0}), (18630, {'train/ssim': 0.7485624722072056, 'train/loss': 0.26614345823015484, 'validation/ssim': 0.7246146644845597, 'validation/loss': 0.28574046326542274, 'validation/num_examples': 3554, 'test/ssim': 0.7419122708173346, 'test/loss': 0.28709925076576026, 'test/num_examples': 3581, 'score': 4475.431641340256, 'total_duration': 4907.1082763671875, 'accumulated_submission_time': 4475.431641340256, 'accumulated_eval_time': 429.3969392776489, 'accumulated_logging_time': 1.5507056713104248, 'global_step': 18630, 'preemption_count': 0}), (18976, {'train/ssim': 0.7473161561148507, 'train/loss': 0.2668733426502773, 'validation/ssim': 0.7237860701630205, 'validation/loss': 0.28600273926605585, 'validation/num_examples': 3554, 'test/ssim': 0.741142760838453, 'test/loss': 0.28730824632173274, 'test/num_examples': 3581, 'score': 4555.57452249527, 'total_duration': 4991.308980464935, 'accumulated_submission_time': 4555.57452249527, 'accumulated_eval_time': 433.4125940799713, 'accumulated_logging_time': 1.5795207023620605, 'global_step': 18976, 'preemption_count': 0}), (19323, {'train/ssim': 0.748532772064209, 'train/loss': 0.2665856054850987, 'validation/ssim': 0.7251577640290869, 'validation/loss': 0.28578102742948086, 'validation/num_examples': 3554, 'test/ssim': 0.7423779855923625, 'test/loss': 0.28715089458688214, 'test/num_examples': 3581, 'score': 4635.542121648788, 'total_duration': 5075.3327651023865, 'accumulated_submission_time': 4635.542121648788, 'accumulated_eval_time': 437.42550253868103, 'accumulated_logging_time': 1.6093058586120605, 'global_step': 19323, 'preemption_count': 0}), (19666, {'train/ssim': 0.7492211205618722, 'train/loss': 0.26595864977155415, 'validation/ssim': 0.7252296872801772, 'validation/loss': 0.2857543224019151, 'validation/num_examples': 3554, 'test/ssim': 0.7424777280482058, 'test/loss': 0.2870662191732407, 'test/num_examples': 3581, 'score': 4715.623168230057, 'total_duration': 5159.4710512161255, 'accumulated_submission_time': 4715.623168230057, 'accumulated_eval_time': 441.4396963119507, 'accumulated_logging_time': 1.6389601230621338, 'global_step': 19666, 'preemption_count': 0}), (20011, {'train/ssim': 0.747901439666748, 'train/loss': 0.2665020397731236, 'validation/ssim': 0.7244954106508511, 'validation/loss': 0.2856981817362479, 'validation/num_examples': 3554, 'test/ssim': 0.7418216640341385, 'test/loss': 0.28692676381204624, 'test/num_examples': 3581, 'score': 4795.6775233745575, 'total_duration': 5243.579426765442, 'accumulated_submission_time': 4795.6775233745575, 'accumulated_eval_time': 445.45088481903076, 'accumulated_logging_time': 1.6683268547058105, 'global_step': 20011, 'preemption_count': 0}), (20354, {'train/ssim': 0.7483769825526646, 'train/loss': 0.2666335957390921, 'validation/ssim': 0.7248445853263928, 'validation/loss': 0.28595743517427546, 'validation/num_examples': 3554, 'test/ssim': 0.7420431018308433, 'test/loss': 0.2872837368119066, 'test/num_examples': 3581, 'score': 4875.658908843994, 'total_duration': 5327.617372274399, 'accumulated_submission_time': 4875.658908843994, 'accumulated_eval_time': 449.4621365070343, 'accumulated_logging_time': 1.7000653743743896, 'global_step': 20354, 'preemption_count': 0}), (20696, {'train/ssim': 0.7491252762930733, 'train/loss': 0.2660750320979527, 'validation/ssim': 0.7255758393931134, 'validation/loss': 0.2855740162383054, 'validation/num_examples': 3554, 'test/ssim': 0.7427288226926836, 'test/loss': 0.28693354738987015, 'test/num_examples': 3581, 'score': 4955.702982664108, 'total_duration': 5411.722235918045, 'accumulated_submission_time': 4955.702982664108, 'accumulated_eval_time': 453.47565054893494, 'accumulated_logging_time': 1.7338788509368896, 'global_step': 20696, 'preemption_count': 0}), (21044, {'train/ssim': 0.7485916273934501, 'train/loss': 0.2661369187491281, 'validation/ssim': 0.7251855853439786, 'validation/loss': 0.28551524800400957, 'validation/num_examples': 3554, 'test/ssim': 0.7424461622539095, 'test/loss': 0.2868228625798485, 'test/num_examples': 3581, 'score': 5035.683332443237, 'total_duration': 5495.758540868759, 'accumulated_submission_time': 5035.683332443237, 'accumulated_eval_time': 457.4879927635193, 'accumulated_logging_time': 1.763725996017456, 'global_step': 21044, 'preemption_count': 0}), (21390, {'train/ssim': 0.7477847508021763, 'train/loss': 0.26690781116485596, 'validation/ssim': 0.7248390210634145, 'validation/loss': 0.2859515789592273, 'validation/num_examples': 3554, 'test/ssim': 0.7419769704691427, 'test/loss': 0.28725404587580283, 'test/num_examples': 3581, 'score': 5115.678194522858, 'total_duration': 5579.808661937714, 'accumulated_submission_time': 5115.678194522858, 'accumulated_eval_time': 461.4994411468506, 'accumulated_logging_time': 1.7938733100891113, 'global_step': 21390, 'preemption_count': 0}), (21731, {'train/ssim': 0.7492568152291434, 'train/loss': 0.26653306824820383, 'validation/ssim': 0.7260055241453293, 'validation/loss': 0.28577091214894307, 'validation/num_examples': 3554, 'test/ssim': 0.7431472910412594, 'test/loss': 0.287159791641214, 'test/num_examples': 3581, 'score': 5195.80691409111, 'total_duration': 5663.9911460876465, 'accumulated_submission_time': 5195.80691409111, 'accumulated_eval_time': 465.50981426239014, 'accumulated_logging_time': 1.823737382888794, 'global_step': 21731, 'preemption_count': 0}), (22078, {'train/ssim': 0.7461775371006557, 'train/loss': 0.26683105741228375, 'validation/ssim': 0.7226040421004502, 'validation/loss': 0.28612309221343907, 'validation/num_examples': 3554, 'test/ssim': 0.7400780459150726, 'test/loss': 0.28738392241605, 'test/num_examples': 3581, 'score': 5275.870712280273, 'total_duration': 5748.111387014389, 'accumulated_submission_time': 5275.870712280273, 'accumulated_eval_time': 469.5228455066681, 'accumulated_logging_time': 1.8534579277038574, 'global_step': 22078, 'preemption_count': 0}), (22424, {'train/ssim': 0.7486978939601353, 'train/loss': 0.2662124293191092, 'validation/ssim': 0.7253482541678391, 'validation/loss': 0.28544057696873243, 'validation/num_examples': 3554, 'test/ssim': 0.7425572902122313, 'test/loss': 0.28676562827247976, 'test/num_examples': 3581, 'score': 5356.035150527954, 'total_duration': 5832.326321363449, 'accumulated_submission_time': 5356.035150527954, 'accumulated_eval_time': 473.52979373931885, 'accumulated_logging_time': 1.8833134174346924, 'global_step': 22424, 'preemption_count': 0}), (22767, {'train/ssim': 0.749427046094622, 'train/loss': 0.2666067055293492, 'validation/ssim': 0.7262519316922833, 'validation/loss': 0.28577135866387343, 'validation/num_examples': 3554, 'test/ssim': 0.7433064153693103, 'test/loss': 0.28724923942116376, 'test/num_examples': 3581, 'score': 5436.060939788818, 'total_duration': 5916.412758111954, 'accumulated_submission_time': 5436.060939788818, 'accumulated_eval_time': 477.544869184494, 'accumulated_logging_time': 1.9157905578613281, 'global_step': 22767, 'preemption_count': 0}), (23114, {'train/ssim': 0.7493207114083427, 'train/loss': 0.26572132110595703, 'validation/ssim': 0.7254548681942882, 'validation/loss': 0.28535773127549946, 'validation/num_examples': 3554, 'test/ssim': 0.7426980068416643, 'test/loss': 0.2866858615784697, 'test/num_examples': 3581, 'score': 5516.128949642181, 'total_duration': 6000.536830663681, 'accumulated_submission_time': 5516.128949642181, 'accumulated_eval_time': 481.5577425956726, 'accumulated_logging_time': 1.9451351165771484, 'global_step': 23114, 'preemption_count': 0}), (23459, {'train/ssim': 0.7489502089364188, 'train/loss': 0.2658481938498361, 'validation/ssim': 0.7253882344277575, 'validation/loss': 0.28523621051983683, 'validation/num_examples': 3554, 'test/ssim': 0.7426928254153867, 'test/loss': 0.2865019891222773, 'test/num_examples': 3581, 'score': 5596.276057720184, 'total_duration': 6084.737917661667, 'accumulated_submission_time': 5596.276057720184, 'accumulated_eval_time': 485.5675754547119, 'accumulated_logging_time': 1.9756977558135986, 'global_step': 23459, 'preemption_count': 0}), (23801, {'train/ssim': 0.7496252059936523, 'train/loss': 0.2658059937613351, 'validation/ssim': 0.7260273003350098, 'validation/loss': 0.2852406241481869, 'validation/num_examples': 3554, 'test/ssim': 0.7432441019006563, 'test/loss': 0.28660053848654354, 'test/num_examples': 3581, 'score': 5676.2350878715515, 'total_duration': 6168.698595523834, 'accumulated_submission_time': 5676.2350878715515, 'accumulated_eval_time': 489.52425837516785, 'accumulated_logging_time': 2.007225275039673, 'global_step': 23801, 'preemption_count': 0}), (24146, {'train/ssim': 0.7498554502214704, 'train/loss': 0.2652804510934012, 'validation/ssim': 0.7258368101962578, 'validation/loss': 0.2851335979541098, 'validation/num_examples': 3554, 'test/ssim': 0.7430751601333426, 'test/loss': 0.2864032693163572, 'test/num_examples': 3581, 'score': 5756.289666891098, 'total_duration': 6252.809968471527, 'accumulated_submission_time': 5756.289666891098, 'accumulated_eval_time': 493.53691935539246, 'accumulated_logging_time': 2.037910223007202, 'global_step': 24146, 'preemption_count': 0}), (24492, {'train/ssim': 0.7493213926042829, 'train/loss': 0.2656843491962978, 'validation/ssim': 0.7257174189733399, 'validation/loss': 0.28517500362707515, 'validation/num_examples': 3554, 'test/ssim': 0.7429374432770176, 'test/loss': 0.2864860016951445, 'test/num_examples': 3581, 'score': 5836.392609119415, 'total_duration': 6336.972864627838, 'accumulated_submission_time': 5836.392609119415, 'accumulated_eval_time': 497.5527238845825, 'accumulated_logging_time': 2.0684311389923096, 'global_step': 24492, 'preemption_count': 0}), (24837, {'train/ssim': 0.7498811313084194, 'train/loss': 0.26557925769260954, 'validation/ssim': 0.7261310978826674, 'validation/loss': 0.28510529577698546, 'validation/num_examples': 3554, 'test/ssim': 0.743295916163432, 'test/loss': 0.2864755024892663, 'test/num_examples': 3581, 'score': 5916.42840719223, 'total_duration': 6421.065683841705, 'accumulated_submission_time': 5916.42840719223, 'accumulated_eval_time': 501.56517338752747, 'accumulated_logging_time': 2.099144697189331, 'global_step': 24837, 'preemption_count': 0}), (25180, {'train/ssim': 0.7501208441598075, 'train/loss': 0.2650695528302874, 'validation/ssim': 0.7260279185864519, 'validation/loss': 0.28501975382051914, 'validation/num_examples': 3554, 'test/ssim': 0.7432925755070162, 'test/loss': 0.2863555456532742, 'test/num_examples': 3581, 'score': 5996.445634841919, 'total_duration': 6505.139622926712, 'accumulated_submission_time': 5996.445634841919, 'accumulated_eval_time': 505.57781767845154, 'accumulated_logging_time': 2.1298437118530273, 'global_step': 25180, 'preemption_count': 0}), (25527, {'train/ssim': 0.7498316083635602, 'train/loss': 0.26556406702314106, 'validation/ssim': 0.7260694788222777, 'validation/loss': 0.2852243950478334, 'validation/num_examples': 3554, 'test/ssim': 0.7433385265768989, 'test/loss': 0.28652288526904146, 'test/num_examples': 3581, 'score': 6076.453567028046, 'total_duration': 6589.206932544708, 'accumulated_submission_time': 6076.453567028046, 'accumulated_eval_time': 509.5925693511963, 'accumulated_logging_time': 2.1610045433044434, 'global_step': 25527, 'preemption_count': 0}), (25872, {'train/ssim': 0.7498658725193569, 'train/loss': 0.2655244214194162, 'validation/ssim': 0.7262190956712508, 'validation/loss': 0.28506074732585646, 'validation/num_examples': 3554, 'test/ssim': 0.743424156463802, 'test/loss': 0.28636764701069883, 'test/num_examples': 3581, 'score': 6156.694766283035, 'total_duration': 6673.505701780319, 'accumulated_submission_time': 6156.694766283035, 'accumulated_eval_time': 513.6058740615845, 'accumulated_logging_time': 2.1919939517974854, 'global_step': 25872, 'preemption_count': 0}), (26214, {'train/ssim': 0.7502429825919015, 'train/loss': 0.26492088181631906, 'validation/ssim': 0.7258607159186832, 'validation/loss': 0.28504517082424735, 'validation/num_examples': 3554, 'test/ssim': 0.7430811596795588, 'test/loss': 0.2863786575415387, 'test/num_examples': 3581, 'score': 6236.789935827255, 'total_duration': 6757.661597251892, 'accumulated_submission_time': 6236.789935827255, 'accumulated_eval_time': 517.6208217144012, 'accumulated_logging_time': 2.224311351776123, 'global_step': 26214, 'preemption_count': 0}), (26559, {'train/ssim': 0.7503128732953753, 'train/loss': 0.2651557922363281, 'validation/ssim': 0.7263939234401379, 'validation/loss': 0.28492397636795685, 'validation/num_examples': 3554, 'test/ssim': 0.7435952798842851, 'test/loss': 0.2862669500815938, 'test/num_examples': 3581, 'score': 6316.855994939804, 'total_duration': 6841.782725572586, 'accumulated_submission_time': 6316.855994939804, 'accumulated_eval_time': 521.6307320594788, 'accumulated_logging_time': 2.2558205127716064, 'global_step': 26559, 'preemption_count': 0}), (26907, {'train/ssim': 0.7502010890415737, 'train/loss': 0.26542275292532785, 'validation/ssim': 0.7263083986573228, 'validation/loss': 0.28511231980031304, 'validation/num_examples': 3554, 'test/ssim': 0.743497310021642, 'test/loss': 0.28640947339255796, 'test/num_examples': 3581, 'score': 6396.952573060989, 'total_duration': 6925.938338279724, 'accumulated_submission_time': 6396.952573060989, 'accumulated_eval_time': 525.6441569328308, 'accumulated_logging_time': 2.287712812423706, 'global_step': 26907, 'preemption_count': 0}), (27249, {'train/ssim': 0.7506561960492816, 'train/loss': 0.26484290191105436, 'validation/ssim': 0.7264343845622889, 'validation/loss': 0.2849978745889315, 'validation/num_examples': 3554, 'test/ssim': 0.7435778948355907, 'test/loss': 0.2863592271929978, 'test/num_examples': 3581, 'score': 6476.943389892578, 'total_duration': 7009.990304231644, 'accumulated_submission_time': 6476.943389892578, 'accumulated_eval_time': 529.6607377529144, 'accumulated_logging_time': 2.3188319206237793, 'global_step': 27249, 'preemption_count': 0}), (27596, {'train/ssim': 0.7495948246547154, 'train/loss': 0.2651593174253191, 'validation/ssim': 0.7254652410795934, 'validation/loss': 0.2850242189698227, 'validation/num_examples': 3554, 'test/ssim': 0.7427244593863446, 'test/loss': 0.2862810285622033, 'test/num_examples': 3581, 'score': 6556.95263504982, 'total_duration': 7094.058998584747, 'accumulated_submission_time': 6556.95263504982, 'accumulated_eval_time': 533.6739375591278, 'accumulated_logging_time': 2.35146427154541, 'global_step': 27596, 'preemption_count': 0}), (27939, {'train/ssim': 0.750136307307652, 'train/loss': 0.265045166015625, 'validation/ssim': 0.7260886446169809, 'validation/loss': 0.28485966104433386, 'validation/num_examples': 3554, 'test/ssim': 0.7433330724439752, 'test/loss': 0.28614869766214046, 'test/num_examples': 3581, 'score': 6636.923789262772, 'total_duration': 7178.088750839233, 'accumulated_submission_time': 6636.923789262772, 'accumulated_eval_time': 537.6880068778992, 'accumulated_logging_time': 2.3826534748077393, 'global_step': 27939, 'preemption_count': 0}), (28283, {'train/ssim': 0.7500929151262555, 'train/loss': 0.2648871626172747, 'validation/ssim': 0.7258392145074212, 'validation/loss': 0.284950715742825, 'validation/num_examples': 3554, 'test/ssim': 0.7430446851656312, 'test/loss': 0.2862953115727974, 'test/num_examples': 3581, 'score': 6716.911543369293, 'total_duration': 7262.139762163162, 'accumulated_submission_time': 6716.911543369293, 'accumulated_eval_time': 541.7042119503021, 'accumulated_logging_time': 2.416171073913574, 'global_step': 28283, 'preemption_count': 0}), (28628, {'train/ssim': 0.7504279272896903, 'train/loss': 0.26495582716805594, 'validation/ssim': 0.7262554351171215, 'validation/loss': 0.28491415303948897, 'validation/num_examples': 3554, 'test/ssim': 0.7434871516990715, 'test/loss': 0.28625201939271505, 'test/num_examples': 3581, 'score': 6796.866130590439, 'total_duration': 7346.153185129166, 'accumulated_submission_time': 6796.866130590439, 'accumulated_eval_time': 545.7160577774048, 'accumulated_logging_time': 2.4494388103485107, 'global_step': 28628, 'preemption_count': 0}), (28972, {'train/ssim': 0.7505592618669782, 'train/loss': 0.2649299076625279, 'validation/ssim': 0.7264863863780248, 'validation/loss': 0.28486613551082407, 'validation/num_examples': 3554, 'test/ssim': 0.7436901817971586, 'test/loss': 0.28614573197736315, 'test/num_examples': 3581, 'score': 6876.82315993309, 'total_duration': 7430.169394493103, 'accumulated_submission_time': 6876.82315993309, 'accumulated_eval_time': 549.7289471626282, 'accumulated_logging_time': 2.482147455215454, 'global_step': 28972, 'preemption_count': 0}), (29314, {'train/ssim': 0.7498602867126465, 'train/loss': 0.26512367384774344, 'validation/ssim': 0.7258943762749719, 'validation/loss': 0.2850154947550295, 'validation/num_examples': 3554, 'test/ssim': 0.7430681379372033, 'test/loss': 0.28638704327090897, 'test/num_examples': 3581, 'score': 6956.778971672058, 'total_duration': 7514.184953689575, 'accumulated_submission_time': 6956.778971672058, 'accumulated_eval_time': 553.7419407367706, 'accumulated_logging_time': 2.5154223442077637, 'global_step': 29314, 'preemption_count': 0}), (29658, {'train/ssim': 0.7504299027579171, 'train/loss': 0.2647002935409546, 'validation/ssim': 0.7261024522325197, 'validation/loss': 0.2848177229881823, 'validation/num_examples': 3554, 'test/ssim': 0.7433210051748813, 'test/loss': 0.2861635942626885, 'test/num_examples': 3581, 'score': 7036.799525976181, 'total_duration': 7598.264146327972, 'accumulated_submission_time': 7036.799525976181, 'accumulated_eval_time': 557.7553491592407, 'accumulated_logging_time': 2.5471506118774414, 'global_step': 29658, 'preemption_count': 0}), (30003, {'train/ssim': 0.7505853516714913, 'train/loss': 0.26493951252528597, 'validation/ssim': 0.7266091436365715, 'validation/loss': 0.2848703602290113, 'validation/num_examples': 3554, 'test/ssim': 0.7437669487180606, 'test/loss': 0.2862120337807177, 'test/num_examples': 3581, 'score': 7116.821959257126, 'total_duration': 7682.350178480148, 'accumulated_submission_time': 7116.821959257126, 'accumulated_eval_time': 561.7724099159241, 'accumulated_logging_time': 2.5802698135375977, 'global_step': 30003, 'preemption_count': 0}), (30348, {'train/ssim': 0.7509135518755231, 'train/loss': 0.26484443460192, 'validation/ssim': 0.726777857585643, 'validation/loss': 0.2848333166634426, 'validation/num_examples': 3554, 'test/ssim': 0.7439271638726962, 'test/loss': 0.28620661373612466, 'test/num_examples': 3581, 'score': 7196.888969659805, 'total_duration': 7766.479268789291, 'accumulated_submission_time': 7196.888969659805, 'accumulated_eval_time': 565.7843985557556, 'accumulated_logging_time': 2.616807460784912, 'global_step': 30348, 'preemption_count': 0}), (30693, {'train/ssim': 0.7508979524884906, 'train/loss': 0.264484030859811, 'validation/ssim': 0.726506582591798, 'validation/loss': 0.28481655517990295, 'validation/num_examples': 3554, 'test/ssim': 0.7436694560920483, 'test/loss': 0.28615278826183327, 'test/num_examples': 3581, 'score': 7276.879731178284, 'total_duration': 7850.534174203873, 'accumulated_submission_time': 7276.879731178284, 'accumulated_eval_time': 569.8019735813141, 'accumulated_logging_time': 2.6498525142669678, 'global_step': 30693, 'preemption_count': 0}), (31041, {'train/ssim': 0.7510170936584473, 'train/loss': 0.26465255873543875, 'validation/ssim': 0.7267936573447172, 'validation/loss': 0.284739548528067, 'validation/num_examples': 3554, 'test/ssim': 0.7439709332894093, 'test/loss': 0.2860615678886833, 'test/num_examples': 3581, 'score': 7356.900419712067, 'total_duration': 7934.61389875412, 'accumulated_submission_time': 7356.900419712067, 'accumulated_eval_time': 573.8156337738037, 'accumulated_logging_time': 2.681325674057007, 'global_step': 31041, 'preemption_count': 0}), (31385, {'train/ssim': 0.7506763594491142, 'train/loss': 0.26465151991162983, 'validation/ssim': 0.726357583994267, 'validation/loss': 0.28475655044272297, 'validation/num_examples': 3554, 'test/ssim': 0.7435804173720678, 'test/loss': 0.2860809982372242, 'test/num_examples': 3581, 'score': 7436.869582891464, 'total_duration': 8018.64168548584, 'accumulated_submission_time': 7436.869582891464, 'accumulated_eval_time': 577.8291063308716, 'accumulated_logging_time': 2.7132408618927, 'global_step': 31385, 'preemption_count': 0}), (31729, {'train/ssim': 0.7512480872017997, 'train/loss': 0.2642843893596104, 'validation/ssim': 0.726590664787915, 'validation/loss': 0.2847422276176491, 'validation/num_examples': 3554, 'test/ssim': 0.7437989235723261, 'test/loss': 0.28608750910840197, 'test/num_examples': 3581, 'score': 7516.999427556992, 'total_duration': 8102.830830574036, 'accumulated_submission_time': 7516.999427556992, 'accumulated_eval_time': 581.842268705368, 'accumulated_logging_time': 2.745941162109375, 'global_step': 31729, 'preemption_count': 0}), (32075, {'train/ssim': 0.750896862574986, 'train/loss': 0.2644829750061035, 'validation/ssim': 0.7264721665948579, 'validation/loss': 0.2847329194987162, 'validation/num_examples': 3554, 'test/ssim': 0.7436901817971586, 'test/loss': 0.2860553979008133, 'test/num_examples': 3581, 'score': 7596.9842693805695, 'total_duration': 8186.874871730804, 'accumulated_submission_time': 7596.9842693805695, 'accumulated_eval_time': 585.8551957607269, 'accumulated_logging_time': 2.778761148452759, 'global_step': 32075, 'preemption_count': 0}), (32419, {'train/ssim': 0.751089368547712, 'train/loss': 0.26451969146728516, 'validation/ssim': 0.7267552570607062, 'validation/loss': 0.2846938666159609, 'validation/num_examples': 3554, 'test/ssim': 0.7439336406555431, 'test/loss': 0.28602935441610233, 'test/num_examples': 3581, 'score': 7677.118875980377, 'total_duration': 8271.065751314163, 'accumulated_submission_time': 7677.118875980377, 'accumulated_eval_time': 589.8650617599487, 'accumulated_logging_time': 2.8115787506103516, 'global_step': 32419, 'preemption_count': 0}), (32765, {'train/ssim': 0.7514265605381557, 'train/loss': 0.2642244781766619, 'validation/ssim': 0.7267815670942952, 'validation/loss': 0.28469903588496237, 'validation/num_examples': 3554, 'test/ssim': 0.7439089607040631, 'test/loss': 0.2860738396877618, 'test/num_examples': 3581, 'score': 7757.2637186050415, 'total_duration': 8355.271630525589, 'accumulated_submission_time': 7757.2637186050415, 'accumulated_eval_time': 593.8802864551544, 'accumulated_logging_time': 2.8437328338623047, 'global_step': 32765, 'preemption_count': 0}), (33109, {'train/ssim': 0.7512797628130231, 'train/loss': 0.2643719060080392, 'validation/ssim': 0.7268199673783061, 'validation/loss': 0.28465397222429834, 'validation/num_examples': 3554, 'test/ssim': 0.7439951360042586, 'test/loss': 0.2859970045901983, 'test/num_examples': 3581, 'score': 7837.2211084365845, 'total_duration': 8439.284693956375, 'accumulated_submission_time': 7837.2211084365845, 'accumulated_eval_time': 597.8902106285095, 'accumulated_logging_time': 2.8761162757873535, 'global_step': 33109, 'preemption_count': 0}), (33454, {'train/ssim': 0.7510183198111398, 'train/loss': 0.26439785957336426, 'validation/ssim': 0.726607151493036, 'validation/loss': 0.28465589567322913, 'validation/num_examples': 3554, 'test/ssim': 0.7438003552822187, 'test/loss': 0.2859811535163886, 'test/num_examples': 3581, 'score': 7917.2318749427795, 'total_duration': 8523.35584950447, 'accumulated_submission_time': 7917.2318749427795, 'accumulated_eval_time': 601.9045717716217, 'accumulated_logging_time': 2.9088120460510254, 'global_step': 33454, 'preemption_count': 0}), (33796, {'train/ssim': 0.7513384137834821, 'train/loss': 0.26416003704071045, 'validation/ssim': 0.7267140402979038, 'validation/loss': 0.2846327284178039, 'validation/num_examples': 3554, 'test/ssim': 0.7438691455337196, 'test/loss': 0.28599066416067437, 'test/num_examples': 3581, 'score': 7997.312318086624, 'total_duration': 8607.498377799988, 'accumulated_submission_time': 7997.312318086624, 'accumulated_eval_time': 605.9201576709747, 'accumulated_logging_time': 2.9417948722839355, 'global_step': 33796, 'preemption_count': 0}), (34141, {'train/ssim': 0.7514914103916713, 'train/loss': 0.26423702921186176, 'validation/ssim': 0.7269534409951814, 'validation/loss': 0.28462163423914955, 'validation/num_examples': 3554, 'test/ssim': 0.744121058298136, 'test/loss': 0.28595476914836987, 'test/num_examples': 3581, 'score': 8077.364030599594, 'total_duration': 8691.611410140991, 'accumulated_submission_time': 8077.364030599594, 'accumulated_eval_time': 609.9347627162933, 'accumulated_logging_time': 2.9749035835266113, 'global_step': 34141, 'preemption_count': 0}), (34487, {'train/ssim': 0.7512409346444267, 'train/loss': 0.2642880848475865, 'validation/ssim': 0.7267562187851716, 'validation/loss': 0.2846199512213351, 'validation/num_examples': 3554, 'test/ssim': 0.7439071881108629, 'test/loss': 0.2859628139944324, 'test/num_examples': 3581, 'score': 8157.329024076462, 'total_duration': 8775.637843370438, 'accumulated_submission_time': 8157.329024076462, 'accumulated_eval_time': 613.9488220214844, 'accumulated_logging_time': 3.0089025497436523, 'global_step': 34487, 'preemption_count': 0}), (34829, {'train/ssim': 0.751697267804827, 'train/loss': 0.26422337123325895, 'validation/ssim': 0.7271451676368177, 'validation/loss': 0.2846372794353633, 'validation/num_examples': 3554, 'test/ssim': 0.7442693425370008, 'test/loss': 0.28600201557482197, 'test/num_examples': 3581, 'score': 8237.486559867859, 'total_duration': 8859.855407238007, 'accumulated_submission_time': 8237.486559867859, 'accumulated_eval_time': 617.962637424469, 'accumulated_logging_time': 3.041879415512085, 'global_step': 34829, 'preemption_count': 0}), (35174, {'train/ssim': 0.7514427730015346, 'train/loss': 0.2641376086643764, 'validation/ssim': 0.7268877689531162, 'validation/loss': 0.2845476158026168, 'validation/num_examples': 3554, 'test/ssim': 0.7440546542297891, 'test/loss': 0.28590031303995916, 'test/num_examples': 3581, 'score': 8317.607504606247, 'total_duration': 8944.038051128387, 'accumulated_submission_time': 8317.607504606247, 'accumulated_eval_time': 621.9767315387726, 'accumulated_logging_time': 3.076141119003296, 'global_step': 35174, 'preemption_count': 0}), (35519, {'train/ssim': 0.7515405927385602, 'train/loss': 0.2641528333936419, 'validation/ssim': 0.7270060610623593, 'validation/loss': 0.28454136459359175, 'validation/num_examples': 3554, 'test/ssim': 0.7441674866046495, 'test/loss': 0.28588320069791084, 'test/num_examples': 3581, 'score': 8397.610383033752, 'total_duration': 9028.099632501602, 'accumulated_submission_time': 8397.610383033752, 'accumulated_eval_time': 625.9883260726929, 'accumulated_logging_time': 3.109600782394409, 'global_step': 35519, 'preemption_count': 0}), (35862, {'train/ssim': 0.7511764253888812, 'train/loss': 0.264157908303397, 'validation/ssim': 0.7266679462181697, 'validation/loss': 0.2845379298633582, 'validation/num_examples': 3554, 'test/ssim': 0.7438509423650865, 'test/loss': 0.2858744911293982, 'test/num_examples': 3581, 'score': 8477.655651330948, 'total_duration': 9112.202283859253, 'accumulated_submission_time': 8477.655651330948, 'accumulated_eval_time': 629.9989938735962, 'accumulated_logging_time': 3.143000602722168, 'global_step': 35862, 'preemption_count': 0}), (36189, {'train/ssim': 0.7514442716326032, 'train/loss': 0.26414341585976736, 'validation/ssim': 0.7268797316843697, 'validation/loss': 0.2845460530003605, 'validation/num_examples': 3554, 'test/ssim': 0.7440562222930047, 'test/loss': 0.2858859788968689, 'test/num_examples': 3581, 'score': 8553.608373880386, 'total_duration': 9192.214786529541, 'accumulated_submission_time': 8553.608373880386, 'accumulated_eval_time': 634.0129742622375, 'accumulated_logging_time': 3.176217794418335, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 20:21:49.702251 139681449744192 submission_runner.py:586] Timing: 8553.608373880386
I0204 20:21:49.702312 139681449744192 submission_runner.py:588] Total number of evals: 107
I0204 20:21:49.702357 139681449744192 submission_runner.py:589] ====================
I0204 20:21:49.702410 139681449744192 submission_runner.py:542] Using RNG seed 813120851
I0204 20:21:49.703907 139681449744192 submission_runner.py:551] --- Tuning run 2/5 ---
I0204 20:21:49.704025 139681449744192 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2.
I0204 20:21:49.704267 139681449744192 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2/hparams.json.
I0204 20:21:49.705138 139681449744192 submission_runner.py:206] Initializing dataset.
I0204 20:21:50.009337 139681449744192 submission_runner.py:213] Initializing model.
I0204 20:21:52.538522 139681449744192 submission_runner.py:255] Initializing optimizer.
I0204 20:21:52.605740 139681449744192 submission_runner.py:262] Initializing metrics bundle.
I0204 20:21:52.605903 139681449744192 submission_runner.py:280] Initializing checkpoint and logger.
I0204 20:21:52.606540 139681449744192 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2 with prefix checkpoint_
I0204 20:21:52.606663 139681449744192 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2/meta_data_0.json.
I0204 20:21:52.606909 139681449744192 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 20:21:52.606974 139681449744192 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 20:21:56.446318 139681449744192 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 20:22:00.167088 139681449744192 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2/flags_0.json.
I0204 20:22:00.174585 139681449744192 submission_runner.py:314] Starting training loop.
I0204 20:22:29.147585 139461883066112 logging_writer.py:48] [0] global_step=0, grad_norm=5.605435371398926, loss=1.0139427185058594
I0204 20:22:29.153617 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:22:30.477980 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:22:31.793716 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:22:33.110312 139681449744192 submission_runner.py:408] Time since start: 32.94s, 	Step: 1, 	{'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 28.97892165184021, 'total_duration': 32.935672760009766, 'accumulated_submission_time': 28.97892165184021, 'accumulated_eval_time': 3.9566385746002197, 'accumulated_logging_time': 0}
I0204 20:22:33.119415 139466119386880 logging_writer.py:48] [1] accumulated_eval_time=3.956639, accumulated_logging_time=0, accumulated_submission_time=28.978922, global_step=1, preemption_count=0, score=28.978922, test/loss=1.032399, test/num_examples=3581, test/ssim=0.212846, total_duration=32.935673, train/loss=1.032718, train/ssim=0.197546, validation/loss=1.037087, validation/num_examples=3554, validation/ssim=0.189760
I0204 20:22:54.932544 139461883066112 logging_writer.py:48] [100] global_step=100, grad_norm=0.46014294028282166, loss=0.4400823712348938
I0204 20:23:19.019690 139466119386880 logging_writer.py:48] [200] global_step=200, grad_norm=0.17156606912612915, loss=0.35069218277931213
I0204 20:23:42.924371 139461883066112 logging_writer.py:48] [300] global_step=300, grad_norm=0.2271040380001068, loss=0.32800668478012085
I0204 20:23:53.284407 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:23:54.652659 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:23:55.969443 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:23:57.289685 139681449744192 submission_runner.py:408] Time since start: 117.12s, 	Step: 344, 	{'train/ssim': 0.6935643468584333, 'train/loss': 0.3145843914576939, 'validation/ssim': 0.6709493402020611, 'validation/loss': 0.33355390025983045, 'validation/num_examples': 3554, 'test/ssim': 0.689466828508971, 'test/loss': 0.3352491202483594, 'test/num_examples': 3581, 'score': 109.12077069282532, 'total_duration': 117.11503720283508, 'accumulated_submission_time': 109.12077069282532, 'accumulated_eval_time': 7.961894273757935, 'accumulated_logging_time': 0.018034934997558594}
I0204 20:23:57.304237 139466119386880 logging_writer.py:48] [344] accumulated_eval_time=7.961894, accumulated_logging_time=0.018035, accumulated_submission_time=109.120771, global_step=344, preemption_count=0, score=109.120771, test/loss=0.335249, test/num_examples=3581, test/ssim=0.689467, total_duration=117.115037, train/loss=0.314584, train/ssim=0.693564, validation/loss=0.333554, validation/num_examples=3554, validation/ssim=0.670949
I0204 20:24:08.831598 139461883066112 logging_writer.py:48] [400] global_step=400, grad_norm=0.19933636486530304, loss=0.3533346652984619
I0204 20:24:32.959710 139466119386880 logging_writer.py:48] [500] global_step=500, grad_norm=0.36611631512641907, loss=0.23368965089321136
I0204 20:24:57.180117 139461883066112 logging_writer.py:48] [600] global_step=600, grad_norm=0.18406082689762115, loss=0.359119176864624
I0204 20:25:17.453361 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:25:18.821924 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:25:20.144456 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:25:21.467859 139681449744192 submission_runner.py:408] Time since start: 201.29s, 	Step: 686, 	{'train/ssim': 0.7199602808271136, 'train/loss': 0.29291772842407227, 'validation/ssim': 0.6985059747819359, 'validation/loss': 0.3106455547996096, 'validation/num_examples': 3554, 'test/ssim': 0.7157858151092572, 'test/loss': 0.3128802553297787, 'test/num_examples': 3581, 'score': 189.2466561794281, 'total_duration': 201.29289603233337, 'accumulated_submission_time': 189.2466561794281, 'accumulated_eval_time': 11.97603702545166, 'accumulated_logging_time': 0.042139530181884766}
I0204 20:25:21.482084 139466119386880 logging_writer.py:48] [686] accumulated_eval_time=11.976037, accumulated_logging_time=0.042140, accumulated_submission_time=189.246656, global_step=686, preemption_count=0, score=189.246656, test/loss=0.312880, test/num_examples=3581, test/ssim=0.715786, total_duration=201.292896, train/loss=0.292918, train/ssim=0.719960, validation/loss=0.310646, validation/num_examples=3554, validation/ssim=0.698506
I0204 20:25:22.830616 139461883066112 logging_writer.py:48] [700] global_step=700, grad_norm=0.7224801182746887, loss=0.32139846682548523
I0204 20:25:47.096489 139466119386880 logging_writer.py:48] [800] global_step=800, grad_norm=0.1846163123846054, loss=0.24806101620197296
I0204 20:26:11.577267 139461883066112 logging_writer.py:48] [900] global_step=900, grad_norm=0.2874668538570404, loss=0.3171146512031555
I0204 20:26:35.848254 139466119386880 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.34763339161872864, loss=0.2606801390647888
I0204 20:26:41.673723 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:26:43.045680 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:26:49.561582 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:26:50.891235 139681449744192 submission_runner.py:408] Time since start: 290.72s, 	Step: 1026, 	{'train/ssim': 0.7229129927498954, 'train/loss': 0.2882750374930246, 'validation/ssim': 0.7015023647430711, 'validation/loss': 0.3057712604305888, 'validation/num_examples': 3554, 'test/ssim': 0.7185578781677604, 'test/loss': 0.30788062212021783, 'test/num_examples': 3581, 'score': 269.41495633125305, 'total_duration': 290.7165720462799, 'accumulated_submission_time': 269.41495633125305, 'accumulated_eval_time': 21.19350576400757, 'accumulated_logging_time': 0.06583929061889648}
I0204 20:26:50.906059 139461883066112 logging_writer.py:48] [1026] accumulated_eval_time=21.193506, accumulated_logging_time=0.065839, accumulated_submission_time=269.414956, global_step=1026, preemption_count=0, score=269.414956, test/loss=0.307881, test/num_examples=3581, test/ssim=0.718558, total_duration=290.716572, train/loss=0.288275, train/ssim=0.722913, validation/loss=0.305771, validation/num_examples=3554, validation/ssim=0.701502
I0204 20:27:06.741780 139466119386880 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.3442797064781189, loss=0.26674899458885193
I0204 20:27:30.431239 139461883066112 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.39583900570869446, loss=0.2555660009384155
I0204 20:27:54.081957 139466119386880 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.27808088064193726, loss=0.3658354878425598
I0204 20:28:10.925908 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:28:12.295671 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:28:13.612251 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:28:14.933517 139681449744192 submission_runner.py:408] Time since start: 374.76s, 	Step: 1372, 	{'train/ssim': 0.7301158223833356, 'train/loss': 0.28062810216631207, 'validation/ssim': 0.7081162812807752, 'validation/loss': 0.298456384146824, 'validation/num_examples': 3554, 'test/ssim': 0.7253081857808573, 'test/loss': 0.3003164896982337, 'test/num_examples': 3581, 'score': 349.4108908176422, 'total_duration': 374.75886607170105, 'accumulated_submission_time': 349.4108908176422, 'accumulated_eval_time': 25.201108932495117, 'accumulated_logging_time': 0.09012818336486816}
I0204 20:28:14.948746 139461883066112 logging_writer.py:48] [1372] accumulated_eval_time=25.201109, accumulated_logging_time=0.090128, accumulated_submission_time=349.410891, global_step=1372, preemption_count=0, score=349.410891, test/loss=0.300316, test/num_examples=3581, test/ssim=0.725308, total_duration=374.758866, train/loss=0.280628, train/ssim=0.730116, validation/loss=0.298456, validation/num_examples=3554, validation/ssim=0.708116
I0204 20:28:19.518983 139466119386880 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.687608540058136, loss=0.27748095989227295
I0204 20:28:43.351549 139461883066112 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.3440367579460144, loss=0.3391522169113159
I0204 20:29:07.123178 139466119386880 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.4491901695728302, loss=0.19533511996269226
I0204 20:29:30.925420 139461883066112 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.3004148304462433, loss=0.3382452428340912
I0204 20:29:35.022651 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:29:36.391004 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:29:37.711148 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:29:39.031445 139681449744192 submission_runner.py:408] Time since start: 458.86s, 	Step: 1718, 	{'train/ssim': 0.7308858462742397, 'train/loss': 0.2795077732631138, 'validation/ssim': 0.7087743068989167, 'validation/loss': 0.29765241684105936, 'validation/num_examples': 3554, 'test/ssim': 0.7260523340416434, 'test/loss': 0.29939467305745604, 'test/num_examples': 3581, 'score': 429.46006417274475, 'total_duration': 458.8567945957184, 'accumulated_submission_time': 429.46006417274475, 'accumulated_eval_time': 29.209868669509888, 'accumulated_logging_time': 0.1150052547454834}
I0204 20:29:39.046395 139466119386880 logging_writer.py:48] [1718] accumulated_eval_time=29.209869, accumulated_logging_time=0.115005, accumulated_submission_time=429.460064, global_step=1718, preemption_count=0, score=429.460064, test/loss=0.299395, test/num_examples=3581, test/ssim=0.726052, total_duration=458.856795, train/loss=0.279508, train/ssim=0.730886, validation/loss=0.297652, validation/num_examples=3554, validation/ssim=0.708774
I0204 20:29:56.511866 139461883066112 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.11609502881765366, loss=0.2787030041217804
I0204 20:30:20.191908 139466119386880 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.11796070635318756, loss=0.21721574664115906
I0204 20:30:44.088269 139461883066112 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.17952066659927368, loss=0.34028419852256775
I0204 20:30:59.066563 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:31:00.437171 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:31:01.814515 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:31:03.132409 139681449744192 submission_runner.py:408] Time since start: 542.96s, 	Step: 2062, 	{'train/ssim': 0.733593395778111, 'train/loss': 0.27726246629442486, 'validation/ssim': 0.7119433264015897, 'validation/loss': 0.2949803341085748, 'validation/num_examples': 3554, 'test/ssim': 0.7291415549296635, 'test/loss': 0.2966512101084718, 'test/num_examples': 3581, 'score': 509.4550085067749, 'total_duration': 542.9577581882477, 'accumulated_submission_time': 509.4550085067749, 'accumulated_eval_time': 33.27567386627197, 'accumulated_logging_time': 0.14037585258483887}
I0204 20:31:03.147734 139466119386880 logging_writer.py:48] [2062] accumulated_eval_time=33.275674, accumulated_logging_time=0.140376, accumulated_submission_time=509.455009, global_step=2062, preemption_count=0, score=509.455009, test/loss=0.296651, test/num_examples=3581, test/ssim=0.729142, total_duration=542.957758, train/loss=0.277262, train/ssim=0.733593, validation/loss=0.294980, validation/num_examples=3554, validation/ssim=0.711943
I0204 20:31:10.157767 139461883066112 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.21787606179714203, loss=0.29328954219818115
I0204 20:31:34.062827 139466119386880 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.20142295956611633, loss=0.28156980872154236
I0204 20:31:57.934184 139461883066112 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.06917795538902283, loss=0.22332550585269928
I0204 20:32:21.760694 139466119386880 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.08221592009067535, loss=0.28752201795578003
I0204 20:32:23.139290 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:32:24.508411 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:32:25.827711 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:32:27.149832 139681449744192 submission_runner.py:408] Time since start: 626.98s, 	Step: 2407, 	{'train/ssim': 0.734459672655378, 'train/loss': 0.2773699590138027, 'validation/ssim': 0.7120967901484243, 'validation/loss': 0.29588926677027644, 'validation/num_examples': 3554, 'test/ssim': 0.7290389490540352, 'test/loss': 0.2977179362433678, 'test/num_examples': 3581, 'score': 589.4221696853638, 'total_duration': 626.9751617908478, 'accumulated_submission_time': 589.4221696853638, 'accumulated_eval_time': 37.286170959472656, 'accumulated_logging_time': 0.1653282642364502}
I0204 20:32:27.166079 139461883066112 logging_writer.py:48] [2407] accumulated_eval_time=37.286171, accumulated_logging_time=0.165328, accumulated_submission_time=589.422170, global_step=2407, preemption_count=0, score=589.422170, test/loss=0.297718, test/num_examples=3581, test/ssim=0.729039, total_duration=626.975162, train/loss=0.277370, train/ssim=0.734460, validation/loss=0.295889, validation/num_examples=3554, validation/ssim=0.712097
I0204 20:32:47.329753 139466119386880 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.21364903450012207, loss=0.2587566077709198
I0204 20:33:11.019258 139461883066112 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1228446289896965, loss=0.2536798417568207
I0204 20:33:34.762547 139466119386880 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.17458507418632507, loss=0.2958203852176666
I0204 20:33:47.262538 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:33:48.631028 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:33:49.949628 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:33:51.271315 139681449744192 submission_runner.py:408] Time since start: 711.10s, 	Step: 2754, 	{'train/ssim': 0.7358302388872419, 'train/loss': 0.2762782233101981, 'validation/ssim': 0.7136425561427265, 'validation/loss': 0.2941995168845843, 'validation/num_examples': 3554, 'test/ssim': 0.730638373533929, 'test/loss': 0.2960094631933294, 'test/num_examples': 3581, 'score': 669.4945640563965, 'total_duration': 711.0966486930847, 'accumulated_submission_time': 669.4945640563965, 'accumulated_eval_time': 41.29489207267761, 'accumulated_logging_time': 0.19099879264831543}
I0204 20:33:51.287026 139461883066112 logging_writer.py:48] [2754] accumulated_eval_time=41.294892, accumulated_logging_time=0.190999, accumulated_submission_time=669.494564, global_step=2754, preemption_count=0, score=669.494564, test/loss=0.296009, test/num_examples=3581, test/ssim=0.730638, total_duration=711.096649, train/loss=0.276278, train/ssim=0.735830, validation/loss=0.294200, validation/num_examples=3554, validation/ssim=0.713643
I0204 20:34:00.206693 139466119386880 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.18008530139923096, loss=0.352863609790802
I0204 20:34:24.051112 139461883066112 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.4102431535720825, loss=0.23024210333824158
I0204 20:34:47.926382 139466119386880 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.09617321193218231, loss=0.2610950171947479
I0204 20:35:11.467413 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:35:12.833155 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:35:14.152381 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:35:15.474022 139681449744192 submission_runner.py:408] Time since start: 795.30s, 	Step: 3099, 	{'train/ssim': 0.7383593831743512, 'train/loss': 0.27408415930611746, 'validation/ssim': 0.7162388687262592, 'validation/loss': 0.2921760829567037, 'validation/num_examples': 3554, 'test/ssim': 0.733525927857093, 'test/loss': 0.2937576562390917, 'test/num_examples': 3581, 'score': 749.650426864624, 'total_duration': 795.2993674278259, 'accumulated_submission_time': 749.650426864624, 'accumulated_eval_time': 45.30148363113403, 'accumulated_logging_time': 0.21605563163757324}
I0204 20:35:15.491308 139461883066112 logging_writer.py:48] [3099] accumulated_eval_time=45.301484, accumulated_logging_time=0.216056, accumulated_submission_time=749.650427, global_step=3099, preemption_count=0, score=749.650427, test/loss=0.293758, test/num_examples=3581, test/ssim=0.733526, total_duration=795.299367, train/loss=0.274084, train/ssim=0.738359, validation/loss=0.292176, validation/num_examples=3554, validation/ssim=0.716239
I0204 20:35:15.654794 139466119386880 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.22051550447940826, loss=0.24024099111557007
I0204 20:35:37.532900 139461883066112 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.10989278554916382, loss=0.2746838331222534
I0204 20:36:01.386414 139466119386880 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.22322683036327362, loss=0.30835437774658203
I0204 20:36:25.195549 139461883066112 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.06980253010988235, loss=0.3774644136428833
I0204 20:36:35.634030 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:36:37.005554 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:36:38.323997 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:36:39.643904 139681449744192 submission_runner.py:408] Time since start: 879.47s, 	Step: 3446, 	{'train/ssim': 0.7405399594988141, 'train/loss': 0.2721844060080392, 'validation/ssim': 0.7177803069604671, 'validation/loss': 0.29077900643421145, 'validation/num_examples': 3554, 'test/ssim': 0.7349211632356535, 'test/loss': 0.2923777265210486, 'test/num_examples': 3581, 'score': 829.7700300216675, 'total_duration': 879.4692540168762, 'accumulated_submission_time': 829.7700300216675, 'accumulated_eval_time': 49.31132197380066, 'accumulated_logging_time': 0.2427656650543213}
I0204 20:36:39.659177 139466119386880 logging_writer.py:48] [3446] accumulated_eval_time=49.311322, accumulated_logging_time=0.242766, accumulated_submission_time=829.770030, global_step=3446, preemption_count=0, score=829.770030, test/loss=0.292378, test/num_examples=3581, test/ssim=0.734921, total_duration=879.469254, train/loss=0.272184, train/ssim=0.740540, validation/loss=0.290779, validation/num_examples=3554, validation/ssim=0.717780
I0204 20:36:50.325620 139461883066112 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.18342338502407074, loss=0.3251316249370575
I0204 20:37:14.140300 139466119386880 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.13692334294319153, loss=0.288606196641922
I0204 20:37:37.626201 139461883066112 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.1325787454843521, loss=0.2272046059370041
I0204 20:37:59.795453 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:38:01.164738 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:38:02.484057 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:38:03.803588 139681449744192 submission_runner.py:408] Time since start: 963.63s, 	Step: 3794, 	{'train/ssim': 0.7399829455784389, 'train/loss': 0.27304991653987337, 'validation/ssim': 0.718139854521314, 'validation/loss': 0.2910478084222883, 'validation/num_examples': 3554, 'test/ssim': 0.7352366848252933, 'test/loss': 0.2926671705376466, 'test/num_examples': 3581, 'score': 909.8821904659271, 'total_duration': 963.6286108493805, 'accumulated_submission_time': 909.8821904659271, 'accumulated_eval_time': 53.319082260131836, 'accumulated_logging_time': 0.2685549259185791}
I0204 20:38:03.819066 139466119386880 logging_writer.py:48] [3794] accumulated_eval_time=53.319082, accumulated_logging_time=0.268555, accumulated_submission_time=909.882190, global_step=3794, preemption_count=0, score=909.882190, test/loss=0.292667, test/num_examples=3581, test/ssim=0.735237, total_duration=963.628611, train/loss=0.273050, train/ssim=0.739983, validation/loss=0.291048, validation/num_examples=3554, validation/ssim=0.718140
I0204 20:38:04.345773 139461883066112 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.10851920396089554, loss=0.25614938139915466
I0204 20:38:27.055430 139466119386880 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.17545945942401886, loss=0.28044450283050537
I0204 20:38:50.936090 139461883066112 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2423342913389206, loss=0.2244168519973755
I0204 20:39:14.796395 139466119386880 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.15373843908309937, loss=0.2935137450695038
I0204 20:39:23.987133 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:39:25.356275 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:39:26.679592 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:39:28.002094 139681449744192 submission_runner.py:408] Time since start: 1047.83s, 	Step: 4139, 	{'train/ssim': 0.740879876273019, 'train/loss': 0.2725841488157, 'validation/ssim': 0.7185715314170653, 'validation/loss': 0.2911185295177969, 'validation/num_examples': 3554, 'test/ssim': 0.7357221708321697, 'test/loss': 0.2926931117573653, 'test/num_examples': 3581, 'score': 990.0270144939423, 'total_duration': 1047.8274364471436, 'accumulated_submission_time': 990.0270144939423, 'accumulated_eval_time': 57.33399033546448, 'accumulated_logging_time': 0.29384326934814453}
I0204 20:39:28.017697 139461883066112 logging_writer.py:48] [4139] accumulated_eval_time=57.333990, accumulated_logging_time=0.293843, accumulated_submission_time=990.027014, global_step=4139, preemption_count=0, score=990.027014, test/loss=0.292693, test/num_examples=3581, test/ssim=0.735722, total_duration=1047.827436, train/loss=0.272584, train/ssim=0.740880, validation/loss=0.291119, validation/num_examples=3554, validation/ssim=0.718572
I0204 20:39:40.801013 139466119386880 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.27899494767189026, loss=0.23751696944236755
I0204 20:40:04.606773 139461883066112 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.18552617728710175, loss=0.3198181986808777
I0204 20:40:28.776812 139466119386880 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.07305534183979034, loss=0.25737106800079346
I0204 20:40:48.129120 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:40:49.502955 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:40:50.820717 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:40:52.141255 139681449744192 submission_runner.py:408] Time since start: 1131.97s, 	Step: 4482, 	{'train/ssim': 0.7423781667436872, 'train/loss': 0.2707956518445696, 'validation/ssim': 0.7193415979354248, 'validation/loss': 0.28956482929665517, 'validation/num_examples': 3554, 'test/ssim': 0.7364936579342363, 'test/loss': 0.29111570833915107, 'test/num_examples': 3581, 'score': 1070.1156814098358, 'total_duration': 1131.9665739536285, 'accumulated_submission_time': 1070.1156814098358, 'accumulated_eval_time': 61.34604811668396, 'accumulated_logging_time': 0.31891942024230957}
I0204 20:40:52.157504 139461883066112 logging_writer.py:48] [4482] accumulated_eval_time=61.346048, accumulated_logging_time=0.318919, accumulated_submission_time=1070.115681, global_step=4482, preemption_count=0, score=1070.115681, test/loss=0.291116, test/num_examples=3581, test/ssim=0.736494, total_duration=1131.966574, train/loss=0.270796, train/ssim=0.742378, validation/loss=0.289565, validation/num_examples=3554, validation/ssim=0.719342
I0204 20:40:54.372359 139466119386880 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.15751861035823822, loss=0.2711159586906433
I0204 20:41:17.994366 139461883066112 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.14451691508293152, loss=0.2347288876771927
I0204 20:41:41.816441 139466119386880 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.10266353189945221, loss=0.2545541226863861
I0204 20:42:05.774968 139461883066112 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.4693029522895813, loss=0.2717570960521698
I0204 20:42:12.381987 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:42:13.754556 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:42:15.074832 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:42:16.398857 139681449744192 submission_runner.py:408] Time since start: 1216.22s, 	Step: 4829, 	{'train/ssim': 0.7408492905752999, 'train/loss': 0.2728027275630406, 'validation/ssim': 0.7187132483865011, 'validation/loss': 0.2910806444433209, 'validation/num_examples': 3554, 'test/ssim': 0.7358825223401284, 'test/loss': 0.2924860592362469, 'test/num_examples': 3581, 'score': 1150.3168470859528, 'total_duration': 1216.2242138385773, 'accumulated_submission_time': 1150.3168470859528, 'accumulated_eval_time': 65.3628830909729, 'accumulated_logging_time': 0.34461069107055664}
I0204 20:42:16.414795 139466119386880 logging_writer.py:48] [4829] accumulated_eval_time=65.362883, accumulated_logging_time=0.344611, accumulated_submission_time=1150.316847, global_step=4829, preemption_count=0, score=1150.316847, test/loss=0.292486, test/num_examples=3581, test/ssim=0.735883, total_duration=1216.224214, train/loss=0.272803, train/ssim=0.740849, validation/loss=0.291081, validation/num_examples=3554, validation/ssim=0.718713
I0204 20:42:31.722677 139461883066112 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.12440844625234604, loss=0.3693731427192688
I0204 20:42:55.780531 139466119386880 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.07128274440765381, loss=0.29687079787254333
I0204 20:43:19.564752 139461883066112 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.1152978390455246, loss=0.2406684160232544
I0204 20:43:36.614522 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:43:37.985679 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:43:39.305724 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:43:40.626040 139681449744192 submission_runner.py:408] Time since start: 1300.45s, 	Step: 5173, 	{'train/ssim': 0.7423981257847377, 'train/loss': 0.27085842405046734, 'validation/ssim': 0.719932715008617, 'validation/loss': 0.2893769839001829, 'validation/num_examples': 3554, 'test/ssim': 0.7370365486901355, 'test/loss': 0.29088963452946104, 'test/num_examples': 3581, 'score': 1230.4913923740387, 'total_duration': 1300.4513957500458, 'accumulated_submission_time': 1230.4913923740387, 'accumulated_eval_time': 69.37438464164734, 'accumulated_logging_time': 0.3716864585876465}
I0204 20:43:40.642766 139466119386880 logging_writer.py:48] [5173] accumulated_eval_time=69.374385, accumulated_logging_time=0.371686, accumulated_submission_time=1230.491392, global_step=5173, preemption_count=0, score=1230.491392, test/loss=0.290890, test/num_examples=3581, test/ssim=0.737037, total_duration=1300.451396, train/loss=0.270858, train/ssim=0.742398, validation/loss=0.289377, validation/num_examples=3554, validation/ssim=0.719933
I0204 20:43:44.964294 139461883066112 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.12751108407974243, loss=0.31272444128990173
I0204 20:44:09.379100 139466119386880 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.13179519772529602, loss=0.19875746965408325
I0204 20:44:33.212005 139461883066112 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.2449198067188263, loss=0.23892083764076233
I0204 20:44:57.244613 139466119386880 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.18162548542022705, loss=0.27161291241645813
I0204 20:45:00.718657 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:45:02.090744 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:45:03.410218 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:45:04.730461 139681449744192 submission_runner.py:408] Time since start: 1384.56s, 	Step: 5516, 	{'train/ssim': 0.7416613442557198, 'train/loss': 0.2711343594959804, 'validation/ssim': 0.7192231684369724, 'validation/loss': 0.28979876877286154, 'validation/num_examples': 3554, 'test/ssim': 0.736393915478393, 'test/loss': 0.29126501522793913, 'test/num_examples': 3581, 'score': 1310.5437569618225, 'total_duration': 1384.5558178424835, 'accumulated_submission_time': 1310.5437569618225, 'accumulated_eval_time': 73.38616728782654, 'accumulated_logging_time': 0.3977348804473877}
I0204 20:45:04.746791 139461883066112 logging_writer.py:48] [5516] accumulated_eval_time=73.386167, accumulated_logging_time=0.397735, accumulated_submission_time=1310.543757, global_step=5516, preemption_count=0, score=1310.543757, test/loss=0.291265, test/num_examples=3581, test/ssim=0.736394, total_duration=1384.555818, train/loss=0.271134, train/ssim=0.741661, validation/loss=0.289799, validation/num_examples=3554, validation/ssim=0.719223
I0204 20:45:22.655858 139466119386880 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.21089117228984833, loss=0.22452899813652039
I0204 20:45:46.342781 139461883066112 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.15577714145183563, loss=0.29133176803588867
I0204 20:46:10.538701 139466119386880 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.21688991785049438, loss=0.4497717618942261
I0204 20:46:24.942150 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:46:26.311363 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:46:27.630494 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:46:28.948342 139681449744192 submission_runner.py:408] Time since start: 1468.77s, 	Step: 5862, 	{'train/ssim': 0.742295469556536, 'train/loss': 0.2712622029440744, 'validation/ssim': 0.7193490169527293, 'validation/loss': 0.290077462784011, 'validation/num_examples': 3554, 'test/ssim': 0.736499725657114, 'test/loss': 0.29165345175710344, 'test/num_examples': 3581, 'score': 1390.7154486179352, 'total_duration': 1468.7736823558807, 'accumulated_submission_time': 1390.7154486179352, 'accumulated_eval_time': 77.39232563972473, 'accumulated_logging_time': 0.42411279678344727}
I0204 20:46:28.965766 139461883066112 logging_writer.py:48] [5862] accumulated_eval_time=77.392326, accumulated_logging_time=0.424113, accumulated_submission_time=1390.715449, global_step=5862, preemption_count=0, score=1390.715449, test/loss=0.291653, test/num_examples=3581, test/ssim=0.736500, total_duration=1468.773682, train/loss=0.271262, train/ssim=0.742295, validation/loss=0.290077, validation/num_examples=3554, validation/ssim=0.719349
I0204 20:46:35.910101 139466119386880 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.043249256908893585, loss=0.280621200799942
I0204 20:46:59.648518 139461883066112 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.14165349304676056, loss=0.23608632385730743
I0204 20:47:23.770505 139466119386880 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.18822221457958221, loss=0.33605536818504333
I0204 20:47:47.590004 139461883066112 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.11453405767679214, loss=0.2325272411108017
I0204 20:47:49.176106 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:47:50.546647 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:47:51.867764 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:47:53.189226 139681449744192 submission_runner.py:408] Time since start: 1553.01s, 	Step: 6208, 	{'train/ssim': 0.7428860664367676, 'train/loss': 0.2708876473563058, 'validation/ssim': 0.7201298685240223, 'validation/loss': 0.28948631136351644, 'validation/num_examples': 3554, 'test/ssim': 0.737248850814193, 'test/loss': 0.29103433949359464, 'test/num_examples': 3581, 'score': 1470.9021430015564, 'total_duration': 1553.0145823955536, 'accumulated_submission_time': 1470.9021430015564, 'accumulated_eval_time': 81.4054057598114, 'accumulated_logging_time': 0.45113205909729004}
I0204 20:47:53.205680 139466119386880 logging_writer.py:48] [6208] accumulated_eval_time=81.405406, accumulated_logging_time=0.451132, accumulated_submission_time=1470.902143, global_step=6208, preemption_count=0, score=1470.902143, test/loss=0.291034, test/num_examples=3581, test/ssim=0.737249, total_duration=1553.014582, train/loss=0.270888, train/ssim=0.742886, validation/loss=0.289486, validation/num_examples=3554, validation/ssim=0.720130
I0204 20:48:13.042384 139461883066112 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.17421220242977142, loss=0.28286212682724
I0204 20:48:37.355815 139466119386880 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.1507084220647812, loss=0.2873622477054596
I0204 20:49:01.529352 139461883066112 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.08116244524717331, loss=0.24953655898571014
I0204 20:49:13.399389 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:49:14.771852 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:49:16.093937 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:49:17.413629 139681449744192 submission_runner.py:408] Time since start: 1637.24s, 	Step: 6552, 	{'train/ssim': 0.7417918613978794, 'train/loss': 0.27284441675458637, 'validation/ssim': 0.7196870631023143, 'validation/loss': 0.29140965725239165, 'validation/num_examples': 3554, 'test/ssim': 0.7366234662978218, 'test/loss': 0.2930313361753002, 'test/num_examples': 3581, 'score': 1551.0724306106567, 'total_duration': 1637.238983631134, 'accumulated_submission_time': 1551.0724306106567, 'accumulated_eval_time': 85.41960525512695, 'accumulated_logging_time': 0.4771711826324463}
I0204 20:49:17.429887 139466119386880 logging_writer.py:48] [6552] accumulated_eval_time=85.419605, accumulated_logging_time=0.477171, accumulated_submission_time=1551.072431, global_step=6552, preemption_count=0, score=1551.072431, test/loss=0.293031, test/num_examples=3581, test/ssim=0.736623, total_duration=1637.238984, train/loss=0.272844, train/ssim=0.741792, validation/loss=0.291410, validation/num_examples=3554, validation/ssim=0.719687
I0204 20:49:26.850264 139461883066112 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.05655418708920479, loss=0.3107560873031616
I0204 20:49:50.735953 139466119386880 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.11578720808029175, loss=0.2604480981826782
I0204 20:50:14.393467 139461883066112 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.1450570672750473, loss=0.27748069167137146
I0204 20:50:37.704127 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:50:39.075330 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:50:40.396355 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:50:41.714903 139681449744192 submission_runner.py:408] Time since start: 1721.54s, 	Step: 6899, 	{'train/ssim': 0.7451910972595215, 'train/loss': 0.2698579856327602, 'validation/ssim': 0.7226475944798115, 'validation/loss': 0.288501505510956, 'validation/num_examples': 3554, 'test/ssim': 0.7397011653300405, 'test/loss': 0.2900458460778239, 'test/num_examples': 3581, 'score': 1631.3222754001617, 'total_duration': 1721.5402591228485, 'accumulated_submission_time': 1631.3222754001617, 'accumulated_eval_time': 89.430344581604, 'accumulated_logging_time': 0.5038919448852539}
I0204 20:50:41.731591 139466119386880 logging_writer.py:48] [6899] accumulated_eval_time=89.430345, accumulated_logging_time=0.503892, accumulated_submission_time=1631.322275, global_step=6899, preemption_count=0, score=1631.322275, test/loss=0.290046, test/num_examples=3581, test/ssim=0.739701, total_duration=1721.540259, train/loss=0.269858, train/ssim=0.745191, validation/loss=0.288502, validation/num_examples=3554, validation/ssim=0.722648
I0204 20:50:41.896243 139461883066112 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.05499110743403435, loss=0.31357529759407043
I0204 20:51:03.659841 139466119386880 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.11346550285816193, loss=0.22688186168670654
I0204 20:51:27.548076 139461883066112 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.08218370378017426, loss=0.24123568832874298
I0204 20:51:51.331297 139466119386880 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.1170177087187767, loss=0.23626035451889038
I0204 20:52:01.758036 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:52:03.129503 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:52:04.448702 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:52:05.768943 139681449744192 submission_runner.py:408] Time since start: 1805.59s, 	Step: 7245, 	{'train/ssim': 0.7445575850350517, 'train/loss': 0.26946187019348145, 'validation/ssim': 0.7216776953564645, 'validation/loss': 0.2881723553126759, 'validation/num_examples': 3554, 'test/ssim': 0.7388482752940868, 'test/loss': 0.2896346044553721, 'test/num_examples': 3581, 'score': 1711.325751543045, 'total_duration': 1805.5942947864532, 'accumulated_submission_time': 1711.325751543045, 'accumulated_eval_time': 93.44122433662415, 'accumulated_logging_time': 0.5299606323242188}
I0204 20:52:05.785819 139461883066112 logging_writer.py:48] [7245] accumulated_eval_time=93.441224, accumulated_logging_time=0.529961, accumulated_submission_time=1711.325752, global_step=7245, preemption_count=0, score=1711.325752, test/loss=0.289635, test/num_examples=3581, test/ssim=0.738848, total_duration=1805.594295, train/loss=0.269462, train/ssim=0.744558, validation/loss=0.288172, validation/num_examples=3554, validation/ssim=0.721678
I0204 20:52:16.638950 139466119386880 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.10653820633888245, loss=0.24694645404815674
I0204 20:52:40.622224 139461883066112 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.09472008049488068, loss=0.25756630301475525
I0204 20:53:05.001102 139466119386880 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.1467249095439911, loss=0.1906358152627945
I0204 20:53:25.973685 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:53:27.344274 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:53:28.663751 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:53:29.983607 139681449744192 submission_runner.py:408] Time since start: 1889.81s, 	Step: 7589, 	{'train/ssim': 0.7447182791573661, 'train/loss': 0.2695349454879761, 'validation/ssim': 0.7220469288565701, 'validation/loss': 0.28818197255732975, 'validation/num_examples': 3554, 'test/ssim': 0.7392248831724728, 'test/loss': 0.2897060195083426, 'test/num_examples': 3581, 'score': 1791.4902153015137, 'total_duration': 1889.8089570999146, 'accumulated_submission_time': 1791.4902153015137, 'accumulated_eval_time': 97.45112013816833, 'accumulated_logging_time': 0.5566811561584473}
I0204 20:53:30.001357 139461883066112 logging_writer.py:48] [7589] accumulated_eval_time=97.451120, accumulated_logging_time=0.556681, accumulated_submission_time=1791.490215, global_step=7589, preemption_count=0, score=1791.490215, test/loss=0.289706, test/num_examples=3581, test/ssim=0.739225, total_duration=1889.808957, train/loss=0.269535, train/ssim=0.744718, validation/loss=0.288182, validation/num_examples=3554, validation/ssim=0.722047
I0204 20:53:30.887138 139466119386880 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.2574186325073242, loss=0.2539377510547638
I0204 20:53:54.299892 139461883066112 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.21740616858005524, loss=0.24355262517929077
I0204 20:54:18.047886 139466119386880 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.04738099128007889, loss=0.3509190082550049
I0204 20:54:41.848551 139461883066112 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.06685607880353928, loss=0.29012739658355713
I0204 20:54:50.048000 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:54:51.418045 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:54:52.737496 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:54:54.059916 139681449744192 submission_runner.py:408] Time since start: 1973.89s, 	Step: 7935, 	{'train/ssim': 0.7456581251961845, 'train/loss': 0.26898149081638884, 'validation/ssim': 0.722861578173361, 'validation/loss': 0.28791280992257845, 'validation/num_examples': 3554, 'test/ssim': 0.7399333750392697, 'test/loss': 0.28943982373333216, 'test/num_examples': 3581, 'score': 1871.5134434700012, 'total_duration': 1973.8852660655975, 'accumulated_submission_time': 1871.5134434700012, 'accumulated_eval_time': 101.46298694610596, 'accumulated_logging_time': 0.5842244625091553}
I0204 20:54:54.077315 139466119386880 logging_writer.py:48] [7935] accumulated_eval_time=101.462987, accumulated_logging_time=0.584224, accumulated_submission_time=1871.513443, global_step=7935, preemption_count=0, score=1871.513443, test/loss=0.289440, test/num_examples=3581, test/ssim=0.739933, total_duration=1973.885266, train/loss=0.268981, train/ssim=0.745658, validation/loss=0.287913, validation/num_examples=3554, validation/ssim=0.722862
I0204 20:55:07.524409 139461883066112 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.22155317664146423, loss=0.27088940143585205
I0204 20:55:31.242065 139466119386880 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.08521787077188492, loss=0.25833192467689514
I0204 20:55:54.964632 139461883066112 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.03721337765455246, loss=0.3223063349723816
I0204 20:56:14.277559 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:56:15.649789 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:56:16.970396 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:56:18.292125 139681449744192 submission_runner.py:408] Time since start: 2058.12s, 	Step: 8282, 	{'train/ssim': 0.7454793793814523, 'train/loss': 0.2688144786017282, 'validation/ssim': 0.7226394885164603, 'validation/loss': 0.2876635858968328, 'validation/num_examples': 3554, 'test/ssim': 0.7398233379075329, 'test/loss': 0.2890387063451201, 'test/num_examples': 3581, 'score': 1951.6899888515472, 'total_duration': 2058.11745595932, 'accumulated_submission_time': 1951.6899888515472, 'accumulated_eval_time': 105.47749543190002, 'accumulated_logging_time': 0.6115193367004395}
I0204 20:56:18.308528 139466119386880 logging_writer.py:48] [8282] accumulated_eval_time=105.477495, accumulated_logging_time=0.611519, accumulated_submission_time=1951.689989, global_step=8282, preemption_count=0, score=1951.689989, test/loss=0.289039, test/num_examples=3581, test/ssim=0.739823, total_duration=2058.117456, train/loss=0.268814, train/ssim=0.745479, validation/loss=0.287664, validation/num_examples=3554, validation/ssim=0.722639
I0204 20:56:20.508403 139461883066112 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.09795704483985901, loss=0.2954944670200348
I0204 20:56:44.289149 139466119386880 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.19417867064476013, loss=0.23366102576255798
I0204 20:57:08.601891 139461883066112 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.041566308587789536, loss=0.27611321210861206
I0204 20:57:32.659991 139466119386880 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.13735707104206085, loss=0.19570472836494446
I0204 20:57:38.446960 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:57:39.818870 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:57:41.141937 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:57:42.464660 139681449744192 submission_runner.py:408] Time since start: 2142.29s, 	Step: 8625, 	{'train/ssim': 0.7453502927507673, 'train/loss': 0.26966796602521625, 'validation/ssim': 0.7224195283923045, 'validation/loss': 0.2886448368036016, 'validation/num_examples': 3554, 'test/ssim': 0.7396019682874895, 'test/loss': 0.2900541977188634, 'test/num_examples': 3581, 'score': 2031.8050429821014, 'total_duration': 2142.290014743805, 'accumulated_submission_time': 2031.8050429821014, 'accumulated_eval_time': 109.49516701698303, 'accumulated_logging_time': 0.6374204158782959}
I0204 20:57:42.482718 139461883066112 logging_writer.py:48] [8625] accumulated_eval_time=109.495167, accumulated_logging_time=0.637420, accumulated_submission_time=2031.805043, global_step=8625, preemption_count=0, score=2031.805043, test/loss=0.290054, test/num_examples=3581, test/ssim=0.739602, total_duration=2142.290015, train/loss=0.269668, train/ssim=0.745350, validation/loss=0.288645, validation/num_examples=3554, validation/ssim=0.722420
I0204 20:57:58.367600 139466119386880 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.11896520853042603, loss=0.2674127519130707
I0204 20:58:22.491646 139461883066112 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.06175624951720238, loss=0.2597859799861908
I0204 20:58:46.009456 139466119386880 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.13679131865501404, loss=0.29243454337120056
I0204 20:59:02.529990 139681449744192 spec.py:321] Evaluating on the training split.
I0204 20:59:03.900838 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 20:59:05.220875 139681449744192 spec.py:349] Evaluating on the test split.
I0204 20:59:06.539983 139681449744192 submission_runner.py:408] Time since start: 2226.37s, 	Step: 8971, 	{'train/ssim': 0.7453242710658482, 'train/loss': 0.26875131470816477, 'validation/ssim': 0.7227986539154826, 'validation/loss': 0.28777392660558526, 'validation/num_examples': 3554, 'test/ssim': 0.7398632894311994, 'test/loss': 0.28923692998856815, 'test/num_examples': 3581, 'score': 2111.8292939662933, 'total_duration': 2226.365335702896, 'accumulated_submission_time': 2111.8292939662933, 'accumulated_eval_time': 113.50512456893921, 'accumulated_logging_time': 0.6649777889251709}
I0204 20:59:06.557956 139461883066112 logging_writer.py:48] [8971] accumulated_eval_time=113.505125, accumulated_logging_time=0.664978, accumulated_submission_time=2111.829294, global_step=8971, preemption_count=0, score=2111.829294, test/loss=0.289237, test/num_examples=3581, test/ssim=0.739863, total_duration=2226.365336, train/loss=0.268751, train/ssim=0.745324, validation/loss=0.287774, validation/num_examples=3554, validation/ssim=0.722799
I0204 20:59:11.419677 139466119386880 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.10074562579393387, loss=0.3318389356136322
I0204 20:59:35.188708 139461883066112 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.13594219088554382, loss=0.2839507460594177
I0204 20:59:59.068404 139466119386880 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.4791087210178375, loss=0.24226444959640503
I0204 21:00:23.022535 139461883066112 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.033404942601919174, loss=0.4276595115661621
I0204 21:00:26.662597 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:00:28.033063 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:00:29.351350 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:00:30.670280 139681449744192 submission_runner.py:408] Time since start: 2310.50s, 	Step: 9316, 	{'train/ssim': 0.7449782235281808, 'train/loss': 0.270092248916626, 'validation/ssim': 0.7226653863824212, 'validation/loss': 0.2887455774413513, 'validation/num_examples': 3554, 'test/ssim': 0.7397393442605068, 'test/loss': 0.2901880625938111, 'test/num_examples': 3581, 'score': 2191.909622192383, 'total_duration': 2310.495637178421, 'accumulated_submission_time': 2191.909622192383, 'accumulated_eval_time': 117.51276755332947, 'accumulated_logging_time': 0.6933310031890869}
I0204 21:00:30.687764 139466119386880 logging_writer.py:48] [9316] accumulated_eval_time=117.512768, accumulated_logging_time=0.693331, accumulated_submission_time=2191.909622, global_step=9316, preemption_count=0, score=2191.909622, test/loss=0.290188, test/num_examples=3581, test/ssim=0.739739, total_duration=2310.495637, train/loss=0.270092, train/ssim=0.744978, validation/loss=0.288746, validation/num_examples=3554, validation/ssim=0.722665
I0204 21:00:48.793781 139461883066112 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.1275215595960617, loss=0.23524323105812073
I0204 21:01:12.720655 139466119386880 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.047337856143713, loss=0.2693372368812561
I0204 21:01:36.647554 139461883066112 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.14274021983146667, loss=0.3242109715938568
I0204 21:01:50.718256 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:01:52.087096 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:01:53.407113 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:01:54.731974 139681449744192 submission_runner.py:408] Time since start: 2394.56s, 	Step: 9658, 	{'train/ssim': 0.7451615333557129, 'train/loss': 0.2685591323035104, 'validation/ssim': 0.7224965350441404, 'validation/loss': 0.2872988003723797, 'validation/num_examples': 3554, 'test/ssim': 0.7397383216105836, 'test/loss': 0.2886718136410046, 'test/num_examples': 3581, 'score': 2271.9167654514313, 'total_duration': 2394.5573313236237, 'accumulated_submission_time': 2271.9167654514313, 'accumulated_eval_time': 121.52645993232727, 'accumulated_logging_time': 0.7202789783477783}
I0204 21:01:54.749555 139466119386880 logging_writer.py:48] [9658] accumulated_eval_time=121.526460, accumulated_logging_time=0.720279, accumulated_submission_time=2271.916765, global_step=9658, preemption_count=0, score=2271.916765, test/loss=0.288672, test/num_examples=3581, test/ssim=0.739738, total_duration=2394.557331, train/loss=0.268559, train/ssim=0.745162, validation/loss=0.287299, validation/num_examples=3554, validation/ssim=0.722497
I0204 21:02:02.652769 139461883066112 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.10844270139932632, loss=0.3239373564720154
I0204 21:02:26.696664 139466119386880 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.12744806706905365, loss=0.2310190200805664
I0204 21:02:50.408916 139461883066112 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.0835677906870842, loss=0.24962273240089417
I0204 21:03:14.345452 139466119386880 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.0808161050081253, loss=0.30968406796455383
I0204 21:03:14.793875 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:03:16.166307 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:03:17.486717 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:03:18.810136 139681449744192 submission_runner.py:408] Time since start: 2478.64s, 	Step: 10003, 	{'train/ssim': 0.7457009043012347, 'train/loss': 0.2682241712297712, 'validation/ssim': 0.7223576345534961, 'validation/loss': 0.28739097135819675, 'validation/num_examples': 3554, 'test/ssim': 0.7395914690816113, 'test/loss': 0.2888142346869764, 'test/num_examples': 3581, 'score': 2351.937286376953, 'total_duration': 2478.6354858875275, 'accumulated_submission_time': 2351.937286376953, 'accumulated_eval_time': 125.54268622398376, 'accumulated_logging_time': 0.7473556995391846}
I0204 21:03:18.828568 139461883066112 logging_writer.py:48] [10003] accumulated_eval_time=125.542686, accumulated_logging_time=0.747356, accumulated_submission_time=2351.937286, global_step=10003, preemption_count=0, score=2351.937286, test/loss=0.288814, test/num_examples=3581, test/ssim=0.739591, total_duration=2478.635486, train/loss=0.268224, train/ssim=0.745701, validation/loss=0.287391, validation/num_examples=3554, validation/ssim=0.722358
I0204 21:03:39.924060 139466119386880 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.09351662546396255, loss=0.25353458523750305
I0204 21:04:03.797028 139461883066112 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.05948784202337265, loss=0.3663766384124756
I0204 21:04:27.620425 139466119386880 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.09706197679042816, loss=0.24246445298194885
I0204 21:04:38.830815 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:04:40.201340 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:04:41.523897 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:04:42.845060 139681449744192 submission_runner.py:408] Time since start: 2562.67s, 	Step: 10348, 	{'train/ssim': 0.7455603054591587, 'train/loss': 0.268939733505249, 'validation/ssim': 0.7225909901255627, 'validation/loss': 0.2879494069732168, 'validation/num_examples': 3554, 'test/ssim': 0.7397801820807736, 'test/loss': 0.289362784105784, 'test/num_examples': 3581, 'score': 2431.914649963379, 'total_duration': 2562.67041516304, 'accumulated_submission_time': 2431.914649963379, 'accumulated_eval_time': 129.55689525604248, 'accumulated_logging_time': 0.7765707969665527}
I0204 21:04:42.862437 139461883066112 logging_writer.py:48] [10348] accumulated_eval_time=129.556895, accumulated_logging_time=0.776571, accumulated_submission_time=2431.914650, global_step=10348, preemption_count=0, score=2431.914650, test/loss=0.289363, test/num_examples=3581, test/ssim=0.739780, total_duration=2562.670415, train/loss=0.268940, train/ssim=0.745560, validation/loss=0.287949, validation/num_examples=3554, validation/ssim=0.722591
I0204 21:04:53.348380 139466119386880 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.18505480885505676, loss=0.293504536151886
I0204 21:05:17.197892 139461883066112 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.1088266521692276, loss=0.33424562215805054
I0204 21:05:40.954377 139466119386880 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.05089212954044342, loss=0.294058620929718
I0204 21:06:02.869122 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:06:04.239014 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:06:05.560290 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:06:06.879437 139681449744192 submission_runner.py:408] Time since start: 2646.70s, 	Step: 10692, 	{'train/ssim': 0.7455687522888184, 'train/loss': 0.26831391879490446, 'validation/ssim': 0.722452364413337, 'validation/loss': 0.2873520215173484, 'validation/num_examples': 3554, 'test/ssim': 0.7395841060021642, 'test/loss': 0.2888140642453225, 'test/num_examples': 3581, 'score': 2511.8980689048767, 'total_duration': 2646.7047917842865, 'accumulated_submission_time': 2511.8980689048767, 'accumulated_eval_time': 133.56716871261597, 'accumulated_logging_time': 0.8033936023712158}
I0204 21:06:06.896991 139461883066112 logging_writer.py:48] [10692] accumulated_eval_time=133.567169, accumulated_logging_time=0.803394, accumulated_submission_time=2511.898069, global_step=10692, preemption_count=0, score=2511.898069, test/loss=0.288814, test/num_examples=3581, test/ssim=0.739584, total_duration=2646.704792, train/loss=0.268314, train/ssim=0.745569, validation/loss=0.287352, validation/num_examples=3554, validation/ssim=0.722452
I0204 21:06:07.564074 139466119386880 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.12701819837093353, loss=0.22932283580303192
I0204 21:06:30.649499 139461883066112 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.0898960530757904, loss=0.32469943165779114
I0204 21:06:54.453542 139466119386880 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.08566542714834213, loss=0.26010948419570923
I0204 21:07:18.460288 139461883066112 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.04503742977976799, loss=0.2659343481063843
I0204 21:07:27.073062 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:07:28.442766 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:07:29.761921 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:07:31.082002 139681449744192 submission_runner.py:408] Time since start: 2730.91s, 	Step: 11038, 	{'train/ssim': 0.7464522634233747, 'train/loss': 0.2678736788885934, 'validation/ssim': 0.7229895562218627, 'validation/loss': 0.2872696051653946, 'validation/num_examples': 3554, 'test/ssim': 0.7401103616526459, 'test/loss': 0.288732559046443, 'test/num_examples': 3581, 'score': 2592.050028562546, 'total_duration': 2730.907357931137, 'accumulated_submission_time': 2592.050028562546, 'accumulated_eval_time': 137.57607746124268, 'accumulated_logging_time': 0.8305361270904541}
I0204 21:07:31.099550 139466119386880 logging_writer.py:48] [11038] accumulated_eval_time=137.576077, accumulated_logging_time=0.830536, accumulated_submission_time=2592.050029, global_step=11038, preemption_count=0, score=2592.050029, test/loss=0.288733, test/num_examples=3581, test/ssim=0.740110, total_duration=2730.907358, train/loss=0.267874, train/ssim=0.746452, validation/loss=0.287270, validation/num_examples=3554, validation/ssim=0.722990
I0204 21:07:43.791295 139461883066112 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.04403161257505417, loss=0.286249577999115
I0204 21:08:07.694960 139466119386880 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.08881977200508118, loss=0.2759827971458435
I0204 21:08:31.439550 139461883066112 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.1125166267156601, loss=0.33326616883277893
I0204 21:08:51.102456 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:08:52.473071 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:08:53.792214 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:08:55.112596 139681449744192 submission_runner.py:408] Time since start: 2814.94s, 	Step: 11384, 	{'train/ssim': 0.7461264474051339, 'train/loss': 0.26816918168749126, 'validation/ssim': 0.7231992121553179, 'validation/loss': 0.2872296249054762, 'validation/num_examples': 3554, 'test/ssim': 0.7403277088496579, 'test/loss': 0.28871657161931025, 'test/num_examples': 3581, 'score': 2672.0285749435425, 'total_duration': 2814.937951564789, 'accumulated_submission_time': 2672.0285749435425, 'accumulated_eval_time': 141.58618927001953, 'accumulated_logging_time': 0.8576686382293701}
I0204 21:08:55.130580 139466119386880 logging_writer.py:48] [11384] accumulated_eval_time=141.586189, accumulated_logging_time=0.857669, accumulated_submission_time=2672.028575, global_step=11384, preemption_count=0, score=2672.028575, test/loss=0.288717, test/num_examples=3581, test/ssim=0.740328, total_duration=2814.937952, train/loss=0.268169, train/ssim=0.746126, validation/loss=0.287230, validation/num_examples=3554, validation/ssim=0.723199
I0204 21:08:56.974780 139461883066112 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.06972094625234604, loss=0.3048707842826843
I0204 21:09:20.760417 139466119386880 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.04778219386935234, loss=0.2635054588317871
I0204 21:09:44.518663 139461883066112 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.12262272834777832, loss=0.23557493090629578
I0204 21:10:08.417080 139466119386880 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.05894390493631363, loss=0.29625484347343445
I0204 21:10:15.224832 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:10:16.596545 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:10:17.917397 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:10:19.241440 139681449744192 submission_runner.py:408] Time since start: 2899.07s, 	Step: 11730, 	{'train/ssim': 0.7456574440002441, 'train/loss': 0.26810736315590994, 'validation/ssim': 0.7232962776317178, 'validation/loss': 0.2868558060405089, 'validation/num_examples': 3554, 'test/ssim': 0.7403952719212511, 'test/loss': 0.28822897213592574, 'test/num_examples': 3581, 'score': 2752.0991699695587, 'total_duration': 2899.0667912960052, 'accumulated_submission_time': 2752.0991699695587, 'accumulated_eval_time': 145.6027750968933, 'accumulated_logging_time': 0.8846747875213623}
I0204 21:10:19.259054 139461883066112 logging_writer.py:48] [11730] accumulated_eval_time=145.602775, accumulated_logging_time=0.884675, accumulated_submission_time=2752.099170, global_step=11730, preemption_count=0, score=2752.099170, test/loss=0.288229, test/num_examples=3581, test/ssim=0.740395, total_duration=2899.066791, train/loss=0.268107, train/ssim=0.745657, validation/loss=0.286856, validation/num_examples=3554, validation/ssim=0.723296
I0204 21:10:34.351696 139466119386880 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.10740276426076889, loss=0.3139728605747223
I0204 21:10:58.322933 139461883066112 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.16497011482715607, loss=0.27508771419525146
I0204 21:11:22.319719 139466119386880 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.06731987744569778, loss=0.25427308678627014
I0204 21:11:39.357794 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:11:40.728690 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:11:42.046861 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:11:43.368242 139681449744192 submission_runner.py:408] Time since start: 2983.19s, 	Step: 12073, 	{'train/ssim': 0.7469180652073452, 'train/loss': 0.2673248733792986, 'validation/ssim': 0.7235540197884426, 'validation/loss': 0.28662962905463035, 'validation/num_examples': 3554, 'test/ssim': 0.7406891815091804, 'test/loss': 0.288034907268832, 'test/num_examples': 3581, 'score': 2832.1749567985535, 'total_duration': 2983.193598508835, 'accumulated_submission_time': 2832.1749567985535, 'accumulated_eval_time': 149.6131820678711, 'accumulated_logging_time': 0.9115986824035645}
I0204 21:11:43.386076 139461883066112 logging_writer.py:48] [12073] accumulated_eval_time=149.613182, accumulated_logging_time=0.911599, accumulated_submission_time=2832.174957, global_step=12073, preemption_count=0, score=2832.174957, test/loss=0.288035, test/num_examples=3581, test/ssim=0.740689, total_duration=2983.193599, train/loss=0.267325, train/ssim=0.746918, validation/loss=0.286630, validation/num_examples=3554, validation/ssim=0.723554
I0204 21:11:47.717395 139466119386880 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.14753933250904083, loss=0.2932647466659546
I0204 21:12:11.740638 139461883066112 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.05757209286093712, loss=0.2583077549934387
I0204 21:12:35.737686 139466119386880 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.1377447098493576, loss=0.2907012403011322
I0204 21:12:59.442825 139461883066112 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.12096551805734634, loss=0.2582341730594635
I0204 21:13:03.510613 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:13:04.883215 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:13:06.204420 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:13:07.527211 139681449744192 submission_runner.py:408] Time since start: 3067.35s, 	Step: 12418, 	{'train/ssim': 0.746204035622733, 'train/loss': 0.2677193880081177, 'validation/ssim': 0.7232028529693655, 'validation/loss': 0.28671171910721194, 'validation/num_examples': 3554, 'test/ssim': 0.7404398594579028, 'test/loss': 0.2881162420260577, 'test/num_examples': 3581, 'score': 2912.2765226364136, 'total_duration': 3067.3525626659393, 'accumulated_submission_time': 2912.2765226364136, 'accumulated_eval_time': 153.62973427772522, 'accumulated_logging_time': 0.938593864440918}
I0204 21:13:07.545516 139466119386880 logging_writer.py:48] [12418] accumulated_eval_time=153.629734, accumulated_logging_time=0.938594, accumulated_submission_time=2912.276523, global_step=12418, preemption_count=0, score=2912.276523, test/loss=0.288116, test/num_examples=3581, test/ssim=0.740440, total_duration=3067.352563, train/loss=0.267719, train/ssim=0.746204, validation/loss=0.286712, validation/num_examples=3554, validation/ssim=0.723203
I0204 21:13:25.205769 139461883066112 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.09351083636283875, loss=0.29894718527793884
I0204 21:13:48.911075 139466119386880 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.09660735726356506, loss=0.30144333839416504
I0204 21:14:12.676795 139461883066112 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.17530855536460876, loss=0.2721560597419739
I0204 21:14:27.571624 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:14:28.942818 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:14:30.262470 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:14:31.583268 139681449744192 submission_runner.py:408] Time since start: 3151.41s, 	Step: 12764, 	{'train/ssim': 0.7461694989885602, 'train/loss': 0.2676114354814802, 'validation/ssim': 0.7230209496561972, 'validation/loss': 0.2867143466758406, 'validation/num_examples': 3554, 'test/ssim': 0.7402508055754329, 'test/loss': 0.28807523376413713, 'test/num_examples': 3581, 'score': 2992.2794008255005, 'total_duration': 3151.4086179733276, 'accumulated_submission_time': 2992.2794008255005, 'accumulated_eval_time': 157.64133405685425, 'accumulated_logging_time': 0.9663434028625488}
I0204 21:14:31.602238 139466119386880 logging_writer.py:48] [12764] accumulated_eval_time=157.641334, accumulated_logging_time=0.966343, accumulated_submission_time=2992.279401, global_step=12764, preemption_count=0, score=2992.279401, test/loss=0.288075, test/num_examples=3581, test/ssim=0.740251, total_duration=3151.408618, train/loss=0.267611, train/ssim=0.746169, validation/loss=0.286714, validation/num_examples=3554, validation/ssim=0.723021
I0204 21:14:38.173195 139461883066112 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.1788962334394455, loss=0.2545314431190491
I0204 21:15:02.658605 139466119386880 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.11485571414232254, loss=0.20899611711502075
I0204 21:15:26.209425 139461883066112 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.08495331555604935, loss=0.30120334029197693
I0204 21:15:50.180069 139466119386880 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.08455686271190643, loss=0.254657506942749
I0204 21:15:51.776662 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:15:53.148082 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:15:54.469607 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:15:55.791278 139681449744192 submission_runner.py:408] Time since start: 3235.62s, 	Step: 13108, 	{'train/ssim': 0.7421060970851353, 'train/loss': 0.27096547399248394, 'validation/ssim': 0.7184103738745076, 'validation/loss': 0.2904571035167241, 'validation/num_examples': 3554, 'test/ssim': 0.7357027404836288, 'test/loss': 0.29178414641728917, 'test/num_examples': 3581, 'score': 3072.431079149246, 'total_duration': 3235.6166298389435, 'accumulated_submission_time': 3072.431079149246, 'accumulated_eval_time': 161.65591073036194, 'accumulated_logging_time': 0.9946553707122803}
I0204 21:15:55.810024 139461883066112 logging_writer.py:48] [13108] accumulated_eval_time=161.655911, accumulated_logging_time=0.994655, accumulated_submission_time=3072.431079, global_step=13108, preemption_count=0, score=3072.431079, test/loss=0.291784, test/num_examples=3581, test/ssim=0.735703, total_duration=3235.616630, train/loss=0.270965, train/ssim=0.742106, validation/loss=0.290457, validation/num_examples=3554, validation/ssim=0.718410
I0204 21:16:15.805442 139466119386880 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.13418623805046082, loss=0.2296825796365738
I0204 21:16:39.483510 139461883066112 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.08240845799446106, loss=0.3481554687023163
I0204 21:17:03.284312 139466119386880 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.06934227794408798, loss=0.405773788690567
I0204 21:17:15.870568 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:17:17.242396 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:17:18.563348 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:17:19.882688 139681449744192 submission_runner.py:408] Time since start: 3319.71s, 	Step: 13454, 	{'train/ssim': 0.746272087097168, 'train/loss': 0.2673053400857108, 'validation/ssim': 0.7233196337973059, 'validation/loss': 0.286368658251486, 'validation/num_examples': 3554, 'test/ssim': 0.7405587595556409, 'test/loss': 0.2877401795609641, 'test/num_examples': 3581, 'score': 3152.4668333530426, 'total_duration': 3319.7080438137054, 'accumulated_submission_time': 3152.4668333530426, 'accumulated_eval_time': 165.66799879074097, 'accumulated_logging_time': 1.0246577262878418}
I0204 21:17:19.903614 139461883066112 logging_writer.py:48] [13454] accumulated_eval_time=165.667999, accumulated_logging_time=1.024658, accumulated_submission_time=3152.466833, global_step=13454, preemption_count=0, score=3152.466833, test/loss=0.287740, test/num_examples=3581, test/ssim=0.740559, total_duration=3319.708044, train/loss=0.267305, train/ssim=0.746272, validation/loss=0.286369, validation/num_examples=3554, validation/ssim=0.723320
I0204 21:17:28.824244 139466119386880 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.09723597019910812, loss=0.32815954089164734
I0204 21:17:52.680652 139461883066112 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.13861459493637085, loss=0.19731515645980835
I0204 21:18:16.412310 139466119386880 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.07559872418642044, loss=0.3164142966270447
I0204 21:18:39.934032 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:18:41.307029 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:18:42.628583 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:18:43.949319 139681449744192 submission_runner.py:408] Time since start: 3403.77s, 	Step: 13800, 	{'train/ssim': 0.7456895964486259, 'train/loss': 0.26762713704790386, 'validation/ssim': 0.7229075348638858, 'validation/loss': 0.28652881972227595, 'validation/num_examples': 3554, 'test/ssim': 0.7401016350399678, 'test/loss': 0.28788123707370494, 'test/num_examples': 3581, 'score': 3232.474317073822, 'total_duration': 3403.774663925171, 'accumulated_submission_time': 3232.474317073822, 'accumulated_eval_time': 169.683251619339, 'accumulated_logging_time': 1.0551369190216064}
I0204 21:18:43.969402 139461883066112 logging_writer.py:48] [13800] accumulated_eval_time=169.683252, accumulated_logging_time=1.055137, accumulated_submission_time=3232.474317, global_step=13800, preemption_count=0, score=3232.474317, test/loss=0.287881, test/num_examples=3581, test/ssim=0.740102, total_duration=3403.774664, train/loss=0.267627, train/ssim=0.745690, validation/loss=0.286529, validation/num_examples=3554, validation/ssim=0.722908
I0204 21:18:44.061519 139466119386880 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.12370031327009201, loss=0.2639492452144623
I0204 21:19:06.024703 139461883066112 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.06766219437122345, loss=0.2338199019432068
I0204 21:19:30.216405 139466119386880 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.05597831308841705, loss=0.21650181710720062
I0204 21:19:54.217104 139461883066112 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.10147016495466232, loss=0.24379901587963104
I0204 21:20:04.154252 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:20:05.526164 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:20:06.846402 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:20:08.166417 139681449744192 submission_runner.py:408] Time since start: 3487.99s, 	Step: 14143, 	{'train/ssim': 0.7468343462262835, 'train/loss': 0.26763127531324116, 'validation/ssim': 0.7231794281091728, 'validation/loss': 0.28713419092593734, 'validation/num_examples': 3554, 'test/ssim': 0.740409725373499, 'test/loss': 0.288486918534889, 'test/num_examples': 3581, 'score': 3312.635585308075, 'total_duration': 3487.991771221161, 'accumulated_submission_time': 3312.635585308075, 'accumulated_eval_time': 173.69537568092346, 'accumulated_logging_time': 1.0848171710968018}
I0204 21:20:08.185110 139466119386880 logging_writer.py:48] [14143] accumulated_eval_time=173.695376, accumulated_logging_time=1.084817, accumulated_submission_time=3312.635585, global_step=14143, preemption_count=0, score=3312.635585, test/loss=0.288487, test/num_examples=3581, test/ssim=0.740410, total_duration=3487.991771, train/loss=0.267631, train/ssim=0.746834, validation/loss=0.287134, validation/num_examples=3554, validation/ssim=0.723179
I0204 21:20:19.558918 139461883066112 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.07483330368995667, loss=0.3551912009716034
I0204 21:20:43.399221 139466119386880 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.13042275607585907, loss=0.33052873611450195
I0204 21:21:07.326633 139461883066112 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.07499179244041443, loss=0.2872214615345001
I0204 21:21:28.176653 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:21:29.548341 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:21:30.870567 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:21:32.192930 139681449744192 submission_runner.py:408] Time since start: 3572.02s, 	Step: 14489, 	{'train/ssim': 0.7479549816676548, 'train/loss': 0.2670495850699289, 'validation/ssim': 0.7246055281021384, 'validation/loss': 0.28627075126617896, 'validation/num_examples': 3554, 'test/ssim': 0.7417685544147934, 'test/loss': 0.287666889649801, 'test/num_examples': 3581, 'score': 3392.603483438492, 'total_duration': 3572.0182886123657, 'accumulated_submission_time': 3392.603483438492, 'accumulated_eval_time': 177.7116355895996, 'accumulated_logging_time': 1.1130201816558838}
I0204 21:21:32.211587 139466119386880 logging_writer.py:48] [14489] accumulated_eval_time=177.711636, accumulated_logging_time=1.113020, accumulated_submission_time=3392.603483, global_step=14489, preemption_count=0, score=3392.603483, test/loss=0.287667, test/num_examples=3581, test/ssim=0.741769, total_duration=3572.018289, train/loss=0.267050, train/ssim=0.747955, validation/loss=0.286271, validation/num_examples=3554, validation/ssim=0.724606
I0204 21:21:33.098676 139461883066112 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.03998956456780434, loss=0.34051313996315
I0204 21:21:56.473826 139466119386880 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.08925441652536392, loss=0.21134424209594727
I0204 21:22:20.146048 139461883066112 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.05985426902770996, loss=0.2602262496948242
I0204 21:22:44.183663 139466119386880 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.04090826213359833, loss=0.34014102816581726
I0204 21:22:52.254177 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:22:53.625396 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:22:54.946080 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:22:56.268070 139681449744192 submission_runner.py:408] Time since start: 3656.09s, 	Step: 14835, 	{'train/ssim': 0.7479761668613979, 'train/loss': 0.2671400308609009, 'validation/ssim': 0.7246696201682963, 'validation/loss': 0.28639548349460997, 'validation/num_examples': 3554, 'test/ssim': 0.7418121874781834, 'test/loss': 0.2877663253106674, 'test/num_examples': 3581, 'score': 3472.621673107147, 'total_duration': 3656.093423604965, 'accumulated_submission_time': 3472.621673107147, 'accumulated_eval_time': 181.7254831790924, 'accumulated_logging_time': 1.142401933670044}
I0204 21:22:56.291271 139461883066112 logging_writer.py:48] [14835] accumulated_eval_time=181.725483, accumulated_logging_time=1.142402, accumulated_submission_time=3472.621673, global_step=14835, preemption_count=0, score=3472.621673, test/loss=0.287766, test/num_examples=3581, test/ssim=0.741812, total_duration=3656.093424, train/loss=0.267140, train/ssim=0.747976, validation/loss=0.286395, validation/num_examples=3554, validation/ssim=0.724670
I0204 21:23:09.785697 139466119386880 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.07779694348573685, loss=0.35203438997268677
I0204 21:23:33.657433 139461883066112 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.07009795308113098, loss=0.21835985779762268
I0204 21:23:58.220651 139466119386880 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.08531571179628372, loss=0.19659589231014252
I0204 21:24:16.294252 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:24:17.664882 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:24:18.988576 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:24:20.310861 139681449744192 submission_runner.py:408] Time since start: 3740.14s, 	Step: 15176, 	{'train/ssim': 0.7476153373718262, 'train/loss': 0.2673849718911307, 'validation/ssim': 0.7247315140071047, 'validation/loss': 0.28666461178205893, 'validation/num_examples': 3554, 'test/ssim': 0.7418471621055571, 'test/loss': 0.28812868426679, 'test/num_examples': 3581, 'score': 3552.6018946170807, 'total_duration': 3740.1362104415894, 'accumulated_submission_time': 3552.6018946170807, 'accumulated_eval_time': 185.74206948280334, 'accumulated_logging_time': 1.1750538349151611}
I0204 21:24:20.329578 139461883066112 logging_writer.py:48] [15176] accumulated_eval_time=185.742069, accumulated_logging_time=1.175054, accumulated_submission_time=3552.601895, global_step=15176, preemption_count=0, score=3552.601895, test/loss=0.288129, test/num_examples=3581, test/ssim=0.741847, total_duration=3740.136210, train/loss=0.267385, train/ssim=0.747615, validation/loss=0.286665, validation/num_examples=3554, validation/ssim=0.724732
I0204 21:24:24.101300 139466119386880 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.09990788996219635, loss=0.2570013403892517
I0204 21:24:48.114095 139461883066112 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.07391669601202011, loss=0.24144293367862701
I0204 21:25:11.688143 139466119386880 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.06508740782737732, loss=0.27408427000045776
I0204 21:25:35.770364 139461883066112 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.07156115025281906, loss=0.25554823875427246
I0204 21:25:40.348700 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:25:41.718659 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:25:43.039884 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:25:44.364575 139681449744192 submission_runner.py:408] Time since start: 3824.19s, 	Step: 15521, 	{'train/ssim': 0.7456714085170201, 'train/loss': 0.2672596148082188, 'validation/ssim': 0.7225538263444359, 'validation/loss': 0.28642826799468907, 'validation/num_examples': 3554, 'test/ssim': 0.7398874921460485, 'test/loss': 0.28774761081707273, 'test/num_examples': 3581, 'score': 3632.597405195236, 'total_duration': 3824.1899275779724, 'accumulated_submission_time': 3632.597405195236, 'accumulated_eval_time': 189.75790739059448, 'accumulated_logging_time': 1.2031304836273193}
I0204 21:25:44.384188 139466119386880 logging_writer.py:48] [15521] accumulated_eval_time=189.757907, accumulated_logging_time=1.203130, accumulated_submission_time=3632.597405, global_step=15521, preemption_count=0, score=3632.597405, test/loss=0.287748, test/num_examples=3581, test/ssim=0.739887, total_duration=3824.189928, train/loss=0.267260, train/ssim=0.745671, validation/loss=0.286428, validation/num_examples=3554, validation/ssim=0.722554
I0204 21:26:01.130833 139461883066112 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.09340301901102066, loss=0.27547886967658997
I0204 21:26:25.083622 139466119386880 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.14574722945690155, loss=0.20728936791419983
I0204 21:26:48.802643 139461883066112 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.04595082998275757, loss=0.24917538464069366
I0204 21:27:04.473930 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:27:05.844446 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:27:07.165918 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:27:08.485281 139681449744192 submission_runner.py:408] Time since start: 3908.31s, 	Step: 15867, 	{'train/ssim': 0.7476047788347516, 'train/loss': 0.2666402203696115, 'validation/ssim': 0.7241376491497257, 'validation/loss': 0.28601328388787284, 'validation/num_examples': 3554, 'test/ssim': 0.7413994459691776, 'test/loss': 0.28736425344919364, 'test/num_examples': 3581, 'score': 3712.6631059646606, 'total_duration': 3908.31063747406, 'accumulated_submission_time': 3712.6631059646606, 'accumulated_eval_time': 193.76922011375427, 'accumulated_logging_time': 1.2327890396118164}
I0204 21:27:08.504059 139466119386880 logging_writer.py:48] [15867] accumulated_eval_time=193.769220, accumulated_logging_time=1.232789, accumulated_submission_time=3712.663106, global_step=15867, preemption_count=0, score=3712.663106, test/loss=0.287364, test/num_examples=3581, test/ssim=0.741399, total_duration=3908.310637, train/loss=0.266640, train/ssim=0.747605, validation/loss=0.286013, validation/num_examples=3554, validation/ssim=0.724138
I0204 21:27:14.309098 139461883066112 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.08458953350782394, loss=0.20501714944839478
I0204 21:27:38.178959 139466119386880 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.21377722918987274, loss=0.23487669229507446
I0204 21:28:02.354724 139461883066112 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.060022614896297455, loss=0.364078551530838
I0204 21:28:26.644982 139466119386880 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.10401424020528793, loss=0.22592686116695404
I0204 21:28:28.722304 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:28:30.092857 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:28:31.416125 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:28:32.738308 139681449744192 submission_runner.py:408] Time since start: 3992.56s, 	Step: 16210, 	{'train/ssim': 0.7477357728140694, 'train/loss': 0.26675924233027865, 'validation/ssim': 0.7241149112355796, 'validation/loss': 0.28622342068356077, 'validation/num_examples': 3554, 'test/ssim': 0.7413657666983734, 'test/loss': 0.28759452012356884, 'test/num_examples': 3581, 'score': 3792.858276128769, 'total_duration': 3992.563661813736, 'accumulated_submission_time': 3792.858276128769, 'accumulated_eval_time': 197.7851824760437, 'accumulated_logging_time': 1.260986328125}
I0204 21:28:32.757304 139461883066112 logging_writer.py:48] [16210] accumulated_eval_time=197.785182, accumulated_logging_time=1.260986, accumulated_submission_time=3792.858276, global_step=16210, preemption_count=0, score=3792.858276, test/loss=0.287595, test/num_examples=3581, test/ssim=0.741366, total_duration=3992.563662, train/loss=0.266759, train/ssim=0.747736, validation/loss=0.286223, validation/num_examples=3554, validation/ssim=0.724115
I0204 21:28:52.315488 139466119386880 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.15627437829971313, loss=0.2436518669128418
I0204 21:29:15.976552 139461883066112 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.10073913633823395, loss=0.23089107871055603
I0204 21:29:39.563645 139466119386880 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.06916295737028122, loss=0.2744053602218628
I0204 21:29:52.930557 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:29:54.300920 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:29:55.623982 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:29:56.945058 139681449744192 submission_runner.py:408] Time since start: 4076.77s, 	Step: 16558, 	{'train/ssim': 0.748434339250837, 'train/loss': 0.26643684932163786, 'validation/ssim': 0.724732063563942, 'validation/loss': 0.28620516509236954, 'validation/num_examples': 3554, 'test/ssim': 0.7419231109065205, 'test/loss': 0.28759850845826934, 'test/num_examples': 3581, 'score': 3873.0085203647614, 'total_duration': 4076.7703862190247, 'accumulated_submission_time': 3873.0085203647614, 'accumulated_eval_time': 201.79962134361267, 'accumulated_logging_time': 1.2895026206970215}
I0204 21:29:56.964490 139461883066112 logging_writer.py:48] [16558] accumulated_eval_time=201.799621, accumulated_logging_time=1.289503, accumulated_submission_time=3873.008520, global_step=16558, preemption_count=0, score=3873.008520, test/loss=0.287599, test/num_examples=3581, test/ssim=0.741923, total_duration=4076.770386, train/loss=0.266437, train/ssim=0.748434, validation/loss=0.286205, validation/num_examples=3554, validation/ssim=0.724732
I0204 21:30:04.926830 139466119386880 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.12363647669553757, loss=0.2332841157913208
I0204 21:30:28.798174 139461883066112 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.15847009420394897, loss=0.3203551173210144
I0204 21:30:52.895301 139466119386880 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.21335017681121826, loss=0.29693594574928284
I0204 21:31:16.712922 139461883066112 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.05594266206026077, loss=0.3301747739315033
I0204 21:31:17.201045 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:31:18.571867 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:31:19.891762 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:31:21.213078 139681449744192 submission_runner.py:408] Time since start: 4161.04s, 	Step: 16903, 	{'train/ssim': 0.7483385631016323, 'train/loss': 0.2663480384009225, 'validation/ssim': 0.7249650756629854, 'validation/loss': 0.28570505119671497, 'validation/num_examples': 3554, 'test/ssim': 0.7421911815397235, 'test/loss': 0.2871007165639835, 'test/num_examples': 3581, 'score': 3953.2207186222076, 'total_duration': 4161.03843665123, 'accumulated_submission_time': 3953.2207186222076, 'accumulated_eval_time': 205.81161665916443, 'accumulated_logging_time': 1.3195016384124756}
I0204 21:31:21.232092 139466119386880 logging_writer.py:48] [16903] accumulated_eval_time=205.811617, accumulated_logging_time=1.319502, accumulated_submission_time=3953.220719, global_step=16903, preemption_count=0, score=3953.220719, test/loss=0.287101, test/num_examples=3581, test/ssim=0.742191, total_duration=4161.038437, train/loss=0.266348, train/ssim=0.748339, validation/loss=0.285705, validation/num_examples=3554, validation/ssim=0.724965
I0204 21:31:42.099420 139461883066112 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.1277976632118225, loss=0.22168764472007751
I0204 21:32:05.949501 139466119386880 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.05498756095767021, loss=0.30983948707580566
I0204 21:32:30.066491 139461883066112 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.05259542539715767, loss=0.25633275508880615
I0204 21:32:41.422425 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:32:42.795907 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:32:44.114575 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:32:45.434867 139681449744192 submission_runner.py:408] Time since start: 4245.26s, 	Step: 17247, 	{'train/ssim': 0.7485357693263462, 'train/loss': 0.2669499261038644, 'validation/ssim': 0.7251728768421145, 'validation/loss': 0.28623745155656477, 'validation/num_examples': 3554, 'test/ssim': 0.7422807656729964, 'test/loss': 0.2876641966716699, 'test/num_examples': 3581, 'score': 4033.3886363506317, 'total_duration': 4245.26022362709, 'accumulated_submission_time': 4033.3886363506317, 'accumulated_eval_time': 209.8240213394165, 'accumulated_logging_time': 1.347517728805542}
I0204 21:32:45.453934 139466119386880 logging_writer.py:48] [17247] accumulated_eval_time=209.824021, accumulated_logging_time=1.347518, accumulated_submission_time=4033.388636, global_step=17247, preemption_count=0, score=4033.388636, test/loss=0.287664, test/num_examples=3581, test/ssim=0.742281, total_duration=4245.260224, train/loss=0.266950, train/ssim=0.748536, validation/loss=0.286237, validation/num_examples=3554, validation/ssim=0.725173
I0204 21:32:55.963462 139461883066112 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.06255294382572174, loss=0.25323647260665894
I0204 21:33:19.955175 139466119386880 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.07851403206586838, loss=0.23237942159175873
I0204 21:33:43.665142 139461883066112 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.09070765972137451, loss=0.25037261843681335
I0204 21:34:05.436575 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:34:06.806788 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:34:08.130657 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:34:09.451068 139681449744192 submission_runner.py:408] Time since start: 4329.28s, 	Step: 17592, 	{'train/ssim': 0.7472812107631138, 'train/loss': 0.26697795731680735, 'validation/ssim': 0.723099261505522, 'validation/loss': 0.28689576912677617, 'validation/num_examples': 3554, 'test/ssim': 0.7403153688739179, 'test/loss': 0.28827253702265426, 'test/num_examples': 3581, 'score': 4113.347852706909, 'total_duration': 4329.27641749382, 'accumulated_submission_time': 4113.347852706909, 'accumulated_eval_time': 213.8384931087494, 'accumulated_logging_time': 1.375917673110962}
I0204 21:34:09.471460 139466119386880 logging_writer.py:48] [17592] accumulated_eval_time=213.838493, accumulated_logging_time=1.375918, accumulated_submission_time=4113.347853, global_step=17592, preemption_count=0, score=4113.347853, test/loss=0.288273, test/num_examples=3581, test/ssim=0.740315, total_duration=4329.276417, train/loss=0.266978, train/ssim=0.747281, validation/loss=0.286896, validation/num_examples=3554, validation/ssim=0.723099
I0204 21:34:10.141851 139461883066112 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.06789574772119522, loss=0.3013274371623993
I0204 21:34:33.220167 139466119386880 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.09746673703193665, loss=0.2609449326992035
I0204 21:34:57.277759 139461883066112 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.13679666817188263, loss=0.2862374782562256
I0204 21:35:21.230379 139466119386880 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.07093092054128647, loss=0.206207275390625
I0204 21:35:29.501210 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:35:30.871873 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:35:32.191863 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:35:33.512446 139681449744192 submission_runner.py:408] Time since start: 4413.34s, 	Step: 17936, 	{'train/ssim': 0.7481169700622559, 'train/loss': 0.26622419697897776, 'validation/ssim': 0.7245039287818303, 'validation/loss': 0.28565562542865436, 'validation/num_examples': 3554, 'test/ssim': 0.7417701224780089, 'test/loss': 0.287055038200747, 'test/num_examples': 3581, 'score': 4193.354947090149, 'total_duration': 4413.337802171707, 'accumulated_submission_time': 4193.354947090149, 'accumulated_eval_time': 217.84970903396606, 'accumulated_logging_time': 1.4057002067565918}
I0204 21:35:33.531680 139461883066112 logging_writer.py:48] [17936] accumulated_eval_time=217.849709, accumulated_logging_time=1.405700, accumulated_submission_time=4193.354947, global_step=17936, preemption_count=0, score=4193.354947, test/loss=0.287055, test/num_examples=3581, test/ssim=0.741770, total_duration=4413.337802, train/loss=0.266224, train/ssim=0.748117, validation/loss=0.285656, validation/num_examples=3554, validation/ssim=0.724504
I0204 21:35:46.760219 139466119386880 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.08247537910938263, loss=0.3135467767715454
I0204 21:36:10.440699 139461883066112 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.07561741024255753, loss=0.2676504850387573
I0204 21:36:34.418257 139466119386880 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.06799010932445526, loss=0.21282817423343658
I0204 21:36:53.658893 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:36:55.031229 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:36:56.352013 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:36:57.672161 139681449744192 submission_runner.py:408] Time since start: 4497.50s, 	Step: 18281, 	{'train/ssim': 0.7480468068804059, 'train/loss': 0.2663684742791312, 'validation/ssim': 0.7245921326542276, 'validation/loss': 0.28573355945765333, 'validation/num_examples': 3554, 'test/ssim': 0.7418551387749581, 'test/loss': 0.28704351634494557, 'test/num_examples': 3581, 'score': 4273.456275224686, 'total_duration': 4497.49751830101, 'accumulated_submission_time': 4273.456275224686, 'accumulated_eval_time': 221.86294984817505, 'accumulated_logging_time': 1.4366326332092285}
I0204 21:36:57.691864 139461883066112 logging_writer.py:48] [18281] accumulated_eval_time=221.862950, accumulated_logging_time=1.436633, accumulated_submission_time=4273.456275, global_step=18281, preemption_count=0, score=4273.456275, test/loss=0.287044, test/num_examples=3581, test/ssim=0.741855, total_duration=4497.497518, train/loss=0.266368, train/ssim=0.748047, validation/loss=0.285734, validation/num_examples=3554, validation/ssim=0.724592
I0204 21:37:03.232395 139466119386880 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.07697993516921997, loss=0.2552430331707001
I0204 21:37:27.858586 139461883066112 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.15354381501674652, loss=0.2206476479768753
I0204 21:37:51.845348 139466119386880 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.06625575572252274, loss=0.33600229024887085
I0204 21:38:15.908625 139461883066112 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.09066052734851837, loss=0.2574962377548218
I0204 21:38:17.713953 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:38:19.085516 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:38:20.405751 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:38:21.725141 139681449744192 submission_runner.py:408] Time since start: 4581.55s, 	Step: 18609, 	{'train/ssim': 0.7484518459865025, 'train/loss': 0.26592135429382324, 'validation/ssim': 0.724492731561269, 'validation/loss': 0.2857109761063678, 'validation/num_examples': 3554, 'test/ssim': 0.741691855670553, 'test/loss': 0.28709396707449036, 'test/num_examples': 3581, 'score': 4350.548347711563, 'total_duration': 4581.550496578217, 'accumulated_submission_time': 4350.548347711563, 'accumulated_eval_time': 225.87409567832947, 'accumulated_logging_time': 4.3728437423706055}
I0204 21:38:21.744920 139466119386880 logging_writer.py:48] [18609] accumulated_eval_time=225.874096, accumulated_logging_time=4.372844, accumulated_submission_time=4350.548348, global_step=18609, preemption_count=0, score=4350.548348, test/loss=0.287094, test/num_examples=3581, test/ssim=0.741692, total_duration=4581.550497, train/loss=0.265921, train/ssim=0.748452, validation/loss=0.285711, validation/num_examples=3554, validation/ssim=0.724493
I0204 21:38:41.141094 139461883066112 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.08046038448810577, loss=0.28863534331321716
I0204 21:39:05.152156 139466119386880 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.08836976438760757, loss=0.2618692219257355
I0204 21:39:29.086201 139461883066112 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.05972220376133919, loss=0.2433432638645172
I0204 21:39:41.796965 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:39:43.167790 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:39:44.488666 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:39:45.808876 139681449744192 submission_runner.py:408] Time since start: 4665.63s, 	Step: 18955, 	{'train/ssim': 0.74802337374006, 'train/loss': 0.2668883630207607, 'validation/ssim': 0.7247163324994724, 'validation/loss': 0.28622769692270156, 'validation/num_examples': 3554, 'test/ssim': 0.7419325874624756, 'test/loss': 0.28756810166721936, 'test/num_examples': 3581, 'score': 4430.576882123947, 'total_duration': 4665.634213447571, 'accumulated_submission_time': 4430.576882123947, 'accumulated_eval_time': 229.88594794273376, 'accumulated_logging_time': 4.401664972305298}
I0204 21:39:45.828711 139466119386880 logging_writer.py:48] [18955] accumulated_eval_time=229.885948, accumulated_logging_time=4.401665, accumulated_submission_time=4430.576882, global_step=18955, preemption_count=0, score=4430.576882, test/loss=0.287568, test/num_examples=3581, test/ssim=0.741933, total_duration=4665.634213, train/loss=0.266888, train/ssim=0.748023, validation/loss=0.286228, validation/num_examples=3554, validation/ssim=0.724716
I0204 21:39:54.676043 139461883066112 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.0334954559803009, loss=0.27970418334007263
I0204 21:40:18.899300 139466119386880 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.06990355253219604, loss=0.2733067274093628
I0204 21:40:42.791832 139461883066112 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.11275779455900192, loss=0.23158970475196838
I0204 21:41:05.925416 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:41:07.295034 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:41:08.614521 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:41:09.934641 139681449744192 submission_runner.py:408] Time since start: 4749.76s, 	Step: 19298, 	{'train/ssim': 0.7479914937700544, 'train/loss': 0.266499434198652, 'validation/ssim': 0.7243800724096089, 'validation/loss': 0.2859593242759039, 'validation/num_examples': 3554, 'test/ssim': 0.7416037714238342, 'test/loss': 0.28725803421050333, 'test/num_examples': 3581, 'score': 4510.648891210556, 'total_duration': 4749.759995222092, 'accumulated_submission_time': 4510.648891210556, 'accumulated_eval_time': 233.89514589309692, 'accumulated_logging_time': 4.43175482749939}
I0204 21:41:09.954685 139466119386880 logging_writer.py:48] [19298] accumulated_eval_time=233.895146, accumulated_logging_time=4.431755, accumulated_submission_time=4510.648891, global_step=19298, preemption_count=0, score=4510.648891, test/loss=0.287258, test/num_examples=3581, test/ssim=0.741604, total_duration=4749.759995, train/loss=0.266499, train/ssim=0.747991, validation/loss=0.285959, validation/num_examples=3554, validation/ssim=0.724380
I0204 21:41:10.192017 139461883066112 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.1342848837375641, loss=0.25642129778862
I0204 21:41:32.655178 139466119386880 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.14784938097000122, loss=0.24409468472003937
I0204 21:41:56.753021 139461883066112 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.2613164782524109, loss=0.22488175332546234
I0204 21:42:20.614372 139466119386880 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.06037120893597603, loss=0.3428729772567749
I0204 21:42:30.054289 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:42:31.423859 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:42:32.742975 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:42:34.064394 139681449744192 submission_runner.py:408] Time since start: 4833.89s, 	Step: 19640, 	{'train/ssim': 0.7494755472455706, 'train/loss': 0.2658189194543021, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.2856957087304797, 'validation/num_examples': 3554, 'test/ssim': 0.742760524840303, 'test/loss': 0.2870987053524679, 'test/num_examples': 3581, 'score': 4590.72519493103, 'total_duration': 4833.889722824097, 'accumulated_submission_time': 4590.72519493103, 'accumulated_eval_time': 237.90518808364868, 'accumulated_logging_time': 4.460954427719116}
I0204 21:42:34.084446 139461883066112 logging_writer.py:48] [19640] accumulated_eval_time=237.905188, accumulated_logging_time=4.460954, accumulated_submission_time=4590.725195, global_step=19640, preemption_count=0, score=4590.725195, test/loss=0.287099, test/num_examples=3581, test/ssim=0.742761, total_duration=4833.889723, train/loss=0.265819, train/ssim=0.749476, validation/loss=0.285696, validation/num_examples=3554, validation/ssim=0.725719
I0204 21:42:46.532393 139466119386880 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.14568543434143066, loss=0.2018122375011444
I0204 21:43:10.516948 139461883066112 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.08149252831935883, loss=0.21865582466125488
I0204 21:43:34.346161 139466119386880 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.05963728576898575, loss=0.31406643986701965
I0204 21:43:54.300373 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:43:55.670795 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:43:56.993251 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:43:58.315302 139681449744192 submission_runner.py:408] Time since start: 4918.14s, 	Step: 19985, 	{'train/ssim': 0.7494589260646275, 'train/loss': 0.2660778931209019, 'validation/ssim': 0.7255726107466939, 'validation/loss': 0.2859783526813977, 'validation/num_examples': 3554, 'test/ssim': 0.7427205051399749, 'test/loss': 0.2873735595634948, 'test/num_examples': 3581, 'score': 4670.917221784592, 'total_duration': 4918.140657424927, 'accumulated_submission_time': 4670.917221784592, 'accumulated_eval_time': 241.92007851600647, 'accumulated_logging_time': 4.490314960479736}
I0204 21:43:58.335549 139461883066112 logging_writer.py:48] [19985] accumulated_eval_time=241.920079, accumulated_logging_time=4.490315, accumulated_submission_time=4670.917222, global_step=19985, preemption_count=0, score=4670.917222, test/loss=0.287374, test/num_examples=3581, test/ssim=0.742721, total_duration=4918.140657, train/loss=0.266078, train/ssim=0.749459, validation/loss=0.285978, validation/num_examples=3554, validation/ssim=0.725573
I0204 21:43:59.801415 139466119386880 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.1385354846715927, loss=0.24102523922920227
I0204 21:44:23.872698 139461883066112 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.04090285673737526, loss=0.3840675354003906
I0204 21:44:47.536306 139466119386880 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.05147577449679375, loss=0.35781577229499817
I0204 21:45:11.755461 139461883066112 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.05305913835763931, loss=0.26848578453063965
I0204 21:45:18.395184 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:45:19.764133 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:45:21.085350 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:45:22.407220 139681449744192 submission_runner.py:408] Time since start: 5002.23s, 	Step: 20329, 	{'train/ssim': 0.7488336563110352, 'train/loss': 0.2660074234008789, 'validation/ssim': 0.7252096971502181, 'validation/loss': 0.2856191142462718, 'validation/num_examples': 3554, 'test/ssim': 0.7423481923912664, 'test/loss': 0.28703608508883693, 'test/num_examples': 3581, 'score': 4750.951722860336, 'total_duration': 5002.232574462891, 'accumulated_submission_time': 4750.951722860336, 'accumulated_eval_time': 245.93207383155823, 'accumulated_logging_time': 4.521239280700684}
I0204 21:45:22.428178 139466119386880 logging_writer.py:48] [20329] accumulated_eval_time=245.932074, accumulated_logging_time=4.521239, accumulated_submission_time=4750.951723, global_step=20329, preemption_count=0, score=4750.951723, test/loss=0.287036, test/num_examples=3581, test/ssim=0.742348, total_duration=5002.232574, train/loss=0.266007, train/ssim=0.748834, validation/loss=0.285619, validation/num_examples=3554, validation/ssim=0.725210
I0204 21:45:37.404132 139461883066112 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.08037297427654266, loss=0.23440983891487122
I0204 21:46:02.052420 139466119386880 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.1548762023448944, loss=0.23255951702594757
I0204 21:46:26.406397 139461883066112 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.07271692156791687, loss=0.36414098739624023
I0204 21:46:42.440796 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:46:43.809566 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:46:45.127219 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:46:46.447377 139681449744192 submission_runner.py:408] Time since start: 5086.27s, 	Step: 20668, 	{'train/ssim': 0.7490506853376117, 'train/loss': 0.2657781328473772, 'validation/ssim': 0.7247555571187394, 'validation/loss': 0.2857364618047007, 'validation/num_examples': 3554, 'test/ssim': 0.7419362690021991, 'test/loss': 0.28714448598069675, 'test/num_examples': 3581, 'score': 4830.941958904266, 'total_duration': 5086.27272605896, 'accumulated_submission_time': 4830.941958904266, 'accumulated_eval_time': 249.9386088848114, 'accumulated_logging_time': 4.551448345184326}
I0204 21:46:46.467443 139466119386880 logging_writer.py:48] [20668] accumulated_eval_time=249.938609, accumulated_logging_time=4.551448, accumulated_submission_time=4830.941959, global_step=20668, preemption_count=0, score=4830.941959, test/loss=0.287144, test/num_examples=3581, test/ssim=0.741936, total_duration=5086.272726, train/loss=0.265778, train/ssim=0.749051, validation/loss=0.285736, validation/num_examples=3554, validation/ssim=0.724756
I0204 21:46:51.942955 139461883066112 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.1851414442062378, loss=0.260043740272522
I0204 21:47:15.796632 139466119386880 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.028367219492793083, loss=0.2359515279531479
I0204 21:47:39.650708 139461883066112 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.07113935798406601, loss=0.3052624464035034
I0204 21:48:03.512156 139466119386880 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.064729705452919, loss=0.310748815536499
I0204 21:48:06.636546 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:48:08.006287 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:48:09.326133 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:48:10.646710 139681449744192 submission_runner.py:408] Time since start: 5170.47s, 	Step: 21014, 	{'train/ssim': 0.7492361749921527, 'train/loss': 0.26613100937434603, 'validation/ssim': 0.7255093430157921, 'validation/loss': 0.2857910224944605, 'validation/num_examples': 3554, 'test/ssim': 0.7425711300745252, 'test/loss': 0.2872181849518291, 'test/num_examples': 3581, 'score': 4911.088220119476, 'total_duration': 5170.472066164017, 'accumulated_submission_time': 4911.088220119476, 'accumulated_eval_time': 253.94873142242432, 'accumulated_logging_time': 4.5808281898498535}
I0204 21:48:10.667090 139461883066112 logging_writer.py:48] [21014] accumulated_eval_time=253.948731, accumulated_logging_time=4.580828, accumulated_submission_time=4911.088220, global_step=21014, preemption_count=0, score=4911.088220, test/loss=0.287218, test/num_examples=3581, test/ssim=0.742571, total_duration=5170.472066, train/loss=0.266131, train/ssim=0.749236, validation/loss=0.285791, validation/num_examples=3554, validation/ssim=0.725509
I0204 21:48:29.049227 139466119386880 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.028768358752131462, loss=0.26955682039260864
I0204 21:48:52.740882 139461883066112 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.04522918537259102, loss=0.22004343569278717
I0204 21:49:16.507542 139466119386880 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.053017809987068176, loss=0.2725721597671509
I0204 21:49:30.831352 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:49:32.200146 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:49:33.518723 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:49:34.837206 139681449744192 submission_runner.py:408] Time since start: 5254.66s, 	Step: 21362, 	{'train/ssim': 0.7492140361240932, 'train/loss': 0.26581534317561556, 'validation/ssim': 0.7254861929340181, 'validation/loss': 0.2855267028293384, 'validation/num_examples': 3554, 'test/ssim': 0.7426757130733385, 'test/loss': 0.286876074464186, 'test/num_examples': 3581, 'score': 4991.229874610901, 'total_duration': 5254.662563562393, 'accumulated_submission_time': 4991.229874610901, 'accumulated_eval_time': 257.9545512199402, 'accumulated_logging_time': 4.6102073192596436}
I0204 21:49:34.857546 139461883066112 logging_writer.py:48] [21362] accumulated_eval_time=257.954551, accumulated_logging_time=4.610207, accumulated_submission_time=4991.229875, global_step=21362, preemption_count=0, score=4991.229875, test/loss=0.286876, test/num_examples=3581, test/ssim=0.742676, total_duration=5254.662564, train/loss=0.265815, train/ssim=0.749214, validation/loss=0.285527, validation/num_examples=3554, validation/ssim=0.725486
I0204 21:49:41.944591 139466119386880 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.03842310234904289, loss=0.2572821080684662
I0204 21:50:05.985272 139461883066112 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.07004351168870926, loss=0.21430665254592896
I0204 21:50:30.379429 139466119386880 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.06935016065835953, loss=0.2230248600244522
I0204 21:50:54.459325 139461883066112 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.10041388869285583, loss=0.3010720908641815
I0204 21:50:54.861987 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:50:56.234575 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:50:57.555307 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:50:58.875193 139681449744192 submission_runner.py:408] Time since start: 5338.70s, 	Step: 21703, 	{'train/ssim': 0.7498057229178292, 'train/loss': 0.26596065929957796, 'validation/ssim': 0.7261010783404263, 'validation/loss': 0.28571909924337013, 'validation/num_examples': 3554, 'test/ssim': 0.7431506316976753, 'test/loss': 0.28719510715189545, 'test/num_examples': 3581, 'score': 5071.210415363312, 'total_duration': 5338.700535297394, 'accumulated_submission_time': 5071.210415363312, 'accumulated_eval_time': 261.9677035808563, 'accumulated_logging_time': 4.641288995742798}
I0204 21:50:58.896681 139466119386880 logging_writer.py:48] [21703] accumulated_eval_time=261.967704, accumulated_logging_time=4.641289, accumulated_submission_time=5071.210415, global_step=21703, preemption_count=0, score=5071.210415, test/loss=0.287195, test/num_examples=3581, test/ssim=0.743151, total_duration=5338.700535, train/loss=0.265961, train/ssim=0.749806, validation/loss=0.285719, validation/num_examples=3554, validation/ssim=0.726101
I0204 21:51:20.081486 139461883066112 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.12746861577033997, loss=0.24641887843608856
I0204 21:51:44.018242 139466119386880 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.05953998491168022, loss=0.3472636044025421
I0204 21:52:07.782245 139461883066112 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.09603430330753326, loss=0.2847371995449066
I0204 21:52:19.004805 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:52:20.375596 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:52:21.694026 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:52:23.014573 139681449744192 submission_runner.py:408] Time since start: 5422.84s, 	Step: 22048, 	{'train/ssim': 0.749934468950544, 'train/loss': 0.26566275528499056, 'validation/ssim': 0.7257356230435776, 'validation/loss': 0.2857178970877884, 'validation/num_examples': 3554, 'test/ssim': 0.7429184219884459, 'test/loss': 0.28715904169793705, 'test/num_examples': 3581, 'score': 5151.294460535049, 'total_duration': 5422.839916706085, 'accumulated_submission_time': 5151.294460535049, 'accumulated_eval_time': 265.9774160385132, 'accumulated_logging_time': 4.673285722732544}
I0204 21:52:23.037220 139466119386880 logging_writer.py:48] [22048] accumulated_eval_time=265.977416, accumulated_logging_time=4.673286, accumulated_submission_time=5151.294461, global_step=22048, preemption_count=0, score=5151.294461, test/loss=0.287159, test/num_examples=3581, test/ssim=0.742918, total_duration=5422.839917, train/loss=0.265663, train/ssim=0.749934, validation/loss=0.285718, validation/num_examples=3554, validation/ssim=0.725736
I0204 21:52:33.394221 139461883066112 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.05443417280912399, loss=0.2694830894470215
I0204 21:52:57.578272 139466119386880 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.049009472131729126, loss=0.2809576690196991
I0204 21:53:21.734744 139461883066112 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.06899908930063248, loss=0.32737159729003906
I0204 21:53:43.211910 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:53:44.581683 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:53:45.900416 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:53:47.224012 139681449744192 submission_runner.py:408] Time since start: 5507.05s, 	Step: 22391, 	{'train/ssim': 0.7499521800449916, 'train/loss': 0.2657770940235683, 'validation/ssim': 0.7259103134232555, 'validation/loss': 0.28578545823148216, 'validation/num_examples': 3554, 'test/ssim': 0.7431317467624267, 'test/loss': 0.2871350094247417, 'test/num_examples': 3581, 'score': 5231.44545173645, 'total_duration': 5507.0493676662445, 'accumulated_submission_time': 5231.44545173645, 'accumulated_eval_time': 269.98947501182556, 'accumulated_logging_time': 4.706132888793945}
I0204 21:53:47.245012 139466119386880 logging_writer.py:48] [22391] accumulated_eval_time=269.989475, accumulated_logging_time=4.706133, accumulated_submission_time=5231.445452, global_step=22391, preemption_count=0, score=5231.445452, test/loss=0.287135, test/num_examples=3581, test/ssim=0.743132, total_duration=5507.049368, train/loss=0.265777, train/ssim=0.749952, validation/loss=0.285785, validation/num_examples=3554, validation/ssim=0.725910
I0204 21:53:47.985161 139461883066112 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.04177778586745262, loss=0.25252437591552734
I0204 21:54:10.994900 139466119386880 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.06573206931352615, loss=0.30819565057754517
I0204 21:54:35.158199 139461883066112 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.05308983474969864, loss=0.2231086641550064
I0204 21:54:59.416633 139466119386880 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.12710629403591156, loss=0.21164152026176453
I0204 21:55:07.284932 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:55:08.655724 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:55:09.975722 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:55:11.296028 139681449744192 submission_runner.py:408] Time since start: 5591.12s, 	Step: 22735, 	{'train/ssim': 0.749309744153704, 'train/loss': 0.2656928300857544, 'validation/ssim': 0.7254960849570906, 'validation/loss': 0.28546091057171497, 'validation/num_examples': 3554, 'test/ssim': 0.7426772129598925, 'test/loss': 0.2868370433254503, 'test/num_examples': 3581, 'score': 5311.462661266327, 'total_duration': 5591.121385335922, 'accumulated_submission_time': 5311.462661266327, 'accumulated_eval_time': 274.00053787231445, 'accumulated_logging_time': 4.736352205276489}
I0204 21:55:11.316759 139461883066112 logging_writer.py:48] [22735] accumulated_eval_time=274.000538, accumulated_logging_time=4.736352, accumulated_submission_time=5311.462661, global_step=22735, preemption_count=0, score=5311.462661, test/loss=0.286837, test/num_examples=3581, test/ssim=0.742677, total_duration=5591.121385, train/loss=0.265693, train/ssim=0.749310, validation/loss=0.285461, validation/num_examples=3554, validation/ssim=0.725496
I0204 21:55:25.091567 139466119386880 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.06666970252990723, loss=0.2318463921546936
I0204 21:55:49.017371 139461883066112 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.07671482861042023, loss=0.20958393812179565
I0204 21:56:12.838699 139466119386880 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.019389530643820763, loss=0.27511927485466003
I0204 21:56:31.429089 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:56:32.801354 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:56:34.123531 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:56:35.445388 139681449744192 submission_runner.py:408] Time since start: 5675.27s, 	Step: 23080, 	{'train/ssim': 0.750044754573277, 'train/loss': 0.26533922127314974, 'validation/ssim': 0.7257962116848973, 'validation/loss': 0.2854270441316123, 'validation/num_examples': 3554, 'test/ssim': 0.7429138541521223, 'test/loss': 0.2868782220290247, 'test/num_examples': 3581, 'score': 5391.550899028778, 'total_duration': 5675.270745754242, 'accumulated_submission_time': 5391.550899028778, 'accumulated_eval_time': 278.01680517196655, 'accumulated_logging_time': 4.767531394958496}
I0204 21:56:35.466150 139461883066112 logging_writer.py:48] [23080] accumulated_eval_time=278.016805, accumulated_logging_time=4.767531, accumulated_submission_time=5391.550899, global_step=23080, preemption_count=0, score=5391.550899, test/loss=0.286878, test/num_examples=3581, test/ssim=0.742914, total_duration=5675.270746, train/loss=0.265339, train/ssim=0.750045, validation/loss=0.285427, validation/num_examples=3554, validation/ssim=0.725796
I0204 21:56:38.144581 139466119386880 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.034687552601099014, loss=0.2659458816051483
I0204 21:57:02.111043 139461883066112 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.0665263757109642, loss=0.30331480503082275
I0204 21:57:25.827825 139466119386880 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.07329226285219193, loss=0.23979105055332184
I0204 21:57:49.581061 139461883066112 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.031587060540914536, loss=0.2934369146823883
I0204 21:57:55.619983 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:57:56.991849 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:57:58.311507 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:57:59.631974 139681449744192 submission_runner.py:408] Time since start: 5759.46s, 	Step: 23426, 	{'train/ssim': 0.749577454158238, 'train/loss': 0.26578846999577116, 'validation/ssim': 0.7258460152732836, 'validation/loss': 0.28555299568927617, 'validation/num_examples': 3554, 'test/ssim': 0.7429287848410011, 'test/loss': 0.2870010422848017, 'test/num_examples': 3581, 'score': 5471.681828737259, 'total_duration': 5759.457330942154, 'accumulated_submission_time': 5471.681828737259, 'accumulated_eval_time': 282.02875447273254, 'accumulated_logging_time': 4.797436714172363}
I0204 21:57:59.652732 139466119386880 logging_writer.py:48] [23426] accumulated_eval_time=282.028754, accumulated_logging_time=4.797437, accumulated_submission_time=5471.681829, global_step=23426, preemption_count=0, score=5471.681829, test/loss=0.287001, test/num_examples=3581, test/ssim=0.742929, total_duration=5759.457331, train/loss=0.265788, train/ssim=0.749577, validation/loss=0.285553, validation/num_examples=3554, validation/ssim=0.725846
I0204 21:58:15.328770 139461883066112 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.10742298513650894, loss=0.24220772087574005
I0204 21:58:38.962034 139466119386880 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.059975989162921906, loss=0.28318271040916443
I0204 21:59:02.969665 139461883066112 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.06148698553442955, loss=0.3347456455230713
I0204 21:59:19.703960 139681449744192 spec.py:321] Evaluating on the training split.
I0204 21:59:21.073560 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 21:59:22.396290 139681449744192 spec.py:349] Evaluating on the test split.
I0204 21:59:23.719377 139681449744192 submission_runner.py:408] Time since start: 5843.54s, 	Step: 23770, 	{'train/ssim': 0.7495931216648647, 'train/loss': 0.26550001757485525, 'validation/ssim': 0.7256565555536015, 'validation/loss': 0.2853825815487391, 'validation/num_examples': 3554, 'test/ssim': 0.7428168387627408, 'test/loss': 0.2867749343867809, 'test/num_examples': 3581, 'score': 5551.710270643234, 'total_duration': 5843.544717788696, 'accumulated_submission_time': 5551.710270643234, 'accumulated_eval_time': 286.0441243648529, 'accumulated_logging_time': 4.827166795730591}
I0204 21:59:23.740833 139466119386880 logging_writer.py:48] [23770] accumulated_eval_time=286.044124, accumulated_logging_time=4.827167, accumulated_submission_time=5551.710271, global_step=23770, preemption_count=0, score=5551.710271, test/loss=0.286775, test/num_examples=3581, test/ssim=0.742817, total_duration=5843.544718, train/loss=0.265500, train/ssim=0.749593, validation/loss=0.285383, validation/num_examples=3554, validation/ssim=0.725657
I0204 21:59:28.892615 139461883066112 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.0319659523665905, loss=0.21041500568389893
I0204 21:59:52.853504 139466119386880 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.037580251693725586, loss=0.2836737334728241
I0204 22:00:16.648487 139461883066112 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.03988964483141899, loss=0.18648135662078857
I0204 22:00:40.376682 139466119386880 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.09118310362100601, loss=0.2921590209007263
I0204 22:00:43.905376 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:00:45.274874 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:00:46.594008 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:00:47.915578 139681449744192 submission_runner.py:408] Time since start: 5927.74s, 	Step: 24116, 	{'train/ssim': 0.750204154423305, 'train/loss': 0.26502604143960135, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.28534869793498524, 'validation/num_examples': 3554, 'test/ssim': 0.7428803794113027, 'test/loss': 0.28677772962990433, 'test/num_examples': 3581, 'score': 5631.85106420517, 'total_duration': 5927.740929841995, 'accumulated_submission_time': 5631.85106420517, 'accumulated_eval_time': 290.05428886413574, 'accumulated_logging_time': 4.858988285064697}
I0204 22:00:47.937728 139461883066112 logging_writer.py:48] [24116] accumulated_eval_time=290.054289, accumulated_logging_time=4.858988, accumulated_submission_time=5631.851064, global_step=24116, preemption_count=0, score=5631.851064, test/loss=0.286778, test/num_examples=3581, test/ssim=0.742880, total_duration=5927.740930, train/loss=0.265026, train/ssim=0.750204, validation/loss=0.285349, validation/num_examples=3554, validation/ssim=0.725719
I0204 22:01:06.072077 139466119386880 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.0658641830086708, loss=0.26967909932136536
I0204 22:01:29.907478 139461883066112 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.05993485823273659, loss=0.24773946404457092
I0204 22:01:53.702007 139466119386880 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.0680556371808052, loss=0.2829807698726654
I0204 22:02:08.114391 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:02:09.485256 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:02:10.803832 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:02:12.126784 139681449744192 submission_runner.py:408] Time since start: 6011.95s, 	Step: 24462, 	{'train/ssim': 0.749311992100307, 'train/loss': 0.2653989621571132, 'validation/ssim': 0.7251623665675999, 'validation/loss': 0.28546176925427336, 'validation/num_examples': 3554, 'test/ssim': 0.7423995294174114, 'test/loss': 0.28685718952893746, 'test/num_examples': 3581, 'score': 5712.004364490509, 'total_duration': 6011.95213842392, 'accumulated_submission_time': 5712.004364490509, 'accumulated_eval_time': 294.06663846969604, 'accumulated_logging_time': 4.8908774852752686}
I0204 22:02:12.147923 139461883066112 logging_writer.py:48] [24462] accumulated_eval_time=294.066638, accumulated_logging_time=4.890877, accumulated_submission_time=5712.004364, global_step=24462, preemption_count=0, score=5712.004364, test/loss=0.286857, test/num_examples=3581, test/ssim=0.742400, total_duration=6011.952138, train/loss=0.265399, train/ssim=0.749312, validation/loss=0.285462, validation/num_examples=3554, validation/ssim=0.725162
I0204 22:02:19.108940 139466119386880 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.05646693706512451, loss=0.33659812808036804
I0204 22:02:42.750428 139461883066112 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.06111086905002594, loss=0.22128812968730927
I0204 22:03:06.715263 139466119386880 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.03310193121433258, loss=0.27113139629364014
I0204 22:03:30.750976 139461883066112 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.053187835961580276, loss=0.2706018388271332
I0204 22:03:32.361394 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:03:33.733941 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:03:35.054223 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:03:36.375303 139681449744192 submission_runner.py:408] Time since start: 6096.20s, 	Step: 24808, 	{'train/ssim': 0.7499324253627232, 'train/loss': 0.26541229656764437, 'validation/ssim': 0.7258076836838773, 'validation/loss': 0.2854906038145839, 'validation/num_examples': 3554, 'test/ssim': 0.7429736450842991, 'test/loss': 0.2868880735566183, 'test/num_examples': 3581, 'score': 5792.194799900055, 'total_duration': 6096.200660705566, 'accumulated_submission_time': 5792.194799900055, 'accumulated_eval_time': 298.0805068016052, 'accumulated_logging_time': 4.921252250671387}
I0204 22:03:36.398181 139466119386880 logging_writer.py:48] [24808] accumulated_eval_time=298.080507, accumulated_logging_time=4.921252, accumulated_submission_time=5792.194800, global_step=24808, preemption_count=0, score=5792.194800, test/loss=0.286888, test/num_examples=3581, test/ssim=0.742974, total_duration=6096.200661, train/loss=0.265412, train/ssim=0.749932, validation/loss=0.285491, validation/num_examples=3554, validation/ssim=0.725808
I0204 22:03:56.408941 139461883066112 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.03994610160589218, loss=0.2746298611164093
I0204 22:04:20.479843 139466119386880 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.04952879622578621, loss=0.2932341694831848
I0204 22:04:44.232306 139461883066112 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.02941812202334404, loss=0.333507776260376
I0204 22:04:56.417901 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:04:57.789336 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:04:59.109042 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:05:00.430343 139681449744192 submission_runner.py:408] Time since start: 6180.26s, 	Step: 25153, 	{'train/ssim': 0.7504647118704659, 'train/loss': 0.265025121825082, 'validation/ssim': 0.7259484389288478, 'validation/loss': 0.28542750782019377, 'validation/num_examples': 3554, 'test/ssim': 0.7430454351089081, 'test/loss': 0.28684045215852766, 'test/num_examples': 3581, 'score': 5872.191735506058, 'total_duration': 6180.25568819046, 'accumulated_submission_time': 5872.191735506058, 'accumulated_eval_time': 302.09289360046387, 'accumulated_logging_time': 4.95358943939209}
I0204 22:05:00.452515 139466119386880 logging_writer.py:48] [25153] accumulated_eval_time=302.092894, accumulated_logging_time=4.953589, accumulated_submission_time=5872.191736, global_step=25153, preemption_count=0, score=5872.191736, test/loss=0.286840, test/num_examples=3581, test/ssim=0.743045, total_duration=6180.255688, train/loss=0.265025, train/ssim=0.750465, validation/loss=0.285428, validation/num_examples=3554, validation/ssim=0.725948
I0204 22:05:09.814636 139461883066112 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.0520644448697567, loss=0.28895604610443115
I0204 22:05:33.546815 139466119386880 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.06551339477300644, loss=0.2815060019493103
I0204 22:05:57.631157 139461883066112 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.10160771757364273, loss=0.21487581729888916
I0204 22:06:20.438500 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:06:21.810086 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:06:23.131248 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:06:24.452022 139681449744192 submission_runner.py:408] Time since start: 6264.28s, 	Step: 25497, 	{'train/ssim': 0.7500345366341727, 'train/loss': 0.2653808423451015, 'validation/ssim': 0.7257026496333356, 'validation/loss': 0.28552526024264036, 'validation/num_examples': 3554, 'test/ssim': 0.742860471826131, 'test/loss': 0.2869330701532393, 'test/num_examples': 3581, 'score': 5952.1544880867, 'total_duration': 6264.277378082275, 'accumulated_submission_time': 5952.1544880867, 'accumulated_eval_time': 306.1063861846924, 'accumulated_logging_time': 4.98514199256897}
I0204 22:06:24.473757 139466119386880 logging_writer.py:48] [25497] accumulated_eval_time=306.106386, accumulated_logging_time=4.985142, accumulated_submission_time=5952.154488, global_step=25497, preemption_count=0, score=5952.154488, test/loss=0.286933, test/num_examples=3581, test/ssim=0.742860, total_duration=6264.277378, train/loss=0.265381, train/ssim=0.750035, validation/loss=0.285525, validation/num_examples=3554, validation/ssim=0.725703
I0204 22:06:24.783170 139461883066112 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.03689449280500412, loss=0.25860199332237244
I0204 22:06:46.913717 139466119386880 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.024650927633047104, loss=0.3484283685684204
I0204 22:07:10.632478 139461883066112 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.042566072195768356, loss=0.24044102430343628
I0204 22:07:34.217614 139466119386880 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.04128362238407135, loss=0.25313764810562134
I0204 22:07:44.479517 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:07:45.850374 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:07:47.168387 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:07:48.488651 139681449744192 submission_runner.py:408] Time since start: 6348.31s, 	Step: 25845, 	{'train/ssim': 0.7496070861816406, 'train/loss': 0.26539559023720877, 'validation/ssim': 0.7255828462427898, 'validation/loss': 0.28537954181248243, 'validation/num_examples': 3554, 'test/ssim': 0.742732231525761, 'test/loss': 0.2867713892003805, 'test/num_examples': 3581, 'score': 6032.137490034103, 'total_duration': 6348.31400680542, 'accumulated_submission_time': 6032.137490034103, 'accumulated_eval_time': 310.115487575531, 'accumulated_logging_time': 5.016194820404053}
I0204 22:07:48.510574 139461883066112 logging_writer.py:48] [25845] accumulated_eval_time=310.115488, accumulated_logging_time=5.016195, accumulated_submission_time=6032.137490, global_step=25845, preemption_count=0, score=6032.137490, test/loss=0.286771, test/num_examples=3581, test/ssim=0.742732, total_duration=6348.314007, train/loss=0.265396, train/ssim=0.749607, validation/loss=0.285380, validation/num_examples=3554, validation/ssim=0.725583
I0204 22:07:59.662560 139466119386880 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.04540183022618294, loss=0.2139325588941574
I0204 22:08:23.939595 139461883066112 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.040155183523893356, loss=0.32333576679229736
I0204 22:08:47.910200 139466119386880 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.0370098352432251, loss=0.2918703556060791
I0204 22:09:08.679455 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:09:10.047529 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:09:11.368899 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:09:12.690263 139681449744192 submission_runner.py:408] Time since start: 6432.52s, 	Step: 26189, 	{'train/ssim': 0.7505412101745605, 'train/loss': 0.2648829051426479, 'validation/ssim': 0.7259142977103263, 'validation/loss': 0.28543772614263857, 'validation/num_examples': 3554, 'test/ssim': 0.743048912118647, 'test/loss': 0.2868577349422298, 'test/num_examples': 3581, 'score': 6112.283630371094, 'total_duration': 6432.515614271164, 'accumulated_submission_time': 6112.283630371094, 'accumulated_eval_time': 314.12628722190857, 'accumulated_logging_time': 5.047453880310059}
I0204 22:09:12.712561 139461883066112 logging_writer.py:48] [26189] accumulated_eval_time=314.126287, accumulated_logging_time=5.047454, accumulated_submission_time=6112.283630, global_step=26189, preemption_count=0, score=6112.283630, test/loss=0.286858, test/num_examples=3581, test/ssim=0.743049, total_duration=6432.515614, train/loss=0.264883, train/ssim=0.750541, validation/loss=0.285438, validation/num_examples=3554, validation/ssim=0.725914
I0204 22:09:13.595367 139466119386880 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.020775863900780678, loss=0.28018760681152344
I0204 22:09:37.311100 139461883066112 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.06771034747362137, loss=0.2571106255054474
I0204 22:10:01.661346 139466119386880 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.02501606196165085, loss=0.40692171454429626
I0204 22:10:25.619401 139461883066112 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.0499236173927784, loss=0.2065919041633606
I0204 22:10:32.840337 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:10:34.211140 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:10:35.529513 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:10:36.848996 139681449744192 submission_runner.py:408] Time since start: 6516.67s, 	Step: 26532, 	{'train/ssim': 0.7501976149422782, 'train/loss': 0.2651327848434448, 'validation/ssim': 0.7257329439539955, 'validation/loss': 0.2854400617591974, 'validation/num_examples': 3554, 'test/ssim': 0.7429106498490295, 'test/loss': 0.28686168918859956, 'test/num_examples': 3581, 'score': 6192.388805150986, 'total_duration': 6516.674349784851, 'accumulated_submission_time': 6192.388805150986, 'accumulated_eval_time': 318.13490319252014, 'accumulated_logging_time': 5.079059839248657}
I0204 22:10:36.870639 139466119386880 logging_writer.py:48] [26532] accumulated_eval_time=318.134903, accumulated_logging_time=5.079060, accumulated_submission_time=6192.388805, global_step=26532, preemption_count=0, score=6192.388805, test/loss=0.286862, test/num_examples=3581, test/ssim=0.742911, total_duration=6516.674350, train/loss=0.265133, train/ssim=0.750198, validation/loss=0.285440, validation/num_examples=3554, validation/ssim=0.725733
I0204 22:10:50.963797 139461883066112 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.07555848360061646, loss=0.3092647194862366
I0204 22:11:14.741248 139466119386880 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.0467853918671608, loss=0.32612740993499756
I0204 22:11:38.423901 139461883066112 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.037487681955099106, loss=0.25942742824554443
I0204 22:11:57.042174 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:11:58.413821 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:11:59.734333 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:12:01.057773 139681449744192 submission_runner.py:408] Time since start: 6600.88s, 	Step: 26880, 	{'train/ssim': 0.7498160089765277, 'train/loss': 0.26521427290780203, 'validation/ssim': 0.7256105988630768, 'validation/loss': 0.2852989973885059, 'validation/num_examples': 3554, 'test/ssim': 0.7427324360557456, 'test/loss': 0.2867100642933189, 'test/num_examples': 3581, 'score': 6272.537399768829, 'total_duration': 6600.883124828339, 'accumulated_submission_time': 6272.537399768829, 'accumulated_eval_time': 322.150488615036, 'accumulated_logging_time': 5.109807968139648}
I0204 22:12:01.091194 139466119386880 logging_writer.py:48] [26880] accumulated_eval_time=322.150489, accumulated_logging_time=5.109808, accumulated_submission_time=6272.537400, global_step=26880, preemption_count=0, score=6272.537400, test/loss=0.286710, test/num_examples=3581, test/ssim=0.742732, total_duration=6600.883125, train/loss=0.265214, train/ssim=0.749816, validation/loss=0.285299, validation/num_examples=3554, validation/ssim=0.725611
I0204 22:12:03.831255 139461883066112 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.0353560671210289, loss=0.22886884212493896
I0204 22:12:28.350990 139466119386880 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.03373909741640091, loss=0.2210886925458908
I0204 22:12:52.061613 139461883066112 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.034199703484773636, loss=0.2820383310317993
I0204 22:13:16.017220 139466119386880 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.03139037266373634, loss=0.35367923974990845
I0204 22:13:21.209273 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:13:22.580239 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:13:23.901017 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:13:25.222632 139681449744192 submission_runner.py:408] Time since start: 6685.05s, 	Step: 27223, 	{'train/ssim': 0.7501500674656459, 'train/loss': 0.2650226354598999, 'validation/ssim': 0.725652296488112, 'validation/loss': 0.2854420195554305, 'validation/num_examples': 3554, 'test/ssim': 0.7427158691269896, 'test/loss': 0.28688998250314157, 'test/num_examples': 3581, 'score': 6352.623078107834, 'total_duration': 6685.047988176346, 'accumulated_submission_time': 6352.623078107834, 'accumulated_eval_time': 326.1638045310974, 'accumulated_logging_time': 5.161976337432861}
I0204 22:13:25.244759 139461883066112 logging_writer.py:48] [27223] accumulated_eval_time=326.163805, accumulated_logging_time=5.161976, accumulated_submission_time=6352.623078, global_step=27223, preemption_count=0, score=6352.623078, test/loss=0.286890, test/num_examples=3581, test/ssim=0.742716, total_duration=6685.047988, train/loss=0.265023, train/ssim=0.750150, validation/loss=0.285442, validation/num_examples=3554, validation/ssim=0.725652
I0204 22:13:41.617002 139466119386880 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.031696464866399765, loss=0.22030799090862274
I0204 22:14:05.518568 139461883066112 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.029654784128069878, loss=0.25872427225112915
I0204 22:14:29.350814 139466119386880 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.0280789602547884, loss=0.3361632525920868
I0204 22:14:45.430455 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:14:46.797547 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:14:48.117361 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:14:49.438235 139681449744192 submission_runner.py:408] Time since start: 6769.26s, 	Step: 27569, 	{'train/ssim': 0.7501449584960938, 'train/loss': 0.2649794135774885, 'validation/ssim': 0.725748056767023, 'validation/loss': 0.28529769219101714, 'validation/num_examples': 3554, 'test/ssim': 0.7429066956026599, 'test/loss': 0.2866826913637078, 'test/num_examples': 3581, 'score': 6432.78490281105, 'total_duration': 6769.26359128952, 'accumulated_submission_time': 6432.78490281105, 'accumulated_eval_time': 330.1715428829193, 'accumulated_logging_time': 5.1945271492004395}
I0204 22:14:49.461787 139461883066112 logging_writer.py:48] [27569] accumulated_eval_time=330.171543, accumulated_logging_time=5.194527, accumulated_submission_time=6432.784903, global_step=27569, preemption_count=0, score=6432.784903, test/loss=0.286683, test/num_examples=3581, test/ssim=0.742907, total_duration=6769.263591, train/loss=0.264979, train/ssim=0.750145, validation/loss=0.285298, validation/num_examples=3554, validation/ssim=0.725748
I0204 22:14:54.691929 139466119386880 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.04482053220272064, loss=0.2986174523830414
I0204 22:15:18.575386 139461883066112 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.02234344370663166, loss=0.36928507685661316
I0204 22:15:42.449869 139466119386880 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.020957812666893005, loss=0.31204262375831604
I0204 22:16:06.710823 139461883066112 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.03418866544961929, loss=0.30386656522750854
I0204 22:16:09.666239 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:16:11.038437 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:16:12.356961 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:16:13.676936 139681449744192 submission_runner.py:408] Time since start: 6853.50s, 	Step: 27914, 	{'train/ssim': 0.7500529289245605, 'train/loss': 0.2651003428867885, 'validation/ssim': 0.7256652110737901, 'validation/loss': 0.2853273510865838, 'validation/num_examples': 3554, 'test/ssim': 0.7428141798729405, 'test/loss': 0.2867274493420134, 'test/num_examples': 3581, 'score': 6512.966456890106, 'total_duration': 6853.502288341522, 'accumulated_submission_time': 6512.966456890106, 'accumulated_eval_time': 334.1822066307068, 'accumulated_logging_time': 5.227466106414795}
I0204 22:16:13.699796 139466119386880 logging_writer.py:48] [27914] accumulated_eval_time=334.182207, accumulated_logging_time=5.227466, accumulated_submission_time=6512.966457, global_step=27914, preemption_count=0, score=6512.966457, test/loss=0.286727, test/num_examples=3581, test/ssim=0.742814, total_duration=6853.502288, train/loss=0.265100, train/ssim=0.750053, validation/loss=0.285327, validation/num_examples=3554, validation/ssim=0.725665
I0204 22:16:32.250555 139461883066112 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.058382246643304825, loss=0.21049000322818756
I0204 22:16:56.750357 139466119386880 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.0581999309360981, loss=0.2181602567434311
I0204 22:17:20.545816 139461883066112 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.033027101308107376, loss=0.36721736192703247
I0204 22:17:33.842287 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:17:35.214087 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:17:36.535610 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:17:37.854556 139681449744192 submission_runner.py:408] Time since start: 6937.68s, 	Step: 28257, 	{'train/ssim': 0.7506343296595982, 'train/loss': 0.26495981216430664, 'validation/ssim': 0.7260884385331668, 'validation/loss': 0.28537514535778347, 'validation/num_examples': 3554, 'test/ssim': 0.7432074910334054, 'test/loss': 0.28680469349954624, 'test/num_examples': 3581, 'score': 6593.085450172424, 'total_duration': 6937.679908514023, 'accumulated_submission_time': 6593.085450172424, 'accumulated_eval_time': 338.1944320201874, 'accumulated_logging_time': 5.260152816772461}
I0204 22:17:37.879087 139466119386880 logging_writer.py:48] [28257] accumulated_eval_time=338.194432, accumulated_logging_time=5.260153, accumulated_submission_time=6593.085450, global_step=28257, preemption_count=0, score=6593.085450, test/loss=0.286805, test/num_examples=3581, test/ssim=0.743207, total_duration=6937.679909, train/loss=0.264960, train/ssim=0.750634, validation/loss=0.285375, validation/num_examples=3554, validation/ssim=0.726088
I0204 22:17:46.106246 139461883066112 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.04306503012776375, loss=0.26341700553894043
I0204 22:18:09.988154 139466119386880 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.04015496000647545, loss=0.22843804955482483
I0204 22:18:33.786449 139461883066112 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.023310193791985512, loss=0.2947671115398407
I0204 22:18:57.428514 139466119386880 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.025998827069997787, loss=0.31183522939682007
I0204 22:18:58.007793 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:18:59.377939 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:19:00.699073 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:19:02.022443 139681449744192 submission_runner.py:408] Time since start: 7021.85s, 	Step: 28604, 	{'train/ssim': 0.7506190027509417, 'train/loss': 0.2649067299706595, 'validation/ssim': 0.7260718144388365, 'validation/loss': 0.28532774608056066, 'validation/num_examples': 3554, 'test/ssim': 0.743204695790282, 'test/loss': 0.28677926360478917, 'test/num_examples': 3581, 'score': 6673.190561294556, 'total_duration': 7021.847796201706, 'accumulated_submission_time': 6673.190561294556, 'accumulated_eval_time': 342.20906805992126, 'accumulated_logging_time': 5.2943854331970215}
I0204 22:19:02.045405 139461883066112 logging_writer.py:48] [28604] accumulated_eval_time=342.209068, accumulated_logging_time=5.294385, accumulated_submission_time=6673.190561, global_step=28604, preemption_count=0, score=6673.190561, test/loss=0.286779, test/num_examples=3581, test/ssim=0.743205, total_duration=7021.847796, train/loss=0.264907, train/ssim=0.750619, validation/loss=0.285328, validation/num_examples=3554, validation/ssim=0.726072
I0204 22:19:22.949420 139466119386880 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.020722931250929832, loss=0.2934834361076355
I0204 22:19:47.031498 139461883066112 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.05160628259181976, loss=0.2690856456756592
I0204 22:20:11.094523 139466119386880 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.020917627960443497, loss=0.3031482398509979
I0204 22:20:22.055288 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:20:23.424752 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:20:24.745971 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:20:26.065901 139681449744192 submission_runner.py:408] Time since start: 7105.89s, 	Step: 28946, 	{'train/ssim': 0.7500931876046317, 'train/loss': 0.2649789367403303, 'validation/ssim': 0.7257242197392023, 'validation/loss': 0.2852500868299803, 'validation/num_examples': 3554, 'test/ssim': 0.7428719255052709, 'test/loss': 0.28663588808555573, 'test/num_examples': 3581, 'score': 6753.176616668701, 'total_duration': 7105.89125585556, 'accumulated_submission_time': 6753.176616668701, 'accumulated_eval_time': 346.21965074539185, 'accumulated_logging_time': 5.327981233596802}
I0204 22:20:26.088114 139461883066112 logging_writer.py:48] [28946] accumulated_eval_time=346.219651, accumulated_logging_time=5.327981, accumulated_submission_time=6753.176617, global_step=28946, preemption_count=0, score=6753.176617, test/loss=0.286636, test/num_examples=3581, test/ssim=0.742872, total_duration=7105.891256, train/loss=0.264979, train/ssim=0.750093, validation/loss=0.285250, validation/num_examples=3554, validation/ssim=0.725724
I0204 22:20:36.785858 139466119386880 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.031828053295612335, loss=0.22491730749607086
I0204 22:21:00.581159 139461883066112 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.04650011658668518, loss=0.18436528742313385
I0204 22:21:25.179594 139466119386880 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.03712041676044464, loss=0.1877855509519577
I0204 22:21:46.235526 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:21:47.608518 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:21:48.927307 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:21:50.249355 139681449744192 submission_runner.py:408] Time since start: 7190.07s, 	Step: 29290, 	{'train/ssim': 0.7503688676016671, 'train/loss': 0.2651293788637434, 'validation/ssim': 0.7259679481965743, 'validation/loss': 0.2854834767493493, 'validation/num_examples': 3554, 'test/ssim': 0.7430520482450782, 'test/loss': 0.2869654199791434, 'test/num_examples': 3581, 'score': 6833.300783395767, 'total_duration': 7190.074701547623, 'accumulated_submission_time': 6833.300783395767, 'accumulated_eval_time': 350.23344373703003, 'accumulated_logging_time': 5.359550714492798}
I0204 22:21:50.271867 139461883066112 logging_writer.py:48] [29290] accumulated_eval_time=350.233444, accumulated_logging_time=5.359551, accumulated_submission_time=6833.300783, global_step=29290, preemption_count=0, score=6833.300783, test/loss=0.286965, test/num_examples=3581, test/ssim=0.743052, total_duration=7190.074702, train/loss=0.265129, train/ssim=0.750369, validation/loss=0.285483, validation/num_examples=3554, validation/ssim=0.725968
I0204 22:21:51.083377 139466119386880 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.032220304012298584, loss=0.29069066047668457
I0204 22:22:14.230707 139461883066112 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.040515441447496414, loss=0.27921897172927856
I0204 22:22:38.455543 139466119386880 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.033801037818193436, loss=0.21288934350013733
I0204 22:23:02.288826 139461883066112 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.030282555148005486, loss=0.25353357195854187
I0204 22:23:10.510422 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:23:11.881679 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:23:13.202127 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:23:14.522444 139681449744192 submission_runner.py:408] Time since start: 7274.35s, 	Step: 29635, 	{'train/ssim': 0.750690392085484, 'train/loss': 0.2648529495511736, 'validation/ssim': 0.7260376732203151, 'validation/loss': 0.2853850373808561, 'validation/num_examples': 3554, 'test/ssim': 0.7431846518517872, 'test/loss': 0.2868040458212615, 'test/num_examples': 3581, 'score': 6913.516995429993, 'total_duration': 7274.34780049324, 'accumulated_submission_time': 6913.516995429993, 'accumulated_eval_time': 354.2454254627228, 'accumulated_logging_time': 5.391098737716675}
I0204 22:23:14.544350 139466119386880 logging_writer.py:48] [29635] accumulated_eval_time=354.245425, accumulated_logging_time=5.391099, accumulated_submission_time=6913.516995, global_step=29635, preemption_count=0, score=6913.516995, test/loss=0.286804, test/num_examples=3581, test/ssim=0.743185, total_duration=7274.347800, train/loss=0.264853, train/ssim=0.750690, validation/loss=0.285385, validation/num_examples=3554, validation/ssim=0.726038
I0204 22:23:27.903550 139461883066112 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.018876176327466965, loss=0.3055282533168793
I0204 22:23:51.714218 139466119386880 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.030464690178632736, loss=0.28520429134368896
I0204 22:24:15.648519 139461883066112 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.028518106788396835, loss=0.24181577563285828
I0204 22:24:34.591025 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:24:35.959204 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:24:37.280234 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:24:38.601364 139681449744192 submission_runner.py:408] Time since start: 7358.43s, 	Step: 29980, 	{'train/ssim': 0.7506021772112165, 'train/loss': 0.2649602379117693, 'validation/ssim': 0.7260679675409749, 'validation/loss': 0.2853407465344946, 'validation/num_examples': 3554, 'test/ssim': 0.7432026504904357, 'test/loss': 0.28675904922464046, 'test/num_examples': 3581, 'score': 6993.540855407715, 'total_duration': 7358.42671585083, 'accumulated_submission_time': 6993.540855407715, 'accumulated_eval_time': 358.25573444366455, 'accumulated_logging_time': 5.422429800033569}
I0204 22:24:38.624593 139466119386880 logging_writer.py:48] [29980] accumulated_eval_time=358.255734, accumulated_logging_time=5.422430, accumulated_submission_time=6993.540855, global_step=29980, preemption_count=0, score=6993.540855, test/loss=0.286759, test/num_examples=3581, test/ssim=0.743203, total_duration=7358.426716, train/loss=0.264960, train/ssim=0.750602, validation/loss=0.285341, validation/num_examples=3554, validation/ssim=0.726068
I0204 22:24:41.396107 139461883066112 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.019956855103373528, loss=0.2951207160949707
I0204 22:25:05.166399 139466119386880 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.018654899671673775, loss=0.23580031096935272
I0204 22:25:29.178736 139461883066112 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.022686222568154335, loss=0.2781037390232086
I0204 22:25:53.688547 139466119386880 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.026818394660949707, loss=0.2183016985654831
I0204 22:25:58.677320 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:26:00.045728 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:26:01.368795 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:26:02.688891 139681449744192 submission_runner.py:408] Time since start: 7442.51s, 	Step: 30322, 	{'train/ssim': 0.750415733882359, 'train/loss': 0.2649151768003191, 'validation/ssim': 0.7259121681775816, 'validation/loss': 0.28531859252448827, 'validation/num_examples': 3554, 'test/ssim': 0.743074205660081, 'test/loss': 0.2867245177455669, 'test/num_examples': 3581, 'score': 7073.571084022522, 'total_duration': 7442.514234781265, 'accumulated_submission_time': 7073.571084022522, 'accumulated_eval_time': 362.267263174057, 'accumulated_logging_time': 5.454789638519287}
I0204 22:26:02.712477 139461883066112 logging_writer.py:48] [30322] accumulated_eval_time=362.267263, accumulated_logging_time=5.454790, accumulated_submission_time=7073.571084, global_step=30322, preemption_count=0, score=7073.571084, test/loss=0.286725, test/num_examples=3581, test/ssim=0.743074, total_duration=7442.514235, train/loss=0.264915, train/ssim=0.750416, validation/loss=0.285319, validation/num_examples=3554, validation/ssim=0.725912
I0204 22:26:19.461043 139466119386880 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.08160042017698288, loss=0.2507100999355316
I0204 22:26:43.188885 139461883066112 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.038572922348976135, loss=0.2250930815935135
I0204 22:27:07.181375 139466119386880 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.032159775495529175, loss=0.32202622294425964
I0204 22:27:22.826068 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:27:24.197065 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:27:25.518603 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:27:26.839729 139681449744192 submission_runner.py:408] Time since start: 7526.67s, 	Step: 30666, 	{'train/ssim': 0.750591686793736, 'train/loss': 0.26462812083108084, 'validation/ssim': 0.7258340624120709, 'validation/loss': 0.2852345790229759, 'validation/num_examples': 3554, 'test/ssim': 0.7429935526694709, 'test/loss': 0.28663183157419364, 'test/num_examples': 3581, 'score': 7153.6601984500885, 'total_duration': 7526.665081501007, 'accumulated_submission_time': 7153.6601984500885, 'accumulated_eval_time': 366.28090047836304, 'accumulated_logging_time': 5.489109992980957}
I0204 22:27:26.862787 139461883066112 logging_writer.py:48] [30666] accumulated_eval_time=366.280900, accumulated_logging_time=5.489110, accumulated_submission_time=7153.660198, global_step=30666, preemption_count=0, score=7153.660198, test/loss=0.286632, test/num_examples=3581, test/ssim=0.742994, total_duration=7526.665082, train/loss=0.264628, train/ssim=0.750592, validation/loss=0.285235, validation/num_examples=3554, validation/ssim=0.725834
I0204 22:27:33.112749 139466119386880 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.024127032607793808, loss=0.29039591550827026
I0204 22:27:56.866837 139461883066112 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.03336897864937782, loss=0.3561789393424988
I0204 22:28:20.638556 139466119386880 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.02734767273068428, loss=0.20991317927837372
I0204 22:28:44.821796 139461883066112 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.021889885887503624, loss=0.2752949595451355
I0204 22:28:46.876428 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:28:48.248488 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:28:49.567360 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:28:50.889096 139681449744192 submission_runner.py:408] Time since start: 7610.71s, 	Step: 31010, 	{'train/ssim': 0.7505792209080288, 'train/loss': 0.26484428133283344, 'validation/ssim': 0.7259497441263365, 'validation/loss': 0.28533076864316614, 'validation/num_examples': 3554, 'test/ssim': 0.7430826595661129, 'test/loss': 0.28677500256344246, 'test/num_examples': 3581, 'score': 7233.649788141251, 'total_duration': 7610.714449882507, 'accumulated_submission_time': 7233.649788141251, 'accumulated_eval_time': 370.2935276031494, 'accumulated_logging_time': 5.52242112159729}
I0204 22:28:50.911916 139466119386880 logging_writer.py:48] [31010] accumulated_eval_time=370.293528, accumulated_logging_time=5.522421, accumulated_submission_time=7233.649788, global_step=31010, preemption_count=0, score=7233.649788, test/loss=0.286775, test/num_examples=3581, test/ssim=0.743083, total_duration=7610.714450, train/loss=0.264844, train/ssim=0.750579, validation/loss=0.285331, validation/num_examples=3554, validation/ssim=0.725950
I0204 22:29:10.241549 139461883066112 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.04082823172211647, loss=0.19972670078277588
I0204 22:29:33.832645 139466119386880 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.03221149742603302, loss=0.21510660648345947
I0204 22:29:57.869905 139461883066112 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.05463675409555435, loss=0.33849504590034485
I0204 22:30:11.077066 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:30:12.444202 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:30:13.762479 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:30:15.084926 139681449744192 submission_runner.py:408] Time since start: 7694.91s, 	Step: 31354, 	{'train/ssim': 0.7504358291625977, 'train/loss': 0.2648018257958548, 'validation/ssim': 0.7258527473445414, 'validation/loss': 0.28525510153612127, 'validation/num_examples': 3554, 'test/ssim': 0.7429784856272689, 'test/loss': 0.28666309057351297, 'test/num_examples': 3581, 'score': 7313.791854381561, 'total_duration': 7694.9102284908295, 'accumulated_submission_time': 7313.791854381561, 'accumulated_eval_time': 374.30131578445435, 'accumulated_logging_time': 5.554333209991455}
I0204 22:30:15.108360 139466119386880 logging_writer.py:48] [31354] accumulated_eval_time=374.301316, accumulated_logging_time=5.554333, accumulated_submission_time=7313.791854, global_step=31354, preemption_count=0, score=7313.791854, test/loss=0.286663, test/num_examples=3581, test/ssim=0.742978, total_duration=7694.910228, train/loss=0.264802, train/ssim=0.750436, validation/loss=0.285255, validation/num_examples=3554, validation/ssim=0.725853
I0204 22:30:24.106178 139461883066112 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.05283266678452492, loss=0.21930813789367676
I0204 22:30:48.298220 139466119386880 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.054109249264001846, loss=0.26047173142433167
I0204 22:31:12.191748 139461883066112 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.0392209030687809, loss=0.21847739815711975
I0204 22:31:35.184588 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:31:36.551701 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:31:37.871730 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:31:39.190206 139681449744192 submission_runner.py:408] Time since start: 7779.02s, 	Step: 31697, 	{'train/ssim': 0.750840391431536, 'train/loss': 0.26459246022360666, 'validation/ssim': 0.726041245339758, 'validation/loss': 0.28527519470798746, 'validation/num_examples': 3554, 'test/ssim': 0.7431663123298311, 'test/loss': 0.2866952699577632, 'test/num_examples': 3581, 'score': 7393.845289468765, 'total_duration': 7779.0155618190765, 'accumulated_submission_time': 7393.845289468765, 'accumulated_eval_time': 378.30689764022827, 'accumulated_logging_time': 5.58677077293396}
I0204 22:31:39.213228 139466119386880 logging_writer.py:48] [31697] accumulated_eval_time=378.306898, accumulated_logging_time=5.586771, accumulated_submission_time=7393.845289, global_step=31697, preemption_count=0, score=7393.845289, test/loss=0.286695, test/num_examples=3581, test/ssim=0.743166, total_duration=7779.015562, train/loss=0.264592, train/ssim=0.750840, validation/loss=0.285275, validation/num_examples=3554, validation/ssim=0.726041
I0204 22:31:39.521495 139461883066112 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.028008142486214638, loss=0.23507483303546906
I0204 22:32:01.638327 139466119386880 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.05667176470160484, loss=0.2184012532234192
I0204 22:32:25.605893 139461883066112 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.03222184628248215, loss=0.30514031648635864
I0204 22:32:49.460386 139466119386880 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.02837938442826271, loss=0.19017304480075836
I0204 22:32:59.318637 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:33:00.691266 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:33:02.010216 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:33:03.331664 139681449744192 submission_runner.py:408] Time since start: 7863.16s, 	Step: 32043, 	{'train/ssim': 0.7502557209559849, 'train/loss': 0.2647336891719273, 'validation/ssim': 0.7255834644942318, 'validation/loss': 0.2852741471152663, 'validation/num_examples': 3554, 'test/ssim': 0.7427708876928582, 'test/loss': 0.2866786007640149, 'test/num_examples': 3581, 'score': 7473.926406145096, 'total_duration': 7863.157017469406, 'accumulated_submission_time': 7473.926406145096, 'accumulated_eval_time': 382.31988549232483, 'accumulated_logging_time': 5.6204071044921875}
I0204 22:33:03.355213 139461883066112 logging_writer.py:48] [32043] accumulated_eval_time=382.319885, accumulated_logging_time=5.620407, accumulated_submission_time=7473.926406, global_step=32043, preemption_count=0, score=7473.926406, test/loss=0.286679, test/num_examples=3581, test/ssim=0.742771, total_duration=7863.157017, train/loss=0.264734, train/ssim=0.750256, validation/loss=0.285274, validation/num_examples=3554, validation/ssim=0.725583
I0204 22:33:14.901674 139466119386880 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.029323760420084, loss=0.3267201781272888
I0204 22:33:38.800866 139461883066112 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.02366762049496174, loss=0.3216046988964081
I0204 22:34:02.715068 139466119386880 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.03480809926986694, loss=0.2948783338069916
I0204 22:34:23.530932 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:34:24.901258 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:34:26.220777 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:34:27.540561 139681449744192 submission_runner.py:408] Time since start: 7947.37s, 	Step: 32388, 	{'train/ssim': 0.7505275181361607, 'train/loss': 0.26482081413269043, 'validation/ssim': 0.7259816184229038, 'validation/loss': 0.2853099026569974, 'validation/num_examples': 3554, 'test/ssim': 0.7431155207169785, 'test/loss': 0.28671190506318067, 'test/num_examples': 3581, 'score': 7554.078770637512, 'total_duration': 7947.365916252136, 'accumulated_submission_time': 7554.078770637512, 'accumulated_eval_time': 386.32947516441345, 'accumulated_logging_time': 5.653552770614624}
I0204 22:34:27.563623 139461883066112 logging_writer.py:48] [32388] accumulated_eval_time=386.329475, accumulated_logging_time=5.653553, accumulated_submission_time=7554.078771, global_step=32388, preemption_count=0, score=7554.078771, test/loss=0.286712, test/num_examples=3581, test/ssim=0.743116, total_duration=7947.365916, train/loss=0.264821, train/ssim=0.750528, validation/loss=0.285310, validation/num_examples=3554, validation/ssim=0.725982
I0204 22:34:28.521238 139466119386880 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.02699233777821064, loss=0.2684176564216614
I0204 22:34:52.567613 139461883066112 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.016482146456837654, loss=0.24908632040023804
I0204 22:35:16.734364 139466119386880 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.028820300474762917, loss=0.2334708869457245
I0204 22:35:40.641273 139461883066112 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.020549515262246132, loss=0.24718396365642548
I0204 22:35:47.566964 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:35:48.940962 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:35:50.259913 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:35:51.580626 139681449744192 submission_runner.py:408] Time since start: 8031.41s, 	Step: 32730, 	{'train/ssim': 0.7509356907435826, 'train/loss': 0.264573335647583, 'validation/ssim': 0.7260761421989308, 'validation/loss': 0.28529200771248064, 'validation/num_examples': 3554, 'test/ssim': 0.7432014914871893, 'test/loss': 0.28671381400970397, 'test/num_examples': 3581, 'score': 7634.058696508408, 'total_duration': 8031.405979156494, 'accumulated_submission_time': 7634.058696508408, 'accumulated_eval_time': 390.34309220314026, 'accumulated_logging_time': 5.686913251876831}
I0204 22:35:51.603791 139466119386880 logging_writer.py:48] [32730] accumulated_eval_time=390.343092, accumulated_logging_time=5.686913, accumulated_submission_time=7634.058697, global_step=32730, preemption_count=0, score=7634.058697, test/loss=0.286714, test/num_examples=3581, test/ssim=0.743201, total_duration=8031.405979, train/loss=0.264573, train/ssim=0.750936, validation/loss=0.285292, validation/num_examples=3554, validation/ssim=0.726076
I0204 22:36:06.155411 139461883066112 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.015662498772144318, loss=0.23234164714813232
I0204 22:36:29.808901 139466119386880 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.025592781603336334, loss=0.21376562118530273
I0204 22:36:53.736321 139461883066112 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.022345632314682007, loss=0.21396401524543762
I0204 22:37:11.729475 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:37:13.100193 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:37:14.421106 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:37:15.743986 139681449744192 submission_runner.py:408] Time since start: 8115.57s, 	Step: 33076, 	{'train/ssim': 0.7511607578822544, 'train/loss': 0.26468498366219656, 'validation/ssim': 0.7264695561998804, 'validation/loss': 0.2852806215817565, 'validation/num_examples': 3554, 'test/ssim': 0.7435912574612539, 'test/loss': 0.28670041729571, 'test/num_examples': 3581, 'score': 7714.161678314209, 'total_duration': 8115.569339990616, 'accumulated_submission_time': 7714.161678314209, 'accumulated_eval_time': 394.3575599193573, 'accumulated_logging_time': 5.719174385070801}
I0204 22:37:15.768418 139466119386880 logging_writer.py:48] [33076] accumulated_eval_time=394.357560, accumulated_logging_time=5.719174, accumulated_submission_time=7714.161678, global_step=33076, preemption_count=0, score=7714.161678, test/loss=0.286700, test/num_examples=3581, test/ssim=0.743591, total_duration=8115.569340, train/loss=0.264685, train/ssim=0.751161, validation/loss=0.285281, validation/num_examples=3554, validation/ssim=0.726470
I0204 22:37:19.590323 139461883066112 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.015710458159446716, loss=0.23435252904891968
I0204 22:37:43.377277 139466119386880 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.016300419345498085, loss=0.288601279258728
I0204 22:38:07.325404 139461883066112 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.01973143219947815, loss=0.32180529832839966
I0204 22:38:31.014834 139466119386880 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.015363046899437904, loss=0.26377546787261963
I0204 22:38:35.777265 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:38:37.148158 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:38:38.468177 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:38:39.790774 139681449744192 submission_runner.py:408] Time since start: 8199.62s, 	Step: 33421, 	{'train/ssim': 0.7507865088326591, 'train/loss': 0.26472517422267366, 'validation/ssim': 0.7260885072277715, 'validation/loss': 0.2852847604316879, 'validation/num_examples': 3554, 'test/ssim': 0.7432023777837894, 'test/loss': 0.28671681378281205, 'test/num_examples': 3581, 'score': 7794.147730350494, 'total_duration': 8199.616106510162, 'accumulated_submission_time': 7794.147730350494, 'accumulated_eval_time': 398.3710045814514, 'accumulated_logging_time': 5.753046751022339}
I0204 22:38:39.818394 139461883066112 logging_writer.py:48] [33421] accumulated_eval_time=398.371005, accumulated_logging_time=5.753047, accumulated_submission_time=7794.147730, global_step=33421, preemption_count=0, score=7794.147730, test/loss=0.286717, test/num_examples=3581, test/ssim=0.743202, total_duration=8199.616107, train/loss=0.264725, train/ssim=0.750787, validation/loss=0.285285, validation/num_examples=3554, validation/ssim=0.726089
I0204 22:38:56.887668 139466119386880 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.026006195694208145, loss=0.2222137749195099
I0204 22:39:21.315257 139461883066112 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.01893610507249832, loss=0.29815566539764404
I0204 22:39:45.220225 139466119386880 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.020066317170858383, loss=0.2486676275730133
I0204 22:39:59.903218 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:40:01.274519 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:40:02.594858 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:40:03.915816 139681449744192 submission_runner.py:408] Time since start: 8283.74s, 	Step: 33763, 	{'train/ssim': 0.750774656023298, 'train/loss': 0.26458351952689035, 'validation/ssim': 0.726001814636677, 'validation/loss': 0.28524426496223443, 'validation/num_examples': 3554, 'test/ssim': 0.7431103392907009, 'test/loss': 0.28667935070729195, 'test/num_examples': 3581, 'score': 7874.208901643753, 'total_duration': 8283.741166591644, 'accumulated_submission_time': 7874.208901643753, 'accumulated_eval_time': 402.38356733322144, 'accumulated_logging_time': 5.791030645370483}
I0204 22:40:03.940562 139461883066112 logging_writer.py:48] [33763] accumulated_eval_time=402.383567, accumulated_logging_time=5.791031, accumulated_submission_time=7874.208902, global_step=33763, preemption_count=0, score=7874.208902, test/loss=0.286679, test/num_examples=3581, test/ssim=0.743110, total_duration=8283.741167, train/loss=0.264584, train/ssim=0.750775, validation/loss=0.285244, validation/num_examples=3554, validation/ssim=0.726002
I0204 22:40:10.729282 139466119386880 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.02049868367612362, loss=0.2382761836051941
I0204 22:40:34.684326 139461883066112 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.018311917781829834, loss=0.28577157855033875
I0204 22:40:58.500700 139466119386880 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.0204661563038826, loss=0.3971157968044281
I0204 22:41:22.412438 139461883066112 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.02199704386293888, loss=0.217166006565094
I0204 22:41:24.017134 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:41:25.386695 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:41:26.709333 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:41:28.033944 139681449744192 submission_runner.py:408] Time since start: 8367.86s, 	Step: 34108, 	{'train/ssim': 0.7508078983851841, 'train/loss': 0.26457490239824566, 'validation/ssim': 0.726052923422552, 'validation/loss': 0.28519605852340674, 'validation/num_examples': 3554, 'test/ssim': 0.7431852654417411, 'test/loss': 0.286617480386938, 'test/num_examples': 3581, 'score': 7954.2614159584045, 'total_duration': 8367.859296798706, 'accumulated_submission_time': 7954.2614159584045, 'accumulated_eval_time': 406.400333404541, 'accumulated_logging_time': 5.826385736465454}
I0204 22:41:28.058074 139466119386880 logging_writer.py:48] [34108] accumulated_eval_time=406.400333, accumulated_logging_time=5.826386, accumulated_submission_time=7954.261416, global_step=34108, preemption_count=0, score=7954.261416, test/loss=0.286617, test/num_examples=3581, test/ssim=0.743185, total_duration=8367.859297, train/loss=0.264575, train/ssim=0.750808, validation/loss=0.285196, validation/num_examples=3554, validation/ssim=0.726053
I0204 22:41:47.883419 139461883066112 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.01899145543575287, loss=0.3113645315170288
I0204 22:42:11.746230 139466119386880 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.019029034301638603, loss=0.2351408749818802
I0204 22:42:36.049649 139461883066112 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.019084131345152855, loss=0.2065209597349167
I0204 22:42:48.136951 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:42:49.509258 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:42:50.828262 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:42:52.148949 139681449744192 submission_runner.py:408] Time since start: 8451.97s, 	Step: 34452, 	{'train/ssim': 0.7507697514125279, 'train/loss': 0.26462178570883615, 'validation/ssim': 0.7260702344629291, 'validation/loss': 0.2852324323165799, 'validation/num_examples': 3554, 'test/ssim': 0.7431785841289095, 'test/loss': 0.28665889770882785, 'test/num_examples': 3581, 'score': 8034.315863609314, 'total_duration': 8451.97430229187, 'accumulated_submission_time': 8034.315863609314, 'accumulated_eval_time': 410.41228795051575, 'accumulated_logging_time': 5.861198663711548}
I0204 22:42:52.174741 139466119386880 logging_writer.py:48] [34452] accumulated_eval_time=410.412288, accumulated_logging_time=5.861199, accumulated_submission_time=8034.315864, global_step=34452, preemption_count=0, score=8034.315864, test/loss=0.286659, test/num_examples=3581, test/ssim=0.743179, total_duration=8451.974302, train/loss=0.264622, train/ssim=0.750770, validation/loss=0.285232, validation/num_examples=3554, validation/ssim=0.726070
I0204 22:43:01.795479 139461883066112 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.021958716213703156, loss=0.23864886164665222
I0204 22:43:25.965168 139466119386880 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.016958415508270264, loss=0.24245479702949524
I0204 22:43:49.767587 139461883066112 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.031273432075977325, loss=0.3458395302295685
I0204 22:44:12.180340 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:44:13.549484 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:44:14.871822 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:44:16.190921 139681449744192 submission_runner.py:408] Time since start: 8536.02s, 	Step: 34795, 	{'train/ssim': 0.7505358287266323, 'train/loss': 0.2645829575402396, 'validation/ssim': 0.725791059589547, 'validation/loss': 0.2851932420446152, 'validation/num_examples': 3554, 'test/ssim': 0.7429303529042167, 'test/loss': 0.2866116853707065, 'test/num_examples': 3581, 'score': 8114.298360586166, 'total_duration': 8536.016276597977, 'accumulated_submission_time': 8114.298360586166, 'accumulated_eval_time': 414.4228415489197, 'accumulated_logging_time': 5.896820545196533}
I0204 22:44:16.215650 139466119386880 logging_writer.py:48] [34795] accumulated_eval_time=414.422842, accumulated_logging_time=5.896821, accumulated_submission_time=8114.298361, global_step=34795, preemption_count=0, score=8114.298361, test/loss=0.286612, test/num_examples=3581, test/ssim=0.742930, total_duration=8536.016277, train/loss=0.264583, train/ssim=0.750536, validation/loss=0.285193, validation/num_examples=3554, validation/ssim=0.725791
I0204 22:44:16.667336 139461883066112 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.020069969817996025, loss=0.31392693519592285
I0204 22:44:39.166155 139466119386880 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.023107871413230896, loss=0.17872129380702972
I0204 22:45:03.203482 139461883066112 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.01730557158589363, loss=0.24014443159103394
I0204 22:45:27.147627 139466119386880 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.018597638234496117, loss=0.2201746106147766
I0204 22:45:36.331539 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:45:37.701448 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:45:39.021380 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:45:40.344623 139681449744192 submission_runner.py:408] Time since start: 8620.17s, 	Step: 35140, 	{'train/ssim': 0.7508696147373745, 'train/loss': 0.26455746378217426, 'validation/ssim': 0.7261189389376407, 'validation/loss': 0.2851793829081229, 'validation/num_examples': 3554, 'test/ssim': 0.7432427383674253, 'test/loss': 0.2865960729152122, 'test/num_examples': 3581, 'score': 8194.391567707062, 'total_duration': 8620.169978618622, 'accumulated_submission_time': 8194.391567707062, 'accumulated_eval_time': 418.43588304519653, 'accumulated_logging_time': 5.930956602096558}
I0204 22:45:40.368093 139461883066112 logging_writer.py:48] [35140] accumulated_eval_time=418.435883, accumulated_logging_time=5.930957, accumulated_submission_time=8194.391568, global_step=35140, preemption_count=0, score=8194.391568, test/loss=0.286596, test/num_examples=3581, test/ssim=0.743243, total_duration=8620.169979, train/loss=0.264557, train/ssim=0.750870, validation/loss=0.285179, validation/num_examples=3554, validation/ssim=0.726119
I0204 22:45:52.864427 139466119386880 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.01810835301876068, loss=0.21710586547851562
I0204 22:46:16.619006 139461883066112 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.023052029311656952, loss=0.28995248675346375
I0204 22:46:40.228099 139466119386880 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.013728578574955463, loss=0.24601346254348755
I0204 22:47:00.551132 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:47:01.923403 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:47:03.243882 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:47:04.564109 139681449744192 submission_runner.py:408] Time since start: 8704.39s, 	Step: 35487, 	{'train/ssim': 0.750948292868478, 'train/loss': 0.26458047117505756, 'validation/ssim': 0.7261771232677968, 'validation/loss': 0.2852134039110861, 'validation/num_examples': 3554, 'test/ssim': 0.7433055290727102, 'test/loss': 0.2866312520725705, 'test/num_examples': 3581, 'score': 8274.552117347717, 'total_duration': 8704.389466524124, 'accumulated_submission_time': 8274.552117347717, 'accumulated_eval_time': 422.4488196372986, 'accumulated_logging_time': 5.9632744789123535}
I0204 22:47:04.588021 139461883066112 logging_writer.py:48] [35487] accumulated_eval_time=422.448820, accumulated_logging_time=5.963274, accumulated_submission_time=8274.552117, global_step=35487, preemption_count=0, score=8274.552117, test/loss=0.286631, test/num_examples=3581, test/ssim=0.743306, total_duration=8704.389467, train/loss=0.264580, train/ssim=0.750948, validation/loss=0.285213, validation/num_examples=3554, validation/ssim=0.726177
I0204 22:47:05.623215 139466119386880 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.022492796182632446, loss=0.31879502534866333
I0204 22:47:29.558956 139461883066112 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.01708933711051941, loss=0.2018677294254303
I0204 22:47:53.635618 139466119386880 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.02706582471728325, loss=0.20897358655929565
I0204 22:48:17.599415 139461883066112 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.024949679151177406, loss=0.23503316938877106
I0204 22:48:24.612657 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:48:25.983261 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:48:27.302931 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:48:28.621752 139681449744192 submission_runner.py:408] Time since start: 8788.45s, 	Step: 35830, 	{'train/ssim': 0.7509431838989258, 'train/loss': 0.26457313128880094, 'validation/ssim': 0.7261721085616559, 'validation/loss': 0.2852237767963914, 'validation/num_examples': 3554, 'test/ssim': 0.7432949616901704, 'test/loss': 0.28664604640812624, 'test/num_examples': 3581, 'score': 8354.554366588593, 'total_duration': 8788.44710612297, 'accumulated_submission_time': 8354.554366588593, 'accumulated_eval_time': 426.4578926563263, 'accumulated_logging_time': 5.996220350265503}
I0204 22:48:28.646341 139466119386880 logging_writer.py:48] [35830] accumulated_eval_time=426.457893, accumulated_logging_time=5.996220, accumulated_submission_time=8354.554367, global_step=35830, preemption_count=0, score=8354.554367, test/loss=0.286646, test/num_examples=3581, test/ssim=0.743295, total_duration=8788.447106, train/loss=0.264573, train/ssim=0.750943, validation/loss=0.285224, validation/num_examples=3554, validation/ssim=0.726172
I0204 22:48:43.390337 139461883066112 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.023638134822249413, loss=0.19030463695526123
I0204 22:49:07.262423 139466119386880 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.024383950978517532, loss=0.30215755105018616
I0204 22:49:30.953136 139461883066112 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.017743133008480072, loss=0.24440814554691315
I0204 22:49:48.647796 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:49:50.019180 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:49:51.339726 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:49:52.659270 139681449744192 submission_runner.py:408] Time since start: 8872.48s, 	Step: 36175, 	{'train/ssim': 0.7508655956813267, 'train/loss': 0.2645613465990339, 'validation/ssim': 0.7261112451419176, 'validation/loss': 0.28519578374498805, 'validation/num_examples': 3554, 'test/ssim': 0.7432375569411477, 'test/loss': 0.2866142079071837, 'test/num_examples': 3581, 'score': 8434.533107995987, 'total_duration': 8872.484619140625, 'accumulated_submission_time': 8434.533107995987, 'accumulated_eval_time': 430.4693253040314, 'accumulated_logging_time': 6.029922008514404}
I0204 22:49:52.684496 139466119386880 logging_writer.py:48] [36175] accumulated_eval_time=430.469325, accumulated_logging_time=6.029922, accumulated_submission_time=8434.533108, global_step=36175, preemption_count=0, score=8434.533108, test/loss=0.286614, test/num_examples=3581, test/ssim=0.743238, total_duration=8872.484619, train/loss=0.264561, train/ssim=0.750866, validation/loss=0.285196, validation/num_examples=3554, validation/ssim=0.726111
I0204 22:49:53.649936 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:49:55.023763 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:49:56.346547 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:49:57.667419 139681449744192 submission_runner.py:408] Time since start: 8877.49s, 	Step: 36189, 	{'train/ssim': 0.7508655956813267, 'train/loss': 0.2645613465990339, 'validation/ssim': 0.7261113138365223, 'validation/loss': 0.28519578374498805, 'validation/num_examples': 3554, 'test/ssim': 0.7432375569411477, 'test/loss': 0.2866142079071837, 'test/num_examples': 3581, 'score': 8435.488661050797, 'total_duration': 8877.492777347565, 'accumulated_submission_time': 8435.488661050797, 'accumulated_eval_time': 434.4867742061615, 'accumulated_logging_time': 6.064191818237305}
I0204 22:49:57.692277 139461883066112 logging_writer.py:48] [36189] accumulated_eval_time=434.486774, accumulated_logging_time=6.064192, accumulated_submission_time=8435.488661, global_step=36189, preemption_count=0, score=8435.488661, test/loss=0.286614, test/num_examples=3581, test/ssim=0.743238, total_duration=8877.492777, train/loss=0.264561, train/ssim=0.750866, validation/loss=0.285196, validation/num_examples=3554, validation/ssim=0.726111
I0204 22:49:57.713243 139466119386880 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8435.488661
I0204 22:49:57.788362 139681449744192 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 22:49:58.055256 139681449744192 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2/checkpoint_36189
I0204 22:49:58.056411 139681449744192 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_2/checkpoint_36189.
I0204 22:49:59.023801 139681449744192 submission_runner.py:583] Tuning trial 2/5
I0204 22:49:59.024063 139681449744192 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0204 22:49:59.029471 139681449744192 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 28.97892165184021, 'total_duration': 32.935672760009766, 'accumulated_submission_time': 28.97892165184021, 'accumulated_eval_time': 3.9566385746002197, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (344, {'train/ssim': 0.6935643468584333, 'train/loss': 0.3145843914576939, 'validation/ssim': 0.6709493402020611, 'validation/loss': 0.33355390025983045, 'validation/num_examples': 3554, 'test/ssim': 0.689466828508971, 'test/loss': 0.3352491202483594, 'test/num_examples': 3581, 'score': 109.12077069282532, 'total_duration': 117.11503720283508, 'accumulated_submission_time': 109.12077069282532, 'accumulated_eval_time': 7.961894273757935, 'accumulated_logging_time': 0.018034934997558594, 'global_step': 344, 'preemption_count': 0}), (686, {'train/ssim': 0.7199602808271136, 'train/loss': 0.29291772842407227, 'validation/ssim': 0.6985059747819359, 'validation/loss': 0.3106455547996096, 'validation/num_examples': 3554, 'test/ssim': 0.7157858151092572, 'test/loss': 0.3128802553297787, 'test/num_examples': 3581, 'score': 189.2466561794281, 'total_duration': 201.29289603233337, 'accumulated_submission_time': 189.2466561794281, 'accumulated_eval_time': 11.97603702545166, 'accumulated_logging_time': 0.042139530181884766, 'global_step': 686, 'preemption_count': 0}), (1026, {'train/ssim': 0.7229129927498954, 'train/loss': 0.2882750374930246, 'validation/ssim': 0.7015023647430711, 'validation/loss': 0.3057712604305888, 'validation/num_examples': 3554, 'test/ssim': 0.7185578781677604, 'test/loss': 0.30788062212021783, 'test/num_examples': 3581, 'score': 269.41495633125305, 'total_duration': 290.7165720462799, 'accumulated_submission_time': 269.41495633125305, 'accumulated_eval_time': 21.19350576400757, 'accumulated_logging_time': 0.06583929061889648, 'global_step': 1026, 'preemption_count': 0}), (1372, {'train/ssim': 0.7301158223833356, 'train/loss': 0.28062810216631207, 'validation/ssim': 0.7081162812807752, 'validation/loss': 0.298456384146824, 'validation/num_examples': 3554, 'test/ssim': 0.7253081857808573, 'test/loss': 0.3003164896982337, 'test/num_examples': 3581, 'score': 349.4108908176422, 'total_duration': 374.75886607170105, 'accumulated_submission_time': 349.4108908176422, 'accumulated_eval_time': 25.201108932495117, 'accumulated_logging_time': 0.09012818336486816, 'global_step': 1372, 'preemption_count': 0}), (1718, {'train/ssim': 0.7308858462742397, 'train/loss': 0.2795077732631138, 'validation/ssim': 0.7087743068989167, 'validation/loss': 0.29765241684105936, 'validation/num_examples': 3554, 'test/ssim': 0.7260523340416434, 'test/loss': 0.29939467305745604, 'test/num_examples': 3581, 'score': 429.46006417274475, 'total_duration': 458.8567945957184, 'accumulated_submission_time': 429.46006417274475, 'accumulated_eval_time': 29.209868669509888, 'accumulated_logging_time': 0.1150052547454834, 'global_step': 1718, 'preemption_count': 0}), (2062, {'train/ssim': 0.733593395778111, 'train/loss': 0.27726246629442486, 'validation/ssim': 0.7119433264015897, 'validation/loss': 0.2949803341085748, 'validation/num_examples': 3554, 'test/ssim': 0.7291415549296635, 'test/loss': 0.2966512101084718, 'test/num_examples': 3581, 'score': 509.4550085067749, 'total_duration': 542.9577581882477, 'accumulated_submission_time': 509.4550085067749, 'accumulated_eval_time': 33.27567386627197, 'accumulated_logging_time': 0.14037585258483887, 'global_step': 2062, 'preemption_count': 0}), (2407, {'train/ssim': 0.734459672655378, 'train/loss': 0.2773699590138027, 'validation/ssim': 0.7120967901484243, 'validation/loss': 0.29588926677027644, 'validation/num_examples': 3554, 'test/ssim': 0.7290389490540352, 'test/loss': 0.2977179362433678, 'test/num_examples': 3581, 'score': 589.4221696853638, 'total_duration': 626.9751617908478, 'accumulated_submission_time': 589.4221696853638, 'accumulated_eval_time': 37.286170959472656, 'accumulated_logging_time': 0.1653282642364502, 'global_step': 2407, 'preemption_count': 0}), (2754, {'train/ssim': 0.7358302388872419, 'train/loss': 0.2762782233101981, 'validation/ssim': 0.7136425561427265, 'validation/loss': 0.2941995168845843, 'validation/num_examples': 3554, 'test/ssim': 0.730638373533929, 'test/loss': 0.2960094631933294, 'test/num_examples': 3581, 'score': 669.4945640563965, 'total_duration': 711.0966486930847, 'accumulated_submission_time': 669.4945640563965, 'accumulated_eval_time': 41.29489207267761, 'accumulated_logging_time': 0.19099879264831543, 'global_step': 2754, 'preemption_count': 0}), (3099, {'train/ssim': 0.7383593831743512, 'train/loss': 0.27408415930611746, 'validation/ssim': 0.7162388687262592, 'validation/loss': 0.2921760829567037, 'validation/num_examples': 3554, 'test/ssim': 0.733525927857093, 'test/loss': 0.2937576562390917, 'test/num_examples': 3581, 'score': 749.650426864624, 'total_duration': 795.2993674278259, 'accumulated_submission_time': 749.650426864624, 'accumulated_eval_time': 45.30148363113403, 'accumulated_logging_time': 0.21605563163757324, 'global_step': 3099, 'preemption_count': 0}), (3446, {'train/ssim': 0.7405399594988141, 'train/loss': 0.2721844060080392, 'validation/ssim': 0.7177803069604671, 'validation/loss': 0.29077900643421145, 'validation/num_examples': 3554, 'test/ssim': 0.7349211632356535, 'test/loss': 0.2923777265210486, 'test/num_examples': 3581, 'score': 829.7700300216675, 'total_duration': 879.4692540168762, 'accumulated_submission_time': 829.7700300216675, 'accumulated_eval_time': 49.31132197380066, 'accumulated_logging_time': 0.2427656650543213, 'global_step': 3446, 'preemption_count': 0}), (3794, {'train/ssim': 0.7399829455784389, 'train/loss': 0.27304991653987337, 'validation/ssim': 0.718139854521314, 'validation/loss': 0.2910478084222883, 'validation/num_examples': 3554, 'test/ssim': 0.7352366848252933, 'test/loss': 0.2926671705376466, 'test/num_examples': 3581, 'score': 909.8821904659271, 'total_duration': 963.6286108493805, 'accumulated_submission_time': 909.8821904659271, 'accumulated_eval_time': 53.319082260131836, 'accumulated_logging_time': 0.2685549259185791, 'global_step': 3794, 'preemption_count': 0}), (4139, {'train/ssim': 0.740879876273019, 'train/loss': 0.2725841488157, 'validation/ssim': 0.7185715314170653, 'validation/loss': 0.2911185295177969, 'validation/num_examples': 3554, 'test/ssim': 0.7357221708321697, 'test/loss': 0.2926931117573653, 'test/num_examples': 3581, 'score': 990.0270144939423, 'total_duration': 1047.8274364471436, 'accumulated_submission_time': 990.0270144939423, 'accumulated_eval_time': 57.33399033546448, 'accumulated_logging_time': 0.29384326934814453, 'global_step': 4139, 'preemption_count': 0}), (4482, {'train/ssim': 0.7423781667436872, 'train/loss': 0.2707956518445696, 'validation/ssim': 0.7193415979354248, 'validation/loss': 0.28956482929665517, 'validation/num_examples': 3554, 'test/ssim': 0.7364936579342363, 'test/loss': 0.29111570833915107, 'test/num_examples': 3581, 'score': 1070.1156814098358, 'total_duration': 1131.9665739536285, 'accumulated_submission_time': 1070.1156814098358, 'accumulated_eval_time': 61.34604811668396, 'accumulated_logging_time': 0.31891942024230957, 'global_step': 4482, 'preemption_count': 0}), (4829, {'train/ssim': 0.7408492905752999, 'train/loss': 0.2728027275630406, 'validation/ssim': 0.7187132483865011, 'validation/loss': 0.2910806444433209, 'validation/num_examples': 3554, 'test/ssim': 0.7358825223401284, 'test/loss': 0.2924860592362469, 'test/num_examples': 3581, 'score': 1150.3168470859528, 'total_duration': 1216.2242138385773, 'accumulated_submission_time': 1150.3168470859528, 'accumulated_eval_time': 65.3628830909729, 'accumulated_logging_time': 0.34461069107055664, 'global_step': 4829, 'preemption_count': 0}), (5173, {'train/ssim': 0.7423981257847377, 'train/loss': 0.27085842405046734, 'validation/ssim': 0.719932715008617, 'validation/loss': 0.2893769839001829, 'validation/num_examples': 3554, 'test/ssim': 0.7370365486901355, 'test/loss': 0.29088963452946104, 'test/num_examples': 3581, 'score': 1230.4913923740387, 'total_duration': 1300.4513957500458, 'accumulated_submission_time': 1230.4913923740387, 'accumulated_eval_time': 69.37438464164734, 'accumulated_logging_time': 0.3716864585876465, 'global_step': 5173, 'preemption_count': 0}), (5516, {'train/ssim': 0.7416613442557198, 'train/loss': 0.2711343594959804, 'validation/ssim': 0.7192231684369724, 'validation/loss': 0.28979876877286154, 'validation/num_examples': 3554, 'test/ssim': 0.736393915478393, 'test/loss': 0.29126501522793913, 'test/num_examples': 3581, 'score': 1310.5437569618225, 'total_duration': 1384.5558178424835, 'accumulated_submission_time': 1310.5437569618225, 'accumulated_eval_time': 73.38616728782654, 'accumulated_logging_time': 0.3977348804473877, 'global_step': 5516, 'preemption_count': 0}), (5862, {'train/ssim': 0.742295469556536, 'train/loss': 0.2712622029440744, 'validation/ssim': 0.7193490169527293, 'validation/loss': 0.290077462784011, 'validation/num_examples': 3554, 'test/ssim': 0.736499725657114, 'test/loss': 0.29165345175710344, 'test/num_examples': 3581, 'score': 1390.7154486179352, 'total_duration': 1468.7736823558807, 'accumulated_submission_time': 1390.7154486179352, 'accumulated_eval_time': 77.39232563972473, 'accumulated_logging_time': 0.42411279678344727, 'global_step': 5862, 'preemption_count': 0}), (6208, {'train/ssim': 0.7428860664367676, 'train/loss': 0.2708876473563058, 'validation/ssim': 0.7201298685240223, 'validation/loss': 0.28948631136351644, 'validation/num_examples': 3554, 'test/ssim': 0.737248850814193, 'test/loss': 0.29103433949359464, 'test/num_examples': 3581, 'score': 1470.9021430015564, 'total_duration': 1553.0145823955536, 'accumulated_submission_time': 1470.9021430015564, 'accumulated_eval_time': 81.4054057598114, 'accumulated_logging_time': 0.45113205909729004, 'global_step': 6208, 'preemption_count': 0}), (6552, {'train/ssim': 0.7417918613978794, 'train/loss': 0.27284441675458637, 'validation/ssim': 0.7196870631023143, 'validation/loss': 0.29140965725239165, 'validation/num_examples': 3554, 'test/ssim': 0.7366234662978218, 'test/loss': 0.2930313361753002, 'test/num_examples': 3581, 'score': 1551.0724306106567, 'total_duration': 1637.238983631134, 'accumulated_submission_time': 1551.0724306106567, 'accumulated_eval_time': 85.41960525512695, 'accumulated_logging_time': 0.4771711826324463, 'global_step': 6552, 'preemption_count': 0}), (6899, {'train/ssim': 0.7451910972595215, 'train/loss': 0.2698579856327602, 'validation/ssim': 0.7226475944798115, 'validation/loss': 0.288501505510956, 'validation/num_examples': 3554, 'test/ssim': 0.7397011653300405, 'test/loss': 0.2900458460778239, 'test/num_examples': 3581, 'score': 1631.3222754001617, 'total_duration': 1721.5402591228485, 'accumulated_submission_time': 1631.3222754001617, 'accumulated_eval_time': 89.430344581604, 'accumulated_logging_time': 0.5038919448852539, 'global_step': 6899, 'preemption_count': 0}), (7245, {'train/ssim': 0.7445575850350517, 'train/loss': 0.26946187019348145, 'validation/ssim': 0.7216776953564645, 'validation/loss': 0.2881723553126759, 'validation/num_examples': 3554, 'test/ssim': 0.7388482752940868, 'test/loss': 0.2896346044553721, 'test/num_examples': 3581, 'score': 1711.325751543045, 'total_duration': 1805.5942947864532, 'accumulated_submission_time': 1711.325751543045, 'accumulated_eval_time': 93.44122433662415, 'accumulated_logging_time': 0.5299606323242188, 'global_step': 7245, 'preemption_count': 0}), (7589, {'train/ssim': 0.7447182791573661, 'train/loss': 0.2695349454879761, 'validation/ssim': 0.7220469288565701, 'validation/loss': 0.28818197255732975, 'validation/num_examples': 3554, 'test/ssim': 0.7392248831724728, 'test/loss': 0.2897060195083426, 'test/num_examples': 3581, 'score': 1791.4902153015137, 'total_duration': 1889.8089570999146, 'accumulated_submission_time': 1791.4902153015137, 'accumulated_eval_time': 97.45112013816833, 'accumulated_logging_time': 0.5566811561584473, 'global_step': 7589, 'preemption_count': 0}), (7935, {'train/ssim': 0.7456581251961845, 'train/loss': 0.26898149081638884, 'validation/ssim': 0.722861578173361, 'validation/loss': 0.28791280992257845, 'validation/num_examples': 3554, 'test/ssim': 0.7399333750392697, 'test/loss': 0.28943982373333216, 'test/num_examples': 3581, 'score': 1871.5134434700012, 'total_duration': 1973.8852660655975, 'accumulated_submission_time': 1871.5134434700012, 'accumulated_eval_time': 101.46298694610596, 'accumulated_logging_time': 0.5842244625091553, 'global_step': 7935, 'preemption_count': 0}), (8282, {'train/ssim': 0.7454793793814523, 'train/loss': 0.2688144786017282, 'validation/ssim': 0.7226394885164603, 'validation/loss': 0.2876635858968328, 'validation/num_examples': 3554, 'test/ssim': 0.7398233379075329, 'test/loss': 0.2890387063451201, 'test/num_examples': 3581, 'score': 1951.6899888515472, 'total_duration': 2058.11745595932, 'accumulated_submission_time': 1951.6899888515472, 'accumulated_eval_time': 105.47749543190002, 'accumulated_logging_time': 0.6115193367004395, 'global_step': 8282, 'preemption_count': 0}), (8625, {'train/ssim': 0.7453502927507673, 'train/loss': 0.26966796602521625, 'validation/ssim': 0.7224195283923045, 'validation/loss': 0.2886448368036016, 'validation/num_examples': 3554, 'test/ssim': 0.7396019682874895, 'test/loss': 0.2900541977188634, 'test/num_examples': 3581, 'score': 2031.8050429821014, 'total_duration': 2142.290014743805, 'accumulated_submission_time': 2031.8050429821014, 'accumulated_eval_time': 109.49516701698303, 'accumulated_logging_time': 0.6374204158782959, 'global_step': 8625, 'preemption_count': 0}), (8971, {'train/ssim': 0.7453242710658482, 'train/loss': 0.26875131470816477, 'validation/ssim': 0.7227986539154826, 'validation/loss': 0.28777392660558526, 'validation/num_examples': 3554, 'test/ssim': 0.7398632894311994, 'test/loss': 0.28923692998856815, 'test/num_examples': 3581, 'score': 2111.8292939662933, 'total_duration': 2226.365335702896, 'accumulated_submission_time': 2111.8292939662933, 'accumulated_eval_time': 113.50512456893921, 'accumulated_logging_time': 0.6649777889251709, 'global_step': 8971, 'preemption_count': 0}), (9316, {'train/ssim': 0.7449782235281808, 'train/loss': 0.270092248916626, 'validation/ssim': 0.7226653863824212, 'validation/loss': 0.2887455774413513, 'validation/num_examples': 3554, 'test/ssim': 0.7397393442605068, 'test/loss': 0.2901880625938111, 'test/num_examples': 3581, 'score': 2191.909622192383, 'total_duration': 2310.495637178421, 'accumulated_submission_time': 2191.909622192383, 'accumulated_eval_time': 117.51276755332947, 'accumulated_logging_time': 0.6933310031890869, 'global_step': 9316, 'preemption_count': 0}), (9658, {'train/ssim': 0.7451615333557129, 'train/loss': 0.2685591323035104, 'validation/ssim': 0.7224965350441404, 'validation/loss': 0.2872988003723797, 'validation/num_examples': 3554, 'test/ssim': 0.7397383216105836, 'test/loss': 0.2886718136410046, 'test/num_examples': 3581, 'score': 2271.9167654514313, 'total_duration': 2394.5573313236237, 'accumulated_submission_time': 2271.9167654514313, 'accumulated_eval_time': 121.52645993232727, 'accumulated_logging_time': 0.7202789783477783, 'global_step': 9658, 'preemption_count': 0}), (10003, {'train/ssim': 0.7457009043012347, 'train/loss': 0.2682241712297712, 'validation/ssim': 0.7223576345534961, 'validation/loss': 0.28739097135819675, 'validation/num_examples': 3554, 'test/ssim': 0.7395914690816113, 'test/loss': 0.2888142346869764, 'test/num_examples': 3581, 'score': 2351.937286376953, 'total_duration': 2478.6354858875275, 'accumulated_submission_time': 2351.937286376953, 'accumulated_eval_time': 125.54268622398376, 'accumulated_logging_time': 0.7473556995391846, 'global_step': 10003, 'preemption_count': 0}), (10348, {'train/ssim': 0.7455603054591587, 'train/loss': 0.268939733505249, 'validation/ssim': 0.7225909901255627, 'validation/loss': 0.2879494069732168, 'validation/num_examples': 3554, 'test/ssim': 0.7397801820807736, 'test/loss': 0.289362784105784, 'test/num_examples': 3581, 'score': 2431.914649963379, 'total_duration': 2562.67041516304, 'accumulated_submission_time': 2431.914649963379, 'accumulated_eval_time': 129.55689525604248, 'accumulated_logging_time': 0.7765707969665527, 'global_step': 10348, 'preemption_count': 0}), (10692, {'train/ssim': 0.7455687522888184, 'train/loss': 0.26831391879490446, 'validation/ssim': 0.722452364413337, 'validation/loss': 0.2873520215173484, 'validation/num_examples': 3554, 'test/ssim': 0.7395841060021642, 'test/loss': 0.2888140642453225, 'test/num_examples': 3581, 'score': 2511.8980689048767, 'total_duration': 2646.7047917842865, 'accumulated_submission_time': 2511.8980689048767, 'accumulated_eval_time': 133.56716871261597, 'accumulated_logging_time': 0.8033936023712158, 'global_step': 10692, 'preemption_count': 0}), (11038, {'train/ssim': 0.7464522634233747, 'train/loss': 0.2678736788885934, 'validation/ssim': 0.7229895562218627, 'validation/loss': 0.2872696051653946, 'validation/num_examples': 3554, 'test/ssim': 0.7401103616526459, 'test/loss': 0.288732559046443, 'test/num_examples': 3581, 'score': 2592.050028562546, 'total_duration': 2730.907357931137, 'accumulated_submission_time': 2592.050028562546, 'accumulated_eval_time': 137.57607746124268, 'accumulated_logging_time': 0.8305361270904541, 'global_step': 11038, 'preemption_count': 0}), (11384, {'train/ssim': 0.7461264474051339, 'train/loss': 0.26816918168749126, 'validation/ssim': 0.7231992121553179, 'validation/loss': 0.2872296249054762, 'validation/num_examples': 3554, 'test/ssim': 0.7403277088496579, 'test/loss': 0.28871657161931025, 'test/num_examples': 3581, 'score': 2672.0285749435425, 'total_duration': 2814.937951564789, 'accumulated_submission_time': 2672.0285749435425, 'accumulated_eval_time': 141.58618927001953, 'accumulated_logging_time': 0.8576686382293701, 'global_step': 11384, 'preemption_count': 0}), (11730, {'train/ssim': 0.7456574440002441, 'train/loss': 0.26810736315590994, 'validation/ssim': 0.7232962776317178, 'validation/loss': 0.2868558060405089, 'validation/num_examples': 3554, 'test/ssim': 0.7403952719212511, 'test/loss': 0.28822897213592574, 'test/num_examples': 3581, 'score': 2752.0991699695587, 'total_duration': 2899.0667912960052, 'accumulated_submission_time': 2752.0991699695587, 'accumulated_eval_time': 145.6027750968933, 'accumulated_logging_time': 0.8846747875213623, 'global_step': 11730, 'preemption_count': 0}), (12073, {'train/ssim': 0.7469180652073452, 'train/loss': 0.2673248733792986, 'validation/ssim': 0.7235540197884426, 'validation/loss': 0.28662962905463035, 'validation/num_examples': 3554, 'test/ssim': 0.7406891815091804, 'test/loss': 0.288034907268832, 'test/num_examples': 3581, 'score': 2832.1749567985535, 'total_duration': 2983.193598508835, 'accumulated_submission_time': 2832.1749567985535, 'accumulated_eval_time': 149.6131820678711, 'accumulated_logging_time': 0.9115986824035645, 'global_step': 12073, 'preemption_count': 0}), (12418, {'train/ssim': 0.746204035622733, 'train/loss': 0.2677193880081177, 'validation/ssim': 0.7232028529693655, 'validation/loss': 0.28671171910721194, 'validation/num_examples': 3554, 'test/ssim': 0.7404398594579028, 'test/loss': 0.2881162420260577, 'test/num_examples': 3581, 'score': 2912.2765226364136, 'total_duration': 3067.3525626659393, 'accumulated_submission_time': 2912.2765226364136, 'accumulated_eval_time': 153.62973427772522, 'accumulated_logging_time': 0.938593864440918, 'global_step': 12418, 'preemption_count': 0}), (12764, {'train/ssim': 0.7461694989885602, 'train/loss': 0.2676114354814802, 'validation/ssim': 0.7230209496561972, 'validation/loss': 0.2867143466758406, 'validation/num_examples': 3554, 'test/ssim': 0.7402508055754329, 'test/loss': 0.28807523376413713, 'test/num_examples': 3581, 'score': 2992.2794008255005, 'total_duration': 3151.4086179733276, 'accumulated_submission_time': 2992.2794008255005, 'accumulated_eval_time': 157.64133405685425, 'accumulated_logging_time': 0.9663434028625488, 'global_step': 12764, 'preemption_count': 0}), (13108, {'train/ssim': 0.7421060970851353, 'train/loss': 0.27096547399248394, 'validation/ssim': 0.7184103738745076, 'validation/loss': 0.2904571035167241, 'validation/num_examples': 3554, 'test/ssim': 0.7357027404836288, 'test/loss': 0.29178414641728917, 'test/num_examples': 3581, 'score': 3072.431079149246, 'total_duration': 3235.6166298389435, 'accumulated_submission_time': 3072.431079149246, 'accumulated_eval_time': 161.65591073036194, 'accumulated_logging_time': 0.9946553707122803, 'global_step': 13108, 'preemption_count': 0}), (13454, {'train/ssim': 0.746272087097168, 'train/loss': 0.2673053400857108, 'validation/ssim': 0.7233196337973059, 'validation/loss': 0.286368658251486, 'validation/num_examples': 3554, 'test/ssim': 0.7405587595556409, 'test/loss': 0.2877401795609641, 'test/num_examples': 3581, 'score': 3152.4668333530426, 'total_duration': 3319.7080438137054, 'accumulated_submission_time': 3152.4668333530426, 'accumulated_eval_time': 165.66799879074097, 'accumulated_logging_time': 1.0246577262878418, 'global_step': 13454, 'preemption_count': 0}), (13800, {'train/ssim': 0.7456895964486259, 'train/loss': 0.26762713704790386, 'validation/ssim': 0.7229075348638858, 'validation/loss': 0.28652881972227595, 'validation/num_examples': 3554, 'test/ssim': 0.7401016350399678, 'test/loss': 0.28788123707370494, 'test/num_examples': 3581, 'score': 3232.474317073822, 'total_duration': 3403.774663925171, 'accumulated_submission_time': 3232.474317073822, 'accumulated_eval_time': 169.683251619339, 'accumulated_logging_time': 1.0551369190216064, 'global_step': 13800, 'preemption_count': 0}), (14143, {'train/ssim': 0.7468343462262835, 'train/loss': 0.26763127531324116, 'validation/ssim': 0.7231794281091728, 'validation/loss': 0.28713419092593734, 'validation/num_examples': 3554, 'test/ssim': 0.740409725373499, 'test/loss': 0.288486918534889, 'test/num_examples': 3581, 'score': 3312.635585308075, 'total_duration': 3487.991771221161, 'accumulated_submission_time': 3312.635585308075, 'accumulated_eval_time': 173.69537568092346, 'accumulated_logging_time': 1.0848171710968018, 'global_step': 14143, 'preemption_count': 0}), (14489, {'train/ssim': 0.7479549816676548, 'train/loss': 0.2670495850699289, 'validation/ssim': 0.7246055281021384, 'validation/loss': 0.28627075126617896, 'validation/num_examples': 3554, 'test/ssim': 0.7417685544147934, 'test/loss': 0.287666889649801, 'test/num_examples': 3581, 'score': 3392.603483438492, 'total_duration': 3572.0182886123657, 'accumulated_submission_time': 3392.603483438492, 'accumulated_eval_time': 177.7116355895996, 'accumulated_logging_time': 1.1130201816558838, 'global_step': 14489, 'preemption_count': 0}), (14835, {'train/ssim': 0.7479761668613979, 'train/loss': 0.2671400308609009, 'validation/ssim': 0.7246696201682963, 'validation/loss': 0.28639548349460997, 'validation/num_examples': 3554, 'test/ssim': 0.7418121874781834, 'test/loss': 0.2877663253106674, 'test/num_examples': 3581, 'score': 3472.621673107147, 'total_duration': 3656.093423604965, 'accumulated_submission_time': 3472.621673107147, 'accumulated_eval_time': 181.7254831790924, 'accumulated_logging_time': 1.142401933670044, 'global_step': 14835, 'preemption_count': 0}), (15176, {'train/ssim': 0.7476153373718262, 'train/loss': 0.2673849718911307, 'validation/ssim': 0.7247315140071047, 'validation/loss': 0.28666461178205893, 'validation/num_examples': 3554, 'test/ssim': 0.7418471621055571, 'test/loss': 0.28812868426679, 'test/num_examples': 3581, 'score': 3552.6018946170807, 'total_duration': 3740.1362104415894, 'accumulated_submission_time': 3552.6018946170807, 'accumulated_eval_time': 185.74206948280334, 'accumulated_logging_time': 1.1750538349151611, 'global_step': 15176, 'preemption_count': 0}), (15521, {'train/ssim': 0.7456714085170201, 'train/loss': 0.2672596148082188, 'validation/ssim': 0.7225538263444359, 'validation/loss': 0.28642826799468907, 'validation/num_examples': 3554, 'test/ssim': 0.7398874921460485, 'test/loss': 0.28774761081707273, 'test/num_examples': 3581, 'score': 3632.597405195236, 'total_duration': 3824.1899275779724, 'accumulated_submission_time': 3632.597405195236, 'accumulated_eval_time': 189.75790739059448, 'accumulated_logging_time': 1.2031304836273193, 'global_step': 15521, 'preemption_count': 0}), (15867, {'train/ssim': 0.7476047788347516, 'train/loss': 0.2666402203696115, 'validation/ssim': 0.7241376491497257, 'validation/loss': 0.28601328388787284, 'validation/num_examples': 3554, 'test/ssim': 0.7413994459691776, 'test/loss': 0.28736425344919364, 'test/num_examples': 3581, 'score': 3712.6631059646606, 'total_duration': 3908.31063747406, 'accumulated_submission_time': 3712.6631059646606, 'accumulated_eval_time': 193.76922011375427, 'accumulated_logging_time': 1.2327890396118164, 'global_step': 15867, 'preemption_count': 0}), (16210, {'train/ssim': 0.7477357728140694, 'train/loss': 0.26675924233027865, 'validation/ssim': 0.7241149112355796, 'validation/loss': 0.28622342068356077, 'validation/num_examples': 3554, 'test/ssim': 0.7413657666983734, 'test/loss': 0.28759452012356884, 'test/num_examples': 3581, 'score': 3792.858276128769, 'total_duration': 3992.563661813736, 'accumulated_submission_time': 3792.858276128769, 'accumulated_eval_time': 197.7851824760437, 'accumulated_logging_time': 1.260986328125, 'global_step': 16210, 'preemption_count': 0}), (16558, {'train/ssim': 0.748434339250837, 'train/loss': 0.26643684932163786, 'validation/ssim': 0.724732063563942, 'validation/loss': 0.28620516509236954, 'validation/num_examples': 3554, 'test/ssim': 0.7419231109065205, 'test/loss': 0.28759850845826934, 'test/num_examples': 3581, 'score': 3873.0085203647614, 'total_duration': 4076.7703862190247, 'accumulated_submission_time': 3873.0085203647614, 'accumulated_eval_time': 201.79962134361267, 'accumulated_logging_time': 1.2895026206970215, 'global_step': 16558, 'preemption_count': 0}), (16903, {'train/ssim': 0.7483385631016323, 'train/loss': 0.2663480384009225, 'validation/ssim': 0.7249650756629854, 'validation/loss': 0.28570505119671497, 'validation/num_examples': 3554, 'test/ssim': 0.7421911815397235, 'test/loss': 0.2871007165639835, 'test/num_examples': 3581, 'score': 3953.2207186222076, 'total_duration': 4161.03843665123, 'accumulated_submission_time': 3953.2207186222076, 'accumulated_eval_time': 205.81161665916443, 'accumulated_logging_time': 1.3195016384124756, 'global_step': 16903, 'preemption_count': 0}), (17247, {'train/ssim': 0.7485357693263462, 'train/loss': 0.2669499261038644, 'validation/ssim': 0.7251728768421145, 'validation/loss': 0.28623745155656477, 'validation/num_examples': 3554, 'test/ssim': 0.7422807656729964, 'test/loss': 0.2876641966716699, 'test/num_examples': 3581, 'score': 4033.3886363506317, 'total_duration': 4245.26022362709, 'accumulated_submission_time': 4033.3886363506317, 'accumulated_eval_time': 209.8240213394165, 'accumulated_logging_time': 1.347517728805542, 'global_step': 17247, 'preemption_count': 0}), (17592, {'train/ssim': 0.7472812107631138, 'train/loss': 0.26697795731680735, 'validation/ssim': 0.723099261505522, 'validation/loss': 0.28689576912677617, 'validation/num_examples': 3554, 'test/ssim': 0.7403153688739179, 'test/loss': 0.28827253702265426, 'test/num_examples': 3581, 'score': 4113.347852706909, 'total_duration': 4329.27641749382, 'accumulated_submission_time': 4113.347852706909, 'accumulated_eval_time': 213.8384931087494, 'accumulated_logging_time': 1.375917673110962, 'global_step': 17592, 'preemption_count': 0}), (17936, {'train/ssim': 0.7481169700622559, 'train/loss': 0.26622419697897776, 'validation/ssim': 0.7245039287818303, 'validation/loss': 0.28565562542865436, 'validation/num_examples': 3554, 'test/ssim': 0.7417701224780089, 'test/loss': 0.287055038200747, 'test/num_examples': 3581, 'score': 4193.354947090149, 'total_duration': 4413.337802171707, 'accumulated_submission_time': 4193.354947090149, 'accumulated_eval_time': 217.84970903396606, 'accumulated_logging_time': 1.4057002067565918, 'global_step': 17936, 'preemption_count': 0}), (18281, {'train/ssim': 0.7480468068804059, 'train/loss': 0.2663684742791312, 'validation/ssim': 0.7245921326542276, 'validation/loss': 0.28573355945765333, 'validation/num_examples': 3554, 'test/ssim': 0.7418551387749581, 'test/loss': 0.28704351634494557, 'test/num_examples': 3581, 'score': 4273.456275224686, 'total_duration': 4497.49751830101, 'accumulated_submission_time': 4273.456275224686, 'accumulated_eval_time': 221.86294984817505, 'accumulated_logging_time': 1.4366326332092285, 'global_step': 18281, 'preemption_count': 0}), (18609, {'train/ssim': 0.7484518459865025, 'train/loss': 0.26592135429382324, 'validation/ssim': 0.724492731561269, 'validation/loss': 0.2857109761063678, 'validation/num_examples': 3554, 'test/ssim': 0.741691855670553, 'test/loss': 0.28709396707449036, 'test/num_examples': 3581, 'score': 4350.548347711563, 'total_duration': 4581.550496578217, 'accumulated_submission_time': 4350.548347711563, 'accumulated_eval_time': 225.87409567832947, 'accumulated_logging_time': 4.3728437423706055, 'global_step': 18609, 'preemption_count': 0}), (18955, {'train/ssim': 0.74802337374006, 'train/loss': 0.2668883630207607, 'validation/ssim': 0.7247163324994724, 'validation/loss': 0.28622769692270156, 'validation/num_examples': 3554, 'test/ssim': 0.7419325874624756, 'test/loss': 0.28756810166721936, 'test/num_examples': 3581, 'score': 4430.576882123947, 'total_duration': 4665.634213447571, 'accumulated_submission_time': 4430.576882123947, 'accumulated_eval_time': 229.88594794273376, 'accumulated_logging_time': 4.401664972305298, 'global_step': 18955, 'preemption_count': 0}), (19298, {'train/ssim': 0.7479914937700544, 'train/loss': 0.266499434198652, 'validation/ssim': 0.7243800724096089, 'validation/loss': 0.2859593242759039, 'validation/num_examples': 3554, 'test/ssim': 0.7416037714238342, 'test/loss': 0.28725803421050333, 'test/num_examples': 3581, 'score': 4510.648891210556, 'total_duration': 4749.759995222092, 'accumulated_submission_time': 4510.648891210556, 'accumulated_eval_time': 233.89514589309692, 'accumulated_logging_time': 4.43175482749939, 'global_step': 19298, 'preemption_count': 0}), (19640, {'train/ssim': 0.7494755472455706, 'train/loss': 0.2658189194543021, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.2856957087304797, 'validation/num_examples': 3554, 'test/ssim': 0.742760524840303, 'test/loss': 0.2870987053524679, 'test/num_examples': 3581, 'score': 4590.72519493103, 'total_duration': 4833.889722824097, 'accumulated_submission_time': 4590.72519493103, 'accumulated_eval_time': 237.90518808364868, 'accumulated_logging_time': 4.460954427719116, 'global_step': 19640, 'preemption_count': 0}), (19985, {'train/ssim': 0.7494589260646275, 'train/loss': 0.2660778931209019, 'validation/ssim': 0.7255726107466939, 'validation/loss': 0.2859783526813977, 'validation/num_examples': 3554, 'test/ssim': 0.7427205051399749, 'test/loss': 0.2873735595634948, 'test/num_examples': 3581, 'score': 4670.917221784592, 'total_duration': 4918.140657424927, 'accumulated_submission_time': 4670.917221784592, 'accumulated_eval_time': 241.92007851600647, 'accumulated_logging_time': 4.490314960479736, 'global_step': 19985, 'preemption_count': 0}), (20329, {'train/ssim': 0.7488336563110352, 'train/loss': 0.2660074234008789, 'validation/ssim': 0.7252096971502181, 'validation/loss': 0.2856191142462718, 'validation/num_examples': 3554, 'test/ssim': 0.7423481923912664, 'test/loss': 0.28703608508883693, 'test/num_examples': 3581, 'score': 4750.951722860336, 'total_duration': 5002.232574462891, 'accumulated_submission_time': 4750.951722860336, 'accumulated_eval_time': 245.93207383155823, 'accumulated_logging_time': 4.521239280700684, 'global_step': 20329, 'preemption_count': 0}), (20668, {'train/ssim': 0.7490506853376117, 'train/loss': 0.2657781328473772, 'validation/ssim': 0.7247555571187394, 'validation/loss': 0.2857364618047007, 'validation/num_examples': 3554, 'test/ssim': 0.7419362690021991, 'test/loss': 0.28714448598069675, 'test/num_examples': 3581, 'score': 4830.941958904266, 'total_duration': 5086.27272605896, 'accumulated_submission_time': 4830.941958904266, 'accumulated_eval_time': 249.9386088848114, 'accumulated_logging_time': 4.551448345184326, 'global_step': 20668, 'preemption_count': 0}), (21014, {'train/ssim': 0.7492361749921527, 'train/loss': 0.26613100937434603, 'validation/ssim': 0.7255093430157921, 'validation/loss': 0.2857910224944605, 'validation/num_examples': 3554, 'test/ssim': 0.7425711300745252, 'test/loss': 0.2872181849518291, 'test/num_examples': 3581, 'score': 4911.088220119476, 'total_duration': 5170.472066164017, 'accumulated_submission_time': 4911.088220119476, 'accumulated_eval_time': 253.94873142242432, 'accumulated_logging_time': 4.5808281898498535, 'global_step': 21014, 'preemption_count': 0}), (21362, {'train/ssim': 0.7492140361240932, 'train/loss': 0.26581534317561556, 'validation/ssim': 0.7254861929340181, 'validation/loss': 0.2855267028293384, 'validation/num_examples': 3554, 'test/ssim': 0.7426757130733385, 'test/loss': 0.286876074464186, 'test/num_examples': 3581, 'score': 4991.229874610901, 'total_duration': 5254.662563562393, 'accumulated_submission_time': 4991.229874610901, 'accumulated_eval_time': 257.9545512199402, 'accumulated_logging_time': 4.6102073192596436, 'global_step': 21362, 'preemption_count': 0}), (21703, {'train/ssim': 0.7498057229178292, 'train/loss': 0.26596065929957796, 'validation/ssim': 0.7261010783404263, 'validation/loss': 0.28571909924337013, 'validation/num_examples': 3554, 'test/ssim': 0.7431506316976753, 'test/loss': 0.28719510715189545, 'test/num_examples': 3581, 'score': 5071.210415363312, 'total_duration': 5338.700535297394, 'accumulated_submission_time': 5071.210415363312, 'accumulated_eval_time': 261.9677035808563, 'accumulated_logging_time': 4.641288995742798, 'global_step': 21703, 'preemption_count': 0}), (22048, {'train/ssim': 0.749934468950544, 'train/loss': 0.26566275528499056, 'validation/ssim': 0.7257356230435776, 'validation/loss': 0.2857178970877884, 'validation/num_examples': 3554, 'test/ssim': 0.7429184219884459, 'test/loss': 0.28715904169793705, 'test/num_examples': 3581, 'score': 5151.294460535049, 'total_duration': 5422.839916706085, 'accumulated_submission_time': 5151.294460535049, 'accumulated_eval_time': 265.9774160385132, 'accumulated_logging_time': 4.673285722732544, 'global_step': 22048, 'preemption_count': 0}), (22391, {'train/ssim': 0.7499521800449916, 'train/loss': 0.2657770940235683, 'validation/ssim': 0.7259103134232555, 'validation/loss': 0.28578545823148216, 'validation/num_examples': 3554, 'test/ssim': 0.7431317467624267, 'test/loss': 0.2871350094247417, 'test/num_examples': 3581, 'score': 5231.44545173645, 'total_duration': 5507.0493676662445, 'accumulated_submission_time': 5231.44545173645, 'accumulated_eval_time': 269.98947501182556, 'accumulated_logging_time': 4.706132888793945, 'global_step': 22391, 'preemption_count': 0}), (22735, {'train/ssim': 0.749309744153704, 'train/loss': 0.2656928300857544, 'validation/ssim': 0.7254960849570906, 'validation/loss': 0.28546091057171497, 'validation/num_examples': 3554, 'test/ssim': 0.7426772129598925, 'test/loss': 0.2868370433254503, 'test/num_examples': 3581, 'score': 5311.462661266327, 'total_duration': 5591.121385335922, 'accumulated_submission_time': 5311.462661266327, 'accumulated_eval_time': 274.00053787231445, 'accumulated_logging_time': 4.736352205276489, 'global_step': 22735, 'preemption_count': 0}), (23080, {'train/ssim': 0.750044754573277, 'train/loss': 0.26533922127314974, 'validation/ssim': 0.7257962116848973, 'validation/loss': 0.2854270441316123, 'validation/num_examples': 3554, 'test/ssim': 0.7429138541521223, 'test/loss': 0.2868782220290247, 'test/num_examples': 3581, 'score': 5391.550899028778, 'total_duration': 5675.270745754242, 'accumulated_submission_time': 5391.550899028778, 'accumulated_eval_time': 278.01680517196655, 'accumulated_logging_time': 4.767531394958496, 'global_step': 23080, 'preemption_count': 0}), (23426, {'train/ssim': 0.749577454158238, 'train/loss': 0.26578846999577116, 'validation/ssim': 0.7258460152732836, 'validation/loss': 0.28555299568927617, 'validation/num_examples': 3554, 'test/ssim': 0.7429287848410011, 'test/loss': 0.2870010422848017, 'test/num_examples': 3581, 'score': 5471.681828737259, 'total_duration': 5759.457330942154, 'accumulated_submission_time': 5471.681828737259, 'accumulated_eval_time': 282.02875447273254, 'accumulated_logging_time': 4.797436714172363, 'global_step': 23426, 'preemption_count': 0}), (23770, {'train/ssim': 0.7495931216648647, 'train/loss': 0.26550001757485525, 'validation/ssim': 0.7256565555536015, 'validation/loss': 0.2853825815487391, 'validation/num_examples': 3554, 'test/ssim': 0.7428168387627408, 'test/loss': 0.2867749343867809, 'test/num_examples': 3581, 'score': 5551.710270643234, 'total_duration': 5843.544717788696, 'accumulated_submission_time': 5551.710270643234, 'accumulated_eval_time': 286.0441243648529, 'accumulated_logging_time': 4.827166795730591, 'global_step': 23770, 'preemption_count': 0}), (24116, {'train/ssim': 0.750204154423305, 'train/loss': 0.26502604143960135, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.28534869793498524, 'validation/num_examples': 3554, 'test/ssim': 0.7428803794113027, 'test/loss': 0.28677772962990433, 'test/num_examples': 3581, 'score': 5631.85106420517, 'total_duration': 5927.740929841995, 'accumulated_submission_time': 5631.85106420517, 'accumulated_eval_time': 290.05428886413574, 'accumulated_logging_time': 4.858988285064697, 'global_step': 24116, 'preemption_count': 0}), (24462, {'train/ssim': 0.749311992100307, 'train/loss': 0.2653989621571132, 'validation/ssim': 0.7251623665675999, 'validation/loss': 0.28546176925427336, 'validation/num_examples': 3554, 'test/ssim': 0.7423995294174114, 'test/loss': 0.28685718952893746, 'test/num_examples': 3581, 'score': 5712.004364490509, 'total_duration': 6011.95213842392, 'accumulated_submission_time': 5712.004364490509, 'accumulated_eval_time': 294.06663846969604, 'accumulated_logging_time': 4.8908774852752686, 'global_step': 24462, 'preemption_count': 0}), (24808, {'train/ssim': 0.7499324253627232, 'train/loss': 0.26541229656764437, 'validation/ssim': 0.7258076836838773, 'validation/loss': 0.2854906038145839, 'validation/num_examples': 3554, 'test/ssim': 0.7429736450842991, 'test/loss': 0.2868880735566183, 'test/num_examples': 3581, 'score': 5792.194799900055, 'total_duration': 6096.200660705566, 'accumulated_submission_time': 5792.194799900055, 'accumulated_eval_time': 298.0805068016052, 'accumulated_logging_time': 4.921252250671387, 'global_step': 24808, 'preemption_count': 0}), (25153, {'train/ssim': 0.7504647118704659, 'train/loss': 0.265025121825082, 'validation/ssim': 0.7259484389288478, 'validation/loss': 0.28542750782019377, 'validation/num_examples': 3554, 'test/ssim': 0.7430454351089081, 'test/loss': 0.28684045215852766, 'test/num_examples': 3581, 'score': 5872.191735506058, 'total_duration': 6180.25568819046, 'accumulated_submission_time': 5872.191735506058, 'accumulated_eval_time': 302.09289360046387, 'accumulated_logging_time': 4.95358943939209, 'global_step': 25153, 'preemption_count': 0}), (25497, {'train/ssim': 0.7500345366341727, 'train/loss': 0.2653808423451015, 'validation/ssim': 0.7257026496333356, 'validation/loss': 0.28552526024264036, 'validation/num_examples': 3554, 'test/ssim': 0.742860471826131, 'test/loss': 0.2869330701532393, 'test/num_examples': 3581, 'score': 5952.1544880867, 'total_duration': 6264.277378082275, 'accumulated_submission_time': 5952.1544880867, 'accumulated_eval_time': 306.1063861846924, 'accumulated_logging_time': 4.98514199256897, 'global_step': 25497, 'preemption_count': 0}), (25845, {'train/ssim': 0.7496070861816406, 'train/loss': 0.26539559023720877, 'validation/ssim': 0.7255828462427898, 'validation/loss': 0.28537954181248243, 'validation/num_examples': 3554, 'test/ssim': 0.742732231525761, 'test/loss': 0.2867713892003805, 'test/num_examples': 3581, 'score': 6032.137490034103, 'total_duration': 6348.31400680542, 'accumulated_submission_time': 6032.137490034103, 'accumulated_eval_time': 310.115487575531, 'accumulated_logging_time': 5.016194820404053, 'global_step': 25845, 'preemption_count': 0}), (26189, {'train/ssim': 0.7505412101745605, 'train/loss': 0.2648829051426479, 'validation/ssim': 0.7259142977103263, 'validation/loss': 0.28543772614263857, 'validation/num_examples': 3554, 'test/ssim': 0.743048912118647, 'test/loss': 0.2868577349422298, 'test/num_examples': 3581, 'score': 6112.283630371094, 'total_duration': 6432.515614271164, 'accumulated_submission_time': 6112.283630371094, 'accumulated_eval_time': 314.12628722190857, 'accumulated_logging_time': 5.047453880310059, 'global_step': 26189, 'preemption_count': 0}), (26532, {'train/ssim': 0.7501976149422782, 'train/loss': 0.2651327848434448, 'validation/ssim': 0.7257329439539955, 'validation/loss': 0.2854400617591974, 'validation/num_examples': 3554, 'test/ssim': 0.7429106498490295, 'test/loss': 0.28686168918859956, 'test/num_examples': 3581, 'score': 6192.388805150986, 'total_duration': 6516.674349784851, 'accumulated_submission_time': 6192.388805150986, 'accumulated_eval_time': 318.13490319252014, 'accumulated_logging_time': 5.079059839248657, 'global_step': 26532, 'preemption_count': 0}), (26880, {'train/ssim': 0.7498160089765277, 'train/loss': 0.26521427290780203, 'validation/ssim': 0.7256105988630768, 'validation/loss': 0.2852989973885059, 'validation/num_examples': 3554, 'test/ssim': 0.7427324360557456, 'test/loss': 0.2867100642933189, 'test/num_examples': 3581, 'score': 6272.537399768829, 'total_duration': 6600.883124828339, 'accumulated_submission_time': 6272.537399768829, 'accumulated_eval_time': 322.150488615036, 'accumulated_logging_time': 5.109807968139648, 'global_step': 26880, 'preemption_count': 0}), (27223, {'train/ssim': 0.7501500674656459, 'train/loss': 0.2650226354598999, 'validation/ssim': 0.725652296488112, 'validation/loss': 0.2854420195554305, 'validation/num_examples': 3554, 'test/ssim': 0.7427158691269896, 'test/loss': 0.28688998250314157, 'test/num_examples': 3581, 'score': 6352.623078107834, 'total_duration': 6685.047988176346, 'accumulated_submission_time': 6352.623078107834, 'accumulated_eval_time': 326.1638045310974, 'accumulated_logging_time': 5.161976337432861, 'global_step': 27223, 'preemption_count': 0}), (27569, {'train/ssim': 0.7501449584960938, 'train/loss': 0.2649794135774885, 'validation/ssim': 0.725748056767023, 'validation/loss': 0.28529769219101714, 'validation/num_examples': 3554, 'test/ssim': 0.7429066956026599, 'test/loss': 0.2866826913637078, 'test/num_examples': 3581, 'score': 6432.78490281105, 'total_duration': 6769.26359128952, 'accumulated_submission_time': 6432.78490281105, 'accumulated_eval_time': 330.1715428829193, 'accumulated_logging_time': 5.1945271492004395, 'global_step': 27569, 'preemption_count': 0}), (27914, {'train/ssim': 0.7500529289245605, 'train/loss': 0.2651003428867885, 'validation/ssim': 0.7256652110737901, 'validation/loss': 0.2853273510865838, 'validation/num_examples': 3554, 'test/ssim': 0.7428141798729405, 'test/loss': 0.2867274493420134, 'test/num_examples': 3581, 'score': 6512.966456890106, 'total_duration': 6853.502288341522, 'accumulated_submission_time': 6512.966456890106, 'accumulated_eval_time': 334.1822066307068, 'accumulated_logging_time': 5.227466106414795, 'global_step': 27914, 'preemption_count': 0}), (28257, {'train/ssim': 0.7506343296595982, 'train/loss': 0.26495981216430664, 'validation/ssim': 0.7260884385331668, 'validation/loss': 0.28537514535778347, 'validation/num_examples': 3554, 'test/ssim': 0.7432074910334054, 'test/loss': 0.28680469349954624, 'test/num_examples': 3581, 'score': 6593.085450172424, 'total_duration': 6937.679908514023, 'accumulated_submission_time': 6593.085450172424, 'accumulated_eval_time': 338.1944320201874, 'accumulated_logging_time': 5.260152816772461, 'global_step': 28257, 'preemption_count': 0}), (28604, {'train/ssim': 0.7506190027509417, 'train/loss': 0.2649067299706595, 'validation/ssim': 0.7260718144388365, 'validation/loss': 0.28532774608056066, 'validation/num_examples': 3554, 'test/ssim': 0.743204695790282, 'test/loss': 0.28677926360478917, 'test/num_examples': 3581, 'score': 6673.190561294556, 'total_duration': 7021.847796201706, 'accumulated_submission_time': 6673.190561294556, 'accumulated_eval_time': 342.20906805992126, 'accumulated_logging_time': 5.2943854331970215, 'global_step': 28604, 'preemption_count': 0}), (28946, {'train/ssim': 0.7500931876046317, 'train/loss': 0.2649789367403303, 'validation/ssim': 0.7257242197392023, 'validation/loss': 0.2852500868299803, 'validation/num_examples': 3554, 'test/ssim': 0.7428719255052709, 'test/loss': 0.28663588808555573, 'test/num_examples': 3581, 'score': 6753.176616668701, 'total_duration': 7105.89125585556, 'accumulated_submission_time': 6753.176616668701, 'accumulated_eval_time': 346.21965074539185, 'accumulated_logging_time': 5.327981233596802, 'global_step': 28946, 'preemption_count': 0}), (29290, {'train/ssim': 0.7503688676016671, 'train/loss': 0.2651293788637434, 'validation/ssim': 0.7259679481965743, 'validation/loss': 0.2854834767493493, 'validation/num_examples': 3554, 'test/ssim': 0.7430520482450782, 'test/loss': 0.2869654199791434, 'test/num_examples': 3581, 'score': 6833.300783395767, 'total_duration': 7190.074701547623, 'accumulated_submission_time': 6833.300783395767, 'accumulated_eval_time': 350.23344373703003, 'accumulated_logging_time': 5.359550714492798, 'global_step': 29290, 'preemption_count': 0}), (29635, {'train/ssim': 0.750690392085484, 'train/loss': 0.2648529495511736, 'validation/ssim': 0.7260376732203151, 'validation/loss': 0.2853850373808561, 'validation/num_examples': 3554, 'test/ssim': 0.7431846518517872, 'test/loss': 0.2868040458212615, 'test/num_examples': 3581, 'score': 6913.516995429993, 'total_duration': 7274.34780049324, 'accumulated_submission_time': 6913.516995429993, 'accumulated_eval_time': 354.2454254627228, 'accumulated_logging_time': 5.391098737716675, 'global_step': 29635, 'preemption_count': 0}), (29980, {'train/ssim': 0.7506021772112165, 'train/loss': 0.2649602379117693, 'validation/ssim': 0.7260679675409749, 'validation/loss': 0.2853407465344946, 'validation/num_examples': 3554, 'test/ssim': 0.7432026504904357, 'test/loss': 0.28675904922464046, 'test/num_examples': 3581, 'score': 6993.540855407715, 'total_duration': 7358.42671585083, 'accumulated_submission_time': 6993.540855407715, 'accumulated_eval_time': 358.25573444366455, 'accumulated_logging_time': 5.422429800033569, 'global_step': 29980, 'preemption_count': 0}), (30322, {'train/ssim': 0.750415733882359, 'train/loss': 0.2649151768003191, 'validation/ssim': 0.7259121681775816, 'validation/loss': 0.28531859252448827, 'validation/num_examples': 3554, 'test/ssim': 0.743074205660081, 'test/loss': 0.2867245177455669, 'test/num_examples': 3581, 'score': 7073.571084022522, 'total_duration': 7442.514234781265, 'accumulated_submission_time': 7073.571084022522, 'accumulated_eval_time': 362.267263174057, 'accumulated_logging_time': 5.454789638519287, 'global_step': 30322, 'preemption_count': 0}), (30666, {'train/ssim': 0.750591686793736, 'train/loss': 0.26462812083108084, 'validation/ssim': 0.7258340624120709, 'validation/loss': 0.2852345790229759, 'validation/num_examples': 3554, 'test/ssim': 0.7429935526694709, 'test/loss': 0.28663183157419364, 'test/num_examples': 3581, 'score': 7153.6601984500885, 'total_duration': 7526.665081501007, 'accumulated_submission_time': 7153.6601984500885, 'accumulated_eval_time': 366.28090047836304, 'accumulated_logging_time': 5.489109992980957, 'global_step': 30666, 'preemption_count': 0}), (31010, {'train/ssim': 0.7505792209080288, 'train/loss': 0.26484428133283344, 'validation/ssim': 0.7259497441263365, 'validation/loss': 0.28533076864316614, 'validation/num_examples': 3554, 'test/ssim': 0.7430826595661129, 'test/loss': 0.28677500256344246, 'test/num_examples': 3581, 'score': 7233.649788141251, 'total_duration': 7610.714449882507, 'accumulated_submission_time': 7233.649788141251, 'accumulated_eval_time': 370.2935276031494, 'accumulated_logging_time': 5.52242112159729, 'global_step': 31010, 'preemption_count': 0}), (31354, {'train/ssim': 0.7504358291625977, 'train/loss': 0.2648018257958548, 'validation/ssim': 0.7258527473445414, 'validation/loss': 0.28525510153612127, 'validation/num_examples': 3554, 'test/ssim': 0.7429784856272689, 'test/loss': 0.28666309057351297, 'test/num_examples': 3581, 'score': 7313.791854381561, 'total_duration': 7694.9102284908295, 'accumulated_submission_time': 7313.791854381561, 'accumulated_eval_time': 374.30131578445435, 'accumulated_logging_time': 5.554333209991455, 'global_step': 31354, 'preemption_count': 0}), (31697, {'train/ssim': 0.750840391431536, 'train/loss': 0.26459246022360666, 'validation/ssim': 0.726041245339758, 'validation/loss': 0.28527519470798746, 'validation/num_examples': 3554, 'test/ssim': 0.7431663123298311, 'test/loss': 0.2866952699577632, 'test/num_examples': 3581, 'score': 7393.845289468765, 'total_duration': 7779.0155618190765, 'accumulated_submission_time': 7393.845289468765, 'accumulated_eval_time': 378.30689764022827, 'accumulated_logging_time': 5.58677077293396, 'global_step': 31697, 'preemption_count': 0}), (32043, {'train/ssim': 0.7502557209559849, 'train/loss': 0.2647336891719273, 'validation/ssim': 0.7255834644942318, 'validation/loss': 0.2852741471152663, 'validation/num_examples': 3554, 'test/ssim': 0.7427708876928582, 'test/loss': 0.2866786007640149, 'test/num_examples': 3581, 'score': 7473.926406145096, 'total_duration': 7863.157017469406, 'accumulated_submission_time': 7473.926406145096, 'accumulated_eval_time': 382.31988549232483, 'accumulated_logging_time': 5.6204071044921875, 'global_step': 32043, 'preemption_count': 0}), (32388, {'train/ssim': 0.7505275181361607, 'train/loss': 0.26482081413269043, 'validation/ssim': 0.7259816184229038, 'validation/loss': 0.2853099026569974, 'validation/num_examples': 3554, 'test/ssim': 0.7431155207169785, 'test/loss': 0.28671190506318067, 'test/num_examples': 3581, 'score': 7554.078770637512, 'total_duration': 7947.365916252136, 'accumulated_submission_time': 7554.078770637512, 'accumulated_eval_time': 386.32947516441345, 'accumulated_logging_time': 5.653552770614624, 'global_step': 32388, 'preemption_count': 0}), (32730, {'train/ssim': 0.7509356907435826, 'train/loss': 0.264573335647583, 'validation/ssim': 0.7260761421989308, 'validation/loss': 0.28529200771248064, 'validation/num_examples': 3554, 'test/ssim': 0.7432014914871893, 'test/loss': 0.28671381400970397, 'test/num_examples': 3581, 'score': 7634.058696508408, 'total_duration': 8031.405979156494, 'accumulated_submission_time': 7634.058696508408, 'accumulated_eval_time': 390.34309220314026, 'accumulated_logging_time': 5.686913251876831, 'global_step': 32730, 'preemption_count': 0}), (33076, {'train/ssim': 0.7511607578822544, 'train/loss': 0.26468498366219656, 'validation/ssim': 0.7264695561998804, 'validation/loss': 0.2852806215817565, 'validation/num_examples': 3554, 'test/ssim': 0.7435912574612539, 'test/loss': 0.28670041729571, 'test/num_examples': 3581, 'score': 7714.161678314209, 'total_duration': 8115.569339990616, 'accumulated_submission_time': 7714.161678314209, 'accumulated_eval_time': 394.3575599193573, 'accumulated_logging_time': 5.719174385070801, 'global_step': 33076, 'preemption_count': 0}), (33421, {'train/ssim': 0.7507865088326591, 'train/loss': 0.26472517422267366, 'validation/ssim': 0.7260885072277715, 'validation/loss': 0.2852847604316879, 'validation/num_examples': 3554, 'test/ssim': 0.7432023777837894, 'test/loss': 0.28671681378281205, 'test/num_examples': 3581, 'score': 7794.147730350494, 'total_duration': 8199.616106510162, 'accumulated_submission_time': 7794.147730350494, 'accumulated_eval_time': 398.3710045814514, 'accumulated_logging_time': 5.753046751022339, 'global_step': 33421, 'preemption_count': 0}), (33763, {'train/ssim': 0.750774656023298, 'train/loss': 0.26458351952689035, 'validation/ssim': 0.726001814636677, 'validation/loss': 0.28524426496223443, 'validation/num_examples': 3554, 'test/ssim': 0.7431103392907009, 'test/loss': 0.28667935070729195, 'test/num_examples': 3581, 'score': 7874.208901643753, 'total_duration': 8283.741166591644, 'accumulated_submission_time': 7874.208901643753, 'accumulated_eval_time': 402.38356733322144, 'accumulated_logging_time': 5.791030645370483, 'global_step': 33763, 'preemption_count': 0}), (34108, {'train/ssim': 0.7508078983851841, 'train/loss': 0.26457490239824566, 'validation/ssim': 0.726052923422552, 'validation/loss': 0.28519605852340674, 'validation/num_examples': 3554, 'test/ssim': 0.7431852654417411, 'test/loss': 0.286617480386938, 'test/num_examples': 3581, 'score': 7954.2614159584045, 'total_duration': 8367.859296798706, 'accumulated_submission_time': 7954.2614159584045, 'accumulated_eval_time': 406.400333404541, 'accumulated_logging_time': 5.826385736465454, 'global_step': 34108, 'preemption_count': 0}), (34452, {'train/ssim': 0.7507697514125279, 'train/loss': 0.26462178570883615, 'validation/ssim': 0.7260702344629291, 'validation/loss': 0.2852324323165799, 'validation/num_examples': 3554, 'test/ssim': 0.7431785841289095, 'test/loss': 0.28665889770882785, 'test/num_examples': 3581, 'score': 8034.315863609314, 'total_duration': 8451.97430229187, 'accumulated_submission_time': 8034.315863609314, 'accumulated_eval_time': 410.41228795051575, 'accumulated_logging_time': 5.861198663711548, 'global_step': 34452, 'preemption_count': 0}), (34795, {'train/ssim': 0.7505358287266323, 'train/loss': 0.2645829575402396, 'validation/ssim': 0.725791059589547, 'validation/loss': 0.2851932420446152, 'validation/num_examples': 3554, 'test/ssim': 0.7429303529042167, 'test/loss': 0.2866116853707065, 'test/num_examples': 3581, 'score': 8114.298360586166, 'total_duration': 8536.016276597977, 'accumulated_submission_time': 8114.298360586166, 'accumulated_eval_time': 414.4228415489197, 'accumulated_logging_time': 5.896820545196533, 'global_step': 34795, 'preemption_count': 0}), (35140, {'train/ssim': 0.7508696147373745, 'train/loss': 0.26455746378217426, 'validation/ssim': 0.7261189389376407, 'validation/loss': 0.2851793829081229, 'validation/num_examples': 3554, 'test/ssim': 0.7432427383674253, 'test/loss': 0.2865960729152122, 'test/num_examples': 3581, 'score': 8194.391567707062, 'total_duration': 8620.169978618622, 'accumulated_submission_time': 8194.391567707062, 'accumulated_eval_time': 418.43588304519653, 'accumulated_logging_time': 5.930956602096558, 'global_step': 35140, 'preemption_count': 0}), (35487, {'train/ssim': 0.750948292868478, 'train/loss': 0.26458047117505756, 'validation/ssim': 0.7261771232677968, 'validation/loss': 0.2852134039110861, 'validation/num_examples': 3554, 'test/ssim': 0.7433055290727102, 'test/loss': 0.2866312520725705, 'test/num_examples': 3581, 'score': 8274.552117347717, 'total_duration': 8704.389466524124, 'accumulated_submission_time': 8274.552117347717, 'accumulated_eval_time': 422.4488196372986, 'accumulated_logging_time': 5.9632744789123535, 'global_step': 35487, 'preemption_count': 0}), (35830, {'train/ssim': 0.7509431838989258, 'train/loss': 0.26457313128880094, 'validation/ssim': 0.7261721085616559, 'validation/loss': 0.2852237767963914, 'validation/num_examples': 3554, 'test/ssim': 0.7432949616901704, 'test/loss': 0.28664604640812624, 'test/num_examples': 3581, 'score': 8354.554366588593, 'total_duration': 8788.44710612297, 'accumulated_submission_time': 8354.554366588593, 'accumulated_eval_time': 426.4578926563263, 'accumulated_logging_time': 5.996220350265503, 'global_step': 35830, 'preemption_count': 0}), (36175, {'train/ssim': 0.7508655956813267, 'train/loss': 0.2645613465990339, 'validation/ssim': 0.7261112451419176, 'validation/loss': 0.28519578374498805, 'validation/num_examples': 3554, 'test/ssim': 0.7432375569411477, 'test/loss': 0.2866142079071837, 'test/num_examples': 3581, 'score': 8434.533107995987, 'total_duration': 8872.484619140625, 'accumulated_submission_time': 8434.533107995987, 'accumulated_eval_time': 430.4693253040314, 'accumulated_logging_time': 6.029922008514404, 'global_step': 36175, 'preemption_count': 0}), (36189, {'train/ssim': 0.7508655956813267, 'train/loss': 0.2645613465990339, 'validation/ssim': 0.7261113138365223, 'validation/loss': 0.28519578374498805, 'validation/num_examples': 3554, 'test/ssim': 0.7432375569411477, 'test/loss': 0.2866142079071837, 'test/num_examples': 3581, 'score': 8435.488661050797, 'total_duration': 8877.492777347565, 'accumulated_submission_time': 8435.488661050797, 'accumulated_eval_time': 434.4867742061615, 'accumulated_logging_time': 6.064191818237305, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 22:49:59.029722 139681449744192 submission_runner.py:586] Timing: 8435.488661050797
I0204 22:49:59.029789 139681449744192 submission_runner.py:588] Total number of evals: 107
I0204 22:49:59.029845 139681449744192 submission_runner.py:589] ====================
I0204 22:49:59.029907 139681449744192 submission_runner.py:542] Using RNG seed 813120851
I0204 22:49:59.031720 139681449744192 submission_runner.py:551] --- Tuning run 3/5 ---
I0204 22:49:59.031847 139681449744192 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3.
I0204 22:49:59.032094 139681449744192 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3/hparams.json.
I0204 22:49:59.033016 139681449744192 submission_runner.py:206] Initializing dataset.
I0204 22:49:59.370507 139681449744192 submission_runner.py:213] Initializing model.
I0204 22:50:01.562664 139681449744192 submission_runner.py:255] Initializing optimizer.
I0204 22:50:01.637516 139681449744192 submission_runner.py:262] Initializing metrics bundle.
I0204 22:50:01.637757 139681449744192 submission_runner.py:280] Initializing checkpoint and logger.
I0204 22:50:01.638574 139681449744192 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3 with prefix checkpoint_
I0204 22:50:01.638793 139681449744192 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3/meta_data_0.json.
I0204 22:50:01.639202 139681449744192 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 22:50:01.639307 139681449744192 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 22:50:05.866727 139681449744192 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 22:50:09.928979 139681449744192 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3/flags_0.json.
I0204 22:50:09.932730 139681449744192 submission_runner.py:314] Starting training loop.
I0204 22:50:54.689886 139462596097792 logging_writer.py:48] [0] global_step=0, grad_norm=5.605435371398926, loss=1.0139427185058594
I0204 22:50:54.695730 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:50:56.021994 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:50:57.340492 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:50:58.660897 139681449744192 submission_runner.py:408] Time since start: 48.73s, 	Step: 1, 	{'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 44.76288342475891, 'total_duration': 48.72807693481445, 'accumulated_submission_time': 44.76288342475891, 'accumulated_eval_time': 3.965081214904785, 'accumulated_logging_time': 0}
I0204 22:50:58.673091 139462604490496 logging_writer.py:48] [1] accumulated_eval_time=3.965081, accumulated_logging_time=0, accumulated_submission_time=44.762883, global_step=1, preemption_count=0, score=44.762883, test/loss=1.032399, test/num_examples=3581, test/ssim=0.212846, total_duration=48.728077, train/loss=1.032718, train/ssim=0.197546, validation/loss=1.037087, validation/num_examples=3554, validation/ssim=0.189760
I0204 22:51:25.733930 139462596097792 logging_writer.py:48] [100] global_step=100, grad_norm=0.8439014554023743, loss=0.47173285484313965
I0204 22:52:03.123726 139462604490496 logging_writer.py:48] [200] global_step=200, grad_norm=0.1966194063425064, loss=0.36092033982276917
I0204 22:52:19.037769 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:52:20.407967 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:52:21.724874 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:52:23.042443 139681449744192 submission_runner.py:408] Time since start: 133.11s, 	Step: 248, 	{'train/ssim': 0.6612253870282855, 'train/loss': 0.3414253166743687, 'validation/ssim': 0.637590141060249, 'validation/loss': 0.36103909245084764, 'validation/num_examples': 3554, 'test/ssim': 0.6574814068608629, 'test/loss': 0.36188959389617076, 'test/num_examples': 3581, 'score': 125.10523748397827, 'total_duration': 133.1096351146698, 'accumulated_submission_time': 125.10523748397827, 'accumulated_eval_time': 7.969703435897827, 'accumulated_logging_time': 0.02441096305847168}
I0204 22:52:23.062931 139462596097792 logging_writer.py:48] [248] accumulated_eval_time=7.969703, accumulated_logging_time=0.024411, accumulated_submission_time=125.105237, global_step=248, preemption_count=0, score=125.105237, test/loss=0.361890, test/num_examples=3581, test/ssim=0.657481, total_duration=133.109635, train/loss=0.341425, train/ssim=0.661225, validation/loss=0.361039, validation/num_examples=3554, validation/ssim=0.637590
I0204 22:52:38.620466 139462604490496 logging_writer.py:48] [300] global_step=300, grad_norm=0.1676543951034546, loss=0.34076255559921265
I0204 22:53:13.817359 139462596097792 logging_writer.py:48] [400] global_step=400, grad_norm=0.07945390790700912, loss=0.3675077557563782
I0204 22:53:43.264046 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:53:44.633118 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:53:45.951127 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:53:47.270563 139681449744192 submission_runner.py:408] Time since start: 217.34s, 	Step: 483, 	{'train/ssim': 0.6970335415431431, 'train/loss': 0.31379175186157227, 'validation/ssim': 0.674776522712085, 'validation/loss': 0.33258781368704277, 'validation/num_examples': 3554, 'test/ssim': 0.693326854732442, 'test/loss': 0.33407699299471166, 'test/num_examples': 3581, 'score': 205.28294610977173, 'total_duration': 217.33776664733887, 'accumulated_submission_time': 205.28294610977173, 'accumulated_eval_time': 11.9761803150177, 'accumulated_logging_time': 0.058553457260131836}
I0204 22:53:47.292051 139462604490496 logging_writer.py:48] [483] accumulated_eval_time=11.976180, accumulated_logging_time=0.058553, accumulated_submission_time=205.282946, global_step=483, preemption_count=0, score=205.282946, test/loss=0.334077, test/num_examples=3581, test/ssim=0.693327, total_duration=217.337767, train/loss=0.313792, train/ssim=0.697034, validation/loss=0.332588, validation/num_examples=3554, validation/ssim=0.674777
I0204 22:53:50.708965 139462596097792 logging_writer.py:48] [500] global_step=500, grad_norm=0.08901172876358032, loss=0.2436014860868454
I0204 22:54:25.945520 139462604490496 logging_writer.py:48] [600] global_step=600, grad_norm=0.11258794367313385, loss=0.3673040270805359
I0204 22:55:02.802027 139462596097792 logging_writer.py:48] [700] global_step=700, grad_norm=0.16454775631427765, loss=0.3240073323249817
I0204 22:55:07.502269 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:55:08.872992 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:55:10.192428 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:55:11.511168 139681449744192 submission_runner.py:408] Time since start: 301.58s, 	Step: 715, 	{'train/ssim': 0.716080801827567, 'train/loss': 0.29663303920200895, 'validation/ssim': 0.6942070664216375, 'validation/loss': 0.31458817859278276, 'validation/num_examples': 3554, 'test/ssim': 0.7114660736569743, 'test/loss': 0.31690584857581683, 'test/num_examples': 3581, 'score': 285.4695768356323, 'total_duration': 301.5783360004425, 'accumulated_submission_time': 285.4695768356323, 'accumulated_eval_time': 15.985013246536255, 'accumulated_logging_time': 0.09372925758361816}
I0204 22:55:11.528296 139462604490496 logging_writer.py:48] [715] accumulated_eval_time=15.985013, accumulated_logging_time=0.093729, accumulated_submission_time=285.469577, global_step=715, preemption_count=0, score=285.469577, test/loss=0.316906, test/num_examples=3581, test/ssim=0.711466, total_duration=301.578336, train/loss=0.296633, train/ssim=0.716081, validation/loss=0.314588, validation/num_examples=3554, validation/ssim=0.694207
I0204 22:55:34.758256 139462596097792 logging_writer.py:48] [800] global_step=800, grad_norm=0.10720288753509521, loss=0.25179094076156616
I0204 22:55:59.222124 139462604490496 logging_writer.py:48] [900] global_step=900, grad_norm=0.11258269846439362, loss=0.31826359033584595
I0204 22:56:23.775658 139462596097792 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.12952697277069092, loss=0.2628425359725952
I0204 22:56:31.516096 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:56:32.886092 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:56:34.205670 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:56:35.521940 139681449744192 submission_runner.py:408] Time since start: 385.59s, 	Step: 1034, 	{'train/ssim': 0.7235066550118583, 'train/loss': 0.2870752811431885, 'validation/ssim': 0.7026445499349324, 'validation/loss': 0.30453200976232764, 'validation/num_examples': 3554, 'test/ssim': 0.7197285396231848, 'test/loss': 0.3066954731242146, 'test/num_examples': 3581, 'score': 365.43087816238403, 'total_duration': 385.58914399147034, 'accumulated_submission_time': 365.43087816238403, 'accumulated_eval_time': 19.990835666656494, 'accumulated_logging_time': 0.12387990951538086}
I0204 22:56:35.536436 139462604490496 logging_writer.py:48] [1034] accumulated_eval_time=19.990836, accumulated_logging_time=0.123880, accumulated_submission_time=365.430878, global_step=1034, preemption_count=0, score=365.430878, test/loss=0.306695, test/num_examples=3581, test/ssim=0.719729, total_duration=385.589144, train/loss=0.287075, train/ssim=0.723507, validation/loss=0.304532, validation/num_examples=3554, validation/ssim=0.702645
I0204 22:56:49.383714 139462596097792 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.5032289624214172, loss=0.2662675380706787
I0204 22:57:13.168357 139462604490496 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.16637957096099854, loss=0.25427281856536865
I0204 22:57:36.820176 139462596097792 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.13284821808338165, loss=0.36560168862342834
I0204 22:57:55.702021 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:57:57.073002 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:57:58.390611 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:57:59.709091 139681449744192 submission_runner.py:408] Time since start: 469.78s, 	Step: 1381, 	{'train/ssim': 0.7308674539838519, 'train/loss': 0.27990336077553885, 'validation/ssim': 0.7087941596396665, 'validation/loss': 0.2979709537229178, 'validation/num_examples': 3554, 'test/ssim': 0.7259140717720259, 'test/loss': 0.29985247933974446, 'test/num_examples': 3581, 'score': 445.5725281238556, 'total_duration': 469.7762997150421, 'accumulated_submission_time': 445.5725281238556, 'accumulated_eval_time': 23.99786949157715, 'accumulated_logging_time': 0.14786100387573242}
I0204 22:57:59.723927 139462604490496 logging_writer.py:48] [1381] accumulated_eval_time=23.997869, accumulated_logging_time=0.147861, accumulated_submission_time=445.572528, global_step=1381, preemption_count=0, score=445.572528, test/loss=0.299852, test/num_examples=3581, test/ssim=0.725914, total_duration=469.776300, train/loss=0.279903, train/ssim=0.730867, validation/loss=0.297971, validation/num_examples=3554, validation/ssim=0.708794
I0204 22:58:02.179162 139462596097792 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.25165414810180664, loss=0.27188602089881897
I0204 22:58:26.048871 139462604490496 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.1311715543270111, loss=0.336352676153183
I0204 22:58:49.879257 139462596097792 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.155751571059227, loss=0.1926872432231903
I0204 22:59:13.922184 139462604490496 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.24059288203716278, loss=0.3370162844657898
I0204 22:59:19.869157 139681449744192 spec.py:321] Evaluating on the training split.
I0204 22:59:21.237124 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 22:59:22.557343 139681449744192 spec.py:349] Evaluating on the test split.
I0204 22:59:23.877583 139681449744192 submission_runner.py:408] Time since start: 553.94s, 	Step: 1727, 	{'train/ssim': 0.7333673749651227, 'train/loss': 0.2783775159290859, 'validation/ssim': 0.7113109925655952, 'validation/loss': 0.2964568902886712, 'validation/num_examples': 3554, 'test/ssim': 0.7284042243350322, 'test/loss': 0.298256906841228, 'test/num_examples': 3581, 'score': 525.693502664566, 'total_duration': 553.9444513320923, 'accumulated_submission_time': 525.693502664566, 'accumulated_eval_time': 28.005931615829468, 'accumulated_logging_time': 0.17231059074401855}
I0204 22:59:23.891995 139462596097792 logging_writer.py:48] [1727] accumulated_eval_time=28.005932, accumulated_logging_time=0.172311, accumulated_submission_time=525.693503, global_step=1727, preemption_count=0, score=525.693503, test/loss=0.298257, test/num_examples=3581, test/ssim=0.728404, total_duration=553.944451, train/loss=0.278378, train/ssim=0.733367, validation/loss=0.296457, validation/num_examples=3554, validation/ssim=0.711311
I0204 22:59:39.051788 139462604490496 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.1038103774189949, loss=0.27820825576782227
I0204 23:00:02.758119 139462596097792 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.1611683964729309, loss=0.21781519055366516
I0204 23:00:26.864597 139462604490496 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.08994849026203156, loss=0.3358006477355957
I0204 23:00:44.003484 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:00:45.371452 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:00:46.690556 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:00:48.010281 139681449744192 submission_runner.py:408] Time since start: 638.08s, 	Step: 2073, 	{'train/ssim': 0.7364885466439384, 'train/loss': 0.275574905531747, 'validation/ssim': 0.7148465664787915, 'validation/loss': 0.29355547061849324, 'validation/num_examples': 3554, 'test/ssim': 0.7319312075668458, 'test/loss': 0.29527090541879014, 'test/num_examples': 3581, 'score': 605.7808966636658, 'total_duration': 638.0774807929993, 'accumulated_submission_time': 605.7808966636658, 'accumulated_eval_time': 32.01269316673279, 'accumulated_logging_time': 0.19582176208496094}
I0204 23:00:48.025433 139462596097792 logging_writer.py:48] [2073] accumulated_eval_time=32.012693, accumulated_logging_time=0.195822, accumulated_submission_time=605.780897, global_step=2073, preemption_count=0, score=605.780897, test/loss=0.295271, test/num_examples=3581, test/ssim=0.731931, total_duration=638.077481, train/loss=0.275575, train/ssim=0.736489, validation/loss=0.293555, validation/num_examples=3554, validation/ssim=0.714847
I0204 23:00:52.391618 139462604490496 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.2124064564704895, loss=0.28997382521629333
I0204 23:01:16.583718 139462596097792 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.448141485452652, loss=0.2866002917289734
I0204 23:01:40.087249 139462604490496 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.15729349851608276, loss=0.2242555171251297
I0204 23:02:03.722960 139462596097792 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.15656274557113647, loss=0.28382712602615356
I0204 23:02:08.168802 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:02:09.540762 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:02:10.861881 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:02:12.182708 139681449744192 submission_runner.py:408] Time since start: 722.25s, 	Step: 2420, 	{'train/ssim': 0.7353577613830566, 'train/loss': 0.27537080219813753, 'validation/ssim': 0.7139438506788126, 'validation/loss': 0.2931602705578222, 'validation/num_examples': 3554, 'test/ssim': 0.7310254806181933, 'test/loss': 0.29491601180710697, 'test/num_examples': 3581, 'score': 685.8993790149689, 'total_duration': 722.2499129772186, 'accumulated_submission_time': 685.8993790149689, 'accumulated_eval_time': 36.02655911445618, 'accumulated_logging_time': 0.22134160995483398}
I0204 23:02:12.198189 139462604490496 logging_writer.py:48] [2420] accumulated_eval_time=36.026559, accumulated_logging_time=0.221342, accumulated_submission_time=685.899379, global_step=2420, preemption_count=0, score=685.899379, test/loss=0.294916, test/num_examples=3581, test/ssim=0.731025, total_duration=722.249913, train/loss=0.275371, train/ssim=0.735358, validation/loss=0.293160, validation/num_examples=3554, validation/ssim=0.713944
I0204 23:02:29.372752 139462596097792 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.15742415189743042, loss=0.2578919231891632
I0204 23:02:53.290874 139462604490496 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.059832535684108734, loss=0.2531015872955322
I0204 23:03:17.051494 139462596097792 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.10355433076620102, loss=0.29418572783470154
I0204 23:03:32.293003 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:03:33.666094 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:03:34.987051 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:03:36.307502 139681449744192 submission_runner.py:408] Time since start: 806.37s, 	Step: 2765, 	{'train/ssim': 0.7376354762486049, 'train/loss': 0.2741092954363142, 'validation/ssim': 0.7155301464898706, 'validation/loss': 0.29229203944938803, 'validation/num_examples': 3554, 'test/ssim': 0.7326973768893117, 'test/loss': 0.2939401310737224, 'test/num_examples': 3581, 'score': 765.968150138855, 'total_duration': 806.3747057914734, 'accumulated_submission_time': 765.968150138855, 'accumulated_eval_time': 40.04101777076721, 'accumulated_logging_time': 0.2482287883758545}
I0204 23:03:36.322238 139462604490496 logging_writer.py:48] [2765] accumulated_eval_time=40.041018, accumulated_logging_time=0.248229, accumulated_submission_time=765.968150, global_step=2765, preemption_count=0, score=765.968150, test/loss=0.293940, test/num_examples=3581, test/ssim=0.732697, total_duration=806.374706, train/loss=0.274109, train/ssim=0.737635, validation/loss=0.292292, validation/num_examples=3554, validation/ssim=0.715530
I0204 23:03:42.601619 139462596097792 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.1964678019285202, loss=0.35101690888404846
I0204 23:04:06.328140 139462604490496 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.17732620239257812, loss=0.2260357141494751
I0204 23:04:29.988353 139462596097792 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.08115313947200775, loss=0.2601655125617981
I0204 23:04:54.037187 139462604490496 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.21948422491550446, loss=0.2400251030921936
I0204 23:04:56.474483 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:04:57.841650 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:04:59.161977 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:05:00.480123 139681449744192 submission_runner.py:408] Time since start: 890.55s, 	Step: 3110, 	{'train/ssim': 0.7347473417009626, 'train/loss': 0.27508325236184256, 'validation/ssim': 0.7142884915104459, 'validation/loss': 0.2927851636690173, 'validation/num_examples': 3554, 'test/ssim': 0.7312285788929419, 'test/loss': 0.29438552920360933, 'test/num_examples': 3581, 'score': 846.0964727401733, 'total_duration': 890.5473172664642, 'accumulated_submission_time': 846.0964727401733, 'accumulated_eval_time': 44.046605587005615, 'accumulated_logging_time': 0.27246928215026855}
I0204 23:05:00.496986 139462596097792 logging_writer.py:48] [3110] accumulated_eval_time=44.046606, accumulated_logging_time=0.272469, accumulated_submission_time=846.096473, global_step=3110, preemption_count=0, score=846.096473, test/loss=0.294386, test/num_examples=3581, test/ssim=0.731229, total_duration=890.547317, train/loss=0.275083, train/ssim=0.734747, validation/loss=0.292785, validation/num_examples=3554, validation/ssim=0.714288
I0204 23:05:19.829978 139462604490496 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.13561998307704926, loss=0.27402082085609436
I0204 23:05:43.601288 139462596097792 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10082777589559555, loss=0.3067592680454254
I0204 23:06:07.185879 139462604490496 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.08127493411302567, loss=0.37726882100105286
I0204 23:06:20.712104 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:06:22.081824 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:06:23.402847 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:06:24.722249 139681449744192 submission_runner.py:408] Time since start: 974.79s, 	Step: 3458, 	{'train/ssim': 0.7395678247724261, 'train/loss': 0.2726844719478062, 'validation/ssim': 0.7174643117789814, 'validation/loss': 0.2909971118040412, 'validation/num_examples': 3554, 'test/ssim': 0.7346316851307246, 'test/loss': 0.29266008016484574, 'test/num_examples': 3581, 'score': 926.2872281074524, 'total_duration': 974.789454460144, 'accumulated_submission_time': 926.2872281074524, 'accumulated_eval_time': 48.05672740936279, 'accumulated_logging_time': 0.2985961437225342}
I0204 23:06:24.741194 139462596097792 logging_writer.py:48] [3458] accumulated_eval_time=48.056727, accumulated_logging_time=0.298596, accumulated_submission_time=926.287228, global_step=3458, preemption_count=0, score=926.287228, test/loss=0.292660, test/num_examples=3581, test/ssim=0.734632, total_duration=974.789454, train/loss=0.272684, train/ssim=0.739568, validation/loss=0.290997, validation/num_examples=3554, validation/ssim=0.717464
I0204 23:06:35.279765 139462604490496 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.16294430196285248, loss=0.32436254620552063
I0204 23:06:59.078317 139462596097792 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.16498853266239166, loss=0.2881898880004883
I0204 23:07:22.857000 139462604490496 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.10597268491983414, loss=0.2254488170146942
I0204 23:07:44.759847 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:07:46.130228 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:07:47.450440 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:07:48.770637 139681449744192 submission_runner.py:408] Time since start: 1058.84s, 	Step: 3793, 	{'train/ssim': 0.7412997654506138, 'train/loss': 0.27185327666146414, 'validation/ssim': 0.7187269186128307, 'validation/loss': 0.29030635320677406, 'validation/num_examples': 3554, 'test/ssim': 0.7358856584665596, 'test/loss': 0.29188521831803266, 'test/num_examples': 3581, 'score': 1003.8125767707825, 'total_duration': 1058.8378336429596, 'accumulated_submission_time': 1003.8125767707825, 'accumulated_eval_time': 52.06747007369995, 'accumulated_logging_time': 2.796729803085327}
I0204 23:07:48.786195 139462596097792 logging_writer.py:48] [3793] accumulated_eval_time=52.067470, accumulated_logging_time=2.796730, accumulated_submission_time=1003.812577, global_step=3793, preemption_count=0, score=1003.812577, test/loss=0.291885, test/num_examples=3581, test/ssim=0.735886, total_duration=1058.837834, train/loss=0.271853, train/ssim=0.741300, validation/loss=0.290306, validation/num_examples=3554, validation/ssim=0.718727
I0204 23:07:49.380380 139462604490496 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.0658441036939621, loss=0.25506678223609924
I0204 23:08:12.191617 139462596097792 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.2206227332353592, loss=0.2791025936603546
I0204 23:08:35.985051 139462604490496 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2799810469150543, loss=0.22281809151172638
I0204 23:08:59.946006 139462596097792 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.14826415479183197, loss=0.2948167026042938
I0204 23:09:08.914273 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:09:10.283927 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:09:11.604082 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:09:12.925392 139681449744192 submission_runner.py:408] Time since start: 1142.99s, 	Step: 4139, 	{'train/ssim': 0.7402080808367048, 'train/loss': 0.2731419290815081, 'validation/ssim': 0.7178762046285875, 'validation/loss': 0.29150270409441825, 'validation/num_examples': 3554, 'test/ssim': 0.7350120427254957, 'test/loss': 0.29316172404050894, 'test/num_examples': 3581, 'score': 1083.9166858196259, 'total_duration': 1142.9926023483276, 'accumulated_submission_time': 1083.9166858196259, 'accumulated_eval_time': 56.0785710811615, 'accumulated_logging_time': 2.8215391635894775}
I0204 23:09:12.940787 139462604490496 logging_writer.py:48] [4139] accumulated_eval_time=56.078571, accumulated_logging_time=2.821539, accumulated_submission_time=1083.916686, global_step=4139, preemption_count=0, score=1083.916686, test/loss=0.293162, test/num_examples=3581, test/ssim=0.735012, total_duration=1142.992602, train/loss=0.273142, train/ssim=0.740208, validation/loss=0.291503, validation/num_examples=3554, validation/ssim=0.717876
I0204 23:09:25.797091 139462596097792 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.05051429942250252, loss=0.2366078644990921
I0204 23:09:49.620584 139462604490496 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.28023561835289, loss=0.3180440366268158
I0204 23:10:13.588232 139462596097792 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.13320299983024597, loss=0.25876888632774353
I0204 23:10:33.110672 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:10:34.481806 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:10:35.800883 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:10:37.120827 139681449744192 submission_runner.py:408] Time since start: 1227.19s, 	Step: 4484, 	{'train/ssim': 0.7428110667637416, 'train/loss': 0.2710321971348354, 'validation/ssim': 0.71978186165676, 'validation/loss': 0.2897092597029755, 'validation/num_examples': 3554, 'test/ssim': 0.7369192848322745, 'test/loss': 0.29128751352624965, 'test/num_examples': 3581, 'score': 1164.0630095005035, 'total_duration': 1227.1880266666412, 'accumulated_submission_time': 1164.0630095005035, 'accumulated_eval_time': 60.08868336677551, 'accumulated_logging_time': 2.8460841178894043}
I0204 23:10:37.136467 139462604490496 logging_writer.py:48] [4484] accumulated_eval_time=60.088683, accumulated_logging_time=2.846084, accumulated_submission_time=1164.063010, global_step=4484, preemption_count=0, score=1164.063010, test/loss=0.291288, test/num_examples=3581, test/ssim=0.736919, total_duration=1227.188027, train/loss=0.271032, train/ssim=0.742811, validation/loss=0.289709, validation/num_examples=3554, validation/ssim=0.719782
I0204 23:10:38.792705 139462596097792 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1747814118862152, loss=0.2633800506591797
I0204 23:11:02.742891 139462604490496 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.2053896188735962, loss=0.23357011377811432
I0204 23:11:26.510000 139462596097792 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1033409833908081, loss=0.25372523069381714
I0204 23:11:50.260884 139462604490496 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.18212804198265076, loss=0.26614910364151
I0204 23:11:57.245700 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:11:58.618321 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:11:59.936710 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:12:01.256207 139681449744192 submission_runner.py:408] Time since start: 1311.32s, 	Step: 4831, 	{'train/ssim': 0.7431929452078683, 'train/loss': 0.27073839732578825, 'validation/ssim': 0.7205519281751196, 'validation/loss': 0.28930533542751125, 'validation/num_examples': 3554, 'test/ssim': 0.737703248263404, 'test/loss': 0.2908246621710067, 'test/num_examples': 3581, 'score': 1244.148692369461, 'total_duration': 1311.323415517807, 'accumulated_submission_time': 1244.148692369461, 'accumulated_eval_time': 64.09915161132812, 'accumulated_logging_time': 2.870636463165283}
I0204 23:12:01.272089 139462596097792 logging_writer.py:48] [4831] accumulated_eval_time=64.099152, accumulated_logging_time=2.870636, accumulated_submission_time=1244.148692, global_step=4831, preemption_count=0, score=1244.148692, test/loss=0.290825, test/num_examples=3581, test/ssim=0.737703, total_duration=1311.323416, train/loss=0.270738, train/ssim=0.743193, validation/loss=0.289305, validation/num_examples=3554, validation/ssim=0.720552
I0204 23:12:15.859785 139462604490496 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.10414283722639084, loss=0.36851611733436584
I0204 23:12:39.688241 139462596097792 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.08228541165590286, loss=0.2966511845588684
I0204 23:13:03.647938 139462604490496 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.11773542314767838, loss=0.24027219414710999
I0204 23:13:21.295611 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:13:22.665740 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:13:23.985759 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:13:25.306816 139681449744192 submission_runner.py:408] Time since start: 1395.37s, 	Step: 5175, 	{'train/ssim': 0.7424209458487374, 'train/loss': 0.27047678402491976, 'validation/ssim': 0.7198196436893289, 'validation/loss': 0.2888622552273846, 'validation/num_examples': 3554, 'test/ssim': 0.7370804544601718, 'test/loss': 0.29030815578312624, 'test/num_examples': 3581, 'score': 1324.1467669010162, 'total_duration': 1395.3740241527557, 'accumulated_submission_time': 1324.1467669010162, 'accumulated_eval_time': 68.11032629013062, 'accumulated_logging_time': 2.897249937057495}
I0204 23:13:25.322240 139462596097792 logging_writer.py:48] [5175] accumulated_eval_time=68.110326, accumulated_logging_time=2.897250, accumulated_submission_time=1324.146767, global_step=5175, preemption_count=0, score=1324.146767, test/loss=0.290308, test/num_examples=3581, test/ssim=0.737080, total_duration=1395.374024, train/loss=0.270477, train/ssim=0.742421, validation/loss=0.288862, validation/num_examples=3554, validation/ssim=0.719820
I0204 23:13:29.273574 139462604490496 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.044729799032211304, loss=0.3117711842060089
I0204 23:13:53.458234 139462596097792 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.15223892033100128, loss=0.19814644753932953
I0204 23:14:17.349059 139462604490496 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.14459140598773956, loss=0.23647081851959229
I0204 23:14:41.721987 139462596097792 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.2500382661819458, loss=0.2706975042819977
I0204 23:14:45.474922 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:14:46.845652 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:14:48.166480 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:14:49.486551 139681449744192 submission_runner.py:408] Time since start: 1479.55s, 	Step: 5517, 	{'train/ssim': 0.7446633747645787, 'train/loss': 0.27059595925467356, 'validation/ssim': 0.7215675779051772, 'validation/loss': 0.28925429533624086, 'validation/num_examples': 3554, 'test/ssim': 0.7387610773439681, 'test/loss': 0.29075000872661266, 'test/num_examples': 3581, 'score': 1404.2759974002838, 'total_duration': 1479.5537617206573, 'accumulated_submission_time': 1404.2759974002838, 'accumulated_eval_time': 72.12192797660828, 'accumulated_logging_time': 2.9218204021453857}
I0204 23:14:49.502307 139462604490496 logging_writer.py:48] [5517] accumulated_eval_time=72.121928, accumulated_logging_time=2.921820, accumulated_submission_time=1404.275997, global_step=5517, preemption_count=0, score=1404.275997, test/loss=0.290750, test/num_examples=3581, test/ssim=0.738761, total_duration=1479.553762, train/loss=0.270596, train/ssim=0.744663, validation/loss=0.289254, validation/num_examples=3554, validation/ssim=0.721568
I0204 23:15:07.081199 139462596097792 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.2788388729095459, loss=0.2274453043937683
I0204 23:15:30.983731 139462604490496 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.1339733749628067, loss=0.2918813228607178
I0204 23:15:55.021260 139462596097792 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.12288247793912888, loss=0.43598881363868713
I0204 23:16:09.684923 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:16:11.055834 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:16:12.376791 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:16:13.695586 139681449744192 submission_runner.py:408] Time since start: 1563.76s, 	Step: 5863, 	{'train/ssim': 0.7418193135942731, 'train/loss': 0.27057336057935444, 'validation/ssim': 0.7196740111274268, 'validation/loss': 0.28884714241435705, 'validation/num_examples': 3554, 'test/ssim': 0.737032253560458, 'test/loss': 0.2902668407262287, 'test/num_examples': 3581, 'score': 1484.4351799488068, 'total_duration': 1563.7628009319305, 'accumulated_submission_time': 1484.4351799488068, 'accumulated_eval_time': 76.13256049156189, 'accumulated_logging_time': 2.946476936340332}
I0204 23:16:13.711686 139462604490496 logging_writer.py:48] [5863] accumulated_eval_time=76.132560, accumulated_logging_time=2.946477, accumulated_submission_time=1484.435180, global_step=5863, preemption_count=0, score=1484.435180, test/loss=0.290267, test/num_examples=3581, test/ssim=0.737032, total_duration=1563.762801, train/loss=0.270573, train/ssim=0.741819, validation/loss=0.288847, validation/num_examples=3554, validation/ssim=0.719674
I0204 23:16:20.408470 139462596097792 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.08093198388814926, loss=0.2798030972480774
I0204 23:16:44.202345 139462604490496 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.1963718831539154, loss=0.23700648546218872
I0204 23:17:07.951577 139462596097792 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.21609513461589813, loss=0.33553001284599304
I0204 23:17:31.774344 139462604490496 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.1167832612991333, loss=0.23252983391284943
I0204 23:17:33.907062 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:17:35.276199 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:17:36.601663 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:17:37.920735 139681449744192 submission_runner.py:408] Time since start: 1647.99s, 	Step: 6210, 	{'train/ssim': 0.745011465890067, 'train/loss': 0.2705646753311157, 'validation/ssim': 0.7222998623909679, 'validation/loss': 0.28937413307408905, 'validation/num_examples': 3554, 'test/ssim': 0.7394353445266685, 'test/loss': 0.2908501261540945, 'test/num_examples': 3581, 'score': 1564.6058371067047, 'total_duration': 1647.987946987152, 'accumulated_submission_time': 1564.6058371067047, 'accumulated_eval_time': 80.14620423316956, 'accumulated_logging_time': 2.9725465774536133}
I0204 23:17:37.936762 139462596097792 logging_writer.py:48] [6210] accumulated_eval_time=80.146204, accumulated_logging_time=2.972547, accumulated_submission_time=1564.605837, global_step=6210, preemption_count=0, score=1564.605837, test/loss=0.290850, test/num_examples=3581, test/ssim=0.739435, total_duration=1647.987947, train/loss=0.270565, train/ssim=0.745011, validation/loss=0.289374, validation/num_examples=3554, validation/ssim=0.722300
I0204 23:17:57.289242 139462604490496 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.11562811583280563, loss=0.28175050020217896
I0204 23:18:21.702789 139462596097792 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.1708330512046814, loss=0.28612440824508667
I0204 23:18:45.764217 139462604490496 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.12691468000411987, loss=0.24930231273174286
I0204 23:18:58.176662 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:18:59.547233 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:19:00.865714 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:19:02.185730 139681449744192 submission_runner.py:408] Time since start: 1732.25s, 	Step: 6553, 	{'train/ssim': 0.7449780872889927, 'train/loss': 0.2694678476878575, 'validation/ssim': 0.7216078329435144, 'validation/loss': 0.28847299725001757, 'validation/num_examples': 3554, 'test/ssim': 0.7388201865095294, 'test/loss': 0.28997773759293843, 'test/num_examples': 3581, 'score': 1644.8221879005432, 'total_duration': 1732.2529256343842, 'accumulated_submission_time': 1644.8221879005432, 'accumulated_eval_time': 84.1552243232727, 'accumulated_logging_time': 2.997762680053711}
I0204 23:19:02.202186 139462596097792 logging_writer.py:48] [6553] accumulated_eval_time=84.155224, accumulated_logging_time=2.997763, accumulated_submission_time=1644.822188, global_step=6553, preemption_count=0, score=1644.822188, test/loss=0.289978, test/num_examples=3581, test/ssim=0.738820, total_duration=1732.252926, train/loss=0.269468, train/ssim=0.744978, validation/loss=0.288473, validation/num_examples=3554, validation/ssim=0.721608
I0204 23:19:11.241484 139462604490496 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.07415754348039627, loss=0.31032323837280273
I0204 23:19:34.969184 139462596097792 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.14891695976257324, loss=0.2599342167377472
I0204 23:19:58.926972 139462604490496 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.1344415545463562, loss=0.2769519090652466
I0204 23:20:22.385916 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:20:23.756757 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:20:25.075052 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:20:26.396979 139681449744192 submission_runner.py:408] Time since start: 1816.46s, 	Step: 6899, 	{'train/ssim': 0.7441498211451939, 'train/loss': 0.2704054968697684, 'validation/ssim': 0.722005643399163, 'validation/loss': 0.2887626823979143, 'validation/num_examples': 3554, 'test/ssim': 0.7392115887234711, 'test/loss': 0.29011344323774785, 'test/num_examples': 3581, 'score': 1724.981882095337, 'total_duration': 1816.4641880989075, 'accumulated_submission_time': 1724.981882095337, 'accumulated_eval_time': 88.16625618934631, 'accumulated_logging_time': 3.023563861846924}
I0204 23:20:26.413502 139462596097792 logging_writer.py:48] [6899] accumulated_eval_time=88.166256, accumulated_logging_time=3.023564, accumulated_submission_time=1724.981882, global_step=6899, preemption_count=0, score=1724.981882, test/loss=0.290113, test/num_examples=3581, test/ssim=0.739212, total_duration=1816.464188, train/loss=0.270405, train/ssim=0.744150, validation/loss=0.288763, validation/num_examples=3554, validation/ssim=0.722006
I0204 23:20:26.575488 139462604490496 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.11045413464307785, loss=0.3137458562850952
I0204 23:20:48.155433 139462596097792 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.3045167028903961, loss=0.22728078067302704
I0204 23:21:12.065934 139462604490496 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.11343157291412354, loss=0.2413267344236374
I0204 23:21:35.923369 139462596097792 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.16813363134860992, loss=0.2361074984073639
I0204 23:21:46.641799 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:21:48.010190 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:21:49.330314 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:21:50.650118 139681449744192 submission_runner.py:408] Time since start: 1900.72s, 	Step: 7247, 	{'train/ssim': 0.7448177337646484, 'train/loss': 0.2693194661821638, 'validation/ssim': 0.7221843180659117, 'validation/loss': 0.28803211527724043, 'validation/num_examples': 3554, 'test/ssim': 0.7395222015934795, 'test/loss': 0.28933997901249653, 'test/num_examples': 3581, 'score': 1805.1859049797058, 'total_duration': 1900.717324256897, 'accumulated_submission_time': 1805.1859049797058, 'accumulated_eval_time': 92.17454433441162, 'accumulated_logging_time': 3.0495445728302}
I0204 23:21:50.666689 139462604490496 logging_writer.py:48] [7247] accumulated_eval_time=92.174544, accumulated_logging_time=3.049545, accumulated_submission_time=1805.185905, global_step=7247, preemption_count=0, score=1805.185905, test/loss=0.289340, test/num_examples=3581, test/ssim=0.739522, total_duration=1900.717324, train/loss=0.269319, train/ssim=0.744818, validation/loss=0.288032, validation/num_examples=3554, validation/ssim=0.722184
I0204 23:22:01.237671 139462596097792 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.14688041806221008, loss=0.2469661384820938
I0204 23:22:25.582362 139462604490496 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.15121161937713623, loss=0.2574912905693054
I0204 23:22:49.837094 139462596097792 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.19695530831813812, loss=0.19041548669338226
I0204 23:23:10.688556 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:23:12.058757 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:23:13.379157 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:23:14.699486 139681449744192 submission_runner.py:408] Time since start: 1984.77s, 	Step: 7588, 	{'train/ssim': 0.7447967529296875, 'train/loss': 0.2691126380647932, 'validation/ssim': 0.7220263204751688, 'validation/loss': 0.28787920108724324, 'validation/num_examples': 3554, 'test/ssim': 0.7393584412524434, 'test/loss': 0.28932811627338734, 'test/num_examples': 3581, 'score': 1885.1832218170166, 'total_duration': 1984.7666964530945, 'accumulated_submission_time': 1885.1832218170166, 'accumulated_eval_time': 96.1854498386383, 'accumulated_logging_time': 3.076326608657837}
I0204 23:23:14.716028 139462604490496 logging_writer.py:48] [7588] accumulated_eval_time=96.185450, accumulated_logging_time=3.076327, accumulated_submission_time=1885.183222, global_step=7588, preemption_count=0, score=1885.183222, test/loss=0.289328, test/num_examples=3581, test/ssim=0.739358, total_duration=1984.766696, train/loss=0.269113, train/ssim=0.744797, validation/loss=0.287879, validation/num_examples=3554, validation/ssim=0.722026
I0204 23:23:15.671070 139462596097792 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.36932235956192017, loss=0.25377506017684937
I0204 23:23:39.380755 139462604490496 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.1615229696035385, loss=0.24275065958499908
I0204 23:24:03.406523 139462596097792 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.0679185763001442, loss=0.35064342617988586
I0204 23:24:27.091607 139462604490496 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.11564386636018753, loss=0.29016098380088806
I0204 23:24:34.922540 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:24:36.292945 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:24:37.614670 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:24:38.932868 139681449744192 submission_runner.py:408] Time since start: 2069.00s, 	Step: 7934, 	{'train/ssim': 0.7456778798784528, 'train/loss': 0.2690371445247105, 'validation/ssim': 0.7227637570563098, 'validation/loss': 0.2876706442674627, 'validation/num_examples': 3554, 'test/ssim': 0.7399581231674114, 'test/loss': 0.28911158719631386, 'test/num_examples': 3581, 'score': 1965.3660056591034, 'total_duration': 2069.0000624656677, 'accumulated_submission_time': 1965.3660056591034, 'accumulated_eval_time': 100.19572973251343, 'accumulated_logging_time': 3.102079153060913}
I0204 23:24:38.949640 139462596097792 logging_writer.py:48] [7934] accumulated_eval_time=100.195730, accumulated_logging_time=3.102079, accumulated_submission_time=1965.366006, global_step=7934, preemption_count=0, score=1965.366006, test/loss=0.289112, test/num_examples=3581, test/ssim=0.739958, total_duration=2069.000062, train/loss=0.269037, train/ssim=0.745678, validation/loss=0.287671, validation/num_examples=3554, validation/ssim=0.722764
I0204 23:24:52.580519 139462604490496 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.1230674460530281, loss=0.2650650143623352
I0204 23:25:16.429630 139462596097792 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.3371597230434418, loss=0.2611861228942871
I0204 23:25:40.207497 139462604490496 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.07500598579645157, loss=0.32266765832901
I0204 23:25:59.022162 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:26:00.391839 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:26:01.712551 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:26:03.031417 139681449744192 submission_runner.py:408] Time since start: 2153.10s, 	Step: 8281, 	{'train/ssim': 0.745875358581543, 'train/loss': 0.26912626198359896, 'validation/ssim': 0.7229084278937464, 'validation/loss': 0.2879217230475345, 'validation/num_examples': 3554, 'test/ssim': 0.7401415865636345, 'test/loss': 0.2892600418768326, 'test/num_examples': 3581, 'score': 2045.4119424819946, 'total_duration': 2153.09862613678, 'accumulated_submission_time': 2045.4119424819946, 'accumulated_eval_time': 104.20498085021973, 'accumulated_logging_time': 3.1299993991851807}
I0204 23:26:03.048768 139462596097792 logging_writer.py:48] [8281] accumulated_eval_time=104.204981, accumulated_logging_time=3.129999, accumulated_submission_time=2045.411942, global_step=8281, preemption_count=0, score=2045.411942, test/loss=0.289260, test/num_examples=3581, test/ssim=0.740142, total_duration=2153.098626, train/loss=0.269126, train/ssim=0.745875, validation/loss=0.287922, validation/num_examples=3554, validation/ssim=0.722908
I0204 23:26:05.508906 139462604490496 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.31310704350471497, loss=0.2966323792934418
I0204 23:26:29.372365 139462596097792 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.16292892396450043, loss=0.2329583615064621
I0204 23:26:53.535306 139462604490496 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.13153794407844543, loss=0.2765822112560272
I0204 23:27:17.752598 139462596097792 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.20216204226016998, loss=0.19614861905574799
I0204 23:27:23.038525 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:27:24.406398 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:27:25.725812 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:27:27.046741 139681449744192 submission_runner.py:408] Time since start: 2237.11s, 	Step: 8624, 	{'train/ssim': 0.7451011112758091, 'train/loss': 0.26903940950121197, 'validation/ssim': 0.7221248972328714, 'validation/loss': 0.28779779798070837, 'validation/num_examples': 3554, 'test/ssim': 0.739326602751501, 'test/loss': 0.2892616781167097, 'test/num_examples': 3581, 'score': 2125.377302646637, 'total_duration': 2237.1139464378357, 'accumulated_submission_time': 2125.377302646637, 'accumulated_eval_time': 108.21316409111023, 'accumulated_logging_time': 3.1573917865753174}
I0204 23:27:27.064484 139462604490496 logging_writer.py:48] [8624] accumulated_eval_time=108.213164, accumulated_logging_time=3.157392, accumulated_submission_time=2125.377303, global_step=8624, preemption_count=0, score=2125.377303, test/loss=0.289262, test/num_examples=3581, test/ssim=0.739327, total_duration=2237.113946, train/loss=0.269039, train/ssim=0.745101, validation/loss=0.287798, validation/num_examples=3554, validation/ssim=0.722125
I0204 23:27:43.246957 139462596097792 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.3582313060760498, loss=0.2684870660305023
I0204 23:28:07.081800 139462604490496 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.12245206534862518, loss=0.25996845960617065
I0204 23:28:30.956805 139462596097792 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.1936357468366623, loss=0.2923801839351654
I0204 23:28:47.172113 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:28:48.543442 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:28:49.861432 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:28:51.183650 139681449744192 submission_runner.py:408] Time since start: 2321.25s, 	Step: 8969, 	{'train/ssim': 0.7463887759617397, 'train/loss': 0.2680323464529855, 'validation/ssim': 0.7232508018034257, 'validation/loss': 0.2870491298317037, 'validation/num_examples': 3554, 'test/ssim': 0.7405642136885646, 'test/loss': 0.2884087539924253, 'test/num_examples': 3581, 'score': 2205.461377620697, 'total_duration': 2321.250861644745, 'accumulated_submission_time': 2205.461377620697, 'accumulated_eval_time': 112.22468495368958, 'accumulated_logging_time': 3.184272289276123}
I0204 23:28:51.200427 139462604490496 logging_writer.py:48] [8969] accumulated_eval_time=112.224685, accumulated_logging_time=3.184272, accumulated_submission_time=2205.461378, global_step=8969, preemption_count=0, score=2205.461378, test/loss=0.288409, test/num_examples=3581, test/ssim=0.740564, total_duration=2321.250862, train/loss=0.268032, train/ssim=0.746389, validation/loss=0.287049, validation/num_examples=3554, validation/ssim=0.723251
I0204 23:28:56.594123 139462596097792 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.2685445249080658, loss=0.33210548758506775
I0204 23:29:20.369015 139462604490496 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.10950642079114914, loss=0.28357070684432983
I0204 23:29:44.257981 139462596097792 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.38067543506622314, loss=0.2276017963886261
I0204 23:30:08.278447 139462604490496 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.061346955597400665, loss=0.4269558787345886
I0204 23:30:11.300090 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:30:12.669409 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:30:13.989020 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:30:15.311081 139681449744192 submission_runner.py:408] Time since start: 2405.38s, 	Step: 9314, 	{'train/ssim': 0.7459329877580915, 'train/loss': 0.26862949984414236, 'validation/ssim': 0.7227771525042206, 'validation/loss': 0.2875499993680096, 'validation/num_examples': 3554, 'test/ssim': 0.740029367778728, 'test/loss': 0.2889439066972389, 'test/num_examples': 3581, 'score': 2285.5357501506805, 'total_duration': 2405.378289461136, 'accumulated_submission_time': 2285.5357501506805, 'accumulated_eval_time': 116.23565125465393, 'accumulated_logging_time': 3.211730480194092}
I0204 23:30:15.329292 139462596097792 logging_writer.py:48] [9314] accumulated_eval_time=116.235651, accumulated_logging_time=3.211730, accumulated_submission_time=2285.535750, global_step=9314, preemption_count=0, score=2285.535750, test/loss=0.288944, test/num_examples=3581, test/ssim=0.740029, total_duration=2405.378289, train/loss=0.268629, train/ssim=0.745933, validation/loss=0.287550, validation/num_examples=3554, validation/ssim=0.722777
I0204 23:30:33.751347 139462604490496 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.09034091234207153, loss=0.2343437820672989
I0204 23:30:57.446866 139462596097792 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.0787036344408989, loss=0.26972395181655884
I0204 23:31:21.433586 139462604490496 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.22396601736545563, loss=0.3240031599998474
I0204 23:31:35.388474 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:31:36.758660 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:31:38.077482 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:31:39.399156 139681449744192 submission_runner.py:408] Time since start: 2489.47s, 	Step: 9658, 	{'train/ssim': 0.746016229901995, 'train/loss': 0.26843258312770296, 'validation/ssim': 0.7231320288319499, 'validation/loss': 0.2871666834739466, 'validation/num_examples': 3554, 'test/ssim': 0.7404210426993159, 'test/loss': 0.28856876461707626, 'test/num_examples': 3581, 'score': 2365.571274280548, 'total_duration': 2489.4663603305817, 'accumulated_submission_time': 2365.571274280548, 'accumulated_eval_time': 120.24630069732666, 'accumulated_logging_time': 3.239140033721924}
I0204 23:31:39.416432 139462596097792 logging_writer.py:48] [9658] accumulated_eval_time=120.246301, accumulated_logging_time=3.239140, accumulated_submission_time=2365.571274, global_step=9658, preemption_count=0, score=2365.571274, test/loss=0.288569, test/num_examples=3581, test/ssim=0.740421, total_duration=2489.466360, train/loss=0.268433, train/ssim=0.746016, validation/loss=0.287167, validation/num_examples=3554, validation/ssim=0.723132
I0204 23:31:47.344956 139462604490496 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.19417037069797516, loss=0.3243738114833832
I0204 23:32:11.541883 139462596097792 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.26793861389160156, loss=0.23135346174240112
I0204 23:32:35.908882 139462604490496 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.19116345047950745, loss=0.2489216923713684
I0204 23:32:59.476792 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:33:00.846680 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:33:02.166545 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:33:03.487728 139681449744192 submission_runner.py:408] Time since start: 2573.55s, 	Step: 10000, 	{'train/ssim': 0.7468297140938895, 'train/loss': 0.2678298609597342, 'validation/ssim': 0.7232698302089196, 'validation/loss': 0.2870614776868933, 'validation/num_examples': 3554, 'test/ssim': 0.7405252848148213, 'test/loss': 0.2884534437940694, 'test/num_examples': 3581, 'score': 2445.607465028763, 'total_duration': 2573.5549368858337, 'accumulated_submission_time': 2445.607465028763, 'accumulated_eval_time': 124.25722122192383, 'accumulated_logging_time': 3.26558256149292}
I0204 23:33:03.505907 139462596097792 logging_writer.py:48] [10000] accumulated_eval_time=124.257221, accumulated_logging_time=3.265583, accumulated_submission_time=2445.607465, global_step=10000, preemption_count=0, score=2445.607465, test/loss=0.288453, test/num_examples=3581, test/ssim=0.740525, total_duration=2573.554937, train/loss=0.267830, train/ssim=0.746830, validation/loss=0.287061, validation/num_examples=3554, validation/ssim=0.723270
I0204 23:33:03.595487 139462604490496 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.10737296938896179, loss=0.30922168493270874
I0204 23:33:25.296757 139462596097792 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.10726318508386612, loss=0.2535775601863861
I0204 23:33:49.059567 139462604490496 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.3280715346336365, loss=0.3675463795661926
I0204 23:34:12.942596 139462596097792 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.0914136990904808, loss=0.24205206334590912
I0204 23:34:23.635081 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:34:25.005058 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:34:26.327435 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:34:27.646305 139681449744192 submission_runner.py:408] Time since start: 2657.71s, 	Step: 10347, 	{'train/ssim': 0.746333122253418, 'train/loss': 0.2679857185908726, 'validation/ssim': 0.7232405663073298, 'validation/loss': 0.28692891427352984, 'validation/num_examples': 3554, 'test/ssim': 0.7405346931941148, 'test/loss': 0.288304341435266, 'test/num_examples': 3581, 'score': 2525.7125160694122, 'total_duration': 2657.7135181427, 'accumulated_submission_time': 2525.7125160694122, 'accumulated_eval_time': 128.26841831207275, 'accumulated_logging_time': 3.2932775020599365}
I0204 23:34:27.663712 139462604490496 logging_writer.py:48] [10347] accumulated_eval_time=128.268418, accumulated_logging_time=3.293278, accumulated_submission_time=2525.712516, global_step=10347, preemption_count=0, score=2525.712516, test/loss=0.288304, test/num_examples=3581, test/ssim=0.740535, total_duration=2657.713518, train/loss=0.267986, train/ssim=0.746333, validation/loss=0.286929, validation/num_examples=3554, validation/ssim=0.723241
I0204 23:34:38.364026 139462596097792 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.19574807584285736, loss=0.2928769886493683
I0204 23:35:02.224502 139462604490496 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.33130943775177, loss=0.3341818153858185
I0204 23:35:26.087543 139462596097792 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.11449234187602997, loss=0.2948160469532013
I0204 23:35:47.666237 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:35:49.034274 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:35:50.353749 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:35:51.674771 139681449744192 submission_runner.py:408] Time since start: 2741.74s, 	Step: 10691, 	{'train/ssim': 0.7459057399204799, 'train/loss': 0.26831020627702984, 'validation/ssim': 0.7228599981974536, 'validation/loss': 0.2871290903515405, 'validation/num_examples': 3554, 'test/ssim': 0.7402006957291958, 'test/loss': 0.28850590573512985, 'test/num_examples': 3581, 'score': 2605.6890666484833, 'total_duration': 2741.7419786453247, 'accumulated_submission_time': 2605.6890666484833, 'accumulated_eval_time': 132.2769341468811, 'accumulated_logging_time': 3.3216447830200195}
I0204 23:35:51.693274 139462604490496 logging_writer.py:48] [10691] accumulated_eval_time=132.276934, accumulated_logging_time=3.321645, accumulated_submission_time=2605.689067, global_step=10691, preemption_count=0, score=2605.689067, test/loss=0.288506, test/num_examples=3581, test/ssim=0.740201, total_duration=2741.741979, train/loss=0.268310, train/ssim=0.745906, validation/loss=0.287129, validation/num_examples=3554, validation/ssim=0.722860
I0204 23:35:52.434073 139462596097792 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.09018857777118683, loss=0.22927826642990112
I0204 23:36:15.849997 139462604490496 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.2071346938610077, loss=0.32516929507255554
I0204 23:36:39.752627 139462596097792 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.16561266779899597, loss=0.2607923150062561
I0204 23:37:03.589384 139462604490496 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.07455950975418091, loss=0.2661190330982208
I0204 23:37:11.855288 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:37:13.226091 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:37:14.547142 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:37:15.869819 139681449744192 submission_runner.py:408] Time since start: 2825.94s, 	Step: 11037, 	{'train/ssim': 0.7467265129089355, 'train/loss': 0.2679037196295602, 'validation/ssim': 0.7233592018895962, 'validation/loss': 0.2869203617952483, 'validation/num_examples': 3554, 'test/ssim': 0.7406535251151913, 'test/loss': 0.28831439749284415, 'test/num_examples': 3581, 'score': 2685.8272409439087, 'total_duration': 2825.9370296001434, 'accumulated_submission_time': 2685.8272409439087, 'accumulated_eval_time': 136.29143595695496, 'accumulated_logging_time': 3.349501371383667}
I0204 23:37:15.887712 139462596097792 logging_writer.py:48] [11037] accumulated_eval_time=136.291436, accumulated_logging_time=3.349501, accumulated_submission_time=2685.827241, global_step=11037, preemption_count=0, score=2685.827241, test/loss=0.288314, test/num_examples=3581, test/ssim=0.740654, total_duration=2825.937030, train/loss=0.267904, train/ssim=0.746727, validation/loss=0.286920, validation/num_examples=3554, validation/ssim=0.723359
I0204 23:37:28.938146 139462604490496 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.10205931961536407, loss=0.28628283739089966
I0204 23:37:52.540838 139462596097792 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.15385089814662933, loss=0.2762904167175293
I0204 23:38:16.624220 139462604490496 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.08639537543058395, loss=0.3327597379684448
I0204 23:38:36.056698 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:38:37.425582 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:38:38.746475 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:38:40.067659 139681449744192 submission_runner.py:408] Time since start: 2910.13s, 	Step: 11383, 	{'train/ssim': 0.7467336654663086, 'train/loss': 0.2682475192206247, 'validation/ssim': 0.7235851384443585, 'validation/loss': 0.28736591500114306, 'validation/num_examples': 3554, 'test/ssim': 0.7408546462667551, 'test/loss': 0.28879033876710414, 'test/num_examples': 3581, 'score': 2765.9728231430054, 'total_duration': 2910.1348733901978, 'accumulated_submission_time': 2765.9728231430054, 'accumulated_eval_time': 140.30236983299255, 'accumulated_logging_time': 3.3763203620910645}
I0204 23:38:40.085177 139462596097792 logging_writer.py:48] [11383] accumulated_eval_time=140.302370, accumulated_logging_time=3.376320, accumulated_submission_time=2765.972823, global_step=11383, preemption_count=0, score=2765.972823, test/loss=0.288790, test/num_examples=3581, test/ssim=0.740855, total_duration=2910.134873, train/loss=0.268248, train/ssim=0.746734, validation/loss=0.287366, validation/num_examples=3554, validation/ssim=0.723585
I0204 23:38:42.134838 139462604490496 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.08024560660123825, loss=0.30492401123046875
I0204 23:39:05.970560 139462596097792 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.10085827112197876, loss=0.26556962728500366
I0204 23:39:29.613000 139462604490496 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.235410675406456, loss=0.23665378987789154
I0204 23:39:53.608560 139462596097792 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.10415897518396378, loss=0.296647310256958
I0204 23:40:00.181679 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:40:01.549920 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:40:02.872041 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:40:04.192605 139681449744192 submission_runner.py:408] Time since start: 2994.26s, 	Step: 11728, 	{'train/ssim': 0.7459479059491839, 'train/loss': 0.26831463405064176, 'validation/ssim': 0.723168093499402, 'validation/loss': 0.2869273342976224, 'validation/num_examples': 3554, 'test/ssim': 0.7404165430396538, 'test/loss': 0.2882078714591769, 'test/num_examples': 3581, 'score': 2846.0457010269165, 'total_duration': 2994.259813785553, 'accumulated_submission_time': 2846.0457010269165, 'accumulated_eval_time': 144.31327152252197, 'accumulated_logging_time': 3.4031455516815186}
I0204 23:40:04.209989 139462604490496 logging_writer.py:48] [11728] accumulated_eval_time=144.313272, accumulated_logging_time=3.403146, accumulated_submission_time=2846.045701, global_step=11728, preemption_count=0, score=2846.045701, test/loss=0.288208, test/num_examples=3581, test/ssim=0.740417, total_duration=2994.259814, train/loss=0.268315, train/ssim=0.745948, validation/loss=0.286927, validation/num_examples=3554, validation/ssim=0.723168
I0204 23:40:19.723857 139462596097792 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.0947740375995636, loss=0.3133377730846405
I0204 23:40:43.646848 139462604490496 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.3044728934764862, loss=0.2761524021625519
I0204 23:41:07.574101 139462596097792 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.12547257542610168, loss=0.25475114583969116
I0204 23:41:24.236965 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:41:25.606461 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:41:26.928161 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:41:28.248193 139681449744192 submission_runner.py:408] Time since start: 3078.32s, 	Step: 12072, 	{'train/ssim': 0.7469075066702706, 'train/loss': 0.2674442529678345, 'validation/ssim': 0.7234120967351927, 'validation/loss': 0.28661930769027855, 'validation/num_examples': 3554, 'test/ssim': 0.7406919085756423, 'test/loss': 0.2879914446470958, 'test/num_examples': 3581, 'score': 2926.0488336086273, 'total_duration': 3078.3154022693634, 'accumulated_submission_time': 2926.0488336086273, 'accumulated_eval_time': 148.32446479797363, 'accumulated_logging_time': 3.4299488067626953}
I0204 23:41:28.266401 139462604490496 logging_writer.py:48] [12072] accumulated_eval_time=148.324465, accumulated_logging_time=3.429949, accumulated_submission_time=2926.048834, global_step=12072, preemption_count=0, score=2926.048834, test/loss=0.287991, test/num_examples=3581, test/ssim=0.740692, total_duration=3078.315402, train/loss=0.267444, train/ssim=0.746908, validation/loss=0.286619, validation/num_examples=3554, validation/ssim=0.723412
I0204 23:41:32.871820 139462596097792 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.10424904525279999, loss=0.29234063625335693
I0204 23:41:56.593783 139462604490496 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.10394856333732605, loss=0.25843507051467896
I0204 23:42:20.671059 139462596097792 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.13019534945487976, loss=0.28580084443092346
I0204 23:42:44.656182 139462604490496 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.28059330582618713, loss=0.2576962411403656
I0204 23:42:48.420552 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:42:49.793136 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:42:51.114012 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:42:52.434614 139681449744192 submission_runner.py:408] Time since start: 3162.50s, 	Step: 12417, 	{'train/ssim': 0.7473031452723912, 'train/loss': 0.2675682646887643, 'validation/ssim': 0.7239558832257668, 'validation/loss': 0.2866649896023846, 'validation/num_examples': 3554, 'test/ssim': 0.7412790459848855, 'test/loss': 0.28798155903117145, 'test/num_examples': 3581, 'score': 3006.178083181381, 'total_duration': 3162.5018265247345, 'accumulated_submission_time': 3006.178083181381, 'accumulated_eval_time': 152.33849143981934, 'accumulated_logging_time': 3.4584479331970215}
I0204 23:42:52.452383 139462596097792 logging_writer.py:48] [12417] accumulated_eval_time=152.338491, accumulated_logging_time=3.458448, accumulated_submission_time=3006.178083, global_step=12417, preemption_count=0, score=3006.178083, test/loss=0.287982, test/num_examples=3581, test/ssim=0.741279, total_duration=3162.501827, train/loss=0.267568, train/ssim=0.747303, validation/loss=0.286665, validation/num_examples=3554, validation/ssim=0.723956
I0204 23:43:10.358236 139462604490496 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.11586353927850723, loss=0.29904794692993164
I0204 23:43:34.171332 139462596097792 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.09375384449958801, loss=0.30059975385665894
I0204 23:43:57.955387 139462604490496 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.3205903172492981, loss=0.2720365524291992
I0204 23:44:12.436144 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:44:13.807641 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:44:15.130266 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:44:16.450479 139681449744192 submission_runner.py:408] Time since start: 3246.52s, 	Step: 12762, 	{'train/ssim': 0.7473674501691546, 'train/loss': 0.2675473690032959, 'validation/ssim': 0.7242794348137662, 'validation/loss': 0.28640245599698405, 'validation/num_examples': 3554, 'test/ssim': 0.7415175279469771, 'test/loss': 0.2877508151201655, 'test/num_examples': 3581, 'score': 3086.1382641792297, 'total_duration': 3246.5176918506622, 'accumulated_submission_time': 3086.1382641792297, 'accumulated_eval_time': 156.35280227661133, 'accumulated_logging_time': 3.4851222038269043}
I0204 23:44:16.468600 139462596097792 logging_writer.py:48] [12762] accumulated_eval_time=156.352802, accumulated_logging_time=3.485122, accumulated_submission_time=3086.138264, global_step=12762, preemption_count=0, score=3086.138264, test/loss=0.287751, test/num_examples=3581, test/ssim=0.741518, total_duration=3246.517692, train/loss=0.267547, train/ssim=0.747367, validation/loss=0.286402, validation/num_examples=3554, validation/ssim=0.724279
I0204 23:44:23.553646 139462604490496 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.2679423987865448, loss=0.25291040539741516
I0204 23:44:47.766189 139462596097792 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.11717543005943298, loss=0.20881250500679016
I0204 23:45:11.813089 139462604490496 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.09763500094413757, loss=0.301560640335083
I0204 23:45:35.623674 139462596097792 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.19882367551326752, loss=0.25637856125831604
I0204 23:45:36.534022 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:45:37.907665 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:45:39.227357 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:45:40.550150 139681449744192 submission_runner.py:408] Time since start: 3330.62s, 	Step: 13105, 	{'train/ssim': 0.7421697889055524, 'train/loss': 0.2700824226651873, 'validation/ssim': 0.720902820215778, 'validation/loss': 0.28875687770381964, 'validation/num_examples': 3554, 'test/ssim': 0.7376949307106954, 'test/loss': 0.29021669679166084, 'test/num_examples': 3581, 'score': 3166.1795699596405, 'total_duration': 3330.6173605918884, 'accumulated_submission_time': 3166.1795699596405, 'accumulated_eval_time': 160.36889815330505, 'accumulated_logging_time': 3.513031244277954}
I0204 23:45:40.568227 139462604490496 logging_writer.py:48] [13105] accumulated_eval_time=160.368898, accumulated_logging_time=3.513031, accumulated_submission_time=3166.179570, global_step=13105, preemption_count=0, score=3166.179570, test/loss=0.290217, test/num_examples=3581, test/ssim=0.737695, total_duration=3330.617361, train/loss=0.270082, train/ssim=0.742170, validation/loss=0.288757, validation/num_examples=3554, validation/ssim=0.720903
I0204 23:46:01.132920 139462596097792 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.10006071627140045, loss=0.22982560098171234
I0204 23:46:24.954736 139462604490496 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.1252942979335785, loss=0.3485276997089386
I0204 23:46:48.697819 139462596097792 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.1324528306722641, loss=0.4059976637363434
I0204 23:47:00.747104 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:47:02.115385 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:47:03.432538 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:47:04.750898 139681449744192 submission_runner.py:408] Time since start: 3414.82s, 	Step: 13452, 	{'train/ssim': 0.7474530764988491, 'train/loss': 0.26738267285483225, 'validation/ssim': 0.7240228604653207, 'validation/loss': 0.286526982141601, 'validation/num_examples': 3554, 'test/ssim': 0.7413308602476613, 'test/loss': 0.28779305056199384, 'test/num_examples': 3581, 'score': 3246.3344492912292, 'total_duration': 3414.818110704422, 'accumulated_submission_time': 3246.3344492912292, 'accumulated_eval_time': 164.37267231941223, 'accumulated_logging_time': 3.5402119159698486}
I0204 23:47:04.769367 139462604490496 logging_writer.py:48] [13452] accumulated_eval_time=164.372672, accumulated_logging_time=3.540212, accumulated_submission_time=3246.334449, global_step=13452, preemption_count=0, score=3246.334449, test/loss=0.287793, test/num_examples=3581, test/ssim=0.741331, total_duration=3414.818111, train/loss=0.267383, train/ssim=0.747453, validation/loss=0.286527, validation/num_examples=3554, validation/ssim=0.724023
I0204 23:47:14.082381 139462596097792 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.1578216701745987, loss=0.3281097114086151
I0204 23:47:37.728381 139462604490496 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.1927526295185089, loss=0.1975802779197693
I0204 23:48:01.629864 139462596097792 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.16740573942661285, loss=0.3193321228027344
I0204 23:48:24.939384 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:48:26.307808 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:48:27.628703 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:48:28.948842 139681449744192 submission_runner.py:408] Time since start: 3499.02s, 	Step: 13798, 	{'train/ssim': 0.7462870052882603, 'train/loss': 0.268414991242545, 'validation/ssim': 0.7231948843952237, 'validation/loss': 0.28716149703129396, 'validation/num_examples': 3554, 'test/ssim': 0.7404483133639347, 'test/loss': 0.2885023605487294, 'test/num_examples': 3581, 'score': 3326.4810423851013, 'total_duration': 3499.016035795212, 'accumulated_submission_time': 3326.4810423851013, 'accumulated_eval_time': 168.38208889961243, 'accumulated_logging_time': 3.567617654800415}
I0204 23:48:28.967554 139462604490496 logging_writer.py:48] [13798] accumulated_eval_time=168.382089, accumulated_logging_time=3.567618, accumulated_submission_time=3326.481042, global_step=13798, preemption_count=0, score=3326.481042, test/loss=0.288502, test/num_examples=3581, test/ssim=0.740448, total_duration=3499.016036, train/loss=0.268415, train/ssim=0.746287, validation/loss=0.287161, validation/num_examples=3554, validation/ssim=0.723195
I0204 23:48:29.201995 139462596097792 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.29078376293182373, loss=0.2651105225086212
I0204 23:48:51.293757 139462604490496 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.11855130642652512, loss=0.23484951257705688
I0204 23:49:15.486767 139462596097792 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.10780756920576096, loss=0.2172643393278122
I0204 23:49:39.371800 139462604490496 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.1702309250831604, loss=0.24431845545768738
I0204 23:49:48.959547 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:49:50.331048 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:49:51.650916 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:49:52.971880 139681449744192 submission_runner.py:408] Time since start: 3583.04s, 	Step: 14141, 	{'train/ssim': 0.7470973559788295, 'train/loss': 0.2679232358932495, 'validation/ssim': 0.7241787972179234, 'validation/loss': 0.2867153255739572, 'validation/num_examples': 3554, 'test/ssim': 0.7413019533431653, 'test/loss': 0.28809316422612397, 'test/num_examples': 3581, 'score': 3406.4493815898895, 'total_duration': 3583.039057970047, 'accumulated_submission_time': 3406.4493815898895, 'accumulated_eval_time': 172.3943543434143, 'accumulated_logging_time': 3.595734119415283}
I0204 23:49:52.990175 139462596097792 logging_writer.py:48] [14141] accumulated_eval_time=172.394354, accumulated_logging_time=3.595734, accumulated_submission_time=3406.449382, global_step=14141, preemption_count=0, score=3406.449382, test/loss=0.288093, test/num_examples=3581, test/ssim=0.741302, total_duration=3583.039058, train/loss=0.267923, train/ssim=0.747097, validation/loss=0.286715, validation/num_examples=3554, validation/ssim=0.724179
I0204 23:50:05.221279 139462604490496 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.11420338600873947, loss=0.3554299771785736
I0204 23:50:28.866609 139462596097792 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.11703487485647202, loss=0.33050328493118286
I0204 23:50:52.616637 139462604490496 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.12215927243232727, loss=0.2879129648208618
I0204 23:51:13.146480 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:51:14.514469 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:51:15.834967 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:51:17.155472 139681449744192 submission_runner.py:408] Time since start: 3667.22s, 	Step: 14487, 	{'train/ssim': 0.7464298520769391, 'train/loss': 0.26779392787388395, 'validation/ssim': 0.7232238048237901, 'validation/loss': 0.286742957978686, 'validation/num_examples': 3554, 'test/ssim': 0.7403454347816601, 'test/loss': 0.2881711583269338, 'test/num_examples': 3581, 'score': 3486.5816123485565, 'total_duration': 3667.2226791381836, 'accumulated_submission_time': 3486.5816123485565, 'accumulated_eval_time': 176.40333008766174, 'accumulated_logging_time': 3.623152017593384}
I0204 23:51:17.174548 139462596097792 logging_writer.py:48] [14487] accumulated_eval_time=176.403330, accumulated_logging_time=3.623152, accumulated_submission_time=3486.581612, global_step=14487, preemption_count=0, score=3486.581612, test/loss=0.288171, test/num_examples=3581, test/ssim=0.740345, total_duration=3667.222679, train/loss=0.267794, train/ssim=0.746430, validation/loss=0.286743, validation/num_examples=3554, validation/ssim=0.723224
I0204 23:51:18.206455 139462604490496 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.14296825230121613, loss=0.3410715162754059
I0204 23:51:42.105350 139462596097792 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.12592992186546326, loss=0.2119627296924591
I0204 23:52:06.149247 139462604490496 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.13685928285121918, loss=0.2607765793800354
I0204 23:52:30.054423 139462596097792 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.0621887668967247, loss=0.34026026725769043
I0204 23:52:37.284566 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:52:38.654675 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:52:39.976306 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:52:41.300359 139681449744192 submission_runner.py:408] Time since start: 3751.37s, 	Step: 14832, 	{'train/ssim': 0.7475502831595284, 'train/loss': 0.267444235937936, 'validation/ssim': 0.7244118780115715, 'validation/loss': 0.286362716168182, 'validation/num_examples': 3554, 'test/ssim': 0.7416326101516685, 'test/loss': 0.2877265442286547, 'test/num_examples': 3581, 'score': 3566.6675159931183, 'total_duration': 3751.3675639629364, 'accumulated_submission_time': 3566.6675159931183, 'accumulated_eval_time': 180.41909766197205, 'accumulated_logging_time': 3.6520910263061523}
I0204 23:52:41.318485 139462604490496 logging_writer.py:48] [14832] accumulated_eval_time=180.419098, accumulated_logging_time=3.652091, accumulated_submission_time=3566.667516, global_step=14832, preemption_count=0, score=3566.667516, test/loss=0.287727, test/num_examples=3581, test/ssim=0.741633, total_duration=3751.367564, train/loss=0.267444, train/ssim=0.747550, validation/loss=0.286363, validation/num_examples=3554, validation/ssim=0.724412
I0204 23:52:55.686297 139462596097792 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.2029392421245575, loss=0.3520457446575165
I0204 23:53:19.671411 139462604490496 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.2426668107509613, loss=0.2189914584159851
I0204 23:53:44.081769 139462596097792 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.11685600876808167, loss=0.19635343551635742
I0204 23:54:01.485718 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:54:02.853087 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:54:04.173049 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:54:05.493746 139681449744192 submission_runner.py:408] Time since start: 3835.56s, 	Step: 15174, 	{'train/ssim': 0.7479367256164551, 'train/loss': 0.26788011619022917, 'validation/ssim': 0.7252343585132949, 'validation/loss': 0.2868504135140423, 'validation/num_examples': 3554, 'test/ssim': 0.742216406904496, 'test/loss': 0.28836334833583493, 'test/num_examples': 3581, 'score': 3646.8111073970795, 'total_duration': 3835.5609562397003, 'accumulated_submission_time': 3646.8111073970795, 'accumulated_eval_time': 184.4270977973938, 'accumulated_logging_time': 3.679409980773926}
I0204 23:54:05.512001 139462604490496 logging_writer.py:48] [15174] accumulated_eval_time=184.427098, accumulated_logging_time=3.679410, accumulated_submission_time=3646.811107, global_step=15174, preemption_count=0, score=3646.811107, test/loss=0.288363, test/num_examples=3581, test/ssim=0.742216, total_duration=3835.560956, train/loss=0.267880, train/ssim=0.747937, validation/loss=0.286850, validation/num_examples=3554, validation/ssim=0.725234
I0204 23:54:09.696149 139462596097792 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.1935880035161972, loss=0.257477730512619
I0204 23:54:33.430913 139462604490496 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.2597506046295166, loss=0.2415957748889923
I0204 23:54:57.373890 139462596097792 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.12661485373973846, loss=0.27428048849105835
I0204 23:55:21.121807 139462604490496 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.1449514627456665, loss=0.2557826340198517
I0204 23:55:25.699567 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:55:27.069312 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:55:28.389396 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:55:29.707637 139681449744192 submission_runner.py:408] Time since start: 3919.77s, 	Step: 15520, 	{'train/ssim': 0.7471392495291573, 'train/loss': 0.26722543580191477, 'validation/ssim': 0.7236271108478123, 'validation/loss': 0.28667081147013046, 'validation/num_examples': 3554, 'test/ssim': 0.7409330494275342, 'test/loss': 0.2879875585773876, 'test/num_examples': 3581, 'score': 3726.9752271175385, 'total_duration': 3919.774846792221, 'accumulated_submission_time': 3726.9752271175385, 'accumulated_eval_time': 188.43514847755432, 'accumulated_logging_time': 3.70670485496521}
I0204 23:55:29.725939 139462596097792 logging_writer.py:48] [15520] accumulated_eval_time=188.435148, accumulated_logging_time=3.706705, accumulated_submission_time=3726.975227, global_step=15520, preemption_count=0, score=3726.975227, test/loss=0.287988, test/num_examples=3581, test/ssim=0.740933, total_duration=3919.774847, train/loss=0.267225, train/ssim=0.747139, validation/loss=0.286671, validation/num_examples=3554, validation/ssim=0.723627
I0204 23:55:46.594005 139462604490496 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.10829298198223114, loss=0.27544987201690674
I0204 23:56:10.470098 139462596097792 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.2310270369052887, loss=0.20776966214179993
I0204 23:56:34.307577 139462604490496 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.1037929430603981, loss=0.24941079318523407
I0204 23:56:49.751491 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:56:51.122734 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:56:52.443475 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:56:53.763745 139681449744192 submission_runner.py:408] Time since start: 4003.83s, 	Step: 15866, 	{'train/ssim': 0.748380184173584, 'train/loss': 0.26701310702732634, 'validation/ssim': 0.724918844194042, 'validation/loss': 0.2861659576467537, 'validation/num_examples': 3554, 'test/ssim': 0.7422716981770107, 'test/loss': 0.2874218968165317, 'test/num_examples': 3581, 'score': 3806.9768195152283, 'total_duration': 4003.8309524059296, 'accumulated_submission_time': 3806.9768195152283, 'accumulated_eval_time': 192.44737243652344, 'accumulated_logging_time': 3.734318971633911}
I0204 23:56:53.781998 139462596097792 logging_writer.py:48] [15866] accumulated_eval_time=192.447372, accumulated_logging_time=3.734319, accumulated_submission_time=3806.976820, global_step=15866, preemption_count=0, score=3806.976820, test/loss=0.287422, test/num_examples=3581, test/ssim=0.742272, total_duration=4003.830952, train/loss=0.267013, train/ssim=0.748380, validation/loss=0.286166, validation/num_examples=3554, validation/ssim=0.724919
I0204 23:56:59.723452 139462604490496 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.3201580047607422, loss=0.20631101727485657
I0204 23:57:23.586935 139462596097792 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.21984440088272095, loss=0.2346225380897522
I0204 23:57:47.557896 139462604490496 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.21040628850460052, loss=0.365755170583725
I0204 23:58:11.944856 139462596097792 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.18173924088478088, loss=0.22633928060531616
I0204 23:58:13.802329 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:58:15.171506 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:58:16.492206 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:58:17.812721 139681449744192 submission_runner.py:408] Time since start: 4087.88s, 	Step: 16209, 	{'train/ssim': 0.7478961263384137, 'train/loss': 0.2671475410461426, 'validation/ssim': 0.7246443405537775, 'validation/loss': 0.2861368311343732, 'validation/num_examples': 3554, 'test/ssim': 0.7419779931190659, 'test/loss': 0.28742220361150866, 'test/num_examples': 3581, 'score': 3886.973289012909, 'total_duration': 4087.8799300193787, 'accumulated_submission_time': 3886.973289012909, 'accumulated_eval_time': 196.4577419757843, 'accumulated_logging_time': 3.761636972427368}
I0204 23:58:17.831734 139462604490496 logging_writer.py:48] [16209] accumulated_eval_time=196.457742, accumulated_logging_time=3.761637, accumulated_submission_time=3886.973289, global_step=16209, preemption_count=0, score=3886.973289, test/loss=0.287422, test/num_examples=3581, test/ssim=0.741978, total_duration=4087.879930, train/loss=0.267148, train/ssim=0.747896, validation/loss=0.286137, validation/num_examples=3554, validation/ssim=0.724644
I0204 23:58:37.658105 139462596097792 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.11281877756118774, loss=0.24424968659877777
I0204 23:59:01.220659 139462604490496 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.21360327303409576, loss=0.23180121183395386
I0204 23:59:24.808517 139462596097792 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.09611352533102036, loss=0.27499404549598694
I0204 23:59:37.964055 139681449744192 spec.py:321] Evaluating on the training split.
I0204 23:59:39.335338 139681449744192 spec.py:333] Evaluating on the validation split.
I0204 23:59:40.653481 139681449744192 spec.py:349] Evaluating on the test split.
I0204 23:59:41.974475 139681449744192 submission_runner.py:408] Time since start: 4172.04s, 	Step: 16556, 	{'train/ssim': 0.748145307813372, 'train/loss': 0.2665354013442993, 'validation/ssim': 0.7245252241092783, 'validation/loss': 0.2858139321451182, 'validation/num_examples': 3554, 'test/ssim': 0.7418374128429559, 'test/loss': 0.2871162608428163, 'test/num_examples': 3581, 'score': 3967.0818524360657, 'total_duration': 4172.041687011719, 'accumulated_submission_time': 3967.0818524360657, 'accumulated_eval_time': 200.4681260585785, 'accumulated_logging_time': 3.789839267730713}
I0204 23:59:41.993441 139462604490496 logging_writer.py:48] [16556] accumulated_eval_time=200.468126, accumulated_logging_time=3.789839, accumulated_submission_time=3967.081852, global_step=16556, preemption_count=0, score=3967.081852, test/loss=0.287116, test/num_examples=3581, test/ssim=0.741837, total_duration=4172.041687, train/loss=0.266535, train/ssim=0.748145, validation/loss=0.285814, validation/num_examples=3554, validation/ssim=0.724525
I0204 23:59:50.319190 139462596097792 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.18389099836349487, loss=0.23364901542663574
I0205 00:00:14.146856 139462604490496 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.2472257912158966, loss=0.3208916187286377
I0205 00:00:37.718342 139462596097792 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.26688462495803833, loss=0.2962999939918518
I0205 00:01:01.595787 139462604490496 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.08910930156707764, loss=0.3306311368942261
I0205 00:01:02.067351 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:01:03.435436 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:01:04.756835 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:01:06.078342 139681449744192 submission_runner.py:408] Time since start: 4256.15s, 	Step: 16903, 	{'train/ssim': 0.7478715351649693, 'train/loss': 0.2666094814028059, 'validation/ssim': 0.724559914884637, 'validation/loss': 0.2857410128222601, 'validation/num_examples': 3554, 'test/ssim': 0.7418483892854649, 'test/loss': 0.2870625035451864, 'test/num_examples': 3581, 'score': 4047.131493330002, 'total_duration': 4256.145545244217, 'accumulated_submission_time': 4047.131493330002, 'accumulated_eval_time': 204.47909569740295, 'accumulated_logging_time': 3.817901611328125}
I0205 00:01:06.096840 139462596097792 logging_writer.py:48] [16903] accumulated_eval_time=204.479096, accumulated_logging_time=3.817902, accumulated_submission_time=4047.131493, global_step=16903, preemption_count=0, score=4047.131493, test/loss=0.287063, test/num_examples=3581, test/ssim=0.741848, total_duration=4256.145545, train/loss=0.266609, train/ssim=0.747872, validation/loss=0.285741, validation/num_examples=3554, validation/ssim=0.724560
I0205 00:01:27.137722 139462604490496 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.498546302318573, loss=0.22526216506958008
I0205 00:01:50.896404 139462596097792 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.1934969276189804, loss=0.31122902035713196
I0205 00:02:14.954630 139462604490496 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.140062615275383, loss=0.2571391463279724
I0205 00:02:26.293591 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:02:27.665469 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:02:28.988233 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:02:30.310573 139681449744192 submission_runner.py:408] Time since start: 4340.38s, 	Step: 17247, 	{'train/ssim': 0.7482375417436872, 'train/loss': 0.2673543861934117, 'validation/ssim': 0.7250987553636747, 'validation/loss': 0.2863902798783061, 'validation/num_examples': 3554, 'test/ssim': 0.7423234442631248, 'test/loss': 0.28769705782253563, 'test/num_examples': 3581, 'score': 4127.304555654526, 'total_duration': 4340.377782583237, 'accumulated_submission_time': 4127.304555654526, 'accumulated_eval_time': 208.49604630470276, 'accumulated_logging_time': 3.8455328941345215}
I0205 00:02:30.329657 139462596097792 logging_writer.py:48] [17247] accumulated_eval_time=208.496046, accumulated_logging_time=3.845533, accumulated_submission_time=4127.304556, global_step=17247, preemption_count=0, score=4127.304556, test/loss=0.287697, test/num_examples=3581, test/ssim=0.742323, total_duration=4340.377783, train/loss=0.267354, train/ssim=0.748238, validation/loss=0.286390, validation/num_examples=3554, validation/ssim=0.725099
I0205 00:02:40.850214 139462604490496 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.2220793068408966, loss=0.25439995527267456
I0205 00:03:05.013881 139462596097792 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.1789678931236267, loss=0.23328609764575958
I0205 00:03:28.779332 139462604490496 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.2582080662250519, loss=0.2513350248336792
I0205 00:03:50.367513 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:03:51.738130 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:03:53.058459 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:03:54.378657 139681449744192 submission_runner.py:408] Time since start: 4424.45s, 	Step: 17592, 	{'train/ssim': 0.748047011239188, 'train/loss': 0.26669936520712717, 'validation/ssim': 0.7240940280757597, 'validation/loss': 0.2863386730565472, 'validation/num_examples': 3554, 'test/ssim': 0.7414175809611491, 'test/loss': 0.28763955080852066, 'test/num_examples': 3581, 'score': 4207.318914651871, 'total_duration': 4424.445866823196, 'accumulated_submission_time': 4207.318914651871, 'accumulated_eval_time': 212.5071542263031, 'accumulated_logging_time': 3.8736438751220703}
I0205 00:03:54.397745 139462596097792 logging_writer.py:48] [17592] accumulated_eval_time=212.507154, accumulated_logging_time=3.873644, accumulated_submission_time=4207.318915, global_step=17592, preemption_count=0, score=4207.318915, test/loss=0.287640, test/num_examples=3581, test/ssim=0.741418, total_duration=4424.445867, train/loss=0.266699, train/ssim=0.748047, validation/loss=0.286339, validation/num_examples=3554, validation/ssim=0.724094
I0205 00:03:55.064902 139462604490496 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.1817832589149475, loss=0.30193042755126953
I0205 00:04:18.069651 139462596097792 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.15011993050575256, loss=0.26136133074760437
I0205 00:04:41.836220 139462604490496 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.18272103369235992, loss=0.2861693799495697
I0205 00:05:05.864435 139462596097792 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.1561829149723053, loss=0.20692193508148193
I0205 00:05:14.463938 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:05:15.834266 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:05:17.153167 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:05:18.473685 139681449744192 submission_runner.py:408] Time since start: 4508.54s, 	Step: 17937, 	{'train/ssim': 0.7487597465515137, 'train/loss': 0.2666618824005127, 'validation/ssim': 0.7253592453045864, 'validation/loss': 0.2859063950830051, 'validation/num_examples': 3554, 'test/ssim': 0.7426705998237224, 'test/loss': 0.28721017419409733, 'test/num_examples': 3581, 'score': 4287.361625432968, 'total_duration': 4508.540894031525, 'accumulated_submission_time': 4287.361625432968, 'accumulated_eval_time': 216.51686763763428, 'accumulated_logging_time': 3.9018309116363525}
I0205 00:05:18.493195 139462604490496 logging_writer.py:48] [17937] accumulated_eval_time=216.516868, accumulated_logging_time=3.901831, accumulated_submission_time=4287.361625, global_step=17937, preemption_count=0, score=4287.361625, test/loss=0.287210, test/num_examples=3581, test/ssim=0.742671, total_duration=4508.540894, train/loss=0.266662, train/ssim=0.748760, validation/loss=0.285906, validation/num_examples=3554, validation/ssim=0.725359
I0205 00:05:31.378880 139462596097792 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.15666399896144867, loss=0.3139243721961975
I0205 00:05:55.032417 139462604490496 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.2612757086753845, loss=0.26890498399734497
I0205 00:06:18.859426 139462596097792 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.08412183076143265, loss=0.21346136927604675
I0205 00:06:38.513933 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:06:39.882923 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:06:41.204236 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:06:42.525169 139681449744192 submission_runner.py:408] Time since start: 4592.59s, 	Step: 18283, 	{'train/ssim': 0.7487377439226423, 'train/loss': 0.2666053431374686, 'validation/ssim': 0.7254902459156936, 'validation/loss': 0.2856880149347566, 'validation/num_examples': 3554, 'test/ssim': 0.7427411626684236, 'test/loss': 0.28693634263299356, 'test/num_examples': 3581, 'score': 4367.358929157257, 'total_duration': 4592.592378616333, 'accumulated_submission_time': 4367.358929157257, 'accumulated_eval_time': 220.5280795097351, 'accumulated_logging_time': 3.9302728176116943}
I0205 00:06:42.544173 139462604490496 logging_writer.py:48] [18283] accumulated_eval_time=220.528080, accumulated_logging_time=3.930273, accumulated_submission_time=4367.358929, global_step=18283, preemption_count=0, score=4367.358929, test/loss=0.286936, test/num_examples=3581, test/ssim=0.742741, total_duration=4592.592379, train/loss=0.266605, train/ssim=0.748738, validation/loss=0.285688, validation/num_examples=3554, validation/ssim=0.725490
I0205 00:06:44.552902 139462596097792 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.20695944130420685, loss=0.2558167576789856
I0205 00:07:08.850249 139462604490496 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.13320529460906982, loss=0.22045204043388367
I0205 00:07:33.098519 139462596097792 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.0991082638502121, loss=0.3368290066719055
I0205 00:07:56.846735 139462604490496 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.1316889524459839, loss=0.2581401467323303
I0205 00:08:02.658829 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:08:04.028325 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:08:05.346889 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:08:06.667956 139681449744192 submission_runner.py:408] Time since start: 4676.74s, 	Step: 18626, 	{'train/ssim': 0.7493752070835659, 'train/loss': 0.2661102328981672, 'validation/ssim': 0.7254873607422974, 'validation/loss': 0.2856842539051509, 'validation/num_examples': 3554, 'test/ssim': 0.7427425262016546, 'test/loss': 0.2870357101171984, 'test/num_examples': 3581, 'score': 4447.448851585388, 'total_duration': 4676.735166788101, 'accumulated_submission_time': 4447.448851585388, 'accumulated_eval_time': 224.53717684745789, 'accumulated_logging_time': 3.9594712257385254}
I0205 00:08:06.688261 139462596097792 logging_writer.py:48] [18626] accumulated_eval_time=224.537177, accumulated_logging_time=3.959471, accumulated_submission_time=4447.448852, global_step=18626, preemption_count=0, score=4447.448852, test/loss=0.287036, test/num_examples=3581, test/ssim=0.742743, total_duration=4676.735167, train/loss=0.266110, train/ssim=0.749375, validation/loss=0.285684, validation/num_examples=3554, validation/ssim=0.725487
I0205 00:08:22.393228 139462604490496 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.2240045815706253, loss=0.289204478263855
I0205 00:08:46.210057 139462596097792 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.24729883670806885, loss=0.2622140944004059
I0205 00:09:10.023108 139462604490496 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.11342346668243408, loss=0.24405476450920105
I0205 00:09:26.816078 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:09:28.187005 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:09:29.507406 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:09:30.827401 139681449744192 submission_runner.py:408] Time since start: 4760.89s, 	Step: 18972, 	{'train/ssim': 0.7464577811104911, 'train/loss': 0.26762427602495464, 'validation/ssim': 0.7239104760920794, 'validation/loss': 0.2866407060596335, 'validation/num_examples': 3554, 'test/ssim': 0.7408810306347738, 'test/loss': 0.28806885924628245, 'test/num_examples': 3581, 'score': 4527.552319765091, 'total_duration': 4760.894608259201, 'accumulated_submission_time': 4527.552319765091, 'accumulated_eval_time': 228.54846930503845, 'accumulated_logging_time': 3.989834785461426}
I0205 00:09:30.847313 139462596097792 logging_writer.py:48] [18972] accumulated_eval_time=228.548469, accumulated_logging_time=3.989835, accumulated_submission_time=4527.552320, global_step=18972, preemption_count=0, score=4527.552320, test/loss=0.288069, test/num_examples=3581, test/ssim=0.740881, total_duration=4760.894608, train/loss=0.267624, train/ssim=0.746458, validation/loss=0.286641, validation/num_examples=3554, validation/ssim=0.723910
I0205 00:09:35.430829 139462604490496 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.11916559934616089, loss=0.28044411540031433
I0205 00:09:59.461707 139462596097792 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.11206550896167755, loss=0.2739786207675934
I0205 00:10:23.089002 139462604490496 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.17934879660606384, loss=0.23212271928787231
I0205 00:10:46.906837 139462596097792 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.5400874018669128, loss=0.25769203901290894
I0205 00:10:51.042282 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:10:52.413569 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:10:53.734310 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:10:55.055827 139681449744192 submission_runner.py:408] Time since start: 4845.12s, 	Step: 19318, 	{'train/ssim': 0.7489397185189384, 'train/loss': 0.26674018587384907, 'validation/ssim': 0.7255840140510692, 'validation/loss': 0.2859350407331528, 'validation/num_examples': 3554, 'test/ssim': 0.7427173008368821, 'test/loss': 0.2872599090686959, 'test/num_examples': 3581, 'score': 4607.723635435104, 'total_duration': 4845.123031139374, 'accumulated_submission_time': 4607.723635435104, 'accumulated_eval_time': 232.56197333335876, 'accumulated_logging_time': 4.01876974105835}
I0205 00:10:55.075095 139462604490496 logging_writer.py:48] [19318] accumulated_eval_time=232.561973, accumulated_logging_time=4.018770, accumulated_submission_time=4607.723635, global_step=19318, preemption_count=0, score=4607.723635, test/loss=0.287260, test/num_examples=3581, test/ssim=0.742717, total_duration=4845.123031, train/loss=0.266740, train/ssim=0.748940, validation/loss=0.285935, validation/num_examples=3554, validation/ssim=0.725584
I0205 00:11:12.785064 139462596097792 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.29781052470207214, loss=0.24489781260490417
I0205 00:11:36.548049 139462604490496 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.8636816143989563, loss=0.22960931062698364
I0205 00:12:00.432449 139462596097792 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.1306743323802948, loss=0.34349581599235535
I0205 00:12:15.172986 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:12:16.542815 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:12:17.859738 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:12:19.178147 139681449744192 submission_runner.py:408] Time since start: 4929.25s, 	Step: 19663, 	{'train/ssim': 0.7484968049185616, 'train/loss': 0.2659630945750645, 'validation/ssim': 0.7245838893016672, 'validation/loss': 0.2855817787286332, 'validation/num_examples': 3554, 'test/ssim': 0.7418566386615122, 'test/loss': 0.28688401704525623, 'test/num_examples': 3581, 'score': 4687.796002864838, 'total_duration': 4929.245357036591, 'accumulated_submission_time': 4687.796002864838, 'accumulated_eval_time': 236.56711435317993, 'accumulated_logging_time': 4.048708200454712}
I0205 00:12:19.197417 139462604490496 logging_writer.py:48] [19663] accumulated_eval_time=236.567114, accumulated_logging_time=4.048708, accumulated_submission_time=4687.796003, global_step=19663, preemption_count=0, score=4687.796003, test/loss=0.286884, test/num_examples=3581, test/ssim=0.741857, total_duration=4929.245357, train/loss=0.265963, train/ssim=0.748497, validation/loss=0.285582, validation/num_examples=3554, validation/ssim=0.724584
I0205 00:12:26.045738 139462596097792 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.21729776263237, loss=0.202734112739563
I0205 00:12:49.793713 139462604490496 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.11234201490879059, loss=0.21936911344528198
I0205 00:13:13.694064 139462596097792 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.09588619321584702, loss=0.3145613670349121
I0205 00:13:37.644104 139462604490496 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.35744228959083557, loss=0.24239188432693481
I0205 00:13:39.231454 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:13:40.598749 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:13:41.918185 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:13:43.237775 139681449744192 submission_runner.py:408] Time since start: 5013.30s, 	Step: 20008, 	{'train/ssim': 0.7490484373910087, 'train/loss': 0.2663997071129935, 'validation/ssim': 0.725382051913337, 'validation/loss': 0.2857362041999332, 'validation/num_examples': 3554, 'test/ssim': 0.7426997794348645, 'test/loss': 0.28695106879188775, 'test/num_examples': 3581, 'score': 4767.805709838867, 'total_duration': 5013.3049693107605, 'accumulated_submission_time': 4767.805709838867, 'accumulated_eval_time': 240.57340145111084, 'accumulated_logging_time': 4.0773022174835205}
I0205 00:13:43.256940 139462596097792 logging_writer.py:48] [20008] accumulated_eval_time=240.573401, accumulated_logging_time=4.077302, accumulated_submission_time=4767.805710, global_step=20008, preemption_count=0, score=4767.805710, test/loss=0.286951, test/num_examples=3581, test/ssim=0.742700, total_duration=5013.304969, train/loss=0.266400, train/ssim=0.749048, validation/loss=0.285736, validation/num_examples=3554, validation/ssim=0.725382
I0205 00:14:03.171677 139462604490496 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.16321417689323425, loss=0.3847770392894745
I0205 00:14:26.914728 139462596097792 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.1706354022026062, loss=0.3598729074001312
I0205 00:14:50.518688 139462604490496 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.18422405421733856, loss=0.269787073135376
I0205 00:15:03.389145 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:15:04.759969 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:15:06.079795 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:15:07.400130 139681449744192 submission_runner.py:408] Time since start: 5097.47s, 	Step: 20354, 	{'train/ssim': 0.7480840001787458, 'train/loss': 0.26671031543186735, 'validation/ssim': 0.7245500228615644, 'validation/loss': 0.2860161518876178, 'validation/num_examples': 3554, 'test/ssim': 0.7417742812543633, 'test/loss': 0.2873005082706472, 'test/num_examples': 3581, 'score': 4847.913654327393, 'total_duration': 5097.467324256897, 'accumulated_submission_time': 4847.913654327393, 'accumulated_eval_time': 244.5843369960785, 'accumulated_logging_time': 4.106105089187622}
I0205 00:15:07.419799 139462596097792 logging_writer.py:48] [20354] accumulated_eval_time=244.584337, accumulated_logging_time=4.106105, accumulated_submission_time=4847.913654, global_step=20354, preemption_count=0, score=4847.913654, test/loss=0.287301, test/num_examples=3581, test/ssim=0.741774, total_duration=5097.467324, train/loss=0.266710, train/ssim=0.748084, validation/loss=0.286016, validation/num_examples=3554, validation/ssim=0.724550
I0205 00:15:16.153012 139462604490496 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.16263143718242645, loss=0.23549790680408478
I0205 00:15:40.320697 139462596097792 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.30369919538497925, loss=0.23320502042770386
I0205 00:16:04.501374 139462604490496 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.21357110142707825, loss=0.3651122450828552
I0205 00:16:27.403304 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:16:28.772684 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:16:30.092755 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:16:31.410264 139681449744192 submission_runner.py:408] Time since start: 5181.48s, 	Step: 20697, 	{'train/ssim': 0.7485865865434919, 'train/loss': 0.26616430282592773, 'validation/ssim': 0.7251484215628518, 'validation/loss': 0.28558687930303006, 'validation/num_examples': 3554, 'test/ssim': 0.742291810292167, 'test/loss': 0.28693893334613235, 'test/num_examples': 3581, 'score': 4927.873211860657, 'total_duration': 5181.477455615997, 'accumulated_submission_time': 4927.873211860657, 'accumulated_eval_time': 248.59125542640686, 'accumulated_logging_time': 4.135280132293701}
I0205 00:16:31.429709 139462596097792 logging_writer.py:48] [20697] accumulated_eval_time=248.591255, accumulated_logging_time=4.135280, accumulated_submission_time=4927.873212, global_step=20697, preemption_count=0, score=4927.873212, test/loss=0.286939, test/num_examples=3581, test/ssim=0.742292, total_duration=5181.477456, train/loss=0.266164, train/ssim=0.748587, validation/loss=0.285587, validation/num_examples=3554, validation/ssim=0.725148
I0205 00:16:31.737198 139462604490496 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.14595180749893188, loss=0.2530011534690857
I0205 00:16:54.057934 139462596097792 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.14131395518779755, loss=0.23597268760204315
I0205 00:17:17.950328 139462604490496 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.12019161880016327, loss=0.30512192845344543
I0205 00:17:41.723222 139462596097792 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.11334467679262161, loss=0.3099609613418579
I0205 00:17:51.519085 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:17:52.891031 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:17:54.208950 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:17:55.528891 139681449744192 submission_runner.py:408] Time since start: 5265.60s, 	Step: 21042, 	{'train/ssim': 0.7484387670244489, 'train/loss': 0.2663168055670602, 'validation/ssim': 0.7248215039392234, 'validation/loss': 0.285725024153023, 'validation/num_examples': 3554, 'test/ssim': 0.742089802844003, 'test/loss': 0.28709587602101366, 'test/num_examples': 3581, 'score': 5007.937152862549, 'total_duration': 5265.59605717659, 'accumulated_submission_time': 5007.937152862549, 'accumulated_eval_time': 252.60098385810852, 'accumulated_logging_time': 4.1652820110321045}
I0205 00:17:55.552272 139462604490496 logging_writer.py:48] [21042] accumulated_eval_time=252.600984, accumulated_logging_time=4.165282, accumulated_submission_time=5007.937153, global_step=21042, preemption_count=0, score=5007.937153, test/loss=0.287096, test/num_examples=3581, test/ssim=0.742090, total_duration=5265.596057, train/loss=0.266317, train/ssim=0.748439, validation/loss=0.285725, validation/num_examples=3554, validation/ssim=0.724822
I0205 00:18:07.437904 139462596097792 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.084834024310112, loss=0.2701399326324463
I0205 00:18:31.202903 139462604490496 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.19851455092430115, loss=0.2203364372253418
I0205 00:18:54.775003 139462596097792 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.11668342351913452, loss=0.27311399579048157
I0205 00:19:15.696461 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:19:17.065116 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:19:18.384526 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:19:19.705118 139681449744192 submission_runner.py:408] Time since start: 5349.77s, 	Step: 21388, 	{'train/ssim': 0.7481115886143276, 'train/loss': 0.2667201246534075, 'validation/ssim': 0.7249347126477209, 'validation/loss': 0.2858996458380962, 'validation/num_examples': 3554, 'test/ssim': 0.7421052107695127, 'test/loss': 0.2872167873302674, 'test/num_examples': 3581, 'score': 5088.057301521301, 'total_duration': 5349.772326469421, 'accumulated_submission_time': 5088.057301521301, 'accumulated_eval_time': 256.6096124649048, 'accumulated_logging_time': 4.198110818862915}
I0205 00:19:19.724737 139462604490496 logging_writer.py:48] [21388] accumulated_eval_time=256.609612, accumulated_logging_time=4.198111, accumulated_submission_time=5088.057302, global_step=21388, preemption_count=0, score=5088.057302, test/loss=0.287217, test/num_examples=3581, test/ssim=0.742105, total_duration=5349.772326, train/loss=0.266720, train/ssim=0.748112, validation/loss=0.285900, validation/num_examples=3554, validation/ssim=0.724935
I0205 00:19:20.678826 139462596097792 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.1173054501414299, loss=0.2577097415924072
I0205 00:19:44.398424 139462604490496 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.3777059018611908, loss=0.2155608832836151
I0205 00:20:08.575639 139462596097792 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.13610295951366425, loss=0.22334614396095276
I0205 00:20:32.474850 139462604490496 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.16247910261154175, loss=0.30207258462905884
I0205 00:20:39.763500 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:20:41.134904 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:20:42.455958 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:20:43.775261 139681449744192 submission_runner.py:408] Time since start: 5433.84s, 	Step: 21732, 	{'train/ssim': 0.7490191459655762, 'train/loss': 0.2662261894771031, 'validation/ssim': 0.7253119834165729, 'validation/loss': 0.2857492218275183, 'validation/num_examples': 3554, 'test/ssim': 0.7425255198879503, 'test/loss': 0.2870578334438704, 'test/num_examples': 3581, 'score': 5168.070353746414, 'total_duration': 5433.842468261719, 'accumulated_submission_time': 5168.070353746414, 'accumulated_eval_time': 260.62133407592773, 'accumulated_logging_time': 4.228944778442383}
I0205 00:20:43.795341 139462596097792 logging_writer.py:48] [21732] accumulated_eval_time=260.621334, accumulated_logging_time=4.228945, accumulated_submission_time=5168.070354, global_step=21732, preemption_count=0, score=5168.070354, test/loss=0.287058, test/num_examples=3581, test/ssim=0.742526, total_duration=5433.842468, train/loss=0.266226, train/ssim=0.749019, validation/loss=0.285749, validation/num_examples=3554, validation/ssim=0.725312
I0205 00:20:57.665464 139462604490496 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.2895532548427582, loss=0.24692144989967346
I0205 00:21:21.601914 139462596097792 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.07805652171373367, loss=0.3476797640323639
I0205 00:21:45.395459 139462604490496 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.17949160933494568, loss=0.285011351108551
I0205 00:22:03.972611 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:22:05.340348 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:22:06.660385 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:22:07.980870 139681449744192 submission_runner.py:408] Time since start: 5518.05s, 	Step: 22079, 	{'train/ssim': 0.749504634312221, 'train/loss': 0.265928966658456, 'validation/ssim': 0.7256125223120076, 'validation/loss': 0.28558181307593555, 'validation/num_examples': 3554, 'test/ssim': 0.7428523588034068, 'test/loss': 0.2868992204407812, 'test/num_examples': 3581, 'score': 5248.222505569458, 'total_duration': 5518.048063755035, 'accumulated_submission_time': 5248.222505569458, 'accumulated_eval_time': 264.62954115867615, 'accumulated_logging_time': 4.259636402130127}
I0205 00:22:08.000879 139462596097792 logging_writer.py:48] [22079] accumulated_eval_time=264.629541, accumulated_logging_time=4.259636, accumulated_submission_time=5248.222506, global_step=22079, preemption_count=0, score=5248.222506, test/loss=0.286899, test/num_examples=3581, test/ssim=0.742852, total_duration=5518.048064, train/loss=0.265929, train/ssim=0.749505, validation/loss=0.285582, validation/num_examples=3554, validation/ssim=0.725613
I0205 00:22:10.830012 139462604490496 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.08994757384061813, loss=0.2699012756347656
I0205 00:22:35.157007 139462596097792 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.06582751125097275, loss=0.2814897894859314
I0205 00:22:59.117860 139462604490496 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.15339967608451843, loss=0.32780060172080994
I0205 00:23:22.826930 139462596097792 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.0827886238694191, loss=0.2532150149345398
I0205 00:23:28.073954 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:23:29.440607 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:23:30.763120 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:23:32.085147 139681449744192 submission_runner.py:408] Time since start: 5602.15s, 	Step: 22423, 	{'train/ssim': 0.749286447252546, 'train/loss': 0.26605565207345144, 'validation/ssim': 0.7258175757069499, 'validation/loss': 0.28542900192784537, 'validation/num_examples': 3554, 'test/ssim': 0.7429833943469003, 'test/loss': 0.2867292901118752, 'test/num_examples': 3581, 'score': 5328.270455598831, 'total_duration': 5602.152354717255, 'accumulated_submission_time': 5328.270455598831, 'accumulated_eval_time': 268.64070224761963, 'accumulated_logging_time': 4.2899558544158936}
I0205 00:23:32.105458 139462604490496 logging_writer.py:48] [22423] accumulated_eval_time=268.640702, accumulated_logging_time=4.289956, accumulated_submission_time=5328.270456, global_step=22423, preemption_count=0, score=5328.270456, test/loss=0.286729, test/num_examples=3581, test/ssim=0.742983, total_duration=5602.152355, train/loss=0.266056, train/ssim=0.749286, validation/loss=0.285429, validation/num_examples=3554, validation/ssim=0.725818
I0205 00:23:48.383183 139462596097792 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.05556610971689224, loss=0.30915409326553345
I0205 00:24:12.287329 139462604490496 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.11529505252838135, loss=0.223845973610878
I0205 00:24:36.649815 139462596097792 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.20950253307819366, loss=0.21231169998645782
I0205 00:24:52.195223 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:24:53.565462 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:24:54.884328 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:24:56.203666 139681449744192 submission_runner.py:408] Time since start: 5686.27s, 	Step: 22767, 	{'train/ssim': 0.7490869930812291, 'train/loss': 0.2664235830307007, 'validation/ssim': 0.725718861560038, 'validation/loss': 0.2856929265989906, 'validation/num_examples': 3554, 'test/ssim': 0.7428747207483943, 'test/loss': 0.2871282258469178, 'test/num_examples': 3581, 'score': 5408.337042331696, 'total_duration': 5686.270875692368, 'accumulated_submission_time': 5408.337042331696, 'accumulated_eval_time': 272.6491093635559, 'accumulated_logging_time': 4.319113254547119}
I0205 00:24:56.223934 139462604490496 logging_writer.py:48] [22767] accumulated_eval_time=272.649109, accumulated_logging_time=4.319113, accumulated_submission_time=5408.337042, global_step=22767, preemption_count=0, score=5408.337042, test/loss=0.287128, test/num_examples=3581, test/ssim=0.742875, total_duration=5686.270876, train/loss=0.266424, train/ssim=0.749087, validation/loss=0.285693, validation/num_examples=3554, validation/ssim=0.725719
I0205 00:25:02.295802 139462596097792 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.14630351960659027, loss=0.23275721073150635
I0205 00:25:26.065708 139462604490496 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.17703485488891602, loss=0.21019135415554047
I0205 00:25:50.250844 139462596097792 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.0770353153347969, loss=0.27557212114334106
I0205 00:26:14.002123 139462604490496 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.12387010455131531, loss=0.2668512761592865
I0205 00:26:16.348180 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:26:17.717241 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:26:19.038183 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:26:20.357470 139681449744192 submission_runner.py:408] Time since start: 5770.42s, 	Step: 23111, 	{'train/ssim': 0.7498129435947963, 'train/loss': 0.26553709166390554, 'validation/ssim': 0.7259281053258653, 'validation/loss': 0.285219534904553, 'validation/num_examples': 3554, 'test/ssim': 0.743165426033231, 'test/loss': 0.2865338276232198, 'test/num_examples': 3581, 'score': 5488.437965869904, 'total_duration': 5770.424674987793, 'accumulated_submission_time': 5488.437965869904, 'accumulated_eval_time': 276.6583559513092, 'accumulated_logging_time': 4.348245620727539}
I0205 00:26:20.377546 139462596097792 logging_writer.py:48] [23111] accumulated_eval_time=276.658356, accumulated_logging_time=4.348246, accumulated_submission_time=5488.437966, global_step=23111, preemption_count=0, score=5488.437966, test/loss=0.286534, test/num_examples=3581, test/ssim=0.743165, total_duration=5770.424675, train/loss=0.265537, train/ssim=0.749813, validation/loss=0.285220, validation/num_examples=3554, validation/ssim=0.725928
I0205 00:26:39.290041 139462604490496 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.10670986026525497, loss=0.3039124011993408
I0205 00:27:03.097706 139462596097792 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.2555607557296753, loss=0.24038265645503998
I0205 00:27:26.796697 139462604490496 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.12406866252422333, loss=0.2932508885860443
I0205 00:27:40.444457 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:27:41.813370 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:27:43.133037 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:27:44.452054 139681449744192 submission_runner.py:408] Time since start: 5854.52s, 	Step: 23459, 	{'train/ssim': 0.7490844045366559, 'train/loss': 0.2656686987195696, 'validation/ssim': 0.7254319241963281, 'validation/loss': 0.28513127951120215, 'validation/num_examples': 3554, 'test/ssim': 0.742678781023108, 'test/loss': 0.2864100188058503, 'test/num_examples': 3581, 'score': 5568.480888128281, 'total_duration': 5854.519265413284, 'accumulated_submission_time': 5568.480888128281, 'accumulated_eval_time': 280.66591787338257, 'accumulated_logging_time': 4.377592325210571}
I0205 00:27:44.472145 139462596097792 logging_writer.py:48] [23459] accumulated_eval_time=280.665918, accumulated_logging_time=4.377592, accumulated_submission_time=5568.480888, global_step=23459, preemption_count=0, score=5568.480888, test/loss=0.286410, test/num_examples=3581, test/ssim=0.742679, total_duration=5854.519265, train/loss=0.265669, train/ssim=0.749084, validation/loss=0.285131, validation/num_examples=3554, validation/ssim=0.725432
I0205 00:27:52.162164 139462604490496 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.08958929032087326, loss=0.24224218726158142
I0205 00:28:15.885116 139462596097792 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.11457346379756927, loss=0.28356415033340454
I0205 00:28:39.710732 139462604490496 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.08401980251073837, loss=0.33542177081108093
I0205 00:29:03.960629 139462596097792 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.12852701544761658, loss=0.21107307076454163
I0205 00:29:04.628850 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:29:05.998828 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:29:07.317893 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:29:08.639593 139681449744192 submission_runner.py:408] Time since start: 5938.71s, 	Step: 23804, 	{'train/ssim': 0.7493758201599121, 'train/loss': 0.26564463547297884, 'validation/ssim': 0.7255900591762803, 'validation/loss': 0.28517653208202903, 'validation/num_examples': 3554, 'test/ssim': 0.7428889014939961, 'test/loss': 0.2864074621810423, 'test/num_examples': 3581, 'score': 5648.613835811615, 'total_duration': 5938.706800699234, 'accumulated_submission_time': 5648.613835811615, 'accumulated_eval_time': 284.6766347885132, 'accumulated_logging_time': 4.406728506088257}
I0205 00:29:08.661332 139462604490496 logging_writer.py:48] [23804] accumulated_eval_time=284.676635, accumulated_logging_time=4.406729, accumulated_submission_time=5648.613836, global_step=23804, preemption_count=0, score=5648.613836, test/loss=0.286407, test/num_examples=3581, test/ssim=0.742889, total_duration=5938.706801, train/loss=0.265645, train/ssim=0.749376, validation/loss=0.285177, validation/num_examples=3554, validation/ssim=0.725590
I0205 00:29:29.563992 139462596097792 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.1015293076634407, loss=0.2843557596206665
I0205 00:29:53.468167 139462604490496 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.13676634430885315, loss=0.1869988888502121
I0205 00:30:17.340686 139462596097792 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.25441065430641174, loss=0.2928558588027954
I0205 00:30:28.669214 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:30:30.038520 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:30:31.358619 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:30:32.676352 139681449744192 submission_runner.py:408] Time since start: 6022.74s, 	Step: 24148, 	{'train/ssim': 0.7498668261936733, 'train/loss': 0.2651958976473127, 'validation/ssim': 0.7257230519309229, 'validation/loss': 0.28512276138022297, 'validation/num_examples': 3554, 'test/ssim': 0.7429643048816671, 'test/loss': 0.2864313581009145, 'test/num_examples': 3581, 'score': 5728.598200559616, 'total_duration': 6022.743552207947, 'accumulated_submission_time': 5728.598200559616, 'accumulated_eval_time': 288.6837303638458, 'accumulated_logging_time': 4.437592029571533}
I0205 00:30:32.696112 139462604490496 logging_writer.py:48] [24148] accumulated_eval_time=288.683730, accumulated_logging_time=4.437592, accumulated_submission_time=5728.598201, global_step=24148, preemption_count=0, score=5728.598201, test/loss=0.286431, test/num_examples=3581, test/ssim=0.742964, total_duration=6022.743552, train/loss=0.265196, train/ssim=0.749867, validation/loss=0.285123, validation/num_examples=3554, validation/ssim=0.725723
I0205 00:30:43.107504 139462596097792 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.1399560123682022, loss=0.2699609100818634
I0205 00:31:07.009185 139462604490496 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.15370848774909973, loss=0.24823151528835297
I0205 00:31:30.854104 139462596097792 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.2119041085243225, loss=0.2831380069255829
I0205 00:31:52.739216 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:31:54.108697 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:31:55.428106 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:31:56.747528 139681449744192 submission_runner.py:408] Time since start: 6106.81s, 	Step: 24494, 	{'train/ssim': 0.7496851512363979, 'train/loss': 0.2655548027583531, 'validation/ssim': 0.7258203921857415, 'validation/loss': 0.28521201284534153, 'validation/num_examples': 3554, 'test/ssim': 0.7430404582126152, 'test/loss': 0.28653703192631247, 'test/num_examples': 3581, 'score': 5808.61803650856, 'total_duration': 6106.814738750458, 'accumulated_submission_time': 5808.61803650856, 'accumulated_eval_time': 292.6920075416565, 'accumulated_logging_time': 4.466193199157715}
I0205 00:31:56.771618 139462604490496 logging_writer.py:48] [24494] accumulated_eval_time=292.692008, accumulated_logging_time=4.466193, accumulated_submission_time=5808.618037, global_step=24494, preemption_count=0, score=5808.618037, test/loss=0.286537, test/num_examples=3581, test/ssim=0.743040, total_duration=6106.814739, train/loss=0.265555, train/ssim=0.749685, validation/loss=0.285212, validation/num_examples=3554, validation/ssim=0.725820
I0205 00:31:57.293196 139462596097792 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.24519304931163788, loss=0.33705559372901917
I0205 00:32:20.160428 139462604490496 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.2515454888343811, loss=0.222012460231781
I0205 00:32:43.965536 139462596097792 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.13978835940361023, loss=0.27165475487709045
I0205 00:33:07.942175 139462604490496 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.14655859768390656, loss=0.272754967212677
I0205 00:33:16.870539 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:33:18.239782 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:33:19.559253 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:33:20.878528 139681449744192 submission_runner.py:408] Time since start: 6190.95s, 	Step: 24838, 	{'train/ssim': 0.748795781816755, 'train/loss': 0.2659956046513149, 'validation/ssim': 0.7251729455367192, 'validation/loss': 0.2854291908380082, 'validation/num_examples': 3554, 'test/ssim': 0.7424380492311854, 'test/loss': 0.2867215520607896, 'test/num_examples': 3581, 'score': 5888.6937420368195, 'total_duration': 6190.94571518898, 'accumulated_submission_time': 5888.6937420368195, 'accumulated_eval_time': 296.69993567466736, 'accumulated_logging_time': 4.499108552932739}
I0205 00:33:20.899335 139462596097792 logging_writer.py:48] [24838] accumulated_eval_time=296.699936, accumulated_logging_time=4.499109, accumulated_submission_time=5888.693742, global_step=24838, preemption_count=0, score=5888.693742, test/loss=0.286722, test/num_examples=3581, test/ssim=0.742438, total_duration=6190.945715, train/loss=0.265996, train/ssim=0.748796, validation/loss=0.285429, validation/num_examples=3554, validation/ssim=0.725173
I0205 00:33:33.751259 139462604490496 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.09936146438121796, loss=0.2755853533744812
I0205 00:33:57.681358 139462596097792 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.1069144681096077, loss=0.29386329650878906
I0205 00:34:21.321460 139462604490496 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.09202402085065842, loss=0.3338361084461212
I0205 00:34:41.074667 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:34:42.444124 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:34:43.763790 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:34:45.082884 139681449744192 submission_runner.py:408] Time since start: 6275.15s, 	Step: 25185, 	{'train/ssim': 0.7506846700395856, 'train/loss': 0.26508048602512907, 'validation/ssim': 0.7263689872986424, 'validation/loss': 0.2851709162980972, 'validation/num_examples': 3554, 'test/ssim': 0.7436003249572396, 'test/loss': 0.2864891037332449, 'test/num_examples': 3581, 'score': 5968.84553027153, 'total_duration': 6275.150093793869, 'accumulated_submission_time': 5968.84553027153, 'accumulated_eval_time': 300.70812129974365, 'accumulated_logging_time': 4.529009819030762}
I0205 00:34:45.103914 139462596097792 logging_writer.py:48] [25185] accumulated_eval_time=300.708121, accumulated_logging_time=4.529010, accumulated_submission_time=5968.845530, global_step=25185, preemption_count=0, score=5968.845530, test/loss=0.286489, test/num_examples=3581, test/ssim=0.743600, total_duration=6275.150094, train/loss=0.265080, train/ssim=0.750685, validation/loss=0.285171, validation/num_examples=3554, validation/ssim=0.726369
I0205 00:34:46.654832 139462604490496 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.09248674660921097, loss=0.28952765464782715
I0205 00:35:10.336472 139462596097792 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.11944864690303802, loss=0.2821166515350342
I0205 00:35:34.104840 139462604490496 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.2566872537136078, loss=0.21562641859054565
I0205 00:35:58.068309 139462596097792 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.11422159522771835, loss=0.25897783041000366
I0205 00:36:05.153742 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:36:06.522748 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:36:07.843082 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:36:09.162534 139681449744192 submission_runner.py:408] Time since start: 6359.23s, 	Step: 25531, 	{'train/ssim': 0.7494222096034459, 'train/loss': 0.26529708930424284, 'validation/ssim': 0.7254723853184791, 'validation/loss': 0.28499687851716377, 'validation/num_examples': 3554, 'test/ssim': 0.742812748163048, 'test/loss': 0.28627891508569536, 'test/num_examples': 3581, 'score': 6048.872050285339, 'total_duration': 6359.229727506638, 'accumulated_submission_time': 6048.872050285339, 'accumulated_eval_time': 304.7168712615967, 'accumulated_logging_time': 4.558919191360474}
I0205 00:36:09.183844 139462604490496 logging_writer.py:48] [25531] accumulated_eval_time=304.716871, accumulated_logging_time=4.558919, accumulated_submission_time=6048.872050, global_step=25531, preemption_count=0, score=6048.872050, test/loss=0.286279, test/num_examples=3581, test/ssim=0.742813, total_duration=6359.229728, train/loss=0.265297, train/ssim=0.749422, validation/loss=0.284997, validation/num_examples=3554, validation/ssim=0.725472
I0205 00:36:23.623853 139462596097792 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.14245976507663727, loss=0.3490336835384369
I0205 00:36:47.449275 139462604490496 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.11616817116737366, loss=0.2410528063774109
I0205 00:37:11.271394 139462596097792 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.06295587867498398, loss=0.25390687584877014
I0205 00:37:29.268697 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:37:30.636504 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:37:31.957651 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:37:33.273909 139681449744192 submission_runner.py:408] Time since start: 6443.34s, 	Step: 25876, 	{'train/ssim': 0.7495801789419991, 'train/loss': 0.2653527430125645, 'validation/ssim': 0.7257883804999649, 'validation/loss': 0.2849699502321328, 'validation/num_examples': 3554, 'test/ssim': 0.7430234140472284, 'test/loss': 0.2862819148588034, 'test/num_examples': 3581, 'score': 6128.933758020401, 'total_duration': 6443.341115951538, 'accumulated_submission_time': 6128.933758020401, 'accumulated_eval_time': 308.72206234931946, 'accumulated_logging_time': 4.588968515396118}
I0205 00:37:33.296412 139462604490496 logging_writer.py:48] [25876] accumulated_eval_time=308.722062, accumulated_logging_time=4.588969, accumulated_submission_time=6128.933758, global_step=25876, preemption_count=0, score=6128.933758, test/loss=0.286282, test/num_examples=3581, test/ssim=0.743023, total_duration=6443.341116, train/loss=0.265353, train/ssim=0.749580, validation/loss=0.284970, validation/num_examples=3554, validation/ssim=0.725788
I0205 00:37:36.918427 139462596097792 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.1362725794315338, loss=0.21472051739692688
I0205 00:38:01.177837 139462604490496 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.14770416915416718, loss=0.32377344369888306
I0205 00:38:24.976871 139462596097792 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.08450181782245636, loss=0.2929690480232239
I0205 00:38:48.574388 139462604490496 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.07683172076940536, loss=0.2806202471256256
I0205 00:38:53.495921 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:38:54.866536 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:38:56.186429 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:38:57.506424 139681449744192 submission_runner.py:408] Time since start: 6527.57s, 	Step: 26222, 	{'train/ssim': 0.7504499980381557, 'train/loss': 0.26486739090510775, 'validation/ssim': 0.7260060737021665, 'validation/loss': 0.2850825063418859, 'validation/num_examples': 3554, 'test/ssim': 0.74321253610636, 'test/loss': 0.2864005763382261, 'test/num_examples': 3581, 'score': 6209.109485387802, 'total_duration': 6527.5736310482025, 'accumulated_submission_time': 6209.109485387802, 'accumulated_eval_time': 312.73252749443054, 'accumulated_logging_time': 4.620581388473511}
I0205 00:38:57.528346 139462596097792 logging_writer.py:48] [26222] accumulated_eval_time=312.732527, accumulated_logging_time=4.620581, accumulated_submission_time=6209.109485, global_step=26222, preemption_count=0, score=6209.109485, test/loss=0.286401, test/num_examples=3581, test/ssim=0.743213, total_duration=6527.573631, train/loss=0.264867, train/ssim=0.750450, validation/loss=0.285083, validation/num_examples=3554, validation/ssim=0.726006
I0205 00:39:14.065478 139462604490496 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.13792158663272858, loss=0.2575317919254303
I0205 00:39:37.771133 139462596097792 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.08133682608604431, loss=0.407626211643219
I0205 00:40:01.668325 139462604490496 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.20714156329631805, loss=0.20702917873859406
I0205 00:40:17.699757 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:40:19.066486 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:40:20.385845 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:40:21.706246 139681449744192 submission_runner.py:408] Time since start: 6611.77s, 	Step: 26568, 	{'train/ssim': 0.7503705705915179, 'train/loss': 0.2652456249509539, 'validation/ssim': 0.7262834625158272, 'validation/loss': 0.2850904405687254, 'validation/num_examples': 3554, 'test/ssim': 0.7435167403701829, 'test/loss': 0.2864089279792656, 'test/num_examples': 3581, 'score': 6289.2570996284485, 'total_duration': 6611.773455381393, 'accumulated_submission_time': 6289.2570996284485, 'accumulated_eval_time': 316.73898911476135, 'accumulated_logging_time': 4.651438236236572}
I0205 00:40:21.727607 139462596097792 logging_writer.py:48] [26568] accumulated_eval_time=316.738989, accumulated_logging_time=4.651438, accumulated_submission_time=6289.257100, global_step=26568, preemption_count=0, score=6289.257100, test/loss=0.286409, test/num_examples=3581, test/ssim=0.743517, total_duration=6611.773455, train/loss=0.265246, train/ssim=0.750371, validation/loss=0.285090, validation/num_examples=3554, validation/ssim=0.726283
I0205 00:40:27.412720 139462604490496 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.18871842324733734, loss=0.30970072746276855
I0205 00:40:51.150665 139462596097792 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.11443942785263062, loss=0.32657691836357117
I0205 00:41:14.959832 139462604490496 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.10678102821111679, loss=0.26020348072052
I0205 00:41:38.581433 139462596097792 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.11281224340200424, loss=0.22959356009960175
I0205 00:41:41.840030 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:41:43.207701 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:41:44.528227 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:41:45.847697 139681449744192 submission_runner.py:408] Time since start: 6695.91s, 	Step: 26915, 	{'train/ssim': 0.7497830390930176, 'train/loss': 0.2651932580130441, 'validation/ssim': 0.7259059856631612, 'validation/loss': 0.28487460212084975, 'validation/num_examples': 3554, 'test/ssim': 0.7430864774591595, 'test/loss': 0.28618026345643677, 'test/num_examples': 3581, 'score': 6369.344420433044, 'total_duration': 6695.914905786514, 'accumulated_submission_time': 6369.344420433044, 'accumulated_eval_time': 320.7466149330139, 'accumulated_logging_time': 4.683363676071167}
I0205 00:41:45.869482 139462604490496 logging_writer.py:48] [26915] accumulated_eval_time=320.746615, accumulated_logging_time=4.683364, accumulated_submission_time=6369.344420, global_step=26915, preemption_count=0, score=6369.344420, test/loss=0.286180, test/num_examples=3581, test/ssim=0.743086, total_duration=6695.914906, train/loss=0.265193, train/ssim=0.749783, validation/loss=0.284875, validation/num_examples=3554, validation/ssim=0.725906
I0205 00:42:04.633394 139462596097792 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.11819441616535187, loss=0.22186340391635895
I0205 00:42:28.787899 139462604490496 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.3028416633605957, loss=0.28297707438468933
I0205 00:42:53.003583 139462596097792 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.10415872931480408, loss=0.3543283939361572
I0205 00:43:05.861181 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:43:07.232239 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:43:08.551038 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:43:09.873655 139681449744192 submission_runner.py:408] Time since start: 6779.94s, 	Step: 27255, 	{'train/ssim': 0.7505489758082798, 'train/loss': 0.2648061513900757, 'validation/ssim': 0.7262866224676421, 'validation/loss': 0.2849321338522615, 'validation/num_examples': 3554, 'test/ssim': 0.7434242928171251, 'test/loss': 0.2862984136108978, 'test/num_examples': 3581, 'score': 6449.312697172165, 'total_duration': 6779.940864801407, 'accumulated_submission_time': 6449.312697172165, 'accumulated_eval_time': 324.75905179977417, 'accumulated_logging_time': 4.714396953582764}
I0205 00:43:09.896538 139462604490496 logging_writer.py:48] [27255] accumulated_eval_time=324.759052, accumulated_logging_time=4.714397, accumulated_submission_time=6449.312697, global_step=27255, preemption_count=0, score=6449.312697, test/loss=0.286298, test/num_examples=3581, test/ssim=0.743424, total_duration=6779.940865, train/loss=0.264806, train/ssim=0.750549, validation/loss=0.284932, validation/num_examples=3554, validation/ssim=0.726287
I0205 00:43:18.631000 139462596097792 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.12463149428367615, loss=0.22068312764167786
I0205 00:43:42.463691 139462604490496 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.1289823204278946, loss=0.2591114640235901
I0205 00:44:06.431705 139462596097792 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.10665877163410187, loss=0.33639585971832275
I0205 00:44:30.120837 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:44:31.490862 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:44:32.810906 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:44:34.128323 139681449744192 submission_runner.py:408] Time since start: 6864.20s, 	Step: 27600, 	{'train/ssim': 0.750410965510777, 'train/loss': 0.2649491514478411, 'validation/ssim': 0.7263029030889491, 'validation/loss': 0.2848861943353879, 'validation/num_examples': 3554, 'test/ssim': 0.74350603663432, 'test/loss': 0.28616468508927323, 'test/num_examples': 3581, 'score': 6529.513382673264, 'total_duration': 6864.195533752441, 'accumulated_submission_time': 6529.513382673264, 'accumulated_eval_time': 328.7665092945099, 'accumulated_logging_time': 4.74639892578125}
I0205 00:44:34.151658 139462604490496 logging_writer.py:48] [27600] accumulated_eval_time=328.766509, accumulated_logging_time=4.746399, accumulated_submission_time=6529.513383, global_step=27600, preemption_count=0, score=6529.513383, test/loss=0.286165, test/num_examples=3581, test/ssim=0.743506, total_duration=6864.195534, train/loss=0.264949, train/ssim=0.750411, validation/loss=0.284886, validation/num_examples=3554, validation/ssim=0.726303
I0205 00:44:34.241336 139462596097792 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.07855577021837234, loss=0.29877763986587524
I0205 00:44:56.144614 139462604490496 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.1083107516169548, loss=0.36969783902168274
I0205 00:45:19.902810 139462596097792 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.05575534328818321, loss=0.31232115626335144
I0205 00:45:43.515669 139462604490496 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.08407621085643768, loss=0.3044426143169403
I0205 00:45:54.207232 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:45:55.577560 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:45:56.896078 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:45:58.216217 139681449744192 submission_runner.py:408] Time since start: 6948.28s, 	Step: 27946, 	{'train/ssim': 0.7503207751682827, 'train/loss': 0.26509937218257357, 'validation/ssim': 0.7263553170723129, 'validation/loss': 0.28493158429542415, 'validation/num_examples': 3554, 'test/ssim': 0.7435222626797682, 'test/loss': 0.28622890750445057, 'test/num_examples': 3581, 'score': 6609.545207738876, 'total_duration': 6948.283418178558, 'accumulated_submission_time': 6609.545207738876, 'accumulated_eval_time': 332.77544808387756, 'accumulated_logging_time': 4.7788896560668945}
I0205 00:45:58.238787 139462596097792 logging_writer.py:48] [27946] accumulated_eval_time=332.775448, accumulated_logging_time=4.778890, accumulated_submission_time=6609.545208, global_step=27946, preemption_count=0, score=6609.545208, test/loss=0.286229, test/num_examples=3581, test/ssim=0.743522, total_duration=6948.283418, train/loss=0.265099, train/ssim=0.750321, validation/loss=0.284932, validation/num_examples=3554, validation/ssim=0.726355
I0205 00:46:09.354668 139462604490496 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.1444808691740036, loss=0.21095353364944458
I0205 00:46:33.506705 139462596097792 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.14388646185398102, loss=0.21849177777767181
I0205 00:46:57.388435 139462604490496 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.132736936211586, loss=0.3675265312194824
I0205 00:47:18.485187 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:47:19.854896 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:47:21.175213 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:47:22.495977 139681449744192 submission_runner.py:408] Time since start: 7032.56s, 	Step: 28290, 	{'train/ssim': 0.7504880087716239, 'train/loss': 0.26482350485665457, 'validation/ssim': 0.7263116273037422, 'validation/loss': 0.28491015157876687, 'validation/num_examples': 3554, 'test/ssim': 0.7434201340407708, 'test/loss': 0.2862642571034627, 'test/num_examples': 3581, 'score': 6689.76785159111, 'total_duration': 7032.563189744949, 'accumulated_submission_time': 6689.76785159111, 'accumulated_eval_time': 336.7862060070038, 'accumulated_logging_time': 4.811024188995361}
I0205 00:47:22.516970 139462596097792 logging_writer.py:48] [28290] accumulated_eval_time=336.786206, accumulated_logging_time=4.811024, accumulated_submission_time=6689.767852, global_step=28290, preemption_count=0, score=6689.767852, test/loss=0.286264, test/num_examples=3581, test/ssim=0.743420, total_duration=7032.563190, train/loss=0.264824, train/ssim=0.750488, validation/loss=0.284910, validation/num_examples=3554, validation/ssim=0.726312
I0205 00:47:23.330902 139462604490496 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.13006940484046936, loss=0.2638016641139984
I0205 00:47:46.539802 139462596097792 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.13554739952087402, loss=0.22883671522140503
I0205 00:48:10.085326 139462604490496 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.09271957725286484, loss=0.2951791286468506
I0205 00:48:34.179847 139462596097792 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.07554369419813156, loss=0.3120662569999695
I0205 00:48:42.613118 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:48:43.983582 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:48:45.302240 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:48:46.625178 139681449744192 submission_runner.py:408] Time since start: 7116.69s, 	Step: 28637, 	{'train/ssim': 0.7506187983921596, 'train/loss': 0.26490603174482075, 'validation/ssim': 0.7264817151449071, 'validation/loss': 0.2849294547626794, 'validation/num_examples': 3554, 'test/ssim': 0.7436845231342503, 'test/loss': 0.2862636776018396, 'test/num_examples': 3581, 'score': 6769.840493440628, 'total_duration': 7116.692368984222, 'accumulated_submission_time': 6769.840493440628, 'accumulated_eval_time': 340.79823088645935, 'accumulated_logging_time': 4.841078758239746}
I0205 00:48:46.647624 139462604490496 logging_writer.py:48] [28637] accumulated_eval_time=340.798231, accumulated_logging_time=4.841079, accumulated_submission_time=6769.840493, global_step=28637, preemption_count=0, score=6769.840493, test/loss=0.286264, test/num_examples=3581, test/ssim=0.743685, total_duration=7116.692369, train/loss=0.264906, train/ssim=0.750619, validation/loss=0.284929, validation/num_examples=3554, validation/ssim=0.726482
I0205 00:48:59.459474 139462596097792 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.056128691881895065, loss=0.2937401533126831
I0205 00:49:23.492089 139462604490496 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.18947327136993408, loss=0.2694762647151947
I0205 00:49:47.534647 139462596097792 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.07169009000062943, loss=0.3032516837120056
I0205 00:50:06.722876 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:50:08.092984 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:50:09.412614 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:50:10.728466 139681449744192 submission_runner.py:408] Time since start: 7200.80s, 	Step: 28982, 	{'train/ssim': 0.7507256780351911, 'train/loss': 0.26495700223105295, 'validation/ssim': 0.7265615382755346, 'validation/loss': 0.2849720625912264, 'validation/num_examples': 3554, 'test/ssim': 0.7437460866596272, 'test/loss': 0.28625147397942263, 'test/num_examples': 3581, 'score': 6849.891664505005, 'total_duration': 7200.7956709861755, 'accumulated_submission_time': 6849.891664505005, 'accumulated_eval_time': 344.80379843711853, 'accumulated_logging_time': 4.873269319534302}
I0205 00:50:10.750928 139462604490496 logging_writer.py:48] [28982] accumulated_eval_time=344.803798, accumulated_logging_time=4.873269, accumulated_submission_time=6849.891665, global_step=28982, preemption_count=0, score=6849.891665, test/loss=0.286251, test/num_examples=3581, test/ssim=0.743746, total_duration=7200.795671, train/loss=0.264957, train/ssim=0.750726, validation/loss=0.284972, validation/num_examples=3554, validation/ssim=0.726562
I0205 00:50:12.993767 139462596097792 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.11685074865818024, loss=0.22530116140842438
I0205 00:50:37.011364 139462604490496 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.14643754065036774, loss=0.18489885330200195
I0205 00:51:01.466662 139462596097792 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.13464780151844025, loss=0.1883717179298401
I0205 00:51:25.647405 139462604490496 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.060803256928920746, loss=0.2908904552459717
I0205 00:51:30.862202 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:51:32.232255 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:51:33.553905 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:51:34.874475 139681449744192 submission_runner.py:408] Time since start: 7284.94s, 	Step: 29323, 	{'train/ssim': 0.750253541128976, 'train/loss': 0.26486986024039133, 'validation/ssim': 0.7261388603729952, 'validation/loss': 0.28492605437974816, 'validation/num_examples': 3554, 'test/ssim': 0.7433762282707345, 'test/loss': 0.28626599560833216, 'test/num_examples': 3581, 'score': 6929.979115247726, 'total_duration': 7284.941651105881, 'accumulated_submission_time': 6929.979115247726, 'accumulated_eval_time': 348.8160009384155, 'accumulated_logging_time': 4.905006408691406}
I0205 00:51:34.895932 139462596097792 logging_writer.py:48] [29323] accumulated_eval_time=348.816001, accumulated_logging_time=4.905006, accumulated_submission_time=6929.979115, global_step=29323, preemption_count=0, score=6929.979115, test/loss=0.286266, test/num_examples=3581, test/ssim=0.743376, total_duration=7284.941651, train/loss=0.264870, train/ssim=0.750254, validation/loss=0.284926, validation/num_examples=3554, validation/ssim=0.726139
I0205 00:51:50.899194 139462604490496 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.16077126562595367, loss=0.2793070673942566
I0205 00:52:15.089847 139462596097792 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.12318245321512222, loss=0.2130662202835083
I0205 00:52:39.140930 139462604490496 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.15041202306747437, loss=0.2540145814418793
I0205 00:52:55.102336 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:52:56.469787 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:52:57.789000 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:52:59.110537 139681449744192 submission_runner.py:408] Time since start: 7369.18s, 	Step: 29668, 	{'train/ssim': 0.7505779947553363, 'train/loss': 0.264641353062221, 'validation/ssim': 0.7261684677476083, 'validation/loss': 0.2848554878471001, 'validation/num_examples': 3554, 'test/ssim': 0.7433797734571349, 'test/loss': 0.2861837404661757, 'test/num_examples': 3581, 'score': 7010.161997318268, 'total_duration': 7369.177745580673, 'accumulated_submission_time': 7010.161997318268, 'accumulated_eval_time': 352.8241741657257, 'accumulated_logging_time': 4.9356300830841064}
I0205 00:52:59.133224 139462596097792 logging_writer.py:48] [29668] accumulated_eval_time=352.824174, accumulated_logging_time=4.935630, accumulated_submission_time=7010.161997, global_step=29668, preemption_count=0, score=7010.161997, test/loss=0.286184, test/num_examples=3581, test/ssim=0.743380, total_duration=7369.177746, train/loss=0.264641, train/ssim=0.750578, validation/loss=0.284855, validation/num_examples=3554, validation/ssim=0.726168
I0205 00:53:04.648049 139462604490496 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.0978216752409935, loss=0.3054804503917694
I0205 00:53:28.276362 139462596097792 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.09199254959821701, loss=0.2855154275894165
I0205 00:53:52.215332 139462604490496 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.10681656748056412, loss=0.24212509393692017
I0205 00:54:16.146047 139462596097792 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.07501260191202164, loss=0.2954369783401489
I0205 00:54:19.246964 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:54:20.615988 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:54:21.936332 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:54:23.254561 139681449744192 submission_runner.py:408] Time since start: 7453.32s, 	Step: 30014, 	{'train/ssim': 0.7503046308244977, 'train/loss': 0.2647990328924997, 'validation/ssim': 0.7261086347469401, 'validation/loss': 0.28482297812543966, 'validation/num_examples': 3554, 'test/ssim': 0.7432790083513683, 'test/loss': 0.2861041101254887, 'test/num_examples': 3581, 'score': 7090.252366781235, 'total_duration': 7453.321771860123, 'accumulated_submission_time': 7090.252366781235, 'accumulated_eval_time': 356.831734418869, 'accumulated_logging_time': 4.967212677001953}
I0205 00:54:23.276458 139462604490496 logging_writer.py:48] [30014] accumulated_eval_time=356.831734, accumulated_logging_time=4.967213, accumulated_submission_time=7090.252367, global_step=30014, preemption_count=0, score=7090.252367, test/loss=0.286104, test/num_examples=3581, test/ssim=0.743279, total_duration=7453.321772, train/loss=0.264799, train/ssim=0.750305, validation/loss=0.284823, validation/num_examples=3554, validation/ssim=0.726109
I0205 00:54:41.855798 139462596097792 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.08102454245090485, loss=0.2358863204717636
I0205 00:55:05.543853 139462604490496 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.11431559175252914, loss=0.27842769026756287
I0205 00:55:29.960236 139462596097792 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.10567957162857056, loss=0.21874555945396423
I0205 00:55:43.356859 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:55:44.726942 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:55:46.045906 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:55:47.366511 139681449744192 submission_runner.py:408] Time since start: 7537.43s, 	Step: 30357, 	{'train/ssim': 0.7509540830339704, 'train/loss': 0.2650235380445208, 'validation/ssim': 0.7267261992429305, 'validation/loss': 0.2851525576649989, 'validation/num_examples': 3554, 'test/ssim': 0.7438623960442264, 'test/loss': 0.2865039321571314, 'test/num_examples': 3581, 'score': 7170.308975458145, 'total_duration': 7537.433724164963, 'accumulated_submission_time': 7170.308975458145, 'accumulated_eval_time': 360.8413755893707, 'accumulated_logging_time': 4.998633146286011}
I0205 00:55:47.388847 139462604490496 logging_writer.py:48] [30357] accumulated_eval_time=360.841376, accumulated_logging_time=4.998633, accumulated_submission_time=7170.308975, global_step=30357, preemption_count=0, score=7170.308975, test/loss=0.286504, test/num_examples=3581, test/ssim=0.743862, total_duration=7537.433724, train/loss=0.265024, train/ssim=0.750954, validation/loss=0.285153, validation/num_examples=3554, validation/ssim=0.726726
I0205 00:55:55.703670 139462596097792 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.16817991435527802, loss=0.25114142894744873
I0205 00:56:19.823069 139462604490496 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.08860606700181961, loss=0.2251306176185608
I0205 00:56:43.691846 139462596097792 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.06678558886051178, loss=0.3220694661140442
I0205 00:57:07.490419 139462604490496 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.06609530746936798, loss=0.29046157002449036
I0205 00:57:07.902467 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:57:09.217999 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:57:10.538265 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:57:11.859098 139681449744192 submission_runner.py:408] Time since start: 7621.93s, 	Step: 30701, 	{'train/ssim': 0.7509610312325614, 'train/loss': 0.264449988092695, 'validation/ssim': 0.7264982705446328, 'validation/loss': 0.2848017686662475, 'validation/num_examples': 3554, 'test/ssim': 0.7436667972022479, 'test/loss': 0.2861409255227241, 'test/num_examples': 3581, 'score': 7250.800181627274, 'total_duration': 7621.926305532455, 'accumulated_submission_time': 7250.800181627274, 'accumulated_eval_time': 364.797967672348, 'accumulated_logging_time': 5.029951572418213}
I0205 00:57:11.882825 139462596097792 logging_writer.py:48] [30701] accumulated_eval_time=364.797968, accumulated_logging_time=5.029952, accumulated_submission_time=7250.800182, global_step=30701, preemption_count=0, score=7250.800182, test/loss=0.286141, test/num_examples=3581, test/ssim=0.743667, total_duration=7621.926306, train/loss=0.264450, train/ssim=0.750961, validation/loss=0.284802, validation/num_examples=3554, validation/ssim=0.726498
I0205 00:57:33.345600 139462604490496 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.142465740442276, loss=0.35588929057121277
I0205 00:57:57.286552 139462596097792 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.08705740422010422, loss=0.2098490446805954
I0205 00:58:21.054233 139462604490496 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.0599173977971077, loss=0.27536705136299133
I0205 00:58:31.913624 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:58:33.283660 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:58:34.601563 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:58:35.923258 139681449744192 submission_runner.py:408] Time since start: 7705.99s, 	Step: 31047, 	{'train/ssim': 0.7511175700596401, 'train/loss': 0.2646209682737078, 'validation/ssim': 0.7267902226144837, 'validation/loss': 0.28479922696587473, 'validation/num_examples': 3554, 'test/ssim': 0.7439442762147445, 'test/loss': 0.28610168985400375, 'test/num_examples': 3581, 'score': 7330.806107759476, 'total_duration': 7705.99044585228, 'accumulated_submission_time': 7330.806107759476, 'accumulated_eval_time': 368.80754828453064, 'accumulated_logging_time': 5.063923120498657}
I0205 00:58:35.945814 139462596097792 logging_writer.py:48] [31047] accumulated_eval_time=368.807548, accumulated_logging_time=5.063923, accumulated_submission_time=7330.806108, global_step=31047, preemption_count=0, score=7330.806108, test/loss=0.286102, test/num_examples=3581, test/ssim=0.743944, total_duration=7705.990446, train/loss=0.264621, train/ssim=0.751118, validation/loss=0.284799, validation/num_examples=3554, validation/ssim=0.726790
I0205 00:58:46.442594 139462604490496 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.12874512374401093, loss=0.199810191988945
I0205 00:59:10.254217 139462596097792 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.08392124623060226, loss=0.21519877016544342
I0205 00:59:34.438364 139462604490496 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.16084492206573486, loss=0.33862772583961487
I0205 00:59:55.983491 139681449744192 spec.py:321] Evaluating on the training split.
I0205 00:59:57.352853 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 00:59:58.675050 139681449744192 spec.py:349] Evaluating on the test split.
I0205 00:59:59.994384 139681449744192 submission_runner.py:408] Time since start: 7790.06s, 	Step: 31390, 	{'train/ssim': 0.7512401853288923, 'train/loss': 0.2646078722817557, 'validation/ssim': 0.7270120374929657, 'validation/loss': 0.28474507844374297, 'validation/num_examples': 3554, 'test/ssim': 0.7441750542140813, 'test/loss': 0.28603988771031136, 'test/num_examples': 3581, 'score': 7410.819982767105, 'total_duration': 7790.061582565308, 'accumulated_submission_time': 7410.819982767105, 'accumulated_eval_time': 372.81839632987976, 'accumulated_logging_time': 5.095531225204468}
I0205 01:00:00.019074 139462596097792 logging_writer.py:48] [31390] accumulated_eval_time=372.818396, accumulated_logging_time=5.095531, accumulated_submission_time=7410.819983, global_step=31390, preemption_count=0, score=7410.819983, test/loss=0.286040, test/num_examples=3581, test/ssim=0.744175, total_duration=7790.061583, train/loss=0.264608, train/ssim=0.751240, validation/loss=0.284745, validation/num_examples=3554, validation/ssim=0.727012
I0205 01:00:00.832198 139462604490496 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.13974906504154205, loss=0.21941035985946655
I0205 01:00:24.489603 139462596097792 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.12852445244789124, loss=0.26087188720703125
I0205 01:00:48.117396 139462604490496 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.09863351285457611, loss=0.21847450733184814
I0205 01:01:12.095676 139462596097792 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.07884972542524338, loss=0.23523734509944916
I0205 01:01:20.170384 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:01:21.540703 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:01:22.860301 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:01:24.177295 139681449744192 submission_runner.py:408] Time since start: 7874.24s, 	Step: 31735, 	{'train/ssim': 0.7512694086347308, 'train/loss': 0.2642558813095093, 'validation/ssim': 0.7266450709148143, 'validation/loss': 0.28473525511527503, 'validation/num_examples': 3554, 'test/ssim': 0.7438293303633762, 'test/loss': 0.28604738714308153, 'test/num_examples': 3581, 'score': 7490.946867465973, 'total_duration': 7874.244492769241, 'accumulated_submission_time': 7490.946867465973, 'accumulated_eval_time': 376.82525968551636, 'accumulated_logging_time': 5.130434513092041}
I0205 01:01:24.199770 139462604490496 logging_writer.py:48] [31735] accumulated_eval_time=376.825260, accumulated_logging_time=5.130435, accumulated_submission_time=7490.946867, global_step=31735, preemption_count=0, score=7490.946867, test/loss=0.286047, test/num_examples=3581, test/ssim=0.743829, total_duration=7874.244493, train/loss=0.264256, train/ssim=0.751269, validation/loss=0.284735, validation/num_examples=3554, validation/ssim=0.726645
I0205 01:01:37.613541 139462596097792 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.23169384896755219, loss=0.2182905226945877
I0205 01:02:01.547078 139462604490496 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.10058998316526413, loss=0.3049566149711609
I0205 01:02:25.769781 139462596097792 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.09423398971557617, loss=0.19014792144298553
I0205 01:02:44.386935 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:02:45.756260 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:02:47.076596 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:02:48.398204 139681449744192 submission_runner.py:408] Time since start: 7958.47s, 	Step: 32079, 	{'train/ssim': 0.7509448868887765, 'train/loss': 0.2644948278154646, 'validation/ssim': 0.7264786238876969, 'validation/loss': 0.2848054438275974, 'validation/num_examples': 3554, 'test/ssim': 0.743691477153728, 'test/loss': 0.28611232541320514, 'test/num_examples': 3581, 'score': 7571.110435009003, 'total_duration': 7958.465414047241, 'accumulated_submission_time': 7571.110435009003, 'accumulated_eval_time': 380.8364975452423, 'accumulated_logging_time': 5.161880731582642}
I0205 01:02:48.421099 139462604490496 logging_writer.py:48] [32079] accumulated_eval_time=380.836498, accumulated_logging_time=5.161881, accumulated_submission_time=7571.110435, global_step=32079, preemption_count=0, score=7571.110435, test/loss=0.286112, test/num_examples=3581, test/ssim=0.743691, total_duration=7958.465414, train/loss=0.264495, train/ssim=0.750945, validation/loss=0.284805, validation/num_examples=3554, validation/ssim=0.726479
I0205 01:02:51.407732 139462596097792 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.1066133975982666, loss=0.32657837867736816
I0205 01:03:15.506718 139462604490496 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.10781222581863403, loss=0.321505606174469
I0205 01:03:39.232036 139462596097792 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.08474011719226837, loss=0.29497790336608887
I0205 01:04:03.357414 139462604490496 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.06596662849187851, loss=0.26835495233535767
I0205 01:04:08.523185 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:04:09.890048 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:04:11.209324 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:04:12.529160 139681449744192 submission_runner.py:408] Time since start: 8042.60s, 	Step: 32422, 	{'train/ssim': 0.7511148452758789, 'train/loss': 0.2644805908203125, 'validation/ssim': 0.7268427739870569, 'validation/loss': 0.2846810378985386, 'validation/num_examples': 3554, 'test/ssim': 0.7440023627303826, 'test/loss': 0.28598595997102766, 'test/num_examples': 3581, 'score': 7651.189124345779, 'total_duration': 8042.596368312836, 'accumulated_submission_time': 7651.189124345779, 'accumulated_eval_time': 384.84243869781494, 'accumulated_logging_time': 5.193868160247803}
I0205 01:04:12.552013 139462596097792 logging_writer.py:48] [32422] accumulated_eval_time=384.842439, accumulated_logging_time=5.193868, accumulated_submission_time=7651.189124, global_step=32422, preemption_count=0, score=7651.189124, test/loss=0.285986, test/num_examples=3581, test/ssim=0.744002, total_duration=8042.596368, train/loss=0.264481, train/ssim=0.751115, validation/loss=0.284681, validation/num_examples=3554, validation/ssim=0.726843
I0205 01:04:29.049497 139462604490496 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.08697149902582169, loss=0.24936127662658691
I0205 01:04:53.048991 139462596097792 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.12805475294589996, loss=0.23364584147930145
I0205 01:05:17.172725 139462604490496 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.10083702206611633, loss=0.24698406457901
I0205 01:05:32.633480 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:05:34.004894 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:05:35.326949 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:05:36.646833 139681449744192 submission_runner.py:408] Time since start: 8126.71s, 	Step: 32767, 	{'train/ssim': 0.7514227458408901, 'train/loss': 0.2641618422099522, 'validation/ssim': 0.7267701637899198, 'validation/loss': 0.2846828067846089, 'validation/num_examples': 3554, 'test/ssim': 0.7438860533457833, 'test/loss': 0.28605096641781275, 'test/num_examples': 3581, 'score': 7731.246908187866, 'total_duration': 8126.714017152786, 'accumulated_submission_time': 7731.246908187866, 'accumulated_eval_time': 388.85573267936707, 'accumulated_logging_time': 5.225993633270264}
I0205 01:05:36.673987 139462596097792 logging_writer.py:48] [32767] accumulated_eval_time=388.855733, accumulated_logging_time=5.225994, accumulated_submission_time=7731.246908, global_step=32767, preemption_count=0, score=7731.246908, test/loss=0.286051, test/num_examples=3581, test/ssim=0.743886, total_duration=8126.714017, train/loss=0.264162, train/ssim=0.751423, validation/loss=0.284683, validation/num_examples=3554, validation/ssim=0.726770
I0205 01:05:42.576463 139462604490496 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.059453342109918594, loss=0.23218730092048645
I0205 01:06:06.553520 139462596097792 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.07840624451637268, loss=0.21365217864513397
I0205 01:06:30.299145 139462604490496 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.07116737961769104, loss=0.21387267112731934
I0205 01:06:54.144473 139462596097792 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.049601923674345016, loss=0.2341001182794571
I0205 01:06:56.667338 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:06:58.039575 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:06:59.359576 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:07:00.677713 139681449744192 submission_runner.py:408] Time since start: 8210.74s, 	Step: 33112, 	{'train/ssim': 0.7512646402631488, 'train/loss': 0.2643602745873587, 'validation/ssim': 0.7267347860685144, 'validation/loss': 0.2847045829742895, 'validation/num_examples': 3554, 'test/ssim': 0.743903847454447, 'test/loss': 0.2860263205546635, 'test/num_examples': 3581, 'score': 7811.2154541015625, 'total_duration': 8210.744921445847, 'accumulated_submission_time': 7811.2154541015625, 'accumulated_eval_time': 392.8660671710968, 'accumulated_logging_time': 5.263420820236206}
I0205 01:07:00.701120 139462604490496 logging_writer.py:48] [33112] accumulated_eval_time=392.866067, accumulated_logging_time=5.263421, accumulated_submission_time=7811.215454, global_step=33112, preemption_count=0, score=7811.215454, test/loss=0.286026, test/num_examples=3581, test/ssim=0.743904, total_duration=8210.744921, train/loss=0.264360, train/ssim=0.751265, validation/loss=0.284705, validation/num_examples=3554, validation/ssim=0.726735
I0205 01:07:19.667205 139462596097792 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.06729652732610703, loss=0.28849226236343384
I0205 01:07:43.277541 139462604490496 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.11081559211015701, loss=0.32164740562438965
I0205 01:08:06.974961 139462596097792 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.058062292635440826, loss=0.26383787393569946
I0205 01:08:20.788391 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:08:22.158771 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:08:23.479077 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:08:24.801579 139681449744192 submission_runner.py:408] Time since start: 8294.87s, 	Step: 33459, 	{'train/ssim': 0.7510176386151995, 'train/loss': 0.26437415395464214, 'validation/ssim': 0.7265887413389842, 'validation/loss': 0.2846880104009127, 'validation/num_examples': 3554, 'test/ssim': 0.7437773797472773, 'test/loss': 0.28598797118254327, 'test/num_examples': 3581, 'score': 7891.278911113739, 'total_duration': 8294.86878991127, 'accumulated_submission_time': 7891.278911113739, 'accumulated_eval_time': 396.87922167778015, 'accumulated_logging_time': 5.295862913131714}
I0205 01:08:24.825427 139462604490496 logging_writer.py:48] [33459] accumulated_eval_time=396.879222, accumulated_logging_time=5.295863, accumulated_submission_time=7891.278911, global_step=33459, preemption_count=0, score=7891.278911, test/loss=0.285988, test/num_examples=3581, test/ssim=0.743777, total_duration=8294.868790, train/loss=0.264374, train/ssim=0.751018, validation/loss=0.284688, validation/num_examples=3554, validation/ssim=0.726589
I0205 01:08:32.686537 139462596097792 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.05928545817732811, loss=0.22216598689556122
I0205 01:08:56.691892 139462604490496 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.05376746878027916, loss=0.29798761010169983
I0205 01:09:20.556868 139462596097792 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.08463442325592041, loss=0.24869638681411743
I0205 01:09:44.090087 139462604490496 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.06861097365617752, loss=0.23817044496536255
I0205 01:09:44.967347 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:09:46.334295 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:09:47.654113 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:09:48.971554 139681449744192 submission_runner.py:408] Time since start: 8379.04s, 	Step: 33805, 	{'train/ssim': 0.7513986315046038, 'train/loss': 0.26413989067077637, 'validation/ssim': 0.7267900165306697, 'validation/loss': 0.2846557926313221, 'validation/num_examples': 3554, 'test/ssim': 0.7439129149504329, 'test/loss': 0.2859865394726508, 'test/num_examples': 3581, 'score': 7971.397326469421, 'total_duration': 8379.038766145706, 'accumulated_submission_time': 7971.397326469421, 'accumulated_eval_time': 400.88340163230896, 'accumulated_logging_time': 5.328710556030273}
I0205 01:09:48.994859 139462596097792 logging_writer.py:48] [33805] accumulated_eval_time=400.883402, accumulated_logging_time=5.328711, accumulated_submission_time=7971.397326, global_step=33805, preemption_count=0, score=7971.397326, test/loss=0.285987, test/num_examples=3581, test/ssim=0.743913, total_duration=8379.038766, train/loss=0.264140, train/ssim=0.751399, validation/loss=0.284656, validation/num_examples=3554, validation/ssim=0.726790
I0205 01:10:09.568367 139462604490496 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.06838325411081314, loss=0.2857564687728882
I0205 01:10:33.520538 139462596097792 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.09506288915872574, loss=0.3970620036125183
I0205 01:10:57.384442 139462604490496 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.07973933964967728, loss=0.2169664353132248
I0205 01:11:09.192242 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:11:10.560641 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:11:11.879905 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:11:13.199204 139681449744192 submission_runner.py:408] Time since start: 8463.27s, 	Step: 34151, 	{'train/ssim': 0.7514948163713727, 'train/loss': 0.2642030886241368, 'validation/ssim': 0.7269228718961029, 'validation/loss': 0.2846536802722285, 'validation/num_examples': 3554, 'test/ssim': 0.7440828793676696, 'test/loss': 0.2859658137675405, 'test/num_examples': 3581, 'score': 8051.56923866272, 'total_duration': 8463.266416311264, 'accumulated_submission_time': 8051.56923866272, 'accumulated_eval_time': 404.8903458118439, 'accumulated_logging_time': 5.362544059753418}
I0205 01:11:13.223974 139462596097792 logging_writer.py:48] [34151] accumulated_eval_time=404.890346, accumulated_logging_time=5.362544, accumulated_submission_time=8051.569239, global_step=34151, preemption_count=0, score=8051.569239, test/loss=0.285966, test/num_examples=3581, test/ssim=0.744083, total_duration=8463.266416, train/loss=0.264203, train/ssim=0.751495, validation/loss=0.284654, validation/num_examples=3554, validation/ssim=0.726923
I0205 01:11:22.784860 139462604490496 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.0873771458864212, loss=0.3111245930194855
I0205 01:11:46.342037 139462596097792 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.06442911177873611, loss=0.23496846854686737
I0205 01:12:10.288716 139462604490496 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.094899021089077, loss=0.206533744931221
I0205 01:12:33.468944 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:12:34.839906 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:12:36.160235 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:12:37.479450 139681449744192 submission_runner.py:408] Time since start: 8547.55s, 	Step: 34497, 	{'train/ssim': 0.751321724482945, 'train/loss': 0.26423217569078716, 'validation/ssim': 0.7267886426385762, 'validation/loss': 0.28463619749533975, 'validation/num_examples': 3554, 'test/ssim': 0.7439314590023737, 'test/loss': 0.28594551416656483, 'test/num_examples': 3581, 'score': 8131.788681983948, 'total_duration': 8547.546661138535, 'accumulated_submission_time': 8131.788681983948, 'accumulated_eval_time': 408.90083360671997, 'accumulated_logging_time': 5.398136138916016}
I0205 01:12:37.502335 139462596097792 logging_writer.py:48] [34497] accumulated_eval_time=408.900834, accumulated_logging_time=5.398136, accumulated_submission_time=8131.788682, global_step=34497, preemption_count=0, score=8131.788682, test/loss=0.285946, test/num_examples=3581, test/ssim=0.743931, total_duration=8547.546661, train/loss=0.264232, train/ssim=0.751322, validation/loss=0.284636, validation/num_examples=3554, validation/ssim=0.726789
I0205 01:12:37.808970 139462604490496 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.06923999637365341, loss=0.23871579766273499
I0205 01:13:00.367465 139462596097792 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.06067657843232155, loss=0.2424585074186325
I0205 01:13:24.250047 139462604490496 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.2990567684173584, loss=0.34930354356765747
I0205 01:13:48.003282 139462596097792 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.06630801409482956, loss=0.31405404210090637
I0205 01:13:57.517125 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:13:58.886858 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:14:00.206387 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:14:01.526285 139681449744192 submission_runner.py:408] Time since start: 8631.59s, 	Step: 34841, 	{'train/ssim': 0.7512396403721401, 'train/loss': 0.26412343978881836, 'validation/ssim': 0.7266201347733188, 'validation/loss': 0.28458855778700054, 'validation/num_examples': 3554, 'test/ssim': 0.7437752662707693, 'test/loss': 0.2859060398795291, 'test/num_examples': 3581, 'score': 8211.779695034027, 'total_duration': 8631.593449831009, 'accumulated_submission_time': 8211.779695034027, 'accumulated_eval_time': 412.909912109375, 'accumulated_logging_time': 5.430059194564819}
I0205 01:14:01.552096 139462604490496 logging_writer.py:48] [34841] accumulated_eval_time=412.909912, accumulated_logging_time=5.430059, accumulated_submission_time=8211.779695, global_step=34841, preemption_count=0, score=8211.779695, test/loss=0.285906, test/num_examples=3581, test/ssim=0.743775, total_duration=8631.593450, train/loss=0.264123, train/ssim=0.751240, validation/loss=0.284589, validation/num_examples=3554, validation/ssim=0.726620
I0205 01:14:13.538647 139462596097792 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.0598701573908329, loss=0.1785615235567093
I0205 01:14:37.469197 139462604490496 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.05290938913822174, loss=0.24003756046295166
I0205 01:15:01.074920 139462596097792 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.09194636344909668, loss=0.22000014781951904
I0205 01:15:21.749876 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:15:23.118041 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:15:24.439253 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:15:25.758116 139681449744192 submission_runner.py:408] Time since start: 8715.83s, 	Step: 35188, 	{'train/ssim': 0.7515051705496651, 'train/loss': 0.2641071251460484, 'validation/ssim': 0.7268994470359103, 'validation/loss': 0.28458234092527784, 'validation/num_examples': 3554, 'test/ssim': 0.7440539724631737, 'test/loss': 0.2859155675679803, 'test/num_examples': 3581, 'score': 8291.951369524002, 'total_duration': 8715.825322628021, 'accumulated_submission_time': 8291.951369524002, 'accumulated_eval_time': 416.91813564300537, 'accumulated_logging_time': 5.4669647216796875}
I0205 01:15:25.782402 139462604490496 logging_writer.py:48] [35188] accumulated_eval_time=416.918136, accumulated_logging_time=5.466965, accumulated_submission_time=8291.951370, global_step=35188, preemption_count=0, score=8291.951370, test/loss=0.285916, test/num_examples=3581, test/ssim=0.744054, total_duration=8715.825323, train/loss=0.264107, train/ssim=0.751505, validation/loss=0.284582, validation/num_examples=3554, validation/ssim=0.726899
I0205 01:15:26.737260 139462596097792 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.057521332055330276, loss=0.21689602732658386
I0205 01:15:50.424945 139462604490496 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.07623595744371414, loss=0.2896127700805664
I0205 01:16:14.091477 139462596097792 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.06523493677377701, loss=0.24569916725158691
I0205 01:16:38.124125 139462604490496 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.04413355141878128, loss=0.3185371160507202
I0205 01:16:45.967564 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:16:47.335874 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:16:48.655799 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:16:49.977108 139681449744192 submission_runner.py:408] Time since start: 8800.04s, 	Step: 35534, 	{'train/ssim': 0.751544748033796, 'train/loss': 0.26413445813315256, 'validation/ssim': 0.7269539218574141, 'validation/loss': 0.28460197040856255, 'validation/num_examples': 3554, 'test/ssim': 0.7441068093758727, 'test/loss': 0.28592238523413505, 'test/num_examples': 3581, 'score': 8372.11243891716, 'total_duration': 8800.044318675995, 'accumulated_submission_time': 8372.11243891716, 'accumulated_eval_time': 420.9276645183563, 'accumulated_logging_time': 5.500535249710083}
I0205 01:16:50.000996 139462596097792 logging_writer.py:48] [35534] accumulated_eval_time=420.927665, accumulated_logging_time=5.500535, accumulated_submission_time=8372.112439, global_step=35534, preemption_count=0, score=8372.112439, test/loss=0.285922, test/num_examples=3581, test/ssim=0.744107, total_duration=8800.044319, train/loss=0.264134, train/ssim=0.751545, validation/loss=0.284602, validation/num_examples=3554, validation/ssim=0.726954
I0205 01:17:03.715230 139462604490496 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.0874389186501503, loss=0.2017413079738617
I0205 01:17:28.159209 139462596097792 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.06909921020269394, loss=0.20884771645069122
I0205 01:17:51.701181 139462604490496 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.11066646873950958, loss=0.23480291664600372
I0205 01:18:09.994857 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:18:11.365313 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:18:12.683237 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:18:14.001364 139681449744192 submission_runner.py:408] Time since start: 8884.07s, 	Step: 35877, 	{'train/ssim': 0.7513072150094169, 'train/loss': 0.2641035829271589, 'validation/ssim': 0.7267433728940982, 'validation/loss': 0.28454378607840636, 'validation/num_examples': 3554, 'test/ssim': 0.7439154374869101, 'test/loss': 0.28585257233271083, 'test/num_examples': 3581, 'score': 8452.082240343094, 'total_duration': 8884.068562984467, 'accumulated_submission_time': 8452.082240343094, 'accumulated_eval_time': 424.93412804603577, 'accumulated_logging_time': 5.533951044082642}
I0205 01:18:14.026518 139462596097792 logging_writer.py:48] [35877] accumulated_eval_time=424.934128, accumulated_logging_time=5.533951, accumulated_submission_time=8452.082240, global_step=35877, preemption_count=0, score=8452.082240, test/loss=0.285853, test/num_examples=3581, test/ssim=0.743915, total_duration=8884.068563, train/loss=0.264104, train/ssim=0.751307, validation/loss=0.284544, validation/num_examples=3554, validation/ssim=0.726743
I0205 01:18:17.480573 139462604490496 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.08718354254961014, loss=0.19019195437431335
I0205 01:18:41.548706 139462596097792 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.05159236118197441, loss=0.3017730712890625
I0205 01:19:05.216330 139462604490496 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.0666750892996788, loss=0.2442747950553894
I0205 01:19:25.905436 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:19:27.274193 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:19:28.595787 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:19:29.916882 139681449744192 submission_runner.py:408] Time since start: 8959.98s, 	Step: 36189, 	{'train/ssim': 0.7515296254839215, 'train/loss': 0.264105030468532, 'validation/ssim': 0.7269513801570414, 'validation/loss': 0.2845614921127603, 'validation/num_examples': 3554, 'test/ssim': 0.7441089228523806, 'test/loss': 0.285875275161006, 'test/num_examples': 3581, 'score': 8523.938553333282, 'total_duration': 8959.984071493149, 'accumulated_submission_time': 8523.938553333282, 'accumulated_eval_time': 428.94553327560425, 'accumulated_logging_time': 5.568581819534302}
I0205 01:19:29.940690 139462596097792 logging_writer.py:48] [36189] accumulated_eval_time=428.945533, accumulated_logging_time=5.568582, accumulated_submission_time=8523.938553, global_step=36189, preemption_count=0, score=8523.938553, test/loss=0.285875, test/num_examples=3581, test/ssim=0.744109, total_duration=8959.984071, train/loss=0.264105, train/ssim=0.751530, validation/loss=0.284561, validation/num_examples=3554, validation/ssim=0.726951
I0205 01:19:29.961792 139462604490496 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8523.938553
I0205 01:19:30.043179 139681449744192 checkpoints.py:490] Saving checkpoint at step: 36189
I0205 01:19:30.510610 139681449744192 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3/checkpoint_36189
I0205 01:19:30.511392 139681449744192 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_3/checkpoint_36189.
I0205 01:19:30.992585 139681449744192 submission_runner.py:583] Tuning trial 3/5
I0205 01:19:30.992862 139681449744192 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0205 01:19:31.001721 139681449744192 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 44.76288342475891, 'total_duration': 48.72807693481445, 'accumulated_submission_time': 44.76288342475891, 'accumulated_eval_time': 3.965081214904785, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (248, {'train/ssim': 0.6612253870282855, 'train/loss': 0.3414253166743687, 'validation/ssim': 0.637590141060249, 'validation/loss': 0.36103909245084764, 'validation/num_examples': 3554, 'test/ssim': 0.6574814068608629, 'test/loss': 0.36188959389617076, 'test/num_examples': 3581, 'score': 125.10523748397827, 'total_duration': 133.1096351146698, 'accumulated_submission_time': 125.10523748397827, 'accumulated_eval_time': 7.969703435897827, 'accumulated_logging_time': 0.02441096305847168, 'global_step': 248, 'preemption_count': 0}), (483, {'train/ssim': 0.6970335415431431, 'train/loss': 0.31379175186157227, 'validation/ssim': 0.674776522712085, 'validation/loss': 0.33258781368704277, 'validation/num_examples': 3554, 'test/ssim': 0.693326854732442, 'test/loss': 0.33407699299471166, 'test/num_examples': 3581, 'score': 205.28294610977173, 'total_duration': 217.33776664733887, 'accumulated_submission_time': 205.28294610977173, 'accumulated_eval_time': 11.9761803150177, 'accumulated_logging_time': 0.058553457260131836, 'global_step': 483, 'preemption_count': 0}), (715, {'train/ssim': 0.716080801827567, 'train/loss': 0.29663303920200895, 'validation/ssim': 0.6942070664216375, 'validation/loss': 0.31458817859278276, 'validation/num_examples': 3554, 'test/ssim': 0.7114660736569743, 'test/loss': 0.31690584857581683, 'test/num_examples': 3581, 'score': 285.4695768356323, 'total_duration': 301.5783360004425, 'accumulated_submission_time': 285.4695768356323, 'accumulated_eval_time': 15.985013246536255, 'accumulated_logging_time': 0.09372925758361816, 'global_step': 715, 'preemption_count': 0}), (1034, {'train/ssim': 0.7235066550118583, 'train/loss': 0.2870752811431885, 'validation/ssim': 0.7026445499349324, 'validation/loss': 0.30453200976232764, 'validation/num_examples': 3554, 'test/ssim': 0.7197285396231848, 'test/loss': 0.3066954731242146, 'test/num_examples': 3581, 'score': 365.43087816238403, 'total_duration': 385.58914399147034, 'accumulated_submission_time': 365.43087816238403, 'accumulated_eval_time': 19.990835666656494, 'accumulated_logging_time': 0.12387990951538086, 'global_step': 1034, 'preemption_count': 0}), (1381, {'train/ssim': 0.7308674539838519, 'train/loss': 0.27990336077553885, 'validation/ssim': 0.7087941596396665, 'validation/loss': 0.2979709537229178, 'validation/num_examples': 3554, 'test/ssim': 0.7259140717720259, 'test/loss': 0.29985247933974446, 'test/num_examples': 3581, 'score': 445.5725281238556, 'total_duration': 469.7762997150421, 'accumulated_submission_time': 445.5725281238556, 'accumulated_eval_time': 23.99786949157715, 'accumulated_logging_time': 0.14786100387573242, 'global_step': 1381, 'preemption_count': 0}), (1727, {'train/ssim': 0.7333673749651227, 'train/loss': 0.2783775159290859, 'validation/ssim': 0.7113109925655952, 'validation/loss': 0.2964568902886712, 'validation/num_examples': 3554, 'test/ssim': 0.7284042243350322, 'test/loss': 0.298256906841228, 'test/num_examples': 3581, 'score': 525.693502664566, 'total_duration': 553.9444513320923, 'accumulated_submission_time': 525.693502664566, 'accumulated_eval_time': 28.005931615829468, 'accumulated_logging_time': 0.17231059074401855, 'global_step': 1727, 'preemption_count': 0}), (2073, {'train/ssim': 0.7364885466439384, 'train/loss': 0.275574905531747, 'validation/ssim': 0.7148465664787915, 'validation/loss': 0.29355547061849324, 'validation/num_examples': 3554, 'test/ssim': 0.7319312075668458, 'test/loss': 0.29527090541879014, 'test/num_examples': 3581, 'score': 605.7808966636658, 'total_duration': 638.0774807929993, 'accumulated_submission_time': 605.7808966636658, 'accumulated_eval_time': 32.01269316673279, 'accumulated_logging_time': 0.19582176208496094, 'global_step': 2073, 'preemption_count': 0}), (2420, {'train/ssim': 0.7353577613830566, 'train/loss': 0.27537080219813753, 'validation/ssim': 0.7139438506788126, 'validation/loss': 0.2931602705578222, 'validation/num_examples': 3554, 'test/ssim': 0.7310254806181933, 'test/loss': 0.29491601180710697, 'test/num_examples': 3581, 'score': 685.8993790149689, 'total_duration': 722.2499129772186, 'accumulated_submission_time': 685.8993790149689, 'accumulated_eval_time': 36.02655911445618, 'accumulated_logging_time': 0.22134160995483398, 'global_step': 2420, 'preemption_count': 0}), (2765, {'train/ssim': 0.7376354762486049, 'train/loss': 0.2741092954363142, 'validation/ssim': 0.7155301464898706, 'validation/loss': 0.29229203944938803, 'validation/num_examples': 3554, 'test/ssim': 0.7326973768893117, 'test/loss': 0.2939401310737224, 'test/num_examples': 3581, 'score': 765.968150138855, 'total_duration': 806.3747057914734, 'accumulated_submission_time': 765.968150138855, 'accumulated_eval_time': 40.04101777076721, 'accumulated_logging_time': 0.2482287883758545, 'global_step': 2765, 'preemption_count': 0}), (3110, {'train/ssim': 0.7347473417009626, 'train/loss': 0.27508325236184256, 'validation/ssim': 0.7142884915104459, 'validation/loss': 0.2927851636690173, 'validation/num_examples': 3554, 'test/ssim': 0.7312285788929419, 'test/loss': 0.29438552920360933, 'test/num_examples': 3581, 'score': 846.0964727401733, 'total_duration': 890.5473172664642, 'accumulated_submission_time': 846.0964727401733, 'accumulated_eval_time': 44.046605587005615, 'accumulated_logging_time': 0.27246928215026855, 'global_step': 3110, 'preemption_count': 0}), (3458, {'train/ssim': 0.7395678247724261, 'train/loss': 0.2726844719478062, 'validation/ssim': 0.7174643117789814, 'validation/loss': 0.2909971118040412, 'validation/num_examples': 3554, 'test/ssim': 0.7346316851307246, 'test/loss': 0.29266008016484574, 'test/num_examples': 3581, 'score': 926.2872281074524, 'total_duration': 974.789454460144, 'accumulated_submission_time': 926.2872281074524, 'accumulated_eval_time': 48.05672740936279, 'accumulated_logging_time': 0.2985961437225342, 'global_step': 3458, 'preemption_count': 0}), (3793, {'train/ssim': 0.7412997654506138, 'train/loss': 0.27185327666146414, 'validation/ssim': 0.7187269186128307, 'validation/loss': 0.29030635320677406, 'validation/num_examples': 3554, 'test/ssim': 0.7358856584665596, 'test/loss': 0.29188521831803266, 'test/num_examples': 3581, 'score': 1003.8125767707825, 'total_duration': 1058.8378336429596, 'accumulated_submission_time': 1003.8125767707825, 'accumulated_eval_time': 52.06747007369995, 'accumulated_logging_time': 2.796729803085327, 'global_step': 3793, 'preemption_count': 0}), (4139, {'train/ssim': 0.7402080808367048, 'train/loss': 0.2731419290815081, 'validation/ssim': 0.7178762046285875, 'validation/loss': 0.29150270409441825, 'validation/num_examples': 3554, 'test/ssim': 0.7350120427254957, 'test/loss': 0.29316172404050894, 'test/num_examples': 3581, 'score': 1083.9166858196259, 'total_duration': 1142.9926023483276, 'accumulated_submission_time': 1083.9166858196259, 'accumulated_eval_time': 56.0785710811615, 'accumulated_logging_time': 2.8215391635894775, 'global_step': 4139, 'preemption_count': 0}), (4484, {'train/ssim': 0.7428110667637416, 'train/loss': 0.2710321971348354, 'validation/ssim': 0.71978186165676, 'validation/loss': 0.2897092597029755, 'validation/num_examples': 3554, 'test/ssim': 0.7369192848322745, 'test/loss': 0.29128751352624965, 'test/num_examples': 3581, 'score': 1164.0630095005035, 'total_duration': 1227.1880266666412, 'accumulated_submission_time': 1164.0630095005035, 'accumulated_eval_time': 60.08868336677551, 'accumulated_logging_time': 2.8460841178894043, 'global_step': 4484, 'preemption_count': 0}), (4831, {'train/ssim': 0.7431929452078683, 'train/loss': 0.27073839732578825, 'validation/ssim': 0.7205519281751196, 'validation/loss': 0.28930533542751125, 'validation/num_examples': 3554, 'test/ssim': 0.737703248263404, 'test/loss': 0.2908246621710067, 'test/num_examples': 3581, 'score': 1244.148692369461, 'total_duration': 1311.323415517807, 'accumulated_submission_time': 1244.148692369461, 'accumulated_eval_time': 64.09915161132812, 'accumulated_logging_time': 2.870636463165283, 'global_step': 4831, 'preemption_count': 0}), (5175, {'train/ssim': 0.7424209458487374, 'train/loss': 0.27047678402491976, 'validation/ssim': 0.7198196436893289, 'validation/loss': 0.2888622552273846, 'validation/num_examples': 3554, 'test/ssim': 0.7370804544601718, 'test/loss': 0.29030815578312624, 'test/num_examples': 3581, 'score': 1324.1467669010162, 'total_duration': 1395.3740241527557, 'accumulated_submission_time': 1324.1467669010162, 'accumulated_eval_time': 68.11032629013062, 'accumulated_logging_time': 2.897249937057495, 'global_step': 5175, 'preemption_count': 0}), (5517, {'train/ssim': 0.7446633747645787, 'train/loss': 0.27059595925467356, 'validation/ssim': 0.7215675779051772, 'validation/loss': 0.28925429533624086, 'validation/num_examples': 3554, 'test/ssim': 0.7387610773439681, 'test/loss': 0.29075000872661266, 'test/num_examples': 3581, 'score': 1404.2759974002838, 'total_duration': 1479.5537617206573, 'accumulated_submission_time': 1404.2759974002838, 'accumulated_eval_time': 72.12192797660828, 'accumulated_logging_time': 2.9218204021453857, 'global_step': 5517, 'preemption_count': 0}), (5863, {'train/ssim': 0.7418193135942731, 'train/loss': 0.27057336057935444, 'validation/ssim': 0.7196740111274268, 'validation/loss': 0.28884714241435705, 'validation/num_examples': 3554, 'test/ssim': 0.737032253560458, 'test/loss': 0.2902668407262287, 'test/num_examples': 3581, 'score': 1484.4351799488068, 'total_duration': 1563.7628009319305, 'accumulated_submission_time': 1484.4351799488068, 'accumulated_eval_time': 76.13256049156189, 'accumulated_logging_time': 2.946476936340332, 'global_step': 5863, 'preemption_count': 0}), (6210, {'train/ssim': 0.745011465890067, 'train/loss': 0.2705646753311157, 'validation/ssim': 0.7222998623909679, 'validation/loss': 0.28937413307408905, 'validation/num_examples': 3554, 'test/ssim': 0.7394353445266685, 'test/loss': 0.2908501261540945, 'test/num_examples': 3581, 'score': 1564.6058371067047, 'total_duration': 1647.987946987152, 'accumulated_submission_time': 1564.6058371067047, 'accumulated_eval_time': 80.14620423316956, 'accumulated_logging_time': 2.9725465774536133, 'global_step': 6210, 'preemption_count': 0}), (6553, {'train/ssim': 0.7449780872889927, 'train/loss': 0.2694678476878575, 'validation/ssim': 0.7216078329435144, 'validation/loss': 0.28847299725001757, 'validation/num_examples': 3554, 'test/ssim': 0.7388201865095294, 'test/loss': 0.28997773759293843, 'test/num_examples': 3581, 'score': 1644.8221879005432, 'total_duration': 1732.2529256343842, 'accumulated_submission_time': 1644.8221879005432, 'accumulated_eval_time': 84.1552243232727, 'accumulated_logging_time': 2.997762680053711, 'global_step': 6553, 'preemption_count': 0}), (6899, {'train/ssim': 0.7441498211451939, 'train/loss': 0.2704054968697684, 'validation/ssim': 0.722005643399163, 'validation/loss': 0.2887626823979143, 'validation/num_examples': 3554, 'test/ssim': 0.7392115887234711, 'test/loss': 0.29011344323774785, 'test/num_examples': 3581, 'score': 1724.981882095337, 'total_duration': 1816.4641880989075, 'accumulated_submission_time': 1724.981882095337, 'accumulated_eval_time': 88.16625618934631, 'accumulated_logging_time': 3.023563861846924, 'global_step': 6899, 'preemption_count': 0}), (7247, {'train/ssim': 0.7448177337646484, 'train/loss': 0.2693194661821638, 'validation/ssim': 0.7221843180659117, 'validation/loss': 0.28803211527724043, 'validation/num_examples': 3554, 'test/ssim': 0.7395222015934795, 'test/loss': 0.28933997901249653, 'test/num_examples': 3581, 'score': 1805.1859049797058, 'total_duration': 1900.717324256897, 'accumulated_submission_time': 1805.1859049797058, 'accumulated_eval_time': 92.17454433441162, 'accumulated_logging_time': 3.0495445728302, 'global_step': 7247, 'preemption_count': 0}), (7588, {'train/ssim': 0.7447967529296875, 'train/loss': 0.2691126380647932, 'validation/ssim': 0.7220263204751688, 'validation/loss': 0.28787920108724324, 'validation/num_examples': 3554, 'test/ssim': 0.7393584412524434, 'test/loss': 0.28932811627338734, 'test/num_examples': 3581, 'score': 1885.1832218170166, 'total_duration': 1984.7666964530945, 'accumulated_submission_time': 1885.1832218170166, 'accumulated_eval_time': 96.1854498386383, 'accumulated_logging_time': 3.076326608657837, 'global_step': 7588, 'preemption_count': 0}), (7934, {'train/ssim': 0.7456778798784528, 'train/loss': 0.2690371445247105, 'validation/ssim': 0.7227637570563098, 'validation/loss': 0.2876706442674627, 'validation/num_examples': 3554, 'test/ssim': 0.7399581231674114, 'test/loss': 0.28911158719631386, 'test/num_examples': 3581, 'score': 1965.3660056591034, 'total_duration': 2069.0000624656677, 'accumulated_submission_time': 1965.3660056591034, 'accumulated_eval_time': 100.19572973251343, 'accumulated_logging_time': 3.102079153060913, 'global_step': 7934, 'preemption_count': 0}), (8281, {'train/ssim': 0.745875358581543, 'train/loss': 0.26912626198359896, 'validation/ssim': 0.7229084278937464, 'validation/loss': 0.2879217230475345, 'validation/num_examples': 3554, 'test/ssim': 0.7401415865636345, 'test/loss': 0.2892600418768326, 'test/num_examples': 3581, 'score': 2045.4119424819946, 'total_duration': 2153.09862613678, 'accumulated_submission_time': 2045.4119424819946, 'accumulated_eval_time': 104.20498085021973, 'accumulated_logging_time': 3.1299993991851807, 'global_step': 8281, 'preemption_count': 0}), (8624, {'train/ssim': 0.7451011112758091, 'train/loss': 0.26903940950121197, 'validation/ssim': 0.7221248972328714, 'validation/loss': 0.28779779798070837, 'validation/num_examples': 3554, 'test/ssim': 0.739326602751501, 'test/loss': 0.2892616781167097, 'test/num_examples': 3581, 'score': 2125.377302646637, 'total_duration': 2237.1139464378357, 'accumulated_submission_time': 2125.377302646637, 'accumulated_eval_time': 108.21316409111023, 'accumulated_logging_time': 3.1573917865753174, 'global_step': 8624, 'preemption_count': 0}), (8969, {'train/ssim': 0.7463887759617397, 'train/loss': 0.2680323464529855, 'validation/ssim': 0.7232508018034257, 'validation/loss': 0.2870491298317037, 'validation/num_examples': 3554, 'test/ssim': 0.7405642136885646, 'test/loss': 0.2884087539924253, 'test/num_examples': 3581, 'score': 2205.461377620697, 'total_duration': 2321.250861644745, 'accumulated_submission_time': 2205.461377620697, 'accumulated_eval_time': 112.22468495368958, 'accumulated_logging_time': 3.184272289276123, 'global_step': 8969, 'preemption_count': 0}), (9314, {'train/ssim': 0.7459329877580915, 'train/loss': 0.26862949984414236, 'validation/ssim': 0.7227771525042206, 'validation/loss': 0.2875499993680096, 'validation/num_examples': 3554, 'test/ssim': 0.740029367778728, 'test/loss': 0.2889439066972389, 'test/num_examples': 3581, 'score': 2285.5357501506805, 'total_duration': 2405.378289461136, 'accumulated_submission_time': 2285.5357501506805, 'accumulated_eval_time': 116.23565125465393, 'accumulated_logging_time': 3.211730480194092, 'global_step': 9314, 'preemption_count': 0}), (9658, {'train/ssim': 0.746016229901995, 'train/loss': 0.26843258312770296, 'validation/ssim': 0.7231320288319499, 'validation/loss': 0.2871666834739466, 'validation/num_examples': 3554, 'test/ssim': 0.7404210426993159, 'test/loss': 0.28856876461707626, 'test/num_examples': 3581, 'score': 2365.571274280548, 'total_duration': 2489.4663603305817, 'accumulated_submission_time': 2365.571274280548, 'accumulated_eval_time': 120.24630069732666, 'accumulated_logging_time': 3.239140033721924, 'global_step': 9658, 'preemption_count': 0}), (10000, {'train/ssim': 0.7468297140938895, 'train/loss': 0.2678298609597342, 'validation/ssim': 0.7232698302089196, 'validation/loss': 0.2870614776868933, 'validation/num_examples': 3554, 'test/ssim': 0.7405252848148213, 'test/loss': 0.2884534437940694, 'test/num_examples': 3581, 'score': 2445.607465028763, 'total_duration': 2573.5549368858337, 'accumulated_submission_time': 2445.607465028763, 'accumulated_eval_time': 124.25722122192383, 'accumulated_logging_time': 3.26558256149292, 'global_step': 10000, 'preemption_count': 0}), (10347, {'train/ssim': 0.746333122253418, 'train/loss': 0.2679857185908726, 'validation/ssim': 0.7232405663073298, 'validation/loss': 0.28692891427352984, 'validation/num_examples': 3554, 'test/ssim': 0.7405346931941148, 'test/loss': 0.288304341435266, 'test/num_examples': 3581, 'score': 2525.7125160694122, 'total_duration': 2657.7135181427, 'accumulated_submission_time': 2525.7125160694122, 'accumulated_eval_time': 128.26841831207275, 'accumulated_logging_time': 3.2932775020599365, 'global_step': 10347, 'preemption_count': 0}), (10691, {'train/ssim': 0.7459057399204799, 'train/loss': 0.26831020627702984, 'validation/ssim': 0.7228599981974536, 'validation/loss': 0.2871290903515405, 'validation/num_examples': 3554, 'test/ssim': 0.7402006957291958, 'test/loss': 0.28850590573512985, 'test/num_examples': 3581, 'score': 2605.6890666484833, 'total_duration': 2741.7419786453247, 'accumulated_submission_time': 2605.6890666484833, 'accumulated_eval_time': 132.2769341468811, 'accumulated_logging_time': 3.3216447830200195, 'global_step': 10691, 'preemption_count': 0}), (11037, {'train/ssim': 0.7467265129089355, 'train/loss': 0.2679037196295602, 'validation/ssim': 0.7233592018895962, 'validation/loss': 0.2869203617952483, 'validation/num_examples': 3554, 'test/ssim': 0.7406535251151913, 'test/loss': 0.28831439749284415, 'test/num_examples': 3581, 'score': 2685.8272409439087, 'total_duration': 2825.9370296001434, 'accumulated_submission_time': 2685.8272409439087, 'accumulated_eval_time': 136.29143595695496, 'accumulated_logging_time': 3.349501371383667, 'global_step': 11037, 'preemption_count': 0}), (11383, {'train/ssim': 0.7467336654663086, 'train/loss': 0.2682475192206247, 'validation/ssim': 0.7235851384443585, 'validation/loss': 0.28736591500114306, 'validation/num_examples': 3554, 'test/ssim': 0.7408546462667551, 'test/loss': 0.28879033876710414, 'test/num_examples': 3581, 'score': 2765.9728231430054, 'total_duration': 2910.1348733901978, 'accumulated_submission_time': 2765.9728231430054, 'accumulated_eval_time': 140.30236983299255, 'accumulated_logging_time': 3.3763203620910645, 'global_step': 11383, 'preemption_count': 0}), (11728, {'train/ssim': 0.7459479059491839, 'train/loss': 0.26831463405064176, 'validation/ssim': 0.723168093499402, 'validation/loss': 0.2869273342976224, 'validation/num_examples': 3554, 'test/ssim': 0.7404165430396538, 'test/loss': 0.2882078714591769, 'test/num_examples': 3581, 'score': 2846.0457010269165, 'total_duration': 2994.259813785553, 'accumulated_submission_time': 2846.0457010269165, 'accumulated_eval_time': 144.31327152252197, 'accumulated_logging_time': 3.4031455516815186, 'global_step': 11728, 'preemption_count': 0}), (12072, {'train/ssim': 0.7469075066702706, 'train/loss': 0.2674442529678345, 'validation/ssim': 0.7234120967351927, 'validation/loss': 0.28661930769027855, 'validation/num_examples': 3554, 'test/ssim': 0.7406919085756423, 'test/loss': 0.2879914446470958, 'test/num_examples': 3581, 'score': 2926.0488336086273, 'total_duration': 3078.3154022693634, 'accumulated_submission_time': 2926.0488336086273, 'accumulated_eval_time': 148.32446479797363, 'accumulated_logging_time': 3.4299488067626953, 'global_step': 12072, 'preemption_count': 0}), (12417, {'train/ssim': 0.7473031452723912, 'train/loss': 0.2675682646887643, 'validation/ssim': 0.7239558832257668, 'validation/loss': 0.2866649896023846, 'validation/num_examples': 3554, 'test/ssim': 0.7412790459848855, 'test/loss': 0.28798155903117145, 'test/num_examples': 3581, 'score': 3006.178083181381, 'total_duration': 3162.5018265247345, 'accumulated_submission_time': 3006.178083181381, 'accumulated_eval_time': 152.33849143981934, 'accumulated_logging_time': 3.4584479331970215, 'global_step': 12417, 'preemption_count': 0}), (12762, {'train/ssim': 0.7473674501691546, 'train/loss': 0.2675473690032959, 'validation/ssim': 0.7242794348137662, 'validation/loss': 0.28640245599698405, 'validation/num_examples': 3554, 'test/ssim': 0.7415175279469771, 'test/loss': 0.2877508151201655, 'test/num_examples': 3581, 'score': 3086.1382641792297, 'total_duration': 3246.5176918506622, 'accumulated_submission_time': 3086.1382641792297, 'accumulated_eval_time': 156.35280227661133, 'accumulated_logging_time': 3.4851222038269043, 'global_step': 12762, 'preemption_count': 0}), (13105, {'train/ssim': 0.7421697889055524, 'train/loss': 0.2700824226651873, 'validation/ssim': 0.720902820215778, 'validation/loss': 0.28875687770381964, 'validation/num_examples': 3554, 'test/ssim': 0.7376949307106954, 'test/loss': 0.29021669679166084, 'test/num_examples': 3581, 'score': 3166.1795699596405, 'total_duration': 3330.6173605918884, 'accumulated_submission_time': 3166.1795699596405, 'accumulated_eval_time': 160.36889815330505, 'accumulated_logging_time': 3.513031244277954, 'global_step': 13105, 'preemption_count': 0}), (13452, {'train/ssim': 0.7474530764988491, 'train/loss': 0.26738267285483225, 'validation/ssim': 0.7240228604653207, 'validation/loss': 0.286526982141601, 'validation/num_examples': 3554, 'test/ssim': 0.7413308602476613, 'test/loss': 0.28779305056199384, 'test/num_examples': 3581, 'score': 3246.3344492912292, 'total_duration': 3414.818110704422, 'accumulated_submission_time': 3246.3344492912292, 'accumulated_eval_time': 164.37267231941223, 'accumulated_logging_time': 3.5402119159698486, 'global_step': 13452, 'preemption_count': 0}), (13798, {'train/ssim': 0.7462870052882603, 'train/loss': 0.268414991242545, 'validation/ssim': 0.7231948843952237, 'validation/loss': 0.28716149703129396, 'validation/num_examples': 3554, 'test/ssim': 0.7404483133639347, 'test/loss': 0.2885023605487294, 'test/num_examples': 3581, 'score': 3326.4810423851013, 'total_duration': 3499.016035795212, 'accumulated_submission_time': 3326.4810423851013, 'accumulated_eval_time': 168.38208889961243, 'accumulated_logging_time': 3.567617654800415, 'global_step': 13798, 'preemption_count': 0}), (14141, {'train/ssim': 0.7470973559788295, 'train/loss': 0.2679232358932495, 'validation/ssim': 0.7241787972179234, 'validation/loss': 0.2867153255739572, 'validation/num_examples': 3554, 'test/ssim': 0.7413019533431653, 'test/loss': 0.28809316422612397, 'test/num_examples': 3581, 'score': 3406.4493815898895, 'total_duration': 3583.039057970047, 'accumulated_submission_time': 3406.4493815898895, 'accumulated_eval_time': 172.3943543434143, 'accumulated_logging_time': 3.595734119415283, 'global_step': 14141, 'preemption_count': 0}), (14487, {'train/ssim': 0.7464298520769391, 'train/loss': 0.26779392787388395, 'validation/ssim': 0.7232238048237901, 'validation/loss': 0.286742957978686, 'validation/num_examples': 3554, 'test/ssim': 0.7403454347816601, 'test/loss': 0.2881711583269338, 'test/num_examples': 3581, 'score': 3486.5816123485565, 'total_duration': 3667.2226791381836, 'accumulated_submission_time': 3486.5816123485565, 'accumulated_eval_time': 176.40333008766174, 'accumulated_logging_time': 3.623152017593384, 'global_step': 14487, 'preemption_count': 0}), (14832, {'train/ssim': 0.7475502831595284, 'train/loss': 0.267444235937936, 'validation/ssim': 0.7244118780115715, 'validation/loss': 0.286362716168182, 'validation/num_examples': 3554, 'test/ssim': 0.7416326101516685, 'test/loss': 0.2877265442286547, 'test/num_examples': 3581, 'score': 3566.6675159931183, 'total_duration': 3751.3675639629364, 'accumulated_submission_time': 3566.6675159931183, 'accumulated_eval_time': 180.41909766197205, 'accumulated_logging_time': 3.6520910263061523, 'global_step': 14832, 'preemption_count': 0}), (15174, {'train/ssim': 0.7479367256164551, 'train/loss': 0.26788011619022917, 'validation/ssim': 0.7252343585132949, 'validation/loss': 0.2868504135140423, 'validation/num_examples': 3554, 'test/ssim': 0.742216406904496, 'test/loss': 0.28836334833583493, 'test/num_examples': 3581, 'score': 3646.8111073970795, 'total_duration': 3835.5609562397003, 'accumulated_submission_time': 3646.8111073970795, 'accumulated_eval_time': 184.4270977973938, 'accumulated_logging_time': 3.679409980773926, 'global_step': 15174, 'preemption_count': 0}), (15520, {'train/ssim': 0.7471392495291573, 'train/loss': 0.26722543580191477, 'validation/ssim': 0.7236271108478123, 'validation/loss': 0.28667081147013046, 'validation/num_examples': 3554, 'test/ssim': 0.7409330494275342, 'test/loss': 0.2879875585773876, 'test/num_examples': 3581, 'score': 3726.9752271175385, 'total_duration': 3919.774846792221, 'accumulated_submission_time': 3726.9752271175385, 'accumulated_eval_time': 188.43514847755432, 'accumulated_logging_time': 3.70670485496521, 'global_step': 15520, 'preemption_count': 0}), (15866, {'train/ssim': 0.748380184173584, 'train/loss': 0.26701310702732634, 'validation/ssim': 0.724918844194042, 'validation/loss': 0.2861659576467537, 'validation/num_examples': 3554, 'test/ssim': 0.7422716981770107, 'test/loss': 0.2874218968165317, 'test/num_examples': 3581, 'score': 3806.9768195152283, 'total_duration': 4003.8309524059296, 'accumulated_submission_time': 3806.9768195152283, 'accumulated_eval_time': 192.44737243652344, 'accumulated_logging_time': 3.734318971633911, 'global_step': 15866, 'preemption_count': 0}), (16209, {'train/ssim': 0.7478961263384137, 'train/loss': 0.2671475410461426, 'validation/ssim': 0.7246443405537775, 'validation/loss': 0.2861368311343732, 'validation/num_examples': 3554, 'test/ssim': 0.7419779931190659, 'test/loss': 0.28742220361150866, 'test/num_examples': 3581, 'score': 3886.973289012909, 'total_duration': 4087.8799300193787, 'accumulated_submission_time': 3886.973289012909, 'accumulated_eval_time': 196.4577419757843, 'accumulated_logging_time': 3.761636972427368, 'global_step': 16209, 'preemption_count': 0}), (16556, {'train/ssim': 0.748145307813372, 'train/loss': 0.2665354013442993, 'validation/ssim': 0.7245252241092783, 'validation/loss': 0.2858139321451182, 'validation/num_examples': 3554, 'test/ssim': 0.7418374128429559, 'test/loss': 0.2871162608428163, 'test/num_examples': 3581, 'score': 3967.0818524360657, 'total_duration': 4172.041687011719, 'accumulated_submission_time': 3967.0818524360657, 'accumulated_eval_time': 200.4681260585785, 'accumulated_logging_time': 3.789839267730713, 'global_step': 16556, 'preemption_count': 0}), (16903, {'train/ssim': 0.7478715351649693, 'train/loss': 0.2666094814028059, 'validation/ssim': 0.724559914884637, 'validation/loss': 0.2857410128222601, 'validation/num_examples': 3554, 'test/ssim': 0.7418483892854649, 'test/loss': 0.2870625035451864, 'test/num_examples': 3581, 'score': 4047.131493330002, 'total_duration': 4256.145545244217, 'accumulated_submission_time': 4047.131493330002, 'accumulated_eval_time': 204.47909569740295, 'accumulated_logging_time': 3.817901611328125, 'global_step': 16903, 'preemption_count': 0}), (17247, {'train/ssim': 0.7482375417436872, 'train/loss': 0.2673543861934117, 'validation/ssim': 0.7250987553636747, 'validation/loss': 0.2863902798783061, 'validation/num_examples': 3554, 'test/ssim': 0.7423234442631248, 'test/loss': 0.28769705782253563, 'test/num_examples': 3581, 'score': 4127.304555654526, 'total_duration': 4340.377782583237, 'accumulated_submission_time': 4127.304555654526, 'accumulated_eval_time': 208.49604630470276, 'accumulated_logging_time': 3.8455328941345215, 'global_step': 17247, 'preemption_count': 0}), (17592, {'train/ssim': 0.748047011239188, 'train/loss': 0.26669936520712717, 'validation/ssim': 0.7240940280757597, 'validation/loss': 0.2863386730565472, 'validation/num_examples': 3554, 'test/ssim': 0.7414175809611491, 'test/loss': 0.28763955080852066, 'test/num_examples': 3581, 'score': 4207.318914651871, 'total_duration': 4424.445866823196, 'accumulated_submission_time': 4207.318914651871, 'accumulated_eval_time': 212.5071542263031, 'accumulated_logging_time': 3.8736438751220703, 'global_step': 17592, 'preemption_count': 0}), (17937, {'train/ssim': 0.7487597465515137, 'train/loss': 0.2666618824005127, 'validation/ssim': 0.7253592453045864, 'validation/loss': 0.2859063950830051, 'validation/num_examples': 3554, 'test/ssim': 0.7426705998237224, 'test/loss': 0.28721017419409733, 'test/num_examples': 3581, 'score': 4287.361625432968, 'total_duration': 4508.540894031525, 'accumulated_submission_time': 4287.361625432968, 'accumulated_eval_time': 216.51686763763428, 'accumulated_logging_time': 3.9018309116363525, 'global_step': 17937, 'preemption_count': 0}), (18283, {'train/ssim': 0.7487377439226423, 'train/loss': 0.2666053431374686, 'validation/ssim': 0.7254902459156936, 'validation/loss': 0.2856880149347566, 'validation/num_examples': 3554, 'test/ssim': 0.7427411626684236, 'test/loss': 0.28693634263299356, 'test/num_examples': 3581, 'score': 4367.358929157257, 'total_duration': 4592.592378616333, 'accumulated_submission_time': 4367.358929157257, 'accumulated_eval_time': 220.5280795097351, 'accumulated_logging_time': 3.9302728176116943, 'global_step': 18283, 'preemption_count': 0}), (18626, {'train/ssim': 0.7493752070835659, 'train/loss': 0.2661102328981672, 'validation/ssim': 0.7254873607422974, 'validation/loss': 0.2856842539051509, 'validation/num_examples': 3554, 'test/ssim': 0.7427425262016546, 'test/loss': 0.2870357101171984, 'test/num_examples': 3581, 'score': 4447.448851585388, 'total_duration': 4676.735166788101, 'accumulated_submission_time': 4447.448851585388, 'accumulated_eval_time': 224.53717684745789, 'accumulated_logging_time': 3.9594712257385254, 'global_step': 18626, 'preemption_count': 0}), (18972, {'train/ssim': 0.7464577811104911, 'train/loss': 0.26762427602495464, 'validation/ssim': 0.7239104760920794, 'validation/loss': 0.2866407060596335, 'validation/num_examples': 3554, 'test/ssim': 0.7408810306347738, 'test/loss': 0.28806885924628245, 'test/num_examples': 3581, 'score': 4527.552319765091, 'total_duration': 4760.894608259201, 'accumulated_submission_time': 4527.552319765091, 'accumulated_eval_time': 228.54846930503845, 'accumulated_logging_time': 3.989834785461426, 'global_step': 18972, 'preemption_count': 0}), (19318, {'train/ssim': 0.7489397185189384, 'train/loss': 0.26674018587384907, 'validation/ssim': 0.7255840140510692, 'validation/loss': 0.2859350407331528, 'validation/num_examples': 3554, 'test/ssim': 0.7427173008368821, 'test/loss': 0.2872599090686959, 'test/num_examples': 3581, 'score': 4607.723635435104, 'total_duration': 4845.123031139374, 'accumulated_submission_time': 4607.723635435104, 'accumulated_eval_time': 232.56197333335876, 'accumulated_logging_time': 4.01876974105835, 'global_step': 19318, 'preemption_count': 0}), (19663, {'train/ssim': 0.7484968049185616, 'train/loss': 0.2659630945750645, 'validation/ssim': 0.7245838893016672, 'validation/loss': 0.2855817787286332, 'validation/num_examples': 3554, 'test/ssim': 0.7418566386615122, 'test/loss': 0.28688401704525623, 'test/num_examples': 3581, 'score': 4687.796002864838, 'total_duration': 4929.245357036591, 'accumulated_submission_time': 4687.796002864838, 'accumulated_eval_time': 236.56711435317993, 'accumulated_logging_time': 4.048708200454712, 'global_step': 19663, 'preemption_count': 0}), (20008, {'train/ssim': 0.7490484373910087, 'train/loss': 0.2663997071129935, 'validation/ssim': 0.725382051913337, 'validation/loss': 0.2857362041999332, 'validation/num_examples': 3554, 'test/ssim': 0.7426997794348645, 'test/loss': 0.28695106879188775, 'test/num_examples': 3581, 'score': 4767.805709838867, 'total_duration': 5013.3049693107605, 'accumulated_submission_time': 4767.805709838867, 'accumulated_eval_time': 240.57340145111084, 'accumulated_logging_time': 4.0773022174835205, 'global_step': 20008, 'preemption_count': 0}), (20354, {'train/ssim': 0.7480840001787458, 'train/loss': 0.26671031543186735, 'validation/ssim': 0.7245500228615644, 'validation/loss': 0.2860161518876178, 'validation/num_examples': 3554, 'test/ssim': 0.7417742812543633, 'test/loss': 0.2873005082706472, 'test/num_examples': 3581, 'score': 4847.913654327393, 'total_duration': 5097.467324256897, 'accumulated_submission_time': 4847.913654327393, 'accumulated_eval_time': 244.5843369960785, 'accumulated_logging_time': 4.106105089187622, 'global_step': 20354, 'preemption_count': 0}), (20697, {'train/ssim': 0.7485865865434919, 'train/loss': 0.26616430282592773, 'validation/ssim': 0.7251484215628518, 'validation/loss': 0.28558687930303006, 'validation/num_examples': 3554, 'test/ssim': 0.742291810292167, 'test/loss': 0.28693893334613235, 'test/num_examples': 3581, 'score': 4927.873211860657, 'total_duration': 5181.477455615997, 'accumulated_submission_time': 4927.873211860657, 'accumulated_eval_time': 248.59125542640686, 'accumulated_logging_time': 4.135280132293701, 'global_step': 20697, 'preemption_count': 0}), (21042, {'train/ssim': 0.7484387670244489, 'train/loss': 0.2663168055670602, 'validation/ssim': 0.7248215039392234, 'validation/loss': 0.285725024153023, 'validation/num_examples': 3554, 'test/ssim': 0.742089802844003, 'test/loss': 0.28709587602101366, 'test/num_examples': 3581, 'score': 5007.937152862549, 'total_duration': 5265.59605717659, 'accumulated_submission_time': 5007.937152862549, 'accumulated_eval_time': 252.60098385810852, 'accumulated_logging_time': 4.1652820110321045, 'global_step': 21042, 'preemption_count': 0}), (21388, {'train/ssim': 0.7481115886143276, 'train/loss': 0.2667201246534075, 'validation/ssim': 0.7249347126477209, 'validation/loss': 0.2858996458380962, 'validation/num_examples': 3554, 'test/ssim': 0.7421052107695127, 'test/loss': 0.2872167873302674, 'test/num_examples': 3581, 'score': 5088.057301521301, 'total_duration': 5349.772326469421, 'accumulated_submission_time': 5088.057301521301, 'accumulated_eval_time': 256.6096124649048, 'accumulated_logging_time': 4.198110818862915, 'global_step': 21388, 'preemption_count': 0}), (21732, {'train/ssim': 0.7490191459655762, 'train/loss': 0.2662261894771031, 'validation/ssim': 0.7253119834165729, 'validation/loss': 0.2857492218275183, 'validation/num_examples': 3554, 'test/ssim': 0.7425255198879503, 'test/loss': 0.2870578334438704, 'test/num_examples': 3581, 'score': 5168.070353746414, 'total_duration': 5433.842468261719, 'accumulated_submission_time': 5168.070353746414, 'accumulated_eval_time': 260.62133407592773, 'accumulated_logging_time': 4.228944778442383, 'global_step': 21732, 'preemption_count': 0}), (22079, {'train/ssim': 0.749504634312221, 'train/loss': 0.265928966658456, 'validation/ssim': 0.7256125223120076, 'validation/loss': 0.28558181307593555, 'validation/num_examples': 3554, 'test/ssim': 0.7428523588034068, 'test/loss': 0.2868992204407812, 'test/num_examples': 3581, 'score': 5248.222505569458, 'total_duration': 5518.048063755035, 'accumulated_submission_time': 5248.222505569458, 'accumulated_eval_time': 264.62954115867615, 'accumulated_logging_time': 4.259636402130127, 'global_step': 22079, 'preemption_count': 0}), (22423, {'train/ssim': 0.749286447252546, 'train/loss': 0.26605565207345144, 'validation/ssim': 0.7258175757069499, 'validation/loss': 0.28542900192784537, 'validation/num_examples': 3554, 'test/ssim': 0.7429833943469003, 'test/loss': 0.2867292901118752, 'test/num_examples': 3581, 'score': 5328.270455598831, 'total_duration': 5602.152354717255, 'accumulated_submission_time': 5328.270455598831, 'accumulated_eval_time': 268.64070224761963, 'accumulated_logging_time': 4.2899558544158936, 'global_step': 22423, 'preemption_count': 0}), (22767, {'train/ssim': 0.7490869930812291, 'train/loss': 0.2664235830307007, 'validation/ssim': 0.725718861560038, 'validation/loss': 0.2856929265989906, 'validation/num_examples': 3554, 'test/ssim': 0.7428747207483943, 'test/loss': 0.2871282258469178, 'test/num_examples': 3581, 'score': 5408.337042331696, 'total_duration': 5686.270875692368, 'accumulated_submission_time': 5408.337042331696, 'accumulated_eval_time': 272.6491093635559, 'accumulated_logging_time': 4.319113254547119, 'global_step': 22767, 'preemption_count': 0}), (23111, {'train/ssim': 0.7498129435947963, 'train/loss': 0.26553709166390554, 'validation/ssim': 0.7259281053258653, 'validation/loss': 0.285219534904553, 'validation/num_examples': 3554, 'test/ssim': 0.743165426033231, 'test/loss': 0.2865338276232198, 'test/num_examples': 3581, 'score': 5488.437965869904, 'total_duration': 5770.424674987793, 'accumulated_submission_time': 5488.437965869904, 'accumulated_eval_time': 276.6583559513092, 'accumulated_logging_time': 4.348245620727539, 'global_step': 23111, 'preemption_count': 0}), (23459, {'train/ssim': 0.7490844045366559, 'train/loss': 0.2656686987195696, 'validation/ssim': 0.7254319241963281, 'validation/loss': 0.28513127951120215, 'validation/num_examples': 3554, 'test/ssim': 0.742678781023108, 'test/loss': 0.2864100188058503, 'test/num_examples': 3581, 'score': 5568.480888128281, 'total_duration': 5854.519265413284, 'accumulated_submission_time': 5568.480888128281, 'accumulated_eval_time': 280.66591787338257, 'accumulated_logging_time': 4.377592325210571, 'global_step': 23459, 'preemption_count': 0}), (23804, {'train/ssim': 0.7493758201599121, 'train/loss': 0.26564463547297884, 'validation/ssim': 0.7255900591762803, 'validation/loss': 0.28517653208202903, 'validation/num_examples': 3554, 'test/ssim': 0.7428889014939961, 'test/loss': 0.2864074621810423, 'test/num_examples': 3581, 'score': 5648.613835811615, 'total_duration': 5938.706800699234, 'accumulated_submission_time': 5648.613835811615, 'accumulated_eval_time': 284.6766347885132, 'accumulated_logging_time': 4.406728506088257, 'global_step': 23804, 'preemption_count': 0}), (24148, {'train/ssim': 0.7498668261936733, 'train/loss': 0.2651958976473127, 'validation/ssim': 0.7257230519309229, 'validation/loss': 0.28512276138022297, 'validation/num_examples': 3554, 'test/ssim': 0.7429643048816671, 'test/loss': 0.2864313581009145, 'test/num_examples': 3581, 'score': 5728.598200559616, 'total_duration': 6022.743552207947, 'accumulated_submission_time': 5728.598200559616, 'accumulated_eval_time': 288.6837303638458, 'accumulated_logging_time': 4.437592029571533, 'global_step': 24148, 'preemption_count': 0}), (24494, {'train/ssim': 0.7496851512363979, 'train/loss': 0.2655548027583531, 'validation/ssim': 0.7258203921857415, 'validation/loss': 0.28521201284534153, 'validation/num_examples': 3554, 'test/ssim': 0.7430404582126152, 'test/loss': 0.28653703192631247, 'test/num_examples': 3581, 'score': 5808.61803650856, 'total_duration': 6106.814738750458, 'accumulated_submission_time': 5808.61803650856, 'accumulated_eval_time': 292.6920075416565, 'accumulated_logging_time': 4.466193199157715, 'global_step': 24494, 'preemption_count': 0}), (24838, {'train/ssim': 0.748795781816755, 'train/loss': 0.2659956046513149, 'validation/ssim': 0.7251729455367192, 'validation/loss': 0.2854291908380082, 'validation/num_examples': 3554, 'test/ssim': 0.7424380492311854, 'test/loss': 0.2867215520607896, 'test/num_examples': 3581, 'score': 5888.6937420368195, 'total_duration': 6190.94571518898, 'accumulated_submission_time': 5888.6937420368195, 'accumulated_eval_time': 296.69993567466736, 'accumulated_logging_time': 4.499108552932739, 'global_step': 24838, 'preemption_count': 0}), (25185, {'train/ssim': 0.7506846700395856, 'train/loss': 0.26508048602512907, 'validation/ssim': 0.7263689872986424, 'validation/loss': 0.2851709162980972, 'validation/num_examples': 3554, 'test/ssim': 0.7436003249572396, 'test/loss': 0.2864891037332449, 'test/num_examples': 3581, 'score': 5968.84553027153, 'total_duration': 6275.150093793869, 'accumulated_submission_time': 5968.84553027153, 'accumulated_eval_time': 300.70812129974365, 'accumulated_logging_time': 4.529009819030762, 'global_step': 25185, 'preemption_count': 0}), (25531, {'train/ssim': 0.7494222096034459, 'train/loss': 0.26529708930424284, 'validation/ssim': 0.7254723853184791, 'validation/loss': 0.28499687851716377, 'validation/num_examples': 3554, 'test/ssim': 0.742812748163048, 'test/loss': 0.28627891508569536, 'test/num_examples': 3581, 'score': 6048.872050285339, 'total_duration': 6359.229727506638, 'accumulated_submission_time': 6048.872050285339, 'accumulated_eval_time': 304.7168712615967, 'accumulated_logging_time': 4.558919191360474, 'global_step': 25531, 'preemption_count': 0}), (25876, {'train/ssim': 0.7495801789419991, 'train/loss': 0.2653527430125645, 'validation/ssim': 0.7257883804999649, 'validation/loss': 0.2849699502321328, 'validation/num_examples': 3554, 'test/ssim': 0.7430234140472284, 'test/loss': 0.2862819148588034, 'test/num_examples': 3581, 'score': 6128.933758020401, 'total_duration': 6443.341115951538, 'accumulated_submission_time': 6128.933758020401, 'accumulated_eval_time': 308.72206234931946, 'accumulated_logging_time': 4.588968515396118, 'global_step': 25876, 'preemption_count': 0}), (26222, {'train/ssim': 0.7504499980381557, 'train/loss': 0.26486739090510775, 'validation/ssim': 0.7260060737021665, 'validation/loss': 0.2850825063418859, 'validation/num_examples': 3554, 'test/ssim': 0.74321253610636, 'test/loss': 0.2864005763382261, 'test/num_examples': 3581, 'score': 6209.109485387802, 'total_duration': 6527.5736310482025, 'accumulated_submission_time': 6209.109485387802, 'accumulated_eval_time': 312.73252749443054, 'accumulated_logging_time': 4.620581388473511, 'global_step': 26222, 'preemption_count': 0}), (26568, {'train/ssim': 0.7503705705915179, 'train/loss': 0.2652456249509539, 'validation/ssim': 0.7262834625158272, 'validation/loss': 0.2850904405687254, 'validation/num_examples': 3554, 'test/ssim': 0.7435167403701829, 'test/loss': 0.2864089279792656, 'test/num_examples': 3581, 'score': 6289.2570996284485, 'total_duration': 6611.773455381393, 'accumulated_submission_time': 6289.2570996284485, 'accumulated_eval_time': 316.73898911476135, 'accumulated_logging_time': 4.651438236236572, 'global_step': 26568, 'preemption_count': 0}), (26915, {'train/ssim': 0.7497830390930176, 'train/loss': 0.2651932580130441, 'validation/ssim': 0.7259059856631612, 'validation/loss': 0.28487460212084975, 'validation/num_examples': 3554, 'test/ssim': 0.7430864774591595, 'test/loss': 0.28618026345643677, 'test/num_examples': 3581, 'score': 6369.344420433044, 'total_duration': 6695.914905786514, 'accumulated_submission_time': 6369.344420433044, 'accumulated_eval_time': 320.7466149330139, 'accumulated_logging_time': 4.683363676071167, 'global_step': 26915, 'preemption_count': 0}), (27255, {'train/ssim': 0.7505489758082798, 'train/loss': 0.2648061513900757, 'validation/ssim': 0.7262866224676421, 'validation/loss': 0.2849321338522615, 'validation/num_examples': 3554, 'test/ssim': 0.7434242928171251, 'test/loss': 0.2862984136108978, 'test/num_examples': 3581, 'score': 6449.312697172165, 'total_duration': 6779.940864801407, 'accumulated_submission_time': 6449.312697172165, 'accumulated_eval_time': 324.75905179977417, 'accumulated_logging_time': 4.714396953582764, 'global_step': 27255, 'preemption_count': 0}), (27600, {'train/ssim': 0.750410965510777, 'train/loss': 0.2649491514478411, 'validation/ssim': 0.7263029030889491, 'validation/loss': 0.2848861943353879, 'validation/num_examples': 3554, 'test/ssim': 0.74350603663432, 'test/loss': 0.28616468508927323, 'test/num_examples': 3581, 'score': 6529.513382673264, 'total_duration': 6864.195533752441, 'accumulated_submission_time': 6529.513382673264, 'accumulated_eval_time': 328.7665092945099, 'accumulated_logging_time': 4.74639892578125, 'global_step': 27600, 'preemption_count': 0}), (27946, {'train/ssim': 0.7503207751682827, 'train/loss': 0.26509937218257357, 'validation/ssim': 0.7263553170723129, 'validation/loss': 0.28493158429542415, 'validation/num_examples': 3554, 'test/ssim': 0.7435222626797682, 'test/loss': 0.28622890750445057, 'test/num_examples': 3581, 'score': 6609.545207738876, 'total_duration': 6948.283418178558, 'accumulated_submission_time': 6609.545207738876, 'accumulated_eval_time': 332.77544808387756, 'accumulated_logging_time': 4.7788896560668945, 'global_step': 27946, 'preemption_count': 0}), (28290, {'train/ssim': 0.7504880087716239, 'train/loss': 0.26482350485665457, 'validation/ssim': 0.7263116273037422, 'validation/loss': 0.28491015157876687, 'validation/num_examples': 3554, 'test/ssim': 0.7434201340407708, 'test/loss': 0.2862642571034627, 'test/num_examples': 3581, 'score': 6689.76785159111, 'total_duration': 7032.563189744949, 'accumulated_submission_time': 6689.76785159111, 'accumulated_eval_time': 336.7862060070038, 'accumulated_logging_time': 4.811024188995361, 'global_step': 28290, 'preemption_count': 0}), (28637, {'train/ssim': 0.7506187983921596, 'train/loss': 0.26490603174482075, 'validation/ssim': 0.7264817151449071, 'validation/loss': 0.2849294547626794, 'validation/num_examples': 3554, 'test/ssim': 0.7436845231342503, 'test/loss': 0.2862636776018396, 'test/num_examples': 3581, 'score': 6769.840493440628, 'total_duration': 7116.692368984222, 'accumulated_submission_time': 6769.840493440628, 'accumulated_eval_time': 340.79823088645935, 'accumulated_logging_time': 4.841078758239746, 'global_step': 28637, 'preemption_count': 0}), (28982, {'train/ssim': 0.7507256780351911, 'train/loss': 0.26495700223105295, 'validation/ssim': 0.7265615382755346, 'validation/loss': 0.2849720625912264, 'validation/num_examples': 3554, 'test/ssim': 0.7437460866596272, 'test/loss': 0.28625147397942263, 'test/num_examples': 3581, 'score': 6849.891664505005, 'total_duration': 7200.7956709861755, 'accumulated_submission_time': 6849.891664505005, 'accumulated_eval_time': 344.80379843711853, 'accumulated_logging_time': 4.873269319534302, 'global_step': 28982, 'preemption_count': 0}), (29323, {'train/ssim': 0.750253541128976, 'train/loss': 0.26486986024039133, 'validation/ssim': 0.7261388603729952, 'validation/loss': 0.28492605437974816, 'validation/num_examples': 3554, 'test/ssim': 0.7433762282707345, 'test/loss': 0.28626599560833216, 'test/num_examples': 3581, 'score': 6929.979115247726, 'total_duration': 7284.941651105881, 'accumulated_submission_time': 6929.979115247726, 'accumulated_eval_time': 348.8160009384155, 'accumulated_logging_time': 4.905006408691406, 'global_step': 29323, 'preemption_count': 0}), (29668, {'train/ssim': 0.7505779947553363, 'train/loss': 0.264641353062221, 'validation/ssim': 0.7261684677476083, 'validation/loss': 0.2848554878471001, 'validation/num_examples': 3554, 'test/ssim': 0.7433797734571349, 'test/loss': 0.2861837404661757, 'test/num_examples': 3581, 'score': 7010.161997318268, 'total_duration': 7369.177745580673, 'accumulated_submission_time': 7010.161997318268, 'accumulated_eval_time': 352.8241741657257, 'accumulated_logging_time': 4.9356300830841064, 'global_step': 29668, 'preemption_count': 0}), (30014, {'train/ssim': 0.7503046308244977, 'train/loss': 0.2647990328924997, 'validation/ssim': 0.7261086347469401, 'validation/loss': 0.28482297812543966, 'validation/num_examples': 3554, 'test/ssim': 0.7432790083513683, 'test/loss': 0.2861041101254887, 'test/num_examples': 3581, 'score': 7090.252366781235, 'total_duration': 7453.321771860123, 'accumulated_submission_time': 7090.252366781235, 'accumulated_eval_time': 356.831734418869, 'accumulated_logging_time': 4.967212677001953, 'global_step': 30014, 'preemption_count': 0}), (30357, {'train/ssim': 0.7509540830339704, 'train/loss': 0.2650235380445208, 'validation/ssim': 0.7267261992429305, 'validation/loss': 0.2851525576649989, 'validation/num_examples': 3554, 'test/ssim': 0.7438623960442264, 'test/loss': 0.2865039321571314, 'test/num_examples': 3581, 'score': 7170.308975458145, 'total_duration': 7537.433724164963, 'accumulated_submission_time': 7170.308975458145, 'accumulated_eval_time': 360.8413755893707, 'accumulated_logging_time': 4.998633146286011, 'global_step': 30357, 'preemption_count': 0}), (30701, {'train/ssim': 0.7509610312325614, 'train/loss': 0.264449988092695, 'validation/ssim': 0.7264982705446328, 'validation/loss': 0.2848017686662475, 'validation/num_examples': 3554, 'test/ssim': 0.7436667972022479, 'test/loss': 0.2861409255227241, 'test/num_examples': 3581, 'score': 7250.800181627274, 'total_duration': 7621.926305532455, 'accumulated_submission_time': 7250.800181627274, 'accumulated_eval_time': 364.797967672348, 'accumulated_logging_time': 5.029951572418213, 'global_step': 30701, 'preemption_count': 0}), (31047, {'train/ssim': 0.7511175700596401, 'train/loss': 0.2646209682737078, 'validation/ssim': 0.7267902226144837, 'validation/loss': 0.28479922696587473, 'validation/num_examples': 3554, 'test/ssim': 0.7439442762147445, 'test/loss': 0.28610168985400375, 'test/num_examples': 3581, 'score': 7330.806107759476, 'total_duration': 7705.99044585228, 'accumulated_submission_time': 7330.806107759476, 'accumulated_eval_time': 368.80754828453064, 'accumulated_logging_time': 5.063923120498657, 'global_step': 31047, 'preemption_count': 0}), (31390, {'train/ssim': 0.7512401853288923, 'train/loss': 0.2646078722817557, 'validation/ssim': 0.7270120374929657, 'validation/loss': 0.28474507844374297, 'validation/num_examples': 3554, 'test/ssim': 0.7441750542140813, 'test/loss': 0.28603988771031136, 'test/num_examples': 3581, 'score': 7410.819982767105, 'total_duration': 7790.061582565308, 'accumulated_submission_time': 7410.819982767105, 'accumulated_eval_time': 372.81839632987976, 'accumulated_logging_time': 5.095531225204468, 'global_step': 31390, 'preemption_count': 0}), (31735, {'train/ssim': 0.7512694086347308, 'train/loss': 0.2642558813095093, 'validation/ssim': 0.7266450709148143, 'validation/loss': 0.28473525511527503, 'validation/num_examples': 3554, 'test/ssim': 0.7438293303633762, 'test/loss': 0.28604738714308153, 'test/num_examples': 3581, 'score': 7490.946867465973, 'total_duration': 7874.244492769241, 'accumulated_submission_time': 7490.946867465973, 'accumulated_eval_time': 376.82525968551636, 'accumulated_logging_time': 5.130434513092041, 'global_step': 31735, 'preemption_count': 0}), (32079, {'train/ssim': 0.7509448868887765, 'train/loss': 0.2644948278154646, 'validation/ssim': 0.7264786238876969, 'validation/loss': 0.2848054438275974, 'validation/num_examples': 3554, 'test/ssim': 0.743691477153728, 'test/loss': 0.28611232541320514, 'test/num_examples': 3581, 'score': 7571.110435009003, 'total_duration': 7958.465414047241, 'accumulated_submission_time': 7571.110435009003, 'accumulated_eval_time': 380.8364975452423, 'accumulated_logging_time': 5.161880731582642, 'global_step': 32079, 'preemption_count': 0}), (32422, {'train/ssim': 0.7511148452758789, 'train/loss': 0.2644805908203125, 'validation/ssim': 0.7268427739870569, 'validation/loss': 0.2846810378985386, 'validation/num_examples': 3554, 'test/ssim': 0.7440023627303826, 'test/loss': 0.28598595997102766, 'test/num_examples': 3581, 'score': 7651.189124345779, 'total_duration': 8042.596368312836, 'accumulated_submission_time': 7651.189124345779, 'accumulated_eval_time': 384.84243869781494, 'accumulated_logging_time': 5.193868160247803, 'global_step': 32422, 'preemption_count': 0}), (32767, {'train/ssim': 0.7514227458408901, 'train/loss': 0.2641618422099522, 'validation/ssim': 0.7267701637899198, 'validation/loss': 0.2846828067846089, 'validation/num_examples': 3554, 'test/ssim': 0.7438860533457833, 'test/loss': 0.28605096641781275, 'test/num_examples': 3581, 'score': 7731.246908187866, 'total_duration': 8126.714017152786, 'accumulated_submission_time': 7731.246908187866, 'accumulated_eval_time': 388.85573267936707, 'accumulated_logging_time': 5.225993633270264, 'global_step': 32767, 'preemption_count': 0}), (33112, {'train/ssim': 0.7512646402631488, 'train/loss': 0.2643602745873587, 'validation/ssim': 0.7267347860685144, 'validation/loss': 0.2847045829742895, 'validation/num_examples': 3554, 'test/ssim': 0.743903847454447, 'test/loss': 0.2860263205546635, 'test/num_examples': 3581, 'score': 7811.2154541015625, 'total_duration': 8210.744921445847, 'accumulated_submission_time': 7811.2154541015625, 'accumulated_eval_time': 392.8660671710968, 'accumulated_logging_time': 5.263420820236206, 'global_step': 33112, 'preemption_count': 0}), (33459, {'train/ssim': 0.7510176386151995, 'train/loss': 0.26437415395464214, 'validation/ssim': 0.7265887413389842, 'validation/loss': 0.2846880104009127, 'validation/num_examples': 3554, 'test/ssim': 0.7437773797472773, 'test/loss': 0.28598797118254327, 'test/num_examples': 3581, 'score': 7891.278911113739, 'total_duration': 8294.86878991127, 'accumulated_submission_time': 7891.278911113739, 'accumulated_eval_time': 396.87922167778015, 'accumulated_logging_time': 5.295862913131714, 'global_step': 33459, 'preemption_count': 0}), (33805, {'train/ssim': 0.7513986315046038, 'train/loss': 0.26413989067077637, 'validation/ssim': 0.7267900165306697, 'validation/loss': 0.2846557926313221, 'validation/num_examples': 3554, 'test/ssim': 0.7439129149504329, 'test/loss': 0.2859865394726508, 'test/num_examples': 3581, 'score': 7971.397326469421, 'total_duration': 8379.038766145706, 'accumulated_submission_time': 7971.397326469421, 'accumulated_eval_time': 400.88340163230896, 'accumulated_logging_time': 5.328710556030273, 'global_step': 33805, 'preemption_count': 0}), (34151, {'train/ssim': 0.7514948163713727, 'train/loss': 0.2642030886241368, 'validation/ssim': 0.7269228718961029, 'validation/loss': 0.2846536802722285, 'validation/num_examples': 3554, 'test/ssim': 0.7440828793676696, 'test/loss': 0.2859658137675405, 'test/num_examples': 3581, 'score': 8051.56923866272, 'total_duration': 8463.266416311264, 'accumulated_submission_time': 8051.56923866272, 'accumulated_eval_time': 404.8903458118439, 'accumulated_logging_time': 5.362544059753418, 'global_step': 34151, 'preemption_count': 0}), (34497, {'train/ssim': 0.751321724482945, 'train/loss': 0.26423217569078716, 'validation/ssim': 0.7267886426385762, 'validation/loss': 0.28463619749533975, 'validation/num_examples': 3554, 'test/ssim': 0.7439314590023737, 'test/loss': 0.28594551416656483, 'test/num_examples': 3581, 'score': 8131.788681983948, 'total_duration': 8547.546661138535, 'accumulated_submission_time': 8131.788681983948, 'accumulated_eval_time': 408.90083360671997, 'accumulated_logging_time': 5.398136138916016, 'global_step': 34497, 'preemption_count': 0}), (34841, {'train/ssim': 0.7512396403721401, 'train/loss': 0.26412343978881836, 'validation/ssim': 0.7266201347733188, 'validation/loss': 0.28458855778700054, 'validation/num_examples': 3554, 'test/ssim': 0.7437752662707693, 'test/loss': 0.2859060398795291, 'test/num_examples': 3581, 'score': 8211.779695034027, 'total_duration': 8631.593449831009, 'accumulated_submission_time': 8211.779695034027, 'accumulated_eval_time': 412.909912109375, 'accumulated_logging_time': 5.430059194564819, 'global_step': 34841, 'preemption_count': 0}), (35188, {'train/ssim': 0.7515051705496651, 'train/loss': 0.2641071251460484, 'validation/ssim': 0.7268994470359103, 'validation/loss': 0.28458234092527784, 'validation/num_examples': 3554, 'test/ssim': 0.7440539724631737, 'test/loss': 0.2859155675679803, 'test/num_examples': 3581, 'score': 8291.951369524002, 'total_duration': 8715.825322628021, 'accumulated_submission_time': 8291.951369524002, 'accumulated_eval_time': 416.91813564300537, 'accumulated_logging_time': 5.4669647216796875, 'global_step': 35188, 'preemption_count': 0}), (35534, {'train/ssim': 0.751544748033796, 'train/loss': 0.26413445813315256, 'validation/ssim': 0.7269539218574141, 'validation/loss': 0.28460197040856255, 'validation/num_examples': 3554, 'test/ssim': 0.7441068093758727, 'test/loss': 0.28592238523413505, 'test/num_examples': 3581, 'score': 8372.11243891716, 'total_duration': 8800.044318675995, 'accumulated_submission_time': 8372.11243891716, 'accumulated_eval_time': 420.9276645183563, 'accumulated_logging_time': 5.500535249710083, 'global_step': 35534, 'preemption_count': 0}), (35877, {'train/ssim': 0.7513072150094169, 'train/loss': 0.2641035829271589, 'validation/ssim': 0.7267433728940982, 'validation/loss': 0.28454378607840636, 'validation/num_examples': 3554, 'test/ssim': 0.7439154374869101, 'test/loss': 0.28585257233271083, 'test/num_examples': 3581, 'score': 8452.082240343094, 'total_duration': 8884.068562984467, 'accumulated_submission_time': 8452.082240343094, 'accumulated_eval_time': 424.93412804603577, 'accumulated_logging_time': 5.533951044082642, 'global_step': 35877, 'preemption_count': 0}), (36189, {'train/ssim': 0.7515296254839215, 'train/loss': 0.264105030468532, 'validation/ssim': 0.7269513801570414, 'validation/loss': 0.2845614921127603, 'validation/num_examples': 3554, 'test/ssim': 0.7441089228523806, 'test/loss': 0.285875275161006, 'test/num_examples': 3581, 'score': 8523.938553333282, 'total_duration': 8959.984071493149, 'accumulated_submission_time': 8523.938553333282, 'accumulated_eval_time': 428.94553327560425, 'accumulated_logging_time': 5.568581819534302, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0205 01:19:31.001958 139681449744192 submission_runner.py:586] Timing: 8523.938553333282
I0205 01:19:31.002017 139681449744192 submission_runner.py:588] Total number of evals: 107
I0205 01:19:31.002078 139681449744192 submission_runner.py:589] ====================
I0205 01:19:31.002153 139681449744192 submission_runner.py:542] Using RNG seed 813120851
I0205 01:19:31.003941 139681449744192 submission_runner.py:551] --- Tuning run 4/5 ---
I0205 01:19:31.004076 139681449744192 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4.
I0205 01:19:31.004346 139681449744192 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4/hparams.json.
I0205 01:19:31.005323 139681449744192 submission_runner.py:206] Initializing dataset.
I0205 01:19:31.353969 139681449744192 submission_runner.py:213] Initializing model.
I0205 01:19:33.562266 139681449744192 submission_runner.py:255] Initializing optimizer.
I0205 01:19:33.630826 139681449744192 submission_runner.py:262] Initializing metrics bundle.
I0205 01:19:33.630965 139681449744192 submission_runner.py:280] Initializing checkpoint and logger.
I0205 01:19:33.631577 139681449744192 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4 with prefix checkpoint_
I0205 01:19:33.631692 139681449744192 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4/meta_data_0.json.
I0205 01:19:33.631897 139681449744192 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0205 01:19:33.631960 139681449744192 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0205 01:19:38.536669 139681449744192 logger_utils.py:220] Unable to record git information. Continuing without it.
I0205 01:19:43.356495 139681449744192 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4/flags_0.json.
I0205 01:19:43.360034 139681449744192 submission_runner.py:314] Starting training loop.
I0205 01:20:14.756125 139462604490496 logging_writer.py:48] [0] global_step=0, grad_norm=5.605435371398926, loss=1.0139427185058594
I0205 01:20:14.761707 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:20:16.085459 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:20:17.401922 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:20:18.719074 139681449744192 submission_runner.py:408] Time since start: 35.36s, 	Step: 1, 	{'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 31.401532649993896, 'total_duration': 35.358983516693115, 'accumulated_submission_time': 31.401532649993896, 'accumulated_eval_time': 3.9573137760162354, 'accumulated_logging_time': 0}
I0205 01:20:18.728046 139462612883200 logging_writer.py:48] [1] accumulated_eval_time=3.957314, accumulated_logging_time=0, accumulated_submission_time=31.401533, global_step=1, preemption_count=0, score=31.401533, test/loss=1.032399, test/num_examples=3581, test/ssim=0.212846, total_duration=35.358984, train/loss=1.032718, train/ssim=0.197546, validation/loss=1.037087, validation/num_examples=3554, validation/ssim=0.189760
I0205 01:20:40.520850 139462604490496 logging_writer.py:48] [100] global_step=100, grad_norm=0.6652691960334778, loss=0.35165002942085266
I0205 01:21:04.816935 139462612883200 logging_writer.py:48] [200] global_step=200, grad_norm=0.13961152732372284, loss=0.3081410825252533
I0205 01:21:29.029738 139462604490496 logging_writer.py:48] [300] global_step=300, grad_norm=0.2843542993068695, loss=0.3059499263763428
I0205 01:21:38.949854 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:21:40.319089 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:21:41.636271 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:21:42.957546 139681449744192 submission_runner.py:408] Time since start: 119.60s, 	Step: 342, 	{'train/ssim': 0.7213667460850307, 'train/loss': 0.29259068625313894, 'validation/ssim': 0.7017441697515123, 'validation/loss': 0.31035226318496767, 'validation/num_examples': 3554, 'test/ssim': 0.7183853912140463, 'test/loss': 0.31235365879598925, 'test/num_examples': 3581, 'score': 111.60064959526062, 'total_duration': 119.59745144844055, 'accumulated_submission_time': 111.60064959526062, 'accumulated_eval_time': 7.96499228477478, 'accumulated_logging_time': 0.017967939376831055}
I0205 01:21:42.972609 139462612883200 logging_writer.py:48] [342] accumulated_eval_time=7.964992, accumulated_logging_time=0.017968, accumulated_submission_time=111.600650, global_step=342, preemption_count=0, score=111.600650, test/loss=0.312354, test/num_examples=3581, test/ssim=0.718385, total_duration=119.597451, train/loss=0.292591, train/ssim=0.721367, validation/loss=0.310352, validation/num_examples=3554, validation/ssim=0.701744
I0205 01:21:54.926394 139462604490496 logging_writer.py:48] [400] global_step=400, grad_norm=0.3344835340976715, loss=0.33655044436454773
I0205 01:22:19.277832 139462612883200 logging_writer.py:48] [500] global_step=500, grad_norm=0.1469956338405609, loss=0.22371850907802582
I0205 01:22:43.599279 139462604490496 logging_writer.py:48] [600] global_step=600, grad_norm=0.19604122638702393, loss=0.3449440002441406
I0205 01:23:02.975312 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:23:04.345036 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:23:05.665188 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:23:06.985009 139681449744192 submission_runner.py:408] Time since start: 203.62s, 	Step: 682, 	{'train/ssim': 0.7287031582423619, 'train/loss': 0.28311089106968473, 'validation/ssim': 0.7073842715734032, 'validation/loss': 0.3006681786807119, 'validation/num_examples': 3554, 'test/ssim': 0.7247404105434935, 'test/loss': 0.30215337349029603, 'test/num_examples': 3581, 'score': 191.57904171943665, 'total_duration': 203.62491083145142, 'accumulated_submission_time': 191.57904171943665, 'accumulated_eval_time': 11.974652290344238, 'accumulated_logging_time': 0.044046878814697266}
I0205 01:23:07.001412 139462612883200 logging_writer.py:48] [682] accumulated_eval_time=11.974652, accumulated_logging_time=0.044047, accumulated_submission_time=191.579042, global_step=682, preemption_count=0, score=191.579042, test/loss=0.302153, test/num_examples=3581, test/ssim=0.724740, total_duration=203.624911, train/loss=0.283111, train/ssim=0.728703, validation/loss=0.300668, validation/num_examples=3554, validation/ssim=0.707384
I0205 01:23:09.230313 139462604490496 logging_writer.py:48] [700] global_step=700, grad_norm=0.28474366664886475, loss=0.3072062134742737
I0205 01:23:33.510817 139462612883200 logging_writer.py:48] [800] global_step=800, grad_norm=0.1713360846042633, loss=0.24193109571933746
I0205 01:23:57.939090 139462604490496 logging_writer.py:48] [900] global_step=900, grad_norm=0.06763552874326706, loss=0.3121720850467682
I0205 01:24:22.756173 139462612883200 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.34074532985687256, loss=0.2539518177509308
I0205 01:24:26.985342 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:24:28.355848 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:24:29.678972 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:24:30.997542 139681449744192 submission_runner.py:408] Time since start: 287.64s, 	Step: 1019, 	{'train/ssim': 0.7273684910365513, 'train/loss': 0.28053527218954905, 'validation/ssim': 0.7060646482176772, 'validation/loss': 0.29812266575733326, 'validation/num_examples': 3554, 'test/ssim': 0.7234966637068906, 'test/loss': 0.29965684640943524, 'test/num_examples': 3581, 'score': 271.53961205482483, 'total_duration': 287.6374468803406, 'accumulated_submission_time': 271.53961205482483, 'accumulated_eval_time': 15.98682451248169, 'accumulated_logging_time': 0.07003068923950195}
I0205 01:24:31.013218 139462604490496 logging_writer.py:48] [1019] accumulated_eval_time=15.986825, accumulated_logging_time=0.070031, accumulated_submission_time=271.539612, global_step=1019, preemption_count=0, score=271.539612, test/loss=0.299657, test/num_examples=3581, test/ssim=0.723497, total_duration=287.637447, train/loss=0.280535, train/ssim=0.727368, validation/loss=0.298123, validation/num_examples=3554, validation/ssim=0.706065
I0205 01:24:48.426389 139462612883200 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.1788298338651657, loss=0.26258784532546997
I0205 01:25:12.205609 139462604490496 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.32052329182624817, loss=0.2531164586544037
I0205 01:25:35.829195 139462612883200 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.23575550317764282, loss=0.35968896746635437
I0205 01:25:51.233289 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:25:52.602325 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:25:53.924094 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:25:55.244177 139681449744192 submission_runner.py:408] Time since start: 371.88s, 	Step: 1366, 	{'train/ssim': 0.7377146993364606, 'train/loss': 0.27565182958330425, 'validation/ssim': 0.715898143487092, 'validation/loss': 0.2935038809703855, 'validation/num_examples': 3554, 'test/ssim': 0.7332023614213907, 'test/loss': 0.29500624361866445, 'test/num_examples': 3581, 'score': 351.7352349758148, 'total_duration': 371.88407588005066, 'accumulated_submission_time': 351.7352349758148, 'accumulated_eval_time': 19.99767827987671, 'accumulated_logging_time': 0.09582114219665527}
I0205 01:25:55.259503 139462604490496 logging_writer.py:48] [1366] accumulated_eval_time=19.997678, accumulated_logging_time=0.095821, accumulated_submission_time=351.735235, global_step=1366, preemption_count=0, score=351.735235, test/loss=0.295006, test/num_examples=3581, test/ssim=0.733202, total_duration=371.884076, train/loss=0.275652, train/ssim=0.737715, validation/loss=0.293504, validation/num_examples=3554, validation/ssim=0.715898
I0205 01:26:01.379563 139462612883200 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.28831928968429565, loss=0.2700134515762329
I0205 01:26:25.407462 139462604490496 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.21421173214912415, loss=0.33364203572273254
I0205 01:26:49.441752 139462612883200 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.08708703517913818, loss=0.19108019769191742
I0205 01:27:13.208012 139462604490496 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.22225281596183777, loss=0.3361724317073822
I0205 01:27:15.287513 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:27:16.657706 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:27:17.979084 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:27:19.296747 139681449744192 submission_runner.py:408] Time since start: 455.94s, 	Step: 1710, 	{'train/ssim': 0.7396605355398995, 'train/loss': 0.2755191666739328, 'validation/ssim': 0.7181294816360088, 'validation/loss': 0.29322625172560846, 'validation/num_examples': 3554, 'test/ssim': 0.7352617738367425, 'test/loss': 0.2947562738891022, 'test/num_examples': 3581, 'score': 431.7387228012085, 'total_duration': 455.9366509914398, 'accumulated_submission_time': 431.7387228012085, 'accumulated_eval_time': 24.006880521774292, 'accumulated_logging_time': 0.1219170093536377}
I0205 01:27:19.311918 139462612883200 logging_writer.py:48] [1710] accumulated_eval_time=24.006881, accumulated_logging_time=0.121917, accumulated_submission_time=431.738723, global_step=1710, preemption_count=0, score=431.738723, test/loss=0.294756, test/num_examples=3581, test/ssim=0.735262, total_duration=455.936651, train/loss=0.275519, train/ssim=0.739661, validation/loss=0.293226, validation/num_examples=3554, validation/ssim=0.718129
I0205 01:27:38.846045 139462604490496 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.09719012677669525, loss=0.27510809898376465
I0205 01:28:02.750492 139462612883200 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.1846243292093277, loss=0.21706043183803558
I0205 01:28:26.653340 139462604490496 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.07877083867788315, loss=0.33444252610206604
I0205 01:28:39.490099 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:28:40.863486 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:28:42.184284 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:28:43.504364 139681449744192 submission_runner.py:408] Time since start: 540.14s, 	Step: 2054, 	{'train/ssim': 0.736421925680978, 'train/loss': 0.2752586773463658, 'validation/ssim': 0.7134809177379361, 'validation/loss': 0.2937887574959553, 'validation/num_examples': 3554, 'test/ssim': 0.73088387769216, 'test/loss': 0.29537160234789517, 'test/num_examples': 3581, 'score': 511.8938019275665, 'total_duration': 540.144252538681, 'accumulated_submission_time': 511.8938019275665, 'accumulated_eval_time': 28.021103382110596, 'accumulated_logging_time': 0.14649391174316406}
I0205 01:28:43.519462 139462612883200 logging_writer.py:48] [2054] accumulated_eval_time=28.021103, accumulated_logging_time=0.146494, accumulated_submission_time=511.893802, global_step=2054, preemption_count=0, score=511.893802, test/loss=0.295372, test/num_examples=3581, test/ssim=0.730884, total_duration=540.144253, train/loss=0.275259, train/ssim=0.736422, validation/loss=0.293789, validation/num_examples=3554, validation/ssim=0.713481
I0205 01:28:52.372269 139462604490496 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.338675856590271, loss=0.2922588884830475
I0205 01:29:16.069546 139462612883200 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.29248154163360596, loss=0.28158050775527954
I0205 01:29:39.883695 139462604490496 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.202259361743927, loss=0.2233092337846756
I0205 01:30:03.539042 139462612883200 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.31177395582199097, loss=0.2862909138202667
I0205 01:30:03.545341 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:30:04.863263 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:30:06.185917 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:30:07.506777 139681449744192 submission_runner.py:408] Time since start: 624.15s, 	Step: 2401, 	{'train/ssim': 0.7367238317217145, 'train/loss': 0.2788510152271816, 'validation/ssim': 0.7148442308622327, 'validation/loss': 0.29763015978914603, 'validation/num_examples': 3554, 'test/ssim': 0.7316117317308364, 'test/loss': 0.2993610619633133, 'test/num_examples': 3581, 'score': 591.8965113162994, 'total_duration': 624.146678686142, 'accumulated_submission_time': 591.8965113162994, 'accumulated_eval_time': 31.982479333877563, 'accumulated_logging_time': 0.17116355895996094}
I0205 01:30:07.521443 139462604490496 logging_writer.py:48] [2401] accumulated_eval_time=31.982479, accumulated_logging_time=0.171164, accumulated_submission_time=591.896511, global_step=2401, preemption_count=0, score=591.896511, test/loss=0.299361, test/num_examples=3581, test/ssim=0.731612, total_duration=624.146679, train/loss=0.278851, train/ssim=0.736724, validation/loss=0.297630, validation/num_examples=3554, validation/ssim=0.714844
I0205 01:30:29.003986 139462612883200 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.09072321653366089, loss=0.2563115358352661
I0205 01:30:52.746469 139462604490496 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.09069383144378662, loss=0.2528142035007477
I0205 01:31:16.496045 139462612883200 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.11911583691835403, loss=0.2943660318851471
I0205 01:31:27.568795 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:31:28.941382 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:31:30.262649 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:31:31.583396 139681449744192 submission_runner.py:408] Time since start: 708.22s, 	Step: 2748, 	{'train/ssim': 0.7392657143729073, 'train/loss': 0.2730081421988351, 'validation/ssim': 0.7169806330674944, 'validation/loss': 0.29130486363296637, 'validation/num_examples': 3554, 'test/ssim': 0.7344828554785674, 'test/loss': 0.2926768857119171, 'test/num_examples': 3581, 'score': 671.9206922054291, 'total_duration': 708.2232940196991, 'accumulated_submission_time': 671.9206922054291, 'accumulated_eval_time': 35.997042179107666, 'accumulated_logging_time': 0.19508838653564453}
I0205 01:31:31.597929 139462604490496 logging_writer.py:48] [2748] accumulated_eval_time=35.997042, accumulated_logging_time=0.195088, accumulated_submission_time=671.920692, global_step=2748, preemption_count=0, score=671.920692, test/loss=0.292677, test/num_examples=3581, test/ssim=0.734483, total_duration=708.223294, train/loss=0.273008, train/ssim=0.739266, validation/loss=0.291305, validation/num_examples=3554, validation/ssim=0.716981
I0205 01:31:41.814134 139462612883200 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.17434996366500854, loss=0.3524504005908966
I0205 01:32:05.702379 139462604490496 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.14203065633773804, loss=0.22692829370498657
I0205 01:32:29.284688 139462612883200 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.14188072085380554, loss=0.2610463500022888
I0205 01:32:51.674013 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:32:53.046045 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:32:54.366750 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:32:55.691931 139681449744192 submission_runner.py:408] Time since start: 792.33s, 	Step: 3094, 	{'train/ssim': 0.7426317759922573, 'train/loss': 0.2729813711983817, 'validation/ssim': 0.7201212130038337, 'validation/loss': 0.29116208189715814, 'validation/num_examples': 3554, 'test/ssim': 0.7372292159356674, 'test/loss': 0.29278593428206157, 'test/num_examples': 3581, 'score': 751.973610162735, 'total_duration': 792.3318250179291, 'accumulated_submission_time': 751.973610162735, 'accumulated_eval_time': 40.014914989471436, 'accumulated_logging_time': 0.21890044212341309}
I0205 01:32:55.707047 139462604490496 logging_writer.py:48] [3094] accumulated_eval_time=40.014915, accumulated_logging_time=0.218900, accumulated_submission_time=751.973610, global_step=3094, preemption_count=0, score=751.973610, test/loss=0.292786, test/num_examples=3581, test/ssim=0.737229, total_duration=792.331825, train/loss=0.272981, train/ssim=0.742632, validation/loss=0.291162, validation/num_examples=3554, validation/ssim=0.720121
I0205 01:32:56.232176 139462612883200 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.10389619320631027, loss=0.23858359456062317
I0205 01:33:18.812704 139462604490496 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.08094020932912827, loss=0.27363669872283936
I0205 01:33:42.765145 139462612883200 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10368769615888596, loss=0.30712252855300903
I0205 01:34:06.524448 139462604490496 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.24584563076496124, loss=0.3810093104839325
I0205 01:34:15.876709 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:34:17.247994 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:34:18.570413 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:34:19.889686 139681449744192 submission_runner.py:408] Time since start: 876.53s, 	Step: 3441, 	{'train/ssim': 0.742382322038923, 'train/loss': 0.2722130332674299, 'validation/ssim': 0.7201152365732274, 'validation/loss': 0.2907499142691334, 'validation/num_examples': 3554, 'test/ssim': 0.7372187167297891, 'test/loss': 0.2922184317513439, 'test/num_examples': 3581, 'score': 832.1201596260071, 'total_duration': 876.5295839309692, 'accumulated_submission_time': 832.1201596260071, 'accumulated_eval_time': 44.0278480052948, 'accumulated_logging_time': 0.2433154582977295}
I0205 01:34:19.905111 139462612883200 logging_writer.py:48] [3441] accumulated_eval_time=44.027848, accumulated_logging_time=0.243315, accumulated_submission_time=832.120160, global_step=3441, preemption_count=0, score=832.120160, test/loss=0.292218, test/num_examples=3581, test/ssim=0.737219, total_duration=876.529584, train/loss=0.272213, train/ssim=0.742382, validation/loss=0.290750, validation/num_examples=3554, validation/ssim=0.720115
I0205 01:34:31.744369 139462604490496 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.1669582575559616, loss=0.3254162073135376
I0205 01:34:55.734104 139462612883200 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.10189230740070343, loss=0.2889026701450348
I0205 01:35:19.609861 139462604490496 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.08464919775724411, loss=0.22602300345897675
I0205 01:35:40.039077 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:35:41.412492 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:35:42.733120 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:35:44.053369 139681449744192 submission_runner.py:408] Time since start: 960.69s, 	Step: 3788, 	{'train/ssim': 0.7390454837254116, 'train/loss': 0.27307660239083426, 'validation/ssim': 0.7167553147641742, 'validation/loss': 0.2911471751679446, 'validation/num_examples': 3554, 'test/ssim': 0.734154175793249, 'test/loss': 0.2925956532196837, 'test/num_examples': 3581, 'score': 912.2310099601746, 'total_duration': 960.6932737827301, 'accumulated_submission_time': 912.2310099601746, 'accumulated_eval_time': 48.04212021827698, 'accumulated_logging_time': 0.2679710388183594}
I0205 01:35:44.068916 139462612883200 logging_writer.py:48] [3788] accumulated_eval_time=48.042120, accumulated_logging_time=0.267971, accumulated_submission_time=912.231010, global_step=3788, preemption_count=0, score=912.231010, test/loss=0.292596, test/num_examples=3581, test/ssim=0.734154, total_duration=960.693274, train/loss=0.273077, train/ssim=0.739045, validation/loss=0.291147, validation/num_examples=3554, validation/ssim=0.716755
I0205 01:35:45.028675 139462604490496 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.08598888665437698, loss=0.2563287019729614
I0205 01:36:08.717869 139462612883200 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.12191042304039001, loss=0.2803518772125244
I0205 01:36:32.470132 139462604490496 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.22934553027153015, loss=0.22565390169620514
I0205 01:36:56.091223 139462612883200 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.12672528624534607, loss=0.293251097202301
I0205 01:37:04.219958 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:37:05.592496 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:37:06.914884 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:37:08.234726 139681449744192 submission_runner.py:408] Time since start: 1044.87s, 	Step: 4135, 	{'train/ssim': 0.7394935062953404, 'train/loss': 0.2732838732855661, 'validation/ssim': 0.7192164363657146, 'validation/loss': 0.2911408552643149, 'validation/num_examples': 3554, 'test/ssim': 0.7359224056871335, 'test/loss': 0.2926088454036931, 'test/num_examples': 3581, 'score': 992.3586266040802, 'total_duration': 1044.8746247291565, 'accumulated_submission_time': 992.3586266040802, 'accumulated_eval_time': 52.056846380233765, 'accumulated_logging_time': 0.29309511184692383}
I0205 01:37:08.250546 139462604490496 logging_writer.py:48] [4135] accumulated_eval_time=52.056846, accumulated_logging_time=0.293095, accumulated_submission_time=992.358627, global_step=4135, preemption_count=0, score=992.358627, test/loss=0.292609, test/num_examples=3581, test/ssim=0.735922, total_duration=1044.874625, train/loss=0.273284, train/ssim=0.739494, validation/loss=0.291141, validation/num_examples=3554, validation/ssim=0.719216
I0205 01:37:22.055866 139462612883200 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.18100853264331818, loss=0.2381349802017212
I0205 01:37:45.652876 139462604490496 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.2705788314342499, loss=0.3231983482837677
I0205 01:38:09.614855 139462612883200 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.16126179695129395, loss=0.25921931862831116
I0205 01:38:28.283063 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:38:29.655037 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:38:30.975621 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:38:32.292774 139681449744192 submission_runner.py:408] Time since start: 1128.93s, 	Step: 4480, 	{'train/ssim': 0.7384296144757952, 'train/loss': 0.2730314220700945, 'validation/ssim': 0.7167116249956036, 'validation/loss': 0.2914937394485087, 'validation/num_examples': 3554, 'test/ssim': 0.7337420478741972, 'test/loss': 0.29308267320144515, 'test/num_examples': 3581, 'score': 1072.3675737380981, 'total_duration': 1128.9326810836792, 'accumulated_submission_time': 1072.3675737380981, 'accumulated_eval_time': 56.066534996032715, 'accumulated_logging_time': 0.318572998046875}
I0205 01:38:32.308490 139462604490496 logging_writer.py:48] [4480] accumulated_eval_time=56.066535, accumulated_logging_time=0.318573, accumulated_submission_time=1072.367574, global_step=4480, preemption_count=0, score=1072.367574, test/loss=0.293083, test/num_examples=3581, test/ssim=0.733742, total_duration=1128.932681, train/loss=0.273031, train/ssim=0.738430, validation/loss=0.291494, validation/num_examples=3554, validation/ssim=0.716712
I0205 01:38:35.055840 139462612883200 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1608680784702301, loss=0.2665024399757385
I0205 01:38:58.908882 139462604490496 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.07054326683282852, loss=0.23437587916851044
I0205 01:39:22.715969 139462612883200 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1202957034111023, loss=0.2562912404537201
I0205 01:39:46.545379 139462604490496 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.1296696960926056, loss=0.2669937014579773
I0205 01:39:52.323461 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:39:53.695127 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:39:55.014748 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:39:56.335970 139681449744192 submission_runner.py:408] Time since start: 1212.98s, 	Step: 4826, 	{'train/ssim': 0.7417031696864537, 'train/loss': 0.2724244935171945, 'validation/ssim': 0.7190104899409117, 'validation/loss': 0.29098567415236354, 'validation/num_examples': 3554, 'test/ssim': 0.7363882568154845, 'test/loss': 0.29234339957195965, 'test/num_examples': 3581, 'score': 1152.3579506874084, 'total_duration': 1212.9758560657501, 'accumulated_submission_time': 1152.3579506874084, 'accumulated_eval_time': 60.07899618148804, 'accumulated_logging_time': 0.3449559211730957}
I0205 01:39:56.353554 139462612883200 logging_writer.py:48] [4826] accumulated_eval_time=60.078996, accumulated_logging_time=0.344956, accumulated_submission_time=1152.357951, global_step=4826, preemption_count=0, score=1152.357951, test/loss=0.292343, test/num_examples=3581, test/ssim=0.736388, total_duration=1212.975856, train/loss=0.272424, train/ssim=0.741703, validation/loss=0.290986, validation/num_examples=3554, validation/ssim=0.719010
I0205 01:40:11.813665 139462604490496 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.1185908317565918, loss=0.3711417019367218
I0205 01:40:35.456549 139462612883200 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.19547122716903687, loss=0.29968005418777466
I0205 01:40:59.215188 139462604490496 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.21844583749771118, loss=0.24285471439361572
I0205 01:41:16.429675 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:41:17.800966 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:41:19.121477 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:41:20.442502 139681449744192 submission_runner.py:408] Time since start: 1297.08s, 	Step: 5173, 	{'train/ssim': 0.7403593744550433, 'train/loss': 0.2726188898086548, 'validation/ssim': 0.7179201004809721, 'validation/loss': 0.2907309202109419, 'validation/num_examples': 3554, 'test/ssim': 0.7354368515035954, 'test/loss': 0.2921543116011589, 'test/num_examples': 3581, 'score': 1232.4112536907196, 'total_duration': 1297.0824031829834, 'accumulated_submission_time': 1232.4112536907196, 'accumulated_eval_time': 64.09178137779236, 'accumulated_logging_time': 0.37175941467285156}
I0205 01:41:20.458345 139462612883200 logging_writer.py:48] [5173] accumulated_eval_time=64.091781, accumulated_logging_time=0.371759, accumulated_submission_time=1232.411254, global_step=5173, preemption_count=0, score=1232.411254, test/loss=0.292154, test/num_examples=3581, test/ssim=0.735437, total_duration=1297.082403, train/loss=0.272619, train/ssim=0.740359, validation/loss=0.290731, validation/num_examples=3554, validation/ssim=0.717920
I0205 01:41:24.849452 139462604490496 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.1481780707836151, loss=0.315685898065567
I0205 01:41:49.372013 139462612883200 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.12778425216674805, loss=0.20114538073539734
I0205 01:42:13.184437 139462604490496 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.10016089677810669, loss=0.23901352286338806
I0205 01:42:37.139307 139462612883200 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.08959173411130905, loss=0.27187925577163696
I0205 01:42:40.447583 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:42:41.821523 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:42:43.140116 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:42:44.460161 139681449744192 submission_runner.py:408] Time since start: 1381.10s, 	Step: 5515, 	{'train/ssim': 0.7342469351632255, 'train/loss': 0.2744945628302438, 'validation/ssim': 0.7122155631199001, 'validation/loss': 0.29285718996201465, 'validation/num_examples': 3554, 'test/ssim': 0.7297423958478777, 'test/loss': 0.2941171858637601, 'test/num_examples': 3581, 'score': 1312.3778328895569, 'total_duration': 1381.1000657081604, 'accumulated_submission_time': 1312.3778328895569, 'accumulated_eval_time': 68.104318857193, 'accumulated_logging_time': 0.39670896530151367}
I0205 01:42:44.475965 139462604490496 logging_writer.py:48] [5515] accumulated_eval_time=68.104319, accumulated_logging_time=0.396709, accumulated_submission_time=1312.377833, global_step=5515, preemption_count=0, score=1312.377833, test/loss=0.294117, test/num_examples=3581, test/ssim=0.729742, total_duration=1381.100066, train/loss=0.274495, train/ssim=0.734247, validation/loss=0.292857, validation/num_examples=3554, validation/ssim=0.712216
I0205 01:43:02.858973 139462612883200 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.27835407853126526, loss=0.2271430492401123
I0205 01:43:26.489948 139462604490496 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.17122505605220795, loss=0.29456207156181335
I0205 01:43:50.170372 139462612883200 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.1271255761384964, loss=0.440350741147995
I0205 01:44:04.637490 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:44:06.010251 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:44:07.330994 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:44:08.650991 139681449744192 submission_runner.py:408] Time since start: 1465.29s, 	Step: 5861, 	{'train/ssim': 0.741619518824986, 'train/loss': 0.27338084152766634, 'validation/ssim': 0.7192837570782921, 'validation/loss': 0.29188608868308596, 'validation/num_examples': 3554, 'test/ssim': 0.7366074447823583, 'test/loss': 0.2932253669540631, 'test/num_examples': 3581, 'score': 1392.5162916183472, 'total_duration': 1465.2908942699432, 'accumulated_submission_time': 1392.5162916183472, 'accumulated_eval_time': 72.11777949333191, 'accumulated_logging_time': 0.42174696922302246}
I0205 01:44:08.667285 139462604490496 logging_writer.py:48] [5861] accumulated_eval_time=72.117779, accumulated_logging_time=0.421747, accumulated_submission_time=1392.516292, global_step=5861, preemption_count=0, score=1392.516292, test/loss=0.293225, test/num_examples=3581, test/ssim=0.736607, total_duration=1465.290894, train/loss=0.273381, train/ssim=0.741620, validation/loss=0.291886, validation/num_examples=3554, validation/ssim=0.719284
I0205 01:44:15.822697 139462612883200 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.07244157046079636, loss=0.2813413441181183
I0205 01:44:39.222862 139462604490496 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.10287179052829742, loss=0.23767930269241333
I0205 01:45:03.011104 139462612883200 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.1321517378091812, loss=0.3381316363811493
I0205 01:45:26.914294 139462604490496 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17418241500854492, loss=0.23516005277633667
I0205 01:45:28.684332 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:45:30.055415 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:45:31.375182 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:45:32.695100 139681449744192 submission_runner.py:408] Time since start: 1549.34s, 	Step: 6209, 	{'train/ssim': 0.7370784623282296, 'train/loss': 0.27326224531446186, 'validation/ssim': 0.7148053497159891, 'validation/loss': 0.2914096229050893, 'validation/num_examples': 3554, 'test/ssim': 0.7324459413615261, 'test/loss': 0.29283079452535954, 'test/num_examples': 3581, 'score': 1472.5103845596313, 'total_duration': 1549.3350069522858, 'accumulated_submission_time': 1472.5103845596313, 'accumulated_eval_time': 76.12851810455322, 'accumulated_logging_time': 0.44706010818481445}
I0205 01:45:32.711721 139462612883200 logging_writer.py:48] [6209] accumulated_eval_time=76.128518, accumulated_logging_time=0.447060, accumulated_submission_time=1472.510385, global_step=6209, preemption_count=0, score=1472.510385, test/loss=0.292831, test/num_examples=3581, test/ssim=0.732446, total_duration=1549.335007, train/loss=0.273262, train/ssim=0.737078, validation/loss=0.291410, validation/num_examples=3554, validation/ssim=0.714805
I0205 01:45:52.266258 139462604490496 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.13472473621368408, loss=0.2840741276741028
I0205 01:46:16.713732 139462612883200 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.11157195270061493, loss=0.2872513234615326
I0205 01:46:40.658559 139462604490496 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.19159093499183655, loss=0.2516826093196869
I0205 01:46:52.704146 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:46:54.074484 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:46:55.392916 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:46:56.716113 139681449744192 submission_runner.py:408] Time since start: 1633.36s, 	Step: 6552, 	{'train/ssim': 0.7439711434500558, 'train/loss': 0.2714024782180786, 'validation/ssim': 0.7208899056300999, 'validation/loss': 0.2901221486243493, 'validation/num_examples': 3554, 'test/ssim': 0.7380670389294192, 'test/loss': 0.29158827486866445, 'test/num_examples': 3581, 'score': 1552.4796981811523, 'total_duration': 1633.3560178279877, 'accumulated_submission_time': 1552.4796981811523, 'accumulated_eval_time': 80.14044666290283, 'accumulated_logging_time': 0.4731578826904297}
I0205 01:46:56.731963 139462612883200 logging_writer.py:48] [6552] accumulated_eval_time=80.140447, accumulated_logging_time=0.473158, accumulated_submission_time=1552.479698, global_step=6552, preemption_count=0, score=1552.479698, test/loss=0.291588, test/num_examples=3581, test/ssim=0.738067, total_duration=1633.356018, train/loss=0.271402, train/ssim=0.743971, validation/loss=0.290122, validation/num_examples=3554, validation/ssim=0.720890
I0205 01:47:06.088594 139462604490496 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.2000628560781479, loss=0.31306540966033936
I0205 01:47:29.932533 139462612883200 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.10938829928636551, loss=0.2621144950389862
I0205 01:47:53.867888 139462604490496 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.11132916063070297, loss=0.27917221188545227
I0205 01:48:16.957825 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:48:18.327189 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:48:19.646021 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:48:20.966209 139681449744192 submission_runner.py:408] Time since start: 1717.61s, 	Step: 6897, 	{'train/ssim': 0.7350197519574847, 'train/loss': 0.2739830527986799, 'validation/ssim': 0.7134123605224747, 'validation/loss': 0.29205068095587716, 'validation/num_examples': 3554, 'test/ssim': 0.7310526149294889, 'test/loss': 0.29322209447430886, 'test/num_examples': 3581, 'score': 1632.6826753616333, 'total_duration': 1717.6061108112335, 'accumulated_submission_time': 1632.6826753616333, 'accumulated_eval_time': 84.14881253242493, 'accumulated_logging_time': 0.49805593490600586}
I0205 01:48:20.982749 139462612883200 logging_writer.py:48] [6897] accumulated_eval_time=84.148813, accumulated_logging_time=0.498056, accumulated_submission_time=1632.682675, global_step=6897, preemption_count=0, score=1632.682675, test/loss=0.293222, test/num_examples=3581, test/ssim=0.731053, total_duration=1717.606111, train/loss=0.273983, train/ssim=0.735020, validation/loss=0.292051, validation/num_examples=3554, validation/ssim=0.713412
I0205 01:48:21.289279 139462604490496 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.11156278848648071, loss=0.3163081407546997
I0205 01:48:43.378666 139462612883200 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.1807248592376709, loss=0.23053017258644104
I0205 01:49:07.079879 139462604490496 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.11021314561367035, loss=0.2446368783712387
I0205 01:49:30.709021 139462612883200 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.16551589965820312, loss=0.2400515377521515
I0205 01:49:41.182721 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:49:42.553207 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:49:43.875918 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:49:45.198012 139681449744192 submission_runner.py:408] Time since start: 1801.84s, 	Step: 7245, 	{'train/ssim': 0.7398674147469657, 'train/loss': 0.27286364351000103, 'validation/ssim': 0.718265909120885, 'validation/loss': 0.29099714615134353, 'validation/num_examples': 3554, 'test/ssim': 0.7354655538781066, 'test/loss': 0.2924798551600461, 'test/num_examples': 3581, 'score': 1712.859538078308, 'total_duration': 1801.8379180431366, 'accumulated_submission_time': 1712.859538078308, 'accumulated_eval_time': 88.164067029953, 'accumulated_logging_time': 0.5237960815429688}
I0205 01:49:45.215084 139462604490496 logging_writer.py:48] [7245] accumulated_eval_time=88.164067, accumulated_logging_time=0.523796, accumulated_submission_time=1712.859538, global_step=7245, preemption_count=0, score=1712.859538, test/loss=0.292480, test/num_examples=3581, test/ssim=0.735466, total_duration=1801.837918, train/loss=0.272864, train/ssim=0.739867, validation/loss=0.290997, validation/num_examples=3554, validation/ssim=0.718266
I0205 01:49:56.379606 139462612883200 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.18188351392745972, loss=0.24982424080371857
I0205 01:50:20.374356 139462604490496 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.16953091323375702, loss=0.2630317211151123
I0205 01:50:44.845182 139462612883200 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.17447111010551453, loss=0.19403961300849915
I0205 01:51:05.202966 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:51:06.573791 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:51:07.892759 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:51:09.213935 139681449744192 submission_runner.py:408] Time since start: 1885.85s, 	Step: 7585, 	{'train/ssim': 0.7441009793962751, 'train/loss': 0.2723337071282523, 'validation/ssim': 0.7217527785593697, 'validation/loss': 0.29072322641521875, 'validation/num_examples': 3554, 'test/ssim': 0.7389684707483943, 'test/loss': 0.2920952024355976, 'test/num_examples': 3581, 'score': 1792.8237624168396, 'total_duration': 1885.8538382053375, 'accumulated_submission_time': 1792.8237624168396, 'accumulated_eval_time': 92.1750111579895, 'accumulated_logging_time': 0.550663948059082}
I0205 01:51:09.232235 139462604490496 logging_writer.py:48] [7585] accumulated_eval_time=92.175011, accumulated_logging_time=0.550664, accumulated_submission_time=1792.823762, global_step=7585, preemption_count=0, score=1792.823762, test/loss=0.292095, test/num_examples=3581, test/ssim=0.738968, total_duration=1885.853838, train/loss=0.272334, train/ssim=0.744101, validation/loss=0.290723, validation/num_examples=3554, validation/ssim=0.721753
I0205 01:51:10.681721 139462612883200 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.1458023637533188, loss=0.2555909752845764
I0205 01:51:34.598682 139462604490496 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.1516469419002533, loss=0.24692219495773315
I0205 01:51:58.296450 139462612883200 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.10088949650526047, loss=0.35398316383361816
I0205 01:52:22.033636 139462604490496 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.08617005497217178, loss=0.29368966817855835
I0205 01:52:29.274779 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:52:30.645465 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:52:31.967770 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:52:33.288991 139681449744192 submission_runner.py:408] Time since start: 1969.93s, 	Step: 7931, 	{'train/ssim': 0.7397144862583706, 'train/loss': 0.2723456450871059, 'validation/ssim': 0.7167655502602701, 'validation/loss': 0.2911539072392023, 'validation/num_examples': 3554, 'test/ssim': 0.7343427524390882, 'test/loss': 0.29241754169139206, 'test/num_examples': 3581, 'score': 1872.8409950733185, 'total_duration': 1969.928893327713, 'accumulated_submission_time': 1872.8409950733185, 'accumulated_eval_time': 96.18921422958374, 'accumulated_logging_time': 0.5797338485717773}
I0205 01:52:33.305521 139462612883200 logging_writer.py:48] [7931] accumulated_eval_time=96.189214, accumulated_logging_time=0.579734, accumulated_submission_time=1872.840995, global_step=7931, preemption_count=0, score=1872.840995, test/loss=0.292418, test/num_examples=3581, test/ssim=0.734343, total_duration=1969.928893, train/loss=0.272346, train/ssim=0.739714, validation/loss=0.291154, validation/num_examples=3554, validation/ssim=0.716766
I0205 01:52:47.556567 139462604490496 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.1922697275876999, loss=0.2682782709598541
I0205 01:53:11.356242 139462612883200 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.09307154268026352, loss=0.25950363278388977
I0205 01:53:35.027060 139462604490496 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.08436692506074905, loss=0.32323330640792847
I0205 01:53:53.351843 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:53:54.723585 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:53:56.045024 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:53:57.363776 139681449744192 submission_runner.py:408] Time since start: 2054.00s, 	Step: 8278, 	{'train/ssim': 0.7389503206525531, 'train/loss': 0.2730504444667271, 'validation/ssim': 0.715964502475204, 'validation/loss': 0.29152715937368107, 'validation/num_examples': 3554, 'test/ssim': 0.733583128076131, 'test/loss': 0.29276524266528203, 'test/num_examples': 3581, 'score': 1952.8641078472137, 'total_duration': 2054.003679037094, 'accumulated_submission_time': 1952.8641078472137, 'accumulated_eval_time': 100.20110750198364, 'accumulated_logging_time': 0.6055564880371094}
I0205 01:53:57.381240 139462612883200 logging_writer.py:48] [8278] accumulated_eval_time=100.201108, accumulated_logging_time=0.605556, accumulated_submission_time=1952.864108, global_step=8278, preemption_count=0, score=1952.864108, test/loss=0.292765, test/num_examples=3581, test/ssim=0.733583, total_duration=2054.003679, train/loss=0.273050, train/ssim=0.738950, validation/loss=0.291527, validation/num_examples=3554, validation/ssim=0.715965
I0205 01:54:00.673385 139462604490496 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.207147017121315, loss=0.2990467846393585
I0205 01:54:24.541084 139462612883200 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.08532755821943283, loss=0.2351103127002716
I0205 01:54:48.332594 139462604490496 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.18251585960388184, loss=0.2809367775917053
I0205 01:55:12.638290 139462612883200 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.3018798828125, loss=0.20089907944202423
I0205 01:55:17.511109 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:55:18.883556 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:55:20.203789 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:55:21.522949 139681449744192 submission_runner.py:408] Time since start: 2138.16s, 	Step: 8622, 	{'train/ssim': 0.7411728586469378, 'train/loss': 0.2715661185128348, 'validation/ssim': 0.7190179776528207, 'validation/loss': 0.2899193964986635, 'validation/num_examples': 3554, 'test/ssim': 0.7363723034766825, 'test/loss': 0.2912397216865052, 'test/num_examples': 3581, 'score': 2032.9702162742615, 'total_duration': 2138.162857532501, 'accumulated_submission_time': 2032.9702162742615, 'accumulated_eval_time': 104.21291184425354, 'accumulated_logging_time': 0.6329255104064941}
I0205 01:55:21.539427 139462604490496 logging_writer.py:48] [8622] accumulated_eval_time=104.212912, accumulated_logging_time=0.632926, accumulated_submission_time=2032.970216, global_step=8622, preemption_count=0, score=2032.970216, test/loss=0.291240, test/num_examples=3581, test/ssim=0.736372, total_duration=2138.162858, train/loss=0.271566, train/ssim=0.741173, validation/loss=0.289919, validation/num_examples=3554, validation/ssim=0.719018
I0205 01:55:38.286067 139462612883200 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.19466954469680786, loss=0.27020132541656494
I0205 01:56:02.163786 139462604490496 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.1403501182794571, loss=0.2617422342300415
I0205 01:56:26.000333 139462612883200 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.4037744104862213, loss=0.2993263304233551
I0205 01:56:41.585309 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:56:42.956960 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:56:44.277325 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:56:45.599075 139681449744192 submission_runner.py:408] Time since start: 2222.24s, 	Step: 8967, 	{'train/ssim': 0.7409847123282296, 'train/loss': 0.2726804869515555, 'validation/ssim': 0.7181451440058737, 'validation/loss': 0.2913322040856254, 'validation/num_examples': 3554, 'test/ssim': 0.7353939683834823, 'test/loss': 0.29281405715494974, 'test/num_examples': 3581, 'score': 2112.99298119545, 'total_duration': 2222.238981962204, 'accumulated_submission_time': 2112.99298119545, 'accumulated_eval_time': 108.22664284706116, 'accumulated_logging_time': 0.6587364673614502}
I0205 01:56:45.615756 139462604490496 logging_writer.py:48] [8967] accumulated_eval_time=108.226643, accumulated_logging_time=0.658736, accumulated_submission_time=2112.992981, global_step=8967, preemption_count=0, score=2112.992981, test/loss=0.292814, test/num_examples=3581, test/ssim=0.735394, total_duration=2222.238982, train/loss=0.272680, train/ssim=0.740985, validation/loss=0.291332, validation/num_examples=3554, validation/ssim=0.718145
I0205 01:56:51.392712 139462612883200 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.30269914865493774, loss=0.33769065141677856
I0205 01:57:15.200443 139462604490496 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.12305968254804611, loss=0.2864093780517578
I0205 01:57:38.783869 139462612883200 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.13831190764904022, loss=0.22804945707321167
I0205 01:58:03.000649 139462604490496 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.06500063091516495, loss=0.4289126396179199
I0205 01:58:05.753657 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:58:07.125607 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:58:08.445061 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:58:09.764354 139681449744192 submission_runner.py:408] Time since start: 2306.40s, 	Step: 9313, 	{'train/ssim': 0.7409087589808873, 'train/loss': 0.27189222403935026, 'validation/ssim': 0.7185364284740785, 'validation/loss': 0.29015419465742825, 'validation/num_examples': 3554, 'test/ssim': 0.7360125352336987, 'test/loss': 0.2915215640053407, 'test/num_examples': 3581, 'score': 2193.1075069904327, 'total_duration': 2306.40425825119, 'accumulated_submission_time': 2193.1075069904327, 'accumulated_eval_time': 112.237300157547, 'accumulated_logging_time': 0.6848461627960205}
I0205 01:58:09.780758 139462612883200 logging_writer.py:48] [9313] accumulated_eval_time=112.237300, accumulated_logging_time=0.684846, accumulated_submission_time=2193.107507, global_step=9313, preemption_count=0, score=2193.107507, test/loss=0.291522, test/num_examples=3581, test/ssim=0.736013, total_duration=2306.404258, train/loss=0.271892, train/ssim=0.740909, validation/loss=0.290154, validation/num_examples=3554, validation/ssim=0.718536
I0205 01:58:28.271488 139462604490496 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.1626477986574173, loss=0.23858335614204407
I0205 01:58:52.205614 139462612883200 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.1458532214164734, loss=0.2720467746257782
I0205 01:59:16.355958 139462604490496 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.07952796667814255, loss=0.32577770948410034
I0205 01:59:29.792034 139681449744192 spec.py:321] Evaluating on the training split.
I0205 01:59:31.161044 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 01:59:32.483049 139681449744192 spec.py:349] Evaluating on the test split.
I0205 01:59:33.805750 139681449744192 submission_runner.py:408] Time since start: 2390.45s, 	Step: 9656, 	{'train/ssim': 0.7410191808428083, 'train/loss': 0.2718787704195295, 'validation/ssim': 0.7191517947427195, 'validation/loss': 0.29007395935917274, 'validation/num_examples': 3554, 'test/ssim': 0.7363588726743577, 'test/loss': 0.2914483081825084, 'test/num_examples': 3581, 'score': 2273.0946094989777, 'total_duration': 2390.445656776428, 'accumulated_submission_time': 2273.0946094989777, 'accumulated_eval_time': 116.2509913444519, 'accumulated_logging_time': 0.7118649482727051}
I0205 01:59:33.822394 139462612883200 logging_writer.py:48] [9656] accumulated_eval_time=116.250991, accumulated_logging_time=0.711865, accumulated_submission_time=2273.094609, global_step=9656, preemption_count=0, score=2273.094609, test/loss=0.291448, test/num_examples=3581, test/ssim=0.736359, total_duration=2390.445657, train/loss=0.271879, train/ssim=0.741019, validation/loss=0.290074, validation/num_examples=3554, validation/ssim=0.719152
I0205 01:59:42.210194 139462604490496 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.102765291929245, loss=0.32576197385787964
I0205 02:00:06.153429 139462612883200 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.08004225045442581, loss=0.23270247876644135
I0205 02:00:29.961192 139462604490496 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.12473177164793015, loss=0.2514525353908539
I0205 02:00:53.604052 139462612883200 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.19562582671642303, loss=0.3130498230457306
I0205 02:00:54.014729 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:00:55.388263 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:00:56.709742 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:00:58.029429 139681449744192 submission_runner.py:408] Time since start: 2474.67s, 	Step: 10003, 	{'train/ssim': 0.742525441305978, 'train/loss': 0.2702041523797171, 'validation/ssim': 0.7192932369337366, 'validation/loss': 0.2888822797046462, 'validation/num_examples': 3554, 'test/ssim': 0.7367913172385507, 'test/loss': 0.29026960188102136, 'test/num_examples': 3581, 'score': 2353.26428937912, 'total_duration': 2474.6693358421326, 'accumulated_submission_time': 2353.26428937912, 'accumulated_eval_time': 120.26565432548523, 'accumulated_logging_time': 0.7373523712158203}
I0205 02:00:58.046297 139462604490496 logging_writer.py:48] [10003] accumulated_eval_time=120.265654, accumulated_logging_time=0.737352, accumulated_submission_time=2353.264289, global_step=10003, preemption_count=0, score=2353.264289, test/loss=0.290270, test/num_examples=3581, test/ssim=0.736791, total_duration=2474.669336, train/loss=0.270204, train/ssim=0.742525, validation/loss=0.288882, validation/num_examples=3554, validation/ssim=0.719293
I0205 02:01:19.193949 139462612883200 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.09849115461111069, loss=0.2569430470466614
I0205 02:01:43.123792 139462604490496 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.15485934913158417, loss=0.36891913414001465
I0205 02:02:07.015091 139462612883200 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.15041695535182953, loss=0.24424123764038086
I0205 02:02:18.244750 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:02:19.615376 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:02:20.936353 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:02:22.256475 139681449744192 submission_runner.py:408] Time since start: 2558.90s, 	Step: 10348, 	{'train/ssim': 0.7450870786394391, 'train/loss': 0.2710064649581909, 'validation/ssim': 0.7226098811418472, 'validation/loss': 0.28952986374287776, 'validation/num_examples': 3554, 'test/ssim': 0.7398191791311785, 'test/loss': 0.29097430994310247, 'test/num_examples': 3581, 'score': 2433.438845872879, 'total_duration': 2558.896376132965, 'accumulated_submission_time': 2433.438845872879, 'accumulated_eval_time': 124.27734661102295, 'accumulated_logging_time': 0.7643404006958008}
I0205 02:02:22.274505 139462604490496 logging_writer.py:48] [10348] accumulated_eval_time=124.277347, accumulated_logging_time=0.764340, accumulated_submission_time=2433.438846, global_step=10348, preemption_count=0, score=2433.438846, test/loss=0.290974, test/num_examples=3581, test/ssim=0.739819, total_duration=2558.896376, train/loss=0.271006, train/ssim=0.745087, validation/loss=0.289530, validation/num_examples=3554, validation/ssim=0.722610
I0205 02:02:32.854081 139462612883200 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.06146401911973953, loss=0.29428642988204956
I0205 02:02:56.691528 139462604490496 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.20836381614208221, loss=0.33674001693725586
I0205 02:03:20.449121 139462612883200 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.13323263823986053, loss=0.29800352454185486
I0205 02:03:42.349650 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:03:43.720652 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:03:45.039956 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:03:46.359586 139681449744192 submission_runner.py:408] Time since start: 2643.00s, 	Step: 10692, 	{'train/ssim': 0.7411471775599888, 'train/loss': 0.2711236817496164, 'validation/ssim': 0.7182149377242192, 'validation/loss': 0.28949407385384424, 'validation/num_examples': 3554, 'test/ssim': 0.7358138684419506, 'test/loss': 0.2907895171019792, 'test/num_examples': 3581, 'score': 2513.490818977356, 'total_duration': 2642.999470949173, 'accumulated_submission_time': 2513.490818977356, 'accumulated_eval_time': 128.28723120689392, 'accumulated_logging_time': 0.7917084693908691}
I0205 02:03:46.376582 139462604490496 logging_writer.py:48] [10692] accumulated_eval_time=128.287231, accumulated_logging_time=0.791708, accumulated_submission_time=2513.490819, global_step=10692, preemption_count=0, score=2513.490819, test/loss=0.290790, test/num_examples=3581, test/ssim=0.735814, total_duration=2642.999471, train/loss=0.271124, train/ssim=0.741147, validation/loss=0.289494, validation/num_examples=3554, validation/ssim=0.718215
I0205 02:03:47.045779 139462612883200 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.12706030905246735, loss=0.23260681331157684
I0205 02:04:10.217872 139462604490496 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.12101265788078308, loss=0.32745638489723206
I0205 02:04:34.043476 139462612883200 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.2293255627155304, loss=0.26249030232429504
I0205 02:04:57.623373 139462604490496 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.1819845587015152, loss=0.26816996932029724
I0205 02:05:06.472580 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:05:07.842164 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:05:09.162969 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:05:10.483201 139681449744192 submission_runner.py:408] Time since start: 2727.12s, 	Step: 11038, 	{'train/ssim': 0.7429281643458775, 'train/loss': 0.2708985464913504, 'validation/ssim': 0.7203224881955191, 'validation/loss': 0.28977791996034397, 'validation/num_examples': 3554, 'test/ssim': 0.7375919157750978, 'test/loss': 0.29111243585939683, 'test/num_examples': 3581, 'score': 2593.563329219818, 'total_duration': 2727.123106479645, 'accumulated_submission_time': 2593.563329219818, 'accumulated_eval_time': 132.29781484603882, 'accumulated_logging_time': 0.81842041015625}
I0205 02:05:10.500057 139462612883200 logging_writer.py:48] [11038] accumulated_eval_time=132.297815, accumulated_logging_time=0.818420, accumulated_submission_time=2593.563329, global_step=11038, preemption_count=0, score=2593.563329, test/loss=0.291112, test/num_examples=3581, test/ssim=0.737592, total_duration=2727.123106, train/loss=0.270899, train/ssim=0.742928, validation/loss=0.289778, validation/num_examples=3554, validation/ssim=0.720322
I0205 02:05:23.128351 139462604490496 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.08067143708467484, loss=0.2883661985397339
I0205 02:05:47.024700 139462612883200 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.2496710568666458, loss=0.27992987632751465
I0205 02:06:11.123028 139462604490496 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.14988505840301514, loss=0.33685964345932007
I0205 02:06:30.592391 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:06:31.964673 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:06:33.286643 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:06:34.606572 139681449744192 submission_runner.py:408] Time since start: 2811.25s, 	Step: 11382, 	{'train/ssim': 0.7329865183149066, 'train/loss': 0.2733525208064488, 'validation/ssim': 0.7107803954391179, 'validation/loss': 0.2919654652987831, 'validation/num_examples': 3554, 'test/ssim': 0.728263507705599, 'test/loss': 0.29321493592484643, 'test/num_examples': 3581, 'score': 2673.632261276245, 'total_duration': 2811.2464735507965, 'accumulated_submission_time': 2673.632261276245, 'accumulated_eval_time': 136.31195998191833, 'accumulated_logging_time': 0.844599723815918}
I0205 02:06:34.624456 139462612883200 logging_writer.py:48] [11382] accumulated_eval_time=136.311960, accumulated_logging_time=0.844600, accumulated_submission_time=2673.632261, global_step=11382, preemption_count=0, score=2673.632261, test/loss=0.293215, test/num_examples=3581, test/ssim=0.728264, total_duration=2811.246474, train/loss=0.273353, train/ssim=0.732987, validation/loss=0.291965, validation/num_examples=3554, validation/ssim=0.710780
I0205 02:06:36.813025 139462604490496 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.04937180504202843, loss=0.30676111578941345
I0205 02:07:00.583955 139462612883200 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.2000102400779724, loss=0.2663074731826782
I0205 02:07:24.490733 139462604490496 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.26576483249664307, loss=0.23966847360134125
I0205 02:07:48.233789 139462612883200 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.11406075209379196, loss=0.29921409487724304
I0205 02:07:54.724476 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:07:56.094652 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:07:57.415220 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:07:58.734858 139681449744192 submission_runner.py:408] Time since start: 2895.37s, 	Step: 11728, 	{'train/ssim': 0.7416582788739886, 'train/loss': 0.27010680947984966, 'validation/ssim': 0.7189289494451674, 'validation/loss': 0.2886116573095456, 'validation/num_examples': 3554, 'test/ssim': 0.7364855449115122, 'test/loss': 0.28991910566400797, 'test/num_examples': 3581, 'score': 2753.709707736969, 'total_duration': 2895.374767303467, 'accumulated_submission_time': 2753.709707736969, 'accumulated_eval_time': 140.32230615615845, 'accumulated_logging_time': 0.871314287185669}
I0205 02:07:58.753525 139462604490496 logging_writer.py:48] [11728] accumulated_eval_time=140.322306, accumulated_logging_time=0.871314, accumulated_submission_time=2753.709708, global_step=11728, preemption_count=0, score=2753.709708, test/loss=0.289919, test/num_examples=3581, test/ssim=0.736486, total_duration=2895.374767, train/loss=0.270107, train/ssim=0.741658, validation/loss=0.288612, validation/num_examples=3554, validation/ssim=0.718929
I0205 02:08:14.409008 139462612883200 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.08792556077241898, loss=0.3153636157512665
I0205 02:08:37.769848 139462604490496 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.11453133821487427, loss=0.27535775303840637
I0205 02:09:01.679139 139462612883200 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.14409367740154266, loss=0.2608148753643036
I0205 02:09:18.976049 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:09:20.347792 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:09:21.668781 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:09:22.989115 139681449744192 submission_runner.py:408] Time since start: 2979.63s, 	Step: 12074, 	{'train/ssim': 0.7418908391680036, 'train/loss': 0.27015936374664307, 'validation/ssim': 0.7188359369504431, 'validation/loss': 0.28897611653462646, 'validation/num_examples': 3554, 'test/ssim': 0.7362733109641162, 'test/loss': 0.2903468119502234, 'test/num_examples': 3581, 'score': 2833.909121990204, 'total_duration': 2979.6290197372437, 'accumulated_submission_time': 2833.909121990204, 'accumulated_eval_time': 144.3353407382965, 'accumulated_logging_time': 0.8990838527679443}
I0205 02:09:23.007655 139462604490496 logging_writer.py:48] [12074] accumulated_eval_time=144.335341, accumulated_logging_time=0.899084, accumulated_submission_time=2833.909122, global_step=12074, preemption_count=0, score=2833.909122, test/loss=0.290347, test/num_examples=3581, test/ssim=0.736273, total_duration=2979.629020, train/loss=0.270159, train/ssim=0.741891, validation/loss=0.288976, validation/num_examples=3554, validation/ssim=0.718836
I0205 02:09:27.150087 139462612883200 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.04799749702215195, loss=0.29443153738975525
I0205 02:09:50.698202 139462604490496 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.21034246683120728, loss=0.26241087913513184
I0205 02:10:14.413045 139462612883200 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.19884522259235382, loss=0.2905271649360657
I0205 02:10:38.364264 139462604490496 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.09905770421028137, loss=0.2592441439628601
I0205 02:10:43.002027 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:10:44.372774 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:10:45.692094 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:10:47.011860 139681449744192 submission_runner.py:408] Time since start: 3063.65s, 	Step: 12421, 	{'train/ssim': 0.7414828709193638, 'train/loss': 0.27051702567509245, 'validation/ssim': 0.7181956345403067, 'validation/loss': 0.28924546807954066, 'validation/num_examples': 3554, 'test/ssim': 0.7358350032070302, 'test/loss': 0.29044819064594385, 'test/num_examples': 3581, 'score': 2913.879408121109, 'total_duration': 3063.651765346527, 'accumulated_submission_time': 2913.879408121109, 'accumulated_eval_time': 148.34514021873474, 'accumulated_logging_time': 0.9278120994567871}
I0205 02:10:47.029170 139462612883200 logging_writer.py:48] [12421] accumulated_eval_time=148.345140, accumulated_logging_time=0.927812, accumulated_submission_time=2913.879408, global_step=12421, preemption_count=0, score=2913.879408, test/loss=0.290448, test/num_examples=3581, test/ssim=0.735835, total_duration=3063.651765, train/loss=0.270517, train/ssim=0.741483, validation/loss=0.289245, validation/num_examples=3554, validation/ssim=0.718196
I0205 02:11:04.401788 139462604490496 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.18781383335590363, loss=0.3024425506591797
I0205 02:11:28.783079 139462612883200 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.1779451221227646, loss=0.3044086694717407
I0205 02:11:52.740784 139462604490496 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.1886119544506073, loss=0.2745888829231262
I0205 02:12:07.112069 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:12:08.483667 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:12:09.803368 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:12:11.122649 139681449744192 submission_runner.py:408] Time since start: 3147.76s, 	Step: 12762, 	{'train/ssim': 0.7418837547302246, 'train/loss': 0.2706202268600464, 'validation/ssim': 0.7193922945536719, 'validation/loss': 0.288879497573157, 'validation/num_examples': 3554, 'test/ssim': 0.7369440329604161, 'test/loss': 0.29017923371614074, 'test/num_examples': 3581, 'score': 2993.9373548030853, 'total_duration': 3147.762551546097, 'accumulated_submission_time': 2993.9373548030853, 'accumulated_eval_time': 152.35568261146545, 'accumulated_logging_time': 0.9562292098999023}
I0205 02:12:11.140658 139462612883200 logging_writer.py:48] [12762] accumulated_eval_time=152.355683, accumulated_logging_time=0.956229, accumulated_submission_time=2993.937355, global_step=12762, preemption_count=0, score=2993.937355, test/loss=0.290179, test/num_examples=3581, test/ssim=0.736944, total_duration=3147.762552, train/loss=0.270620, train/ssim=0.741884, validation/loss=0.288879, validation/num_examples=3554, validation/ssim=0.719392
I0205 02:12:18.246548 139462604490496 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.06671158969402313, loss=0.255506694316864
I0205 02:12:43.041085 139462612883200 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.1924562007188797, loss=0.2130134105682373
I0205 02:13:06.623167 139462604490496 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.15764522552490234, loss=0.3043460249900818
I0205 02:13:30.382032 139462612883200 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.23211921751499176, loss=0.25929296016693115
I0205 02:13:31.259854 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:13:32.631822 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:13:33.954223 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:13:35.273520 139681449744192 submission_runner.py:408] Time since start: 3231.91s, 	Step: 13105, 	{'train/ssim': 0.7434845651899066, 'train/loss': 0.2700550215584891, 'validation/ssim': 0.7209310536982977, 'validation/loss': 0.28924096858293474, 'validation/num_examples': 3554, 'test/ssim': 0.7382352307534558, 'test/loss': 0.29054077455232474, 'test/num_examples': 3581, 'score': 3074.032609462738, 'total_duration': 3231.913425922394, 'accumulated_submission_time': 3074.032609462738, 'accumulated_eval_time': 156.36930775642395, 'accumulated_logging_time': 0.9846577644348145}
I0205 02:13:35.291245 139462604490496 logging_writer.py:48] [13105] accumulated_eval_time=156.369308, accumulated_logging_time=0.984658, accumulated_submission_time=3074.032609, global_step=13105, preemption_count=0, score=3074.032609, test/loss=0.290541, test/num_examples=3581, test/ssim=0.738235, total_duration=3231.913426, train/loss=0.270055, train/ssim=0.743485, validation/loss=0.289241, validation/num_examples=3554, validation/ssim=0.720931
I0205 02:13:55.989869 139462612883200 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.09389281272888184, loss=0.2323499619960785
I0205 02:14:19.904475 139462604490496 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.10346756130456924, loss=0.35201922059059143
I0205 02:14:43.829603 139462612883200 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.1612183004617691, loss=0.4100976586341858
I0205 02:14:55.352432 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:14:56.723573 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:14:58.045835 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:14:59.367062 139681449744192 submission_runner.py:408] Time since start: 3316.01s, 	Step: 13450, 	{'train/ssim': 0.7449960708618164, 'train/loss': 0.2694966622761318, 'validation/ssim': 0.7224813535365081, 'validation/loss': 0.2880865729250932, 'validation/num_examples': 3554, 'test/ssim': 0.7398077254520385, 'test/loss': 0.28937624899643954, 'test/num_examples': 3581, 'score': 3154.0704021453857, 'total_duration': 3316.0069653987885, 'accumulated_submission_time': 3154.0704021453857, 'accumulated_eval_time': 160.3839066028595, 'accumulated_logging_time': 1.0118327140808105}
I0205 02:14:59.385279 139462604490496 logging_writer.py:48] [13450] accumulated_eval_time=160.383907, accumulated_logging_time=1.011833, accumulated_submission_time=3154.070402, global_step=13450, preemption_count=0, score=3154.070402, test/loss=0.289376, test/num_examples=3581, test/ssim=0.739808, total_duration=3316.006965, train/loss=0.269497, train/ssim=0.744996, validation/loss=0.288087, validation/num_examples=3554, validation/ssim=0.722481
I0205 02:15:09.299756 139462612883200 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.07998504489660263, loss=0.33001217246055603
I0205 02:15:32.968603 139462604490496 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.21654945611953735, loss=0.20144662261009216
I0205 02:15:56.536850 139462612883200 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.10644787549972534, loss=0.3194632828235626
I0205 02:16:19.501971 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:16:20.875420 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:16:22.196252 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:16:23.517004 139681449744192 submission_runner.py:408] Time since start: 3400.16s, 	Step: 13797, 	{'train/ssim': 0.7459932054792132, 'train/loss': 0.2703155108860561, 'validation/ssim': 0.7233974647843978, 'validation/loss': 0.2888293848590497, 'validation/num_examples': 3554, 'test/ssim': 0.740477765681723, 'test/loss': 0.29021291298694496, 'test/num_examples': 3581, 'score': 3234.164406776428, 'total_duration': 3400.156908750534, 'accumulated_submission_time': 3234.164406776428, 'accumulated_eval_time': 164.39890503883362, 'accumulated_logging_time': 1.0392420291900635}
I0205 02:16:23.535094 139462604490496 logging_writer.py:48] [13797] accumulated_eval_time=164.398905, accumulated_logging_time=1.039242, accumulated_submission_time=3234.164407, global_step=13797, preemption_count=0, score=3234.164407, test/loss=0.290213, test/num_examples=3581, test/ssim=0.740478, total_duration=3400.156909, train/loss=0.270316, train/ssim=0.745993, validation/loss=0.288829, validation/num_examples=3554, validation/ssim=0.723397
I0205 02:16:23.844655 139462612883200 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.19207629561424255, loss=0.26720088720321655
I0205 02:16:45.907628 139462604490496 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.17872637510299683, loss=0.23724934458732605
I0205 02:17:10.096001 139462612883200 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.14460474252700806, loss=0.21930120885372162
I0205 02:17:33.764519 139462604490496 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.08468113094568253, loss=0.24609240889549255
I0205 02:17:43.719432 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:17:45.093857 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:17:46.415623 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:17:47.735081 139681449744192 submission_runner.py:408] Time since start: 3484.37s, 	Step: 14143, 	{'train/ssim': 0.7477308000837054, 'train/loss': 0.2687981128692627, 'validation/ssim': 0.7242183653102139, 'validation/loss': 0.28805078303605974, 'validation/num_examples': 3554, 'test/ssim': 0.7413721753045588, 'test/loss': 0.28940703075912805, 'test/num_examples': 3581, 'score': 3314.325216770172, 'total_duration': 3484.3749873638153, 'accumulated_submission_time': 3314.325216770172, 'accumulated_eval_time': 168.41451406478882, 'accumulated_logging_time': 1.0669360160827637}
I0205 02:17:47.753130 139462612883200 logging_writer.py:48] [14143] accumulated_eval_time=168.414514, accumulated_logging_time=1.066936, accumulated_submission_time=3314.325217, global_step=14143, preemption_count=0, score=3314.325217, test/loss=0.289407, test/num_examples=3581, test/ssim=0.741372, total_duration=3484.374987, train/loss=0.268798, train/ssim=0.747731, validation/loss=0.288051, validation/num_examples=3554, validation/ssim=0.724218
I0205 02:17:59.358799 139462604490496 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.08620783686637878, loss=0.3572676479816437
I0205 02:18:23.553813 139462612883200 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.11177131533622742, loss=0.3334784507751465
I0205 02:18:47.287235 139462604490496 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.1180264949798584, loss=0.2906501889228821
I0205 02:19:07.946999 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:19:09.318549 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:19:10.639565 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:19:11.961278 139681449744192 submission_runner.py:408] Time since start: 3568.60s, 	Step: 14487, 	{'train/ssim': 0.7401647567749023, 'train/loss': 0.27143326827457975, 'validation/ssim': 0.7168947648116559, 'validation/loss': 0.2901178552115574, 'validation/num_examples': 3554, 'test/ssim': 0.7343974301216489, 'test/loss': 0.2915374832558119, 'test/num_examples': 3581, 'score': 3394.4950959682465, 'total_duration': 3568.6011819839478, 'accumulated_submission_time': 3394.4950959682465, 'accumulated_eval_time': 172.42876362800598, 'accumulated_logging_time': 1.09513521194458}
I0205 02:19:11.979305 139462612883200 logging_writer.py:48] [14487] accumulated_eval_time=172.428764, accumulated_logging_time=1.095135, accumulated_submission_time=3394.495096, global_step=14487, preemption_count=0, score=3394.495096, test/loss=0.291537, test/num_examples=3581, test/ssim=0.734397, total_duration=3568.601182, train/loss=0.271433, train/ssim=0.740165, validation/loss=0.290118, validation/num_examples=3554, validation/ssim=0.716895
I0205 02:19:13.027567 139462604490496 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.07494737952947617, loss=0.34375670552253723
I0205 02:19:36.808766 139462612883200 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.07796797156333923, loss=0.21519972383975983
I0205 02:20:00.456245 139462604490496 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.1216379851102829, loss=0.2633519768714905
I0205 02:20:24.431001 139462612883200 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.06911011040210724, loss=0.3423081040382385
I0205 02:20:32.144272 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:20:33.514008 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:20:34.834007 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:20:36.153274 139681449744192 submission_runner.py:408] Time since start: 3652.79s, 	Step: 14833, 	{'train/ssim': 0.7431543213980538, 'train/loss': 0.27032084124428885, 'validation/ssim': 0.7210589630521947, 'validation/loss': 0.28862306061392096, 'validation/num_examples': 3554, 'test/ssim': 0.7382288221472704, 'test/loss': 0.2900032697526878, 'test/num_examples': 3581, 'score': 3474.6364142894745, 'total_duration': 3652.7931792736053, 'accumulated_submission_time': 3474.6364142894745, 'accumulated_eval_time': 176.43772840499878, 'accumulated_logging_time': 1.122864007949829}
I0205 02:20:36.172657 139462604490496 logging_writer.py:48] [14833] accumulated_eval_time=176.437728, accumulated_logging_time=1.122864, accumulated_submission_time=3474.636414, global_step=14833, preemption_count=0, score=3474.636414, test/loss=0.290003, test/num_examples=3581, test/ssim=0.738229, total_duration=3652.793179, train/loss=0.270321, train/ssim=0.743154, validation/loss=0.288623, validation/num_examples=3554, validation/ssim=0.721059
I0205 02:20:50.083184 139462612883200 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.11504143476486206, loss=0.3545045554637909
I0205 02:21:14.100413 139462604490496 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.07676174491643906, loss=0.22156190872192383
I0205 02:21:38.305422 139462612883200 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.09120382368564606, loss=0.19944120943546295
I0205 02:21:56.168687 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:21:57.538467 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:21:58.859383 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:22:00.179523 139681449744192 submission_runner.py:408] Time since start: 3736.82s, 	Step: 15177, 	{'train/ssim': 0.7430147443498883, 'train/loss': 0.2690542936325073, 'validation/ssim': 0.7197655123408483, 'validation/loss': 0.28780626459073405, 'validation/num_examples': 3554, 'test/ssim': 0.7372273069891441, 'test/loss': 0.28929661865575257, 'test/num_examples': 3581, 'score': 3554.6089866161346, 'total_duration': 3736.8194127082825, 'accumulated_submission_time': 3554.6089866161346, 'accumulated_eval_time': 180.44852137565613, 'accumulated_logging_time': 1.1519262790679932}
I0205 02:22:00.197947 139462604490496 logging_writer.py:48] [15177] accumulated_eval_time=180.448521, accumulated_logging_time=1.151926, accumulated_submission_time=3554.608987, global_step=15177, preemption_count=0, score=3554.608987, test/loss=0.289297, test/num_examples=3581, test/ssim=0.737227, total_duration=3736.819413, train/loss=0.269054, train/ssim=0.743015, validation/loss=0.287806, validation/num_examples=3554, validation/ssim=0.719766
I0205 02:22:07.152732 139462612883200 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.07077936083078384, loss=0.2612245976924896
I0205 02:22:31.035099 139462604490496 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.10002171248197556, loss=0.24333074688911438
I0205 02:22:55.030618 139462612883200 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.1447189897298813, loss=0.2769901752471924
I0205 02:23:18.947936 139462604490496 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.09791842848062515, loss=0.2583500146865845
I0205 02:23:20.325178 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:23:21.694950 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:23:23.016689 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:23:24.338778 139681449744192 submission_runner.py:408] Time since start: 3820.98s, 	Step: 15507, 	{'train/ssim': 0.7467621394566127, 'train/loss': 0.26903694016592844, 'validation/ssim': 0.7243016231710748, 'validation/loss': 0.2878441324915588, 'validation/num_examples': 3554, 'test/ssim': 0.7414995974849903, 'test/loss': 0.28926365523989456, 'test/num_examples': 3581, 'score': 3631.1549224853516, 'total_duration': 3820.978665113449, 'accumulated_submission_time': 3631.1549224853516, 'accumulated_eval_time': 184.462073802948, 'accumulated_logging_time': 4.738783836364746}
I0205 02:23:24.357151 139462612883200 logging_writer.py:48] [15507] accumulated_eval_time=184.462074, accumulated_logging_time=4.738784, accumulated_submission_time=3631.154922, global_step=15507, preemption_count=0, score=3631.154922, test/loss=0.289264, test/num_examples=3581, test/ssim=0.741500, total_duration=3820.978665, train/loss=0.269037, train/ssim=0.746762, validation/loss=0.287844, validation/num_examples=3554, validation/ssim=0.724302
I0205 02:23:44.427928 139462604490496 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.07811509072780609, loss=0.27786847949028015
I0205 02:24:08.057047 139462612883200 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.1609574556350708, loss=0.21025533974170685
I0205 02:24:31.882284 139462604490496 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.14795397222042084, loss=0.2518962025642395
I0205 02:24:44.490294 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:24:45.860973 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:24:47.182830 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:24:48.504139 139681449744192 submission_runner.py:408] Time since start: 3905.14s, 	Step: 15854, 	{'train/ssim': 0.7453158242361886, 'train/loss': 0.2699409893580845, 'validation/ssim': 0.7223393617886537, 'validation/loss': 0.28888846221906656, 'validation/num_examples': 3554, 'test/ssim': 0.7394906357991832, 'test/loss': 0.2902920660910011, 'test/num_examples': 3581, 'score': 3711.2650315761566, 'total_duration': 3905.1440398693085, 'accumulated_submission_time': 3711.2650315761566, 'accumulated_eval_time': 188.47587609291077, 'accumulated_logging_time': 4.7664830684661865}
I0205 02:24:48.522491 139462612883200 logging_writer.py:48] [15854] accumulated_eval_time=188.475876, accumulated_logging_time=4.766483, accumulated_submission_time=3711.265032, global_step=15854, preemption_count=0, score=3711.265032, test/loss=0.290292, test/num_examples=3581, test/ssim=0.739491, total_duration=3905.144040, train/loss=0.269941, train/ssim=0.745316, validation/loss=0.288888, validation/num_examples=3554, validation/ssim=0.722339
I0205 02:24:57.451875 139462604490496 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.060728054493665695, loss=0.20829081535339355
I0205 02:25:21.327656 139462612883200 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.1330651491880417, loss=0.23805296421051025
I0205 02:25:45.599754 139462604490496 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.039874471724033356, loss=0.3655385673046112
I0205 02:26:08.513803 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:26:09.884778 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:26:11.203257 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:26:12.521765 139681449744192 submission_runner.py:408] Time since start: 3989.16s, 	Step: 16197, 	{'train/ssim': 0.741283689226423, 'train/loss': 0.2696803978511265, 'validation/ssim': 0.7182117090777996, 'validation/loss': 0.28838826245515614, 'validation/num_examples': 3554, 'test/ssim': 0.7357913019669785, 'test/loss': 0.28964489913126573, 'test/num_examples': 3581, 'score': 3791.233234167099, 'total_duration': 3989.16166472435, 'accumulated_submission_time': 3791.233234167099, 'accumulated_eval_time': 192.4837954044342, 'accumulated_logging_time': 4.794270038604736}
I0205 02:26:12.540899 139462612883200 logging_writer.py:48] [16197] accumulated_eval_time=192.483795, accumulated_logging_time=4.794270, accumulated_submission_time=3791.233234, global_step=16197, preemption_count=0, score=3791.233234, test/loss=0.289645, test/num_examples=3581, test/ssim=0.735791, total_duration=3989.161665, train/loss=0.269680, train/ssim=0.741284, validation/loss=0.288388, validation/num_examples=3554, validation/ssim=0.718212
I0205 02:26:12.847952 139462604490496 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.088134765625, loss=0.22853444516658783
I0205 02:26:35.038582 139462612883200 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.14205020666122437, loss=0.24608348309993744
I0205 02:26:58.848381 139462604490496 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.10623397678136826, loss=0.23360475897789001
I0205 02:27:22.676359 139462612883200 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.04265521839261055, loss=0.2761029899120331
I0205 02:27:32.531129 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:27:33.902778 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:27:35.223137 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:27:36.543257 139681449744192 submission_runner.py:408] Time since start: 4073.18s, 	Step: 16543, 	{'train/ssim': 0.7450265884399414, 'train/loss': 0.2695753744670323, 'validation/ssim': 0.7212872352235158, 'validation/loss': 0.28914376571732553, 'validation/num_examples': 3554, 'test/ssim': 0.738705104304838, 'test/loss': 0.29042136312962513, 'test/num_examples': 3581, 'score': 3871.200170278549, 'total_duration': 4073.1831629276276, 'accumulated_submission_time': 3871.200170278549, 'accumulated_eval_time': 196.49588203430176, 'accumulated_logging_time': 4.823106288909912}
I0205 02:27:36.561918 139462604490496 logging_writer.py:48] [16543] accumulated_eval_time=196.495882, accumulated_logging_time=4.823106, accumulated_submission_time=3871.200170, global_step=16543, preemption_count=0, score=3871.200170, test/loss=0.290421, test/num_examples=3581, test/ssim=0.738705, total_duration=4073.183163, train/loss=0.269575, train/ssim=0.745027, validation/loss=0.289144, validation/num_examples=3554, validation/ssim=0.721287
I0205 02:27:48.272137 139462612883200 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.14721830189228058, loss=0.2363910675048828
I0205 02:28:11.719514 139462604490496 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.0950244888663292, loss=0.3223377764225006
I0205 02:28:35.474828 139462612883200 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.20191408693790436, loss=0.2989134192466736
I0205 02:28:56.569955 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:28:57.941417 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:28:59.262833 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:29:00.584921 139681449744192 submission_runner.py:408] Time since start: 4157.22s, 	Step: 16890, 	{'train/ssim': 0.7434981209891183, 'train/loss': 0.2689415046146938, 'validation/ssim': 0.7204480619328574, 'validation/loss': 0.2876258897325197, 'validation/num_examples': 3554, 'test/ssim': 0.7379346398526948, 'test/loss': 0.2889543036381248, 'test/num_examples': 3581, 'score': 3951.185159444809, 'total_duration': 4157.22482085228, 'accumulated_submission_time': 3951.185159444809, 'accumulated_eval_time': 200.5108027458191, 'accumulated_logging_time': 4.8511247634887695}
I0205 02:29:00.603976 139462604490496 logging_writer.py:48] [16890] accumulated_eval_time=200.510803, accumulated_logging_time=4.851125, accumulated_submission_time=3951.185159, global_step=16890, preemption_count=0, score=3951.185159, test/loss=0.288954, test/num_examples=3581, test/ssim=0.737935, total_duration=4157.224821, train/loss=0.268942, train/ssim=0.743498, validation/loss=0.287626, validation/num_examples=3554, validation/ssim=0.720448
I0205 02:29:01.418151 139462612883200 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.14240308105945587, loss=0.33321288228034973
I0205 02:29:24.826052 139462604490496 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.08517201244831085, loss=0.22424709796905518
I0205 02:29:48.529486 139462612883200 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.08963023126125336, loss=0.31203752756118774
I0205 02:30:12.931805 139462604490496 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.13776300847530365, loss=0.2596198320388794
I0205 02:30:20.735291 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:30:22.109719 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:30:23.431634 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:30:24.748910 139681449744192 submission_runner.py:408] Time since start: 4241.39s, 	Step: 17233, 	{'train/ssim': 0.7445393289838519, 'train/loss': 0.26896725382123676, 'validation/ssim': 0.721334771889948, 'validation/loss': 0.2876462748564558, 'validation/num_examples': 3554, 'test/ssim': 0.7388480025874407, 'test/loss': 0.2889681435004189, 'test/num_examples': 3581, 'score': 4031.2938227653503, 'total_duration': 4241.38879776001, 'accumulated_submission_time': 4031.2938227653503, 'accumulated_eval_time': 204.5243673324585, 'accumulated_logging_time': 4.8789660930633545}
I0205 02:30:24.768425 139462612883200 logging_writer.py:48] [17233] accumulated_eval_time=204.524367, accumulated_logging_time=4.878966, accumulated_submission_time=4031.293823, global_step=17233, preemption_count=0, score=4031.293823, test/loss=0.288968, test/num_examples=3581, test/ssim=0.738848, total_duration=4241.388798, train/loss=0.268967, train/ssim=0.744539, validation/loss=0.287646, validation/num_examples=3554, validation/ssim=0.721335
I0205 02:30:38.610925 139462604490496 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.0872378870844841, loss=0.2566026449203491
I0205 02:31:02.412634 139462612883200 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.11024636030197144, loss=0.23531289398670197
I0205 02:31:26.297870 139462604490496 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.0783439502120018, loss=0.25219863653182983
I0205 02:31:44.823127 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:31:46.193742 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:31:47.514640 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:31:48.836044 139681449744192 submission_runner.py:408] Time since start: 4325.48s, 	Step: 17578, 	{'train/ssim': 0.7461472238813128, 'train/loss': 0.2680603095463344, 'validation/ssim': 0.7228117745849747, 'validation/loss': 0.2870571671004502, 'validation/num_examples': 3554, 'test/ssim': 0.7402261938006144, 'test/loss': 0.28837596101822116, 'test/num_examples': 3581, 'score': 4111.324229717255, 'total_duration': 4325.475947856903, 'accumulated_submission_time': 4111.324229717255, 'accumulated_eval_time': 208.53724908828735, 'accumulated_logging_time': 4.909036159515381}
I0205 02:31:48.854759 139462612883200 logging_writer.py:48] [17578] accumulated_eval_time=208.537249, accumulated_logging_time=4.909036, accumulated_submission_time=4111.324230, global_step=17578, preemption_count=0, score=4111.324230, test/loss=0.288376, test/num_examples=3581, test/ssim=0.740226, total_duration=4325.475948, train/loss=0.268060, train/ssim=0.746147, validation/loss=0.287057, validation/num_examples=3554, validation/ssim=0.722812
I0205 02:31:52.074833 139462604490496 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.07724469155073166, loss=0.3045799434185028
I0205 02:32:16.137852 139462612883200 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.12541933357715607, loss=0.26379138231277466
I0205 02:32:40.172094 139462604490496 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.12760572135448456, loss=0.2890356183052063
I0205 02:33:04.133773 139462612883200 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.08785931020975113, loss=0.20905539393424988
I0205 02:33:08.993196 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:33:10.362307 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:33:11.683875 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:33:13.004871 139681449744192 submission_runner.py:408] Time since start: 4409.64s, 	Step: 17922, 	{'train/ssim': 0.7468926565987724, 'train/loss': 0.2687728575297764, 'validation/ssim': 0.7236925768060636, 'validation/loss': 0.28773008227415414, 'validation/num_examples': 3554, 'test/ssim': 0.7409845909836638, 'test/loss': 0.289038569991797, 'test/num_examples': 3581, 'score': 4191.43989610672, 'total_duration': 4409.6447513103485, 'accumulated_submission_time': 4191.43989610672, 'accumulated_eval_time': 212.54886436462402, 'accumulated_logging_time': 4.937071323394775}
I0205 02:33:13.025180 139462604490496 logging_writer.py:48] [17922] accumulated_eval_time=212.548864, accumulated_logging_time=4.937071, accumulated_submission_time=4191.439896, global_step=17922, preemption_count=0, score=4191.439896, test/loss=0.289039, test/num_examples=3581, test/ssim=0.740985, total_duration=4409.644751, train/loss=0.268773, train/ssim=0.746893, validation/loss=0.287730, validation/num_examples=3554, validation/ssim=0.723693
I0205 02:33:29.632171 139462612883200 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.04900580644607544, loss=0.31594282388687134
I0205 02:33:53.487004 139462604490496 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.09189122170209885, loss=0.27116304636001587
I0205 02:34:17.011008 139462612883200 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.10134689509868622, loss=0.2152968943119049
I0205 02:34:33.184238 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:34:34.556999 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:34:35.877628 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:34:37.196572 139681449744192 submission_runner.py:408] Time since start: 4493.84s, 	Step: 18269, 	{'train/ssim': 0.7458718163626534, 'train/loss': 0.26871468339647564, 'validation/ssim': 0.7227657491998453, 'validation/loss': 0.28786850190256574, 'validation/num_examples': 3554, 'test/ssim': 0.7402092178118891, 'test/loss': 0.28917113951017526, 'test/num_examples': 3581, 'score': 4271.575967788696, 'total_duration': 4493.836472988129, 'accumulated_submission_time': 4271.575967788696, 'accumulated_eval_time': 216.56116938591003, 'accumulated_logging_time': 4.9665985107421875}
I0205 02:34:37.217102 139462604490496 logging_writer.py:48] [18269] accumulated_eval_time=216.561169, accumulated_logging_time=4.966599, accumulated_submission_time=4271.575968, global_step=18269, preemption_count=0, score=4271.575968, test/loss=0.289171, test/num_examples=3581, test/ssim=0.740209, total_duration=4493.836473, train/loss=0.268715, train/ssim=0.745872, validation/loss=0.287869, validation/num_examples=3554, validation/ssim=0.722766
I0205 02:34:42.681570 139462612883200 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.09899070113897324, loss=0.2572484314441681
I0205 02:35:06.855002 139462604490496 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.1701173335313797, loss=0.22363421320915222
I0205 02:35:30.983086 139462612883200 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.06981424987316132, loss=0.3390260934829712
I0205 02:35:54.766970 139462604490496 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.15691208839416504, loss=0.2603486478328705
I0205 02:35:57.258092 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:35:58.627976 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:35:59.947002 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:36:01.265893 139681449744192 submission_runner.py:408] Time since start: 4577.91s, 	Step: 18612, 	{'train/ssim': 0.7453145980834961, 'train/loss': 0.26775710923331125, 'validation/ssim': 0.7217790885929586, 'validation/loss': 0.28692822732748313, 'validation/num_examples': 3554, 'test/ssim': 0.7391915447849763, 'test/loss': 0.28823524438878806, 'test/num_examples': 3581, 'score': 4351.592973470688, 'total_duration': 4577.905798196793, 'accumulated_submission_time': 4351.592973470688, 'accumulated_eval_time': 220.5689299106598, 'accumulated_logging_time': 4.99765419960022}
I0205 02:36:01.285550 139462612883200 logging_writer.py:48] [18612] accumulated_eval_time=220.568930, accumulated_logging_time=4.997654, accumulated_submission_time=4351.592973, global_step=18612, preemption_count=0, score=4351.592973, test/loss=0.288235, test/num_examples=3581, test/ssim=0.739192, total_duration=4577.905798, train/loss=0.267757, train/ssim=0.745315, validation/loss=0.286928, validation/num_examples=3554, validation/ssim=0.721779
I0205 02:36:20.104381 139462604490496 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.14148017764091492, loss=0.29116418957710266
I0205 02:36:43.870648 139462612883200 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.16066257655620575, loss=0.26583215594291687
I0205 02:37:07.860688 139462604490496 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.05543278530240059, loss=0.24578768014907837
I0205 02:37:21.411365 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:37:22.781835 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:37:24.104154 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:37:25.423569 139681449744192 submission_runner.py:408] Time since start: 4662.06s, 	Step: 18958, 	{'train/ssim': 0.7447752271379743, 'train/loss': 0.2680262838091169, 'validation/ssim': 0.7214467440955613, 'validation/loss': 0.28691507231068863, 'validation/num_examples': 3554, 'test/ssim': 0.7389786972476263, 'test/loss': 0.2881993834648143, 'test/num_examples': 3581, 'score': 4431.69629073143, 'total_duration': 4662.063468456268, 'accumulated_submission_time': 4431.69629073143, 'accumulated_eval_time': 224.58108806610107, 'accumulated_logging_time': 5.0261549949646}
I0205 02:37:25.442825 139462612883200 logging_writer.py:48] [18958] accumulated_eval_time=224.581088, accumulated_logging_time=5.026155, accumulated_submission_time=4431.696291, global_step=18958, preemption_count=0, score=4431.696291, test/loss=0.288199, test/num_examples=3581, test/ssim=0.738979, total_duration=4662.063468, train/loss=0.268026, train/ssim=0.744775, validation/loss=0.286915, validation/num_examples=3554, validation/ssim=0.721447
I0205 02:37:33.342278 139462604490496 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.07097439467906952, loss=0.2822093069553375
I0205 02:37:57.258935 139462612883200 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.09298475086688995, loss=0.27606600522994995
I0205 02:38:21.232637 139462604490496 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.06667499989271164, loss=0.2340020090341568
I0205 02:38:44.856426 139462612883200 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.09884616732597351, loss=0.2582125663757324
I0205 02:38:45.521619 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:38:46.891371 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:38:48.210545 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:38:49.531864 139681449744192 submission_runner.py:408] Time since start: 4746.17s, 	Step: 19304, 	{'train/ssim': 0.748098645891462, 'train/loss': 0.268930333001273, 'validation/ssim': 0.7257016879088702, 'validation/loss': 0.28763554132447594, 'validation/num_examples': 3554, 'test/ssim': 0.7427710922228428, 'test/loss': 0.28900407260105415, 'test/num_examples': 3581, 'score': 4511.751484632492, 'total_duration': 4746.171770095825, 'accumulated_submission_time': 4511.751484632492, 'accumulated_eval_time': 228.59129190444946, 'accumulated_logging_time': 5.055289030075073}
I0205 02:38:49.551482 139462604490496 logging_writer.py:48] [19304] accumulated_eval_time=228.591292, accumulated_logging_time=5.055289, accumulated_submission_time=4511.751485, global_step=19304, preemption_count=0, score=4511.751485, test/loss=0.289004, test/num_examples=3581, test/ssim=0.742771, total_duration=4746.171770, train/loss=0.268930, train/ssim=0.748099, validation/loss=0.287636, validation/num_examples=3554, validation/ssim=0.725702
I0205 02:39:11.164926 139462612883200 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.1503191590309143, loss=0.24727627635002136
I0205 02:39:34.981642 139462604490496 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.19395841658115387, loss=0.22661514580249786
I0205 02:39:58.888207 139462612883200 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.11470513790845871, loss=0.34506985545158386
I0205 02:40:09.720385 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:40:11.091548 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:40:12.412444 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:40:13.733594 139681449744192 submission_runner.py:408] Time since start: 4830.37s, 	Step: 19646, 	{'train/ssim': 0.7443575177873883, 'train/loss': 0.2679600204740252, 'validation/ssim': 0.721302622814962, 'validation/loss': 0.28713487787198405, 'validation/num_examples': 3554, 'test/ssim': 0.7385132551792446, 'test/loss': 0.28854234616072677, 'test/num_examples': 3581, 'score': 4591.897384405136, 'total_duration': 4830.373497962952, 'accumulated_submission_time': 4591.897384405136, 'accumulated_eval_time': 232.60448598861694, 'accumulated_logging_time': 5.084141492843628}
I0205 02:40:13.753516 139462604490496 logging_writer.py:48] [19646] accumulated_eval_time=232.604486, accumulated_logging_time=5.084141, accumulated_submission_time=4591.897384, global_step=19646, preemption_count=0, score=4591.897384, test/loss=0.288542, test/num_examples=3581, test/ssim=0.738513, total_duration=4830.373498, train/loss=0.267960, train/ssim=0.744358, validation/loss=0.287135, validation/num_examples=3554, validation/ssim=0.721303
I0205 02:40:24.541303 139462612883200 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.06130805239081383, loss=0.20440557599067688
I0205 02:40:48.302990 139462604490496 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.1660994440317154, loss=0.2220347821712494
I0205 02:41:12.341040 139462612883200 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.18180611729621887, loss=0.3176581859588623
I0205 02:41:33.739442 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:41:35.112263 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:41:36.432540 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:41:37.753595 139681449744192 submission_runner.py:408] Time since start: 4914.39s, 	Step: 19992, 	{'train/ssim': 0.7473198345729283, 'train/loss': 0.26764990602220806, 'validation/ssim': 0.7242911815911649, 'validation/loss': 0.2864868473188221, 'validation/num_examples': 3554, 'test/ssim': 0.7415709102729684, 'test/loss': 0.2878015044680257, 'test/num_examples': 3581, 'score': 4671.86004781723, 'total_duration': 4914.393493652344, 'accumulated_submission_time': 4671.86004781723, 'accumulated_eval_time': 236.61859679222107, 'accumulated_logging_time': 5.113516569137573}
I0205 02:41:37.773601 139462604490496 logging_writer.py:48] [19992] accumulated_eval_time=236.618597, accumulated_logging_time=5.113517, accumulated_submission_time=4671.860048, global_step=19992, preemption_count=0, score=4671.860048, test/loss=0.287802, test/num_examples=3581, test/ssim=0.741571, total_duration=4914.393494, train/loss=0.267650, train/ssim=0.747320, validation/loss=0.286487, validation/num_examples=3554, validation/ssim=0.724291
I0205 02:41:38.441015 139462612883200 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.12282908707857132, loss=0.24372164905071259
I0205 02:42:01.299043 139462604490496 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.06191973388195038, loss=0.38682347536087036
I0205 02:42:25.243172 139462612883200 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.1073266938328743, loss=0.3605698049068451
I0205 02:42:49.324808 139462604490496 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.07151002436876297, loss=0.2705110013484955
I0205 02:42:57.946793 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:42:59.319436 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:43:00.639523 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:43:01.960156 139681449744192 submission_runner.py:408] Time since start: 4998.60s, 	Step: 20337, 	{'train/ssim': 0.7448357854570661, 'train/loss': 0.26822255338941303, 'validation/ssim': 0.7214832896252462, 'validation/loss': 0.28723403853382634, 'validation/num_examples': 3554, 'test/ssim': 0.7389167928389416, 'test/loss': 0.2885085646249302, 'test/num_examples': 3581, 'score': 4752.0103261470795, 'total_duration': 4998.600042819977, 'accumulated_submission_time': 4752.0103261470795, 'accumulated_eval_time': 240.63190078735352, 'accumulated_logging_time': 5.14256739616394}
I0205 02:43:01.981733 139462612883200 logging_writer.py:48] [20337] accumulated_eval_time=240.631901, accumulated_logging_time=5.142567, accumulated_submission_time=4752.010326, global_step=20337, preemption_count=0, score=4752.010326, test/loss=0.288509, test/num_examples=3581, test/ssim=0.738917, total_duration=4998.600043, train/loss=0.268223, train/ssim=0.744836, validation/loss=0.287234, validation/num_examples=3554, validation/ssim=0.721483
I0205 02:43:15.003504 139462604490496 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.1753597855567932, loss=0.23779235780239105
I0205 02:43:39.124265 139462612883200 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.0570966862142086, loss=0.23427508771419525
I0205 02:44:02.750655 139462604490496 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.06361037492752075, loss=0.3665906488895416
I0205 02:44:22.018441 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:44:23.390192 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:44:24.713619 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:44:26.031552 139681449744192 submission_runner.py:408] Time since start: 5082.67s, 	Step: 20681, 	{'train/ssim': 0.7465263775416783, 'train/loss': 0.2680410317012242, 'validation/ssim': 0.7229192816412845, 'validation/loss': 0.28738049543098443, 'validation/num_examples': 3554, 'test/ssim': 0.7401653120418529, 'test/loss': 0.2886559284788641, 'test/num_examples': 3581, 'score': 4832.023688554764, 'total_duration': 5082.671446084976, 'accumulated_submission_time': 4832.023688554764, 'accumulated_eval_time': 244.6449682712555, 'accumulated_logging_time': 5.173840522766113}
I0205 02:44:26.051730 139462612883200 logging_writer.py:48] [20681] accumulated_eval_time=244.644968, accumulated_logging_time=5.173841, accumulated_submission_time=4832.023689, global_step=20681, preemption_count=0, score=4832.023689, test/loss=0.288656, test/num_examples=3581, test/ssim=0.740165, total_duration=5082.671446, train/loss=0.268041, train/ssim=0.746526, validation/loss=0.287380, validation/num_examples=3554, validation/ssim=0.722919
I0205 02:44:28.460494 139462604490496 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.06534627825021744, loss=0.25509822368621826
I0205 02:44:52.284392 139462612883200 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.15507858991622925, loss=0.2375883162021637
I0205 02:45:16.443833 139462604490496 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.08007307350635529, loss=0.3073241710662842
I0205 02:45:40.241703 139462612883200 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.09991181641817093, loss=0.3146856427192688
I0205 02:45:46.173128 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:45:47.545402 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:45:48.863804 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:45:50.183889 139681449744192 submission_runner.py:408] Time since start: 5166.82s, 	Step: 21026, 	{'train/ssim': 0.7433980533054897, 'train/loss': 0.2681511810847691, 'validation/ssim': 0.7203869237347004, 'validation/loss': 0.28704777311326146, 'validation/num_examples': 3554, 'test/ssim': 0.7379010287585521, 'test/loss': 0.2883169200293214, 'test/num_examples': 3581, 'score': 4912.122037649155, 'total_duration': 5166.823796510696, 'accumulated_submission_time': 4912.122037649155, 'accumulated_eval_time': 248.65569019317627, 'accumulated_logging_time': 5.203402757644653}
I0205 02:45:50.203666 139462604490496 logging_writer.py:48] [21026] accumulated_eval_time=248.655690, accumulated_logging_time=5.203403, accumulated_submission_time=4912.122038, global_step=21026, preemption_count=0, score=4912.122038, test/loss=0.288317, test/num_examples=3581, test/ssim=0.737901, total_duration=5166.823797, train/loss=0.268151, train/ssim=0.743398, validation/loss=0.287048, validation/num_examples=3554, validation/ssim=0.720387
I0205 02:46:06.090860 139462612883200 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.10848596692085266, loss=0.27186277508735657
I0205 02:46:30.110713 139462604490496 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.07674489915370941, loss=0.22271552681922913
I0205 02:46:54.064547 139462612883200 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.06048272177577019, loss=0.2744095027446747
I0205 02:47:10.193267 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:47:11.564194 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:47:12.884512 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:47:14.204796 139681449744192 submission_runner.py:408] Time since start: 5250.84s, 	Step: 21369, 	{'train/ssim': 0.7488290241786412, 'train/loss': 0.26764767510550364, 'validation/ssim': 0.7261367308402504, 'validation/loss': 0.2864730053559809, 'validation/num_examples': 3554, 'test/ssim': 0.7432473743804106, 'test/loss': 0.2877285213518396, 'test/num_examples': 3581, 'score': 4992.088282823563, 'total_duration': 5250.844703674316, 'accumulated_submission_time': 4992.088282823563, 'accumulated_eval_time': 252.6671848297119, 'accumulated_logging_time': 5.232451677322388}
I0205 02:47:14.225390 139462604490496 logging_writer.py:48] [21369] accumulated_eval_time=252.667185, accumulated_logging_time=5.232452, accumulated_submission_time=4992.088283, global_step=21369, preemption_count=0, score=4992.088283, test/loss=0.287729, test/num_examples=3581, test/ssim=0.743247, total_duration=5250.844704, train/loss=0.267648, train/ssim=0.748829, validation/loss=0.286473, validation/num_examples=3554, validation/ssim=0.726137
I0205 02:47:19.621869 139462612883200 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.09548473358154297, loss=0.25959867238998413
I0205 02:47:43.501073 139462604490496 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.08986075967550278, loss=0.2169065773487091
I0205 02:48:07.731110 139462612883200 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.12273617088794708, loss=0.22525537014007568
I0205 02:48:31.519302 139462604490496 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.13673721253871918, loss=0.30361855030059814
I0205 02:48:34.391259 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:48:35.762294 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:48:37.083533 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:48:38.405239 139681449744192 submission_runner.py:408] Time since start: 5335.05s, 	Step: 21713, 	{'train/ssim': 0.7478596142360142, 'train/loss': 0.26826337405613493, 'validation/ssim': 0.7245296205639772, 'validation/loss': 0.2876049893990486, 'validation/num_examples': 3554, 'test/ssim': 0.7417139449088942, 'test/loss': 0.2888652308298136, 'test/num_examples': 3581, 'score': 5072.231734991074, 'total_duration': 5335.0451447963715, 'accumulated_submission_time': 5072.231734991074, 'accumulated_eval_time': 256.68112564086914, 'accumulated_logging_time': 5.262057304382324}
I0205 02:48:38.425999 139462612883200 logging_writer.py:48] [21713] accumulated_eval_time=256.681126, accumulated_logging_time=5.262057, accumulated_submission_time=5072.231735, global_step=21713, preemption_count=0, score=5072.231735, test/loss=0.288865, test/num_examples=3581, test/ssim=0.741714, total_duration=5335.045145, train/loss=0.268263, train/ssim=0.747860, validation/loss=0.287605, validation/num_examples=3554, validation/ssim=0.724530
I0205 02:48:57.121537 139462604490496 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.08617126196622849, loss=0.24849729239940643
I0205 02:49:21.075973 139462612883200 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.052547331899404526, loss=0.34925147891044617
I0205 02:49:45.061255 139462604490496 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.09131719172000885, loss=0.2872529625892639
I0205 02:49:58.651102 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:50:00.022262 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:50:01.342610 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:50:02.662923 139681449744192 submission_runner.py:408] Time since start: 5419.30s, 	Step: 22057, 	{'train/ssim': 0.7472703797476632, 'train/loss': 0.26737151827131, 'validation/ssim': 0.7236122728132034, 'validation/loss': 0.2867679971620885, 'validation/num_examples': 3554, 'test/ssim': 0.7409195504485478, 'test/loss': 0.28806425732162805, 'test/num_examples': 3581, 'score': 5152.4338619709015, 'total_duration': 5419.302825212479, 'accumulated_submission_time': 5152.4338619709015, 'accumulated_eval_time': 260.69290471076965, 'accumulated_logging_time': 5.292056083679199}
I0205 02:50:02.684213 139462612883200 logging_writer.py:48] [22057] accumulated_eval_time=260.692905, accumulated_logging_time=5.292056, accumulated_submission_time=5152.433862, global_step=22057, preemption_count=0, score=5152.433862, test/loss=0.288064, test/num_examples=3581, test/ssim=0.740920, total_duration=5419.302825, train/loss=0.267372, train/ssim=0.747270, validation/loss=0.286768, validation/num_examples=3554, validation/ssim=0.723612
I0205 02:50:10.837296 139462604490496 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.11143045872449875, loss=0.27198493480682373
I0205 02:50:34.660727 139462612883200 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.16023248434066772, loss=0.28401950001716614
I0205 02:50:58.493437 139462604490496 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.08700913190841675, loss=0.32958048582077026
I0205 02:51:22.403980 139462612883200 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.08245134353637695, loss=0.2547253668308258
I0205 02:51:22.797340 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:51:24.169825 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:51:25.489876 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:51:26.808969 139681449744192 submission_runner.py:408] Time since start: 5503.45s, 	Step: 22403, 	{'train/ssim': 0.746769768851144, 'train/loss': 0.2673004354749407, 'validation/ssim': 0.7232089667891812, 'validation/loss': 0.2865335081290447, 'validation/num_examples': 3554, 'test/ssim': 0.7407228607799846, 'test/loss': 0.2876894220364423, 'test/num_examples': 3581, 'score': 5232.52370929718, 'total_duration': 5503.448872804642, 'accumulated_submission_time': 5232.52370929718, 'accumulated_eval_time': 264.7044961452484, 'accumulated_logging_time': 5.322473049163818}
I0205 02:51:26.829146 139462604490496 logging_writer.py:48] [22403] accumulated_eval_time=264.704496, accumulated_logging_time=5.322473, accumulated_submission_time=5232.523709, global_step=22403, preemption_count=0, score=5232.523709, test/loss=0.287689, test/num_examples=3581, test/ssim=0.740723, total_duration=5503.448873, train/loss=0.267300, train/ssim=0.746770, validation/loss=0.286534, validation/num_examples=3554, validation/ssim=0.723209
I0205 02:51:47.803057 139462612883200 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.06274047493934631, loss=0.3102063834667206
I0205 02:52:11.717002 139462604490496 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.11449086666107178, loss=0.2255161702632904
I0205 02:52:36.228665 139462612883200 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.08002969622612, loss=0.2146793007850647
I0205 02:52:47.016717 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:52:48.389172 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:52:49.708654 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:52:51.030119 139681449744192 submission_runner.py:408] Time since start: 5587.67s, 	Step: 22747, 	{'train/ssim': 0.7487727573939732, 'train/loss': 0.26724702971322195, 'validation/ssim': 0.7256340924178742, 'validation/loss': 0.2863474487922939, 'validation/num_examples': 3554, 'test/ssim': 0.7426483742320581, 'test/loss': 0.2877149541961917, 'test/num_examples': 3581, 'score': 5312.687821388245, 'total_duration': 5587.670019626617, 'accumulated_submission_time': 5312.687821388245, 'accumulated_eval_time': 268.71786284446716, 'accumulated_logging_time': 5.352055549621582}
I0205 02:52:51.051316 139462604490496 logging_writer.py:48] [22747] accumulated_eval_time=268.717863, accumulated_logging_time=5.352056, accumulated_submission_time=5312.687821, global_step=22747, preemption_count=0, score=5312.687821, test/loss=0.287715, test/num_examples=3581, test/ssim=0.742648, total_duration=5587.670020, train/loss=0.267247, train/ssim=0.748773, validation/loss=0.286347, validation/num_examples=3554, validation/ssim=0.725634
I0205 02:53:01.763919 139462612883200 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.11764143407344818, loss=0.2352951467037201
I0205 02:53:25.408875 139462604490496 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.09090474992990494, loss=0.2118605673313141
I0205 02:53:49.158618 139462612883200 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.08331453800201416, loss=0.2768360376358032
I0205 02:54:11.185393 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:54:12.556822 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:54:13.879310 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:54:15.199661 139681449744192 submission_runner.py:408] Time since start: 5671.84s, 	Step: 23094, 	{'train/ssim': 0.7463985170636859, 'train/loss': 0.267437253679548, 'validation/ssim': 0.722510411354284, 'validation/loss': 0.28699774626741, 'validation/num_examples': 3554, 'test/ssim': 0.7398897419758796, 'test/loss': 0.288260537930222, 'test/num_examples': 3581, 'score': 5392.799517869949, 'total_duration': 5671.839567661285, 'accumulated_submission_time': 5392.799517869949, 'accumulated_eval_time': 272.73209524154663, 'accumulated_logging_time': 5.382074594497681}
I0205 02:54:15.220768 139462604490496 logging_writer.py:48] [23094] accumulated_eval_time=272.732095, accumulated_logging_time=5.382075, accumulated_submission_time=5392.799518, global_step=23094, preemption_count=0, score=5392.799518, test/loss=0.288261, test/num_examples=3581, test/ssim=0.739890, total_duration=5671.839568, train/loss=0.267437, train/ssim=0.746399, validation/loss=0.286998, validation/num_examples=3554, validation/ssim=0.722510
I0205 02:54:15.743077 139462612883200 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.04646996408700943, loss=0.2683795690536499
I0205 02:54:38.323298 139462604490496 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.044687461107969284, loss=0.3055535554885864
I0205 02:55:01.824028 139462612883200 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.04039471969008446, loss=0.2421088069677353
I0205 02:55:25.858899 139462604490496 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.0490918904542923, loss=0.29456019401550293
I0205 02:55:35.377394 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:55:36.747654 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:55:38.067535 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:55:39.386512 139681449744192 submission_runner.py:408] Time since start: 5756.03s, 	Step: 23441, 	{'train/ssim': 0.7481884275163923, 'train/loss': 0.2669349568230765, 'validation/ssim': 0.7248329072435987, 'validation/loss': 0.28614380363674735, 'validation/num_examples': 3554, 'test/ssim': 0.7420801217580634, 'test/loss': 0.2874584395071209, 'test/num_examples': 3581, 'score': 5472.933496236801, 'total_duration': 5756.026417970657, 'accumulated_submission_time': 5472.933496236801, 'accumulated_eval_time': 276.74117255210876, 'accumulated_logging_time': 5.412250757217407}
I0205 02:55:39.407611 139462612883200 logging_writer.py:48] [23441] accumulated_eval_time=276.741173, accumulated_logging_time=5.412251, accumulated_submission_time=5472.933496, global_step=23441, preemption_count=0, score=5472.933496, test/loss=0.287458, test/num_examples=3581, test/ssim=0.742080, total_duration=5756.026418, train/loss=0.266935, train/ssim=0.748188, validation/loss=0.286144, validation/num_examples=3554, validation/ssim=0.724833
I0205 02:55:51.501208 139462604490496 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.04030727595090866, loss=0.24339807033538818
I0205 02:56:15.295697 139462612883200 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.055807631462812424, loss=0.2853124439716339
I0205 02:56:39.276254 139462604490496 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.06072622910141945, loss=0.33753809332847595
I0205 02:56:59.537096 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:57:00.906094 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:57:02.224660 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:57:03.545473 139681449744192 submission_runner.py:408] Time since start: 5840.19s, 	Step: 23786, 	{'train/ssim': 0.7467733110700335, 'train/loss': 0.26686833586011616, 'validation/ssim': 0.7233074748522791, 'validation/loss': 0.2860006269069622, 'validation/num_examples': 3554, 'test/ssim': 0.7407065665578749, 'test/loss': 0.28726188619188076, 'test/num_examples': 3581, 'score': 5553.040453672409, 'total_duration': 5840.18537902832, 'accumulated_submission_time': 5553.040453672409, 'accumulated_eval_time': 280.7495219707489, 'accumulated_logging_time': 5.442123651504517}
I0205 02:57:03.567224 139462612883200 logging_writer.py:48] [23786] accumulated_eval_time=280.749522, accumulated_logging_time=5.442124, accumulated_submission_time=5553.040454, global_step=23786, preemption_count=0, score=5553.040454, test/loss=0.287262, test/num_examples=3581, test/ssim=0.740707, total_duration=5840.185379, train/loss=0.266868, train/ssim=0.746773, validation/loss=0.286001, validation/num_examples=3554, validation/ssim=0.723307
I0205 02:57:04.793892 139462604490496 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.047595683485269547, loss=0.21261274814605713
I0205 02:57:28.785619 139462612883200 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.04394719377160072, loss=0.28559422492980957
I0205 02:57:52.580010 139462604490496 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.08526702970266342, loss=0.18816138803958893
I0205 02:58:16.474353 139462612883200 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.07294347137212753, loss=0.2946076989173889
I0205 02:58:23.694050 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:58:25.062793 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:58:26.382152 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:58:27.702795 139681449744192 submission_runner.py:408] Time since start: 5924.34s, 	Step: 24132, 	{'train/ssim': 0.7495803151811872, 'train/loss': 0.26633802482060026, 'validation/ssim': 0.726013904887099, 'validation/loss': 0.28584266366352173, 'validation/num_examples': 3554, 'test/ssim': 0.7431660396231848, 'test/loss': 0.2871942549436261, 'test/num_examples': 3581, 'score': 5633.144581317902, 'total_duration': 5924.342694759369, 'accumulated_submission_time': 5633.144581317902, 'accumulated_eval_time': 284.75822138786316, 'accumulated_logging_time': 5.472839117050171}
I0205 02:58:27.723761 139462604490496 logging_writer.py:48] [24132] accumulated_eval_time=284.758221, accumulated_logging_time=5.472839, accumulated_submission_time=5633.144581, global_step=24132, preemption_count=0, score=5633.144581, test/loss=0.287194, test/num_examples=3581, test/ssim=0.743166, total_duration=5924.342695, train/loss=0.266338, train/ssim=0.749580, validation/loss=0.285843, validation/num_examples=3554, validation/ssim=0.726014
I0205 02:58:41.425268 139462612883200 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.121919646859169, loss=0.27239060401916504
I0205 02:59:05.115648 139462604490496 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.06907519698143005, loss=0.24936191737651825
I0205 02:59:28.614659 139462612883200 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.12551769614219666, loss=0.28515997529029846
I0205 02:59:47.748821 139681449744192 spec.py:321] Evaluating on the training split.
I0205 02:59:49.119657 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 02:59:50.438264 139681449744192 spec.py:349] Evaluating on the test split.
I0205 02:59:51.757964 139681449744192 submission_runner.py:408] Time since start: 6008.40s, 	Step: 24482, 	{'train/ssim': 0.7474779401506696, 'train/loss': 0.26655629702976774, 'validation/ssim': 0.7240453922956528, 'validation/loss': 0.28574350300167944, 'validation/num_examples': 3554, 'test/ssim': 0.7414027184489319, 'test/loss': 0.2870046897361945, 'test/num_examples': 3581, 'score': 5713.145759820938, 'total_duration': 6008.39787364006, 'accumulated_submission_time': 5713.145759820938, 'accumulated_eval_time': 288.76734495162964, 'accumulated_logging_time': 5.504015684127808}
I0205 02:59:51.778460 139462604490496 logging_writer.py:48] [24482] accumulated_eval_time=288.767345, accumulated_logging_time=5.504016, accumulated_submission_time=5713.145760, global_step=24482, preemption_count=0, score=5713.145760, test/loss=0.287005, test/num_examples=3581, test/ssim=0.741403, total_duration=6008.397874, train/loss=0.266556, train/ssim=0.747478, validation/loss=0.285744, validation/num_examples=3554, validation/ssim=0.724045
I0205 02:59:53.995745 139462612883200 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.0961255356669426, loss=0.33839479088783264
I0205 03:00:17.845571 139462604490496 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.08078118413686752, loss=0.22328302264213562
I0205 03:00:41.698778 139462612883200 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.07467315346002579, loss=0.27284324169158936
I0205 03:01:05.969895 139462604490496 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.11735817044973373, loss=0.2733793556690216
I0205 03:01:11.969247 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:01:13.339198 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:01:14.658291 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:01:15.980121 139681449744192 submission_runner.py:408] Time since start: 6092.62s, 	Step: 24825, 	{'train/ssim': 0.7502619198390416, 'train/loss': 0.2664697340556553, 'validation/ssim': 0.7271315661050929, 'validation/loss': 0.2857424038880047, 'validation/num_examples': 3554, 'test/ssim': 0.7442264594168877, 'test/loss': 0.2870229610814891, 'test/num_examples': 3581, 'score': 5793.313705205917, 'total_duration': 6092.62002158165, 'accumulated_submission_time': 5793.313705205917, 'accumulated_eval_time': 292.7781751155853, 'accumulated_logging_time': 5.533693075180054}
I0205 03:01:16.003558 139462612883200 logging_writer.py:48] [24825] accumulated_eval_time=292.778175, accumulated_logging_time=5.533693, accumulated_submission_time=5793.313705, global_step=24825, preemption_count=0, score=5793.313705, test/loss=0.287023, test/num_examples=3581, test/ssim=0.744226, total_duration=6092.620022, train/loss=0.266470, train/ssim=0.750262, validation/loss=0.285742, validation/num_examples=3554, validation/ssim=0.727132
I0205 03:01:31.880747 139462604490496 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.09172441065311432, loss=0.2769463062286377
I0205 03:01:55.747351 139462612883200 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.0782947689294815, loss=0.29496264457702637
I0205 03:02:19.705085 139462604490496 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.08000187575817108, loss=0.3346748650074005
I0205 03:02:35.982383 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:02:37.353952 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:02:38.674791 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:02:39.995889 139681449744192 submission_runner.py:408] Time since start: 6176.64s, 	Step: 25169, 	{'train/ssim': 0.7488915579659599, 'train/loss': 0.2660852500370571, 'validation/ssim': 0.7247901105048888, 'validation/loss': 0.28593902502022367, 'validation/num_examples': 3554, 'test/ssim': 0.7421172780386065, 'test/loss': 0.28720161802307315, 'test/num_examples': 3581, 'score': 5873.269628047943, 'total_duration': 6176.635795116425, 'accumulated_submission_time': 5873.269628047943, 'accumulated_eval_time': 296.7916488647461, 'accumulated_logging_time': 5.566459655761719}
I0205 03:02:40.017149 139462612883200 logging_writer.py:48] [25169] accumulated_eval_time=296.791649, accumulated_logging_time=5.566460, accumulated_submission_time=5873.269628, global_step=25169, preemption_count=0, score=5873.269628, test/loss=0.287202, test/num_examples=3581, test/ssim=0.742117, total_duration=6176.635795, train/loss=0.266085, train/ssim=0.748892, validation/loss=0.285939, validation/num_examples=3554, validation/ssim=0.724790
I0205 03:02:45.265252 139462604490496 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.08920961618423462, loss=0.2912958264350891
I0205 03:03:09.123444 139462612883200 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.08189715445041656, loss=0.28333935141563416
I0205 03:03:33.047264 139462604490496 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.12670980393886566, loss=0.21745102107524872
I0205 03:03:56.759798 139462612883200 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.08673865348100662, loss=0.26051658391952515
I0205 03:04:00.183391 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:04:01.555408 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:04:02.876061 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:04:04.197882 139681449744192 submission_runner.py:408] Time since start: 6260.84s, 	Step: 25516, 	{'train/ssim': 0.7491566794259208, 'train/loss': 0.2663029602595738, 'validation/ssim': 0.7255977529720034, 'validation/loss': 0.28578575018355196, 'validation/num_examples': 3554, 'test/ssim': 0.7428563812264382, 'test/loss': 0.2870041784112329, 'test/num_examples': 3581, 'score': 5953.41180896759, 'total_duration': 6260.837786436081, 'accumulated_submission_time': 5953.41180896759, 'accumulated_eval_time': 300.80610942840576, 'accumulated_logging_time': 5.5982396602630615}
I0205 03:04:04.218721 139462604490496 logging_writer.py:48] [25516] accumulated_eval_time=300.806109, accumulated_logging_time=5.598240, accumulated_submission_time=5953.411809, global_step=25516, preemption_count=0, score=5953.411809, test/loss=0.287004, test/num_examples=3581, test/ssim=0.742856, total_duration=6260.837786, train/loss=0.266303, train/ssim=0.749157, validation/loss=0.285786, validation/num_examples=3554, validation/ssim=0.725598
I0205 03:04:22.355699 139462612883200 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.02994120493531227, loss=0.3502700924873352
I0205 03:04:46.050878 139462604490496 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.1352444887161255, loss=0.24314473569393158
I0205 03:05:09.666816 139462612883200 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.043462175875902176, loss=0.25507989525794983
I0205 03:05:24.364669 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:05:25.735400 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:05:27.055764 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:05:28.378402 139681449744192 submission_runner.py:408] Time since start: 6345.02s, 	Step: 25862, 	{'train/ssim': 0.7497294970921108, 'train/loss': 0.2662316220147269, 'validation/ssim': 0.7261816571117051, 'validation/loss': 0.28572486959016247, 'validation/num_examples': 3554, 'test/ssim': 0.7434290651834334, 'test/loss': 0.286961567997766, 'test/num_examples': 3581, 'score': 6033.534689426422, 'total_duration': 6345.01830124855, 'accumulated_submission_time': 6033.534689426422, 'accumulated_eval_time': 304.81979846954346, 'accumulated_logging_time': 5.628521680831909}
I0205 03:05:28.399401 139462604490496 logging_writer.py:48] [25862] accumulated_eval_time=304.819798, accumulated_logging_time=5.628522, accumulated_submission_time=6033.534689, global_step=25862, preemption_count=0, score=6033.534689, test/loss=0.286962, test/num_examples=3581, test/ssim=0.743429, total_duration=6345.018301, train/loss=0.266232, train/ssim=0.749729, validation/loss=0.285725, validation/num_examples=3554, validation/ssim=0.726182
I0205 03:05:35.282253 139462612883200 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.11690488457679749, loss=0.21584056317806244
I0205 03:05:59.850323 139462604490496 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.08720429986715317, loss=0.32551848888397217
I0205 03:06:23.731188 139462612883200 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.08902065455913544, loss=0.29472658038139343
I0205 03:06:47.337751 139462604490496 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.028589628636837006, loss=0.2816813588142395
I0205 03:06:48.440081 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:06:49.810851 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:06:51.131385 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:06:52.452286 139681449744192 submission_runner.py:408] Time since start: 6429.09s, 	Step: 26206, 	{'train/ssim': 0.7487617901393345, 'train/loss': 0.26592167786189486, 'validation/ssim': 0.7249687851716375, 'validation/loss': 0.2857339029306767, 'validation/num_examples': 3554, 'test/ssim': 0.742172296604475, 'test/loss': 0.28698795236578467, 'test/num_examples': 3581, 'score': 6113.551764726639, 'total_duration': 6429.092185497284, 'accumulated_submission_time': 6113.551764726639, 'accumulated_eval_time': 308.8319561481476, 'accumulated_logging_time': 5.6597490310668945}
I0205 03:06:52.474723 139462612883200 logging_writer.py:48] [26206] accumulated_eval_time=308.831956, accumulated_logging_time=5.659749, accumulated_submission_time=6113.551765, global_step=26206, preemption_count=0, score=6113.551765, test/loss=0.286988, test/num_examples=3581, test/ssim=0.742172, total_duration=6429.092185, train/loss=0.265922, train/ssim=0.748762, validation/loss=0.285734, validation/num_examples=3554, validation/ssim=0.724969
I0205 03:07:12.905875 139462604490496 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.0888822078704834, loss=0.2587781548500061
I0205 03:07:36.820972 139462612883200 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.06903822720050812, loss=0.40875673294067383
I0205 03:08:00.519596 139462604490496 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.1216011717915535, loss=0.20846985280513763
I0205 03:08:12.660719 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:08:14.030946 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:08:15.350322 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:08:16.667198 139681449744192 submission_runner.py:408] Time since start: 6513.31s, 	Step: 26552, 	{'train/ssim': 0.7490940093994141, 'train/loss': 0.26601377555302214, 'validation/ssim': 0.7254139262099043, 'validation/loss': 0.28561696753987587, 'validation/num_examples': 3554, 'test/ssim': 0.7426279894102555, 'test/loss': 0.28687692667245535, 'test/num_examples': 3581, 'score': 6193.714996337891, 'total_duration': 6513.307105064392, 'accumulated_submission_time': 6193.714996337891, 'accumulated_eval_time': 312.83840131759644, 'accumulated_logging_time': 5.691235303878784}
I0205 03:08:16.688601 139462612883200 logging_writer.py:48] [26552] accumulated_eval_time=312.838401, accumulated_logging_time=5.691235, accumulated_submission_time=6193.714996, global_step=26552, preemption_count=0, score=6193.714996, test/loss=0.286877, test/num_examples=3581, test/ssim=0.742628, total_duration=6513.307105, train/loss=0.266014, train/ssim=0.749094, validation/loss=0.285617, validation/num_examples=3554, validation/ssim=0.725414
I0205 03:08:26.003912 139462604490496 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.044821642339229584, loss=0.31059080362319946
I0205 03:08:49.800755 139462612883200 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.06834457814693451, loss=0.32788777351379395
I0205 03:09:13.897684 139462604490496 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.11315011233091354, loss=0.26200538873672485
I0205 03:09:36.783324 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:09:38.155035 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:09:39.473588 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:09:40.794779 139681449744192 submission_runner.py:408] Time since start: 6597.43s, 	Step: 26896, 	{'train/ssim': 0.7483999388558524, 'train/loss': 0.26618504524230957, 'validation/ssim': 0.7247854392717712, 'validation/loss': 0.2855410256544123, 'validation/num_examples': 3554, 'test/ssim': 0.7420892574307107, 'test/loss': 0.28677333223523455, 'test/num_examples': 3581, 'score': 6273.787319660187, 'total_duration': 6597.434686660767, 'accumulated_submission_time': 6273.787319660187, 'accumulated_eval_time': 316.84984970092773, 'accumulated_logging_time': 5.721496343612671}
I0205 03:09:40.816620 139462612883200 logging_writer.py:48] [26896] accumulated_eval_time=316.849850, accumulated_logging_time=5.721496, accumulated_submission_time=6273.787320, global_step=26896, preemption_count=0, score=6273.787320, test/loss=0.286773, test/num_examples=3581, test/ssim=0.742089, total_duration=6597.434687, train/loss=0.266185, train/ssim=0.748400, validation/loss=0.285541, validation/num_examples=3554, validation/ssim=0.724785
I0205 03:09:41.199551 139462604490496 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.0653562843799591, loss=0.23126426339149475
I0205 03:10:04.131045 139462612883200 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.036756958812475204, loss=0.22300241887569427
I0205 03:10:27.982184 139462604490496 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.05293700471520424, loss=0.28382962942123413
I0205 03:10:52.107014 139462612883200 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.06205596774816513, loss=0.35530275106430054
I0205 03:11:00.908696 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:11:02.281094 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:11:03.601920 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:11:04.921825 139681449744192 submission_runner.py:408] Time since start: 6681.56s, 	Step: 27238, 	{'train/ssim': 0.7507381439208984, 'train/loss': 0.2653639316558838, 'validation/ssim': 0.7267112925137169, 'validation/loss': 0.2852600647213087, 'validation/num_examples': 3554, 'test/ssim': 0.743832057429838, 'test/loss': 0.2866217755166155, 'test/num_examples': 3581, 'score': 6353.8551030159, 'total_duration': 6681.561727285385, 'accumulated_submission_time': 6353.8551030159, 'accumulated_eval_time': 320.86294293403625, 'accumulated_logging_time': 5.753942012786865}
I0205 03:11:04.947124 139462604490496 logging_writer.py:48] [27238] accumulated_eval_time=320.862943, accumulated_logging_time=5.753942, accumulated_submission_time=6353.855103, global_step=27238, preemption_count=0, score=6353.855103, test/loss=0.286622, test/num_examples=3581, test/ssim=0.743832, total_duration=6681.561727, train/loss=0.265364, train/ssim=0.750738, validation/loss=0.285260, validation/num_examples=3554, validation/ssim=0.726711
I0205 03:11:17.496934 139462612883200 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.08286425471305847, loss=0.22187945246696472
I0205 03:11:41.733310 139462604490496 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.0390179380774498, loss=0.2605399191379547
I0205 03:12:05.559770 139462612883200 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.04418468102812767, loss=0.3376080393791199
I0205 03:12:25.067604 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:12:26.437896 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:12:27.758449 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:12:29.079401 139681449744192 submission_runner.py:408] Time since start: 6765.72s, 	Step: 27583, 	{'train/ssim': 0.7501236370631627, 'train/loss': 0.2658776044845581, 'validation/ssim': 0.7266756400138928, 'validation/loss': 0.2853921472724395, 'validation/num_examples': 3554, 'test/ssim': 0.7437995371622801, 'test/loss': 0.28667035138796776, 'test/num_examples': 3581, 'score': 6433.951121091843, 'total_duration': 6765.719286441803, 'accumulated_submission_time': 6433.951121091843, 'accumulated_eval_time': 324.87469935417175, 'accumulated_logging_time': 5.79008412361145}
I0205 03:12:29.101487 139462604490496 logging_writer.py:48] [27583] accumulated_eval_time=324.874699, accumulated_logging_time=5.790084, accumulated_submission_time=6433.951121, global_step=27583, preemption_count=0, score=6433.951121, test/loss=0.286670, test/num_examples=3581, test/ssim=0.743800, total_duration=6765.719286, train/loss=0.265878, train/ssim=0.750124, validation/loss=0.285392, validation/num_examples=3554, validation/ssim=0.726676
I0205 03:12:31.180241 139462612883200 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.047371700406074524, loss=0.29956358671188354
I0205 03:12:54.785852 139462604490496 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.052799858152866364, loss=0.37092897295951843
I0205 03:13:18.897151 139462612883200 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.10844391584396362, loss=0.3137863874435425
I0205 03:13:42.675127 139462604490496 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.03423904627561569, loss=0.3057602643966675
I0205 03:13:49.277150 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:13:50.645540 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:13:51.965801 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:13:53.285672 139681449744192 submission_runner.py:408] Time since start: 6849.93s, 	Step: 27929, 	{'train/ssim': 0.749838011605399, 'train/loss': 0.2655642032623291, 'validation/ssim': 0.7262190269766461, 'validation/loss': 0.285093068137354, 'validation/num_examples': 3554, 'test/ssim': 0.7433997492189681, 'test/loss': 0.28635360261842013, 'test/num_examples': 3581, 'score': 6514.103759050369, 'total_duration': 6849.925580263138, 'accumulated_submission_time': 6514.103759050369, 'accumulated_eval_time': 328.8831934928894, 'accumulated_logging_time': 5.821483612060547}
I0205 03:13:53.307645 139462612883200 logging_writer.py:48] [27929] accumulated_eval_time=328.883193, accumulated_logging_time=5.821484, accumulated_submission_time=6514.103759, global_step=27929, preemption_count=0, score=6514.103759, test/loss=0.286354, test/num_examples=3581, test/ssim=0.743400, total_duration=6849.925580, train/loss=0.265564, train/ssim=0.749838, validation/loss=0.285093, validation/num_examples=3554, validation/ssim=0.726219
I0205 03:14:08.051467 139462604490496 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.03988577425479889, loss=0.21225273609161377
I0205 03:14:32.395068 139462612883200 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.07758919149637222, loss=0.21983753144741058
I0205 03:14:56.285656 139462604490496 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.03215976804494858, loss=0.3683037757873535
I0205 03:15:13.500622 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:15:14.869744 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:15:16.190044 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:15:17.508915 139681449744192 submission_runner.py:408] Time since start: 6934.15s, 	Step: 28272, 	{'train/ssim': 0.749901294708252, 'train/loss': 0.26528477668762207, 'validation/ssim': 0.7256960549512873, 'validation/loss': 0.2852201188086927, 'validation/num_examples': 3554, 'test/ssim': 0.7428893105539653, 'test/loss': 0.2865293279635577, 'test/num_examples': 3581, 'score': 6594.274115562439, 'total_duration': 6934.148802280426, 'accumulated_submission_time': 6594.274115562439, 'accumulated_eval_time': 332.8914361000061, 'accumulated_logging_time': 5.852307319641113}
I0205 03:15:17.531545 139462612883200 logging_writer.py:48] [28272] accumulated_eval_time=332.891436, accumulated_logging_time=5.852307, accumulated_submission_time=6594.274116, global_step=28272, preemption_count=0, score=6594.274116, test/loss=0.286529, test/num_examples=3581, test/ssim=0.742889, total_duration=6934.148802, train/loss=0.265285, train/ssim=0.749901, validation/loss=0.285220, validation/num_examples=3554, validation/ssim=0.725696
I0205 03:15:22.076727 139462604490496 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.11407425254583359, loss=0.26468566060066223
I0205 03:15:46.120666 139462612883200 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.0485784076154232, loss=0.2296699732542038
I0205 03:16:10.184195 139462604490496 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.06639101356267929, loss=0.29589420557022095
I0205 03:16:34.010551 139462612883200 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.04269999638199806, loss=0.31307828426361084
I0205 03:16:37.532335 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:16:38.899068 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:16:40.219925 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:16:41.539330 139681449744192 submission_runner.py:408] Time since start: 7018.18s, 	Step: 28616, 	{'train/ssim': 0.7493587221418109, 'train/loss': 0.26545797075544086, 'validation/ssim': 0.7255252801640757, 'validation/loss': 0.28514584276739235, 'validation/num_examples': 3554, 'test/ssim': 0.7427862956183677, 'test/loss': 0.2864145184655124, 'test/num_examples': 3581, 'score': 6674.250906705856, 'total_duration': 7018.179235696793, 'accumulated_submission_time': 6674.250906705856, 'accumulated_eval_time': 336.89839482307434, 'accumulated_logging_time': 5.885340690612793}
I0205 03:16:41.561818 139462604490496 logging_writer.py:48] [28616] accumulated_eval_time=336.898395, accumulated_logging_time=5.885341, accumulated_submission_time=6674.250907, global_step=28616, preemption_count=0, score=6674.250907, test/loss=0.286415, test/num_examples=3581, test/ssim=0.742786, total_duration=7018.179236, train/loss=0.265458, train/ssim=0.749359, validation/loss=0.285146, validation/num_examples=3554, validation/ssim=0.725525
I0205 03:16:59.534642 139462612883200 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.04219500720500946, loss=0.294486403465271
I0205 03:17:23.208038 139462604490496 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.0608624629676342, loss=0.2708342671394348
I0205 03:17:47.008111 139462612883200 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.03899379074573517, loss=0.3040757179260254
I0205 03:18:01.766779 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:18:03.138332 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:18:04.461173 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:18:05.782946 139681449744192 submission_runner.py:408] Time since start: 7102.42s, 	Step: 28963, 	{'train/ssim': 0.7498035430908203, 'train/loss': 0.2655364956174578, 'validation/ssim': 0.7261129625070343, 'validation/loss': 0.2851735782140282, 'validation/num_examples': 3554, 'test/ssim': 0.7433507301993159, 'test/loss': 0.28644724326305504, 'test/num_examples': 3581, 'score': 6754.433007955551, 'total_duration': 7102.422847747803, 'accumulated_submission_time': 6754.433007955551, 'accumulated_eval_time': 340.9145243167877, 'accumulated_logging_time': 5.916884183883667}
I0205 03:18:05.805782 139462604490496 logging_writer.py:48] [28963] accumulated_eval_time=340.914524, accumulated_logging_time=5.916884, accumulated_submission_time=6754.433008, global_step=28963, preemption_count=0, score=6754.433008, test/loss=0.286447, test/num_examples=3581, test/ssim=0.743351, total_duration=7102.422848, train/loss=0.265536, train/ssim=0.749804, validation/loss=0.285174, validation/num_examples=3554, validation/ssim=0.726113
I0205 03:18:12.451428 139462612883200 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.05951959267258644, loss=0.2262999713420868
I0205 03:18:36.189700 139462604490496 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.0625017061829567, loss=0.1857876032590866
I0205 03:19:00.438126 139462612883200 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.10476623475551605, loss=0.18980799615383148
I0205 03:19:24.195776 139462604490496 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.04864346981048584, loss=0.2914729118347168
I0205 03:19:25.813759 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:19:27.185749 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:19:28.504531 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:19:29.825105 139681449744192 submission_runner.py:408] Time since start: 7186.46s, 	Step: 29308, 	{'train/ssim': 0.7496084485735212, 'train/loss': 0.2654083626610892, 'validation/ssim': 0.7259997537985369, 'validation/loss': 0.2850448101775728, 'validation/num_examples': 3554, 'test/ssim': 0.743136519128735, 'test/loss': 0.2863590567513439, 'test/num_examples': 3581, 'score': 6834.417027235031, 'total_duration': 7186.464999914169, 'accumulated_submission_time': 6834.417027235031, 'accumulated_eval_time': 344.9258232116699, 'accumulated_logging_time': 5.949899196624756}
I0205 03:19:29.848448 139462612883200 logging_writer.py:48] [29308] accumulated_eval_time=344.925823, accumulated_logging_time=5.949899, accumulated_submission_time=6834.417027, global_step=29308, preemption_count=0, score=6834.417027, test/loss=0.286359, test/num_examples=3581, test/ssim=0.743137, total_duration=7186.465000, train/loss=0.265408, train/ssim=0.749608, validation/loss=0.285045, validation/num_examples=3554, validation/ssim=0.726000
I0205 03:19:49.835634 139462604490496 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.04092346504330635, loss=0.27994799613952637
I0205 03:20:13.830047 139462612883200 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.044011190533638, loss=0.21383479237556458
I0205 03:20:37.561598 139462604490496 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.07629325985908508, loss=0.25480738282203674
I0205 03:20:49.826617 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:20:51.196090 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:20:52.517627 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:20:53.838336 139681449744192 submission_runner.py:408] Time since start: 7270.48s, 	Step: 29652, 	{'train/ssim': 0.7499695505414691, 'train/loss': 0.2650468349456787, 'validation/ssim': 0.7257326691755768, 'validation/loss': 0.2850546850269942, 'validation/num_examples': 3554, 'test/ssim': 0.7429690772479755, 'test/loss': 0.28630315188887534, 'test/num_examples': 3581, 'score': 6914.371897935867, 'total_duration': 7270.478240966797, 'accumulated_submission_time': 6914.371897935867, 'accumulated_eval_time': 348.9375340938568, 'accumulated_logging_time': 5.982892036437988}
I0205 03:20:53.859963 139462612883200 logging_writer.py:48] [29652] accumulated_eval_time=348.937534, accumulated_logging_time=5.982892, accumulated_submission_time=6914.371898, global_step=29652, preemption_count=0, score=6914.371898, test/loss=0.286303, test/num_examples=3581, test/ssim=0.742969, total_duration=7270.478241, train/loss=0.265047, train/ssim=0.749970, validation/loss=0.285055, validation/num_examples=3554, validation/ssim=0.725733
I0205 03:21:03.143406 139462604490496 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.04200054705142975, loss=0.30646392703056335
I0205 03:21:26.867899 139462612883200 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.045462653040885925, loss=0.28661030530929565
I0205 03:21:50.796768 139462604490496 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.044169243425130844, loss=0.24300752580165863
I0205 03:22:13.863000 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:22:15.233677 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:22:16.554312 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:22:17.874719 139681449744192 submission_runner.py:408] Time since start: 7354.51s, 	Step: 29999, 	{'train/ssim': 0.7508008139474052, 'train/loss': 0.26522018228258404, 'validation/ssim': 0.7267960616558807, 'validation/loss': 0.2850975504603088, 'validation/num_examples': 3554, 'test/ssim': 0.7440159298860305, 'test/loss': 0.28634940975373496, 'test/num_examples': 3581, 'score': 6994.351936340332, 'total_duration': 7354.5146226882935, 'accumulated_submission_time': 6994.351936340332, 'accumulated_eval_time': 352.9492189884186, 'accumulated_logging_time': 6.013725280761719}
I0205 03:22:17.897005 139462612883200 logging_writer.py:48] [29999] accumulated_eval_time=352.949219, accumulated_logging_time=6.013725, accumulated_submission_time=6994.351936, global_step=29999, preemption_count=0, score=6994.351936, test/loss=0.286349, test/num_examples=3581, test/ssim=0.744016, total_duration=7354.514623, train/loss=0.265220, train/ssim=0.750801, validation/loss=0.285098, validation/num_examples=3554, validation/ssim=0.726796
I0205 03:22:18.060506 139462604490496 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.03536919876933098, loss=0.29649078845977783
I0205 03:22:40.319799 139462612883200 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.0448560006916523, loss=0.2367056906223297
I0205 03:23:04.321316 139462604490496 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.05370336398482323, loss=0.27943679690361023
I0205 03:23:28.754638 139462612883200 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.056296348571777344, loss=0.21963843703269958
I0205 03:23:37.947623 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:23:39.319314 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:23:40.636466 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:23:41.954193 139681449744192 submission_runner.py:408] Time since start: 7438.59s, 	Step: 30341, 	{'train/ssim': 0.7502134186880929, 'train/loss': 0.2650173732212612, 'validation/ssim': 0.7262326285083709, 'validation/loss': 0.2848916383828081, 'validation/num_examples': 3554, 'test/ssim': 0.7433912271362748, 'test/loss': 0.2861762069450747, 'test/num_examples': 3581, 'score': 7074.379700660706, 'total_duration': 7438.5940990448, 'accumulated_submission_time': 7074.379700660706, 'accumulated_eval_time': 356.95574593544006, 'accumulated_logging_time': 6.045287609100342}
I0205 03:23:41.976890 139462604490496 logging_writer.py:48] [30341] accumulated_eval_time=356.955746, accumulated_logging_time=6.045288, accumulated_submission_time=7074.379701, global_step=30341, preemption_count=0, score=7074.379701, test/loss=0.286176, test/num_examples=3581, test/ssim=0.743391, total_duration=7438.594099, train/loss=0.265017, train/ssim=0.750213, validation/loss=0.284892, validation/num_examples=3554, validation/ssim=0.726233
I0205 03:23:54.013408 139462612883200 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.08729225397109985, loss=0.25211942195892334
I0205 03:24:17.862304 139462604490496 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.08213622123003006, loss=0.22576113045215607
I0205 03:24:41.604962 139462612883200 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.025576723739504814, loss=0.32256078720092773
I0205 03:25:02.068722 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:25:03.438561 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:25:04.760058 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:25:06.079708 139681449744192 submission_runner.py:408] Time since start: 7522.72s, 	Step: 30688, 	{'train/ssim': 0.7507006100245884, 'train/loss': 0.2646711894444057, 'validation/ssim': 0.7264637171584833, 'validation/loss': 0.284826086556301, 'validation/num_examples': 3554, 'test/ssim': 0.7436298454516894, 'test/loss': 0.2861211542908755, 'test/num_examples': 3581, 'score': 7154.448456525803, 'total_duration': 7522.719612360001, 'accumulated_submission_time': 7154.448456525803, 'accumulated_eval_time': 360.9666941165924, 'accumulated_logging_time': 6.0774827003479}
I0205 03:25:06.102264 139462604490496 logging_writer.py:48] [30688] accumulated_eval_time=360.966694, accumulated_logging_time=6.077483, accumulated_submission_time=7154.448457, global_step=30688, preemption_count=0, score=7154.448457, test/loss=0.286121, test/num_examples=3581, test/ssim=0.743630, total_duration=7522.719612, train/loss=0.264671, train/ssim=0.750701, validation/loss=0.284826, validation/num_examples=3554, validation/ssim=0.726464
I0205 03:25:07.057316 139462612883200 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.037957727909088135, loss=0.2912777364253998
I0205 03:25:30.645205 139462604490496 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.049569182097911835, loss=0.35710805654525757
I0205 03:25:54.198306 139462612883200 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.03409789130091667, loss=0.2105116844177246
I0205 03:26:18.110577 139462604490496 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.022465381771326065, loss=0.2757646441459656
I0205 03:26:26.270831 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:26:27.643287 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:26:28.963740 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:26:30.282117 139681449744192 submission_runner.py:408] Time since start: 7606.92s, 	Step: 31036, 	{'train/ssim': 0.750760691506522, 'train/loss': 0.26485397134508404, 'validation/ssim': 0.7266390944842079, 'validation/loss': 0.28487082391759283, 'validation/num_examples': 3554, 'test/ssim': 0.7438296712466839, 'test/loss': 0.2861302217868612, 'test/num_examples': 3581, 'score': 7234.592389583588, 'total_duration': 7606.922004938126, 'accumulated_submission_time': 7234.592389583588, 'accumulated_eval_time': 364.9779260158539, 'accumulated_logging_time': 6.110843896865845}
I0205 03:26:30.304370 139462612883200 logging_writer.py:48] [31036] accumulated_eval_time=364.977926, accumulated_logging_time=6.110844, accumulated_submission_time=7234.592390, global_step=31036, preemption_count=0, score=7234.592390, test/loss=0.286130, test/num_examples=3581, test/ssim=0.743830, total_duration=7606.922005, train/loss=0.264854, train/ssim=0.750761, validation/loss=0.284871, validation/num_examples=3554, validation/ssim=0.726639
I0205 03:26:43.371623 139462604490496 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.03776197507977486, loss=0.20042406022548676
I0205 03:27:07.355713 139462612883200 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.05989312380552292, loss=0.21587210893630981
I0205 03:27:31.109705 139462604490496 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.04327138885855675, loss=0.33905714750289917
I0205 03:27:50.455101 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:27:51.827681 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:27:53.147836 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:27:54.470310 139681449744192 submission_runner.py:408] Time since start: 7691.11s, 	Step: 31381, 	{'train/ssim': 0.7507956368582589, 'train/loss': 0.26478144100734163, 'validation/ssim': 0.7267478380434018, 'validation/loss': 0.28474595429995253, 'validation/num_examples': 3554, 'test/ssim': 0.7439185736133412, 'test/loss': 0.28599553879197503, 'test/num_examples': 3581, 'score': 7314.720451116562, 'total_duration': 7691.110218048096, 'accumulated_submission_time': 7314.720451116562, 'accumulated_eval_time': 368.99309515953064, 'accumulated_logging_time': 6.142259836196899}
I0205 03:27:54.493015 139462612883200 logging_writer.py:48] [31381] accumulated_eval_time=368.993095, accumulated_logging_time=6.142260, accumulated_submission_time=7314.720451, global_step=31381, preemption_count=0, score=7314.720451, test/loss=0.285996, test/num_examples=3581, test/ssim=0.743919, total_duration=7691.110218, train/loss=0.264781, train/ssim=0.750796, validation/loss=0.284746, validation/num_examples=3554, validation/ssim=0.726748
I0205 03:27:56.886828 139462604490496 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.06630708277225494, loss=0.21994858980178833
I0205 03:28:20.866549 139462612883200 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.06754117459058762, loss=0.261415034532547
I0205 03:28:44.456583 139462604490496 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.024640021845698357, loss=0.21866415441036224
I0205 03:29:08.219147 139462612883200 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.030717339366674423, loss=0.2356569617986679
I0205 03:29:14.522741 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:29:15.893723 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:29:17.213570 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:29:18.534317 139681449744192 submission_runner.py:408] Time since start: 7775.17s, 	Step: 31728, 	{'train/ssim': 0.751133850642613, 'train/loss': 0.2644347974232265, 'validation/ssim': 0.7264723039840673, 'validation/loss': 0.2848719573785699, 'validation/num_examples': 3554, 'test/ssim': 0.743655343523108, 'test/loss': 0.2861455615357093, 'test/num_examples': 3581, 'score': 7394.727523565292, 'total_duration': 7775.174228429794, 'accumulated_submission_time': 7394.727523565292, 'accumulated_eval_time': 373.00463938713074, 'accumulated_logging_time': 6.173776626586914}
I0205 03:29:18.557056 139462604490496 logging_writer.py:48] [31728] accumulated_eval_time=373.004639, accumulated_logging_time=6.173777, accumulated_submission_time=7394.727524, global_step=31728, preemption_count=0, score=7394.727524, test/loss=0.286146, test/num_examples=3581, test/ssim=0.743655, total_duration=7775.174228, train/loss=0.264435, train/ssim=0.751134, validation/loss=0.284872, validation/num_examples=3554, validation/ssim=0.726472
I0205 03:29:33.689015 139462612883200 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.0661611258983612, loss=0.21908272802829742
I0205 03:29:57.575171 139462604490496 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.025841251015663147, loss=0.3054301142692566
I0205 03:30:21.410399 139462612883200 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.05549202114343643, loss=0.19069182872772217
I0205 03:30:38.702554 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:30:40.077993 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:30:41.397734 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:30:42.718085 139681449744192 submission_runner.py:408] Time since start: 7859.36s, 	Step: 32074, 	{'train/ssim': 0.7505387578691755, 'train/loss': 0.2645878280912127, 'validation/ssim': 0.7262119514323649, 'validation/loss': 0.2847132041471757, 'validation/num_examples': 3554, 'test/ssim': 0.7434837428659942, 'test/loss': 0.2859557236216315, 'test/num_examples': 3581, 'score': 7474.850043296814, 'total_duration': 7859.357992172241, 'accumulated_submission_time': 7474.850043296814, 'accumulated_eval_time': 377.02014422416687, 'accumulated_logging_time': 6.205841541290283}
I0205 03:30:42.741025 139462604490496 logging_writer.py:48] [32074] accumulated_eval_time=377.020144, accumulated_logging_time=6.205842, accumulated_submission_time=7474.850043, global_step=32074, preemption_count=0, score=7474.850043, test/loss=0.285956, test/num_examples=3581, test/ssim=0.743484, total_duration=7859.357992, train/loss=0.264588, train/ssim=0.750539, validation/loss=0.284713, validation/num_examples=3554, validation/ssim=0.726212
I0205 03:30:46.942891 139462612883200 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.033687885850667953, loss=0.32723861932754517
I0205 03:31:10.820014 139462604490496 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.02197185531258583, loss=0.321968138217926
I0205 03:31:34.855610 139462612883200 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.0352371409535408, loss=0.2953207492828369
I0205 03:31:58.834099 139462604490496 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.028929634019732475, loss=0.26865503191947937
I0205 03:32:02.863545 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:32:04.233553 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:32:05.554328 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:32:06.872271 139681449744192 submission_runner.py:408] Time since start: 7943.51s, 	Step: 32417, 	{'train/ssim': 0.7507827622549874, 'train/loss': 0.26464855670928955, 'validation/ssim': 0.7266321563291361, 'validation/loss': 0.2846971467833339, 'validation/num_examples': 3554, 'test/ssim': 0.7438118089613586, 'test/loss': 0.28595545091498537, 'test/num_examples': 3581, 'score': 7554.948711395264, 'total_duration': 7943.512165546417, 'accumulated_submission_time': 7554.948711395264, 'accumulated_eval_time': 381.02881836891174, 'accumulated_logging_time': 6.23901629447937}
I0205 03:32:06.895683 139462612883200 logging_writer.py:48] [32417] accumulated_eval_time=381.028818, accumulated_logging_time=6.239016, accumulated_submission_time=7554.948711, global_step=32417, preemption_count=0, score=7554.948711, test/loss=0.285955, test/num_examples=3581, test/ssim=0.743812, total_duration=7943.512166, train/loss=0.264649, train/ssim=0.750783, validation/loss=0.284697, validation/num_examples=3554, validation/ssim=0.726632
I0205 03:32:24.843848 139462604490496 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.017624830827116966, loss=0.24977073073387146
I0205 03:32:48.507523 139462612883200 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.01916804537177086, loss=0.2337161898612976
I0205 03:33:12.566518 139462604490496 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.02447744645178318, loss=0.24723556637763977
I0205 03:33:27.030653 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:33:28.401522 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:33:29.720663 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:33:31.041779 139681449744192 submission_runner.py:408] Time since start: 8027.68s, 	Step: 32762, 	{'train/ssim': 0.7513869830540248, 'train/loss': 0.2641993931361607, 'validation/ssim': 0.7267633630240574, 'validation/loss': 0.28467150652214057, 'validation/num_examples': 3554, 'test/ssim': 0.7439133921870636, 'test/loss': 0.28595453053005443, 'test/num_examples': 3581, 'score': 7635.059431314468, 'total_duration': 8027.681664466858, 'accumulated_submission_time': 7635.059431314468, 'accumulated_eval_time': 385.0398862361908, 'accumulated_logging_time': 6.273144245147705}
I0205 03:33:31.064374 139462612883200 logging_writer.py:48] [32762] accumulated_eval_time=385.039886, accumulated_logging_time=6.273144, accumulated_submission_time=7635.059431, global_step=32762, preemption_count=0, score=7635.059431, test/loss=0.285955, test/num_examples=3581, test/ssim=0.743913, total_duration=8027.681664, train/loss=0.264199, train/ssim=0.751387, validation/loss=0.284672, validation/num_examples=3554, validation/ssim=0.726763
I0205 03:33:38.100102 139462604490496 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.023012852296233177, loss=0.23229286074638367
I0205 03:34:02.171500 139462612883200 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.02600868046283722, loss=0.21409112215042114
I0205 03:34:25.881629 139462604490496 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.022527558729052544, loss=0.21421761810779572
I0205 03:34:49.765207 139462612883200 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.02255776710808277, loss=0.23462267220020294
I0205 03:34:51.064314 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:34:52.436399 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:34:53.756669 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:34:55.079683 139681449744192 submission_runner.py:408] Time since start: 8111.72s, 	Step: 33107, 	{'train/ssim': 0.7509965215410505, 'train/loss': 0.2644737107413156, 'validation/ssim': 0.7265825588245639, 'validation/loss': 0.28466851830683737, 'validation/num_examples': 3554, 'test/ssim': 0.7437964010358489, 'test/loss': 0.2859292881211167, 'test/num_examples': 3581, 'score': 7715.03692984581, 'total_duration': 8111.719587564468, 'accumulated_submission_time': 7715.03692984581, 'accumulated_eval_time': 389.0552260875702, 'accumulated_logging_time': 6.30461573600769}
I0205 03:34:55.106721 139462604490496 logging_writer.py:48] [33107] accumulated_eval_time=389.055226, accumulated_logging_time=6.304616, accumulated_submission_time=7715.036930, global_step=33107, preemption_count=0, score=7715.036930, test/loss=0.285929, test/num_examples=3581, test/ssim=0.743796, total_duration=8111.719588, train/loss=0.264474, train/ssim=0.750997, validation/loss=0.284669, validation/num_examples=3554, validation/ssim=0.726583
I0205 03:35:15.285973 139462612883200 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.022478969767689705, loss=0.2887905538082123
I0205 03:35:39.180171 139462604490496 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.016325216740369797, loss=0.32201769948005676
I0205 03:36:02.941454 139462612883200 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.01448418851941824, loss=0.2641150951385498
I0205 03:36:15.088856 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:36:16.460688 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:36:17.781593 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:36:19.102621 139681449744192 submission_runner.py:408] Time since start: 8195.74s, 	Step: 33451, 	{'train/ssim': 0.7508912086486816, 'train/loss': 0.26448542731148855, 'validation/ssim': 0.7264931184492825, 'validation/loss': 0.28466446532516176, 'validation/num_examples': 3554, 'test/ssim': 0.7437085213191148, 'test/loss': 0.2859337366482826, 'test/num_examples': 3581, 'score': 7794.994208097458, 'total_duration': 8195.742512226105, 'accumulated_submission_time': 7794.994208097458, 'accumulated_eval_time': 393.0689616203308, 'accumulated_logging_time': 6.34293532371521}
I0205 03:36:19.127272 139462604490496 logging_writer.py:48] [33451] accumulated_eval_time=393.068962, accumulated_logging_time=6.342935, accumulated_submission_time=7794.994208, global_step=33451, preemption_count=0, score=7794.994208, test/loss=0.285934, test/num_examples=3581, test/ssim=0.743709, total_duration=8195.742512, train/loss=0.264485, train/ssim=0.750891, validation/loss=0.284664, validation/num_examples=3554, validation/ssim=0.726493
I0205 03:36:28.898800 139462612883200 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.02426196075975895, loss=0.22226646542549133
I0205 03:36:52.995945 139462604490496 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.02530924417078495, loss=0.2984749972820282
I0205 03:37:17.183846 139462612883200 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.026796851307153702, loss=0.24912437796592712
I0205 03:37:39.201462 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:37:40.572379 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:37:41.891999 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:37:43.211031 139681449744192 submission_runner.py:408] Time since start: 8279.85s, 	Step: 33794, 	{'train/ssim': 0.7513776506696429, 'train/loss': 0.26415651185171946, 'validation/ssim': 0.726762607383406, 'validation/loss': 0.284640010045899, 'validation/num_examples': 3554, 'test/ssim': 0.7439062336376012, 'test/loss': 0.28593636144975215, 'test/num_examples': 3581, 'score': 7875.045525312424, 'total_duration': 8279.850937843323, 'accumulated_submission_time': 7875.045525312424, 'accumulated_eval_time': 397.07849621772766, 'accumulated_logging_time': 6.376688718795776}
I0205 03:37:43.234876 139462604490496 logging_writer.py:48] [33794] accumulated_eval_time=397.078496, accumulated_logging_time=6.376689, accumulated_submission_time=7875.045525, global_step=33794, preemption_count=0, score=7875.045525, test/loss=0.285936, test/num_examples=3581, test/ssim=0.743906, total_duration=8279.850938, train/loss=0.264157, train/ssim=0.751378, validation/loss=0.284640, validation/num_examples=3554, validation/ssim=0.726763
I0205 03:37:43.761011 139462612883200 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.01709628850221634, loss=0.23839214444160461
I0205 03:38:06.453860 139462604490496 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.0180653166025877, loss=0.2858318090438843
I0205 03:38:30.301860 139462612883200 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.02672405168414116, loss=0.39730405807495117
I0205 03:38:54.074797 139462604490496 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.02704514004290104, loss=0.21725225448608398
I0205 03:39:03.319972 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:39:04.689389 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:39:06.009144 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:39:07.329521 139681449744192 submission_runner.py:408] Time since start: 8363.97s, 	Step: 34140, 	{'train/ssim': 0.7512272426060268, 'train/loss': 0.2642498016357422, 'validation/ssim': 0.7266439031065349, 'validation/loss': 0.28463939179445696, 'validation/num_examples': 3554, 'test/ssim': 0.7438452155255166, 'test/loss': 0.28590491496461357, 'test/num_examples': 3581, 'score': 7955.107652187347, 'total_duration': 8363.969428777695, 'accumulated_submission_time': 7955.107652187347, 'accumulated_eval_time': 401.0880081653595, 'accumulated_logging_time': 6.409821510314941}
I0205 03:39:07.352751 139462612883200 logging_writer.py:48] [34140] accumulated_eval_time=401.088008, accumulated_logging_time=6.409822, accumulated_submission_time=7955.107652, global_step=34140, preemption_count=0, score=7955.107652, test/loss=0.285905, test/num_examples=3581, test/ssim=0.743845, total_duration=8363.969429, train/loss=0.264250, train/ssim=0.751227, validation/loss=0.284639, validation/num_examples=3554, validation/ssim=0.726644
I0205 03:39:19.728844 139462604490496 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.018421215936541557, loss=0.31162914633750916
I0205 03:39:43.790563 139462612883200 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.0199122317135334, loss=0.2353408932685852
I0205 03:40:07.537055 139462604490496 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.017959296703338623, loss=0.2066873461008072
I0205 03:40:27.487355 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:40:28.860119 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:40:30.179658 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:40:31.500095 139681449744192 submission_runner.py:408] Time since start: 8448.14s, 	Step: 34485, 	{'train/ssim': 0.7511179787772042, 'train/loss': 0.2643188067844936, 'validation/ssim': 0.7266925388866418, 'validation/loss': 0.28458929625400076, 'validation/num_examples': 3554, 'test/ssim': 0.7438459654687937, 'test/loss': 0.28584766361307945, 'test/num_examples': 3581, 'score': 8035.217735528946, 'total_duration': 8448.139996290207, 'accumulated_submission_time': 8035.217735528946, 'accumulated_eval_time': 405.10070538520813, 'accumulated_logging_time': 6.443702220916748}
I0205 03:40:31.524558 139462612883200 logging_writer.py:48] [34485] accumulated_eval_time=405.100705, accumulated_logging_time=6.443702, accumulated_submission_time=8035.217736, global_step=34485, preemption_count=0, score=8035.217736, test/loss=0.285848, test/num_examples=3581, test/ssim=0.743846, total_duration=8448.139996, train/loss=0.264319, train/ssim=0.751118, validation/loss=0.284589, validation/num_examples=3554, validation/ssim=0.726693
I0205 03:40:33.006542 139462604490496 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.02413160167634487, loss=0.2392083704471588
I0205 03:40:57.155575 139462612883200 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.020863816142082214, loss=0.24269191920757294
I0205 03:41:21.117167 139462604490496 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.05776163935661316, loss=0.35152122378349304
I0205 03:41:45.250570 139462612883200 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.01749555952847004, loss=0.314075231552124
I0205 03:41:51.662576 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:41:53.033198 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:41:54.352722 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:41:55.673547 139681449744192 submission_runner.py:408] Time since start: 8532.31s, 	Step: 34828, 	{'train/ssim': 0.7513903209141323, 'train/loss': 0.26417223044804167, 'validation/ssim': 0.7267753158852701, 'validation/loss': 0.284604168635912, 'validation/num_examples': 3554, 'test/ssim': 0.7439223233297263, 'test/loss': 0.2859044888604789, 'test/num_examples': 3581, 'score': 8115.333026409149, 'total_duration': 8532.313452720642, 'accumulated_submission_time': 8115.333026409149, 'accumulated_eval_time': 409.1116394996643, 'accumulated_logging_time': 6.4771833419799805}
I0205 03:41:55.697195 139462604490496 logging_writer.py:48] [34828] accumulated_eval_time=409.111639, accumulated_logging_time=6.477183, accumulated_submission_time=8115.333026, global_step=34828, preemption_count=0, score=8115.333026, test/loss=0.285904, test/num_examples=3581, test/ssim=0.743922, total_duration=8532.313453, train/loss=0.264172, train/ssim=0.751390, validation/loss=0.284604, validation/num_examples=3554, validation/ssim=0.726775
I0205 03:42:10.711754 139462612883200 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.02583405375480652, loss=0.1786409616470337
I0205 03:42:34.540147 139462604490496 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.021210430189967155, loss=0.2401200830936432
I0205 03:42:58.542328 139462612883200 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.020387180149555206, loss=0.22031722962856293
I0205 03:43:15.805269 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:43:17.175074 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:43:18.496189 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:43:19.815371 139681449744192 submission_runner.py:408] Time since start: 8616.46s, 	Step: 35173, 	{'train/ssim': 0.7513918195452008, 'train/loss': 0.2641371658870152, 'validation/ssim': 0.7268032058947664, 'validation/loss': 0.28455235573033905, 'validation/num_examples': 3554, 'test/ssim': 0.7439750238891022, 'test/loss': 0.28583968694367845, 'test/num_examples': 3581, 'score': 8195.418248653412, 'total_duration': 8616.45526599884, 'accumulated_submission_time': 8195.418248653412, 'accumulated_eval_time': 413.12169218063354, 'accumulated_logging_time': 6.510056257247925}
I0205 03:43:19.839384 139462604490496 logging_writer.py:48] [35173] accumulated_eval_time=413.121692, accumulated_logging_time=6.510056, accumulated_submission_time=8195.418249, global_step=35173, preemption_count=0, score=8195.418249, test/loss=0.285840, test/num_examples=3581, test/ssim=0.743975, total_duration=8616.455266, train/loss=0.264137, train/ssim=0.751392, validation/loss=0.284552, validation/num_examples=3554, validation/ssim=0.726803
I0205 03:43:24.117621 139462612883200 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.013102603144943714, loss=0.2171747386455536
I0205 03:43:47.790864 139462604490496 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.01758706569671631, loss=0.2900393307209015
I0205 03:44:11.724080 139462612883200 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.01683473028242588, loss=0.2459717094898224
I0205 03:44:35.616535 139462604490496 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.01722477562725544, loss=0.3187200427055359
I0205 03:44:39.892524 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:44:41.262604 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:44:42.583017 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:44:43.904515 139681449744192 submission_runner.py:408] Time since start: 8700.54s, 	Step: 35519, 	{'train/ssim': 0.751441410609654, 'train/loss': 0.26416036060878206, 'validation/ssim': 0.7268765717325548, 'validation/loss': 0.284526028523099, 'validation/num_examples': 3554, 'test/ssim': 0.7440558132330355, 'test/loss': 0.28581664323207556, 'test/num_examples': 3581, 'score': 8275.447546958923, 'total_duration': 8700.54442024231, 'accumulated_submission_time': 8275.447546958923, 'accumulated_eval_time': 417.1336545944214, 'accumulated_logging_time': 6.544367790222168}
I0205 03:44:43.929315 139462612883200 logging_writer.py:48] [35519] accumulated_eval_time=417.133655, accumulated_logging_time=6.544368, accumulated_submission_time=8275.447547, global_step=35519, preemption_count=0, score=8275.447547, test/loss=0.285817, test/num_examples=3581, test/ssim=0.744056, total_duration=8700.544420, train/loss=0.264160, train/ssim=0.751441, validation/loss=0.284526, validation/num_examples=3554, validation/ssim=0.726877
I0205 03:45:01.251554 139462604490496 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.01659229025244713, loss=0.20208849012851715
I0205 03:45:25.518660 139462612883200 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.024763552471995354, loss=0.2090148627758026
I0205 03:45:49.099691 139462604490496 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.029678689315915108, loss=0.2351846694946289
I0205 03:46:03.951277 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:46:05.321341 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:46:06.643658 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:46:07.963737 139681449744192 submission_runner.py:408] Time since start: 8784.60s, 	Step: 35863, 	{'train/ssim': 0.751368590763637, 'train/loss': 0.26414031641823904, 'validation/ssim': 0.7268266994495639, 'validation/loss': 0.2844962150646719, 'validation/num_examples': 3554, 'test/ssim': 0.7440089758665527, 'test/loss': 0.2857884180941951, 'test/num_examples': 3581, 'score': 8355.44581079483, 'total_duration': 8784.603637218475, 'accumulated_submission_time': 8355.44581079483, 'accumulated_eval_time': 421.14607095718384, 'accumulated_logging_time': 6.579448938369751}
I0205 03:46:07.987891 139462612883200 logging_writer.py:48] [35863] accumulated_eval_time=421.146071, accumulated_logging_time=6.579449, accumulated_submission_time=8355.445811, global_step=35863, preemption_count=0, score=8355.445811, test/loss=0.285788, test/num_examples=3581, test/ssim=0.744009, total_duration=8784.603637, train/loss=0.264140, train/ssim=0.751369, validation/loss=0.284496, validation/num_examples=3554, validation/ssim=0.726827
I0205 03:46:14.726498 139462604490496 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.018733251839876175, loss=0.19046233594417572
I0205 03:46:38.388071 139462612883200 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.02090650610625744, loss=0.30206969380378723
I0205 03:47:02.167104 139462604490496 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.015121040865778923, loss=0.2444370537996292
I0205 03:47:23.157714 139681449744192 spec.py:321] Evaluating on the training split.
I0205 03:47:24.526954 139681449744192 spec.py:333] Evaluating on the validation split.
I0205 03:47:25.846298 139681449744192 spec.py:349] Evaluating on the test split.
I0205 03:47:27.168184 139681449744192 submission_runner.py:408] Time since start: 8863.81s, 	Step: 36189, 	{'train/ssim': 0.7514665467398507, 'train/loss': 0.26413134166172575, 'validation/ssim': 0.7269076903884707, 'validation/loss': 0.28450164193844085, 'validation/num_examples': 3554, 'test/ssim': 0.744079675064577, 'test/loss': 0.28579595161529603, 'test/num_examples': 3581, 'score': 8430.592392921448, 'total_duration': 8863.808090209961, 'accumulated_submission_time': 8430.592392921448, 'accumulated_eval_time': 425.1565029621124, 'accumulated_logging_time': 6.6140077114105225}
I0205 03:47:27.192406 139462612883200 logging_writer.py:48] [36189] accumulated_eval_time=425.156503, accumulated_logging_time=6.614008, accumulated_submission_time=8430.592393, global_step=36189, preemption_count=0, score=8430.592393, test/loss=0.285796, test/num_examples=3581, test/ssim=0.744080, total_duration=8863.808090, train/loss=0.264131, train/ssim=0.751467, validation/loss=0.284502, validation/num_examples=3554, validation/ssim=0.726908
I0205 03:47:27.213104 139462604490496 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8430.592393
I0205 03:47:27.260205 139681449744192 checkpoints.py:490] Saving checkpoint at step: 36189
I0205 03:47:27.456368 139681449744192 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4/checkpoint_36189
I0205 03:47:27.457121 139681449744192 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_4/checkpoint_36189.
I0205 03:47:28.071078 139681449744192 submission_runner.py:583] Tuning trial 4/5
I0205 03:47:28.071361 139681449744192 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0205 03:47:28.078733 139681449744192 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.19754627772739955, 'train/loss': 1.0327176366533553, 'validation/ssim': 0.18975977771525043, 'validation/loss': 1.0370871866426914, 'validation/num_examples': 3554, 'test/ssim': 0.21284559431504818, 'test/loss': 1.0323986403937448, 'test/num_examples': 3581, 'score': 31.401532649993896, 'total_duration': 35.358983516693115, 'accumulated_submission_time': 31.401532649993896, 'accumulated_eval_time': 3.9573137760162354, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (342, {'train/ssim': 0.7213667460850307, 'train/loss': 0.29259068625313894, 'validation/ssim': 0.7017441697515123, 'validation/loss': 0.31035226318496767, 'validation/num_examples': 3554, 'test/ssim': 0.7183853912140463, 'test/loss': 0.31235365879598925, 'test/num_examples': 3581, 'score': 111.60064959526062, 'total_duration': 119.59745144844055, 'accumulated_submission_time': 111.60064959526062, 'accumulated_eval_time': 7.96499228477478, 'accumulated_logging_time': 0.017967939376831055, 'global_step': 342, 'preemption_count': 0}), (682, {'train/ssim': 0.7287031582423619, 'train/loss': 0.28311089106968473, 'validation/ssim': 0.7073842715734032, 'validation/loss': 0.3006681786807119, 'validation/num_examples': 3554, 'test/ssim': 0.7247404105434935, 'test/loss': 0.30215337349029603, 'test/num_examples': 3581, 'score': 191.57904171943665, 'total_duration': 203.62491083145142, 'accumulated_submission_time': 191.57904171943665, 'accumulated_eval_time': 11.974652290344238, 'accumulated_logging_time': 0.044046878814697266, 'global_step': 682, 'preemption_count': 0}), (1019, {'train/ssim': 0.7273684910365513, 'train/loss': 0.28053527218954905, 'validation/ssim': 0.7060646482176772, 'validation/loss': 0.29812266575733326, 'validation/num_examples': 3554, 'test/ssim': 0.7234966637068906, 'test/loss': 0.29965684640943524, 'test/num_examples': 3581, 'score': 271.53961205482483, 'total_duration': 287.6374468803406, 'accumulated_submission_time': 271.53961205482483, 'accumulated_eval_time': 15.98682451248169, 'accumulated_logging_time': 0.07003068923950195, 'global_step': 1019, 'preemption_count': 0}), (1366, {'train/ssim': 0.7377146993364606, 'train/loss': 0.27565182958330425, 'validation/ssim': 0.715898143487092, 'validation/loss': 0.2935038809703855, 'validation/num_examples': 3554, 'test/ssim': 0.7332023614213907, 'test/loss': 0.29500624361866445, 'test/num_examples': 3581, 'score': 351.7352349758148, 'total_duration': 371.88407588005066, 'accumulated_submission_time': 351.7352349758148, 'accumulated_eval_time': 19.99767827987671, 'accumulated_logging_time': 0.09582114219665527, 'global_step': 1366, 'preemption_count': 0}), (1710, {'train/ssim': 0.7396605355398995, 'train/loss': 0.2755191666739328, 'validation/ssim': 0.7181294816360088, 'validation/loss': 0.29322625172560846, 'validation/num_examples': 3554, 'test/ssim': 0.7352617738367425, 'test/loss': 0.2947562738891022, 'test/num_examples': 3581, 'score': 431.7387228012085, 'total_duration': 455.9366509914398, 'accumulated_submission_time': 431.7387228012085, 'accumulated_eval_time': 24.006880521774292, 'accumulated_logging_time': 0.1219170093536377, 'global_step': 1710, 'preemption_count': 0}), (2054, {'train/ssim': 0.736421925680978, 'train/loss': 0.2752586773463658, 'validation/ssim': 0.7134809177379361, 'validation/loss': 0.2937887574959553, 'validation/num_examples': 3554, 'test/ssim': 0.73088387769216, 'test/loss': 0.29537160234789517, 'test/num_examples': 3581, 'score': 511.8938019275665, 'total_duration': 540.144252538681, 'accumulated_submission_time': 511.8938019275665, 'accumulated_eval_time': 28.021103382110596, 'accumulated_logging_time': 0.14649391174316406, 'global_step': 2054, 'preemption_count': 0}), (2401, {'train/ssim': 0.7367238317217145, 'train/loss': 0.2788510152271816, 'validation/ssim': 0.7148442308622327, 'validation/loss': 0.29763015978914603, 'validation/num_examples': 3554, 'test/ssim': 0.7316117317308364, 'test/loss': 0.2993610619633133, 'test/num_examples': 3581, 'score': 591.8965113162994, 'total_duration': 624.146678686142, 'accumulated_submission_time': 591.8965113162994, 'accumulated_eval_time': 31.982479333877563, 'accumulated_logging_time': 0.17116355895996094, 'global_step': 2401, 'preemption_count': 0}), (2748, {'train/ssim': 0.7392657143729073, 'train/loss': 0.2730081421988351, 'validation/ssim': 0.7169806330674944, 'validation/loss': 0.29130486363296637, 'validation/num_examples': 3554, 'test/ssim': 0.7344828554785674, 'test/loss': 0.2926768857119171, 'test/num_examples': 3581, 'score': 671.9206922054291, 'total_duration': 708.2232940196991, 'accumulated_submission_time': 671.9206922054291, 'accumulated_eval_time': 35.997042179107666, 'accumulated_logging_time': 0.19508838653564453, 'global_step': 2748, 'preemption_count': 0}), (3094, {'train/ssim': 0.7426317759922573, 'train/loss': 0.2729813711983817, 'validation/ssim': 0.7201212130038337, 'validation/loss': 0.29116208189715814, 'validation/num_examples': 3554, 'test/ssim': 0.7372292159356674, 'test/loss': 0.29278593428206157, 'test/num_examples': 3581, 'score': 751.973610162735, 'total_duration': 792.3318250179291, 'accumulated_submission_time': 751.973610162735, 'accumulated_eval_time': 40.014914989471436, 'accumulated_logging_time': 0.21890044212341309, 'global_step': 3094, 'preemption_count': 0}), (3441, {'train/ssim': 0.742382322038923, 'train/loss': 0.2722130332674299, 'validation/ssim': 0.7201152365732274, 'validation/loss': 0.2907499142691334, 'validation/num_examples': 3554, 'test/ssim': 0.7372187167297891, 'test/loss': 0.2922184317513439, 'test/num_examples': 3581, 'score': 832.1201596260071, 'total_duration': 876.5295839309692, 'accumulated_submission_time': 832.1201596260071, 'accumulated_eval_time': 44.0278480052948, 'accumulated_logging_time': 0.2433154582977295, 'global_step': 3441, 'preemption_count': 0}), (3788, {'train/ssim': 0.7390454837254116, 'train/loss': 0.27307660239083426, 'validation/ssim': 0.7167553147641742, 'validation/loss': 0.2911471751679446, 'validation/num_examples': 3554, 'test/ssim': 0.734154175793249, 'test/loss': 0.2925956532196837, 'test/num_examples': 3581, 'score': 912.2310099601746, 'total_duration': 960.6932737827301, 'accumulated_submission_time': 912.2310099601746, 'accumulated_eval_time': 48.04212021827698, 'accumulated_logging_time': 0.2679710388183594, 'global_step': 3788, 'preemption_count': 0}), (4135, {'train/ssim': 0.7394935062953404, 'train/loss': 0.2732838732855661, 'validation/ssim': 0.7192164363657146, 'validation/loss': 0.2911408552643149, 'validation/num_examples': 3554, 'test/ssim': 0.7359224056871335, 'test/loss': 0.2926088454036931, 'test/num_examples': 3581, 'score': 992.3586266040802, 'total_duration': 1044.8746247291565, 'accumulated_submission_time': 992.3586266040802, 'accumulated_eval_time': 52.056846380233765, 'accumulated_logging_time': 0.29309511184692383, 'global_step': 4135, 'preemption_count': 0}), (4480, {'train/ssim': 0.7384296144757952, 'train/loss': 0.2730314220700945, 'validation/ssim': 0.7167116249956036, 'validation/loss': 0.2914937394485087, 'validation/num_examples': 3554, 'test/ssim': 0.7337420478741972, 'test/loss': 0.29308267320144515, 'test/num_examples': 3581, 'score': 1072.3675737380981, 'total_duration': 1128.9326810836792, 'accumulated_submission_time': 1072.3675737380981, 'accumulated_eval_time': 56.066534996032715, 'accumulated_logging_time': 0.318572998046875, 'global_step': 4480, 'preemption_count': 0}), (4826, {'train/ssim': 0.7417031696864537, 'train/loss': 0.2724244935171945, 'validation/ssim': 0.7190104899409117, 'validation/loss': 0.29098567415236354, 'validation/num_examples': 3554, 'test/ssim': 0.7363882568154845, 'test/loss': 0.29234339957195965, 'test/num_examples': 3581, 'score': 1152.3579506874084, 'total_duration': 1212.9758560657501, 'accumulated_submission_time': 1152.3579506874084, 'accumulated_eval_time': 60.07899618148804, 'accumulated_logging_time': 0.3449559211730957, 'global_step': 4826, 'preemption_count': 0}), (5173, {'train/ssim': 0.7403593744550433, 'train/loss': 0.2726188898086548, 'validation/ssim': 0.7179201004809721, 'validation/loss': 0.2907309202109419, 'validation/num_examples': 3554, 'test/ssim': 0.7354368515035954, 'test/loss': 0.2921543116011589, 'test/num_examples': 3581, 'score': 1232.4112536907196, 'total_duration': 1297.0824031829834, 'accumulated_submission_time': 1232.4112536907196, 'accumulated_eval_time': 64.09178137779236, 'accumulated_logging_time': 0.37175941467285156, 'global_step': 5173, 'preemption_count': 0}), (5515, {'train/ssim': 0.7342469351632255, 'train/loss': 0.2744945628302438, 'validation/ssim': 0.7122155631199001, 'validation/loss': 0.29285718996201465, 'validation/num_examples': 3554, 'test/ssim': 0.7297423958478777, 'test/loss': 0.2941171858637601, 'test/num_examples': 3581, 'score': 1312.3778328895569, 'total_duration': 1381.1000657081604, 'accumulated_submission_time': 1312.3778328895569, 'accumulated_eval_time': 68.104318857193, 'accumulated_logging_time': 0.39670896530151367, 'global_step': 5515, 'preemption_count': 0}), (5861, {'train/ssim': 0.741619518824986, 'train/loss': 0.27338084152766634, 'validation/ssim': 0.7192837570782921, 'validation/loss': 0.29188608868308596, 'validation/num_examples': 3554, 'test/ssim': 0.7366074447823583, 'test/loss': 0.2932253669540631, 'test/num_examples': 3581, 'score': 1392.5162916183472, 'total_duration': 1465.2908942699432, 'accumulated_submission_time': 1392.5162916183472, 'accumulated_eval_time': 72.11777949333191, 'accumulated_logging_time': 0.42174696922302246, 'global_step': 5861, 'preemption_count': 0}), (6209, {'train/ssim': 0.7370784623282296, 'train/loss': 0.27326224531446186, 'validation/ssim': 0.7148053497159891, 'validation/loss': 0.2914096229050893, 'validation/num_examples': 3554, 'test/ssim': 0.7324459413615261, 'test/loss': 0.29283079452535954, 'test/num_examples': 3581, 'score': 1472.5103845596313, 'total_duration': 1549.3350069522858, 'accumulated_submission_time': 1472.5103845596313, 'accumulated_eval_time': 76.12851810455322, 'accumulated_logging_time': 0.44706010818481445, 'global_step': 6209, 'preemption_count': 0}), (6552, {'train/ssim': 0.7439711434500558, 'train/loss': 0.2714024782180786, 'validation/ssim': 0.7208899056300999, 'validation/loss': 0.2901221486243493, 'validation/num_examples': 3554, 'test/ssim': 0.7380670389294192, 'test/loss': 0.29158827486866445, 'test/num_examples': 3581, 'score': 1552.4796981811523, 'total_duration': 1633.3560178279877, 'accumulated_submission_time': 1552.4796981811523, 'accumulated_eval_time': 80.14044666290283, 'accumulated_logging_time': 0.4731578826904297, 'global_step': 6552, 'preemption_count': 0}), (6897, {'train/ssim': 0.7350197519574847, 'train/loss': 0.2739830527986799, 'validation/ssim': 0.7134123605224747, 'validation/loss': 0.29205068095587716, 'validation/num_examples': 3554, 'test/ssim': 0.7310526149294889, 'test/loss': 0.29322209447430886, 'test/num_examples': 3581, 'score': 1632.6826753616333, 'total_duration': 1717.6061108112335, 'accumulated_submission_time': 1632.6826753616333, 'accumulated_eval_time': 84.14881253242493, 'accumulated_logging_time': 0.49805593490600586, 'global_step': 6897, 'preemption_count': 0}), (7245, {'train/ssim': 0.7398674147469657, 'train/loss': 0.27286364351000103, 'validation/ssim': 0.718265909120885, 'validation/loss': 0.29099714615134353, 'validation/num_examples': 3554, 'test/ssim': 0.7354655538781066, 'test/loss': 0.2924798551600461, 'test/num_examples': 3581, 'score': 1712.859538078308, 'total_duration': 1801.8379180431366, 'accumulated_submission_time': 1712.859538078308, 'accumulated_eval_time': 88.164067029953, 'accumulated_logging_time': 0.5237960815429688, 'global_step': 7245, 'preemption_count': 0}), (7585, {'train/ssim': 0.7441009793962751, 'train/loss': 0.2723337071282523, 'validation/ssim': 0.7217527785593697, 'validation/loss': 0.29072322641521875, 'validation/num_examples': 3554, 'test/ssim': 0.7389684707483943, 'test/loss': 0.2920952024355976, 'test/num_examples': 3581, 'score': 1792.8237624168396, 'total_duration': 1885.8538382053375, 'accumulated_submission_time': 1792.8237624168396, 'accumulated_eval_time': 92.1750111579895, 'accumulated_logging_time': 0.550663948059082, 'global_step': 7585, 'preemption_count': 0}), (7931, {'train/ssim': 0.7397144862583706, 'train/loss': 0.2723456450871059, 'validation/ssim': 0.7167655502602701, 'validation/loss': 0.2911539072392023, 'validation/num_examples': 3554, 'test/ssim': 0.7343427524390882, 'test/loss': 0.29241754169139206, 'test/num_examples': 3581, 'score': 1872.8409950733185, 'total_duration': 1969.928893327713, 'accumulated_submission_time': 1872.8409950733185, 'accumulated_eval_time': 96.18921422958374, 'accumulated_logging_time': 0.5797338485717773, 'global_step': 7931, 'preemption_count': 0}), (8278, {'train/ssim': 0.7389503206525531, 'train/loss': 0.2730504444667271, 'validation/ssim': 0.715964502475204, 'validation/loss': 0.29152715937368107, 'validation/num_examples': 3554, 'test/ssim': 0.733583128076131, 'test/loss': 0.29276524266528203, 'test/num_examples': 3581, 'score': 1952.8641078472137, 'total_duration': 2054.003679037094, 'accumulated_submission_time': 1952.8641078472137, 'accumulated_eval_time': 100.20110750198364, 'accumulated_logging_time': 0.6055564880371094, 'global_step': 8278, 'preemption_count': 0}), (8622, {'train/ssim': 0.7411728586469378, 'train/loss': 0.2715661185128348, 'validation/ssim': 0.7190179776528207, 'validation/loss': 0.2899193964986635, 'validation/num_examples': 3554, 'test/ssim': 0.7363723034766825, 'test/loss': 0.2912397216865052, 'test/num_examples': 3581, 'score': 2032.9702162742615, 'total_duration': 2138.162857532501, 'accumulated_submission_time': 2032.9702162742615, 'accumulated_eval_time': 104.21291184425354, 'accumulated_logging_time': 0.6329255104064941, 'global_step': 8622, 'preemption_count': 0}), (8967, {'train/ssim': 0.7409847123282296, 'train/loss': 0.2726804869515555, 'validation/ssim': 0.7181451440058737, 'validation/loss': 0.2913322040856254, 'validation/num_examples': 3554, 'test/ssim': 0.7353939683834823, 'test/loss': 0.29281405715494974, 'test/num_examples': 3581, 'score': 2112.99298119545, 'total_duration': 2222.238981962204, 'accumulated_submission_time': 2112.99298119545, 'accumulated_eval_time': 108.22664284706116, 'accumulated_logging_time': 0.6587364673614502, 'global_step': 8967, 'preemption_count': 0}), (9313, {'train/ssim': 0.7409087589808873, 'train/loss': 0.27189222403935026, 'validation/ssim': 0.7185364284740785, 'validation/loss': 0.29015419465742825, 'validation/num_examples': 3554, 'test/ssim': 0.7360125352336987, 'test/loss': 0.2915215640053407, 'test/num_examples': 3581, 'score': 2193.1075069904327, 'total_duration': 2306.40425825119, 'accumulated_submission_time': 2193.1075069904327, 'accumulated_eval_time': 112.237300157547, 'accumulated_logging_time': 0.6848461627960205, 'global_step': 9313, 'preemption_count': 0}), (9656, {'train/ssim': 0.7410191808428083, 'train/loss': 0.2718787704195295, 'validation/ssim': 0.7191517947427195, 'validation/loss': 0.29007395935917274, 'validation/num_examples': 3554, 'test/ssim': 0.7363588726743577, 'test/loss': 0.2914483081825084, 'test/num_examples': 3581, 'score': 2273.0946094989777, 'total_duration': 2390.445656776428, 'accumulated_submission_time': 2273.0946094989777, 'accumulated_eval_time': 116.2509913444519, 'accumulated_logging_time': 0.7118649482727051, 'global_step': 9656, 'preemption_count': 0}), (10003, {'train/ssim': 0.742525441305978, 'train/loss': 0.2702041523797171, 'validation/ssim': 0.7192932369337366, 'validation/loss': 0.2888822797046462, 'validation/num_examples': 3554, 'test/ssim': 0.7367913172385507, 'test/loss': 0.29026960188102136, 'test/num_examples': 3581, 'score': 2353.26428937912, 'total_duration': 2474.6693358421326, 'accumulated_submission_time': 2353.26428937912, 'accumulated_eval_time': 120.26565432548523, 'accumulated_logging_time': 0.7373523712158203, 'global_step': 10003, 'preemption_count': 0}), (10348, {'train/ssim': 0.7450870786394391, 'train/loss': 0.2710064649581909, 'validation/ssim': 0.7226098811418472, 'validation/loss': 0.28952986374287776, 'validation/num_examples': 3554, 'test/ssim': 0.7398191791311785, 'test/loss': 0.29097430994310247, 'test/num_examples': 3581, 'score': 2433.438845872879, 'total_duration': 2558.896376132965, 'accumulated_submission_time': 2433.438845872879, 'accumulated_eval_time': 124.27734661102295, 'accumulated_logging_time': 0.7643404006958008, 'global_step': 10348, 'preemption_count': 0}), (10692, {'train/ssim': 0.7411471775599888, 'train/loss': 0.2711236817496164, 'validation/ssim': 0.7182149377242192, 'validation/loss': 0.28949407385384424, 'validation/num_examples': 3554, 'test/ssim': 0.7358138684419506, 'test/loss': 0.2907895171019792, 'test/num_examples': 3581, 'score': 2513.490818977356, 'total_duration': 2642.999470949173, 'accumulated_submission_time': 2513.490818977356, 'accumulated_eval_time': 128.28723120689392, 'accumulated_logging_time': 0.7917084693908691, 'global_step': 10692, 'preemption_count': 0}), (11038, {'train/ssim': 0.7429281643458775, 'train/loss': 0.2708985464913504, 'validation/ssim': 0.7203224881955191, 'validation/loss': 0.28977791996034397, 'validation/num_examples': 3554, 'test/ssim': 0.7375919157750978, 'test/loss': 0.29111243585939683, 'test/num_examples': 3581, 'score': 2593.563329219818, 'total_duration': 2727.123106479645, 'accumulated_submission_time': 2593.563329219818, 'accumulated_eval_time': 132.29781484603882, 'accumulated_logging_time': 0.81842041015625, 'global_step': 11038, 'preemption_count': 0}), (11382, {'train/ssim': 0.7329865183149066, 'train/loss': 0.2733525208064488, 'validation/ssim': 0.7107803954391179, 'validation/loss': 0.2919654652987831, 'validation/num_examples': 3554, 'test/ssim': 0.728263507705599, 'test/loss': 0.29321493592484643, 'test/num_examples': 3581, 'score': 2673.632261276245, 'total_duration': 2811.2464735507965, 'accumulated_submission_time': 2673.632261276245, 'accumulated_eval_time': 136.31195998191833, 'accumulated_logging_time': 0.844599723815918, 'global_step': 11382, 'preemption_count': 0}), (11728, {'train/ssim': 0.7416582788739886, 'train/loss': 0.27010680947984966, 'validation/ssim': 0.7189289494451674, 'validation/loss': 0.2886116573095456, 'validation/num_examples': 3554, 'test/ssim': 0.7364855449115122, 'test/loss': 0.28991910566400797, 'test/num_examples': 3581, 'score': 2753.709707736969, 'total_duration': 2895.374767303467, 'accumulated_submission_time': 2753.709707736969, 'accumulated_eval_time': 140.32230615615845, 'accumulated_logging_time': 0.871314287185669, 'global_step': 11728, 'preemption_count': 0}), (12074, {'train/ssim': 0.7418908391680036, 'train/loss': 0.27015936374664307, 'validation/ssim': 0.7188359369504431, 'validation/loss': 0.28897611653462646, 'validation/num_examples': 3554, 'test/ssim': 0.7362733109641162, 'test/loss': 0.2903468119502234, 'test/num_examples': 3581, 'score': 2833.909121990204, 'total_duration': 2979.6290197372437, 'accumulated_submission_time': 2833.909121990204, 'accumulated_eval_time': 144.3353407382965, 'accumulated_logging_time': 0.8990838527679443, 'global_step': 12074, 'preemption_count': 0}), (12421, {'train/ssim': 0.7414828709193638, 'train/loss': 0.27051702567509245, 'validation/ssim': 0.7181956345403067, 'validation/loss': 0.28924546807954066, 'validation/num_examples': 3554, 'test/ssim': 0.7358350032070302, 'test/loss': 0.29044819064594385, 'test/num_examples': 3581, 'score': 2913.879408121109, 'total_duration': 3063.651765346527, 'accumulated_submission_time': 2913.879408121109, 'accumulated_eval_time': 148.34514021873474, 'accumulated_logging_time': 0.9278120994567871, 'global_step': 12421, 'preemption_count': 0}), (12762, {'train/ssim': 0.7418837547302246, 'train/loss': 0.2706202268600464, 'validation/ssim': 0.7193922945536719, 'validation/loss': 0.288879497573157, 'validation/num_examples': 3554, 'test/ssim': 0.7369440329604161, 'test/loss': 0.29017923371614074, 'test/num_examples': 3581, 'score': 2993.9373548030853, 'total_duration': 3147.762551546097, 'accumulated_submission_time': 2993.9373548030853, 'accumulated_eval_time': 152.35568261146545, 'accumulated_logging_time': 0.9562292098999023, 'global_step': 12762, 'preemption_count': 0}), (13105, {'train/ssim': 0.7434845651899066, 'train/loss': 0.2700550215584891, 'validation/ssim': 0.7209310536982977, 'validation/loss': 0.28924096858293474, 'validation/num_examples': 3554, 'test/ssim': 0.7382352307534558, 'test/loss': 0.29054077455232474, 'test/num_examples': 3581, 'score': 3074.032609462738, 'total_duration': 3231.913425922394, 'accumulated_submission_time': 3074.032609462738, 'accumulated_eval_time': 156.36930775642395, 'accumulated_logging_time': 0.9846577644348145, 'global_step': 13105, 'preemption_count': 0}), (13450, {'train/ssim': 0.7449960708618164, 'train/loss': 0.2694966622761318, 'validation/ssim': 0.7224813535365081, 'validation/loss': 0.2880865729250932, 'validation/num_examples': 3554, 'test/ssim': 0.7398077254520385, 'test/loss': 0.28937624899643954, 'test/num_examples': 3581, 'score': 3154.0704021453857, 'total_duration': 3316.0069653987885, 'accumulated_submission_time': 3154.0704021453857, 'accumulated_eval_time': 160.3839066028595, 'accumulated_logging_time': 1.0118327140808105, 'global_step': 13450, 'preemption_count': 0}), (13797, {'train/ssim': 0.7459932054792132, 'train/loss': 0.2703155108860561, 'validation/ssim': 0.7233974647843978, 'validation/loss': 0.2888293848590497, 'validation/num_examples': 3554, 'test/ssim': 0.740477765681723, 'test/loss': 0.29021291298694496, 'test/num_examples': 3581, 'score': 3234.164406776428, 'total_duration': 3400.156908750534, 'accumulated_submission_time': 3234.164406776428, 'accumulated_eval_time': 164.39890503883362, 'accumulated_logging_time': 1.0392420291900635, 'global_step': 13797, 'preemption_count': 0}), (14143, {'train/ssim': 0.7477308000837054, 'train/loss': 0.2687981128692627, 'validation/ssim': 0.7242183653102139, 'validation/loss': 0.28805078303605974, 'validation/num_examples': 3554, 'test/ssim': 0.7413721753045588, 'test/loss': 0.28940703075912805, 'test/num_examples': 3581, 'score': 3314.325216770172, 'total_duration': 3484.3749873638153, 'accumulated_submission_time': 3314.325216770172, 'accumulated_eval_time': 168.41451406478882, 'accumulated_logging_time': 1.0669360160827637, 'global_step': 14143, 'preemption_count': 0}), (14487, {'train/ssim': 0.7401647567749023, 'train/loss': 0.27143326827457975, 'validation/ssim': 0.7168947648116559, 'validation/loss': 0.2901178552115574, 'validation/num_examples': 3554, 'test/ssim': 0.7343974301216489, 'test/loss': 0.2915374832558119, 'test/num_examples': 3581, 'score': 3394.4950959682465, 'total_duration': 3568.6011819839478, 'accumulated_submission_time': 3394.4950959682465, 'accumulated_eval_time': 172.42876362800598, 'accumulated_logging_time': 1.09513521194458, 'global_step': 14487, 'preemption_count': 0}), (14833, {'train/ssim': 0.7431543213980538, 'train/loss': 0.27032084124428885, 'validation/ssim': 0.7210589630521947, 'validation/loss': 0.28862306061392096, 'validation/num_examples': 3554, 'test/ssim': 0.7382288221472704, 'test/loss': 0.2900032697526878, 'test/num_examples': 3581, 'score': 3474.6364142894745, 'total_duration': 3652.7931792736053, 'accumulated_submission_time': 3474.6364142894745, 'accumulated_eval_time': 176.43772840499878, 'accumulated_logging_time': 1.122864007949829, 'global_step': 14833, 'preemption_count': 0}), (15177, {'train/ssim': 0.7430147443498883, 'train/loss': 0.2690542936325073, 'validation/ssim': 0.7197655123408483, 'validation/loss': 0.28780626459073405, 'validation/num_examples': 3554, 'test/ssim': 0.7372273069891441, 'test/loss': 0.28929661865575257, 'test/num_examples': 3581, 'score': 3554.6089866161346, 'total_duration': 3736.8194127082825, 'accumulated_submission_time': 3554.6089866161346, 'accumulated_eval_time': 180.44852137565613, 'accumulated_logging_time': 1.1519262790679932, 'global_step': 15177, 'preemption_count': 0}), (15507, {'train/ssim': 0.7467621394566127, 'train/loss': 0.26903694016592844, 'validation/ssim': 0.7243016231710748, 'validation/loss': 0.2878441324915588, 'validation/num_examples': 3554, 'test/ssim': 0.7414995974849903, 'test/loss': 0.28926365523989456, 'test/num_examples': 3581, 'score': 3631.1549224853516, 'total_duration': 3820.978665113449, 'accumulated_submission_time': 3631.1549224853516, 'accumulated_eval_time': 184.462073802948, 'accumulated_logging_time': 4.738783836364746, 'global_step': 15507, 'preemption_count': 0}), (15854, {'train/ssim': 0.7453158242361886, 'train/loss': 0.2699409893580845, 'validation/ssim': 0.7223393617886537, 'validation/loss': 0.28888846221906656, 'validation/num_examples': 3554, 'test/ssim': 0.7394906357991832, 'test/loss': 0.2902920660910011, 'test/num_examples': 3581, 'score': 3711.2650315761566, 'total_duration': 3905.1440398693085, 'accumulated_submission_time': 3711.2650315761566, 'accumulated_eval_time': 188.47587609291077, 'accumulated_logging_time': 4.7664830684661865, 'global_step': 15854, 'preemption_count': 0}), (16197, {'train/ssim': 0.741283689226423, 'train/loss': 0.2696803978511265, 'validation/ssim': 0.7182117090777996, 'validation/loss': 0.28838826245515614, 'validation/num_examples': 3554, 'test/ssim': 0.7357913019669785, 'test/loss': 0.28964489913126573, 'test/num_examples': 3581, 'score': 3791.233234167099, 'total_duration': 3989.16166472435, 'accumulated_submission_time': 3791.233234167099, 'accumulated_eval_time': 192.4837954044342, 'accumulated_logging_time': 4.794270038604736, 'global_step': 16197, 'preemption_count': 0}), (16543, {'train/ssim': 0.7450265884399414, 'train/loss': 0.2695753744670323, 'validation/ssim': 0.7212872352235158, 'validation/loss': 0.28914376571732553, 'validation/num_examples': 3554, 'test/ssim': 0.738705104304838, 'test/loss': 0.29042136312962513, 'test/num_examples': 3581, 'score': 3871.200170278549, 'total_duration': 4073.1831629276276, 'accumulated_submission_time': 3871.200170278549, 'accumulated_eval_time': 196.49588203430176, 'accumulated_logging_time': 4.823106288909912, 'global_step': 16543, 'preemption_count': 0}), (16890, {'train/ssim': 0.7434981209891183, 'train/loss': 0.2689415046146938, 'validation/ssim': 0.7204480619328574, 'validation/loss': 0.2876258897325197, 'validation/num_examples': 3554, 'test/ssim': 0.7379346398526948, 'test/loss': 0.2889543036381248, 'test/num_examples': 3581, 'score': 3951.185159444809, 'total_duration': 4157.22482085228, 'accumulated_submission_time': 3951.185159444809, 'accumulated_eval_time': 200.5108027458191, 'accumulated_logging_time': 4.8511247634887695, 'global_step': 16890, 'preemption_count': 0}), (17233, {'train/ssim': 0.7445393289838519, 'train/loss': 0.26896725382123676, 'validation/ssim': 0.721334771889948, 'validation/loss': 0.2876462748564558, 'validation/num_examples': 3554, 'test/ssim': 0.7388480025874407, 'test/loss': 0.2889681435004189, 'test/num_examples': 3581, 'score': 4031.2938227653503, 'total_duration': 4241.38879776001, 'accumulated_submission_time': 4031.2938227653503, 'accumulated_eval_time': 204.5243673324585, 'accumulated_logging_time': 4.8789660930633545, 'global_step': 17233, 'preemption_count': 0}), (17578, {'train/ssim': 0.7461472238813128, 'train/loss': 0.2680603095463344, 'validation/ssim': 0.7228117745849747, 'validation/loss': 0.2870571671004502, 'validation/num_examples': 3554, 'test/ssim': 0.7402261938006144, 'test/loss': 0.28837596101822116, 'test/num_examples': 3581, 'score': 4111.324229717255, 'total_duration': 4325.475947856903, 'accumulated_submission_time': 4111.324229717255, 'accumulated_eval_time': 208.53724908828735, 'accumulated_logging_time': 4.909036159515381, 'global_step': 17578, 'preemption_count': 0}), (17922, {'train/ssim': 0.7468926565987724, 'train/loss': 0.2687728575297764, 'validation/ssim': 0.7236925768060636, 'validation/loss': 0.28773008227415414, 'validation/num_examples': 3554, 'test/ssim': 0.7409845909836638, 'test/loss': 0.289038569991797, 'test/num_examples': 3581, 'score': 4191.43989610672, 'total_duration': 4409.6447513103485, 'accumulated_submission_time': 4191.43989610672, 'accumulated_eval_time': 212.54886436462402, 'accumulated_logging_time': 4.937071323394775, 'global_step': 17922, 'preemption_count': 0}), (18269, {'train/ssim': 0.7458718163626534, 'train/loss': 0.26871468339647564, 'validation/ssim': 0.7227657491998453, 'validation/loss': 0.28786850190256574, 'validation/num_examples': 3554, 'test/ssim': 0.7402092178118891, 'test/loss': 0.28917113951017526, 'test/num_examples': 3581, 'score': 4271.575967788696, 'total_duration': 4493.836472988129, 'accumulated_submission_time': 4271.575967788696, 'accumulated_eval_time': 216.56116938591003, 'accumulated_logging_time': 4.9665985107421875, 'global_step': 18269, 'preemption_count': 0}), (18612, {'train/ssim': 0.7453145980834961, 'train/loss': 0.26775710923331125, 'validation/ssim': 0.7217790885929586, 'validation/loss': 0.28692822732748313, 'validation/num_examples': 3554, 'test/ssim': 0.7391915447849763, 'test/loss': 0.28823524438878806, 'test/num_examples': 3581, 'score': 4351.592973470688, 'total_duration': 4577.905798196793, 'accumulated_submission_time': 4351.592973470688, 'accumulated_eval_time': 220.5689299106598, 'accumulated_logging_time': 4.99765419960022, 'global_step': 18612, 'preemption_count': 0}), (18958, {'train/ssim': 0.7447752271379743, 'train/loss': 0.2680262838091169, 'validation/ssim': 0.7214467440955613, 'validation/loss': 0.28691507231068863, 'validation/num_examples': 3554, 'test/ssim': 0.7389786972476263, 'test/loss': 0.2881993834648143, 'test/num_examples': 3581, 'score': 4431.69629073143, 'total_duration': 4662.063468456268, 'accumulated_submission_time': 4431.69629073143, 'accumulated_eval_time': 224.58108806610107, 'accumulated_logging_time': 5.0261549949646, 'global_step': 18958, 'preemption_count': 0}), (19304, {'train/ssim': 0.748098645891462, 'train/loss': 0.268930333001273, 'validation/ssim': 0.7257016879088702, 'validation/loss': 0.28763554132447594, 'validation/num_examples': 3554, 'test/ssim': 0.7427710922228428, 'test/loss': 0.28900407260105415, 'test/num_examples': 3581, 'score': 4511.751484632492, 'total_duration': 4746.171770095825, 'accumulated_submission_time': 4511.751484632492, 'accumulated_eval_time': 228.59129190444946, 'accumulated_logging_time': 5.055289030075073, 'global_step': 19304, 'preemption_count': 0}), (19646, {'train/ssim': 0.7443575177873883, 'train/loss': 0.2679600204740252, 'validation/ssim': 0.721302622814962, 'validation/loss': 0.28713487787198405, 'validation/num_examples': 3554, 'test/ssim': 0.7385132551792446, 'test/loss': 0.28854234616072677, 'test/num_examples': 3581, 'score': 4591.897384405136, 'total_duration': 4830.373497962952, 'accumulated_submission_time': 4591.897384405136, 'accumulated_eval_time': 232.60448598861694, 'accumulated_logging_time': 5.084141492843628, 'global_step': 19646, 'preemption_count': 0}), (19992, {'train/ssim': 0.7473198345729283, 'train/loss': 0.26764990602220806, 'validation/ssim': 0.7242911815911649, 'validation/loss': 0.2864868473188221, 'validation/num_examples': 3554, 'test/ssim': 0.7415709102729684, 'test/loss': 0.2878015044680257, 'test/num_examples': 3581, 'score': 4671.86004781723, 'total_duration': 4914.393493652344, 'accumulated_submission_time': 4671.86004781723, 'accumulated_eval_time': 236.61859679222107, 'accumulated_logging_time': 5.113516569137573, 'global_step': 19992, 'preemption_count': 0}), (20337, {'train/ssim': 0.7448357854570661, 'train/loss': 0.26822255338941303, 'validation/ssim': 0.7214832896252462, 'validation/loss': 0.28723403853382634, 'validation/num_examples': 3554, 'test/ssim': 0.7389167928389416, 'test/loss': 0.2885085646249302, 'test/num_examples': 3581, 'score': 4752.0103261470795, 'total_duration': 4998.600042819977, 'accumulated_submission_time': 4752.0103261470795, 'accumulated_eval_time': 240.63190078735352, 'accumulated_logging_time': 5.14256739616394, 'global_step': 20337, 'preemption_count': 0}), (20681, {'train/ssim': 0.7465263775416783, 'train/loss': 0.2680410317012242, 'validation/ssim': 0.7229192816412845, 'validation/loss': 0.28738049543098443, 'validation/num_examples': 3554, 'test/ssim': 0.7401653120418529, 'test/loss': 0.2886559284788641, 'test/num_examples': 3581, 'score': 4832.023688554764, 'total_duration': 5082.671446084976, 'accumulated_submission_time': 4832.023688554764, 'accumulated_eval_time': 244.6449682712555, 'accumulated_logging_time': 5.173840522766113, 'global_step': 20681, 'preemption_count': 0}), (21026, {'train/ssim': 0.7433980533054897, 'train/loss': 0.2681511810847691, 'validation/ssim': 0.7203869237347004, 'validation/loss': 0.28704777311326146, 'validation/num_examples': 3554, 'test/ssim': 0.7379010287585521, 'test/loss': 0.2883169200293214, 'test/num_examples': 3581, 'score': 4912.122037649155, 'total_duration': 5166.823796510696, 'accumulated_submission_time': 4912.122037649155, 'accumulated_eval_time': 248.65569019317627, 'accumulated_logging_time': 5.203402757644653, 'global_step': 21026, 'preemption_count': 0}), (21369, {'train/ssim': 0.7488290241786412, 'train/loss': 0.26764767510550364, 'validation/ssim': 0.7261367308402504, 'validation/loss': 0.2864730053559809, 'validation/num_examples': 3554, 'test/ssim': 0.7432473743804106, 'test/loss': 0.2877285213518396, 'test/num_examples': 3581, 'score': 4992.088282823563, 'total_duration': 5250.844703674316, 'accumulated_submission_time': 4992.088282823563, 'accumulated_eval_time': 252.6671848297119, 'accumulated_logging_time': 5.232451677322388, 'global_step': 21369, 'preemption_count': 0}), (21713, {'train/ssim': 0.7478596142360142, 'train/loss': 0.26826337405613493, 'validation/ssim': 0.7245296205639772, 'validation/loss': 0.2876049893990486, 'validation/num_examples': 3554, 'test/ssim': 0.7417139449088942, 'test/loss': 0.2888652308298136, 'test/num_examples': 3581, 'score': 5072.231734991074, 'total_duration': 5335.0451447963715, 'accumulated_submission_time': 5072.231734991074, 'accumulated_eval_time': 256.68112564086914, 'accumulated_logging_time': 5.262057304382324, 'global_step': 21713, 'preemption_count': 0}), (22057, {'train/ssim': 0.7472703797476632, 'train/loss': 0.26737151827131, 'validation/ssim': 0.7236122728132034, 'validation/loss': 0.2867679971620885, 'validation/num_examples': 3554, 'test/ssim': 0.7409195504485478, 'test/loss': 0.28806425732162805, 'test/num_examples': 3581, 'score': 5152.4338619709015, 'total_duration': 5419.302825212479, 'accumulated_submission_time': 5152.4338619709015, 'accumulated_eval_time': 260.69290471076965, 'accumulated_logging_time': 5.292056083679199, 'global_step': 22057, 'preemption_count': 0}), (22403, {'train/ssim': 0.746769768851144, 'train/loss': 0.2673004354749407, 'validation/ssim': 0.7232089667891812, 'validation/loss': 0.2865335081290447, 'validation/num_examples': 3554, 'test/ssim': 0.7407228607799846, 'test/loss': 0.2876894220364423, 'test/num_examples': 3581, 'score': 5232.52370929718, 'total_duration': 5503.448872804642, 'accumulated_submission_time': 5232.52370929718, 'accumulated_eval_time': 264.7044961452484, 'accumulated_logging_time': 5.322473049163818, 'global_step': 22403, 'preemption_count': 0}), (22747, {'train/ssim': 0.7487727573939732, 'train/loss': 0.26724702971322195, 'validation/ssim': 0.7256340924178742, 'validation/loss': 0.2863474487922939, 'validation/num_examples': 3554, 'test/ssim': 0.7426483742320581, 'test/loss': 0.2877149541961917, 'test/num_examples': 3581, 'score': 5312.687821388245, 'total_duration': 5587.670019626617, 'accumulated_submission_time': 5312.687821388245, 'accumulated_eval_time': 268.71786284446716, 'accumulated_logging_time': 5.352055549621582, 'global_step': 22747, 'preemption_count': 0}), (23094, {'train/ssim': 0.7463985170636859, 'train/loss': 0.267437253679548, 'validation/ssim': 0.722510411354284, 'validation/loss': 0.28699774626741, 'validation/num_examples': 3554, 'test/ssim': 0.7398897419758796, 'test/loss': 0.288260537930222, 'test/num_examples': 3581, 'score': 5392.799517869949, 'total_duration': 5671.839567661285, 'accumulated_submission_time': 5392.799517869949, 'accumulated_eval_time': 272.73209524154663, 'accumulated_logging_time': 5.382074594497681, 'global_step': 23094, 'preemption_count': 0}), (23441, {'train/ssim': 0.7481884275163923, 'train/loss': 0.2669349568230765, 'validation/ssim': 0.7248329072435987, 'validation/loss': 0.28614380363674735, 'validation/num_examples': 3554, 'test/ssim': 0.7420801217580634, 'test/loss': 0.2874584395071209, 'test/num_examples': 3581, 'score': 5472.933496236801, 'total_duration': 5756.026417970657, 'accumulated_submission_time': 5472.933496236801, 'accumulated_eval_time': 276.74117255210876, 'accumulated_logging_time': 5.412250757217407, 'global_step': 23441, 'preemption_count': 0}), (23786, {'train/ssim': 0.7467733110700335, 'train/loss': 0.26686833586011616, 'validation/ssim': 0.7233074748522791, 'validation/loss': 0.2860006269069622, 'validation/num_examples': 3554, 'test/ssim': 0.7407065665578749, 'test/loss': 0.28726188619188076, 'test/num_examples': 3581, 'score': 5553.040453672409, 'total_duration': 5840.18537902832, 'accumulated_submission_time': 5553.040453672409, 'accumulated_eval_time': 280.7495219707489, 'accumulated_logging_time': 5.442123651504517, 'global_step': 23786, 'preemption_count': 0}), (24132, {'train/ssim': 0.7495803151811872, 'train/loss': 0.26633802482060026, 'validation/ssim': 0.726013904887099, 'validation/loss': 0.28584266366352173, 'validation/num_examples': 3554, 'test/ssim': 0.7431660396231848, 'test/loss': 0.2871942549436261, 'test/num_examples': 3581, 'score': 5633.144581317902, 'total_duration': 5924.342694759369, 'accumulated_submission_time': 5633.144581317902, 'accumulated_eval_time': 284.75822138786316, 'accumulated_logging_time': 5.472839117050171, 'global_step': 24132, 'preemption_count': 0}), (24482, {'train/ssim': 0.7474779401506696, 'train/loss': 0.26655629702976774, 'validation/ssim': 0.7240453922956528, 'validation/loss': 0.28574350300167944, 'validation/num_examples': 3554, 'test/ssim': 0.7414027184489319, 'test/loss': 0.2870046897361945, 'test/num_examples': 3581, 'score': 5713.145759820938, 'total_duration': 6008.39787364006, 'accumulated_submission_time': 5713.145759820938, 'accumulated_eval_time': 288.76734495162964, 'accumulated_logging_time': 5.504015684127808, 'global_step': 24482, 'preemption_count': 0}), (24825, {'train/ssim': 0.7502619198390416, 'train/loss': 0.2664697340556553, 'validation/ssim': 0.7271315661050929, 'validation/loss': 0.2857424038880047, 'validation/num_examples': 3554, 'test/ssim': 0.7442264594168877, 'test/loss': 0.2870229610814891, 'test/num_examples': 3581, 'score': 5793.313705205917, 'total_duration': 6092.62002158165, 'accumulated_submission_time': 5793.313705205917, 'accumulated_eval_time': 292.7781751155853, 'accumulated_logging_time': 5.533693075180054, 'global_step': 24825, 'preemption_count': 0}), (25169, {'train/ssim': 0.7488915579659599, 'train/loss': 0.2660852500370571, 'validation/ssim': 0.7247901105048888, 'validation/loss': 0.28593902502022367, 'validation/num_examples': 3554, 'test/ssim': 0.7421172780386065, 'test/loss': 0.28720161802307315, 'test/num_examples': 3581, 'score': 5873.269628047943, 'total_duration': 6176.635795116425, 'accumulated_submission_time': 5873.269628047943, 'accumulated_eval_time': 296.7916488647461, 'accumulated_logging_time': 5.566459655761719, 'global_step': 25169, 'preemption_count': 0}), (25516, {'train/ssim': 0.7491566794259208, 'train/loss': 0.2663029602595738, 'validation/ssim': 0.7255977529720034, 'validation/loss': 0.28578575018355196, 'validation/num_examples': 3554, 'test/ssim': 0.7428563812264382, 'test/loss': 0.2870041784112329, 'test/num_examples': 3581, 'score': 5953.41180896759, 'total_duration': 6260.837786436081, 'accumulated_submission_time': 5953.41180896759, 'accumulated_eval_time': 300.80610942840576, 'accumulated_logging_time': 5.5982396602630615, 'global_step': 25516, 'preemption_count': 0}), (25862, {'train/ssim': 0.7497294970921108, 'train/loss': 0.2662316220147269, 'validation/ssim': 0.7261816571117051, 'validation/loss': 0.28572486959016247, 'validation/num_examples': 3554, 'test/ssim': 0.7434290651834334, 'test/loss': 0.286961567997766, 'test/num_examples': 3581, 'score': 6033.534689426422, 'total_duration': 6345.01830124855, 'accumulated_submission_time': 6033.534689426422, 'accumulated_eval_time': 304.81979846954346, 'accumulated_logging_time': 5.628521680831909, 'global_step': 25862, 'preemption_count': 0}), (26206, {'train/ssim': 0.7487617901393345, 'train/loss': 0.26592167786189486, 'validation/ssim': 0.7249687851716375, 'validation/loss': 0.2857339029306767, 'validation/num_examples': 3554, 'test/ssim': 0.742172296604475, 'test/loss': 0.28698795236578467, 'test/num_examples': 3581, 'score': 6113.551764726639, 'total_duration': 6429.092185497284, 'accumulated_submission_time': 6113.551764726639, 'accumulated_eval_time': 308.8319561481476, 'accumulated_logging_time': 5.6597490310668945, 'global_step': 26206, 'preemption_count': 0}), (26552, {'train/ssim': 0.7490940093994141, 'train/loss': 0.26601377555302214, 'validation/ssim': 0.7254139262099043, 'validation/loss': 0.28561696753987587, 'validation/num_examples': 3554, 'test/ssim': 0.7426279894102555, 'test/loss': 0.28687692667245535, 'test/num_examples': 3581, 'score': 6193.714996337891, 'total_duration': 6513.307105064392, 'accumulated_submission_time': 6193.714996337891, 'accumulated_eval_time': 312.83840131759644, 'accumulated_logging_time': 5.691235303878784, 'global_step': 26552, 'preemption_count': 0}), (26896, {'train/ssim': 0.7483999388558524, 'train/loss': 0.26618504524230957, 'validation/ssim': 0.7247854392717712, 'validation/loss': 0.2855410256544123, 'validation/num_examples': 3554, 'test/ssim': 0.7420892574307107, 'test/loss': 0.28677333223523455, 'test/num_examples': 3581, 'score': 6273.787319660187, 'total_duration': 6597.434686660767, 'accumulated_submission_time': 6273.787319660187, 'accumulated_eval_time': 316.84984970092773, 'accumulated_logging_time': 5.721496343612671, 'global_step': 26896, 'preemption_count': 0}), (27238, {'train/ssim': 0.7507381439208984, 'train/loss': 0.2653639316558838, 'validation/ssim': 0.7267112925137169, 'validation/loss': 0.2852600647213087, 'validation/num_examples': 3554, 'test/ssim': 0.743832057429838, 'test/loss': 0.2866217755166155, 'test/num_examples': 3581, 'score': 6353.8551030159, 'total_duration': 6681.561727285385, 'accumulated_submission_time': 6353.8551030159, 'accumulated_eval_time': 320.86294293403625, 'accumulated_logging_time': 5.753942012786865, 'global_step': 27238, 'preemption_count': 0}), (27583, {'train/ssim': 0.7501236370631627, 'train/loss': 0.2658776044845581, 'validation/ssim': 0.7266756400138928, 'validation/loss': 0.2853921472724395, 'validation/num_examples': 3554, 'test/ssim': 0.7437995371622801, 'test/loss': 0.28667035138796776, 'test/num_examples': 3581, 'score': 6433.951121091843, 'total_duration': 6765.719286441803, 'accumulated_submission_time': 6433.951121091843, 'accumulated_eval_time': 324.87469935417175, 'accumulated_logging_time': 5.79008412361145, 'global_step': 27583, 'preemption_count': 0}), (27929, {'train/ssim': 0.749838011605399, 'train/loss': 0.2655642032623291, 'validation/ssim': 0.7262190269766461, 'validation/loss': 0.285093068137354, 'validation/num_examples': 3554, 'test/ssim': 0.7433997492189681, 'test/loss': 0.28635360261842013, 'test/num_examples': 3581, 'score': 6514.103759050369, 'total_duration': 6849.925580263138, 'accumulated_submission_time': 6514.103759050369, 'accumulated_eval_time': 328.8831934928894, 'accumulated_logging_time': 5.821483612060547, 'global_step': 27929, 'preemption_count': 0}), (28272, {'train/ssim': 0.749901294708252, 'train/loss': 0.26528477668762207, 'validation/ssim': 0.7256960549512873, 'validation/loss': 0.2852201188086927, 'validation/num_examples': 3554, 'test/ssim': 0.7428893105539653, 'test/loss': 0.2865293279635577, 'test/num_examples': 3581, 'score': 6594.274115562439, 'total_duration': 6934.148802280426, 'accumulated_submission_time': 6594.274115562439, 'accumulated_eval_time': 332.8914361000061, 'accumulated_logging_time': 5.852307319641113, 'global_step': 28272, 'preemption_count': 0}), (28616, {'train/ssim': 0.7493587221418109, 'train/loss': 0.26545797075544086, 'validation/ssim': 0.7255252801640757, 'validation/loss': 0.28514584276739235, 'validation/num_examples': 3554, 'test/ssim': 0.7427862956183677, 'test/loss': 0.2864145184655124, 'test/num_examples': 3581, 'score': 6674.250906705856, 'total_duration': 7018.179235696793, 'accumulated_submission_time': 6674.250906705856, 'accumulated_eval_time': 336.89839482307434, 'accumulated_logging_time': 5.885340690612793, 'global_step': 28616, 'preemption_count': 0}), (28963, {'train/ssim': 0.7498035430908203, 'train/loss': 0.2655364956174578, 'validation/ssim': 0.7261129625070343, 'validation/loss': 0.2851735782140282, 'validation/num_examples': 3554, 'test/ssim': 0.7433507301993159, 'test/loss': 0.28644724326305504, 'test/num_examples': 3581, 'score': 6754.433007955551, 'total_duration': 7102.422847747803, 'accumulated_submission_time': 6754.433007955551, 'accumulated_eval_time': 340.9145243167877, 'accumulated_logging_time': 5.916884183883667, 'global_step': 28963, 'preemption_count': 0}), (29308, {'train/ssim': 0.7496084485735212, 'train/loss': 0.2654083626610892, 'validation/ssim': 0.7259997537985369, 'validation/loss': 0.2850448101775728, 'validation/num_examples': 3554, 'test/ssim': 0.743136519128735, 'test/loss': 0.2863590567513439, 'test/num_examples': 3581, 'score': 6834.417027235031, 'total_duration': 7186.464999914169, 'accumulated_submission_time': 6834.417027235031, 'accumulated_eval_time': 344.9258232116699, 'accumulated_logging_time': 5.949899196624756, 'global_step': 29308, 'preemption_count': 0}), (29652, {'train/ssim': 0.7499695505414691, 'train/loss': 0.2650468349456787, 'validation/ssim': 0.7257326691755768, 'validation/loss': 0.2850546850269942, 'validation/num_examples': 3554, 'test/ssim': 0.7429690772479755, 'test/loss': 0.28630315188887534, 'test/num_examples': 3581, 'score': 6914.371897935867, 'total_duration': 7270.478240966797, 'accumulated_submission_time': 6914.371897935867, 'accumulated_eval_time': 348.9375340938568, 'accumulated_logging_time': 5.982892036437988, 'global_step': 29652, 'preemption_count': 0}), (29999, {'train/ssim': 0.7508008139474052, 'train/loss': 0.26522018228258404, 'validation/ssim': 0.7267960616558807, 'validation/loss': 0.2850975504603088, 'validation/num_examples': 3554, 'test/ssim': 0.7440159298860305, 'test/loss': 0.28634940975373496, 'test/num_examples': 3581, 'score': 6994.351936340332, 'total_duration': 7354.5146226882935, 'accumulated_submission_time': 6994.351936340332, 'accumulated_eval_time': 352.9492189884186, 'accumulated_logging_time': 6.013725280761719, 'global_step': 29999, 'preemption_count': 0}), (30341, {'train/ssim': 0.7502134186880929, 'train/loss': 0.2650173732212612, 'validation/ssim': 0.7262326285083709, 'validation/loss': 0.2848916383828081, 'validation/num_examples': 3554, 'test/ssim': 0.7433912271362748, 'test/loss': 0.2861762069450747, 'test/num_examples': 3581, 'score': 7074.379700660706, 'total_duration': 7438.5940990448, 'accumulated_submission_time': 7074.379700660706, 'accumulated_eval_time': 356.95574593544006, 'accumulated_logging_time': 6.045287609100342, 'global_step': 30341, 'preemption_count': 0}), (30688, {'train/ssim': 0.7507006100245884, 'train/loss': 0.2646711894444057, 'validation/ssim': 0.7264637171584833, 'validation/loss': 0.284826086556301, 'validation/num_examples': 3554, 'test/ssim': 0.7436298454516894, 'test/loss': 0.2861211542908755, 'test/num_examples': 3581, 'score': 7154.448456525803, 'total_duration': 7522.719612360001, 'accumulated_submission_time': 7154.448456525803, 'accumulated_eval_time': 360.9666941165924, 'accumulated_logging_time': 6.0774827003479, 'global_step': 30688, 'preemption_count': 0}), (31036, {'train/ssim': 0.750760691506522, 'train/loss': 0.26485397134508404, 'validation/ssim': 0.7266390944842079, 'validation/loss': 0.28487082391759283, 'validation/num_examples': 3554, 'test/ssim': 0.7438296712466839, 'test/loss': 0.2861302217868612, 'test/num_examples': 3581, 'score': 7234.592389583588, 'total_duration': 7606.922004938126, 'accumulated_submission_time': 7234.592389583588, 'accumulated_eval_time': 364.9779260158539, 'accumulated_logging_time': 6.110843896865845, 'global_step': 31036, 'preemption_count': 0}), (31381, {'train/ssim': 0.7507956368582589, 'train/loss': 0.26478144100734163, 'validation/ssim': 0.7267478380434018, 'validation/loss': 0.28474595429995253, 'validation/num_examples': 3554, 'test/ssim': 0.7439185736133412, 'test/loss': 0.28599553879197503, 'test/num_examples': 3581, 'score': 7314.720451116562, 'total_duration': 7691.110218048096, 'accumulated_submission_time': 7314.720451116562, 'accumulated_eval_time': 368.99309515953064, 'accumulated_logging_time': 6.142259836196899, 'global_step': 31381, 'preemption_count': 0}), (31728, {'train/ssim': 0.751133850642613, 'train/loss': 0.2644347974232265, 'validation/ssim': 0.7264723039840673, 'validation/loss': 0.2848719573785699, 'validation/num_examples': 3554, 'test/ssim': 0.743655343523108, 'test/loss': 0.2861455615357093, 'test/num_examples': 3581, 'score': 7394.727523565292, 'total_duration': 7775.174228429794, 'accumulated_submission_time': 7394.727523565292, 'accumulated_eval_time': 373.00463938713074, 'accumulated_logging_time': 6.173776626586914, 'global_step': 31728, 'preemption_count': 0}), (32074, {'train/ssim': 0.7505387578691755, 'train/loss': 0.2645878280912127, 'validation/ssim': 0.7262119514323649, 'validation/loss': 0.2847132041471757, 'validation/num_examples': 3554, 'test/ssim': 0.7434837428659942, 'test/loss': 0.2859557236216315, 'test/num_examples': 3581, 'score': 7474.850043296814, 'total_duration': 7859.357992172241, 'accumulated_submission_time': 7474.850043296814, 'accumulated_eval_time': 377.02014422416687, 'accumulated_logging_time': 6.205841541290283, 'global_step': 32074, 'preemption_count': 0}), (32417, {'train/ssim': 0.7507827622549874, 'train/loss': 0.26464855670928955, 'validation/ssim': 0.7266321563291361, 'validation/loss': 0.2846971467833339, 'validation/num_examples': 3554, 'test/ssim': 0.7438118089613586, 'test/loss': 0.28595545091498537, 'test/num_examples': 3581, 'score': 7554.948711395264, 'total_duration': 7943.512165546417, 'accumulated_submission_time': 7554.948711395264, 'accumulated_eval_time': 381.02881836891174, 'accumulated_logging_time': 6.23901629447937, 'global_step': 32417, 'preemption_count': 0}), (32762, {'train/ssim': 0.7513869830540248, 'train/loss': 0.2641993931361607, 'validation/ssim': 0.7267633630240574, 'validation/loss': 0.28467150652214057, 'validation/num_examples': 3554, 'test/ssim': 0.7439133921870636, 'test/loss': 0.28595453053005443, 'test/num_examples': 3581, 'score': 7635.059431314468, 'total_duration': 8027.681664466858, 'accumulated_submission_time': 7635.059431314468, 'accumulated_eval_time': 385.0398862361908, 'accumulated_logging_time': 6.273144245147705, 'global_step': 32762, 'preemption_count': 0}), (33107, {'train/ssim': 0.7509965215410505, 'train/loss': 0.2644737107413156, 'validation/ssim': 0.7265825588245639, 'validation/loss': 0.28466851830683737, 'validation/num_examples': 3554, 'test/ssim': 0.7437964010358489, 'test/loss': 0.2859292881211167, 'test/num_examples': 3581, 'score': 7715.03692984581, 'total_duration': 8111.719587564468, 'accumulated_submission_time': 7715.03692984581, 'accumulated_eval_time': 389.0552260875702, 'accumulated_logging_time': 6.30461573600769, 'global_step': 33107, 'preemption_count': 0}), (33451, {'train/ssim': 0.7508912086486816, 'train/loss': 0.26448542731148855, 'validation/ssim': 0.7264931184492825, 'validation/loss': 0.28466446532516176, 'validation/num_examples': 3554, 'test/ssim': 0.7437085213191148, 'test/loss': 0.2859337366482826, 'test/num_examples': 3581, 'score': 7794.994208097458, 'total_duration': 8195.742512226105, 'accumulated_submission_time': 7794.994208097458, 'accumulated_eval_time': 393.0689616203308, 'accumulated_logging_time': 6.34293532371521, 'global_step': 33451, 'preemption_count': 0}), (33794, {'train/ssim': 0.7513776506696429, 'train/loss': 0.26415651185171946, 'validation/ssim': 0.726762607383406, 'validation/loss': 0.284640010045899, 'validation/num_examples': 3554, 'test/ssim': 0.7439062336376012, 'test/loss': 0.28593636144975215, 'test/num_examples': 3581, 'score': 7875.045525312424, 'total_duration': 8279.850937843323, 'accumulated_submission_time': 7875.045525312424, 'accumulated_eval_time': 397.07849621772766, 'accumulated_logging_time': 6.376688718795776, 'global_step': 33794, 'preemption_count': 0}), (34140, {'train/ssim': 0.7512272426060268, 'train/loss': 0.2642498016357422, 'validation/ssim': 0.7266439031065349, 'validation/loss': 0.28463939179445696, 'validation/num_examples': 3554, 'test/ssim': 0.7438452155255166, 'test/loss': 0.28590491496461357, 'test/num_examples': 3581, 'score': 7955.107652187347, 'total_duration': 8363.969428777695, 'accumulated_submission_time': 7955.107652187347, 'accumulated_eval_time': 401.0880081653595, 'accumulated_logging_time': 6.409821510314941, 'global_step': 34140, 'preemption_count': 0}), (34485, {'train/ssim': 0.7511179787772042, 'train/loss': 0.2643188067844936, 'validation/ssim': 0.7266925388866418, 'validation/loss': 0.28458929625400076, 'validation/num_examples': 3554, 'test/ssim': 0.7438459654687937, 'test/loss': 0.28584766361307945, 'test/num_examples': 3581, 'score': 8035.217735528946, 'total_duration': 8448.139996290207, 'accumulated_submission_time': 8035.217735528946, 'accumulated_eval_time': 405.10070538520813, 'accumulated_logging_time': 6.443702220916748, 'global_step': 34485, 'preemption_count': 0}), (34828, {'train/ssim': 0.7513903209141323, 'train/loss': 0.26417223044804167, 'validation/ssim': 0.7267753158852701, 'validation/loss': 0.284604168635912, 'validation/num_examples': 3554, 'test/ssim': 0.7439223233297263, 'test/loss': 0.2859044888604789, 'test/num_examples': 3581, 'score': 8115.333026409149, 'total_duration': 8532.313452720642, 'accumulated_submission_time': 8115.333026409149, 'accumulated_eval_time': 409.1116394996643, 'accumulated_logging_time': 6.4771833419799805, 'global_step': 34828, 'preemption_count': 0}), (35173, {'train/ssim': 0.7513918195452008, 'train/loss': 0.2641371658870152, 'validation/ssim': 0.7268032058947664, 'validation/loss': 0.28455235573033905, 'validation/num_examples': 3554, 'test/ssim': 0.7439750238891022, 'test/loss': 0.28583968694367845, 'test/num_examples': 3581, 'score': 8195.418248653412, 'total_duration': 8616.45526599884, 'accumulated_submission_time': 8195.418248653412, 'accumulated_eval_time': 413.12169218063354, 'accumulated_logging_time': 6.510056257247925, 'global_step': 35173, 'preemption_count': 0}), (35519, {'train/ssim': 0.751441410609654, 'train/loss': 0.26416036060878206, 'validation/ssim': 0.7268765717325548, 'validation/loss': 0.284526028523099, 'validation/num_examples': 3554, 'test/ssim': 0.7440558132330355, 'test/loss': 0.28581664323207556, 'test/num_examples': 3581, 'score': 8275.447546958923, 'total_duration': 8700.54442024231, 'accumulated_submission_time': 8275.447546958923, 'accumulated_eval_time': 417.1336545944214, 'accumulated_logging_time': 6.544367790222168, 'global_step': 35519, 'preemption_count': 0}), (35863, {'train/ssim': 0.751368590763637, 'train/loss': 0.26414031641823904, 'validation/ssim': 0.7268266994495639, 'validation/loss': 0.2844962150646719, 'validation/num_examples': 3554, 'test/ssim': 0.7440089758665527, 'test/loss': 0.2857884180941951, 'test/num_examples': 3581, 'score': 8355.44581079483, 'total_duration': 8784.603637218475, 'accumulated_submission_time': 8355.44581079483, 'accumulated_eval_time': 421.14607095718384, 'accumulated_logging_time': 6.579448938369751, 'global_step': 35863, 'preemption_count': 0}), (36189, {'train/ssim': 0.7514665467398507, 'train/loss': 0.26413134166172575, 'validation/ssim': 0.7269076903884707, 'validation/loss': 0.28450164193844085, 'validation/num_examples': 3554, 'test/ssim': 0.744079675064577, 'test/loss': 0.28579595161529603, 'test/num_examples': 3581, 'score': 8430.592392921448, 'total_duration': 8863.808090209961, 'accumulated_submission_time': 8430.592392921448, 'accumulated_eval_time': 425.1565029621124, 'accumulated_logging_time': 6.6140077114105225, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0205 03:47:28.078920 139681449744192 submission_runner.py:586] Timing: 8430.592392921448
I0205 03:47:28.078977 139681449744192 submission_runner.py:588] Total number of evals: 106
I0205 03:47:28.079022 139681449744192 submission_runner.py:589] ====================
I0205 03:47:28.079088 139681449744192 submission_runner.py:542] Using RNG seed 813120851
I0205 03:47:28.080942 139681449744192 submission_runner.py:551] --- Tuning run 5/5 ---
I0205 03:47:28.081068 139681449744192 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_5.
I0205 03:47:28.081360 139681449744192 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_4/fastmri_jax/trial_5/hparams.json.
I0205 03:47:28.082387 139681449744192 submission_runner.py:206] Initializing dataset.
I0205 03:47:28.454339 139681449744192 submission_runner.py:213] Initializing model.
Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 208, in cache_miss
    outs, out_flat, out_tree, args_flat = _python_pjit_helper(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 150, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _ = infer_params_fn(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 301, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 474, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat = _pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 935, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 345, in memoized_fun
    ans = call(fun, *args)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 888, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2150, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2172, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 188, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1640, in init
    _, v_out = self.init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1545, in init_with_output
    return init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 965, in wrapper
    return apply(fn, mutable=mutable, flags=init_flags)({}, *args, rngs=rngs,
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 933, in wrapper
    y = fn(root, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 2121, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1289, in make_rng
    return self.scope.make_rng(name)
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 711, in make_rng
    raise errors.InvalidRngError(f'{self.name} needs PRNG for "{name}"')
jax._src.traceback_util.UnfilteredStackTrace: flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)

The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)
