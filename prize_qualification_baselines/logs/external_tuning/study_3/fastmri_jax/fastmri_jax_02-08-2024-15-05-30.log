python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification/study_3 --overwrite=true --save_checkpoints=false --num_tuning_trials=5 --rng_seed=1572671891 --max_global_steps=36189 2>&1 | tee -a /logs/fastmri_jax_02-08-2024-15-05-30.log
I0208 15:05:49.994930 140466628462400 logger_utils.py:61] Removing existing experiment directory /experiment_runs/prize_qualification/study_3/fastmri_jax because --overwrite was set.
I0208 15:05:49.998747 140466628462400 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification/study_3/fastmri_jax.
I0208 15:05:51.666234 140466628462400 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0208 15:05:51.667277 140466628462400 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0208 15:05:51.667477 140466628462400 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0208 15:05:51.668741 140466628462400 submission_runner.py:542] Using RNG seed 1572671891
I0208 15:05:52.834996 140466628462400 submission_runner.py:551] --- Tuning run 1/5 ---
I0208 15:05:52.835266 140466628462400 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1.
I0208 15:05:52.835486 140466628462400 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1/hparams.json.
I0208 15:05:53.029496 140466628462400 submission_runner.py:206] Initializing dataset.
I0208 15:05:59.497716 140466628462400 submission_runner.py:213] Initializing model.
I0208 15:06:06.278142 140466628462400 submission_runner.py:255] Initializing optimizer.
I0208 15:06:07.151757 140466628462400 submission_runner.py:262] Initializing metrics bundle.
I0208 15:06:07.151956 140466628462400 submission_runner.py:280] Initializing checkpoint and logger.
I0208 15:06:07.152866 140466628462400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1 with prefix checkpoint_
I0208 15:06:07.153028 140466628462400 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1/meta_data_0.json.
I0208 15:06:07.153274 140466628462400 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0208 15:06:07.153348 140466628462400 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0208 15:06:07.531060 140466628462400 logger_utils.py:220] Unable to record git information. Continuing without it.
I0208 15:06:07.870853 140466628462400 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1/flags_0.json.
I0208 15:06:07.881764 140466628462400 submission_runner.py:314] Starting training loop.
I0208 15:07:03.784965 140304619394816 logging_writer.py:48] [0] global_step=0, grad_norm=4.160696983337402, loss=0.8857511878013611
I0208 15:07:03.800280 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:08:30.644123 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:09:30.636848 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:10:26.224188 140466628462400 submission_runner.py:408] Time since start: 258.34s, 	Step: 1, 	{'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 55.91798734664917, 'total_duration': 258.3423571586609, 'accumulated_submission_time': 55.91798734664917, 'accumulated_eval_time': 202.42385411262512, 'accumulated_logging_time': 0}
I0208 15:10:26.245503 140280502134528 logging_writer.py:48] [1] accumulated_eval_time=202.423854, accumulated_logging_time=0, accumulated_submission_time=55.917987, global_step=1, preemption_count=0, score=55.917987, test/loss=0.894958, test/num_examples=3581, test/ssim=0.283672, total_duration=258.342357, train/loss=0.892833, train/ssim=0.265677, validation/loss=0.895667, validation/num_examples=3554, validation/ssim=0.261322
I0208 15:10:48.116964 140280493741824 logging_writer.py:48] [100] global_step=100, grad_norm=1.0042463541030884, loss=0.38269874453544617
I0208 15:11:12.051508 140280502134528 logging_writer.py:48] [200] global_step=200, grad_norm=0.25711649656295776, loss=0.2843652367591858
I0208 15:11:35.889225 140280493741824 logging_writer.py:48] [300] global_step=300, grad_norm=0.10312224924564362, loss=0.32610946893692017
I0208 15:11:46.568907 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:11:48.362009 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:11:49.683215 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:11:51.005307 140466628462400 submission_runner.py:408] Time since start: 343.12s, 	Step: 339, 	{'train/ssim': 0.6871940749032157, 'train/loss': 0.3207972730909075, 'validation/ssim': 0.665303880201006, 'validation/loss': 0.33881968518087013, 'validation/num_examples': 3554, 'test/ssim': 0.6843897125235618, 'test/loss': 0.34010575291032535, 'test/num_examples': 3581, 'score': 136.21887683868408, 'total_duration': 343.12347984313965, 'accumulated_submission_time': 136.21887683868408, 'accumulated_eval_time': 206.8602089881897, 'accumulated_logging_time': 0.0311276912689209}
I0208 15:11:51.026185 140280502134528 logging_writer.py:48] [339] accumulated_eval_time=206.860209, accumulated_logging_time=0.031128, accumulated_submission_time=136.218877, global_step=339, preemption_count=0, score=136.218877, test/loss=0.340106, test/num_examples=3581, test/ssim=0.684390, total_duration=343.123480, train/loss=0.320797, train/ssim=0.687194, validation/loss=0.338820, validation/num_examples=3554, validation/ssim=0.665304
I0208 15:12:08.661295 140280493741824 logging_writer.py:48] [400] global_step=400, grad_norm=0.1257667988538742, loss=0.29917219281196594
I0208 15:12:43.807986 140280502134528 logging_writer.py:48] [500] global_step=500, grad_norm=0.16659963130950928, loss=0.30708473920822144
I0208 15:13:11.052839 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:13:12.424219 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:13:13.743929 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:13:15.065542 140466628462400 submission_runner.py:408] Time since start: 427.18s, 	Step: 583, 	{'train/ssim': 0.7098658425467355, 'train/loss': 0.2993877274649484, 'validation/ssim': 0.6883714597548537, 'validation/loss': 0.31659200021102984, 'validation/num_examples': 3554, 'test/ssim': 0.7065911014730523, 'test/loss': 0.3183245708142802, 'test/num_examples': 3581, 'score': 216.22331738471985, 'total_duration': 427.18370366096497, 'accumulated_submission_time': 216.22331738471985, 'accumulated_eval_time': 210.8728530406952, 'accumulated_logging_time': 0.06534719467163086}
I0208 15:13:15.088324 140280493741824 logging_writer.py:48] [583] accumulated_eval_time=210.872853, accumulated_logging_time=0.065347, accumulated_submission_time=216.223317, global_step=583, preemption_count=0, score=216.223317, test/loss=0.318325, test/num_examples=3581, test/ssim=0.706591, total_duration=427.183704, train/loss=0.299388, train/ssim=0.709866, validation/loss=0.316592, validation/num_examples=3554, validation/ssim=0.688371
I0208 15:13:17.977817 140280502134528 logging_writer.py:48] [600] global_step=600, grad_norm=0.0935281366109848, loss=0.2775394916534424
I0208 15:13:52.168136 140280493741824 logging_writer.py:48] [700] global_step=700, grad_norm=0.18253643810749054, loss=0.2409132570028305
I0208 15:14:26.446291 140280502134528 logging_writer.py:48] [800] global_step=800, grad_norm=0.14795638620853424, loss=0.3561832904815674
I0208 15:14:35.293904 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:14:36.665535 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:14:37.987523 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:14:39.311392 140466628462400 submission_runner.py:408] Time since start: 511.43s, 	Step: 826, 	{'train/ssim': 0.7211519650050572, 'train/loss': 0.28913658005850656, 'validation/ssim': 0.6996939792751126, 'validation/loss': 0.30625318742965674, 'validation/num_examples': 3554, 'test/ssim': 0.7172323875139626, 'test/loss': 0.3082724674824595, 'test/num_examples': 3581, 'score': 296.40825033187866, 'total_duration': 511.42957520484924, 'accumulated_submission_time': 296.40825033187866, 'accumulated_eval_time': 214.89030241966248, 'accumulated_logging_time': 0.10000324249267578}
I0208 15:14:39.327368 140280493741824 logging_writer.py:48] [826] accumulated_eval_time=214.890302, accumulated_logging_time=0.100003, accumulated_submission_time=296.408250, global_step=826, preemption_count=0, score=296.408250, test/loss=0.308272, test/num_examples=3581, test/ssim=0.717232, total_duration=511.429575, train/loss=0.289137, train/ssim=0.721152, validation/loss=0.306253, validation/num_examples=3554, validation/ssim=0.699694
I0208 15:15:02.395787 140280502134528 logging_writer.py:48] [900] global_step=900, grad_norm=0.10757599771022797, loss=0.36933162808418274
I0208 15:15:32.875974 140280493741824 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.11945334076881409, loss=0.2840626835823059
I0208 15:15:56.951151 140280502134528 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.5071536302566528, loss=0.26979583501815796
I0208 15:15:59.454047 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:16:00.826539 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:16:02.144804 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:16:03.468620 140466628462400 submission_runner.py:408] Time since start: 595.59s, 	Step: 1112, 	{'train/ssim': 0.7276527541024345, 'train/loss': 0.283478992325919, 'validation/ssim': 0.7057840307575971, 'validation/loss': 0.3010855670986916, 'validation/num_examples': 3554, 'test/ssim': 0.7226963378769896, 'test/loss': 0.3031021199123848, 'test/num_examples': 3581, 'score': 376.50986886024475, 'total_duration': 595.5867800712585, 'accumulated_submission_time': 376.50986886024475, 'accumulated_eval_time': 218.90482091903687, 'accumulated_logging_time': 0.1307234764099121}
I0208 15:16:03.483396 140280493741824 logging_writer.py:48] [1112] accumulated_eval_time=218.904821, accumulated_logging_time=0.130723, accumulated_submission_time=376.509869, global_step=1112, preemption_count=0, score=376.509869, test/loss=0.303102, test/num_examples=3581, test/ssim=0.722696, total_duration=595.586780, train/loss=0.283479, train/ssim=0.727653, validation/loss=0.301086, validation/num_examples=3554, validation/ssim=0.705784
I0208 15:16:22.500726 140280502134528 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.1390787661075592, loss=0.26873427629470825
I0208 15:16:46.525418 140280493741824 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.27435773611068726, loss=0.29432353377342224
I0208 15:17:10.162774 140280502134528 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.2798384130001068, loss=0.2968926429748535
I0208 15:17:23.767770 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:17:25.140673 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:17:26.458050 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:17:27.781151 140466628462400 submission_runner.py:408] Time since start: 679.90s, 	Step: 1458, 	{'train/ssim': 0.730339595249721, 'train/loss': 0.28099383626665386, 'validation/ssim': 0.7092974850080894, 'validation/loss': 0.29821444174917344, 'validation/num_examples': 3554, 'test/ssim': 0.7262398198608978, 'test/loss': 0.30017164838077703, 'test/num_examples': 3581, 'score': 456.7718312740326, 'total_duration': 679.8992731571198, 'accumulated_submission_time': 456.7718312740326, 'accumulated_eval_time': 222.91810631752014, 'accumulated_logging_time': 0.15522503852844238}
I0208 15:17:27.799104 140280493741824 logging_writer.py:48] [1458] accumulated_eval_time=222.918106, accumulated_logging_time=0.155225, accumulated_submission_time=456.771831, global_step=1458, preemption_count=0, score=456.771831, test/loss=0.300172, test/num_examples=3581, test/ssim=0.726240, total_duration=679.899273, train/loss=0.280994, train/ssim=0.730340, validation/loss=0.298214, validation/num_examples=3554, validation/ssim=0.709297
I0208 15:17:35.782437 140280502134528 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.16771577298641205, loss=0.27619728446006775
I0208 15:17:59.645730 140280493741824 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.41387638449668884, loss=0.2531028091907501
I0208 15:18:23.375930 140280502134528 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.17003193497657776, loss=0.4150604009628296
I0208 15:18:46.846658 140280493741824 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.11160360276699066, loss=0.2574235498905182
I0208 15:18:47.917647 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:18:49.290107 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:18:50.613804 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:18:51.937700 140466628462400 submission_runner.py:408] Time since start: 764.06s, 	Step: 1806, 	{'train/ssim': 0.734905515398298, 'train/loss': 0.27697512081691195, 'validation/ssim': 0.7133297896076604, 'validation/loss': 0.29460859325539884, 'validation/num_examples': 3554, 'test/ssim': 0.7303801203399888, 'test/loss': 0.2963384155852939, 'test/num_examples': 3581, 'score': 536.8662204742432, 'total_duration': 764.0558526515961, 'accumulated_submission_time': 536.8662204742432, 'accumulated_eval_time': 226.938090801239, 'accumulated_logging_time': 0.18469452857971191}
I0208 15:18:51.955426 140280502134528 logging_writer.py:48] [1806] accumulated_eval_time=226.938091, accumulated_logging_time=0.184695, accumulated_submission_time=536.866220, global_step=1806, preemption_count=0, score=536.866220, test/loss=0.296338, test/num_examples=3581, test/ssim=0.730380, total_duration=764.055853, train/loss=0.276975, train/ssim=0.734906, validation/loss=0.294609, validation/num_examples=3554, validation/ssim=0.713330
I0208 15:19:12.279504 140280493741824 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.08241644501686096, loss=0.3131087124347687
I0208 15:19:36.191770 140280502134528 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.09490411728620529, loss=0.27362847328186035
I0208 15:19:59.911576 140280493741824 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.17937307059764862, loss=0.31237322092056274
I0208 15:20:11.995681 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:20:13.368440 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:20:14.689831 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:20:16.011369 140466628462400 submission_runner.py:408] Time since start: 848.13s, 	Step: 2152, 	{'train/ssim': 0.7232328142438617, 'train/loss': 0.29465011187962126, 'validation/ssim': 0.7039935745814575, 'validation/loss': 0.3114003024211276, 'validation/num_examples': 3554, 'test/ssim': 0.720800208566043, 'test/loss': 0.3137618477402436, 'test/num_examples': 3581, 'score': 616.8835611343384, 'total_duration': 848.1295416355133, 'accumulated_submission_time': 616.8835611343384, 'accumulated_eval_time': 230.95373272895813, 'accumulated_logging_time': 0.21259403228759766}
I0208 15:20:16.027363 140280502134528 logging_writer.py:48] [2152] accumulated_eval_time=230.953733, accumulated_logging_time=0.212594, accumulated_submission_time=616.883561, global_step=2152, preemption_count=0, score=616.883561, test/loss=0.313762, test/num_examples=3581, test/ssim=0.720800, total_duration=848.129542, train/loss=0.294650, train/ssim=0.723233, validation/loss=0.311400, validation/num_examples=3554, validation/ssim=0.703994
I0208 15:20:25.378051 140280493741824 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.6036730408668518, loss=0.28819790482521057
I0208 15:20:49.207147 140280502134528 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.172145277261734, loss=0.28092896938323975
I0208 15:21:13.146234 140280493741824 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.23097577691078186, loss=0.33894622325897217
I0208 15:21:36.145221 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:21:37.521045 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:21:38.844594 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:21:40.168101 140466628462400 submission_runner.py:408] Time since start: 932.29s, 	Step: 2498, 	{'train/ssim': 0.7367127282278878, 'train/loss': 0.27586754730769564, 'validation/ssim': 0.7151943672622397, 'validation/loss': 0.29359514175269064, 'validation/num_examples': 3554, 'test/ssim': 0.7322592054855487, 'test/loss': 0.29526262195441216, 'test/num_examples': 3581, 'score': 696.9776549339294, 'total_duration': 932.2862796783447, 'accumulated_submission_time': 696.9776549339294, 'accumulated_eval_time': 234.97657227516174, 'accumulated_logging_time': 0.23948168754577637}
I0208 15:21:40.182941 140280502134528 logging_writer.py:48] [2498] accumulated_eval_time=234.976572, accumulated_logging_time=0.239482, accumulated_submission_time=696.977655, global_step=2498, preemption_count=0, score=696.977655, test/loss=0.295263, test/num_examples=3581, test/ssim=0.732259, total_duration=932.286280, train/loss=0.275868, train/ssim=0.736713, validation/loss=0.293595, validation/num_examples=3554, validation/ssim=0.715194
I0208 15:21:40.420424 140280493741824 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.2923394739627838, loss=0.3012067973613739
I0208 15:22:02.514714 140280502134528 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.10704053938388824, loss=0.24765631556510925
I0208 15:22:26.540789 140280493741824 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.14505627751350403, loss=0.29977312684059143
I0208 15:22:50.255730 140280502134528 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.21134044229984283, loss=0.23725084960460663
I0208 15:23:00.322660 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:23:01.693543 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:23:03.016768 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:23:04.337608 140466628462400 submission_runner.py:408] Time since start: 1016.46s, 	Step: 2844, 	{'train/ssim': 0.7388166018894741, 'train/loss': 0.27419754437037874, 'validation/ssim': 0.7174660978387029, 'validation/loss': 0.29198198635120637, 'validation/num_examples': 3554, 'test/ssim': 0.7344461764346552, 'test/loss': 0.29358455569542374, 'test/num_examples': 3581, 'score': 777.0949683189392, 'total_duration': 1016.4557588100433, 'accumulated_submission_time': 777.0949683189392, 'accumulated_eval_time': 238.99145531654358, 'accumulated_logging_time': 0.2640409469604492}
I0208 15:23:04.355894 140280493741824 logging_writer.py:48] [2844] accumulated_eval_time=238.991455, accumulated_logging_time=0.264041, accumulated_submission_time=777.094968, global_step=2844, preemption_count=0, score=777.094968, test/loss=0.293585, test/num_examples=3581, test/ssim=0.734446, total_duration=1016.455759, train/loss=0.274198, train/ssim=0.738817, validation/loss=0.291982, validation/num_examples=3554, validation/ssim=0.717466
I0208 15:23:15.617414 140280502134528 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.21890310943126678, loss=0.2515697777271271
I0208 15:23:39.188066 140280493741824 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.09432187676429749, loss=0.2639460265636444
I0208 15:24:03.479014 140280502134528 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.1847582310438156, loss=0.2874428927898407
I0208 15:24:24.416847 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:24:25.787621 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:24:27.109111 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:24:28.435264 140466628462400 submission_runner.py:408] Time since start: 1100.55s, 	Step: 3188, 	{'train/ssim': 0.7401871000017438, 'train/loss': 0.2737694127219064, 'validation/ssim': 0.7183199030801561, 'validation/loss': 0.29197903248320556, 'validation/num_examples': 3554, 'test/ssim': 0.7352607511868193, 'test/loss': 0.2936349723366378, 'test/num_examples': 3581, 'score': 857.13303399086, 'total_duration': 1100.553381204605, 'accumulated_submission_time': 857.13303399086, 'accumulated_eval_time': 243.00977039337158, 'accumulated_logging_time': 0.29268765449523926}
I0208 15:24:28.452710 140280493741824 logging_writer.py:48] [3188] accumulated_eval_time=243.009770, accumulated_logging_time=0.292688, accumulated_submission_time=857.133034, global_step=3188, preemption_count=0, score=857.133034, test/loss=0.293635, test/num_examples=3581, test/ssim=0.735261, total_duration=1100.553381, train/loss=0.273769, train/ssim=0.740187, validation/loss=0.291979, validation/num_examples=3554, validation/ssim=0.718320
I0208 15:24:29.413669 140280502134528 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.19263088703155518, loss=0.2655496597290039
I0208 15:24:53.345590 140280493741824 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.0756201222538948, loss=0.2633933126926422
I0208 15:25:17.318840 140280502134528 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.14303961396217346, loss=0.28577324748039246
I0208 15:25:40.788141 140280493741824 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.1066184863448143, loss=0.3284647762775421
I0208 15:25:48.638449 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:25:50.014113 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:25:51.332876 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:25:52.655555 140466628462400 submission_runner.py:408] Time since start: 1184.77s, 	Step: 3535, 	{'train/ssim': 0.7400742939540318, 'train/loss': 0.2726729597364153, 'validation/ssim': 0.7181579212023425, 'validation/loss': 0.2907690800638365, 'validation/num_examples': 3554, 'test/ssim': 0.7353010435937937, 'test/loss': 0.2923930662698967, 'test/num_examples': 3581, 'score': 937.29634308815, 'total_duration': 1184.7737319469452, 'accumulated_submission_time': 937.29634308815, 'accumulated_eval_time': 247.0268371105194, 'accumulated_logging_time': 0.3201866149902344}
I0208 15:25:52.671673 140280502134528 logging_writer.py:48] [3535] accumulated_eval_time=247.026837, accumulated_logging_time=0.320187, accumulated_submission_time=937.296343, global_step=3535, preemption_count=0, score=937.296343, test/loss=0.292393, test/num_examples=3581, test/ssim=0.735301, total_duration=1184.773732, train/loss=0.272673, train/ssim=0.740074, validation/loss=0.290769, validation/num_examples=3554, validation/ssim=0.718158
I0208 15:26:06.042071 140280493741824 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.096967414021492, loss=0.2490381896495819
I0208 15:26:30.023011 140280502134528 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.42453470826148987, loss=0.25591808557510376
I0208 15:26:53.759677 140280493741824 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.07120774686336517, loss=0.2650800943374634
I0208 15:27:12.839122 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:27:14.211500 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:27:15.534997 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:27:16.854051 140466628462400 submission_runner.py:408] Time since start: 1268.97s, 	Step: 3881, 	{'train/ssim': 0.7403202056884766, 'train/loss': 0.27328058651515413, 'validation/ssim': 0.7185890485412564, 'validation/loss': 0.29121209156935846, 'validation/num_examples': 3554, 'test/ssim': 0.7356736290491482, 'test/loss': 0.29279292238987015, 'test/num_examples': 3581, 'score': 1017.4413931369781, 'total_duration': 1268.9722275733948, 'accumulated_submission_time': 1017.4413931369781, 'accumulated_eval_time': 251.04173159599304, 'accumulated_logging_time': 0.34575533866882324}
I0208 15:27:16.869801 140280502134528 logging_writer.py:48] [3881] accumulated_eval_time=251.041732, accumulated_logging_time=0.345755, accumulated_submission_time=1017.441393, global_step=3881, preemption_count=0, score=1017.441393, test/loss=0.292793, test/num_examples=3581, test/ssim=0.735674, total_duration=1268.972228, train/loss=0.273281, train/ssim=0.740320, validation/loss=0.291212, validation/num_examples=3554, validation/ssim=0.718589
I0208 15:27:19.360001 140280493741824 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.133510023355484, loss=0.3222118616104126
I0208 15:27:43.200480 140280502134528 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2973729372024536, loss=0.2341429591178894
I0208 15:28:06.921755 140280493741824 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.116450734436512, loss=0.24462391436100006
I0208 15:28:31.104201 140280502134528 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.14830562472343445, loss=0.2943269908428192
I0208 15:28:36.953251 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:28:38.328182 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:28:39.650686 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:28:40.972599 140466628462400 submission_runner.py:408] Time since start: 1353.09s, 	Step: 4225, 	{'train/ssim': 0.7391737529209682, 'train/loss': 0.2730711357934134, 'validation/ssim': 0.717479836759637, 'validation/loss': 0.2909697026567776, 'validation/num_examples': 3554, 'test/ssim': 0.7346395254468026, 'test/loss': 0.29249185425247837, 'test/num_examples': 3581, 'score': 1097.5015771389008, 'total_duration': 1353.090767621994, 'accumulated_submission_time': 1097.5015771389008, 'accumulated_eval_time': 255.06102967262268, 'accumulated_logging_time': 0.3724069595336914}
I0208 15:28:40.988093 140280493741824 logging_writer.py:48] [4225] accumulated_eval_time=255.061030, accumulated_logging_time=0.372407, accumulated_submission_time=1097.501577, global_step=4225, preemption_count=0, score=1097.501577, test/loss=0.292492, test/num_examples=3581, test/ssim=0.734640, total_duration=1353.090768, train/loss=0.273071, train/ssim=0.739174, validation/loss=0.290970, validation/num_examples=3554, validation/ssim=0.717480
I0208 15:28:56.677147 140280502134528 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.2209918051958084, loss=0.2908939719200134
I0208 15:29:20.503667 140280493741824 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.0561593733727932, loss=0.2936173975467682
I0208 15:29:44.283309 140280502134528 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1116437166929245, loss=0.2537197470664978
I0208 15:30:00.983624 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:30:02.356647 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:30:03.677014 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:30:05.001307 140466628462400 submission_runner.py:408] Time since start: 1437.12s, 	Step: 4572, 	{'train/ssim': 0.7415586880275181, 'train/loss': 0.2717891590935843, 'validation/ssim': 0.7190310983223129, 'validation/loss': 0.2903687622551175, 'validation/num_examples': 3554, 'test/ssim': 0.7362364273902192, 'test/loss': 0.29186558343950714, 'test/num_examples': 3581, 'score': 1177.474592924118, 'total_duration': 1437.1194834709167, 'accumulated_submission_time': 1177.474592924118, 'accumulated_eval_time': 259.0786759853363, 'accumulated_logging_time': 0.39757752418518066}
I0208 15:30:05.017478 140280493741824 logging_writer.py:48] [4572] accumulated_eval_time=259.078676, accumulated_logging_time=0.397578, accumulated_submission_time=1177.474593, global_step=4572, preemption_count=0, score=1177.474593, test/loss=0.291866, test/num_examples=3581, test/ssim=0.736236, total_duration=1437.119483, train/loss=0.271789, train/ssim=0.741559, validation/loss=0.290369, validation/num_examples=3554, validation/ssim=0.719031
I0208 15:30:09.624078 140280502134528 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.05355486273765564, loss=0.24674735963344574
I0208 15:30:33.460868 140280493741824 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.13786821067333221, loss=0.27871981263160706
I0208 15:30:57.153805 140280502134528 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.14424312114715576, loss=0.2519305348396301
I0208 15:31:20.932147 140280493741824 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.044976796954870224, loss=0.2844030261039734
I0208 15:31:25.197878 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:31:26.570878 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:31:27.892446 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:31:29.215392 140466628462400 submission_runner.py:408] Time since start: 1521.33s, 	Step: 4919, 	{'train/ssim': 0.740943159375872, 'train/loss': 0.2720399243491037, 'validation/ssim': 0.7187721883573087, 'validation/loss': 0.29030807057189084, 'validation/num_examples': 3554, 'test/ssim': 0.7359213148605487, 'test/loss': 0.2918626177547298, 'test/num_examples': 3581, 'score': 1257.6327981948853, 'total_duration': 1521.3335707187653, 'accumulated_submission_time': 1257.6327981948853, 'accumulated_eval_time': 263.0961480140686, 'accumulated_logging_time': 0.4233999252319336}
I0208 15:31:29.231180 140280502134528 logging_writer.py:48] [4919] accumulated_eval_time=263.096148, accumulated_logging_time=0.423400, accumulated_submission_time=1257.632798, global_step=4919, preemption_count=0, score=1257.632798, test/loss=0.291863, test/num_examples=3581, test/ssim=0.735921, total_duration=1521.333571, train/loss=0.272040, train/ssim=0.740943, validation/loss=0.290308, validation/num_examples=3554, validation/ssim=0.718772
I0208 15:31:46.466724 140280493741824 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.22666843235492706, loss=0.2575603127479553
I0208 15:32:10.526416 140280502134528 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.14599154889583588, loss=0.2325703501701355
I0208 15:32:34.152847 140280493741824 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.10365559905767441, loss=0.2572718858718872
I0208 15:32:49.234037 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:32:50.606292 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:32:51.929260 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:32:53.251823 140466628462400 submission_runner.py:408] Time since start: 1605.37s, 	Step: 5264, 	{'train/ssim': 0.7398541995457241, 'train/loss': 0.2729257345199585, 'validation/ssim': 0.7182161742271033, 'validation/loss': 0.2908276422143184, 'validation/num_examples': 3554, 'test/ssim': 0.7353418132373988, 'test/loss': 0.29238464645219564, 'test/num_examples': 3581, 'score': 1337.6137821674347, 'total_duration': 1605.3700017929077, 'accumulated_submission_time': 1337.6137821674347, 'accumulated_eval_time': 267.11389446258545, 'accumulated_logging_time': 0.44838404655456543}
I0208 15:32:53.267200 140280502134528 logging_writer.py:48] [5264] accumulated_eval_time=267.113894, accumulated_logging_time=0.448384, accumulated_submission_time=1337.613782, global_step=5264, preemption_count=0, score=1337.613782, test/loss=0.292385, test/num_examples=3581, test/ssim=0.735342, total_duration=1605.370002, train/loss=0.272926, train/ssim=0.739854, validation/loss=0.290828, validation/num_examples=3554, validation/ssim=0.718216
I0208 15:33:00.052187 140280493741824 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.18958906829357147, loss=0.25862181186676025
I0208 15:33:23.790447 140280502134528 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.09539701789617538, loss=0.3216995894908905
I0208 15:33:47.785465 140280493741824 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.11499384045600891, loss=0.274518221616745
I0208 15:34:11.987468 140280502134528 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.09320030361413956, loss=0.2168097198009491
I0208 15:34:13.365184 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:34:14.737850 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:34:16.058772 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:34:17.379154 140466628462400 submission_runner.py:408] Time since start: 1689.50s, 	Step: 5607, 	{'train/ssim': 0.7430362701416016, 'train/loss': 0.27040735312870573, 'validation/ssim': 0.72083666731148, 'validation/loss': 0.28880499827439154, 'validation/num_examples': 3554, 'test/ssim': 0.7379724097231919, 'test/loss': 0.2903670263303721, 'test/num_examples': 3581, 'score': 1417.68976521492, 'total_duration': 1689.497330904007, 'accumulated_submission_time': 1417.68976521492, 'accumulated_eval_time': 271.12782073020935, 'accumulated_logging_time': 0.47333264350891113}
I0208 15:34:17.396036 140280493741824 logging_writer.py:48] [5607] accumulated_eval_time=271.127821, accumulated_logging_time=0.473333, accumulated_submission_time=1417.689765, global_step=5607, preemption_count=0, score=1417.689765, test/loss=0.290367, test/num_examples=3581, test/ssim=0.737972, total_duration=1689.497331, train/loss=0.270407, train/ssim=0.743036, validation/loss=0.288805, validation/num_examples=3554, validation/ssim=0.720837
I0208 15:34:37.574958 140280502134528 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.14337655901908875, loss=0.2542211413383484
I0208 15:35:01.286410 140280493741824 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.13400079309940338, loss=0.358561247587204
I0208 15:35:25.171946 140280502134528 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.1067553162574768, loss=0.2521863877773285
I0208 15:35:37.529378 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:35:38.901868 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:35:40.221667 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:35:41.544847 140466628462400 submission_runner.py:408] Time since start: 1773.66s, 	Step: 5954, 	{'train/ssim': 0.7426825250898089, 'train/loss': 0.27037811279296875, 'validation/ssim': 0.7202349712691686, 'validation/loss': 0.28870113203212927, 'validation/num_examples': 3554, 'test/ssim': 0.7374507900856954, 'test/loss': 0.29025484163379645, 'test/num_examples': 3581, 'score': 1497.8008234500885, 'total_duration': 1773.6630256175995, 'accumulated_submission_time': 1497.8008234500885, 'accumulated_eval_time': 275.14325308799744, 'accumulated_logging_time': 0.4997069835662842}
I0208 15:35:41.560958 140280493741824 logging_writer.py:48] [5954] accumulated_eval_time=275.143253, accumulated_logging_time=0.499707, accumulated_submission_time=1497.800823, global_step=5954, preemption_count=0, score=1497.800823, test/loss=0.290255, test/num_examples=3581, test/ssim=0.737451, total_duration=1773.663026, train/loss=0.270378, train/ssim=0.742683, validation/loss=0.288701, validation/num_examples=3554, validation/ssim=0.720235
I0208 15:35:50.477636 140280502134528 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.2922615110874176, loss=0.22825944423675537
I0208 15:36:15.244104 140280493741824 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.09331990778446198, loss=0.3468254804611206
I0208 15:36:38.919059 140280502134528 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.08444889634847641, loss=0.23744544386863708
I0208 15:37:01.630034 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:37:03.003701 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:37:04.323812 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:37:05.645038 140466628462400 submission_runner.py:408] Time since start: 1857.76s, 	Step: 6296, 	{'train/ssim': 0.742091178894043, 'train/loss': 0.2712857723236084, 'validation/ssim': 0.7200937351619654, 'validation/loss': 0.2893256346831915, 'validation/num_examples': 3554, 'test/ssim': 0.7372403969081611, 'test/loss': 0.2908137539051592, 'test/num_examples': 3581, 'score': 1577.8476405143738, 'total_duration': 1857.763218164444, 'accumulated_submission_time': 1577.8476405143738, 'accumulated_eval_time': 279.15823125839233, 'accumulated_logging_time': 0.5257272720336914}
I0208 15:37:05.661485 140280493741824 logging_writer.py:48] [6296] accumulated_eval_time=279.158231, accumulated_logging_time=0.525727, accumulated_submission_time=1577.847641, global_step=6296, preemption_count=0, score=1577.847641, test/loss=0.290814, test/num_examples=3581, test/ssim=0.737240, total_duration=1857.763218, train/loss=0.271286, train/ssim=0.742091, validation/loss=0.289326, validation/num_examples=3554, validation/ssim=0.720094
I0208 15:37:06.045594 140280502134528 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.1926305741071701, loss=0.26346439123153687
I0208 15:37:28.894338 140280493741824 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.2832348048686981, loss=0.21498432755470276
I0208 15:37:52.979319 140280502134528 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.12802143394947052, loss=0.3013668954372406
I0208 15:38:17.053307 140280493741824 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.26923656463623047, loss=0.33828067779541016
I0208 15:38:25.720832 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:38:27.094250 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:38:28.415997 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:38:29.738087 140466628462400 submission_runner.py:408] Time since start: 1941.86s, 	Step: 6638, 	{'train/ssim': 0.7428139277866909, 'train/loss': 0.27047950880868094, 'validation/ssim': 0.720252831866383, 'validation/loss': 0.2890228975604073, 'validation/num_examples': 3554, 'test/ssim': 0.7374012938294122, 'test/loss': 0.29054350161878667, 'test/num_examples': 3581, 'score': 1657.8847556114197, 'total_duration': 1941.856261730194, 'accumulated_submission_time': 1657.8847556114197, 'accumulated_eval_time': 283.1754529476166, 'accumulated_logging_time': 0.5520541667938232}
I0208 15:38:29.755090 140280502134528 logging_writer.py:48] [6638] accumulated_eval_time=283.175453, accumulated_logging_time=0.552054, accumulated_submission_time=1657.884756, global_step=6638, preemption_count=0, score=1657.884756, test/loss=0.290544, test/num_examples=3581, test/ssim=0.737401, total_duration=1941.856262, train/loss=0.270480, train/ssim=0.742814, validation/loss=0.289023, validation/num_examples=3554, validation/ssim=0.720253
I0208 15:38:42.396255 140280493741824 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.10461844503879547, loss=0.2305009961128235
I0208 15:39:06.098306 140280502134528 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.09704682976007462, loss=0.3652305006980896
I0208 15:39:30.090342 140280493741824 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.04056137800216675, loss=0.3279849886894226
I0208 15:39:49.753835 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:39:51.126976 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:39:52.448215 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:39:53.772871 140466628462400 submission_runner.py:408] Time since start: 2025.89s, 	Step: 6984, 	{'train/ssim': 0.7429917199271066, 'train/loss': 0.27064037322998047, 'validation/ssim': 0.7208075407990996, 'validation/loss': 0.2890006061611916, 'validation/num_examples': 3554, 'test/ssim': 0.737995862494764, 'test/loss': 0.29048991476281066, 'test/num_examples': 3581, 'score': 1737.8613169193268, 'total_duration': 2025.891048192978, 'accumulated_submission_time': 1737.8613169193268, 'accumulated_eval_time': 287.19444942474365, 'accumulated_logging_time': 0.5787684917449951}
I0208 15:39:53.790375 140280502134528 logging_writer.py:48] [6984] accumulated_eval_time=287.194449, accumulated_logging_time=0.578768, accumulated_submission_time=1737.861317, global_step=6984, preemption_count=0, score=1737.861317, test/loss=0.290490, test/num_examples=3581, test/ssim=0.737996, total_duration=2025.891048, train/loss=0.270640, train/ssim=0.742992, validation/loss=0.289001, validation/num_examples=3554, validation/ssim=0.720808
I0208 15:39:55.455735 140280493741824 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.18354660272598267, loss=0.2529318928718567
I0208 15:40:19.309051 140280502134528 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.11880946159362793, loss=0.23121505975723267
I0208 15:40:43.285776 140280493741824 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.06952379643917084, loss=0.2667539119720459
I0208 15:41:06.909033 140280502134528 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.08512422442436218, loss=0.2883765399456024
I0208 15:41:13.877697 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:41:15.250793 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:41:16.573930 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:41:17.896530 140466628462400 submission_runner.py:408] Time since start: 2110.01s, 	Step: 7331, 	{'train/ssim': 0.7436522756304059, 'train/loss': 0.2696965081351144, 'validation/ssim': 0.7215000511087859, 'validation/loss': 0.2879728146597584, 'validation/num_examples': 3554, 'test/ssim': 0.7387117856176696, 'test/loss': 0.2893841915775098, 'test/num_examples': 3581, 'score': 1817.9266390800476, 'total_duration': 2110.0144007205963, 'accumulated_submission_time': 1817.9266390800476, 'accumulated_eval_time': 291.2129316329956, 'accumulated_logging_time': 0.6057913303375244}
I0208 15:41:17.913135 140280493741824 logging_writer.py:48] [7331] accumulated_eval_time=291.212932, accumulated_logging_time=0.605791, accumulated_submission_time=1817.926639, global_step=7331, preemption_count=0, score=1817.926639, test/loss=0.289384, test/num_examples=3581, test/ssim=0.738712, total_duration=2110.014401, train/loss=0.269697, train/ssim=0.743652, validation/loss=0.287973, validation/num_examples=3554, validation/ssim=0.721500
I0208 15:41:32.367285 140280502134528 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.24265217781066895, loss=0.2202140837907791
I0208 15:41:56.703365 140280493741824 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.14301113784313202, loss=0.16140317916870117
I0208 15:42:20.568294 140280502134528 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.1586250215768814, loss=0.2903723120689392
I0208 15:42:38.043334 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:42:39.415367 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:42:40.735493 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:42:42.058946 140466628462400 submission_runner.py:408] Time since start: 2194.18s, 	Step: 7674, 	{'train/ssim': 0.742138317653111, 'train/loss': 0.2708191360746111, 'validation/ssim': 0.7195088006031936, 'validation/loss': 0.28937241570897226, 'validation/num_examples': 3554, 'test/ssim': 0.7367458434052988, 'test/loss': 0.29074131620226545, 'test/num_examples': 3581, 'score': 1898.0349142551422, 'total_duration': 2194.177098274231, 'accumulated_submission_time': 1898.0349142551422, 'accumulated_eval_time': 295.2284879684448, 'accumulated_logging_time': 0.6318953037261963}
I0208 15:42:42.080322 140280493741824 logging_writer.py:48] [7674] accumulated_eval_time=295.228488, accumulated_logging_time=0.631895, accumulated_submission_time=1898.034914, global_step=7674, preemption_count=0, score=1898.034914, test/loss=0.290741, test/num_examples=3581, test/ssim=0.736746, total_duration=2194.177098, train/loss=0.270819, train/ssim=0.742138, validation/loss=0.289372, validation/num_examples=3554, validation/ssim=0.719509
I0208 15:42:46.261724 140280502134528 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.1217263787984848, loss=0.24463987350463867
I0208 15:43:10.273828 140280493741824 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.13873191177845, loss=0.30280572175979614
I0208 15:43:33.929697 140280502134528 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.15177881717681885, loss=0.2947458326816559
I0208 15:43:57.623991 140280493741824 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.15413768589496613, loss=0.295162558555603
I0208 15:44:02.110401 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:44:03.481614 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:44:04.803381 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:44:06.124918 140466628462400 submission_runner.py:408] Time since start: 2278.24s, 	Step: 8020, 	{'train/ssim': 0.744044576372419, 'train/loss': 0.26975313254765104, 'validation/ssim': 0.7217948883520329, 'validation/loss': 0.2882133659916643, 'validation/num_examples': 3554, 'test/ssim': 0.7389935597598436, 'test/loss': 0.28960542484422996, 'test/num_examples': 3581, 'score': 1978.0424547195435, 'total_duration': 2278.243096113205, 'accumulated_submission_time': 1978.0424547195435, 'accumulated_eval_time': 299.24297618865967, 'accumulated_logging_time': 0.6634461879730225}
I0208 15:44:06.141689 140280502134528 logging_writer.py:48] [8020] accumulated_eval_time=299.242976, accumulated_logging_time=0.663446, accumulated_submission_time=1978.042455, global_step=8020, preemption_count=0, score=1978.042455, test/loss=0.289605, test/num_examples=3581, test/ssim=0.738994, total_duration=2278.243096, train/loss=0.269753, train/ssim=0.744045, validation/loss=0.288213, validation/num_examples=3554, validation/ssim=0.721795
I0208 15:44:23.279940 140280493741824 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.15633268654346466, loss=0.2556498944759369
I0208 15:44:47.363469 140280502134528 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.06929730623960495, loss=0.29509392380714417
I0208 15:45:11.146025 140280493741824 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.18060153722763062, loss=0.2143525779247284
I0208 15:45:26.252738 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:45:27.627015 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:45:28.946477 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:45:30.269175 140466628462400 submission_runner.py:408] Time since start: 2362.39s, 	Step: 8365, 	{'train/ssim': 0.7434047971452985, 'train/loss': 0.2699533700942993, 'validation/ssim': 0.7211110335625351, 'validation/loss': 0.2882835031830332, 'validation/num_examples': 3554, 'test/ssim': 0.7383492221315624, 'test/loss': 0.28965805722694427, 'test/num_examples': 3581, 'score': 2058.131326675415, 'total_duration': 2362.3873484134674, 'accumulated_submission_time': 2058.131326675415, 'accumulated_eval_time': 303.2593698501587, 'accumulated_logging_time': 0.6898679733276367}
I0208 15:45:30.285791 140280502134528 logging_writer.py:48] [8365] accumulated_eval_time=303.259370, accumulated_logging_time=0.689868, accumulated_submission_time=2058.131327, global_step=8365, preemption_count=0, score=2058.131327, test/loss=0.289658, test/num_examples=3581, test/ssim=0.738349, total_duration=2362.387348, train/loss=0.269953, train/ssim=0.743405, validation/loss=0.288284, validation/num_examples=3554, validation/ssim=0.721111
I0208 15:45:36.520183 140280493741824 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.12075894325971603, loss=0.2685275375843048
I0208 15:46:00.650939 140280502134528 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.19381466507911682, loss=0.26431411504745483
I0208 15:46:24.988263 140280493741824 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.09719216823577881, loss=0.28867292404174805
I0208 15:46:48.965357 140280502134528 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.2033853530883789, loss=0.21802297234535217
I0208 15:46:50.456914 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:46:51.832180 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:46:53.151019 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:46:54.474460 140466628462400 submission_runner.py:408] Time since start: 2446.59s, 	Step: 8708, 	{'train/ssim': 0.7450571060180664, 'train/loss': 0.2695001704352243, 'validation/ssim': 0.7223065944622257, 'validation/loss': 0.28825949441870075, 'validation/num_examples': 3554, 'test/ssim': 0.7395078844945546, 'test/loss': 0.28965195541573585, 'test/num_examples': 3581, 'score': 2138.2803223133087, 'total_duration': 2446.592636823654, 'accumulated_submission_time': 2138.2803223133087, 'accumulated_eval_time': 307.27687430381775, 'accumulated_logging_time': 0.7161507606506348}
I0208 15:46:54.492295 140280493741824 logging_writer.py:48] [8708] accumulated_eval_time=307.276874, accumulated_logging_time=0.716151, accumulated_submission_time=2138.280322, global_step=8708, preemption_count=0, score=2138.280322, test/loss=0.289652, test/num_examples=3581, test/ssim=0.739508, total_duration=2446.592637, train/loss=0.269500, train/ssim=0.745057, validation/loss=0.288259, validation/num_examples=3554, validation/ssim=0.722307
I0208 15:47:14.601841 140280502134528 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.12903615832328796, loss=0.34600314497947693
I0208 15:47:38.348046 140280493741824 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.14425210654735565, loss=0.28313422203063965
I0208 15:48:02.403773 140280502134528 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.755118191242218, loss=0.24117884039878845
I0208 15:48:14.573887 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:48:15.947134 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:48:17.264708 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:48:18.589179 140466628462400 submission_runner.py:408] Time since start: 2530.71s, 	Step: 9053, 	{'train/ssim': 0.7446896008082798, 'train/loss': 0.26951772826058523, 'validation/ssim': 0.7220156041168402, 'validation/loss': 0.288230230517111, 'validation/num_examples': 3554, 'test/ssim': 0.7392402910979824, 'test/loss': 0.28965836402192124, 'test/num_examples': 3581, 'score': 2218.340068101883, 'total_duration': 2530.707357406616, 'accumulated_submission_time': 2218.340068101883, 'accumulated_eval_time': 311.29213285446167, 'accumulated_logging_time': 0.7432451248168945}
I0208 15:48:18.606768 140280493741824 logging_writer.py:48] [9053] accumulated_eval_time=311.292133, accumulated_logging_time=0.743245, accumulated_submission_time=2218.340068, global_step=9053, preemption_count=0, score=2218.340068, test/loss=0.289658, test/num_examples=3581, test/ssim=0.739240, total_duration=2530.707357, train/loss=0.269518, train/ssim=0.744690, validation/loss=0.288230, validation/num_examples=3554, validation/ssim=0.722016
I0208 15:48:27.735410 140280502134528 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.17959633469581604, loss=0.28321996331214905
I0208 15:48:51.806501 140280493741824 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.13748060166835785, loss=0.2375347763299942
I0208 15:49:15.532104 140280502134528 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.07916074991226196, loss=0.41621720790863037
I0208 15:49:38.659217 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:49:40.031633 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:49:41.355242 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:49:42.681462 140466628462400 submission_runner.py:408] Time since start: 2614.80s, 	Step: 9398, 	{'train/ssim': 0.7459303992135184, 'train/loss': 0.26855312074933735, 'validation/ssim': 0.7233655904878307, 'validation/loss': 0.28725948988485683, 'validation/num_examples': 3554, 'test/ssim': 0.7406060741587546, 'test/loss': 0.28859511489676415, 'test/num_examples': 3581, 'score': 2298.3692531585693, 'total_duration': 2614.7996389865875, 'accumulated_submission_time': 2298.3692531585693, 'accumulated_eval_time': 315.3143537044525, 'accumulated_logging_time': 0.7714033126831055}
I0208 15:49:42.698802 140280493741824 logging_writer.py:48] [9398] accumulated_eval_time=315.314354, accumulated_logging_time=0.771403, accumulated_submission_time=2298.369253, global_step=9398, preemption_count=0, score=2298.369253, test/loss=0.288595, test/num_examples=3581, test/ssim=0.740606, total_duration=2614.799639, train/loss=0.268553, train/ssim=0.745930, validation/loss=0.287259, validation/num_examples=3554, validation/ssim=0.723366
I0208 15:49:42.937265 140280502134528 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.10104478150606155, loss=0.3028360605239868
I0208 15:50:05.194204 140280493741824 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.14098456501960754, loss=0.27868956327438354
I0208 15:50:29.203244 140280502134528 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.11858560144901276, loss=0.3330281674861908
I0208 15:50:53.324909 140280493741824 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.07082371413707733, loss=0.400339275598526
I0208 15:51:02.709966 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:51:04.081885 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:51:05.403092 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:51:06.722122 140466628462400 submission_runner.py:408] Time since start: 2698.84s, 	Step: 9740, 	{'train/ssim': 0.7458776746477399, 'train/loss': 0.2690248829977853, 'validation/ssim': 0.7237394265264491, 'validation/loss': 0.2874351591626512, 'validation/num_examples': 3554, 'test/ssim': 0.7407723570362678, 'test/loss': 0.28887729809890744, 'test/num_examples': 3581, 'score': 2378.3575394153595, 'total_duration': 2698.840270757675, 'accumulated_submission_time': 2378.3575394153595, 'accumulated_eval_time': 319.326447725296, 'accumulated_logging_time': 0.7993285655975342}
I0208 15:51:06.739689 140280502134528 logging_writer.py:48] [9740] accumulated_eval_time=319.326448, accumulated_logging_time=0.799329, accumulated_submission_time=2378.357539, global_step=9740, preemption_count=0, score=2378.357539, test/loss=0.288877, test/num_examples=3581, test/ssim=0.740772, total_duration=2698.840271, train/loss=0.269025, train/ssim=0.745878, validation/loss=0.287435, validation/num_examples=3554, validation/ssim=0.723739
I0208 15:51:19.213686 140280493741824 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.1399809569120407, loss=0.24627438187599182
I0208 15:51:43.197251 140280502134528 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.10810725390911102, loss=0.2807464301586151
I0208 15:52:06.991580 140280493741824 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.07260875403881073, loss=0.2963506579399109
I0208 15:52:26.778576 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:52:28.153473 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:52:29.474544 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:52:30.793368 140466628462400 submission_runner.py:408] Time since start: 2782.91s, 	Step: 10084, 	{'train/ssim': 0.7447167805262974, 'train/loss': 0.2694817951747349, 'validation/ssim': 0.7220355255521947, 'validation/loss': 0.28815937203239306, 'validation/num_examples': 3554, 'test/ssim': 0.7392846741046495, 'test/loss': 0.28955061080834615, 'test/num_examples': 3581, 'score': 2458.3733851909637, 'total_duration': 2782.9115421772003, 'accumulated_submission_time': 2458.3733851909637, 'accumulated_eval_time': 323.3411955833435, 'accumulated_logging_time': 0.8272280693054199}
I0208 15:52:30.810424 140280502134528 logging_writer.py:48] [10084] accumulated_eval_time=323.341196, accumulated_logging_time=0.827228, accumulated_submission_time=2458.373385, global_step=10084, preemption_count=0, score=2458.373385, test/loss=0.289551, test/num_examples=3581, test/ssim=0.739285, total_duration=2782.911542, train/loss=0.269482, train/ssim=0.744717, validation/loss=0.288159, validation/num_examples=3554, validation/ssim=0.722036
I0208 15:52:32.565642 140280493741824 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.2226538509130478, loss=0.24293817579746246
I0208 15:52:56.192918 140280502134528 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.12078931927680969, loss=0.3651287257671356
I0208 15:53:20.281470 140280493741824 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.09212808310985565, loss=0.2948857247829437
I0208 15:53:44.273171 140280502134528 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.33129116892814636, loss=0.2861897051334381
I0208 15:53:50.873287 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:53:52.247578 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:53:53.571593 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:53:54.895693 140466628462400 submission_runner.py:408] Time since start: 2867.01s, 	Step: 10429, 	{'train/ssim': 0.7417423384530204, 'train/loss': 0.2712743282318115, 'validation/ssim': 0.7195695953283272, 'validation/loss': 0.2896735385085467, 'validation/num_examples': 3554, 'test/ssim': 0.7367384803258518, 'test/loss': 0.2910769158187308, 'test/num_examples': 3581, 'score': 2538.4143187999725, 'total_duration': 2867.0138463974, 'accumulated_submission_time': 2538.4143187999725, 'accumulated_eval_time': 327.36353492736816, 'accumulated_logging_time': 0.8536674976348877}
I0208 15:53:54.915905 140280493741824 logging_writer.py:48] [10429] accumulated_eval_time=327.363535, accumulated_logging_time=0.853667, accumulated_submission_time=2538.414319, global_step=10429, preemption_count=0, score=2538.414319, test/loss=0.291077, test/num_examples=3581, test/ssim=0.736738, total_duration=2867.013846, train/loss=0.271274, train/ssim=0.741742, validation/loss=0.289674, validation/num_examples=3554, validation/ssim=0.719570
I0208 15:54:09.705471 140280502134528 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.12906229496002197, loss=0.24649056792259216
I0208 15:54:33.511368 140280493741824 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.15843980014324188, loss=0.2475569248199463
I0208 15:54:57.627015 140280502134528 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.19048994779586792, loss=0.2544642984867096
I0208 15:55:15.006620 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:55:16.380801 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:55:17.701643 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:55:19.025624 140466628462400 submission_runner.py:408] Time since start: 2951.14s, 	Step: 10772, 	{'train/ssim': 0.7439629690987724, 'train/loss': 0.26972126960754395, 'validation/ssim': 0.7215402374525183, 'validation/loss': 0.2880775739318813, 'validation/num_examples': 3554, 'test/ssim': 0.7387032635349763, 'test/loss': 0.2895300555448897, 'test/num_examples': 3581, 'score': 2618.481980085373, 'total_duration': 2951.143794298172, 'accumulated_submission_time': 2618.481980085373, 'accumulated_eval_time': 331.38250207901, 'accumulated_logging_time': 0.8842437267303467}
I0208 15:55:19.043029 140280493741824 logging_writer.py:48] [10772] accumulated_eval_time=331.382502, accumulated_logging_time=0.884244, accumulated_submission_time=2618.481980, global_step=10772, preemption_count=0, score=2618.481980, test/loss=0.289530, test/num_examples=3581, test/ssim=0.738703, total_duration=2951.143794, train/loss=0.269721, train/ssim=0.743963, validation/loss=0.288078, validation/num_examples=3554, validation/ssim=0.721540
I0208 15:55:23.755743 140280502134528 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.09546003490686417, loss=0.23375031352043152
I0208 15:55:47.818646 140280493741824 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.15333661437034607, loss=0.2475328892469406
I0208 15:56:11.957511 140280502134528 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.12478777766227722, loss=0.26852932572364807
I0208 15:56:35.590236 140280493741824 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.15594102442264557, loss=0.24528226256370544
I0208 15:56:39.254320 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:56:40.628445 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:56:41.951832 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:56:43.274385 140466628462400 submission_runner.py:408] Time since start: 3035.39s, 	Step: 11116, 	{'train/ssim': 0.7449778829302106, 'train/loss': 0.2687648705073765, 'validation/ssim': 0.7219717082644556, 'validation/loss': 0.28773325939962013, 'validation/num_examples': 3554, 'test/ssim': 0.7391950899713767, 'test/loss': 0.28910320146694357, 'test/num_examples': 3581, 'score': 2698.670265674591, 'total_duration': 3035.3925642967224, 'accumulated_submission_time': 2698.670265674591, 'accumulated_eval_time': 335.40252470970154, 'accumulated_logging_time': 0.9122757911682129}
I0208 15:56:43.292114 140280502134528 logging_writer.py:48] [11116] accumulated_eval_time=335.402525, accumulated_logging_time=0.912276, accumulated_submission_time=2698.670266, global_step=11116, preemption_count=0, score=2698.670266, test/loss=0.289103, test/num_examples=3581, test/ssim=0.739195, total_duration=3035.392564, train/loss=0.268765, train/ssim=0.744978, validation/loss=0.287733, validation/num_examples=3554, validation/ssim=0.721972
I0208 15:57:01.344061 140280493741824 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.14527101814746857, loss=0.38718828558921814
I0208 15:57:25.561751 140280502134528 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.20473724603652954, loss=0.2817070186138153
I0208 15:57:49.460747 140280493741824 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.1253241002559662, loss=0.268729567527771
I0208 15:58:03.465888 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:58:04.839866 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:58:06.160858 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:58:07.484571 140466628462400 submission_runner.py:408] Time since start: 3119.60s, 	Step: 11460, 	{'train/ssim': 0.7453946386064801, 'train/loss': 0.2682352236339024, 'validation/ssim': 0.7226209409731992, 'validation/loss': 0.2870142501461821, 'validation/num_examples': 3554, 'test/ssim': 0.7399028318948967, 'test/loss': 0.28836051900438076, 'test/num_examples': 3581, 'score': 2778.822010755539, 'total_duration': 3119.602737426758, 'accumulated_submission_time': 2778.822010755539, 'accumulated_eval_time': 339.4211540222168, 'accumulated_logging_time': 0.9393706321716309}
I0208 15:58:07.501998 140280502134528 logging_writer.py:48] [11460] accumulated_eval_time=339.421154, accumulated_logging_time=0.939371, accumulated_submission_time=2778.822011, global_step=11460, preemption_count=0, score=2778.822011, test/loss=0.288361, test/num_examples=3581, test/ssim=0.739903, total_duration=3119.602737, train/loss=0.268235, train/ssim=0.745395, validation/loss=0.287014, validation/num_examples=3554, validation/ssim=0.722621
I0208 15:58:15.037914 140280493741824 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.11373019963502884, loss=0.3682451844215393
I0208 15:58:39.202563 140280502134528 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.20599400997161865, loss=0.2574833631515503
I0208 15:59:02.841226 140280493741824 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.17094482481479645, loss=0.24075539410114288
I0208 15:59:26.971221 140280502134528 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.10847823321819305, loss=0.27308645844459534
I0208 15:59:27.647205 140466628462400 spec.py:321] Evaluating on the training split.
I0208 15:59:29.021069 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 15:59:30.343128 140466628462400 spec.py:349] Evaluating on the test split.
I0208 15:59:31.667254 140466628462400 submission_runner.py:408] Time since start: 3203.79s, 	Step: 11804, 	{'train/ssim': 0.7457089424133301, 'train/loss': 0.2681718553815569, 'validation/ssim': 0.7230791339863534, 'validation/loss': 0.2868413629998769, 'validation/num_examples': 3554, 'test/ssim': 0.7403026880148702, 'test/loss': 0.2882328241173031, 'test/num_examples': 3581, 'score': 2858.9452958106995, 'total_duration': 3203.785383462906, 'accumulated_submission_time': 2858.9452958106995, 'accumulated_eval_time': 343.4411287307739, 'accumulated_logging_time': 0.9664688110351562}
I0208 15:59:31.688322 140280493741824 logging_writer.py:48] [11804] accumulated_eval_time=343.441129, accumulated_logging_time=0.966469, accumulated_submission_time=2858.945296, global_step=11804, preemption_count=0, score=2858.945296, test/loss=0.288233, test/num_examples=3581, test/ssim=0.740303, total_duration=3203.785383, train/loss=0.268172, train/ssim=0.745709, validation/loss=0.286841, validation/num_examples=3554, validation/ssim=0.723079
I0208 15:59:52.699232 140280502134528 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.16378992795944214, loss=0.31446754932403564
I0208 16:00:17.013628 140280493741824 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.14819090068340302, loss=0.33943086862564087
I0208 16:00:40.865949 140280502134528 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.07427147775888443, loss=0.3272257447242737
I0208 16:00:51.701344 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:00:53.076609 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:00:54.397801 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:00:55.718886 140466628462400 submission_runner.py:408] Time since start: 3287.84s, 	Step: 12146, 	{'train/ssim': 0.7462355749947684, 'train/loss': 0.2677620989935739, 'validation/ssim': 0.7232231178777434, 'validation/loss': 0.2868784065654456, 'validation/num_examples': 3554, 'test/ssim': 0.7404194746361002, 'test/loss': 0.28824993645935143, 'test/num_examples': 3581, 'score': 2938.934836626053, 'total_duration': 3287.8370637893677, 'accumulated_submission_time': 2938.934836626053, 'accumulated_eval_time': 347.45862650871277, 'accumulated_logging_time': 0.9985432624816895}
I0208 16:00:55.737437 140280493741824 logging_writer.py:48] [12146] accumulated_eval_time=347.458627, accumulated_logging_time=0.998543, accumulated_submission_time=2938.934837, global_step=12146, preemption_count=0, score=2938.934837, test/loss=0.288250, test/num_examples=3581, test/ssim=0.740419, total_duration=3287.837064, train/loss=0.267762, train/ssim=0.746236, validation/loss=0.286878, validation/num_examples=3554, validation/ssim=0.723223
I0208 16:01:06.693219 140280502134528 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.08804280310869217, loss=0.2685331702232361
I0208 16:01:30.473165 140280493741824 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.0804811418056488, loss=0.22964446246623993
I0208 16:01:54.047561 140280502134528 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.19051551818847656, loss=0.26482778787612915
I0208 16:02:15.743891 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:02:17.119502 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:02:18.446607 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:02:19.772074 140466628462400 submission_runner.py:408] Time since start: 3371.89s, 	Step: 12492, 	{'train/ssim': 0.7459902082170758, 'train/loss': 0.26780971458980013, 'validation/ssim': 0.7231852671505697, 'validation/loss': 0.28669284526457867, 'validation/num_examples': 3554, 'test/ssim': 0.7405588277323024, 'test/loss': 0.28797555948495535, 'test/num_examples': 3581, 'score': 3018.917544603348, 'total_duration': 3371.8902475833893, 'accumulated_submission_time': 3018.917544603348, 'accumulated_eval_time': 351.48676466941833, 'accumulated_logging_time': 1.028304100036621}
I0208 16:02:19.790780 140280493741824 logging_writer.py:48] [12492] accumulated_eval_time=351.486765, accumulated_logging_time=1.028304, accumulated_submission_time=3018.917545, global_step=12492, preemption_count=0, score=3018.917545, test/loss=0.287976, test/num_examples=3581, test/ssim=0.740559, total_duration=3371.890248, train/loss=0.267810, train/ssim=0.745990, validation/loss=0.286693, validation/num_examples=3554, validation/ssim=0.723185
I0208 16:02:20.463682 140280502134528 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.06587669998407364, loss=0.3471500873565674
I0208 16:02:43.736347 140280493741824 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.13560926914215088, loss=0.27771008014678955
I0208 16:03:07.829969 140280502134528 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.14001308381557465, loss=0.3060326874256134
I0208 16:03:31.940862 140280493741824 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.2851652503013611, loss=0.26396822929382324
I0208 16:03:39.811859 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:03:41.183980 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:03:42.507432 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:03:43.830784 140466628462400 submission_runner.py:408] Time since start: 3455.95s, 	Step: 12834, 	{'train/ssim': 0.7463996069771903, 'train/loss': 0.2683678013937814, 'validation/ssim': 0.7237146964687676, 'validation/loss': 0.28724753702364414, 'validation/num_examples': 3554, 'test/ssim': 0.7409299814777646, 'test/loss': 0.2885652194306758, 'test/num_examples': 3581, 'score': 3098.9161932468414, 'total_duration': 3455.9489629268646, 'accumulated_submission_time': 3098.9161932468414, 'accumulated_eval_time': 355.50565004348755, 'accumulated_logging_time': 1.0569570064544678}
I0208 16:03:43.848823 140280502134528 logging_writer.py:48] [12834] accumulated_eval_time=355.505650, accumulated_logging_time=1.056957, accumulated_submission_time=3098.916193, global_step=12834, preemption_count=0, score=3098.916193, test/loss=0.288565, test/num_examples=3581, test/ssim=0.740930, total_duration=3455.948963, train/loss=0.268368, train/ssim=0.746400, validation/loss=0.287248, validation/num_examples=3554, validation/ssim=0.723715
I0208 16:03:57.931417 140280493741824 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.1850542426109314, loss=0.3053203523159027
I0208 16:04:21.835210 140280502134528 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.11735013872385025, loss=0.3116726875305176
I0208 16:04:45.811743 140280493741824 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.21320384740829468, loss=0.2561604976654053
I0208 16:05:03.925836 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:05:05.295653 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:05:06.616770 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:05:07.939477 140466628462400 submission_runner.py:408] Time since start: 3540.06s, 	Step: 13177, 	{'train/ssim': 0.7463410241263253, 'train/loss': 0.2676967552730015, 'validation/ssim': 0.7232975828292065, 'validation/loss': 0.2867473029124314, 'validation/num_examples': 3554, 'test/ssim': 0.7405494193530089, 'test/loss': 0.28811678743935004, 'test/num_examples': 3581, 'score': 3178.969719648361, 'total_duration': 3540.0576510429382, 'accumulated_submission_time': 3178.969719648361, 'accumulated_eval_time': 359.51924538612366, 'accumulated_logging_time': 1.0859599113464355}
I0208 16:05:07.958436 140280502134528 logging_writer.py:48] [13177] accumulated_eval_time=359.519245, accumulated_logging_time=1.085960, accumulated_submission_time=3178.969720, global_step=13177, preemption_count=0, score=3178.969720, test/loss=0.288117, test/num_examples=3581, test/ssim=0.740549, total_duration=3540.057651, train/loss=0.267697, train/ssim=0.746341, validation/loss=0.286747, validation/num_examples=3554, validation/ssim=0.723298
I0208 16:05:11.265614 140280493741824 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.08446616679430008, loss=0.24011793732643127
I0208 16:05:34.952635 140280502134528 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.12143488228321075, loss=0.24186305701732635
I0208 16:05:58.781292 140280493741824 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.10744952410459518, loss=0.2940673232078552
I0208 16:06:22.957198 140280502134528 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.12227945774793625, loss=0.24911336600780487
I0208 16:06:28.008595 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:06:29.381680 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:06:30.704422 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:06:32.027553 140466628462400 submission_runner.py:408] Time since start: 3624.15s, 	Step: 13522, 	{'train/ssim': 0.7465722220284599, 'train/loss': 0.2675368956157139, 'validation/ssim': 0.7237550202017093, 'validation/loss': 0.28640898198442777, 'validation/num_examples': 3554, 'test/ssim': 0.7410320419401005, 'test/loss': 0.2877505083251885, 'test/num_examples': 3581, 'score': 3258.9978489875793, 'total_duration': 3624.1457312107086, 'accumulated_submission_time': 3258.9978489875793, 'accumulated_eval_time': 363.53816270828247, 'accumulated_logging_time': 1.11417555809021}
I0208 16:06:32.045845 140280493741824 logging_writer.py:48] [13522] accumulated_eval_time=363.538163, accumulated_logging_time=1.114176, accumulated_submission_time=3258.997849, global_step=13522, preemption_count=0, score=3258.997849, test/loss=0.287751, test/num_examples=3581, test/ssim=0.741032, total_duration=3624.145731, train/loss=0.267537, train/ssim=0.746572, validation/loss=0.286409, validation/num_examples=3554, validation/ssim=0.723755
I0208 16:06:48.893215 140280502134528 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.16750706732273102, loss=0.20631423592567444
I0208 16:07:12.666239 140280493741824 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.11965708434581757, loss=0.28157997131347656
I0208 16:07:36.344619 140280502134528 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.15380892157554626, loss=0.32873260974884033
I0208 16:07:52.127721 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:07:53.500739 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:07:54.823438 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:07:56.145125 140466628462400 submission_runner.py:408] Time since start: 3708.26s, 	Step: 13868, 	{'train/ssim': 0.7468410900660923, 'train/loss': 0.2678717374801636, 'validation/ssim': 0.7240890820642234, 'validation/loss': 0.2867557008278524, 'validation/num_examples': 3554, 'test/ssim': 0.7413182475652751, 'test/loss': 0.28803766842362466, 'test/num_examples': 3581, 'score': 3339.0577857494354, 'total_duration': 3708.263298511505, 'accumulated_submission_time': 3339.0577857494354, 'accumulated_eval_time': 367.55552864074707, 'accumulated_logging_time': 1.1418681144714355}
I0208 16:07:56.164212 140280493741824 logging_writer.py:48] [13868] accumulated_eval_time=367.555529, accumulated_logging_time=1.141868, accumulated_submission_time=3339.057786, global_step=13868, preemption_count=0, score=3339.057786, test/loss=0.288038, test/num_examples=3581, test/ssim=0.741318, total_duration=3708.263299, train/loss=0.267872, train/ssim=0.746841, validation/loss=0.286756, validation/num_examples=3554, validation/ssim=0.724089
I0208 16:08:01.740346 140280502134528 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.21506717801094055, loss=0.2533751130104065
I0208 16:08:25.853317 140280493741824 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.10466316342353821, loss=0.24618776142597198
I0208 16:08:49.855677 140280502134528 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.260807603597641, loss=0.3197033107280731
I0208 16:09:13.957675 140280493741824 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.18469876050949097, loss=0.24670445919036865
I0208 16:09:16.273030 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:09:17.646821 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:09:18.968214 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:09:20.287174 140466628462400 submission_runner.py:408] Time since start: 3792.41s, 	Step: 14211, 	{'train/ssim': 0.7465951783316476, 'train/loss': 0.26786759921482634, 'validation/ssim': 0.723388877958814, 'validation/loss': 0.28721214212858753, 'validation/num_examples': 3554, 'test/ssim': 0.7405325115409452, 'test/loss': 0.2886754610923974, 'test/num_examples': 3581, 'score': 3419.144530057907, 'total_duration': 3792.405335187912, 'accumulated_submission_time': 3419.144530057907, 'accumulated_eval_time': 371.56961011886597, 'accumulated_logging_time': 1.1705811023712158}
I0208 16:09:20.305225 140280502134528 logging_writer.py:48] [14211] accumulated_eval_time=371.569610, accumulated_logging_time=1.170581, accumulated_submission_time=3419.144530, global_step=14211, preemption_count=0, score=3419.144530, test/loss=0.288675, test/num_examples=3581, test/ssim=0.740533, total_duration=3792.405335, train/loss=0.267868, train/ssim=0.746595, validation/loss=0.287212, validation/num_examples=3554, validation/ssim=0.723389
I0208 16:09:39.385768 140280493741824 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.0705183893442154, loss=0.2756071984767914
I0208 16:10:03.179662 140280502134528 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.14226225018501282, loss=0.28944849967956543
I0208 16:10:26.855487 140280493741824 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.23808690905570984, loss=0.3328776955604553
I0208 16:10:40.453162 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:10:41.828573 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:10:43.150082 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:10:44.473668 140466628462400 submission_runner.py:408] Time since start: 3876.59s, 	Step: 14559, 	{'train/ssim': 0.7471063477652413, 'train/loss': 0.2675107717514038, 'validation/ssim': 0.7242466674873382, 'validation/loss': 0.2865292147162528, 'validation/num_examples': 3554, 'test/ssim': 0.7414607367879084, 'test/loss': 0.28782291193975146, 'test/num_examples': 3581, 'score': 3499.2701807022095, 'total_duration': 3876.59183716774, 'accumulated_submission_time': 3499.2701807022095, 'accumulated_eval_time': 375.59007000923157, 'accumulated_logging_time': 1.198145866394043}
I0208 16:10:44.492398 140280502134528 logging_writer.py:48] [14559] accumulated_eval_time=375.590070, accumulated_logging_time=1.198146, accumulated_submission_time=3499.270181, global_step=14559, preemption_count=0, score=3499.270181, test/loss=0.287823, test/num_examples=3581, test/ssim=0.741461, total_duration=3876.591837, train/loss=0.267511, train/ssim=0.747106, validation/loss=0.286529, validation/num_examples=3554, validation/ssim=0.724247
I0208 16:10:52.127817 140280493741824 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.21083271503448486, loss=0.22095884382724762
I0208 16:11:15.894036 140280502134528 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.13315904140472412, loss=0.27102622389793396
I0208 16:11:39.560912 140280493741824 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.11004412174224854, loss=0.2860550284385681
I0208 16:12:03.733664 140280502134528 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.17465324699878693, loss=0.27972814440727234
I0208 16:12:04.627134 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:12:05.999464 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:12:07.319694 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:12:08.642859 140466628462400 submission_runner.py:408] Time since start: 3960.76s, 	Step: 14905, 	{'train/ssim': 0.7477654048374721, 'train/loss': 0.2676566668919155, 'validation/ssim': 0.7249977742948087, 'validation/loss': 0.2865739349038935, 'validation/num_examples': 3554, 'test/ssim': 0.742121709521607, 'test/loss': 0.2879113711581088, 'test/num_examples': 3581, 'score': 3579.3831877708435, 'total_duration': 3960.7610342502594, 'accumulated_submission_time': 3579.3831877708435, 'accumulated_eval_time': 379.60575890541077, 'accumulated_logging_time': 1.2259979248046875}
I0208 16:12:08.661057 140280493741824 logging_writer.py:48] [14905] accumulated_eval_time=379.605759, accumulated_logging_time=1.225998, accumulated_submission_time=3579.383188, global_step=14905, preemption_count=0, score=3579.383188, test/loss=0.287911, test/num_examples=3581, test/ssim=0.742122, total_duration=3960.761034, train/loss=0.267657, train/ssim=0.747765, validation/loss=0.286574, validation/num_examples=3554, validation/ssim=0.724998
I0208 16:12:29.056710 140280502134528 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.18644824624061584, loss=0.23815186321735382
I0208 16:12:53.360932 140280493741824 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.18748122453689575, loss=0.19481214880943298
I0208 16:13:17.587476 140280502134528 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.07273087650537491, loss=0.19491256773471832
I0208 16:13:28.772834 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:13:30.147421 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:13:31.470872 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:13:32.792332 140466628462400 submission_runner.py:408] Time since start: 4044.91s, 	Step: 15248, 	{'train/ssim': 0.7476011684962681, 'train/loss': 0.2673081500189645, 'validation/ssim': 0.7246028490125562, 'validation/loss': 0.28648566233689154, 'validation/num_examples': 3554, 'test/ssim': 0.7418195505576306, 'test/loss': 0.2878147989170274, 'test/num_examples': 3581, 'score': 3659.4731526374817, 'total_duration': 4044.9105067253113, 'accumulated_submission_time': 3659.4731526374817, 'accumulated_eval_time': 383.6252100467682, 'accumulated_logging_time': 1.2533009052276611}
I0208 16:13:32.811776 140280493741824 logging_writer.py:48] [15248] accumulated_eval_time=383.625210, accumulated_logging_time=1.253301, accumulated_submission_time=3659.473153, global_step=15248, preemption_count=0, score=3659.473153, test/loss=0.287815, test/num_examples=3581, test/ssim=0.741820, total_duration=4044.910507, train/loss=0.267308, train/ssim=0.747601, validation/loss=0.286486, validation/num_examples=3554, validation/ssim=0.724603
I0208 16:13:43.429318 140280502134528 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.14827793836593628, loss=0.22754749655723572
I0208 16:14:07.157783 140280493741824 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.14549420773983002, loss=0.2977811396121979
I0208 16:14:31.354567 140280502134528 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.1452847421169281, loss=0.2629818320274353
I0208 16:14:52.841644 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:14:54.214205 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:14:55.536301 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:14:56.857936 140466628462400 submission_runner.py:408] Time since start: 4128.98s, 	Step: 15592, 	{'train/ssim': 0.7472316878182548, 'train/loss': 0.26755171162741526, 'validation/ssim': 0.7243855679779826, 'validation/loss': 0.28649069421668366, 'validation/num_examples': 3554, 'test/ssim': 0.741601521594003, 'test/loss': 0.28786576097153377, 'test/num_examples': 3581, 'score': 3739.480894804001, 'total_duration': 4128.976114034653, 'accumulated_submission_time': 3739.480894804001, 'accumulated_eval_time': 387.6414725780487, 'accumulated_logging_time': 1.2822730541229248}
I0208 16:14:56.876664 140280493741824 logging_writer.py:48] [15592] accumulated_eval_time=387.641473, accumulated_logging_time=1.282273, accumulated_submission_time=3739.480895, global_step=15592, preemption_count=0, score=3739.480895, test/loss=0.287866, test/num_examples=3581, test/ssim=0.741602, total_duration=4128.976114, train/loss=0.267552, train/ssim=0.747232, validation/loss=0.286491, validation/num_examples=3554, validation/ssim=0.724386
I0208 16:14:57.553070 140280502134528 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.13145503401756287, loss=0.3594893515110016
I0208 16:15:20.511239 140280493741824 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.19265896081924438, loss=0.25518307089805603
I0208 16:15:44.562805 140280502134528 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.0828813835978508, loss=0.26687929034233093
I0208 16:16:08.787757 140280493741824 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.05666358023881912, loss=0.1900871843099594
I0208 16:16:17.014986 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:16:18.386115 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:16:19.710498 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:16:21.031540 140466628462400 submission_runner.py:408] Time since start: 4213.15s, 	Step: 15936, 	{'train/ssim': 0.7483240536281041, 'train/loss': 0.2673044204711914, 'validation/ssim': 0.7253718164172411, 'validation/loss': 0.2863633515932752, 'validation/num_examples': 3554, 'test/ssim': 0.7426279894102555, 'test/loss': 0.28762550641624196, 'test/num_examples': 3581, 'score': 3819.596107006073, 'total_duration': 4213.149703264236, 'accumulated_submission_time': 3819.596107006073, 'accumulated_eval_time': 391.657977104187, 'accumulated_logging_time': 1.3116509914398193}
I0208 16:16:21.051290 140280502134528 logging_writer.py:48] [15936] accumulated_eval_time=391.657977, accumulated_logging_time=1.311651, accumulated_submission_time=3819.596107, global_step=15936, preemption_count=0, score=3819.596107, test/loss=0.287626, test/num_examples=3581, test/ssim=0.742628, total_duration=4213.149703, train/loss=0.267304, train/ssim=0.748324, validation/loss=0.286363, validation/num_examples=3554, validation/ssim=0.725372
I0208 16:16:34.208411 140280493741824 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.18708162009716034, loss=0.2619955837726593
I0208 16:16:58.266731 140280502134528 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.12813985347747803, loss=0.24290364980697632
I0208 16:17:22.622362 140280493741824 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.15554401278495789, loss=0.213971808552742
I0208 16:17:41.045144 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:17:42.416419 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:17:43.735268 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:17:45.057423 140466628462400 submission_runner.py:408] Time since start: 4297.18s, 	Step: 16279, 	{'train/ssim': 0.7473345484052386, 'train/loss': 0.2675484078271048, 'validation/ssim': 0.7243296505697805, 'validation/loss': 0.2866905955162757, 'validation/num_examples': 3554, 'test/ssim': 0.7415096876308992, 'test/loss': 0.28810379978532535, 'test/num_examples': 3581, 'score': 3899.568253993988, 'total_duration': 4297.175599813461, 'accumulated_submission_time': 3899.568253993988, 'accumulated_eval_time': 395.67021560668945, 'accumulated_logging_time': 1.340677261352539}
I0208 16:17:45.078344 140280502134528 logging_writer.py:48] [16279] accumulated_eval_time=395.670216, accumulated_logging_time=1.340677, accumulated_submission_time=3899.568254, global_step=16279, preemption_count=0, score=3899.568254, test/loss=0.288104, test/num_examples=3581, test/ssim=0.741510, total_duration=4297.175600, train/loss=0.267548, train/ssim=0.747335, validation/loss=0.286691, validation/num_examples=3554, validation/ssim=0.724330
I0208 16:17:48.053251 140280493741824 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.2717236876487732, loss=0.24231821298599243
I0208 16:18:12.063725 140280502134528 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.09133206307888031, loss=0.2872465252876282
I0208 16:18:35.752439 140280493741824 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.1658707559108734, loss=0.3338519036769867
I0208 16:18:59.446592 140280502134528 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.22693152725696564, loss=0.3260972201824188
I0208 16:19:05.290417 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:19:06.662521 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:19:07.982662 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:19:09.305445 140466628462400 submission_runner.py:408] Time since start: 4381.42s, 	Step: 16625, 	{'train/ssim': 0.7466865948268345, 'train/loss': 0.26763645240238737, 'validation/ssim': 0.7237747355532499, 'validation/loss': 0.28666423396173324, 'validation/num_examples': 3554, 'test/ssim': 0.7408988929200991, 'test/loss': 0.288077960830599, 'test/num_examples': 3581, 'score': 3979.7582840919495, 'total_duration': 4381.423604011536, 'accumulated_submission_time': 3979.7582840919495, 'accumulated_eval_time': 399.6851809024811, 'accumulated_logging_time': 1.3709535598754883}
I0208 16:19:09.323924 140280493741824 logging_writer.py:48] [16625] accumulated_eval_time=399.685181, accumulated_logging_time=1.370954, accumulated_submission_time=3979.758284, global_step=16625, preemption_count=0, score=3979.758284, test/loss=0.288078, test/num_examples=3581, test/ssim=0.740899, total_duration=4381.423604, train/loss=0.267636, train/ssim=0.746687, validation/loss=0.286664, validation/num_examples=3554, validation/ssim=0.723775
I0208 16:19:25.195022 140280502134528 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.13091421127319336, loss=0.23359978199005127
I0208 16:19:49.160924 140280493741824 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.19608564674854279, loss=0.22665297985076904
I0208 16:20:12.970088 140280502134528 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.096987783908844, loss=0.4334287941455841
I0208 16:20:29.369057 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:20:30.740340 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:20:32.065122 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:20:33.386384 140466628462400 submission_runner.py:408] Time since start: 4465.50s, 	Step: 16969, 	{'train/ssim': 0.7481282779148647, 'train/loss': 0.26680430344172884, 'validation/ssim': 0.7251985686242614, 'validation/loss': 0.2858984608561656, 'validation/num_examples': 3554, 'test/ssim': 0.7424319815083077, 'test/loss': 0.2871888348990331, 'test/num_examples': 3581, 'score': 4059.7816610336304, 'total_duration': 4465.504558324814, 'accumulated_submission_time': 4059.7816610336304, 'accumulated_eval_time': 403.7024691104889, 'accumulated_logging_time': 1.3988149166107178}
I0208 16:20:33.405096 140280493741824 logging_writer.py:48] [16969] accumulated_eval_time=403.702469, accumulated_logging_time=1.398815, accumulated_submission_time=4059.781661, global_step=16969, preemption_count=0, score=4059.781661, test/loss=0.287189, test/num_examples=3581, test/ssim=0.742432, total_duration=4465.504558, train/loss=0.266804, train/ssim=0.748128, validation/loss=0.285898, validation/num_examples=3554, validation/ssim=0.725199
I0208 16:20:38.808681 140280502134528 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.3629631996154785, loss=0.225650817155838
I0208 16:21:03.000680 140280493741824 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.11748170107603073, loss=0.2697840631008148
I0208 16:21:26.924587 140280502134528 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.14156439900398254, loss=0.2731025218963623
I0208 16:21:51.452653 140280493741824 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.07684703171253204, loss=0.3082997798919678
I0208 16:21:53.495236 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:21:54.867119 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:21:56.191229 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:21:57.513987 140466628462400 submission_runner.py:408] Time since start: 4549.63s, 	Step: 17310, 	{'train/ssim': 0.7480014392307827, 'train/loss': 0.2669447490147182, 'validation/ssim': 0.7251391477912211, 'validation/loss': 0.2859115471783554, 'validation/num_examples': 3554, 'test/ssim': 0.7423032639713069, 'test/loss': 0.28726846523972005, 'test/num_examples': 3581, 'score': 4139.849115371704, 'total_duration': 4549.632168054581, 'accumulated_submission_time': 4139.849115371704, 'accumulated_eval_time': 407.72118186950684, 'accumulated_logging_time': 1.4279568195343018}
I0208 16:21:57.533125 140280502134528 logging_writer.py:48] [17310] accumulated_eval_time=407.721182, accumulated_logging_time=1.427957, accumulated_submission_time=4139.849115, global_step=17310, preemption_count=0, score=4139.849115, test/loss=0.287268, test/num_examples=3581, test/ssim=0.742303, total_duration=4549.632168, train/loss=0.266945, train/ssim=0.748001, validation/loss=0.285912, validation/num_examples=3554, validation/ssim=0.725139
I0208 16:22:17.115432 140280493741824 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.15009663999080658, loss=0.2967856824398041
I0208 16:22:40.887049 140280502134528 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.08222038298845291, loss=0.28413426876068115
I0208 16:23:04.859833 140280493741824 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.14174695312976837, loss=0.2755593955516815
I0208 16:23:17.595582 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:23:18.969428 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:23:20.291375 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:23:21.613916 140466628462400 submission_runner.py:408] Time since start: 4633.73s, 	Step: 17656, 	{'train/ssim': 0.7473434720720563, 'train/loss': 0.2665583406175886, 'validation/ssim': 0.7239926348392656, 'validation/loss': 0.2859433184330156, 'validation/num_examples': 3554, 'test/ssim': 0.7412486391938355, 'test/loss': 0.28727313534103605, 'test/num_examples': 3581, 'score': 4219.889711856842, 'total_duration': 4633.732095003128, 'accumulated_submission_time': 4219.889711856842, 'accumulated_eval_time': 411.73948407173157, 'accumulated_logging_time': 1.4562327861785889}
I0208 16:23:21.633236 140280502134528 logging_writer.py:48] [17656] accumulated_eval_time=411.739484, accumulated_logging_time=1.456233, accumulated_submission_time=4219.889712, global_step=17656, preemption_count=0, score=4219.889712, test/loss=0.287273, test/num_examples=3581, test/ssim=0.741249, total_duration=4633.732095, train/loss=0.266558, train/ssim=0.747343, validation/loss=0.285943, validation/num_examples=3554, validation/ssim=0.723993
I0208 16:23:29.959010 140280493741824 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.08666056394577026, loss=0.21659839153289795
I0208 16:23:53.593754 140280502134528 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.2653917670249939, loss=0.3059382438659668
I0208 16:24:17.509323 140280493741824 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.07536023110151291, loss=0.339976042509079
I0208 16:24:41.363398 140280502134528 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.11074857413768768, loss=0.2756383419036865
I0208 16:24:41.798245 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:24:43.169047 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:24:44.490668 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:24:45.812321 140466628462400 submission_runner.py:408] Time since start: 4717.93s, 	Step: 18003, 	{'train/ssim': 0.7483083861214774, 'train/loss': 0.2665321145738874, 'validation/ssim': 0.7252950158492192, 'validation/loss': 0.2856605886138418, 'validation/num_examples': 3554, 'test/ssim': 0.7424689332588662, 'test/loss': 0.28695945452125804, 'test/num_examples': 3581, 'score': 4300.033041477203, 'total_duration': 4717.930500507355, 'accumulated_submission_time': 4300.033041477203, 'accumulated_eval_time': 415.75352668762207, 'accumulated_logging_time': 1.4845950603485107}
I0208 16:24:45.831561 140280493741824 logging_writer.py:48] [18003] accumulated_eval_time=415.753527, accumulated_logging_time=1.484595, accumulated_submission_time=4300.033041, global_step=18003, preemption_count=0, score=4300.033041, test/loss=0.286959, test/num_examples=3581, test/ssim=0.742469, total_duration=4717.930501, train/loss=0.266532, train/ssim=0.748308, validation/loss=0.285661, validation/num_examples=3554, validation/ssim=0.725295
I0208 16:25:06.881529 140280502134528 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.14971567690372467, loss=0.22907567024230957
I0208 16:25:30.785083 140280493741824 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.05756488814949989, loss=0.2366371750831604
I0208 16:25:54.919119 140280502134528 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.1588425487279892, loss=0.31028252840042114
I0208 16:26:05.950099 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:26:07.326336 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:26:08.647494 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:26:09.970130 140466628462400 submission_runner.py:408] Time since start: 4802.09s, 	Step: 18345, 	{'train/ssim': 0.7470991952078683, 'train/loss': 0.26688592774527414, 'validation/ssim': 0.7242033898863957, 'validation/loss': 0.285921439201428, 'validation/num_examples': 3554, 'test/ssim': 0.7414670090407708, 'test/loss': 0.28718528971263263, 'test/num_examples': 3581, 'score': 4380.129502534866, 'total_duration': 4802.0883066654205, 'accumulated_submission_time': 4380.129502534866, 'accumulated_eval_time': 419.7735161781311, 'accumulated_logging_time': 1.5131938457489014}
I0208 16:26:09.989970 140280493741824 logging_writer.py:48] [18345] accumulated_eval_time=419.773516, accumulated_logging_time=1.513194, accumulated_submission_time=4380.129503, global_step=18345, preemption_count=0, score=4380.129503, test/loss=0.287185, test/num_examples=3581, test/ssim=0.741467, total_duration=4802.088307, train/loss=0.266886, train/ssim=0.747099, validation/loss=0.285921, validation/num_examples=3554, validation/ssim=0.724203
I0208 16:26:20.971453 140280502134528 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.12821802496910095, loss=0.33342307806015015
I0208 16:26:44.666232 140280493741824 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.20219740271568298, loss=0.25519102811813354
I0208 16:27:08.567559 140280502134528 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.049530476331710815, loss=0.29364705085754395
I0208 16:27:30.018631 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:27:31.392774 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:27:32.711956 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:27:34.035731 140466628462400 submission_runner.py:408] Time since start: 4886.15s, 	Step: 18691, 	{'train/ssim': 0.7492048399788993, 'train/loss': 0.2664386204310826, 'validation/ssim': 0.7258765843723621, 'validation/loss': 0.2859228817881261, 'validation/num_examples': 3554, 'test/ssim': 0.743057638731325, 'test/loss': 0.28718869854571, 'test/num_examples': 3581, 'score': 4460.136431455612, 'total_duration': 4886.153877258301, 'accumulated_submission_time': 4460.136431455612, 'accumulated_eval_time': 423.7905547618866, 'accumulated_logging_time': 1.542210578918457}
I0208 16:27:34.056969 140280493741824 logging_writer.py:48] [18691] accumulated_eval_time=423.790555, accumulated_logging_time=1.542211, accumulated_submission_time=4460.136431, global_step=18691, preemption_count=0, score=4460.136431, test/loss=0.287189, test/num_examples=3581, test/ssim=0.743058, total_duration=4886.153877, train/loss=0.266439, train/ssim=0.749205, validation/loss=0.285923, validation/num_examples=3554, validation/ssim=0.725877
I0208 16:27:34.802286 140280502134528 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.10558745265007019, loss=0.2786112129688263
I0208 16:27:58.054331 140280493741824 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.1516202986240387, loss=0.2847115993499756
I0208 16:28:21.852670 140280502134528 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.14891882240772247, loss=0.24338939785957336
I0208 16:28:45.623121 140280493741824 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.13251623511314392, loss=0.27284735441207886
I0208 16:28:54.322878 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:28:55.695678 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:28:57.017622 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:28:58.339999 140466628462400 submission_runner.py:408] Time since start: 4970.46s, 	Step: 19038, 	{'train/ssim': 0.7488509586879185, 'train/loss': 0.266427789415632, 'validation/ssim': 0.7257310891996693, 'validation/loss': 0.28569581177238673, 'validation/num_examples': 3554, 'test/ssim': 0.7429034912995671, 'test/loss': 0.28701924545343477, 'test/num_examples': 3581, 'score': 4540.380712032318, 'total_duration': 4970.458175897598, 'accumulated_submission_time': 4540.380712032318, 'accumulated_eval_time': 427.80764269828796, 'accumulated_logging_time': 1.5725533962249756}
I0208 16:28:58.359796 140280502134528 logging_writer.py:48] [19038] accumulated_eval_time=427.807643, accumulated_logging_time=1.572553, accumulated_submission_time=4540.380712, global_step=19038, preemption_count=0, score=4540.380712, test/loss=0.287019, test/num_examples=3581, test/ssim=0.742903, total_duration=4970.458176, train/loss=0.266428, train/ssim=0.748851, validation/loss=0.285696, validation/num_examples=3554, validation/ssim=0.725731
I0208 16:29:11.227002 140280493741824 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.15484139323234558, loss=0.30341866612434387
I0208 16:29:34.997256 140280502134528 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.32790350914001465, loss=0.22564756870269775
I0208 16:29:58.822728 140280493741824 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.19211618602275848, loss=0.23761333525180817
I0208 16:30:18.514488 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:30:19.887736 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:30:21.209582 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:30:22.533094 140466628462400 submission_runner.py:408] Time since start: 5054.65s, 	Step: 19384, 	{'train/ssim': 0.7485593387058803, 'train/loss': 0.2664816209248134, 'validation/ssim': 0.7254547994996835, 'validation/loss': 0.28563797091525395, 'validation/num_examples': 3554, 'test/ssim': 0.7426361024329796, 'test/loss': 0.28693194523832377, 'test/num_examples': 3581, 'score': 4620.512376785278, 'total_duration': 5054.651271343231, 'accumulated_submission_time': 4620.512376785278, 'accumulated_eval_time': 431.82620668411255, 'accumulated_logging_time': 1.60274076461792}
I0208 16:30:22.552815 140280502134528 logging_writer.py:48] [19384] accumulated_eval_time=431.826207, accumulated_logging_time=1.602741, accumulated_submission_time=4620.512377, global_step=19384, preemption_count=0, score=4620.512377, test/loss=0.286932, test/num_examples=3581, test/ssim=0.742636, total_duration=5054.651271, train/loss=0.266482, train/ssim=0.748559, validation/loss=0.285638, validation/num_examples=3554, validation/ssim=0.725455
I0208 16:30:24.323599 140280493741824 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.08421687036752701, loss=0.2220577448606491
I0208 16:30:48.321399 140280502134528 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.2160564810037613, loss=0.32932546734809875
I0208 16:31:12.501260 140280493741824 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.07254297286272049, loss=0.2931976914405823
I0208 16:31:36.244669 140280502134528 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.2209935039281845, loss=0.3338139057159424
I0208 16:31:42.632704 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:31:44.006834 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:31:45.329055 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:31:46.653252 140466628462400 submission_runner.py:408] Time since start: 5138.77s, 	Step: 19728, 	{'train/ssim': 0.7484092712402344, 'train/loss': 0.2663026877811977, 'validation/ssim': 0.7250737505275746, 'validation/loss': 0.2859123371663091, 'validation/num_examples': 3554, 'test/ssim': 0.742244086629084, 'test/loss': 0.28714332697745043, 'test/num_examples': 3581, 'score': 4700.570680141449, 'total_duration': 5138.771405696869, 'accumulated_submission_time': 4700.570680141449, 'accumulated_eval_time': 435.8466863632202, 'accumulated_logging_time': 1.6315891742706299}
I0208 16:31:46.675802 140280493741824 logging_writer.py:48] [19728] accumulated_eval_time=435.846686, accumulated_logging_time=1.631589, accumulated_submission_time=4700.570680, global_step=19728, preemption_count=0, score=4700.570680, test/loss=0.287143, test/num_examples=3581, test/ssim=0.742244, total_duration=5138.771406, train/loss=0.266303, train/ssim=0.748409, validation/loss=0.285912, validation/num_examples=3554, validation/ssim=0.725074
I0208 16:32:01.596905 140280502134528 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.10429266095161438, loss=0.24873672425746918
I0208 16:32:25.578026 140280493741824 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.0696471780538559, loss=0.23127570748329163
I0208 16:32:49.702290 140280502134528 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.10442997515201569, loss=0.23414993286132812
I0208 16:33:06.812327 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:33:08.185437 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:33:09.507329 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:33:10.830083 140466628462400 submission_runner.py:408] Time since start: 5222.95s, 	Step: 20072, 	{'train/ssim': 0.7486628804888044, 'train/loss': 0.2662466253553118, 'validation/ssim': 0.7255211584877954, 'validation/loss': 0.2855280252004783, 'validation/num_examples': 3554, 'test/ssim': 0.7426688954071837, 'test/loss': 0.28686107559864565, 'test/num_examples': 3581, 'score': 4780.684697151184, 'total_duration': 5222.948258399963, 'accumulated_submission_time': 4780.684697151184, 'accumulated_eval_time': 439.86440348625183, 'accumulated_logging_time': 1.6642556190490723}
I0208 16:33:10.850068 140280493741824 logging_writer.py:48] [20072] accumulated_eval_time=439.864403, accumulated_logging_time=1.664256, accumulated_submission_time=4780.684697, global_step=20072, preemption_count=0, score=4780.684697, test/loss=0.286861, test/num_examples=3581, test/ssim=0.742669, total_duration=5222.948258, train/loss=0.266247, train/ssim=0.748663, validation/loss=0.285528, validation/num_examples=3554, validation/ssim=0.725521
I0208 16:33:15.459551 140280502134528 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.11172673851251602, loss=0.35265541076660156
I0208 16:33:39.335106 140280493741824 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.11986817419528961, loss=0.28058189153671265
I0208 16:34:03.232777 140280502134528 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.16746771335601807, loss=0.2634601593017578
I0208 16:34:27.170186 140280493741824 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.19745133817195892, loss=0.2810346782207489
I0208 16:34:30.918953 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:34:32.294910 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:34:33.618561 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:34:34.940732 140466628462400 submission_runner.py:408] Time since start: 5307.06s, 	Step: 20417, 	{'train/ssim': 0.7478485788617816, 'train/loss': 0.2665714366095407, 'validation/ssim': 0.7244868238252673, 'validation/loss': 0.2859325677273846, 'validation/num_examples': 3554, 'test/ssim': 0.7418312769434167, 'test/loss': 0.28714189526755796, 'test/num_examples': 3581, 'score': 4860.731207847595, 'total_duration': 5307.05890750885, 'accumulated_submission_time': 4860.731207847595, 'accumulated_eval_time': 443.8861367702484, 'accumulated_logging_time': 1.6940970420837402}
I0208 16:34:34.961626 140280502134528 logging_writer.py:48] [20417] accumulated_eval_time=443.886137, accumulated_logging_time=1.694097, accumulated_submission_time=4860.731208, global_step=20417, preemption_count=0, score=4860.731208, test/loss=0.287142, test/num_examples=3581, test/ssim=0.741831, total_duration=5307.058908, train/loss=0.266571, train/ssim=0.747849, validation/loss=0.285933, validation/num_examples=3554, validation/ssim=0.724487
I0208 16:34:53.308571 140280493741824 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.17541979253292084, loss=0.23485444486141205
I0208 16:35:17.107315 140280502134528 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.26595720648765564, loss=0.28978773951530457
I0208 16:35:40.719311 140280493741824 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.1605159193277359, loss=0.2631186246871948
I0208 16:35:55.046201 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:35:56.421161 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:35:57.744118 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:35:59.065428 140466628462400 submission_runner.py:408] Time since start: 5391.18s, 	Step: 20761, 	{'train/ssim': 0.7485369273594448, 'train/loss': 0.26598404135022846, 'validation/ssim': 0.724897548866594, 'validation/loss': 0.2856829830549645, 'validation/num_examples': 3554, 'test/ssim': 0.7421095058991902, 'test/loss': 0.28697489653509844, 'test/num_examples': 3581, 'score': 4940.794360637665, 'total_duration': 5391.183601856232, 'accumulated_submission_time': 4940.794360637665, 'accumulated_eval_time': 447.90532636642456, 'accumulated_logging_time': 1.7241308689117432}
I0208 16:35:59.085946 140280502134528 logging_writer.py:48] [20761] accumulated_eval_time=447.905326, accumulated_logging_time=1.724131, accumulated_submission_time=4940.794361, global_step=20761, preemption_count=0, score=4940.794361, test/loss=0.286975, test/num_examples=3581, test/ssim=0.742110, total_duration=5391.183602, train/loss=0.265984, train/ssim=0.748537, validation/loss=0.285683, validation/num_examples=3554, validation/ssim=0.724898
I0208 16:36:06.291702 140280493741824 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.1029035896062851, loss=0.25952908396720886
I0208 16:36:30.101657 140280502134528 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.1441551297903061, loss=0.33501386642456055
I0208 16:36:53.928943 140280493741824 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.11405570805072784, loss=0.3086959719657898
I0208 16:37:17.828761 140280502134528 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.14176954329013824, loss=0.2335149645805359
I0208 16:37:19.199586 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:37:20.573875 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:37:21.894675 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:37:23.217156 140466628462400 submission_runner.py:408] Time since start: 5475.34s, 	Step: 21107, 	{'train/ssim': 0.7491487775530133, 'train/loss': 0.2664053269795009, 'validation/ssim': 0.7259544153594542, 'validation/loss': 0.285788927309018, 'validation/num_examples': 3554, 'test/ssim': 0.7430941132452528, 'test/loss': 0.2870494818028309, 'test/num_examples': 3581, 'score': 5020.885152101517, 'total_duration': 5475.335332632065, 'accumulated_submission_time': 5020.885152101517, 'accumulated_eval_time': 451.92284989356995, 'accumulated_logging_time': 1.7548644542694092}
I0208 16:37:23.236973 140280493741824 logging_writer.py:48] [21107] accumulated_eval_time=451.922850, accumulated_logging_time=1.754864, accumulated_submission_time=5020.885152, global_step=21107, preemption_count=0, score=5020.885152, test/loss=0.287049, test/num_examples=3581, test/ssim=0.743094, total_duration=5475.335333, train/loss=0.266405, train/ssim=0.749149, validation/loss=0.285789, validation/num_examples=3554, validation/ssim=0.725954
I0208 16:37:43.500762 140280502134528 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.16045355796813965, loss=0.2860969007015228
I0208 16:38:07.760309 140280493741824 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.08778200298547745, loss=0.3115992248058319
I0208 16:38:31.685655 140280502134528 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.12917210161685944, loss=0.26223641633987427
I0208 16:38:43.294311 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:38:44.668271 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:38:45.989433 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:38:47.314438 140466628462400 submission_runner.py:408] Time since start: 5559.43s, 	Step: 21449, 	{'train/ssim': 0.7486867223467145, 'train/loss': 0.2660897970199585, 'validation/ssim': 0.7254420223032146, 'validation/loss': 0.2854990189036561, 'validation/num_examples': 3554, 'test/ssim': 0.7426107407148841, 'test/loss': 0.28676784401398003, 'test/num_examples': 3581, 'score': 5100.921221733093, 'total_duration': 5559.43258523941, 'accumulated_submission_time': 5100.921221733093, 'accumulated_eval_time': 455.94290256500244, 'accumulated_logging_time': 1.7836058139801025}
I0208 16:38:47.334556 140280493741824 logging_writer.py:48] [21449] accumulated_eval_time=455.942903, accumulated_logging_time=1.783606, accumulated_submission_time=5100.921222, global_step=21449, preemption_count=0, score=5100.921222, test/loss=0.286768, test/num_examples=3581, test/ssim=0.742611, total_duration=5559.432585, train/loss=0.266090, train/ssim=0.748687, validation/loss=0.285499, validation/num_examples=3554, validation/ssim=0.725442
I0208 16:38:57.375215 140280502134528 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.1973850280046463, loss=0.2169874608516693
I0208 16:39:21.880725 140280493741824 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.09174689650535583, loss=0.24899467825889587
I0208 16:39:45.799968 140280502134528 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.16370880603790283, loss=0.32892924547195435
I0208 16:40:07.452299 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:40:08.822631 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:40:10.144785 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:40:11.466145 140466628462400 submission_runner.py:408] Time since start: 5643.58s, 	Step: 21791, 	{'train/ssim': 0.7492446218218122, 'train/loss': 0.2659718820026943, 'validation/ssim': 0.7256659667144415, 'validation/loss': 0.2857284245359542, 'validation/num_examples': 3554, 'test/ssim': 0.7427518664042865, 'test/loss': 0.2870056101211254, 'test/num_examples': 3581, 'score': 5181.017259836197, 'total_duration': 5643.584321975708, 'accumulated_submission_time': 5181.017259836197, 'accumulated_eval_time': 459.95671033859253, 'accumulated_logging_time': 1.8128316402435303}
I0208 16:40:11.486025 140280493741824 logging_writer.py:48] [21791] accumulated_eval_time=459.956710, accumulated_logging_time=1.812832, accumulated_submission_time=5181.017260, global_step=21791, preemption_count=0, score=5181.017260, test/loss=0.287006, test/num_examples=3581, test/ssim=0.742752, total_duration=5643.584322, train/loss=0.265972, train/ssim=0.749245, validation/loss=0.285728, validation/num_examples=3554, validation/ssim=0.725666
I0208 16:40:12.230745 140280502134528 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.4480723440647125, loss=0.2675400972366333
I0208 16:40:35.101542 140280493741824 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.17930269241333008, loss=0.23010516166687012
I0208 16:40:58.877727 140280502134528 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.18873709440231323, loss=0.2396426498889923
I0208 16:41:22.964834 140280493741824 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.4916871190071106, loss=0.3058823049068451
I0208 16:41:31.596580 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:41:32.971551 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:41:34.292601 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:41:35.615252 140466628462400 submission_runner.py:408] Time since start: 5727.73s, 	Step: 22138, 	{'train/ssim': 0.748035022190639, 'train/loss': 0.2667830841881888, 'validation/ssim': 0.7249676173633582, 'validation/loss': 0.28607260167900606, 'validation/num_examples': 3554, 'test/ssim': 0.7421120284356674, 'test/loss': 0.28734789105042235, 'test/num_examples': 3581, 'score': 5261.106295824051, 'total_duration': 5727.733413934708, 'accumulated_submission_time': 5261.106295824051, 'accumulated_eval_time': 463.9753234386444, 'accumulated_logging_time': 1.8418028354644775}
I0208 16:41:35.635814 140280502134528 logging_writer.py:48] [22138] accumulated_eval_time=463.975323, accumulated_logging_time=1.841803, accumulated_submission_time=5261.106296, global_step=22138, preemption_count=0, score=5261.106296, test/loss=0.287348, test/num_examples=3581, test/ssim=0.742112, total_duration=5727.733414, train/loss=0.266783, train/ssim=0.748035, validation/loss=0.286073, validation/num_examples=3554, validation/ssim=0.724968
I0208 16:41:48.246953 140280493741824 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.1604517698287964, loss=0.25909310579299927
I0208 16:42:12.404200 140280502134528 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.1355869472026825, loss=0.32886001467704773
I0208 16:42:36.226746 140280493741824 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.1324114203453064, loss=0.22656764090061188
I0208 16:42:55.695519 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:42:57.069211 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:42:58.389428 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:42:59.712975 140466628462400 submission_runner.py:408] Time since start: 5811.83s, 	Step: 22483, 	{'train/ssim': 0.7493149893624442, 'train/loss': 0.2660031999860491, 'validation/ssim': 0.7261346700021103, 'validation/loss': 0.2854326255682418, 'validation/num_examples': 3554, 'test/ssim': 0.7432496923869031, 'test/loss': 0.286731574030037, 'test/num_examples': 3581, 'score': 5341.142727136612, 'total_duration': 5811.8311512470245, 'accumulated_submission_time': 5341.142727136612, 'accumulated_eval_time': 467.9927349090576, 'accumulated_logging_time': 1.8729948997497559}
I0208 16:42:59.733295 140280502134528 logging_writer.py:48] [22483] accumulated_eval_time=467.992735, accumulated_logging_time=1.872995, accumulated_submission_time=5341.142727, global_step=22483, preemption_count=0, score=5341.142727, test/loss=0.286732, test/num_examples=3581, test/ssim=0.743250, total_duration=5811.831151, train/loss=0.266003, train/ssim=0.749315, validation/loss=0.285433, validation/num_examples=3554, validation/ssim=0.726135
I0208 16:43:01.857412 140280493741824 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.14610400795936584, loss=0.2251604199409485
I0208 16:43:25.644046 140280502134528 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.09150885045528412, loss=0.2168237268924713
I0208 16:43:50.011672 140280493741824 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.2979061007499695, loss=0.2979714870452881
I0208 16:44:13.948220 140280502134528 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.16230317950248718, loss=0.26461049914360046
I0208 16:44:19.757771 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:44:21.130086 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:44:22.452571 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:44:23.776473 140466628462400 submission_runner.py:408] Time since start: 5895.89s, 	Step: 22826, 	{'train/ssim': 0.7495972088405064, 'train/loss': 0.26590023721967426, 'validation/ssim': 0.7261499202043472, 'validation/loss': 0.2854917201019098, 'validation/num_examples': 3554, 'test/ssim': 0.7432502378001955, 'test/loss': 0.2868267486495567, 'test/num_examples': 3581, 'score': 5421.144332408905, 'total_duration': 5895.894639015198, 'accumulated_submission_time': 5421.144332408905, 'accumulated_eval_time': 472.01139187812805, 'accumulated_logging_time': 1.9036543369293213}
I0208 16:44:23.798429 140280493741824 logging_writer.py:48] [22826] accumulated_eval_time=472.011392, accumulated_logging_time=1.903654, accumulated_submission_time=5421.144332, global_step=22826, preemption_count=0, score=5421.144332, test/loss=0.286827, test/num_examples=3581, test/ssim=0.743250, total_duration=5895.894639, train/loss=0.265900, train/ssim=0.749597, validation/loss=0.285492, validation/num_examples=3554, validation/ssim=0.726150
I0208 16:44:39.679415 140280502134528 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.16090719401836395, loss=0.20586994290351868
I0208 16:45:03.706760 140280493741824 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.19275356829166412, loss=0.25745201110839844
I0208 16:45:27.772518 140280502134528 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.189179465174675, loss=0.316224604845047
I0208 16:45:43.903340 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:45:45.276148 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:45:46.597308 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:45:47.921526 140466628462400 submission_runner.py:408] Time since start: 5980.04s, 	Step: 23169, 	{'train/ssim': 0.7486049788338798, 'train/loss': 0.2657872268131801, 'validation/ssim': 0.7252260464661298, 'validation/loss': 0.2853719510586663, 'validation/num_examples': 3554, 'test/ssim': 0.742398370414165, 'test/loss': 0.2866561024657044, 'test/num_examples': 3581, 'score': 5501.226588726044, 'total_duration': 5980.0396893024445, 'accumulated_submission_time': 5501.226588726044, 'accumulated_eval_time': 476.02953267097473, 'accumulated_logging_time': 1.9357259273529053}
I0208 16:45:47.942490 140280493741824 logging_writer.py:48] [23169] accumulated_eval_time=476.029533, accumulated_logging_time=1.935726, accumulated_submission_time=5501.226589, global_step=23169, preemption_count=0, score=5501.226589, test/loss=0.286656, test/num_examples=3581, test/ssim=0.742398, total_duration=5980.039689, train/loss=0.265787, train/ssim=0.748605, validation/loss=0.285372, validation/num_examples=3554, validation/ssim=0.725226
I0208 16:45:53.375977 140280502134528 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.08427576720714569, loss=0.2730206549167633
I0208 16:46:17.248695 140280493741824 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.11392591148614883, loss=0.2630392014980316
I0208 16:46:40.873764 140280502134528 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.0995107963681221, loss=0.3006044924259186
I0208 16:47:04.845223 140280493741824 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.1575329303741455, loss=0.2716313600540161
I0208 16:47:07.940645 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:47:09.313249 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:47:10.635472 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:47:11.960742 140466628462400 submission_runner.py:408] Time since start: 6064.08s, 	Step: 23514, 	{'train/ssim': 0.7499886240277972, 'train/loss': 0.265853796686445, 'validation/ssim': 0.7267512727736354, 'validation/loss': 0.2853215979134426, 'validation/num_examples': 3554, 'test/ssim': 0.7437929922027716, 'test/loss': 0.2866178894469073, 'test/num_examples': 3581, 'score': 5581.201484680176, 'total_duration': 6064.078918218613, 'accumulated_submission_time': 5581.201484680176, 'accumulated_eval_time': 480.0495846271515, 'accumulated_logging_time': 1.9672400951385498}
I0208 16:47:11.981874 140280502134528 logging_writer.py:48] [23514] accumulated_eval_time=480.049585, accumulated_logging_time=1.967240, accumulated_submission_time=5581.201485, global_step=23514, preemption_count=0, score=5581.201485, test/loss=0.286618, test/num_examples=3581, test/ssim=0.743793, total_duration=6064.078918, train/loss=0.265854, train/ssim=0.749989, validation/loss=0.285322, validation/num_examples=3554, validation/ssim=0.726751
I0208 16:47:30.398280 140280493741824 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.3068477213382721, loss=0.25719574093818665
I0208 16:47:54.781351 140280502134528 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.13193437457084656, loss=0.28518521785736084
I0208 16:48:19.017109 140280493741824 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.09913395345211029, loss=0.29175037145614624
I0208 16:48:32.141961 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:48:33.515186 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:48:34.838023 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:48:36.161506 140466628462400 submission_runner.py:408] Time since start: 6148.28s, 	Step: 23856, 	{'train/ssim': 0.7493819509233747, 'train/loss': 0.26600572041102816, 'validation/ssim': 0.7261044443760551, 'validation/loss': 0.2854621299009479, 'validation/num_examples': 3554, 'test/ssim': 0.7432202400691148, 'test/loss': 0.2868497923611596, 'test/num_examples': 3581, 'score': 5661.339335203171, 'total_duration': 6148.279658317566, 'accumulated_submission_time': 5661.339335203171, 'accumulated_eval_time': 484.0690758228302, 'accumulated_logging_time': 1.9982903003692627}
I0208 16:48:36.185684 140280502134528 logging_writer.py:48] [23856] accumulated_eval_time=484.069076, accumulated_logging_time=1.998290, accumulated_submission_time=5661.339335, global_step=23856, preemption_count=0, score=5661.339335, test/loss=0.286850, test/num_examples=3581, test/ssim=0.743220, total_duration=6148.279658, train/loss=0.266006, train/ssim=0.749382, validation/loss=0.285462, validation/num_examples=3554, validation/ssim=0.726104
I0208 16:48:44.727129 140280493741824 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.07557938247919083, loss=0.22834590077400208
I0208 16:49:08.892291 140280502134528 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.10720193386077881, loss=0.1893140971660614
I0208 16:49:32.715564 140280493741824 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.06141335889697075, loss=0.34947332739830017
I0208 16:49:56.186559 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:49:57.560438 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:49:58.884491 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:50:00.207236 140466628462400 submission_runner.py:408] Time since start: 6232.33s, 	Step: 24199, 	{'train/ssim': 0.7496466636657715, 'train/loss': 0.26554931913103375, 'validation/ssim': 0.7258055541511326, 'validation/loss': 0.2854341025022422, 'validation/num_examples': 3554, 'test/ssim': 0.7429892575397934, 'test/loss': 0.28676791219064157, 'test/num_examples': 3581, 'score': 5741.316986083984, 'total_duration': 6232.325395584106, 'accumulated_submission_time': 5741.316986083984, 'accumulated_eval_time': 488.0896954536438, 'accumulated_logging_time': 2.0329601764678955}
I0208 16:50:00.229106 140280502134528 logging_writer.py:48] [24199] accumulated_eval_time=488.089695, accumulated_logging_time=2.032960, accumulated_submission_time=5741.316986, global_step=24199, preemption_count=0, score=5741.316986, test/loss=0.286768, test/num_examples=3581, test/ssim=0.742989, total_duration=6232.325396, train/loss=0.265549, train/ssim=0.749647, validation/loss=0.285434, validation/num_examples=3554, validation/ssim=0.725806
I0208 16:50:00.394512 140280493741824 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.1414015144109726, loss=0.27435657382011414
I0208 16:50:22.099551 140280502134528 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.2709399461746216, loss=0.27077484130859375
I0208 16:50:46.057178 140280493741824 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.1237080991268158, loss=0.33024996519088745
I0208 16:51:09.802058 140280502134528 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.10158506780862808, loss=0.30683112144470215
I0208 16:51:20.291948 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:51:21.665840 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:51:22.988224 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:51:24.312236 140466628462400 submission_runner.py:408] Time since start: 6316.43s, 	Step: 24545, 	{'train/ssim': 0.7499784060886928, 'train/loss': 0.26558062008449007, 'validation/ssim': 0.7264893402460256, 'validation/loss': 0.28520514338487446, 'validation/num_examples': 3554, 'test/ssim': 0.7436160055893954, 'test/loss': 0.28648971732319883, 'test/num_examples': 3581, 'score': 5821.357635498047, 'total_duration': 6316.430392026901, 'accumulated_submission_time': 5821.357635498047, 'accumulated_eval_time': 492.1099181175232, 'accumulated_logging_time': 2.064488172531128}
I0208 16:51:24.337215 140280493741824 logging_writer.py:48] [24545] accumulated_eval_time=492.109918, accumulated_logging_time=2.064488, accumulated_submission_time=5821.357635, global_step=24545, preemption_count=0, score=5821.357635, test/loss=0.286490, test/num_examples=3581, test/ssim=0.743616, total_duration=6316.430392, train/loss=0.265581, train/ssim=0.749978, validation/loss=0.285205, validation/num_examples=3554, validation/ssim=0.726489
I0208 16:51:35.376684 140280502134528 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.20265457034111023, loss=0.17385433614253998
I0208 16:51:59.026440 140280493741824 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.10076458007097244, loss=0.2319359928369522
I0208 16:52:23.288108 140280502134528 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.15268763899803162, loss=0.32010143995285034
I0208 16:52:44.507448 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:52:45.878272 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:52:47.202420 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:52:48.524055 140466628462400 submission_runner.py:408] Time since start: 6400.64s, 	Step: 24889, 	{'train/ssim': 0.7498251370021275, 'train/loss': 0.26585865020751953, 'validation/ssim': 0.7265470437139491, 'validation/loss': 0.2853666100531531, 'validation/num_examples': 3554, 'test/ssim': 0.743647980443661, 'test/loss': 0.28666909011972913, 'test/num_examples': 3581, 'score': 5901.505459070206, 'total_duration': 6400.642231225967, 'accumulated_submission_time': 5901.505459070206, 'accumulated_eval_time': 496.126501083374, 'accumulated_logging_time': 2.0994303226470947}
I0208 16:52:48.544821 140280493741824 logging_writer.py:48] [24889] accumulated_eval_time=496.126501, accumulated_logging_time=2.099430, accumulated_submission_time=5901.505459, global_step=24889, preemption_count=0, score=5901.505459, test/loss=0.286669, test/num_examples=3581, test/ssim=0.743648, total_duration=6400.642231, train/loss=0.265859, train/ssim=0.749825, validation/loss=0.285367, validation/num_examples=3554, validation/ssim=0.726547
I0208 16:52:49.436877 140280502134528 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.15461693704128265, loss=0.316261351108551
I0208 16:53:13.327458 140280493741824 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.1304280012845993, loss=0.25670212507247925
I0208 16:53:37.074052 140280502134528 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.06596032530069351, loss=0.2367008626461029
I0208 16:54:00.774439 140280493741824 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.08173839747905731, loss=0.23410534858703613
I0208 16:54:08.760835 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:54:10.134040 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:54:11.458174 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:54:12.780771 140466628462400 submission_runner.py:408] Time since start: 6484.90s, 	Step: 25235, 	{'train/ssim': 0.7498918942042759, 'train/loss': 0.26507547923496794, 'validation/ssim': 0.7259708333699705, 'validation/loss': 0.2850697291454171, 'validation/num_examples': 3554, 'test/ssim': 0.7431427232049358, 'test/loss': 0.28636771518736037, 'test/num_examples': 3581, 'score': 5981.699506759644, 'total_duration': 6484.898949146271, 'accumulated_submission_time': 5981.699506759644, 'accumulated_eval_time': 500.1464011669159, 'accumulated_logging_time': 2.1296558380126953}
I0208 16:54:12.801784 140280502134528 logging_writer.py:48] [25235] accumulated_eval_time=500.146401, accumulated_logging_time=2.129656, accumulated_submission_time=5981.699507, global_step=25235, preemption_count=0, score=5981.699507, test/loss=0.286368, test/num_examples=3581, test/ssim=0.743143, total_duration=6484.898949, train/loss=0.265075, train/ssim=0.749892, validation/loss=0.285070, validation/num_examples=3554, validation/ssim=0.725971
I0208 16:54:26.389158 140280493741824 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.11312570422887802, loss=0.2933323085308075
I0208 16:54:50.021424 140280502134528 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.1344381868839264, loss=0.23132561147212982
I0208 16:55:14.084820 140280493741824 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.10953553766012192, loss=0.2554031014442444
I0208 16:55:32.942055 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:55:34.316434 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:55:35.638790 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:55:36.961575 140466628462400 submission_runner.py:408] Time since start: 6569.08s, 	Step: 25580, 	{'train/ssim': 0.7498783384050641, 'train/loss': 0.2653120585850307, 'validation/ssim': 0.726230086807998, 'validation/loss': 0.2851230018113393, 'validation/num_examples': 3554, 'test/ssim': 0.7433790916905194, 'test/loss': 0.28637095357878384, 'test/num_examples': 3581, 'score': 6061.817725658417, 'total_duration': 6569.079738616943, 'accumulated_submission_time': 6061.817725658417, 'accumulated_eval_time': 504.1658718585968, 'accumulated_logging_time': 2.16015625}
I0208 16:55:36.983494 140280502134528 logging_writer.py:48] [25580] accumulated_eval_time=504.165872, accumulated_logging_time=2.160156, accumulated_submission_time=6061.817726, global_step=25580, preemption_count=0, score=6061.817726, test/loss=0.286371, test/num_examples=3581, test/ssim=0.743379, total_duration=6569.079739, train/loss=0.265312, train/ssim=0.749878, validation/loss=0.285123, validation/num_examples=3554, validation/ssim=0.726230
I0208 16:55:39.674564 140280493741824 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.06823410093784332, loss=0.22257186472415924
I0208 16:56:03.330370 140280502134528 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.1730004847049713, loss=0.26988139748573303
I0208 16:56:27.056403 140280493741824 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.0784069076180458, loss=0.21699963510036469
I0208 16:56:51.063620 140280502134528 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.21029804646968842, loss=0.28200334310531616
I0208 16:56:57.100268 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:56:58.472437 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:56:59.793932 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:57:01.121176 140466628462400 submission_runner.py:408] Time since start: 6653.24s, 	Step: 25925, 	{'train/ssim': 0.7497959818158831, 'train/loss': 0.26541459560394287, 'validation/ssim': 0.72636321695185, 'validation/loss': 0.28510725357321853, 'validation/num_examples': 3554, 'test/ssim': 0.7434775387897934, 'test/loss': 0.2863817254913083, 'test/num_examples': 3581, 'score': 6141.91224861145, 'total_duration': 6653.2393543720245, 'accumulated_submission_time': 6141.91224861145, 'accumulated_eval_time': 508.18673872947693, 'accumulated_logging_time': 2.1918129920959473}
I0208 16:57:01.141930 140280493741824 logging_writer.py:48] [25925] accumulated_eval_time=508.186739, accumulated_logging_time=2.191813, accumulated_submission_time=6141.912249, global_step=25925, preemption_count=0, score=6141.912249, test/loss=0.286382, test/num_examples=3581, test/ssim=0.743478, total_duration=6653.239354, train/loss=0.265415, train/ssim=0.749796, validation/loss=0.285107, validation/num_examples=3554, validation/ssim=0.726363
I0208 16:57:16.892772 140280502134528 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.1066918894648552, loss=0.360763281583786
I0208 16:57:41.078425 140280493741824 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.11539027094841003, loss=0.29273876547813416
I0208 16:58:05.359801 140280502134528 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.09504780918359756, loss=0.28967204689979553
I0208 16:58:21.214379 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:58:22.586613 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:58:23.908325 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:58:25.234379 140466628462400 submission_runner.py:408] Time since start: 6737.35s, 	Step: 26268, 	{'train/ssim': 0.7502094677516392, 'train/loss': 0.26494574546813965, 'validation/ssim': 0.7263461806898917, 'validation/loss': 0.28503902265712927, 'validation/num_examples': 3554, 'test/ssim': 0.7434729027768081, 'test/loss': 0.28635292085180464, 'test/num_examples': 3581, 'score': 6221.960324764252, 'total_duration': 6737.352556943893, 'accumulated_submission_time': 6221.960324764252, 'accumulated_eval_time': 512.2066950798035, 'accumulated_logging_time': 2.224546432495117}
I0208 16:58:25.255916 140280493741824 logging_writer.py:48] [26268] accumulated_eval_time=512.206695, accumulated_logging_time=2.224546, accumulated_submission_time=6221.960325, global_step=26268, preemption_count=0, score=6221.960325, test/loss=0.286353, test/num_examples=3581, test/ssim=0.743473, total_duration=6737.352557, train/loss=0.264946, train/ssim=0.750209, validation/loss=0.285039, validation/num_examples=3554, validation/ssim=0.726346
I0208 16:58:30.798712 140280502134528 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.20401187241077423, loss=0.24435244500637054
I0208 16:58:54.647385 140280493741824 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.11295939236879349, loss=0.3293308913707733
I0208 16:59:18.677301 140280502134528 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.1352425366640091, loss=0.284166544675827
I0208 16:59:42.403459 140280493741824 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.07682546973228455, loss=0.31447386741638184
I0208 16:59:45.251117 140466628462400 spec.py:321] Evaluating on the training split.
I0208 16:59:46.621690 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 16:59:47.944992 140466628462400 spec.py:349] Evaluating on the test split.
I0208 16:59:49.272001 140466628462400 submission_runner.py:408] Time since start: 6821.39s, 	Step: 26613, 	{'train/ssim': 0.7500839233398438, 'train/loss': 0.26523120062691824, 'validation/ssim': 0.7263961216674873, 'validation/loss': 0.2850700726184405, 'validation/num_examples': 3554, 'test/ssim': 0.7435960298275621, 'test/loss': 0.28635268223348925, 'test/num_examples': 3581, 'score': 6301.933490514755, 'total_duration': 6821.390177488327, 'accumulated_submission_time': 6301.933490514755, 'accumulated_eval_time': 516.2275338172913, 'accumulated_logging_time': 2.2554852962493896}
I0208 16:59:49.294684 140280502134528 logging_writer.py:48] [26613] accumulated_eval_time=516.227534, accumulated_logging_time=2.255485, accumulated_submission_time=6301.933491, global_step=26613, preemption_count=0, score=6301.933491, test/loss=0.286353, test/num_examples=3581, test/ssim=0.743596, total_duration=6821.390177, train/loss=0.265231, train/ssim=0.750084, validation/loss=0.285070, validation/num_examples=3554, validation/ssim=0.726396
I0208 17:00:08.095470 140280493741824 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.07687564939260483, loss=0.247606560587883
I0208 17:00:31.668889 140280502134528 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.10955188423395157, loss=0.22246183454990387
I0208 17:00:55.389063 140280493741824 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.08705150336027145, loss=0.249686136841774
I0208 17:01:09.452150 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:01:10.829216 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:01:12.149241 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:01:13.470768 140466628462400 submission_runner.py:408] Time since start: 6905.59s, 	Step: 26958, 	{'train/ssim': 0.7498068809509277, 'train/loss': 0.26525681359427317, 'validation/ssim': 0.7262263086047411, 'validation/loss': 0.28504298977054904, 'validation/num_examples': 3554, 'test/ssim': 0.7434109301914619, 'test/loss': 0.28628532369188076, 'test/num_examples': 3581, 'score': 6382.069779396057, 'total_duration': 6905.588939666748, 'accumulated_submission_time': 6382.069779396057, 'accumulated_eval_time': 520.2461042404175, 'accumulated_logging_time': 2.287006378173828}
I0208 17:01:13.492129 140280502134528 logging_writer.py:48] [26958] accumulated_eval_time=520.246104, accumulated_logging_time=2.287006, accumulated_submission_time=6382.069779, global_step=26958, preemption_count=0, score=6382.069779, test/loss=0.286285, test/num_examples=3581, test/ssim=0.743411, total_duration=6905.588940, train/loss=0.265257, train/ssim=0.749807, validation/loss=0.285043, validation/num_examples=3554, validation/ssim=0.726226
I0208 17:01:21.624906 140280493741824 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.12374958395957947, loss=0.25419965386390686
I0208 17:01:45.657098 140280502134528 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.33451148867607117, loss=0.2896708846092224
I0208 17:02:09.720093 140280493741824 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.1086430475115776, loss=0.2662104368209839
I0208 17:02:33.497461 140280502134528 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.12979069352149963, loss=0.249636709690094
I0208 17:02:33.503378 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:02:34.820665 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:02:36.140463 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:02:37.464318 140466628462400 submission_runner.py:408] Time since start: 6989.58s, 	Step: 27301, 	{'train/ssim': 0.7503508159092495, 'train/loss': 0.26479027952466694, 'validation/ssim': 0.7261952586434299, 'validation/loss': 0.28503661834596583, 'validation/num_examples': 3554, 'test/ssim': 0.7433469804829308, 'test/loss': 0.2863510459936121, 'test/num_examples': 3581, 'score': 6462.058999300003, 'total_duration': 6989.5824983119965, 'accumulated_submission_time': 6462.058999300003, 'accumulated_eval_time': 524.2069962024689, 'accumulated_logging_time': 2.317927598953247}
I0208 17:02:37.486218 140280493741824 logging_writer.py:48] [27301] accumulated_eval_time=524.206996, accumulated_logging_time=2.317928, accumulated_submission_time=6462.058999, global_step=27301, preemption_count=0, score=6462.058999, test/loss=0.286351, test/num_examples=3581, test/ssim=0.743347, total_duration=6989.582498, train/loss=0.264790, train/ssim=0.750351, validation/loss=0.285037, validation/num_examples=3554, validation/ssim=0.726195
I0208 17:02:59.120476 140280502134528 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.08346716314554214, loss=0.2479262351989746
I0208 17:03:22.999843 140280493741824 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.19396820664405823, loss=0.3647717833518982
I0208 17:03:47.046922 140280502134528 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.16167348623275757, loss=0.28339308500289917
I0208 17:03:57.597016 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:03:58.969227 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:04:00.289535 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:04:01.612273 140466628462400 submission_runner.py:408] Time since start: 7073.73s, 	Step: 27646, 	{'train/ssim': 0.7499651908874512, 'train/loss': 0.26499886172158377, 'validation/ssim': 0.7260563581527856, 'validation/loss': 0.2849680439568532, 'validation/num_examples': 3554, 'test/ssim': 0.743229239388439, 'test/loss': 0.28623681599719003, 'test/num_examples': 3581, 'score': 6542.14812707901, 'total_duration': 7073.7304475307465, 'accumulated_submission_time': 6542.14812707901, 'accumulated_eval_time': 528.22221159935, 'accumulated_logging_time': 2.3489346504211426}
I0208 17:04:01.634725 140280493741824 logging_writer.py:48] [27646] accumulated_eval_time=528.222212, accumulated_logging_time=2.348935, accumulated_submission_time=6542.148127, global_step=27646, preemption_count=0, score=6542.148127, test/loss=0.286237, test/num_examples=3581, test/ssim=0.743229, total_duration=7073.730448, train/loss=0.264999, train/ssim=0.749965, validation/loss=0.284968, validation/num_examples=3554, validation/ssim=0.726056
I0208 17:04:12.492175 140280502134528 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.07784698903560638, loss=0.30588406324386597
I0208 17:04:36.507921 140280493741824 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.10218819975852966, loss=0.2670521140098572
I0208 17:05:00.624486 140280502134528 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.08497104048728943, loss=0.25842776894569397
I0208 17:05:21.852061 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:05:23.222589 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:05:24.544180 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:05:25.865149 140466628462400 submission_runner.py:408] Time since start: 7157.98s, 	Step: 27989, 	{'train/ssim': 0.7497949600219727, 'train/loss': 0.2651307923453195, 'validation/ssim': 0.726063158918648, 'validation/loss': 0.28501516845565733, 'validation/num_examples': 3554, 'test/ssim': 0.7432007415439124, 'test/loss': 0.2863091855234222, 'test/num_examples': 3581, 'score': 6622.342363357544, 'total_duration': 7157.983325958252, 'accumulated_submission_time': 6622.342363357544, 'accumulated_eval_time': 532.2352705001831, 'accumulated_logging_time': 2.3820061683654785}
I0208 17:05:25.887110 140280493741824 logging_writer.py:48] [27989] accumulated_eval_time=532.235271, accumulated_logging_time=2.382006, accumulated_submission_time=6622.342363, global_step=27989, preemption_count=0, score=6622.342363, test/loss=0.286309, test/num_examples=3581, test/ssim=0.743201, total_duration=7157.983326, train/loss=0.265131, train/ssim=0.749795, validation/loss=0.285015, validation/num_examples=3554, validation/ssim=0.726063
I0208 17:05:26.779911 140280502134528 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.11958415806293488, loss=0.17673853039741516
I0208 17:05:50.792938 140280493741824 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.13885174691677094, loss=0.23875094950199127
I0208 17:06:14.697601 140280502134528 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.06586921215057373, loss=0.3099035322666168
I0208 17:06:38.505937 140280493741824 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.1463112235069275, loss=0.3091398775577545
I0208 17:06:46.019972 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:06:47.392050 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:06:48.715819 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:06:50.038401 140466628462400 submission_runner.py:408] Time since start: 7242.16s, 	Step: 28333, 	{'train/ssim': 0.75055878502982, 'train/loss': 0.2647071395601545, 'validation/ssim': 0.7264404983821047, 'validation/loss': 0.28501199133019134, 'validation/num_examples': 3554, 'test/ssim': 0.7435149677769827, 'test/loss': 0.28632087782087756, 'test/num_examples': 3581, 'score': 6702.4536962509155, 'total_duration': 7242.156578779221, 'accumulated_submission_time': 6702.4536962509155, 'accumulated_eval_time': 536.2536578178406, 'accumulated_logging_time': 2.413137912750244}
I0208 17:06:50.059890 140280502134528 logging_writer.py:48] [28333] accumulated_eval_time=536.253658, accumulated_logging_time=2.413138, accumulated_submission_time=6702.453696, global_step=28333, preemption_count=0, score=6702.453696, test/loss=0.286321, test/num_examples=3581, test/ssim=0.743515, total_duration=7242.156579, train/loss=0.264707, train/ssim=0.750559, validation/loss=0.285012, validation/num_examples=3554, validation/ssim=0.726440
I0208 17:07:04.178967 140280493741824 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.16539213061332703, loss=0.3220885097980499
I0208 17:07:27.968631 140280502134528 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.09580188244581223, loss=0.2874015271663666
I0208 17:07:51.816335 140280493741824 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.11598411947488785, loss=0.31702423095703125
I0208 17:08:10.079700 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:08:11.453433 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:08:12.775994 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:08:14.098371 140466628462400 submission_runner.py:408] Time since start: 7326.22s, 	Step: 28677, 	{'train/ssim': 0.7505395071847099, 'train/loss': 0.26479266371045795, 'validation/ssim': 0.7266726174512873, 'validation/loss': 0.2848629755590092, 'validation/num_examples': 3554, 'test/ssim': 0.7437867199499092, 'test/loss': 0.28617555926679, 'test/num_examples': 3581, 'score': 6782.451961994171, 'total_duration': 7326.216543912888, 'accumulated_submission_time': 6782.451961994171, 'accumulated_eval_time': 540.2722911834717, 'accumulated_logging_time': 2.4437241554260254}
I0208 17:08:14.121828 140280502134528 logging_writer.py:48] [28677] accumulated_eval_time=540.272291, accumulated_logging_time=2.443724, accumulated_submission_time=6782.451962, global_step=28677, preemption_count=0, score=6782.451962, test/loss=0.286176, test/num_examples=3581, test/ssim=0.743787, total_duration=7326.216544, train/loss=0.264793, train/ssim=0.750540, validation/loss=0.284863, validation/num_examples=3554, validation/ssim=0.726673
I0208 17:08:17.557484 140280493741824 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.07849877327680588, loss=0.29163414239883423
I0208 17:08:41.523856 140280502134528 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.12874437868595123, loss=0.23045894503593445
I0208 17:09:05.365250 140280493741824 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.08862096071243286, loss=0.2493661493062973
I0208 17:09:29.130271 140280502134528 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.10593883693218231, loss=0.29018503427505493
I0208 17:09:34.323141 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:09:35.697435 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:09:37.020524 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:09:38.344315 140466628462400 submission_runner.py:408] Time since start: 7410.46s, 	Step: 29023, 	{'train/ssim': 0.7501329013279506, 'train/loss': 0.26496262209756033, 'validation/ssim': 0.7262491839080966, 'validation/loss': 0.2849998839061181, 'validation/num_examples': 3554, 'test/ssim': 0.7433983175090757, 'test/loss': 0.2862706316213174, 'test/num_examples': 3581, 'score': 6862.631316900253, 'total_duration': 7410.462491750717, 'accumulated_submission_time': 6862.631316900253, 'accumulated_eval_time': 544.2934327125549, 'accumulated_logging_time': 2.476641893386841}
I0208 17:09:38.366910 140280493741824 logging_writer.py:48] [29023] accumulated_eval_time=544.293433, accumulated_logging_time=2.476642, accumulated_submission_time=6862.631317, global_step=29023, preemption_count=0, score=6862.631317, test/loss=0.286271, test/num_examples=3581, test/ssim=0.743398, total_duration=7410.462492, train/loss=0.264963, train/ssim=0.750133, validation/loss=0.285000, validation/num_examples=3554, validation/ssim=0.726249
I0208 17:09:54.628772 140280502134528 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.13622575998306274, loss=0.23781295120716095
I0208 17:10:19.104102 140280493741824 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.08579375594854355, loss=0.2462000846862793
I0208 17:10:42.873901 140280502134528 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.07717181742191315, loss=0.2763770818710327
I0208 17:10:58.355964 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:10:59.728520 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:11:01.048869 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:11:02.372516 140466628462400 submission_runner.py:408] Time since start: 7494.49s, 	Step: 29366, 	{'train/ssim': 0.7502886227199009, 'train/loss': 0.26472565105983187, 'validation/ssim': 0.7261591939759777, 'validation/loss': 0.285006427067213, 'validation/num_examples': 3554, 'test/ssim': 0.7433084606691567, 'test/loss': 0.2862858691051731, 'test/num_examples': 3581, 'score': 6942.597845315933, 'total_duration': 7494.490667819977, 'accumulated_submission_time': 6942.597845315933, 'accumulated_eval_time': 548.3099186420441, 'accumulated_logging_time': 2.50946044921875}
I0208 17:11:02.396482 140280493741824 logging_writer.py:48] [29366] accumulated_eval_time=548.309919, accumulated_logging_time=2.509460, accumulated_submission_time=6942.597845, global_step=29366, preemption_count=0, score=6942.597845, test/loss=0.286286, test/num_examples=3581, test/ssim=0.743308, total_duration=7494.490668, train/loss=0.264726, train/ssim=0.750289, validation/loss=0.285006, validation/num_examples=3554, validation/ssim=0.726159
I0208 17:11:08.466969 140280502134528 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.1227196678519249, loss=0.19695594906806946
I0208 17:11:32.159425 140280493741824 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.1028376892209053, loss=0.2241600602865219
I0208 17:11:56.125740 140280502134528 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.14249154925346375, loss=0.261468768119812
I0208 17:12:20.201056 140280493741824 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.0728943794965744, loss=0.3033095896244049
I0208 17:12:22.469229 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:12:23.840881 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:12:25.160529 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:12:26.484798 140466628462400 submission_runner.py:408] Time since start: 7578.60s, 	Step: 29711, 	{'train/ssim': 0.7505989074707031, 'train/loss': 0.26468569891793386, 'validation/ssim': 0.7264604198174592, 'validation/loss': 0.28494558082112587, 'validation/num_examples': 3554, 'test/ssim': 0.7435891439847458, 'test/loss': 0.2862731200694638, 'test/num_examples': 3581, 'score': 7022.6484632492065, 'total_duration': 7578.602977514267, 'accumulated_submission_time': 7022.6484632492065, 'accumulated_eval_time': 552.3254547119141, 'accumulated_logging_time': 2.542933702468872}
I0208 17:12:26.506932 140280502134528 logging_writer.py:48] [29711] accumulated_eval_time=552.325455, accumulated_logging_time=2.542934, accumulated_submission_time=7022.648463, global_step=29711, preemption_count=0, score=7022.648463, test/loss=0.286273, test/num_examples=3581, test/ssim=0.743589, total_duration=7578.602978, train/loss=0.264686, train/ssim=0.750599, validation/loss=0.284946, validation/num_examples=3554, validation/ssim=0.726460
I0208 17:12:45.488483 140280493741824 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.15414083003997803, loss=0.25701606273651123
I0208 17:13:09.674718 140280502134528 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.09895617514848709, loss=0.23974786698818207
I0208 17:13:33.458102 140280493741824 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.1221667155623436, loss=0.29487189650535583
I0208 17:13:46.622379 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:13:47.996112 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:13:49.315815 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:13:50.636729 140466628462400 submission_runner.py:408] Time since start: 7662.75s, 	Step: 30056, 	{'train/ssim': 0.7506581715175084, 'train/loss': 0.2647981473377773, 'validation/ssim': 0.7267338930386537, 'validation/loss': 0.28490774726760343, 'validation/num_examples': 3554, 'test/ssim': 0.7438693500637042, 'test/loss': 0.2861787635698827, 'test/num_examples': 3581, 'score': 7102.741122245789, 'total_duration': 7662.754905939102, 'accumulated_submission_time': 7102.741122245789, 'accumulated_eval_time': 556.3397581577301, 'accumulated_logging_time': 2.5753839015960693}
I0208 17:13:50.658655 140280502134528 logging_writer.py:48] [30056] accumulated_eval_time=556.339758, accumulated_logging_time=2.575384, accumulated_submission_time=7102.741122, global_step=30056, preemption_count=0, score=7102.741122, test/loss=0.286179, test/num_examples=3581, test/ssim=0.743869, total_duration=7662.754906, train/loss=0.264798, train/ssim=0.750658, validation/loss=0.284908, validation/num_examples=3554, validation/ssim=0.726734
I0208 17:13:59.042675 140280493741824 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.05070740729570389, loss=0.24938851594924927
I0208 17:14:23.082487 140280502134528 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.12703222036361694, loss=0.2562362551689148
I0208 17:14:47.566851 140280493741824 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.09013808518648148, loss=0.17996688187122345
I0208 17:15:10.725222 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:15:12.098105 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:15:13.420330 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:15:14.742389 140466628462400 submission_runner.py:408] Time since start: 7746.86s, 	Step: 30397, 	{'train/ssim': 0.7500651904514858, 'train/loss': 0.2648999180112566, 'validation/ssim': 0.7260751804744654, 'validation/loss': 0.28502863259817285, 'validation/num_examples': 3554, 'test/ssim': 0.7432389204743787, 'test/loss': 0.28634780760218864, 'test/num_examples': 3581, 'score': 7182.78594827652, 'total_duration': 7746.8605670928955, 'accumulated_submission_time': 7182.78594827652, 'accumulated_eval_time': 560.3569049835205, 'accumulated_logging_time': 2.6066181659698486}
I0208 17:15:14.764828 140280502134528 logging_writer.py:48] [30397] accumulated_eval_time=560.356905, accumulated_logging_time=2.606618, accumulated_submission_time=7182.785948, global_step=30397, preemption_count=0, score=7182.785948, test/loss=0.286348, test/num_examples=3581, test/ssim=0.743239, total_duration=7746.860567, train/loss=0.264900, train/ssim=0.750065, validation/loss=0.285029, validation/num_examples=3554, validation/ssim=0.726075
I0208 17:15:15.075306 140280493741824 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.11574461311101913, loss=0.25362345576286316
I0208 17:15:37.111660 140280502134528 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.16163264214992523, loss=0.21690042316913605
I0208 17:16:00.754954 140280493741824 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.07522562891244888, loss=0.3440685272216797
I0208 17:16:24.758940 140280502134528 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.04518348351120949, loss=0.28578293323516846
I0208 17:16:34.976426 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:16:36.348259 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:16:37.672118 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:16:38.993310 140466628462400 submission_runner.py:408] Time since start: 7831.11s, 	Step: 30744, 	{'train/ssim': 0.750626632145473, 'train/loss': 0.2645703213555472, 'validation/ssim': 0.7264586337577378, 'validation/loss': 0.28491935665579277, 'validation/num_examples': 3554, 'test/ssim': 0.7435880531581611, 'test/loss': 0.28622454419811155, 'test/num_examples': 3581, 'score': 7262.975407361984, 'total_duration': 7831.111491441727, 'accumulated_submission_time': 7262.975407361984, 'accumulated_eval_time': 564.373776435852, 'accumulated_logging_time': 2.638613700866699}
I0208 17:16:39.015500 140280493741824 logging_writer.py:48] [30744] accumulated_eval_time=564.373776, accumulated_logging_time=2.638614, accumulated_submission_time=7262.975407, global_step=30744, preemption_count=0, score=7262.975407, test/loss=0.286225, test/num_examples=3581, test/ssim=0.743588, total_duration=7831.111491, train/loss=0.264570, train/ssim=0.750627, validation/loss=0.284919, validation/num_examples=3554, validation/ssim=0.726459
I0208 17:16:50.343085 140280502134528 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.05963441729545593, loss=0.3233852982521057
I0208 17:17:14.047317 140280493741824 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.062160588800907135, loss=0.24804943799972534
I0208 17:17:37.923886 140280502134528 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.08467583358287811, loss=0.2908536493778229
I0208 17:17:59.002960 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:18:00.376254 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:18:01.703755 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:18:03.029083 140466628462400 submission_runner.py:408] Time since start: 7915.15s, 	Step: 31088, 	{'train/ssim': 0.7506256103515625, 'train/loss': 0.2646536486489432, 'validation/ssim': 0.7265625686946047, 'validation/loss': 0.284842779345236, 'validation/num_examples': 3554, 'test/ssim': 0.7437144526886693, 'test/loss': 0.28614382303083985, 'test/num_examples': 3581, 'score': 7342.940884590149, 'total_duration': 7915.147254228592, 'accumulated_submission_time': 7342.940884590149, 'accumulated_eval_time': 568.3998596668243, 'accumulated_logging_time': 2.67030930519104}
I0208 17:18:03.052504 140280493741824 logging_writer.py:48] [31088] accumulated_eval_time=568.399860, accumulated_logging_time=2.670309, accumulated_submission_time=7342.940885, global_step=31088, preemption_count=0, score=7342.940885, test/loss=0.286144, test/num_examples=3581, test/ssim=0.743714, total_duration=7915.147254, train/loss=0.264654, train/ssim=0.750626, validation/loss=0.284843, validation/num_examples=3554, validation/ssim=0.726563
I0208 17:18:04.019802 140280502134528 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.07067113369703293, loss=0.2032822072505951
I0208 17:18:27.732688 140280493741824 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.05941357463598251, loss=0.19064874947071075
I0208 17:18:51.580721 140280502134528 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.05264671891927719, loss=0.30600932240486145
I0208 17:19:15.942923 140280493741824 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.07235493510961533, loss=0.19001084566116333
I0208 17:19:23.220382 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:19:24.592597 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:19:25.914690 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:19:27.239116 140466628462400 submission_runner.py:408] Time since start: 7999.36s, 	Step: 31433, 	{'train/ssim': 0.7506649153573173, 'train/loss': 0.26468786171504427, 'validation/ssim': 0.7265348847689224, 'validation/loss': 0.28496610333427125, 'validation/num_examples': 3554, 'test/ssim': 0.743663320192509, 'test/loss': 0.2862593824721621, 'test/num_examples': 3581, 'score': 7423.0860686302185, 'total_duration': 7999.357291936874, 'accumulated_submission_time': 7423.0860686302185, 'accumulated_eval_time': 572.4185557365417, 'accumulated_logging_time': 2.7039809226989746}
I0208 17:19:27.262190 140280502134528 logging_writer.py:48] [31433] accumulated_eval_time=572.418556, accumulated_logging_time=2.703981, accumulated_submission_time=7423.086069, global_step=31433, preemption_count=0, score=7423.086069, test/loss=0.286259, test/num_examples=3581, test/ssim=0.743663, total_duration=7999.357292, train/loss=0.264688, train/ssim=0.750665, validation/loss=0.284966, validation/num_examples=3554, validation/ssim=0.726535
I0208 17:19:41.396111 140280493741824 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.10154783725738525, loss=0.3266252875328064
I0208 17:20:05.140352 140280502134528 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.08785094320774078, loss=0.22480584681034088
I0208 17:20:28.884469 140280493741824 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.07197120785713196, loss=0.23043814301490784
I0208 17:20:47.404484 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:20:48.778969 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:20:50.100061 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:20:51.424468 140466628462400 submission_runner.py:408] Time since start: 8083.54s, 	Step: 31779, 	{'train/ssim': 0.7508582387651715, 'train/loss': 0.264353837285723, 'validation/ssim': 0.7265188102314294, 'validation/loss': 0.28483960221977, 'validation/num_examples': 3554, 'test/ssim': 0.7436525482799846, 'test/loss': 0.28615858327806476, 'test/num_examples': 3581, 'score': 7503.2064254283905, 'total_duration': 8083.542644500732, 'accumulated_submission_time': 7503.2064254283905, 'accumulated_eval_time': 576.4384963512421, 'accumulated_logging_time': 2.7362942695617676}
I0208 17:20:51.447231 140280502134528 logging_writer.py:48] [31779] accumulated_eval_time=576.438496, accumulated_logging_time=2.736294, accumulated_submission_time=7503.206425, global_step=31779, preemption_count=0, score=7503.206425, test/loss=0.286159, test/num_examples=3581, test/ssim=0.743653, total_duration=8083.542645, train/loss=0.264354, train/ssim=0.750858, validation/loss=0.284840, validation/num_examples=3554, validation/ssim=0.726519
I0208 17:20:54.427692 140280493741824 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.061641424894332886, loss=0.24440352618694305
I0208 17:21:18.148128 140280502134528 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.06849081814289093, loss=0.2984200119972229
I0208 17:21:42.112265 140280493741824 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.08783429116010666, loss=0.304230272769928
I0208 17:22:05.952609 140280502134528 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.05348466336727142, loss=0.3117316961288452
I0208 17:22:11.524517 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:22:12.898662 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:22:14.221757 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:22:15.545087 140466628462400 submission_runner.py:408] Time since start: 8167.66s, 	Step: 32124, 	{'train/ssim': 0.7506969315665108, 'train/loss': 0.26444237572806223, 'validation/ssim': 0.7265397620858539, 'validation/loss': 0.28476238948412, 'validation/num_examples': 3554, 'test/ssim': 0.743674023928372, 'test/loss': 0.28606848781983035, 'test/num_examples': 3581, 'score': 7583.260835409164, 'total_duration': 8167.663266420364, 'accumulated_submission_time': 7583.260835409164, 'accumulated_eval_time': 580.4590227603912, 'accumulated_logging_time': 2.7696642875671387}
I0208 17:22:15.567419 140280493741824 logging_writer.py:48] [32124] accumulated_eval_time=580.459023, accumulated_logging_time=2.769664, accumulated_submission_time=7583.260835, global_step=32124, preemption_count=0, score=7583.260835, test/loss=0.286068, test/num_examples=3581, test/ssim=0.743674, total_duration=8167.663266, train/loss=0.264442, train/ssim=0.750697, validation/loss=0.284762, validation/num_examples=3554, validation/ssim=0.726540
I0208 17:22:31.639606 140280502134528 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.05778651684522629, loss=0.21983790397644043
I0208 17:22:55.569321 140280493741824 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.06655387580394745, loss=0.2768486738204956
I0208 17:23:19.671406 140280502134528 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.08118867874145508, loss=0.26105883717536926
I0208 17:23:35.564751 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:23:36.937484 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:23:38.258365 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:23:39.582206 140466628462400 submission_runner.py:408] Time since start: 8251.70s, 	Step: 32467, 	{'train/ssim': 0.7506919588361468, 'train/loss': 0.26448231084006174, 'validation/ssim': 0.7265296639789673, 'validation/loss': 0.2847786872790781, 'validation/num_examples': 3554, 'test/ssim': 0.7436811824778344, 'test/loss': 0.2860721693595539, 'test/num_examples': 3581, 'score': 7663.235911130905, 'total_duration': 8251.700382471085, 'accumulated_submission_time': 7663.235911130905, 'accumulated_eval_time': 584.4764456748962, 'accumulated_logging_time': 2.801800489425659}
I0208 17:23:39.604606 140280493741824 logging_writer.py:48] [32467] accumulated_eval_time=584.476446, accumulated_logging_time=2.801800, accumulated_submission_time=7663.235911, global_step=32467, preemption_count=0, score=7663.235911, test/loss=0.286072, test/num_examples=3581, test/ssim=0.743681, total_duration=8251.700382, train/loss=0.264482, train/ssim=0.750692, validation/loss=0.284779, validation/num_examples=3554, validation/ssim=0.726530
I0208 17:23:45.367259 140280502134528 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.051487769931554794, loss=0.30588340759277344
I0208 17:24:09.623833 140280493741824 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.06813754141330719, loss=0.2688252925872803
I0208 17:24:33.793124 140280502134528 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.057371586561203, loss=0.2608674168586731
I0208 17:24:57.672118 140280493741824 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.0827830508351326, loss=0.23086272180080414
I0208 17:24:59.762021 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:25:01.133514 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:25:02.454774 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:25:03.780225 140466628462400 submission_runner.py:408] Time since start: 8335.90s, 	Step: 32810, 	{'train/ssim': 0.7511326926095145, 'train/loss': 0.26420453616550993, 'validation/ssim': 0.7267132846572524, 'validation/loss': 0.2847665283340514, 'validation/num_examples': 3554, 'test/ssim': 0.7438340345530229, 'test/loss': 0.28608474795360933, 'test/num_examples': 3581, 'score': 7743.370946645737, 'total_duration': 8335.898382425308, 'accumulated_submission_time': 7743.370946645737, 'accumulated_eval_time': 588.4945957660675, 'accumulated_logging_time': 2.8336546421051025}
I0208 17:25:03.803797 140280502134528 logging_writer.py:48] [32810] accumulated_eval_time=588.494596, accumulated_logging_time=2.833655, accumulated_submission_time=7743.370947, global_step=32810, preemption_count=0, score=7743.370947, test/loss=0.286085, test/num_examples=3581, test/ssim=0.743834, total_duration=8335.898382, train/loss=0.264205, train/ssim=0.751133, validation/loss=0.284767, validation/num_examples=3554, validation/ssim=0.726713
I0208 17:25:23.179278 140280493741824 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.12169177085161209, loss=0.2464497983455658
I0208 17:25:47.113972 140280502134528 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.07763738930225372, loss=0.32256466150283813
I0208 17:26:11.061352 140280493741824 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.06423655897378922, loss=0.25606685876846313
I0208 17:26:23.795053 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:26:25.170989 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:26:26.495111 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:26:27.816452 140466628462400 submission_runner.py:408] Time since start: 8419.93s, 	Step: 33155, 	{'train/ssim': 0.750725269317627, 'train/loss': 0.2643196071897234, 'validation/ssim': 0.7264477800101998, 'validation/loss': 0.28475035075465144, 'validation/num_examples': 3554, 'test/ssim': 0.7435964388875315, 'test/loss': 0.28605205724439753, 'test/num_examples': 3581, 'score': 7823.340132236481, 'total_duration': 8419.934628725052, 'accumulated_submission_time': 7823.340132236481, 'accumulated_eval_time': 592.5159690380096, 'accumulated_logging_time': 2.867058038711548}
I0208 17:26:27.839082 140280502134528 logging_writer.py:48] [33155] accumulated_eval_time=592.515969, accumulated_logging_time=2.867058, accumulated_submission_time=7823.340132, global_step=33155, preemption_count=0, score=7823.340132, test/loss=0.286052, test/num_examples=3581, test/ssim=0.743596, total_duration=8419.934629, train/loss=0.264320, train/ssim=0.750725, validation/loss=0.284750, validation/num_examples=3554, validation/ssim=0.726448
I0208 17:26:36.478330 140280493741824 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.043606191873550415, loss=0.3297688663005829
I0208 17:27:00.496545 140280502134528 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.06586181372404099, loss=0.19717760384082794
I0208 17:27:24.303014 140280493741824 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.06968609243631363, loss=0.266665518283844
I0208 17:27:47.911222 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:27:49.285409 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:27:50.608082 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:27:51.931000 140466628462400 submission_runner.py:408] Time since start: 8504.05s, 	Step: 33500, 	{'train/ssim': 0.7509395054408482, 'train/loss': 0.2643869774682181, 'validation/ssim': 0.7267172002497186, 'validation/loss': 0.2847576495563977, 'validation/num_examples': 3554, 'test/ssim': 0.7438440565222704, 'test/loss': 0.2860510005061435, 'test/num_examples': 3581, 'score': 7903.3904502391815, 'total_duration': 8504.049171447754, 'accumulated_submission_time': 7903.3904502391815, 'accumulated_eval_time': 596.5357365608215, 'accumulated_logging_time': 2.8989980220794678}
I0208 17:27:51.955325 140280502134528 logging_writer.py:48] [33500] accumulated_eval_time=596.535737, accumulated_logging_time=2.898998, accumulated_submission_time=7903.390450, global_step=33500, preemption_count=0, score=7903.390450, test/loss=0.286051, test/num_examples=3581, test/ssim=0.743844, total_duration=8504.049171, train/loss=0.264387, train/ssim=0.750940, validation/loss=0.284758, validation/num_examples=3554, validation/ssim=0.726717
I0208 17:27:52.046833 140280493741824 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.06168929114937782, loss=0.25315961241722107
I0208 17:28:13.893542 140280502134528 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.0720716118812561, loss=0.2853372097015381
I0208 17:28:37.995980 140280493741824 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.07490840554237366, loss=0.2455618530511856
I0208 17:29:01.942883 140280502134528 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.10096601396799088, loss=0.326831191778183
I0208 17:29:12.065158 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:29:13.437996 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:29:14.758436 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:29:16.080433 140466628462400 submission_runner.py:408] Time since start: 8588.20s, 	Step: 33844, 	{'train/ssim': 0.7513058526175362, 'train/loss': 0.2641360419137137, 'validation/ssim': 0.7268690840206458, 'validation/loss': 0.2847431893421145, 'validation/num_examples': 3554, 'test/ssim': 0.7439712741727171, 'test/loss': 0.2860495006195895, 'test/num_examples': 3581, 'score': 7983.478590726852, 'total_duration': 8588.198611021042, 'accumulated_submission_time': 7983.478590726852, 'accumulated_eval_time': 600.5509705543518, 'accumulated_logging_time': 2.932687520980835}
I0208 17:29:16.103832 140280493741824 logging_writer.py:48] [33844] accumulated_eval_time=600.550971, accumulated_logging_time=2.932688, accumulated_submission_time=7983.478591, global_step=33844, preemption_count=0, score=7983.478591, test/loss=0.286050, test/num_examples=3581, test/ssim=0.743971, total_duration=8588.198611, train/loss=0.264136, train/ssim=0.751306, validation/loss=0.284743, validation/num_examples=3554, validation/ssim=0.726869
I0208 17:29:27.293941 140280502134528 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.050031643360853195, loss=0.21351860463619232
I0208 17:29:51.164704 140280493741824 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.143264502286911, loss=0.26257655024528503
I0208 17:30:15.179228 140280502134528 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.06624875962734222, loss=0.22285571694374084
I0208 17:30:36.232058 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:30:37.603630 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:30:38.924899 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:30:40.252601 140466628462400 submission_runner.py:408] Time since start: 8672.37s, 	Step: 34190, 	{'train/ssim': 0.7509686606270927, 'train/loss': 0.2641798939023699, 'validation/ssim': 0.7265910082609384, 'validation/loss': 0.2846628166546497, 'validation/num_examples': 3554, 'test/ssim': 0.7437399507600879, 'test/loss': 0.2859617913445092, 'test/num_examples': 3581, 'score': 8063.584829330444, 'total_duration': 8672.370778083801, 'accumulated_submission_time': 8063.584829330444, 'accumulated_eval_time': 604.5714876651764, 'accumulated_logging_time': 2.965465784072876}
I0208 17:30:40.276422 140280493741824 logging_writer.py:48] [34190] accumulated_eval_time=604.571488, accumulated_logging_time=2.965466, accumulated_submission_time=8063.584829, global_step=34190, preemption_count=0, score=8063.584829, test/loss=0.285962, test/num_examples=3581, test/ssim=0.743740, total_duration=8672.370778, train/loss=0.264180, train/ssim=0.750969, validation/loss=0.284663, validation/num_examples=3554, validation/ssim=0.726591
I0208 17:30:41.095989 140280502134528 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.07984237372875214, loss=0.2314966917037964
I0208 17:31:04.576386 140280493741824 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.0661846473813057, loss=0.24997535347938538
I0208 17:31:28.349980 140280502134528 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.05474000796675682, loss=0.1864546239376068
I0208 17:31:52.320172 140280493741824 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.07637704908847809, loss=0.24844759702682495
I0208 17:32:00.300991 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:32:01.675704 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:32:02.994786 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:32:04.321425 140466628462400 submission_runner.py:408] Time since start: 8756.44s, 	Step: 34534, 	{'train/ssim': 0.7508820125034877, 'train/loss': 0.2642404351915632, 'validation/ssim': 0.726557279210045, 'validation/loss': 0.28470202410026557, 'validation/num_examples': 3554, 'test/ssim': 0.7436853412541887, 'test/loss': 0.28599434570039795, 'test/num_examples': 3581, 'score': 8143.587386846542, 'total_duration': 8756.439602851868, 'accumulated_submission_time': 8143.587386846542, 'accumulated_eval_time': 608.591876745224, 'accumulated_logging_time': 2.998674154281616}
I0208 17:32:04.344692 140280502134528 logging_writer.py:48] [34534] accumulated_eval_time=608.591877, accumulated_logging_time=2.998674, accumulated_submission_time=8143.587387, global_step=34534, preemption_count=0, score=8143.587387, test/loss=0.285994, test/num_examples=3581, test/ssim=0.743685, total_duration=8756.439603, train/loss=0.264240, train/ssim=0.750882, validation/loss=0.284702, validation/num_examples=3554, validation/ssim=0.726557
I0208 17:32:18.485041 140280493741824 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.05918259546160698, loss=0.22409673035144806
I0208 17:32:42.338133 140280502134528 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.12942707538604736, loss=0.3967576324939728
I0208 17:33:06.734820 140280493741824 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.1013890728354454, loss=0.34024477005004883
I0208 17:33:24.331596 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:33:25.706583 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:33:27.026204 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:33:28.346453 140466628462400 submission_runner.py:408] Time since start: 8840.46s, 	Step: 34875, 	{'train/ssim': 0.7510365758623395, 'train/loss': 0.26410153933933805, 'validation/ssim': 0.7266363467000211, 'validation/loss': 0.28466364098990576, 'validation/num_examples': 3554, 'test/ssim': 0.7437644943582449, 'test/loss': 0.28595943924968587, 'test/num_examples': 3581, 'score': 8223.553173303604, 'total_duration': 8840.46463394165, 'accumulated_submission_time': 8223.553173303604, 'accumulated_eval_time': 612.6066925525665, 'accumulated_logging_time': 3.0308783054351807}
I0208 17:33:28.369849 140280502134528 logging_writer.py:48] [34875] accumulated_eval_time=612.606693, accumulated_logging_time=3.030878, accumulated_submission_time=8223.553173, global_step=34875, preemption_count=0, score=8223.553173, test/loss=0.285959, test/num_examples=3581, test/ssim=0.743764, total_duration=8840.464634, train/loss=0.264102, train/ssim=0.751037, validation/loss=0.284664, validation/num_examples=3554, validation/ssim=0.726636
I0208 17:33:32.194833 140280493741824 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.07138101756572723, loss=0.24535740911960602
I0208 17:33:56.160121 140280502134528 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.06056173890829086, loss=0.32436272501945496
I0208 17:34:19.834391 140280493741824 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.09493070840835571, loss=0.2803775668144226
I0208 17:34:44.069855 140280502134528 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.05836575850844383, loss=0.253577321767807
I0208 17:34:48.488986 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:34:49.861185 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:34:51.183462 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:34:52.506403 140466628462400 submission_runner.py:408] Time since start: 8924.62s, 	Step: 35220, 	{'train/ssim': 0.7510863712855748, 'train/loss': 0.2640958513532366, 'validation/ssim': 0.7266660227692389, 'validation/loss': 0.28464203653673675, 'validation/num_examples': 3554, 'test/ssim': 0.7438080592449735, 'test/loss': 0.28594075884442194, 'test/num_examples': 3581, 'score': 8303.650809764862, 'total_duration': 8924.624583244324, 'accumulated_submission_time': 8303.650809764862, 'accumulated_eval_time': 616.624080657959, 'accumulated_logging_time': 3.063483715057373}
I0208 17:34:52.530929 140280493741824 logging_writer.py:48] [35220] accumulated_eval_time=616.624081, accumulated_logging_time=3.063484, accumulated_submission_time=8303.650810, global_step=35220, preemption_count=0, score=8303.650810, test/loss=0.285941, test/num_examples=3581, test/ssim=0.743808, total_duration=8924.624583, train/loss=0.264096, train/ssim=0.751086, validation/loss=0.284642, validation/num_examples=3554, validation/ssim=0.726666
I0208 17:35:09.698375 140280502134528 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.06860242038965225, loss=0.30267688632011414
I0208 17:35:33.379948 140280493741824 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.056571170687675476, loss=0.30920520424842834
I0208 17:35:57.039194 140280502134528 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.06698634475469589, loss=0.263333797454834
I0208 17:36:12.690006 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:36:14.063775 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:36:15.385991 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:36:16.709340 140466628462400 submission_runner.py:408] Time since start: 9008.83s, 	Step: 35566, 	{'train/ssim': 0.7510568073817662, 'train/loss': 0.264108487537929, 'validation/ssim': 0.7267169254713, 'validation/loss': 0.2846336729686181, 'validation/num_examples': 3554, 'test/ssim': 0.7438390796259774, 'test/loss': 0.28593455476822116, 'test/num_examples': 3581, 'score': 8383.785435676575, 'total_duration': 9008.827517747879, 'accumulated_submission_time': 8383.785435676575, 'accumulated_eval_time': 620.6433687210083, 'accumulated_logging_time': 3.0999300479888916}
I0208 17:36:16.732755 140280493741824 logging_writer.py:48] [35566] accumulated_eval_time=620.643369, accumulated_logging_time=3.099930, accumulated_submission_time=8383.785436, global_step=35566, preemption_count=0, score=8383.785436, test/loss=0.285935, test/num_examples=3581, test/ssim=0.743839, total_duration=9008.827518, train/loss=0.264108, train/ssim=0.751057, validation/loss=0.284634, validation/num_examples=3554, validation/ssim=0.726717
I0208 17:36:22.671141 140280502134528 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.04369277134537697, loss=0.19503021240234375
I0208 17:36:47.070780 140280493741824 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.06433413922786713, loss=0.30994266271591187
I0208 17:37:11.137846 140280502134528 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.08901843428611755, loss=0.22954531013965607
I0208 17:37:35.167620 140280493741824 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.07766330987215042, loss=0.2899553179740906
I0208 17:37:36.958842 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:37:38.332229 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:37:39.653049 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:37:40.976852 140466628462400 submission_runner.py:408] Time since start: 9093.10s, 	Step: 35909, 	{'train/ssim': 0.7510451589311872, 'train/loss': 0.2640914406095232, 'validation/ssim': 0.7266632062904473, 'validation/loss': 0.2846232485623593, 'validation/num_examples': 3554, 'test/ssim': 0.7438034914086498, 'test/loss': 0.28592248749912735, 'test/num_examples': 3581, 'score': 8463.990142822266, 'total_duration': 9093.095028400421, 'accumulated_submission_time': 8463.990142822266, 'accumulated_eval_time': 624.6613454818726, 'accumulated_logging_time': 3.1323611736297607}
I0208 17:37:41.000600 140280502134528 logging_writer.py:48] [35909] accumulated_eval_time=624.661345, accumulated_logging_time=3.132361, accumulated_submission_time=8463.990143, global_step=35909, preemption_count=0, score=8463.990143, test/loss=0.285922, test/num_examples=3581, test/ssim=0.743803, total_duration=9093.095028, train/loss=0.264091, train/ssim=0.751045, validation/loss=0.284623, validation/num_examples=3554, validation/ssim=0.726663
I0208 17:38:00.889968 140280493741824 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.06523462384939194, loss=0.22369924187660217
I0208 17:38:25.037804 140280502134528 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.05683264881372452, loss=0.3965109884738922
I0208 17:38:45.767970 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:38:47.141462 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:38:48.466086 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:38:49.790338 140466628462400 submission_runner.py:408] Time since start: 9161.91s, 	Step: 36189, 	{'train/ssim': 0.7512311254228864, 'train/loss': 0.2641005516052246, 'validation/ssim': 0.7268648249551561, 'validation/loss': 0.2846340336152926, 'validation/num_examples': 3554, 'test/ssim': 0.7439900909313041, 'test/loss': 0.28593407753159034, 'test/num_examples': 3581, 'score': 8528.737991809845, 'total_duration': 9161.908516168594, 'accumulated_submission_time': 8528.737991809845, 'accumulated_eval_time': 628.6836860179901, 'accumulated_logging_time': 3.1654698848724365}
I0208 17:38:49.815752 140280493741824 logging_writer.py:48] [36189] accumulated_eval_time=628.683686, accumulated_logging_time=3.165470, accumulated_submission_time=8528.737992, global_step=36189, preemption_count=0, score=8528.737992, test/loss=0.285934, test/num_examples=3581, test/ssim=0.743990, total_duration=9161.908516, train/loss=0.264101, train/ssim=0.751231, validation/loss=0.284634, validation/num_examples=3554, validation/ssim=0.726865
I0208 17:38:49.836897 140280502134528 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8528.737992
I0208 17:38:49.905372 140466628462400 checkpoints.py:490] Saving checkpoint at step: 36189
I0208 17:38:50.152987 140466628462400 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1/checkpoint_36189
I0208 17:38:50.154480 140466628462400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_1/checkpoint_36189.
I0208 17:38:50.600390 140466628462400 submission_runner.py:583] Tuning trial 1/5
I0208 17:38:50.600624 140466628462400 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0208 17:38:50.605871 140466628462400 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 55.91798734664917, 'total_duration': 258.3423571586609, 'accumulated_submission_time': 55.91798734664917, 'accumulated_eval_time': 202.42385411262512, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (339, {'train/ssim': 0.6871940749032157, 'train/loss': 0.3207972730909075, 'validation/ssim': 0.665303880201006, 'validation/loss': 0.33881968518087013, 'validation/num_examples': 3554, 'test/ssim': 0.6843897125235618, 'test/loss': 0.34010575291032535, 'test/num_examples': 3581, 'score': 136.21887683868408, 'total_duration': 343.12347984313965, 'accumulated_submission_time': 136.21887683868408, 'accumulated_eval_time': 206.8602089881897, 'accumulated_logging_time': 0.0311276912689209, 'global_step': 339, 'preemption_count': 0}), (583, {'train/ssim': 0.7098658425467355, 'train/loss': 0.2993877274649484, 'validation/ssim': 0.6883714597548537, 'validation/loss': 0.31659200021102984, 'validation/num_examples': 3554, 'test/ssim': 0.7065911014730523, 'test/loss': 0.3183245708142802, 'test/num_examples': 3581, 'score': 216.22331738471985, 'total_duration': 427.18370366096497, 'accumulated_submission_time': 216.22331738471985, 'accumulated_eval_time': 210.8728530406952, 'accumulated_logging_time': 0.06534719467163086, 'global_step': 583, 'preemption_count': 0}), (826, {'train/ssim': 0.7211519650050572, 'train/loss': 0.28913658005850656, 'validation/ssim': 0.6996939792751126, 'validation/loss': 0.30625318742965674, 'validation/num_examples': 3554, 'test/ssim': 0.7172323875139626, 'test/loss': 0.3082724674824595, 'test/num_examples': 3581, 'score': 296.40825033187866, 'total_duration': 511.42957520484924, 'accumulated_submission_time': 296.40825033187866, 'accumulated_eval_time': 214.89030241966248, 'accumulated_logging_time': 0.10000324249267578, 'global_step': 826, 'preemption_count': 0}), (1112, {'train/ssim': 0.7276527541024345, 'train/loss': 0.283478992325919, 'validation/ssim': 0.7057840307575971, 'validation/loss': 0.3010855670986916, 'validation/num_examples': 3554, 'test/ssim': 0.7226963378769896, 'test/loss': 0.3031021199123848, 'test/num_examples': 3581, 'score': 376.50986886024475, 'total_duration': 595.5867800712585, 'accumulated_submission_time': 376.50986886024475, 'accumulated_eval_time': 218.90482091903687, 'accumulated_logging_time': 0.1307234764099121, 'global_step': 1112, 'preemption_count': 0}), (1458, {'train/ssim': 0.730339595249721, 'train/loss': 0.28099383626665386, 'validation/ssim': 0.7092974850080894, 'validation/loss': 0.29821444174917344, 'validation/num_examples': 3554, 'test/ssim': 0.7262398198608978, 'test/loss': 0.30017164838077703, 'test/num_examples': 3581, 'score': 456.7718312740326, 'total_duration': 679.8992731571198, 'accumulated_submission_time': 456.7718312740326, 'accumulated_eval_time': 222.91810631752014, 'accumulated_logging_time': 0.15522503852844238, 'global_step': 1458, 'preemption_count': 0}), (1806, {'train/ssim': 0.734905515398298, 'train/loss': 0.27697512081691195, 'validation/ssim': 0.7133297896076604, 'validation/loss': 0.29460859325539884, 'validation/num_examples': 3554, 'test/ssim': 0.7303801203399888, 'test/loss': 0.2963384155852939, 'test/num_examples': 3581, 'score': 536.8662204742432, 'total_duration': 764.0558526515961, 'accumulated_submission_time': 536.8662204742432, 'accumulated_eval_time': 226.938090801239, 'accumulated_logging_time': 0.18469452857971191, 'global_step': 1806, 'preemption_count': 0}), (2152, {'train/ssim': 0.7232328142438617, 'train/loss': 0.29465011187962126, 'validation/ssim': 0.7039935745814575, 'validation/loss': 0.3114003024211276, 'validation/num_examples': 3554, 'test/ssim': 0.720800208566043, 'test/loss': 0.3137618477402436, 'test/num_examples': 3581, 'score': 616.8835611343384, 'total_duration': 848.1295416355133, 'accumulated_submission_time': 616.8835611343384, 'accumulated_eval_time': 230.95373272895813, 'accumulated_logging_time': 0.21259403228759766, 'global_step': 2152, 'preemption_count': 0}), (2498, {'train/ssim': 0.7367127282278878, 'train/loss': 0.27586754730769564, 'validation/ssim': 0.7151943672622397, 'validation/loss': 0.29359514175269064, 'validation/num_examples': 3554, 'test/ssim': 0.7322592054855487, 'test/loss': 0.29526262195441216, 'test/num_examples': 3581, 'score': 696.9776549339294, 'total_duration': 932.2862796783447, 'accumulated_submission_time': 696.9776549339294, 'accumulated_eval_time': 234.97657227516174, 'accumulated_logging_time': 0.23948168754577637, 'global_step': 2498, 'preemption_count': 0}), (2844, {'train/ssim': 0.7388166018894741, 'train/loss': 0.27419754437037874, 'validation/ssim': 0.7174660978387029, 'validation/loss': 0.29198198635120637, 'validation/num_examples': 3554, 'test/ssim': 0.7344461764346552, 'test/loss': 0.29358455569542374, 'test/num_examples': 3581, 'score': 777.0949683189392, 'total_duration': 1016.4557588100433, 'accumulated_submission_time': 777.0949683189392, 'accumulated_eval_time': 238.99145531654358, 'accumulated_logging_time': 0.2640409469604492, 'global_step': 2844, 'preemption_count': 0}), (3188, {'train/ssim': 0.7401871000017438, 'train/loss': 0.2737694127219064, 'validation/ssim': 0.7183199030801561, 'validation/loss': 0.29197903248320556, 'validation/num_examples': 3554, 'test/ssim': 0.7352607511868193, 'test/loss': 0.2936349723366378, 'test/num_examples': 3581, 'score': 857.13303399086, 'total_duration': 1100.553381204605, 'accumulated_submission_time': 857.13303399086, 'accumulated_eval_time': 243.00977039337158, 'accumulated_logging_time': 0.29268765449523926, 'global_step': 3188, 'preemption_count': 0}), (3535, {'train/ssim': 0.7400742939540318, 'train/loss': 0.2726729597364153, 'validation/ssim': 0.7181579212023425, 'validation/loss': 0.2907690800638365, 'validation/num_examples': 3554, 'test/ssim': 0.7353010435937937, 'test/loss': 0.2923930662698967, 'test/num_examples': 3581, 'score': 937.29634308815, 'total_duration': 1184.7737319469452, 'accumulated_submission_time': 937.29634308815, 'accumulated_eval_time': 247.0268371105194, 'accumulated_logging_time': 0.3201866149902344, 'global_step': 3535, 'preemption_count': 0}), (3881, {'train/ssim': 0.7403202056884766, 'train/loss': 0.27328058651515413, 'validation/ssim': 0.7185890485412564, 'validation/loss': 0.29121209156935846, 'validation/num_examples': 3554, 'test/ssim': 0.7356736290491482, 'test/loss': 0.29279292238987015, 'test/num_examples': 3581, 'score': 1017.4413931369781, 'total_duration': 1268.9722275733948, 'accumulated_submission_time': 1017.4413931369781, 'accumulated_eval_time': 251.04173159599304, 'accumulated_logging_time': 0.34575533866882324, 'global_step': 3881, 'preemption_count': 0}), (4225, {'train/ssim': 0.7391737529209682, 'train/loss': 0.2730711357934134, 'validation/ssim': 0.717479836759637, 'validation/loss': 0.2909697026567776, 'validation/num_examples': 3554, 'test/ssim': 0.7346395254468026, 'test/loss': 0.29249185425247837, 'test/num_examples': 3581, 'score': 1097.5015771389008, 'total_duration': 1353.090767621994, 'accumulated_submission_time': 1097.5015771389008, 'accumulated_eval_time': 255.06102967262268, 'accumulated_logging_time': 0.3724069595336914, 'global_step': 4225, 'preemption_count': 0}), (4572, {'train/ssim': 0.7415586880275181, 'train/loss': 0.2717891590935843, 'validation/ssim': 0.7190310983223129, 'validation/loss': 0.2903687622551175, 'validation/num_examples': 3554, 'test/ssim': 0.7362364273902192, 'test/loss': 0.29186558343950714, 'test/num_examples': 3581, 'score': 1177.474592924118, 'total_duration': 1437.1194834709167, 'accumulated_submission_time': 1177.474592924118, 'accumulated_eval_time': 259.0786759853363, 'accumulated_logging_time': 0.39757752418518066, 'global_step': 4572, 'preemption_count': 0}), (4919, {'train/ssim': 0.740943159375872, 'train/loss': 0.2720399243491037, 'validation/ssim': 0.7187721883573087, 'validation/loss': 0.29030807057189084, 'validation/num_examples': 3554, 'test/ssim': 0.7359213148605487, 'test/loss': 0.2918626177547298, 'test/num_examples': 3581, 'score': 1257.6327981948853, 'total_duration': 1521.3335707187653, 'accumulated_submission_time': 1257.6327981948853, 'accumulated_eval_time': 263.0961480140686, 'accumulated_logging_time': 0.4233999252319336, 'global_step': 4919, 'preemption_count': 0}), (5264, {'train/ssim': 0.7398541995457241, 'train/loss': 0.2729257345199585, 'validation/ssim': 0.7182161742271033, 'validation/loss': 0.2908276422143184, 'validation/num_examples': 3554, 'test/ssim': 0.7353418132373988, 'test/loss': 0.29238464645219564, 'test/num_examples': 3581, 'score': 1337.6137821674347, 'total_duration': 1605.3700017929077, 'accumulated_submission_time': 1337.6137821674347, 'accumulated_eval_time': 267.11389446258545, 'accumulated_logging_time': 0.44838404655456543, 'global_step': 5264, 'preemption_count': 0}), (5607, {'train/ssim': 0.7430362701416016, 'train/loss': 0.27040735312870573, 'validation/ssim': 0.72083666731148, 'validation/loss': 0.28880499827439154, 'validation/num_examples': 3554, 'test/ssim': 0.7379724097231919, 'test/loss': 0.2903670263303721, 'test/num_examples': 3581, 'score': 1417.68976521492, 'total_duration': 1689.497330904007, 'accumulated_submission_time': 1417.68976521492, 'accumulated_eval_time': 271.12782073020935, 'accumulated_logging_time': 0.47333264350891113, 'global_step': 5607, 'preemption_count': 0}), (5954, {'train/ssim': 0.7426825250898089, 'train/loss': 0.27037811279296875, 'validation/ssim': 0.7202349712691686, 'validation/loss': 0.28870113203212927, 'validation/num_examples': 3554, 'test/ssim': 0.7374507900856954, 'test/loss': 0.29025484163379645, 'test/num_examples': 3581, 'score': 1497.8008234500885, 'total_duration': 1773.6630256175995, 'accumulated_submission_time': 1497.8008234500885, 'accumulated_eval_time': 275.14325308799744, 'accumulated_logging_time': 0.4997069835662842, 'global_step': 5954, 'preemption_count': 0}), (6296, {'train/ssim': 0.742091178894043, 'train/loss': 0.2712857723236084, 'validation/ssim': 0.7200937351619654, 'validation/loss': 0.2893256346831915, 'validation/num_examples': 3554, 'test/ssim': 0.7372403969081611, 'test/loss': 0.2908137539051592, 'test/num_examples': 3581, 'score': 1577.8476405143738, 'total_duration': 1857.763218164444, 'accumulated_submission_time': 1577.8476405143738, 'accumulated_eval_time': 279.15823125839233, 'accumulated_logging_time': 0.5257272720336914, 'global_step': 6296, 'preemption_count': 0}), (6638, {'train/ssim': 0.7428139277866909, 'train/loss': 0.27047950880868094, 'validation/ssim': 0.720252831866383, 'validation/loss': 0.2890228975604073, 'validation/num_examples': 3554, 'test/ssim': 0.7374012938294122, 'test/loss': 0.29054350161878667, 'test/num_examples': 3581, 'score': 1657.8847556114197, 'total_duration': 1941.856261730194, 'accumulated_submission_time': 1657.8847556114197, 'accumulated_eval_time': 283.1754529476166, 'accumulated_logging_time': 0.5520541667938232, 'global_step': 6638, 'preemption_count': 0}), (6984, {'train/ssim': 0.7429917199271066, 'train/loss': 0.27064037322998047, 'validation/ssim': 0.7208075407990996, 'validation/loss': 0.2890006061611916, 'validation/num_examples': 3554, 'test/ssim': 0.737995862494764, 'test/loss': 0.29048991476281066, 'test/num_examples': 3581, 'score': 1737.8613169193268, 'total_duration': 2025.891048192978, 'accumulated_submission_time': 1737.8613169193268, 'accumulated_eval_time': 287.19444942474365, 'accumulated_logging_time': 0.5787684917449951, 'global_step': 6984, 'preemption_count': 0}), (7331, {'train/ssim': 0.7436522756304059, 'train/loss': 0.2696965081351144, 'validation/ssim': 0.7215000511087859, 'validation/loss': 0.2879728146597584, 'validation/num_examples': 3554, 'test/ssim': 0.7387117856176696, 'test/loss': 0.2893841915775098, 'test/num_examples': 3581, 'score': 1817.9266390800476, 'total_duration': 2110.0144007205963, 'accumulated_submission_time': 1817.9266390800476, 'accumulated_eval_time': 291.2129316329956, 'accumulated_logging_time': 0.6057913303375244, 'global_step': 7331, 'preemption_count': 0}), (7674, {'train/ssim': 0.742138317653111, 'train/loss': 0.2708191360746111, 'validation/ssim': 0.7195088006031936, 'validation/loss': 0.28937241570897226, 'validation/num_examples': 3554, 'test/ssim': 0.7367458434052988, 'test/loss': 0.29074131620226545, 'test/num_examples': 3581, 'score': 1898.0349142551422, 'total_duration': 2194.177098274231, 'accumulated_submission_time': 1898.0349142551422, 'accumulated_eval_time': 295.2284879684448, 'accumulated_logging_time': 0.6318953037261963, 'global_step': 7674, 'preemption_count': 0}), (8020, {'train/ssim': 0.744044576372419, 'train/loss': 0.26975313254765104, 'validation/ssim': 0.7217948883520329, 'validation/loss': 0.2882133659916643, 'validation/num_examples': 3554, 'test/ssim': 0.7389935597598436, 'test/loss': 0.28960542484422996, 'test/num_examples': 3581, 'score': 1978.0424547195435, 'total_duration': 2278.243096113205, 'accumulated_submission_time': 1978.0424547195435, 'accumulated_eval_time': 299.24297618865967, 'accumulated_logging_time': 0.6634461879730225, 'global_step': 8020, 'preemption_count': 0}), (8365, {'train/ssim': 0.7434047971452985, 'train/loss': 0.2699533700942993, 'validation/ssim': 0.7211110335625351, 'validation/loss': 0.2882835031830332, 'validation/num_examples': 3554, 'test/ssim': 0.7383492221315624, 'test/loss': 0.28965805722694427, 'test/num_examples': 3581, 'score': 2058.131326675415, 'total_duration': 2362.3873484134674, 'accumulated_submission_time': 2058.131326675415, 'accumulated_eval_time': 303.2593698501587, 'accumulated_logging_time': 0.6898679733276367, 'global_step': 8365, 'preemption_count': 0}), (8708, {'train/ssim': 0.7450571060180664, 'train/loss': 0.2695001704352243, 'validation/ssim': 0.7223065944622257, 'validation/loss': 0.28825949441870075, 'validation/num_examples': 3554, 'test/ssim': 0.7395078844945546, 'test/loss': 0.28965195541573585, 'test/num_examples': 3581, 'score': 2138.2803223133087, 'total_duration': 2446.592636823654, 'accumulated_submission_time': 2138.2803223133087, 'accumulated_eval_time': 307.27687430381775, 'accumulated_logging_time': 0.7161507606506348, 'global_step': 8708, 'preemption_count': 0}), (9053, {'train/ssim': 0.7446896008082798, 'train/loss': 0.26951772826058523, 'validation/ssim': 0.7220156041168402, 'validation/loss': 0.288230230517111, 'validation/num_examples': 3554, 'test/ssim': 0.7392402910979824, 'test/loss': 0.28965836402192124, 'test/num_examples': 3581, 'score': 2218.340068101883, 'total_duration': 2530.707357406616, 'accumulated_submission_time': 2218.340068101883, 'accumulated_eval_time': 311.29213285446167, 'accumulated_logging_time': 0.7432451248168945, 'global_step': 9053, 'preemption_count': 0}), (9398, {'train/ssim': 0.7459303992135184, 'train/loss': 0.26855312074933735, 'validation/ssim': 0.7233655904878307, 'validation/loss': 0.28725948988485683, 'validation/num_examples': 3554, 'test/ssim': 0.7406060741587546, 'test/loss': 0.28859511489676415, 'test/num_examples': 3581, 'score': 2298.3692531585693, 'total_duration': 2614.7996389865875, 'accumulated_submission_time': 2298.3692531585693, 'accumulated_eval_time': 315.3143537044525, 'accumulated_logging_time': 0.7714033126831055, 'global_step': 9398, 'preemption_count': 0}), (9740, {'train/ssim': 0.7458776746477399, 'train/loss': 0.2690248829977853, 'validation/ssim': 0.7237394265264491, 'validation/loss': 0.2874351591626512, 'validation/num_examples': 3554, 'test/ssim': 0.7407723570362678, 'test/loss': 0.28887729809890744, 'test/num_examples': 3581, 'score': 2378.3575394153595, 'total_duration': 2698.840270757675, 'accumulated_submission_time': 2378.3575394153595, 'accumulated_eval_time': 319.326447725296, 'accumulated_logging_time': 0.7993285655975342, 'global_step': 9740, 'preemption_count': 0}), (10084, {'train/ssim': 0.7447167805262974, 'train/loss': 0.2694817951747349, 'validation/ssim': 0.7220355255521947, 'validation/loss': 0.28815937203239306, 'validation/num_examples': 3554, 'test/ssim': 0.7392846741046495, 'test/loss': 0.28955061080834615, 'test/num_examples': 3581, 'score': 2458.3733851909637, 'total_duration': 2782.9115421772003, 'accumulated_submission_time': 2458.3733851909637, 'accumulated_eval_time': 323.3411955833435, 'accumulated_logging_time': 0.8272280693054199, 'global_step': 10084, 'preemption_count': 0}), (10429, {'train/ssim': 0.7417423384530204, 'train/loss': 0.2712743282318115, 'validation/ssim': 0.7195695953283272, 'validation/loss': 0.2896735385085467, 'validation/num_examples': 3554, 'test/ssim': 0.7367384803258518, 'test/loss': 0.2910769158187308, 'test/num_examples': 3581, 'score': 2538.4143187999725, 'total_duration': 2867.0138463974, 'accumulated_submission_time': 2538.4143187999725, 'accumulated_eval_time': 327.36353492736816, 'accumulated_logging_time': 0.8536674976348877, 'global_step': 10429, 'preemption_count': 0}), (10772, {'train/ssim': 0.7439629690987724, 'train/loss': 0.26972126960754395, 'validation/ssim': 0.7215402374525183, 'validation/loss': 0.2880775739318813, 'validation/num_examples': 3554, 'test/ssim': 0.7387032635349763, 'test/loss': 0.2895300555448897, 'test/num_examples': 3581, 'score': 2618.481980085373, 'total_duration': 2951.143794298172, 'accumulated_submission_time': 2618.481980085373, 'accumulated_eval_time': 331.38250207901, 'accumulated_logging_time': 0.8842437267303467, 'global_step': 10772, 'preemption_count': 0}), (11116, {'train/ssim': 0.7449778829302106, 'train/loss': 0.2687648705073765, 'validation/ssim': 0.7219717082644556, 'validation/loss': 0.28773325939962013, 'validation/num_examples': 3554, 'test/ssim': 0.7391950899713767, 'test/loss': 0.28910320146694357, 'test/num_examples': 3581, 'score': 2698.670265674591, 'total_duration': 3035.3925642967224, 'accumulated_submission_time': 2698.670265674591, 'accumulated_eval_time': 335.40252470970154, 'accumulated_logging_time': 0.9122757911682129, 'global_step': 11116, 'preemption_count': 0}), (11460, {'train/ssim': 0.7453946386064801, 'train/loss': 0.2682352236339024, 'validation/ssim': 0.7226209409731992, 'validation/loss': 0.2870142501461821, 'validation/num_examples': 3554, 'test/ssim': 0.7399028318948967, 'test/loss': 0.28836051900438076, 'test/num_examples': 3581, 'score': 2778.822010755539, 'total_duration': 3119.602737426758, 'accumulated_submission_time': 2778.822010755539, 'accumulated_eval_time': 339.4211540222168, 'accumulated_logging_time': 0.9393706321716309, 'global_step': 11460, 'preemption_count': 0}), (11804, {'train/ssim': 0.7457089424133301, 'train/loss': 0.2681718553815569, 'validation/ssim': 0.7230791339863534, 'validation/loss': 0.2868413629998769, 'validation/num_examples': 3554, 'test/ssim': 0.7403026880148702, 'test/loss': 0.2882328241173031, 'test/num_examples': 3581, 'score': 2858.9452958106995, 'total_duration': 3203.785383462906, 'accumulated_submission_time': 2858.9452958106995, 'accumulated_eval_time': 343.4411287307739, 'accumulated_logging_time': 0.9664688110351562, 'global_step': 11804, 'preemption_count': 0}), (12146, {'train/ssim': 0.7462355749947684, 'train/loss': 0.2677620989935739, 'validation/ssim': 0.7232231178777434, 'validation/loss': 0.2868784065654456, 'validation/num_examples': 3554, 'test/ssim': 0.7404194746361002, 'test/loss': 0.28824993645935143, 'test/num_examples': 3581, 'score': 2938.934836626053, 'total_duration': 3287.8370637893677, 'accumulated_submission_time': 2938.934836626053, 'accumulated_eval_time': 347.45862650871277, 'accumulated_logging_time': 0.9985432624816895, 'global_step': 12146, 'preemption_count': 0}), (12492, {'train/ssim': 0.7459902082170758, 'train/loss': 0.26780971458980013, 'validation/ssim': 0.7231852671505697, 'validation/loss': 0.28669284526457867, 'validation/num_examples': 3554, 'test/ssim': 0.7405588277323024, 'test/loss': 0.28797555948495535, 'test/num_examples': 3581, 'score': 3018.917544603348, 'total_duration': 3371.8902475833893, 'accumulated_submission_time': 3018.917544603348, 'accumulated_eval_time': 351.48676466941833, 'accumulated_logging_time': 1.028304100036621, 'global_step': 12492, 'preemption_count': 0}), (12834, {'train/ssim': 0.7463996069771903, 'train/loss': 0.2683678013937814, 'validation/ssim': 0.7237146964687676, 'validation/loss': 0.28724753702364414, 'validation/num_examples': 3554, 'test/ssim': 0.7409299814777646, 'test/loss': 0.2885652194306758, 'test/num_examples': 3581, 'score': 3098.9161932468414, 'total_duration': 3455.9489629268646, 'accumulated_submission_time': 3098.9161932468414, 'accumulated_eval_time': 355.50565004348755, 'accumulated_logging_time': 1.0569570064544678, 'global_step': 12834, 'preemption_count': 0}), (13177, {'train/ssim': 0.7463410241263253, 'train/loss': 0.2676967552730015, 'validation/ssim': 0.7232975828292065, 'validation/loss': 0.2867473029124314, 'validation/num_examples': 3554, 'test/ssim': 0.7405494193530089, 'test/loss': 0.28811678743935004, 'test/num_examples': 3581, 'score': 3178.969719648361, 'total_duration': 3540.0576510429382, 'accumulated_submission_time': 3178.969719648361, 'accumulated_eval_time': 359.51924538612366, 'accumulated_logging_time': 1.0859599113464355, 'global_step': 13177, 'preemption_count': 0}), (13522, {'train/ssim': 0.7465722220284599, 'train/loss': 0.2675368956157139, 'validation/ssim': 0.7237550202017093, 'validation/loss': 0.28640898198442777, 'validation/num_examples': 3554, 'test/ssim': 0.7410320419401005, 'test/loss': 0.2877505083251885, 'test/num_examples': 3581, 'score': 3258.9978489875793, 'total_duration': 3624.1457312107086, 'accumulated_submission_time': 3258.9978489875793, 'accumulated_eval_time': 363.53816270828247, 'accumulated_logging_time': 1.11417555809021, 'global_step': 13522, 'preemption_count': 0}), (13868, {'train/ssim': 0.7468410900660923, 'train/loss': 0.2678717374801636, 'validation/ssim': 0.7240890820642234, 'validation/loss': 0.2867557008278524, 'validation/num_examples': 3554, 'test/ssim': 0.7413182475652751, 'test/loss': 0.28803766842362466, 'test/num_examples': 3581, 'score': 3339.0577857494354, 'total_duration': 3708.263298511505, 'accumulated_submission_time': 3339.0577857494354, 'accumulated_eval_time': 367.55552864074707, 'accumulated_logging_time': 1.1418681144714355, 'global_step': 13868, 'preemption_count': 0}), (14211, {'train/ssim': 0.7465951783316476, 'train/loss': 0.26786759921482634, 'validation/ssim': 0.723388877958814, 'validation/loss': 0.28721214212858753, 'validation/num_examples': 3554, 'test/ssim': 0.7405325115409452, 'test/loss': 0.2886754610923974, 'test/num_examples': 3581, 'score': 3419.144530057907, 'total_duration': 3792.405335187912, 'accumulated_submission_time': 3419.144530057907, 'accumulated_eval_time': 371.56961011886597, 'accumulated_logging_time': 1.1705811023712158, 'global_step': 14211, 'preemption_count': 0}), (14559, {'train/ssim': 0.7471063477652413, 'train/loss': 0.2675107717514038, 'validation/ssim': 0.7242466674873382, 'validation/loss': 0.2865292147162528, 'validation/num_examples': 3554, 'test/ssim': 0.7414607367879084, 'test/loss': 0.28782291193975146, 'test/num_examples': 3581, 'score': 3499.2701807022095, 'total_duration': 3876.59183716774, 'accumulated_submission_time': 3499.2701807022095, 'accumulated_eval_time': 375.59007000923157, 'accumulated_logging_time': 1.198145866394043, 'global_step': 14559, 'preemption_count': 0}), (14905, {'train/ssim': 0.7477654048374721, 'train/loss': 0.2676566668919155, 'validation/ssim': 0.7249977742948087, 'validation/loss': 0.2865739349038935, 'validation/num_examples': 3554, 'test/ssim': 0.742121709521607, 'test/loss': 0.2879113711581088, 'test/num_examples': 3581, 'score': 3579.3831877708435, 'total_duration': 3960.7610342502594, 'accumulated_submission_time': 3579.3831877708435, 'accumulated_eval_time': 379.60575890541077, 'accumulated_logging_time': 1.2259979248046875, 'global_step': 14905, 'preemption_count': 0}), (15248, {'train/ssim': 0.7476011684962681, 'train/loss': 0.2673081500189645, 'validation/ssim': 0.7246028490125562, 'validation/loss': 0.28648566233689154, 'validation/num_examples': 3554, 'test/ssim': 0.7418195505576306, 'test/loss': 0.2878147989170274, 'test/num_examples': 3581, 'score': 3659.4731526374817, 'total_duration': 4044.9105067253113, 'accumulated_submission_time': 3659.4731526374817, 'accumulated_eval_time': 383.6252100467682, 'accumulated_logging_time': 1.2533009052276611, 'global_step': 15248, 'preemption_count': 0}), (15592, {'train/ssim': 0.7472316878182548, 'train/loss': 0.26755171162741526, 'validation/ssim': 0.7243855679779826, 'validation/loss': 0.28649069421668366, 'validation/num_examples': 3554, 'test/ssim': 0.741601521594003, 'test/loss': 0.28786576097153377, 'test/num_examples': 3581, 'score': 3739.480894804001, 'total_duration': 4128.976114034653, 'accumulated_submission_time': 3739.480894804001, 'accumulated_eval_time': 387.6414725780487, 'accumulated_logging_time': 1.2822730541229248, 'global_step': 15592, 'preemption_count': 0}), (15936, {'train/ssim': 0.7483240536281041, 'train/loss': 0.2673044204711914, 'validation/ssim': 0.7253718164172411, 'validation/loss': 0.2863633515932752, 'validation/num_examples': 3554, 'test/ssim': 0.7426279894102555, 'test/loss': 0.28762550641624196, 'test/num_examples': 3581, 'score': 3819.596107006073, 'total_duration': 4213.149703264236, 'accumulated_submission_time': 3819.596107006073, 'accumulated_eval_time': 391.657977104187, 'accumulated_logging_time': 1.3116509914398193, 'global_step': 15936, 'preemption_count': 0}), (16279, {'train/ssim': 0.7473345484052386, 'train/loss': 0.2675484078271048, 'validation/ssim': 0.7243296505697805, 'validation/loss': 0.2866905955162757, 'validation/num_examples': 3554, 'test/ssim': 0.7415096876308992, 'test/loss': 0.28810379978532535, 'test/num_examples': 3581, 'score': 3899.568253993988, 'total_duration': 4297.175599813461, 'accumulated_submission_time': 3899.568253993988, 'accumulated_eval_time': 395.67021560668945, 'accumulated_logging_time': 1.340677261352539, 'global_step': 16279, 'preemption_count': 0}), (16625, {'train/ssim': 0.7466865948268345, 'train/loss': 0.26763645240238737, 'validation/ssim': 0.7237747355532499, 'validation/loss': 0.28666423396173324, 'validation/num_examples': 3554, 'test/ssim': 0.7408988929200991, 'test/loss': 0.288077960830599, 'test/num_examples': 3581, 'score': 3979.7582840919495, 'total_duration': 4381.423604011536, 'accumulated_submission_time': 3979.7582840919495, 'accumulated_eval_time': 399.6851809024811, 'accumulated_logging_time': 1.3709535598754883, 'global_step': 16625, 'preemption_count': 0}), (16969, {'train/ssim': 0.7481282779148647, 'train/loss': 0.26680430344172884, 'validation/ssim': 0.7251985686242614, 'validation/loss': 0.2858984608561656, 'validation/num_examples': 3554, 'test/ssim': 0.7424319815083077, 'test/loss': 0.2871888348990331, 'test/num_examples': 3581, 'score': 4059.7816610336304, 'total_duration': 4465.504558324814, 'accumulated_submission_time': 4059.7816610336304, 'accumulated_eval_time': 403.7024691104889, 'accumulated_logging_time': 1.3988149166107178, 'global_step': 16969, 'preemption_count': 0}), (17310, {'train/ssim': 0.7480014392307827, 'train/loss': 0.2669447490147182, 'validation/ssim': 0.7251391477912211, 'validation/loss': 0.2859115471783554, 'validation/num_examples': 3554, 'test/ssim': 0.7423032639713069, 'test/loss': 0.28726846523972005, 'test/num_examples': 3581, 'score': 4139.849115371704, 'total_duration': 4549.632168054581, 'accumulated_submission_time': 4139.849115371704, 'accumulated_eval_time': 407.72118186950684, 'accumulated_logging_time': 1.4279568195343018, 'global_step': 17310, 'preemption_count': 0}), (17656, {'train/ssim': 0.7473434720720563, 'train/loss': 0.2665583406175886, 'validation/ssim': 0.7239926348392656, 'validation/loss': 0.2859433184330156, 'validation/num_examples': 3554, 'test/ssim': 0.7412486391938355, 'test/loss': 0.28727313534103605, 'test/num_examples': 3581, 'score': 4219.889711856842, 'total_duration': 4633.732095003128, 'accumulated_submission_time': 4219.889711856842, 'accumulated_eval_time': 411.73948407173157, 'accumulated_logging_time': 1.4562327861785889, 'global_step': 17656, 'preemption_count': 0}), (18003, {'train/ssim': 0.7483083861214774, 'train/loss': 0.2665321145738874, 'validation/ssim': 0.7252950158492192, 'validation/loss': 0.2856605886138418, 'validation/num_examples': 3554, 'test/ssim': 0.7424689332588662, 'test/loss': 0.28695945452125804, 'test/num_examples': 3581, 'score': 4300.033041477203, 'total_duration': 4717.930500507355, 'accumulated_submission_time': 4300.033041477203, 'accumulated_eval_time': 415.75352668762207, 'accumulated_logging_time': 1.4845950603485107, 'global_step': 18003, 'preemption_count': 0}), (18345, {'train/ssim': 0.7470991952078683, 'train/loss': 0.26688592774527414, 'validation/ssim': 0.7242033898863957, 'validation/loss': 0.285921439201428, 'validation/num_examples': 3554, 'test/ssim': 0.7414670090407708, 'test/loss': 0.28718528971263263, 'test/num_examples': 3581, 'score': 4380.129502534866, 'total_duration': 4802.0883066654205, 'accumulated_submission_time': 4380.129502534866, 'accumulated_eval_time': 419.7735161781311, 'accumulated_logging_time': 1.5131938457489014, 'global_step': 18345, 'preemption_count': 0}), (18691, {'train/ssim': 0.7492048399788993, 'train/loss': 0.2664386204310826, 'validation/ssim': 0.7258765843723621, 'validation/loss': 0.2859228817881261, 'validation/num_examples': 3554, 'test/ssim': 0.743057638731325, 'test/loss': 0.28718869854571, 'test/num_examples': 3581, 'score': 4460.136431455612, 'total_duration': 4886.153877258301, 'accumulated_submission_time': 4460.136431455612, 'accumulated_eval_time': 423.7905547618866, 'accumulated_logging_time': 1.542210578918457, 'global_step': 18691, 'preemption_count': 0}), (19038, {'train/ssim': 0.7488509586879185, 'train/loss': 0.266427789415632, 'validation/ssim': 0.7257310891996693, 'validation/loss': 0.28569581177238673, 'validation/num_examples': 3554, 'test/ssim': 0.7429034912995671, 'test/loss': 0.28701924545343477, 'test/num_examples': 3581, 'score': 4540.380712032318, 'total_duration': 4970.458175897598, 'accumulated_submission_time': 4540.380712032318, 'accumulated_eval_time': 427.80764269828796, 'accumulated_logging_time': 1.5725533962249756, 'global_step': 19038, 'preemption_count': 0}), (19384, {'train/ssim': 0.7485593387058803, 'train/loss': 0.2664816209248134, 'validation/ssim': 0.7254547994996835, 'validation/loss': 0.28563797091525395, 'validation/num_examples': 3554, 'test/ssim': 0.7426361024329796, 'test/loss': 0.28693194523832377, 'test/num_examples': 3581, 'score': 4620.512376785278, 'total_duration': 5054.651271343231, 'accumulated_submission_time': 4620.512376785278, 'accumulated_eval_time': 431.82620668411255, 'accumulated_logging_time': 1.60274076461792, 'global_step': 19384, 'preemption_count': 0}), (19728, {'train/ssim': 0.7484092712402344, 'train/loss': 0.2663026877811977, 'validation/ssim': 0.7250737505275746, 'validation/loss': 0.2859123371663091, 'validation/num_examples': 3554, 'test/ssim': 0.742244086629084, 'test/loss': 0.28714332697745043, 'test/num_examples': 3581, 'score': 4700.570680141449, 'total_duration': 5138.771405696869, 'accumulated_submission_time': 4700.570680141449, 'accumulated_eval_time': 435.8466863632202, 'accumulated_logging_time': 1.6315891742706299, 'global_step': 19728, 'preemption_count': 0}), (20072, {'train/ssim': 0.7486628804888044, 'train/loss': 0.2662466253553118, 'validation/ssim': 0.7255211584877954, 'validation/loss': 0.2855280252004783, 'validation/num_examples': 3554, 'test/ssim': 0.7426688954071837, 'test/loss': 0.28686107559864565, 'test/num_examples': 3581, 'score': 4780.684697151184, 'total_duration': 5222.948258399963, 'accumulated_submission_time': 4780.684697151184, 'accumulated_eval_time': 439.86440348625183, 'accumulated_logging_time': 1.6642556190490723, 'global_step': 20072, 'preemption_count': 0}), (20417, {'train/ssim': 0.7478485788617816, 'train/loss': 0.2665714366095407, 'validation/ssim': 0.7244868238252673, 'validation/loss': 0.2859325677273846, 'validation/num_examples': 3554, 'test/ssim': 0.7418312769434167, 'test/loss': 0.28714189526755796, 'test/num_examples': 3581, 'score': 4860.731207847595, 'total_duration': 5307.05890750885, 'accumulated_submission_time': 4860.731207847595, 'accumulated_eval_time': 443.8861367702484, 'accumulated_logging_time': 1.6940970420837402, 'global_step': 20417, 'preemption_count': 0}), (20761, {'train/ssim': 0.7485369273594448, 'train/loss': 0.26598404135022846, 'validation/ssim': 0.724897548866594, 'validation/loss': 0.2856829830549645, 'validation/num_examples': 3554, 'test/ssim': 0.7421095058991902, 'test/loss': 0.28697489653509844, 'test/num_examples': 3581, 'score': 4940.794360637665, 'total_duration': 5391.183601856232, 'accumulated_submission_time': 4940.794360637665, 'accumulated_eval_time': 447.90532636642456, 'accumulated_logging_time': 1.7241308689117432, 'global_step': 20761, 'preemption_count': 0}), (21107, {'train/ssim': 0.7491487775530133, 'train/loss': 0.2664053269795009, 'validation/ssim': 0.7259544153594542, 'validation/loss': 0.285788927309018, 'validation/num_examples': 3554, 'test/ssim': 0.7430941132452528, 'test/loss': 0.2870494818028309, 'test/num_examples': 3581, 'score': 5020.885152101517, 'total_duration': 5475.335332632065, 'accumulated_submission_time': 5020.885152101517, 'accumulated_eval_time': 451.92284989356995, 'accumulated_logging_time': 1.7548644542694092, 'global_step': 21107, 'preemption_count': 0}), (21449, {'train/ssim': 0.7486867223467145, 'train/loss': 0.2660897970199585, 'validation/ssim': 0.7254420223032146, 'validation/loss': 0.2854990189036561, 'validation/num_examples': 3554, 'test/ssim': 0.7426107407148841, 'test/loss': 0.28676784401398003, 'test/num_examples': 3581, 'score': 5100.921221733093, 'total_duration': 5559.43258523941, 'accumulated_submission_time': 5100.921221733093, 'accumulated_eval_time': 455.94290256500244, 'accumulated_logging_time': 1.7836058139801025, 'global_step': 21449, 'preemption_count': 0}), (21791, {'train/ssim': 0.7492446218218122, 'train/loss': 0.2659718820026943, 'validation/ssim': 0.7256659667144415, 'validation/loss': 0.2857284245359542, 'validation/num_examples': 3554, 'test/ssim': 0.7427518664042865, 'test/loss': 0.2870056101211254, 'test/num_examples': 3581, 'score': 5181.017259836197, 'total_duration': 5643.584321975708, 'accumulated_submission_time': 5181.017259836197, 'accumulated_eval_time': 459.95671033859253, 'accumulated_logging_time': 1.8128316402435303, 'global_step': 21791, 'preemption_count': 0}), (22138, {'train/ssim': 0.748035022190639, 'train/loss': 0.2667830841881888, 'validation/ssim': 0.7249676173633582, 'validation/loss': 0.28607260167900606, 'validation/num_examples': 3554, 'test/ssim': 0.7421120284356674, 'test/loss': 0.28734789105042235, 'test/num_examples': 3581, 'score': 5261.106295824051, 'total_duration': 5727.733413934708, 'accumulated_submission_time': 5261.106295824051, 'accumulated_eval_time': 463.9753234386444, 'accumulated_logging_time': 1.8418028354644775, 'global_step': 22138, 'preemption_count': 0}), (22483, {'train/ssim': 0.7493149893624442, 'train/loss': 0.2660031999860491, 'validation/ssim': 0.7261346700021103, 'validation/loss': 0.2854326255682418, 'validation/num_examples': 3554, 'test/ssim': 0.7432496923869031, 'test/loss': 0.286731574030037, 'test/num_examples': 3581, 'score': 5341.142727136612, 'total_duration': 5811.8311512470245, 'accumulated_submission_time': 5341.142727136612, 'accumulated_eval_time': 467.9927349090576, 'accumulated_logging_time': 1.8729948997497559, 'global_step': 22483, 'preemption_count': 0}), (22826, {'train/ssim': 0.7495972088405064, 'train/loss': 0.26590023721967426, 'validation/ssim': 0.7261499202043472, 'validation/loss': 0.2854917201019098, 'validation/num_examples': 3554, 'test/ssim': 0.7432502378001955, 'test/loss': 0.2868267486495567, 'test/num_examples': 3581, 'score': 5421.144332408905, 'total_duration': 5895.894639015198, 'accumulated_submission_time': 5421.144332408905, 'accumulated_eval_time': 472.01139187812805, 'accumulated_logging_time': 1.9036543369293213, 'global_step': 22826, 'preemption_count': 0}), (23169, {'train/ssim': 0.7486049788338798, 'train/loss': 0.2657872268131801, 'validation/ssim': 0.7252260464661298, 'validation/loss': 0.2853719510586663, 'validation/num_examples': 3554, 'test/ssim': 0.742398370414165, 'test/loss': 0.2866561024657044, 'test/num_examples': 3581, 'score': 5501.226588726044, 'total_duration': 5980.0396893024445, 'accumulated_submission_time': 5501.226588726044, 'accumulated_eval_time': 476.02953267097473, 'accumulated_logging_time': 1.9357259273529053, 'global_step': 23169, 'preemption_count': 0}), (23514, {'train/ssim': 0.7499886240277972, 'train/loss': 0.265853796686445, 'validation/ssim': 0.7267512727736354, 'validation/loss': 0.2853215979134426, 'validation/num_examples': 3554, 'test/ssim': 0.7437929922027716, 'test/loss': 0.2866178894469073, 'test/num_examples': 3581, 'score': 5581.201484680176, 'total_duration': 6064.078918218613, 'accumulated_submission_time': 5581.201484680176, 'accumulated_eval_time': 480.0495846271515, 'accumulated_logging_time': 1.9672400951385498, 'global_step': 23514, 'preemption_count': 0}), (23856, {'train/ssim': 0.7493819509233747, 'train/loss': 0.26600572041102816, 'validation/ssim': 0.7261044443760551, 'validation/loss': 0.2854621299009479, 'validation/num_examples': 3554, 'test/ssim': 0.7432202400691148, 'test/loss': 0.2868497923611596, 'test/num_examples': 3581, 'score': 5661.339335203171, 'total_duration': 6148.279658317566, 'accumulated_submission_time': 5661.339335203171, 'accumulated_eval_time': 484.0690758228302, 'accumulated_logging_time': 1.9982903003692627, 'global_step': 23856, 'preemption_count': 0}), (24199, {'train/ssim': 0.7496466636657715, 'train/loss': 0.26554931913103375, 'validation/ssim': 0.7258055541511326, 'validation/loss': 0.2854341025022422, 'validation/num_examples': 3554, 'test/ssim': 0.7429892575397934, 'test/loss': 0.28676791219064157, 'test/num_examples': 3581, 'score': 5741.316986083984, 'total_duration': 6232.325395584106, 'accumulated_submission_time': 5741.316986083984, 'accumulated_eval_time': 488.0896954536438, 'accumulated_logging_time': 2.0329601764678955, 'global_step': 24199, 'preemption_count': 0}), (24545, {'train/ssim': 0.7499784060886928, 'train/loss': 0.26558062008449007, 'validation/ssim': 0.7264893402460256, 'validation/loss': 0.28520514338487446, 'validation/num_examples': 3554, 'test/ssim': 0.7436160055893954, 'test/loss': 0.28648971732319883, 'test/num_examples': 3581, 'score': 5821.357635498047, 'total_duration': 6316.430392026901, 'accumulated_submission_time': 5821.357635498047, 'accumulated_eval_time': 492.1099181175232, 'accumulated_logging_time': 2.064488172531128, 'global_step': 24545, 'preemption_count': 0}), (24889, {'train/ssim': 0.7498251370021275, 'train/loss': 0.26585865020751953, 'validation/ssim': 0.7265470437139491, 'validation/loss': 0.2853666100531531, 'validation/num_examples': 3554, 'test/ssim': 0.743647980443661, 'test/loss': 0.28666909011972913, 'test/num_examples': 3581, 'score': 5901.505459070206, 'total_duration': 6400.642231225967, 'accumulated_submission_time': 5901.505459070206, 'accumulated_eval_time': 496.126501083374, 'accumulated_logging_time': 2.0994303226470947, 'global_step': 24889, 'preemption_count': 0}), (25235, {'train/ssim': 0.7498918942042759, 'train/loss': 0.26507547923496794, 'validation/ssim': 0.7259708333699705, 'validation/loss': 0.2850697291454171, 'validation/num_examples': 3554, 'test/ssim': 0.7431427232049358, 'test/loss': 0.28636771518736037, 'test/num_examples': 3581, 'score': 5981.699506759644, 'total_duration': 6484.898949146271, 'accumulated_submission_time': 5981.699506759644, 'accumulated_eval_time': 500.1464011669159, 'accumulated_logging_time': 2.1296558380126953, 'global_step': 25235, 'preemption_count': 0}), (25580, {'train/ssim': 0.7498783384050641, 'train/loss': 0.2653120585850307, 'validation/ssim': 0.726230086807998, 'validation/loss': 0.2851230018113393, 'validation/num_examples': 3554, 'test/ssim': 0.7433790916905194, 'test/loss': 0.28637095357878384, 'test/num_examples': 3581, 'score': 6061.817725658417, 'total_duration': 6569.079738616943, 'accumulated_submission_time': 6061.817725658417, 'accumulated_eval_time': 504.1658718585968, 'accumulated_logging_time': 2.16015625, 'global_step': 25580, 'preemption_count': 0}), (25925, {'train/ssim': 0.7497959818158831, 'train/loss': 0.26541459560394287, 'validation/ssim': 0.72636321695185, 'validation/loss': 0.28510725357321853, 'validation/num_examples': 3554, 'test/ssim': 0.7434775387897934, 'test/loss': 0.2863817254913083, 'test/num_examples': 3581, 'score': 6141.91224861145, 'total_duration': 6653.2393543720245, 'accumulated_submission_time': 6141.91224861145, 'accumulated_eval_time': 508.18673872947693, 'accumulated_logging_time': 2.1918129920959473, 'global_step': 25925, 'preemption_count': 0}), (26268, {'train/ssim': 0.7502094677516392, 'train/loss': 0.26494574546813965, 'validation/ssim': 0.7263461806898917, 'validation/loss': 0.28503902265712927, 'validation/num_examples': 3554, 'test/ssim': 0.7434729027768081, 'test/loss': 0.28635292085180464, 'test/num_examples': 3581, 'score': 6221.960324764252, 'total_duration': 6737.352556943893, 'accumulated_submission_time': 6221.960324764252, 'accumulated_eval_time': 512.2066950798035, 'accumulated_logging_time': 2.224546432495117, 'global_step': 26268, 'preemption_count': 0}), (26613, {'train/ssim': 0.7500839233398438, 'train/loss': 0.26523120062691824, 'validation/ssim': 0.7263961216674873, 'validation/loss': 0.2850700726184405, 'validation/num_examples': 3554, 'test/ssim': 0.7435960298275621, 'test/loss': 0.28635268223348925, 'test/num_examples': 3581, 'score': 6301.933490514755, 'total_duration': 6821.390177488327, 'accumulated_submission_time': 6301.933490514755, 'accumulated_eval_time': 516.2275338172913, 'accumulated_logging_time': 2.2554852962493896, 'global_step': 26613, 'preemption_count': 0}), (26958, {'train/ssim': 0.7498068809509277, 'train/loss': 0.26525681359427317, 'validation/ssim': 0.7262263086047411, 'validation/loss': 0.28504298977054904, 'validation/num_examples': 3554, 'test/ssim': 0.7434109301914619, 'test/loss': 0.28628532369188076, 'test/num_examples': 3581, 'score': 6382.069779396057, 'total_duration': 6905.588939666748, 'accumulated_submission_time': 6382.069779396057, 'accumulated_eval_time': 520.2461042404175, 'accumulated_logging_time': 2.287006378173828, 'global_step': 26958, 'preemption_count': 0}), (27301, {'train/ssim': 0.7503508159092495, 'train/loss': 0.26479027952466694, 'validation/ssim': 0.7261952586434299, 'validation/loss': 0.28503661834596583, 'validation/num_examples': 3554, 'test/ssim': 0.7433469804829308, 'test/loss': 0.2863510459936121, 'test/num_examples': 3581, 'score': 6462.058999300003, 'total_duration': 6989.5824983119965, 'accumulated_submission_time': 6462.058999300003, 'accumulated_eval_time': 524.2069962024689, 'accumulated_logging_time': 2.317927598953247, 'global_step': 27301, 'preemption_count': 0}), (27646, {'train/ssim': 0.7499651908874512, 'train/loss': 0.26499886172158377, 'validation/ssim': 0.7260563581527856, 'validation/loss': 0.2849680439568532, 'validation/num_examples': 3554, 'test/ssim': 0.743229239388439, 'test/loss': 0.28623681599719003, 'test/num_examples': 3581, 'score': 6542.14812707901, 'total_duration': 7073.7304475307465, 'accumulated_submission_time': 6542.14812707901, 'accumulated_eval_time': 528.22221159935, 'accumulated_logging_time': 2.3489346504211426, 'global_step': 27646, 'preemption_count': 0}), (27989, {'train/ssim': 0.7497949600219727, 'train/loss': 0.2651307923453195, 'validation/ssim': 0.726063158918648, 'validation/loss': 0.28501516845565733, 'validation/num_examples': 3554, 'test/ssim': 0.7432007415439124, 'test/loss': 0.2863091855234222, 'test/num_examples': 3581, 'score': 6622.342363357544, 'total_duration': 7157.983325958252, 'accumulated_submission_time': 6622.342363357544, 'accumulated_eval_time': 532.2352705001831, 'accumulated_logging_time': 2.3820061683654785, 'global_step': 27989, 'preemption_count': 0}), (28333, {'train/ssim': 0.75055878502982, 'train/loss': 0.2647071395601545, 'validation/ssim': 0.7264404983821047, 'validation/loss': 0.28501199133019134, 'validation/num_examples': 3554, 'test/ssim': 0.7435149677769827, 'test/loss': 0.28632087782087756, 'test/num_examples': 3581, 'score': 6702.4536962509155, 'total_duration': 7242.156578779221, 'accumulated_submission_time': 6702.4536962509155, 'accumulated_eval_time': 536.2536578178406, 'accumulated_logging_time': 2.413137912750244, 'global_step': 28333, 'preemption_count': 0}), (28677, {'train/ssim': 0.7505395071847099, 'train/loss': 0.26479266371045795, 'validation/ssim': 0.7266726174512873, 'validation/loss': 0.2848629755590092, 'validation/num_examples': 3554, 'test/ssim': 0.7437867199499092, 'test/loss': 0.28617555926679, 'test/num_examples': 3581, 'score': 6782.451961994171, 'total_duration': 7326.216543912888, 'accumulated_submission_time': 6782.451961994171, 'accumulated_eval_time': 540.2722911834717, 'accumulated_logging_time': 2.4437241554260254, 'global_step': 28677, 'preemption_count': 0}), (29023, {'train/ssim': 0.7501329013279506, 'train/loss': 0.26496262209756033, 'validation/ssim': 0.7262491839080966, 'validation/loss': 0.2849998839061181, 'validation/num_examples': 3554, 'test/ssim': 0.7433983175090757, 'test/loss': 0.2862706316213174, 'test/num_examples': 3581, 'score': 6862.631316900253, 'total_duration': 7410.462491750717, 'accumulated_submission_time': 6862.631316900253, 'accumulated_eval_time': 544.2934327125549, 'accumulated_logging_time': 2.476641893386841, 'global_step': 29023, 'preemption_count': 0}), (29366, {'train/ssim': 0.7502886227199009, 'train/loss': 0.26472565105983187, 'validation/ssim': 0.7261591939759777, 'validation/loss': 0.285006427067213, 'validation/num_examples': 3554, 'test/ssim': 0.7433084606691567, 'test/loss': 0.2862858691051731, 'test/num_examples': 3581, 'score': 6942.597845315933, 'total_duration': 7494.490667819977, 'accumulated_submission_time': 6942.597845315933, 'accumulated_eval_time': 548.3099186420441, 'accumulated_logging_time': 2.50946044921875, 'global_step': 29366, 'preemption_count': 0}), (29711, {'train/ssim': 0.7505989074707031, 'train/loss': 0.26468569891793386, 'validation/ssim': 0.7264604198174592, 'validation/loss': 0.28494558082112587, 'validation/num_examples': 3554, 'test/ssim': 0.7435891439847458, 'test/loss': 0.2862731200694638, 'test/num_examples': 3581, 'score': 7022.6484632492065, 'total_duration': 7578.602977514267, 'accumulated_submission_time': 7022.6484632492065, 'accumulated_eval_time': 552.3254547119141, 'accumulated_logging_time': 2.542933702468872, 'global_step': 29711, 'preemption_count': 0}), (30056, {'train/ssim': 0.7506581715175084, 'train/loss': 0.2647981473377773, 'validation/ssim': 0.7267338930386537, 'validation/loss': 0.28490774726760343, 'validation/num_examples': 3554, 'test/ssim': 0.7438693500637042, 'test/loss': 0.2861787635698827, 'test/num_examples': 3581, 'score': 7102.741122245789, 'total_duration': 7662.754905939102, 'accumulated_submission_time': 7102.741122245789, 'accumulated_eval_time': 556.3397581577301, 'accumulated_logging_time': 2.5753839015960693, 'global_step': 30056, 'preemption_count': 0}), (30397, {'train/ssim': 0.7500651904514858, 'train/loss': 0.2648999180112566, 'validation/ssim': 0.7260751804744654, 'validation/loss': 0.28502863259817285, 'validation/num_examples': 3554, 'test/ssim': 0.7432389204743787, 'test/loss': 0.28634780760218864, 'test/num_examples': 3581, 'score': 7182.78594827652, 'total_duration': 7746.8605670928955, 'accumulated_submission_time': 7182.78594827652, 'accumulated_eval_time': 560.3569049835205, 'accumulated_logging_time': 2.6066181659698486, 'global_step': 30397, 'preemption_count': 0}), (30744, {'train/ssim': 0.750626632145473, 'train/loss': 0.2645703213555472, 'validation/ssim': 0.7264586337577378, 'validation/loss': 0.28491935665579277, 'validation/num_examples': 3554, 'test/ssim': 0.7435880531581611, 'test/loss': 0.28622454419811155, 'test/num_examples': 3581, 'score': 7262.975407361984, 'total_duration': 7831.111491441727, 'accumulated_submission_time': 7262.975407361984, 'accumulated_eval_time': 564.373776435852, 'accumulated_logging_time': 2.638613700866699, 'global_step': 30744, 'preemption_count': 0}), (31088, {'train/ssim': 0.7506256103515625, 'train/loss': 0.2646536486489432, 'validation/ssim': 0.7265625686946047, 'validation/loss': 0.284842779345236, 'validation/num_examples': 3554, 'test/ssim': 0.7437144526886693, 'test/loss': 0.28614382303083985, 'test/num_examples': 3581, 'score': 7342.940884590149, 'total_duration': 7915.147254228592, 'accumulated_submission_time': 7342.940884590149, 'accumulated_eval_time': 568.3998596668243, 'accumulated_logging_time': 2.67030930519104, 'global_step': 31088, 'preemption_count': 0}), (31433, {'train/ssim': 0.7506649153573173, 'train/loss': 0.26468786171504427, 'validation/ssim': 0.7265348847689224, 'validation/loss': 0.28496610333427125, 'validation/num_examples': 3554, 'test/ssim': 0.743663320192509, 'test/loss': 0.2862593824721621, 'test/num_examples': 3581, 'score': 7423.0860686302185, 'total_duration': 7999.357291936874, 'accumulated_submission_time': 7423.0860686302185, 'accumulated_eval_time': 572.4185557365417, 'accumulated_logging_time': 2.7039809226989746, 'global_step': 31433, 'preemption_count': 0}), (31779, {'train/ssim': 0.7508582387651715, 'train/loss': 0.264353837285723, 'validation/ssim': 0.7265188102314294, 'validation/loss': 0.28483960221977, 'validation/num_examples': 3554, 'test/ssim': 0.7436525482799846, 'test/loss': 0.28615858327806476, 'test/num_examples': 3581, 'score': 7503.2064254283905, 'total_duration': 8083.542644500732, 'accumulated_submission_time': 7503.2064254283905, 'accumulated_eval_time': 576.4384963512421, 'accumulated_logging_time': 2.7362942695617676, 'global_step': 31779, 'preemption_count': 0}), (32124, {'train/ssim': 0.7506969315665108, 'train/loss': 0.26444237572806223, 'validation/ssim': 0.7265397620858539, 'validation/loss': 0.28476238948412, 'validation/num_examples': 3554, 'test/ssim': 0.743674023928372, 'test/loss': 0.28606848781983035, 'test/num_examples': 3581, 'score': 7583.260835409164, 'total_duration': 8167.663266420364, 'accumulated_submission_time': 7583.260835409164, 'accumulated_eval_time': 580.4590227603912, 'accumulated_logging_time': 2.7696642875671387, 'global_step': 32124, 'preemption_count': 0}), (32467, {'train/ssim': 0.7506919588361468, 'train/loss': 0.26448231084006174, 'validation/ssim': 0.7265296639789673, 'validation/loss': 0.2847786872790781, 'validation/num_examples': 3554, 'test/ssim': 0.7436811824778344, 'test/loss': 0.2860721693595539, 'test/num_examples': 3581, 'score': 7663.235911130905, 'total_duration': 8251.700382471085, 'accumulated_submission_time': 7663.235911130905, 'accumulated_eval_time': 584.4764456748962, 'accumulated_logging_time': 2.801800489425659, 'global_step': 32467, 'preemption_count': 0}), (32810, {'train/ssim': 0.7511326926095145, 'train/loss': 0.26420453616550993, 'validation/ssim': 0.7267132846572524, 'validation/loss': 0.2847665283340514, 'validation/num_examples': 3554, 'test/ssim': 0.7438340345530229, 'test/loss': 0.28608474795360933, 'test/num_examples': 3581, 'score': 7743.370946645737, 'total_duration': 8335.898382425308, 'accumulated_submission_time': 7743.370946645737, 'accumulated_eval_time': 588.4945957660675, 'accumulated_logging_time': 2.8336546421051025, 'global_step': 32810, 'preemption_count': 0}), (33155, {'train/ssim': 0.750725269317627, 'train/loss': 0.2643196071897234, 'validation/ssim': 0.7264477800101998, 'validation/loss': 0.28475035075465144, 'validation/num_examples': 3554, 'test/ssim': 0.7435964388875315, 'test/loss': 0.28605205724439753, 'test/num_examples': 3581, 'score': 7823.340132236481, 'total_duration': 8419.934628725052, 'accumulated_submission_time': 7823.340132236481, 'accumulated_eval_time': 592.5159690380096, 'accumulated_logging_time': 2.867058038711548, 'global_step': 33155, 'preemption_count': 0}), (33500, {'train/ssim': 0.7509395054408482, 'train/loss': 0.2643869774682181, 'validation/ssim': 0.7267172002497186, 'validation/loss': 0.2847576495563977, 'validation/num_examples': 3554, 'test/ssim': 0.7438440565222704, 'test/loss': 0.2860510005061435, 'test/num_examples': 3581, 'score': 7903.3904502391815, 'total_duration': 8504.049171447754, 'accumulated_submission_time': 7903.3904502391815, 'accumulated_eval_time': 596.5357365608215, 'accumulated_logging_time': 2.8989980220794678, 'global_step': 33500, 'preemption_count': 0}), (33844, {'train/ssim': 0.7513058526175362, 'train/loss': 0.2641360419137137, 'validation/ssim': 0.7268690840206458, 'validation/loss': 0.2847431893421145, 'validation/num_examples': 3554, 'test/ssim': 0.7439712741727171, 'test/loss': 0.2860495006195895, 'test/num_examples': 3581, 'score': 7983.478590726852, 'total_duration': 8588.198611021042, 'accumulated_submission_time': 7983.478590726852, 'accumulated_eval_time': 600.5509705543518, 'accumulated_logging_time': 2.932687520980835, 'global_step': 33844, 'preemption_count': 0}), (34190, {'train/ssim': 0.7509686606270927, 'train/loss': 0.2641798939023699, 'validation/ssim': 0.7265910082609384, 'validation/loss': 0.2846628166546497, 'validation/num_examples': 3554, 'test/ssim': 0.7437399507600879, 'test/loss': 0.2859617913445092, 'test/num_examples': 3581, 'score': 8063.584829330444, 'total_duration': 8672.370778083801, 'accumulated_submission_time': 8063.584829330444, 'accumulated_eval_time': 604.5714876651764, 'accumulated_logging_time': 2.965465784072876, 'global_step': 34190, 'preemption_count': 0}), (34534, {'train/ssim': 0.7508820125034877, 'train/loss': 0.2642404351915632, 'validation/ssim': 0.726557279210045, 'validation/loss': 0.28470202410026557, 'validation/num_examples': 3554, 'test/ssim': 0.7436853412541887, 'test/loss': 0.28599434570039795, 'test/num_examples': 3581, 'score': 8143.587386846542, 'total_duration': 8756.439602851868, 'accumulated_submission_time': 8143.587386846542, 'accumulated_eval_time': 608.591876745224, 'accumulated_logging_time': 2.998674154281616, 'global_step': 34534, 'preemption_count': 0}), (34875, {'train/ssim': 0.7510365758623395, 'train/loss': 0.26410153933933805, 'validation/ssim': 0.7266363467000211, 'validation/loss': 0.28466364098990576, 'validation/num_examples': 3554, 'test/ssim': 0.7437644943582449, 'test/loss': 0.28595943924968587, 'test/num_examples': 3581, 'score': 8223.553173303604, 'total_duration': 8840.46463394165, 'accumulated_submission_time': 8223.553173303604, 'accumulated_eval_time': 612.6066925525665, 'accumulated_logging_time': 3.0308783054351807, 'global_step': 34875, 'preemption_count': 0}), (35220, {'train/ssim': 0.7510863712855748, 'train/loss': 0.2640958513532366, 'validation/ssim': 0.7266660227692389, 'validation/loss': 0.28464203653673675, 'validation/num_examples': 3554, 'test/ssim': 0.7438080592449735, 'test/loss': 0.28594075884442194, 'test/num_examples': 3581, 'score': 8303.650809764862, 'total_duration': 8924.624583244324, 'accumulated_submission_time': 8303.650809764862, 'accumulated_eval_time': 616.624080657959, 'accumulated_logging_time': 3.063483715057373, 'global_step': 35220, 'preemption_count': 0}), (35566, {'train/ssim': 0.7510568073817662, 'train/loss': 0.264108487537929, 'validation/ssim': 0.7267169254713, 'validation/loss': 0.2846336729686181, 'validation/num_examples': 3554, 'test/ssim': 0.7438390796259774, 'test/loss': 0.28593455476822116, 'test/num_examples': 3581, 'score': 8383.785435676575, 'total_duration': 9008.827517747879, 'accumulated_submission_time': 8383.785435676575, 'accumulated_eval_time': 620.6433687210083, 'accumulated_logging_time': 3.0999300479888916, 'global_step': 35566, 'preemption_count': 0}), (35909, {'train/ssim': 0.7510451589311872, 'train/loss': 0.2640914406095232, 'validation/ssim': 0.7266632062904473, 'validation/loss': 0.2846232485623593, 'validation/num_examples': 3554, 'test/ssim': 0.7438034914086498, 'test/loss': 0.28592248749912735, 'test/num_examples': 3581, 'score': 8463.990142822266, 'total_duration': 9093.095028400421, 'accumulated_submission_time': 8463.990142822266, 'accumulated_eval_time': 624.6613454818726, 'accumulated_logging_time': 3.1323611736297607, 'global_step': 35909, 'preemption_count': 0}), (36189, {'train/ssim': 0.7512311254228864, 'train/loss': 0.2641005516052246, 'validation/ssim': 0.7268648249551561, 'validation/loss': 0.2846340336152926, 'validation/num_examples': 3554, 'test/ssim': 0.7439900909313041, 'test/loss': 0.28593407753159034, 'test/num_examples': 3581, 'score': 8528.737991809845, 'total_duration': 9161.908516168594, 'accumulated_submission_time': 8528.737991809845, 'accumulated_eval_time': 628.6836860179901, 'accumulated_logging_time': 3.1654698848724365, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0208 17:38:50.606127 140466628462400 submission_runner.py:586] Timing: 8528.737991809845
I0208 17:38:50.606188 140466628462400 submission_runner.py:588] Total number of evals: 107
I0208 17:38:50.606231 140466628462400 submission_runner.py:589] ====================
I0208 17:38:50.606277 140466628462400 submission_runner.py:542] Using RNG seed 1572671891
I0208 17:38:50.608138 140466628462400 submission_runner.py:551] --- Tuning run 2/5 ---
I0208 17:38:50.608297 140466628462400 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2.
I0208 17:38:50.608583 140466628462400 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2/hparams.json.
I0208 17:38:50.609522 140466628462400 submission_runner.py:206] Initializing dataset.
I0208 17:38:50.911426 140466628462400 submission_runner.py:213] Initializing model.
I0208 17:38:53.296870 140466628462400 submission_runner.py:255] Initializing optimizer.
I0208 17:38:53.363831 140466628462400 submission_runner.py:262] Initializing metrics bundle.
I0208 17:38:53.363980 140466628462400 submission_runner.py:280] Initializing checkpoint and logger.
I0208 17:38:53.364653 140466628462400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2 with prefix checkpoint_
I0208 17:38:53.364774 140466628462400 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2/meta_data_0.json.
I0208 17:38:53.365026 140466628462400 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0208 17:38:53.365101 140466628462400 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0208 17:38:57.453845 140466628462400 logger_utils.py:220] Unable to record git information. Continuing without it.
I0208 17:39:01.532154 140466628462400 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2/flags_0.json.
I0208 17:39:01.540283 140466628462400 submission_runner.py:314] Starting training loop.
I0208 17:39:30.709797 140244451907328 logging_writer.py:48] [0] global_step=0, grad_norm=4.160696983337402, loss=0.8857511878013611
I0208 17:39:30.717028 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:39:32.041293 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:39:33.358735 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:39:34.677577 140466628462400 submission_runner.py:408] Time since start: 33.14s, 	Step: 1, 	{'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 29.176573991775513, 'total_duration': 33.137226819992065, 'accumulated_submission_time': 29.176573991775513, 'accumulated_eval_time': 3.9605116844177246, 'accumulated_logging_time': 0}
I0208 17:39:34.686836 140244460300032 logging_writer.py:48] [1] accumulated_eval_time=3.960512, accumulated_logging_time=0, accumulated_submission_time=29.176574, global_step=1, preemption_count=0, score=29.176574, test/loss=0.894958, test/num_examples=3581, test/ssim=0.283672, total_duration=33.137227, train/loss=0.892833, train/ssim=0.265677, validation/loss=0.895667, validation/num_examples=3554, validation/ssim=0.261322
I0208 17:39:56.325432 140244451907328 logging_writer.py:48] [100] global_step=100, grad_norm=0.5582873225212097, loss=0.32098978757858276
I0208 17:40:20.243727 140244460300032 logging_writer.py:48] [200] global_step=200, grad_norm=0.20868554711341858, loss=0.2707943022251129
I0208 17:40:44.212148 140244451907328 logging_writer.py:48] [300] global_step=300, grad_norm=0.1646595597267151, loss=0.30556565523147583
I0208 17:40:54.804912 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:40:56.179217 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:40:57.498773 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:40:58.817179 140466628462400 submission_runner.py:408] Time since start: 117.28s, 	Step: 345, 	{'train/ssim': 0.7004432678222656, 'train/loss': 0.30544791902814594, 'validation/ssim': 0.6780527057980444, 'validation/loss': 0.32312870401308386, 'validation/num_examples': 3554, 'test/ssim': 0.6965224312124756, 'test/loss': 0.3249313665548206, 'test/num_examples': 3581, 'score': 109.27268695831299, 'total_duration': 117.27683687210083, 'accumulated_submission_time': 109.27268695831299, 'accumulated_eval_time': 7.9727394580841064, 'accumulated_logging_time': 0.018121719360351562}
I0208 17:40:58.831882 140244460300032 logging_writer.py:48] [345] accumulated_eval_time=7.972739, accumulated_logging_time=0.018122, accumulated_submission_time=109.272687, global_step=345, preemption_count=0, score=109.272687, test/loss=0.324931, test/num_examples=3581, test/ssim=0.696522, total_duration=117.276837, train/loss=0.305448, train/ssim=0.700443, validation/loss=0.323129, validation/num_examples=3554, validation/ssim=0.678053
I0208 17:41:10.105498 140244451907328 logging_writer.py:48] [400] global_step=400, grad_norm=0.229507714509964, loss=0.29260942339897156
I0208 17:41:34.372030 140244460300032 logging_writer.py:48] [500] global_step=500, grad_norm=0.3024040162563324, loss=0.2989880442619324
I0208 17:41:58.638421 140244451907328 logging_writer.py:48] [600] global_step=600, grad_norm=0.12314200401306152, loss=0.2723539471626282
I0208 17:42:18.995851 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:42:20.367533 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:42:21.687941 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:42:23.008581 140466628462400 submission_runner.py:408] Time since start: 201.47s, 	Step: 684, 	{'train/ssim': 0.719583238874163, 'train/loss': 0.29089525767735075, 'validation/ssim': 0.6983924912950197, 'validation/loss': 0.3081439033813133, 'validation/num_examples': 3554, 'test/ssim': 0.7156626198818417, 'test/loss': 0.3102621692613795, 'test/num_examples': 3581, 'score': 189.41457438468933, 'total_duration': 201.46821546554565, 'accumulated_submission_time': 189.41457438468933, 'accumulated_eval_time': 11.985413312911987, 'accumulated_logging_time': 0.0421442985534668}
I0208 17:42:23.023683 140244460300032 logging_writer.py:48] [684] accumulated_eval_time=11.985413, accumulated_logging_time=0.042144, accumulated_submission_time=189.414574, global_step=684, preemption_count=0, score=189.414574, test/loss=0.310262, test/num_examples=3581, test/ssim=0.715663, total_duration=201.468215, train/loss=0.290895, train/ssim=0.719583, validation/loss=0.308144, validation/num_examples=3554, validation/ssim=0.698392
I0208 17:42:24.765461 140244451907328 logging_writer.py:48] [700] global_step=700, grad_norm=0.9728707671165466, loss=0.2465665489435196
I0208 17:42:48.766431 140244460300032 logging_writer.py:48] [800] global_step=800, grad_norm=0.18481121957302094, loss=0.3512110710144043
I0208 17:43:12.964841 140244451907328 logging_writer.py:48] [900] global_step=900, grad_norm=0.15338824689388275, loss=0.36575382947921753
I0208 17:43:37.317863 140244460300032 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.2526637613773346, loss=0.2843562364578247
I0208 17:43:43.199654 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:43:44.573394 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:43:45.895233 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:43:47.218750 140466628462400 submission_runner.py:408] Time since start: 285.68s, 	Step: 1026, 	{'train/ssim': 0.7229753902980259, 'train/loss': 0.2880307946886335, 'validation/ssim': 0.70181561214037, 'validation/loss': 0.305126321134637, 'validation/num_examples': 3554, 'test/ssim': 0.7192106015254119, 'test/loss': 0.3069072980116413, 'test/num_examples': 3581, 'score': 269.56817269325256, 'total_duration': 285.6784076690674, 'accumulated_submission_time': 269.56817269325256, 'accumulated_eval_time': 16.004467010498047, 'accumulated_logging_time': 0.06655621528625488}
I0208 17:43:47.233397 140244451907328 logging_writer.py:48] [1026] accumulated_eval_time=16.004467, accumulated_logging_time=0.066556, accumulated_submission_time=269.568173, global_step=1026, preemption_count=0, score=269.568173, test/loss=0.306907, test/num_examples=3581, test/ssim=0.719211, total_duration=285.678408, train/loss=0.288031, train/ssim=0.722975, validation/loss=0.305126, validation/num_examples=3554, validation/ssim=0.701816
I0208 17:44:03.037389 140244460300032 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.8122900128364563, loss=0.27402278780937195
I0208 17:44:26.832181 140244451907328 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.15972626209259033, loss=0.27921146154403687
I0208 17:44:50.383350 140244460300032 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.10000685602426529, loss=0.29366084933280945
I0208 17:45:07.243298 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:45:08.616302 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:45:09.935854 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:45:11.258540 140466628462400 submission_runner.py:408] Time since start: 369.72s, 	Step: 1372, 	{'train/ssim': 0.7281092916216169, 'train/loss': 0.2867491585867746, 'validation/ssim': 0.7068357451551069, 'validation/loss': 0.3044106607431767, 'validation/num_examples': 3554, 'test/ssim': 0.7239998756457693, 'test/loss': 0.30622972426085593, 'test/num_examples': 3581, 'score': 349.55478286743164, 'total_duration': 369.7181885242462, 'accumulated_submission_time': 349.55478286743164, 'accumulated_eval_time': 20.019661903381348, 'accumulated_logging_time': 0.09123992919921875}
I0208 17:45:11.273138 140244451907328 logging_writer.py:48] [1372] accumulated_eval_time=20.019662, accumulated_logging_time=0.091240, accumulated_submission_time=349.554783, global_step=1372, preemption_count=0, score=349.554783, test/loss=0.306230, test/num_examples=3581, test/ssim=0.724000, total_duration=369.718189, train/loss=0.286749, train/ssim=0.728109, validation/loss=0.304411, validation/num_examples=3554, validation/ssim=0.706836
I0208 17:45:15.901272 140244460300032 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.6857403516769409, loss=0.3038772642612457
I0208 17:45:39.473881 140244451907328 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.3763454854488373, loss=0.27916938066482544
I0208 17:46:03.314992 140244460300032 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.34039953351020813, loss=0.2539037764072418
I0208 17:46:27.311046 140244451907328 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.20141702890396118, loss=0.4162713587284088
I0208 17:46:31.480249 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:46:32.853812 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:46:34.176586 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:46:35.496344 140466628462400 submission_runner.py:408] Time since start: 453.96s, 	Step: 1719, 	{'train/ssim': 0.7329938752310616, 'train/loss': 0.2795459202357701, 'validation/ssim': 0.7116876450830051, 'validation/loss': 0.29747734864105585, 'validation/num_examples': 3554, 'test/ssim': 0.728800262561959, 'test/loss': 0.2991478394543249, 'test/num_examples': 3581, 'score': 429.73734307289124, 'total_duration': 453.9560031890869, 'accumulated_submission_time': 429.73734307289124, 'accumulated_eval_time': 24.035717964172363, 'accumulated_logging_time': 0.11692500114440918}
I0208 17:46:35.511124 140244460300032 logging_writer.py:48] [1719] accumulated_eval_time=24.035718, accumulated_logging_time=0.116925, accumulated_submission_time=429.737343, global_step=1719, preemption_count=0, score=429.737343, test/loss=0.299148, test/num_examples=3581, test/ssim=0.728800, total_duration=453.956003, train/loss=0.279546, train/ssim=0.732994, validation/loss=0.297477, validation/num_examples=3554, validation/ssim=0.711688
I0208 17:46:52.431247 140244451907328 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.23002268373966217, loss=0.2590349316596985
I0208 17:47:16.385396 140244460300032 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.14163950085639954, loss=0.31441617012023926
I0208 17:47:39.917214 140244451907328 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.6765057444572449, loss=0.31638669967651367
I0208 17:47:55.711856 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:47:57.082997 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:47:58.403042 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:47:59.722697 140466628462400 submission_runner.py:408] Time since start: 538.18s, 	Step: 2067, 	{'train/ssim': 0.7248802185058594, 'train/loss': 0.2891953672681536, 'validation/ssim': 0.7033233213236846, 'validation/loss': 0.30676850000659467, 'validation/num_examples': 3554, 'test/ssim': 0.7207346226176348, 'test/loss': 0.3087029349234676, 'test/num_examples': 3581, 'score': 509.9147651195526, 'total_duration': 538.1823544502258, 'accumulated_submission_time': 509.9147651195526, 'accumulated_eval_time': 28.04653525352478, 'accumulated_logging_time': 0.14153599739074707}
I0208 17:47:59.737409 140244460300032 logging_writer.py:48] [2067] accumulated_eval_time=28.046535, accumulated_logging_time=0.141536, accumulated_submission_time=509.914765, global_step=2067, preemption_count=0, score=509.914765, test/loss=0.308703, test/num_examples=3581, test/ssim=0.720735, total_duration=538.182354, train/loss=0.289195, train/ssim=0.724880, validation/loss=0.306769, validation/num_examples=3554, validation/ssim=0.703323
I0208 17:48:05.633599 140244451907328 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.24606817960739136, loss=0.31945863366127014
I0208 17:48:29.364613 140244460300032 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.08365245908498764, loss=0.28252163529396057
I0208 17:48:52.932280 140244451907328 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.21744324266910553, loss=0.2944825291633606
I0208 17:49:16.651987 140244460300032 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.25233566761016846, loss=0.3442327380180359
I0208 17:49:19.916088 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:49:21.287994 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:49:22.609577 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:49:23.932688 140466628462400 submission_runner.py:408] Time since start: 622.39s, 	Step: 2415, 	{'train/ssim': 0.72991943359375, 'train/loss': 0.28169032505580355, 'validation/ssim': 0.7089212446583075, 'validation/loss': 0.2988491112017269, 'validation/num_examples': 3554, 'test/ssim': 0.7260800819428931, 'test/loss': 0.30067448534801733, 'test/num_examples': 3581, 'score': 590.0707066059113, 'total_duration': 622.3923435211182, 'accumulated_submission_time': 590.0707066059113, 'accumulated_eval_time': 32.063100814819336, 'accumulated_logging_time': 0.16549324989318848}
I0208 17:49:23.948141 140244451907328 logging_writer.py:48] [2415] accumulated_eval_time=32.063101, accumulated_logging_time=0.165493, accumulated_submission_time=590.070707, global_step=2415, preemption_count=0, score=590.070707, test/loss=0.300674, test/num_examples=3581, test/ssim=0.726080, total_duration=622.392344, train/loss=0.281690, train/ssim=0.729919, validation/loss=0.298849, validation/num_examples=3554, validation/ssim=0.708921
I0208 17:49:42.096009 140244460300032 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.18792301416397095, loss=0.3059089779853821
I0208 17:50:05.985884 140244451907328 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.10613573342561722, loss=0.2494901865720749
I0208 17:50:29.787096 140244460300032 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.12596864998340607, loss=0.30309155583381653
I0208 17:50:43.961555 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:50:45.334974 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:50:46.655829 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:50:47.976171 140466628462400 submission_runner.py:408] Time since start: 706.44s, 	Step: 2762, 	{'train/ssim': 0.735365731375558, 'train/loss': 0.2765935829707554, 'validation/ssim': 0.713966107730726, 'validation/loss': 0.294382897131753, 'validation/num_examples': 3554, 'test/ssim': 0.7312001492250768, 'test/loss': 0.2960129061147375, 'test/num_examples': 3581, 'score': 670.0614335536957, 'total_duration': 706.4358239173889, 'accumulated_submission_time': 670.0614335536957, 'accumulated_eval_time': 36.077672481536865, 'accumulated_logging_time': 0.19008660316467285}
I0208 17:50:47.992329 140244451907328 logging_writer.py:48] [2762] accumulated_eval_time=36.077672, accumulated_logging_time=0.190087, accumulated_submission_time=670.061434, global_step=2762, preemption_count=0, score=670.061434, test/loss=0.296013, test/num_examples=3581, test/ssim=0.731200, total_duration=706.435824, train/loss=0.276594, train/ssim=0.735366, validation/loss=0.294383, validation/num_examples=3554, validation/ssim=0.713966
I0208 17:50:54.875155 140244460300032 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.15653884410858154, loss=0.23931163549423218
I0208 17:51:18.781529 140244451907328 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.20514412224292755, loss=0.2537676692008972
I0208 17:51:42.618086 140244460300032 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.09707613289356232, loss=0.26781246066093445
I0208 17:52:06.488172 140244451907328 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.17868345975875854, loss=0.28996607661247253
I0208 17:52:08.133354 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:52:09.505958 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:52:10.828300 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:52:12.149107 140466628462400 submission_runner.py:408] Time since start: 790.61s, 	Step: 3107, 	{'train/ssim': 0.7322643143790108, 'train/loss': 0.2801121303013393, 'validation/ssim': 0.7105216915579277, 'validation/loss': 0.2975265683253025, 'validation/num_examples': 3554, 'test/ssim': 0.7275827637400517, 'test/loss': 0.29931974690641583, 'test/num_examples': 3581, 'score': 750.1785328388214, 'total_duration': 790.608763217926, 'accumulated_submission_time': 750.1785328388214, 'accumulated_eval_time': 40.0933940410614, 'accumulated_logging_time': 0.21664667129516602}
I0208 17:52:12.165975 140244460300032 logging_writer.py:48] [3107] accumulated_eval_time=40.093394, accumulated_logging_time=0.216647, accumulated_submission_time=750.178533, global_step=3107, preemption_count=0, score=750.178533, test/loss=0.299320, test/num_examples=3581, test/ssim=0.727583, total_duration=790.608763, train/loss=0.280112, train/ssim=0.732264, validation/loss=0.297527, validation/num_examples=3554, validation/ssim=0.710522
I0208 17:52:32.072746 140244451907328 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.1031128317117691, loss=0.26662737131118774
I0208 17:52:55.844084 140244460300032 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.1520886868238449, loss=0.26392531394958496
I0208 17:53:19.693030 140244451907328 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.10625811666250229, loss=0.28514865040779114
I0208 17:53:32.325380 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:53:33.697692 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:53:35.018974 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:53:36.339230 140466628462400 submission_runner.py:408] Time since start: 874.80s, 	Step: 3455, 	{'train/ssim': 0.7370850699288505, 'train/loss': 0.27470595496041433, 'validation/ssim': 0.7150101970271173, 'validation/loss': 0.29273261229644415, 'validation/num_examples': 3554, 'test/ssim': 0.7320430854684445, 'test/loss': 0.2944108909217048, 'test/num_examples': 3581, 'score': 830.3153464794159, 'total_duration': 874.7988729476929, 'accumulated_submission_time': 830.3153464794159, 'accumulated_eval_time': 44.107200622558594, 'accumulated_logging_time': 0.24260187149047852}
I0208 17:53:36.354687 140244460300032 logging_writer.py:48] [3455] accumulated_eval_time=44.107201, accumulated_logging_time=0.242602, accumulated_submission_time=830.315346, global_step=3455, preemption_count=0, score=830.315346, test/loss=0.294411, test/num_examples=3581, test/ssim=0.732043, total_duration=874.798873, train/loss=0.274706, train/ssim=0.737085, validation/loss=0.292733, validation/num_examples=3554, validation/ssim=0.715010
I0208 17:53:45.080888 140244451907328 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.0901782438158989, loss=0.3299434781074524
I0208 17:54:08.592813 140244460300032 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.11425918340682983, loss=0.24680274724960327
I0208 17:54:32.362464 140244451907328 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.2594766914844513, loss=0.25584182143211365
I0208 17:54:56.042314 140244460300032 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.10531654208898544, loss=0.26611360907554626
I0208 17:54:56.425140 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:54:57.796589 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:54:59.117233 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:55:00.438096 140466628462400 submission_runner.py:408] Time since start: 958.90s, 	Step: 3803, 	{'train/ssim': 0.7389027050563267, 'train/loss': 0.2740594318934849, 'validation/ssim': 0.7170717221132878, 'validation/loss': 0.2919730217052969, 'validation/num_examples': 3554, 'test/ssim': 0.7343342985330564, 'test/loss': 0.29355793270908964, 'test/num_examples': 3581, 'score': 910.3621096611023, 'total_duration': 958.8977530002594, 'accumulated_submission_time': 910.3621096611023, 'accumulated_eval_time': 48.12011766433716, 'accumulated_logging_time': 0.2682778835296631}
I0208 17:55:00.454053 140244451907328 logging_writer.py:48] [3803] accumulated_eval_time=48.120118, accumulated_logging_time=0.268278, accumulated_submission_time=910.362110, global_step=3803, preemption_count=0, score=910.362110, test/loss=0.293558, test/num_examples=3581, test/ssim=0.734334, total_duration=958.897753, train/loss=0.274059, train/ssim=0.738903, validation/loss=0.291973, validation/num_examples=3554, validation/ssim=0.717072
I0208 17:55:21.486005 140244460300032 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.1436839997768402, loss=0.3235795199871063
I0208 17:55:45.055783 140244451907328 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.17604707181453705, loss=0.23694787919521332
I0208 17:56:09.099328 140244460300032 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.11539304256439209, loss=0.24300529062747955
I0208 17:56:20.571343 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:56:21.945501 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:56:23.267226 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:56:24.590098 140466628462400 submission_runner.py:408] Time since start: 1043.05s, 	Step: 4149, 	{'train/ssim': 0.7399940490722656, 'train/loss': 0.2729658229010446, 'validation/ssim': 0.7180402473445414, 'validation/loss': 0.2910110224614871, 'validation/num_examples': 3554, 'test/ssim': 0.7352640236665736, 'test/loss': 0.29254370260358487, 'test/num_examples': 3581, 'score': 990.4565176963806, 'total_duration': 1043.0497572422028, 'accumulated_submission_time': 990.4565176963806, 'accumulated_eval_time': 52.13883900642395, 'accumulated_logging_time': 0.29352760314941406}
I0208 17:56:24.606024 140244451907328 logging_writer.py:48] [4149] accumulated_eval_time=52.138839, accumulated_logging_time=0.293528, accumulated_submission_time=990.456518, global_step=4149, preemption_count=0, score=990.456518, test/loss=0.292544, test/num_examples=3581, test/ssim=0.735264, total_duration=1043.049757, train/loss=0.272966, train/ssim=0.739994, validation/loss=0.291011, validation/num_examples=3554, validation/ssim=0.718040
I0208 17:56:34.779362 140244460300032 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.2087271362543106, loss=0.2947138547897339
I0208 17:56:58.533584 140244451907328 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.16184255480766296, loss=0.2950376272201538
I0208 17:57:22.405420 140244460300032 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.08671354502439499, loss=0.2942880094051361
I0208 17:57:44.765281 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:57:46.137268 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:57:47.458596 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:57:48.780223 140466628462400 submission_runner.py:408] Time since start: 1127.24s, 	Step: 4496, 	{'train/ssim': 0.7390618324279785, 'train/loss': 0.2744659355708531, 'validation/ssim': 0.7164873371113534, 'validation/loss': 0.2924563912910629, 'validation/num_examples': 3554, 'test/ssim': 0.7336459187814158, 'test/loss': 0.29424372174759145, 'test/num_examples': 3581, 'score': 1070.5930817127228, 'total_duration': 1127.2398805618286, 'accumulated_submission_time': 1070.5930817127228, 'accumulated_eval_time': 56.15374946594238, 'accumulated_logging_time': 0.31876206398010254}
I0208 17:57:48.796702 140244451907328 logging_writer.py:48] [4496] accumulated_eval_time=56.153749, accumulated_logging_time=0.318762, accumulated_submission_time=1070.593082, global_step=4496, preemption_count=0, score=1070.593082, test/loss=0.294244, test/num_examples=3581, test/ssim=0.733646, total_duration=1127.239881, train/loss=0.274466, train/ssim=0.739062, validation/loss=0.292456, validation/num_examples=3554, validation/ssim=0.716487
I0208 17:57:49.181674 140244460300032 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.1982654184103012, loss=0.2558010518550873
I0208 17:58:11.530246 140244451907328 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1346668303012848, loss=0.24743574857711792
I0208 17:58:35.195611 140244460300032 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.11392903327941895, loss=0.27917689085006714
I0208 17:58:58.838248 140244451907328 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.18652774393558502, loss=0.2533688247203827
I0208 17:59:09.000015 140466628462400 spec.py:321] Evaluating on the training split.
I0208 17:59:10.372948 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 17:59:11.694377 140466628462400 spec.py:349] Evaluating on the test split.
I0208 17:59:13.018007 140466628462400 submission_runner.py:408] Time since start: 1211.48s, 	Step: 4843, 	{'train/ssim': 0.7348019736153739, 'train/loss': 0.2777554307665144, 'validation/ssim': 0.7128869154913478, 'validation/loss': 0.2955745424389772, 'validation/num_examples': 3554, 'test/ssim': 0.7299596748682281, 'test/loss': 0.29721179270804243, 'test/num_examples': 3581, 'score': 1150.773977279663, 'total_duration': 1211.4776709079742, 'accumulated_submission_time': 1150.773977279663, 'accumulated_eval_time': 60.17170739173889, 'accumulated_logging_time': 0.3441455364227295}
I0208 17:59:13.033899 140244460300032 logging_writer.py:48] [4843] accumulated_eval_time=60.171707, accumulated_logging_time=0.344146, accumulated_submission_time=1150.773977, global_step=4843, preemption_count=0, score=1150.773977, test/loss=0.297212, test/num_examples=3581, test/ssim=0.729960, total_duration=1211.477671, train/loss=0.277755, train/ssim=0.734802, validation/loss=0.295575, validation/num_examples=3554, validation/ssim=0.712887
I0208 17:59:24.259253 140244451907328 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.09393036365509033, loss=0.284421443939209
I0208 17:59:48.068046 140244460300032 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.09861350059509277, loss=0.25789010524749756
I0208 18:00:11.671926 140244451907328 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.14251480996608734, loss=0.23330481350421906
I0208 18:00:33.172586 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:00:34.543995 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:00:35.865455 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:00:37.186820 140466628462400 submission_runner.py:408] Time since start: 1295.65s, 	Step: 5192, 	{'train/ssim': 0.7410356657845634, 'train/loss': 0.27177795342036654, 'validation/ssim': 0.7192005679120357, 'validation/loss': 0.28972268949818863, 'validation/num_examples': 3554, 'test/ssim': 0.7364080962239947, 'test/loss': 0.29136526900874404, 'test/num_examples': 3581, 'score': 1230.8901679515839, 'total_duration': 1295.6464822292328, 'accumulated_submission_time': 1230.8901679515839, 'accumulated_eval_time': 64.18590641021729, 'accumulated_logging_time': 0.3689992427825928}
I0208 18:00:37.202471 140244460300032 logging_writer.py:48] [5192] accumulated_eval_time=64.185906, accumulated_logging_time=0.368999, accumulated_submission_time=1230.890168, global_step=5192, preemption_count=0, score=1230.890168, test/loss=0.291365, test/num_examples=3581, test/ssim=0.736408, total_duration=1295.646482, train/loss=0.271778, train/ssim=0.741036, validation/loss=0.289723, validation/num_examples=3554, validation/ssim=0.719201
I0208 18:00:37.878292 140244451907328 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.08044353872537613, loss=0.2574613094329834
I0208 18:01:01.041168 140244460300032 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.15184332430362701, loss=0.2594151794910431
I0208 18:01:24.938764 140244451907328 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.06627262383699417, loss=0.32233577966690063
I0208 18:01:48.639561 140244460300032 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.1352451592683792, loss=0.27628931403160095
I0208 18:01:57.268475 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:01:58.641413 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:01:59.961175 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:02:01.286996 140466628462400 submission_runner.py:408] Time since start: 1379.75s, 	Step: 5538, 	{'train/ssim': 0.7400689806256976, 'train/loss': 0.2726975509098598, 'validation/ssim': 0.7185819729969752, 'validation/loss': 0.2905688352912212, 'validation/num_examples': 3554, 'test/ssim': 0.7357066265533371, 'test/loss': 0.2921690718483838, 'test/num_examples': 3581, 'score': 1310.9333474636078, 'total_duration': 1379.7466549873352, 'accumulated_submission_time': 1310.9333474636078, 'accumulated_eval_time': 68.20439505577087, 'accumulated_logging_time': 0.39395570755004883}
I0208 18:02:01.303802 140244451907328 logging_writer.py:48] [5538] accumulated_eval_time=68.204395, accumulated_logging_time=0.393956, accumulated_submission_time=1310.933347, global_step=5538, preemption_count=0, score=1310.933347, test/loss=0.292169, test/num_examples=3581, test/ssim=0.735707, total_duration=1379.746655, train/loss=0.272698, train/ssim=0.740069, validation/loss=0.290569, validation/num_examples=3554, validation/ssim=0.718582
I0208 18:02:14.044318 140244460300032 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.12724903225898743, loss=0.21774576604366302
I0208 18:02:37.452572 140244451907328 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.08507593721151352, loss=0.25531429052352905
I0208 18:03:01.033292 140244460300032 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.19948627054691315, loss=0.3621252179145813
I0208 18:03:21.323481 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:03:22.697002 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:03:24.021548 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:03:25.342220 140466628462400 submission_runner.py:408] Time since start: 1463.80s, 	Step: 5887, 	{'train/ssim': 0.7430743489946637, 'train/loss': 0.2713005372456142, 'validation/ssim': 0.7210018091411086, 'validation/loss': 0.28938642940832515, 'validation/num_examples': 3554, 'test/ssim': 0.7382192092379922, 'test/loss': 0.2909360287476438, 'test/num_examples': 3581, 'score': 1390.9299306869507, 'total_duration': 1463.8018777370453, 'accumulated_submission_time': 1390.9299306869507, 'accumulated_eval_time': 72.22309613227844, 'accumulated_logging_time': 0.42021870613098145}
I0208 18:03:25.357825 140244451907328 logging_writer.py:48] [5887] accumulated_eval_time=72.223096, accumulated_logging_time=0.420219, accumulated_submission_time=1390.929931, global_step=5887, preemption_count=0, score=1390.929931, test/loss=0.290936, test/num_examples=3581, test/ssim=0.738219, total_duration=1463.801878, train/loss=0.271301, train/ssim=0.743074, validation/loss=0.289386, validation/num_examples=3554, validation/ssim=0.721002
I0208 18:03:26.451678 140244460300032 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.06721540540456772, loss=0.25276196002960205
I0208 18:03:49.837287 140244451907328 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.3373355567455292, loss=0.23273015022277832
I0208 18:04:13.376814 140244460300032 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.025498751550912857, loss=0.34496939182281494
I0208 18:04:37.200197 140244451907328 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.08609220385551453, loss=0.2365107536315918
I0208 18:04:45.462631 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:04:46.833488 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:04:48.154798 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:04:49.474247 140466628462400 submission_runner.py:408] Time since start: 1547.93s, 	Step: 6236, 	{'train/ssim': 0.7420650890895298, 'train/loss': 0.27099316460745676, 'validation/ssim': 0.7202885530608117, 'validation/loss': 0.2892046634843662, 'validation/num_examples': 3554, 'test/ssim': 0.7374493583758028, 'test/loss': 0.2907333395328644, 'test/num_examples': 3581, 'score': 1471.0121450424194, 'total_duration': 1547.9339079856873, 'accumulated_submission_time': 1471.0121450424194, 'accumulated_eval_time': 76.23468589782715, 'accumulated_logging_time': 0.4449434280395508}
I0208 18:04:49.490328 140244460300032 logging_writer.py:48] [6236] accumulated_eval_time=76.234686, accumulated_logging_time=0.444943, accumulated_submission_time=1471.012145, global_step=6236, preemption_count=0, score=1471.012145, test/loss=0.290733, test/num_examples=3581, test/ssim=0.737449, total_duration=1547.933908, train/loss=0.270993, train/ssim=0.742065, validation/loss=0.289205, validation/num_examples=3554, validation/ssim=0.720289
I0208 18:05:02.924927 140244451907328 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.142939031124115, loss=0.26241475343704224
I0208 18:05:27.183094 140244460300032 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.15729711949825287, loss=0.21481728553771973
I0208 18:05:51.145824 140244451907328 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.13377876579761505, loss=0.3032306730747223
I0208 18:06:09.678591 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:06:11.049546 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:06:12.372330 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:06:13.694146 140466628462400 submission_runner.py:408] Time since start: 1632.15s, 	Step: 6579, 	{'train/ssim': 0.7435024806431362, 'train/loss': 0.2706704991204398, 'validation/ssim': 0.720853978351857, 'validation/loss': 0.2891689422899374, 'validation/num_examples': 3554, 'test/ssim': 0.7380951277139766, 'test/loss': 0.29070808007976123, 'test/num_examples': 3581, 'score': 1551.1771442890167, 'total_duration': 1632.15380692482, 'accumulated_submission_time': 1551.1771442890167, 'accumulated_eval_time': 80.25021290779114, 'accumulated_logging_time': 0.4702737331390381}
I0208 18:06:13.710678 140244460300032 logging_writer.py:48] [6579] accumulated_eval_time=80.250213, accumulated_logging_time=0.470274, accumulated_submission_time=1551.177144, global_step=6579, preemption_count=0, score=1551.177144, test/loss=0.290708, test/num_examples=3581, test/ssim=0.738095, total_duration=1632.153807, train/loss=0.270670, train/ssim=0.743502, validation/loss=0.289169, validation/num_examples=3554, validation/ssim=0.720854
I0208 18:06:16.697355 140244451907328 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.15116871893405914, loss=0.33911943435668945
I0208 18:06:40.336730 140244460300032 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.10247202217578888, loss=0.23066571354866028
I0208 18:07:04.064231 140244451907328 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.07290744036436081, loss=0.365764319896698
I0208 18:07:27.566876 140244460300032 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.08921278268098831, loss=0.3286600112915039
I0208 18:07:33.849520 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:07:35.219961 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:07:36.544717 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:07:37.866449 140466628462400 submission_runner.py:408] Time since start: 1716.33s, 	Step: 6928, 	{'train/ssim': 0.7426629747663226, 'train/loss': 0.2704187972205026, 'validation/ssim': 0.720276600199599, 'validation/loss': 0.28866671603518923, 'validation/num_examples': 3554, 'test/ssim': 0.7376407302647654, 'test/loss': 0.2901382936308817, 'test/num_examples': 3581, 'score': 1631.2922222614288, 'total_duration': 1716.3261096477509, 'accumulated_submission_time': 1631.2922222614288, 'accumulated_eval_time': 84.26713466644287, 'accumulated_logging_time': 0.49689340591430664}
I0208 18:07:37.885040 140244451907328 logging_writer.py:48] [6928] accumulated_eval_time=84.267135, accumulated_logging_time=0.496893, accumulated_submission_time=1631.292222, global_step=6928, preemption_count=0, score=1631.292222, test/loss=0.290138, test/num_examples=3581, test/ssim=0.737641, total_duration=1716.326110, train/loss=0.270419, train/ssim=0.742663, validation/loss=0.288667, validation/num_examples=3554, validation/ssim=0.720277
I0208 18:07:52.661313 140244460300032 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.13990448415279388, loss=0.2534806430339813
I0208 18:08:16.270996 140244451907328 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.1643868237733841, loss=0.23195543885231018
I0208 18:08:39.523837 140244460300032 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.08301227539777756, loss=0.26694321632385254
I0208 18:08:57.976605 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:08:59.350504 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:09:00.672156 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:09:01.996171 140466628462400 submission_runner.py:408] Time since start: 1800.46s, 	Step: 7279, 	{'train/ssim': 0.7441093581063407, 'train/loss': 0.2699455533708845, 'validation/ssim': 0.7217107374613112, 'validation/loss': 0.2883482821952378, 'validation/num_examples': 3554, 'test/ssim': 0.7389450179768221, 'test/loss': 0.2898458498411757, 'test/num_examples': 3581, 'score': 1711.3607697486877, 'total_duration': 1800.455798149109, 'accumulated_submission_time': 1711.3607697486877, 'accumulated_eval_time': 88.28663372993469, 'accumulated_logging_time': 0.5245425701141357}
I0208 18:09:02.016318 140244451907328 logging_writer.py:48] [7279] accumulated_eval_time=88.286634, accumulated_logging_time=0.524543, accumulated_submission_time=1711.360770, global_step=7279, preemption_count=0, score=1711.360770, test/loss=0.289846, test/num_examples=3581, test/ssim=0.738945, total_duration=1800.455798, train/loss=0.269946, train/ssim=0.744109, validation/loss=0.288348, validation/num_examples=3554, validation/ssim=0.721711
I0208 18:09:05.003813 140244460300032 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.09185416996479034, loss=0.28914064168930054
I0208 18:09:29.157831 140244451907328 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.18695881962776184, loss=0.22172152996063232
I0208 18:09:53.079645 140244460300032 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.09180782735347748, loss=0.1620083898305893
I0208 18:10:16.857719 140244451907328 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.11880829930305481, loss=0.29588639736175537
I0208 18:10:22.126649 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:10:23.499280 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:10:24.821124 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:10:26.142237 140466628462400 submission_runner.py:408] Time since start: 1884.60s, 	Step: 7623, 	{'train/ssim': 0.7333408083234515, 'train/loss': 0.27960704054151264, 'validation/ssim': 0.7108606307373734, 'validation/loss': 0.29829945132245356, 'validation/num_examples': 3554, 'test/ssim': 0.7279741659539933, 'test/loss': 0.29984678658850533, 'test/num_examples': 3581, 'score': 1791.4479806423187, 'total_duration': 1884.6018981933594, 'accumulated_submission_time': 1791.4479806423187, 'accumulated_eval_time': 92.30220317840576, 'accumulated_logging_time': 0.5551633834838867}
I0208 18:10:26.159132 140244460300032 logging_writer.py:48] [7623] accumulated_eval_time=92.302203, accumulated_logging_time=0.555163, accumulated_submission_time=1791.447981, global_step=7623, preemption_count=0, score=1791.447981, test/loss=0.299847, test/num_examples=3581, test/ssim=0.727974, total_duration=1884.601898, train/loss=0.279607, train/ssim=0.733341, validation/loss=0.298299, validation/num_examples=3554, validation/ssim=0.710861
I0208 18:10:42.411736 140244451907328 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.11430170387029648, loss=0.246600940823555
I0208 18:11:06.129646 140244460300032 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.09483933448791504, loss=0.3036113381385803
I0208 18:11:29.828736 140244451907328 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.06760329008102417, loss=0.2947332262992859
I0208 18:11:46.337993 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:11:47.711529 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:11:49.033747 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:11:50.359001 140466628462400 submission_runner.py:408] Time since start: 1968.82s, 	Step: 7970, 	{'train/ssim': 0.7422810282026019, 'train/loss': 0.2711213656834194, 'validation/ssim': 0.7199205560635903, 'validation/loss': 0.2898536557619935, 'validation/num_examples': 3554, 'test/ssim': 0.737044593536198, 'test/loss': 0.2914284687739982, 'test/num_examples': 3581, 'score': 1871.6037764549255, 'total_duration': 1968.8186626434326, 'accumulated_submission_time': 1871.6037764549255, 'accumulated_eval_time': 96.32317352294922, 'accumulated_logging_time': 0.5827598571777344}
I0208 18:11:50.376648 140244460300032 logging_writer.py:48] [7970] accumulated_eval_time=96.323174, accumulated_logging_time=0.582760, accumulated_submission_time=1871.603776, global_step=7970, preemption_count=0, score=1871.603776, test/loss=0.291428, test/num_examples=3581, test/ssim=0.737045, total_duration=1968.818663, train/loss=0.271121, train/ssim=0.742281, validation/loss=0.289854, validation/num_examples=3554, validation/ssim=0.719921
I0208 18:11:55.512212 140244451907328 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.0890779197216034, loss=0.2954440414905548
I0208 18:12:19.251926 140244460300032 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.12482848763465881, loss=0.2577899396419525
I0208 18:12:42.858223 140244451907328 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.04087129235267639, loss=0.29562824964523315
I0208 18:13:06.783038 140244460300032 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.1914847493171692, loss=0.21405424177646637
I0208 18:13:10.457143 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:13:11.829882 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:13:13.152661 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:13:14.474274 140466628462400 submission_runner.py:408] Time since start: 2052.93s, 	Step: 8317, 	{'train/ssim': 0.7444945062909808, 'train/loss': 0.2702023983001709, 'validation/ssim': 0.7221898136342854, 'validation/loss': 0.2886703911965391, 'validation/num_examples': 3554, 'test/ssim': 0.7393386700205948, 'test/loss': 0.2901830516091874, 'test/num_examples': 3581, 'score': 1951.662151813507, 'total_duration': 2052.933934688568, 'accumulated_submission_time': 1951.662151813507, 'accumulated_eval_time': 100.34027457237244, 'accumulated_logging_time': 0.6097853183746338}
I0208 18:13:14.491791 140244451907328 logging_writer.py:48] [8317] accumulated_eval_time=100.340275, accumulated_logging_time=0.609785, accumulated_submission_time=1951.662152, global_step=8317, preemption_count=0, score=1951.662152, test/loss=0.290183, test/num_examples=3581, test/ssim=0.739339, total_duration=2052.933935, train/loss=0.270202, train/ssim=0.744495, validation/loss=0.288670, validation/num_examples=3554, validation/ssim=0.722190
I0208 18:13:32.088063 140244460300032 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.07102539390325546, loss=0.26835960149765015
I0208 18:13:55.918895 140244451907328 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.14081797003746033, loss=0.26414212584495544
I0208 18:14:20.302561 140244460300032 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.3493322432041168, loss=0.3527515232563019
I0208 18:14:34.572221 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:14:35.946859 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:14:37.269284 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:14:38.588437 140466628462400 submission_runner.py:408] Time since start: 2137.05s, 	Step: 8661, 	{'train/ssim': 0.732374940599714, 'train/loss': 0.27880374022892546, 'validation/ssim': 0.7117548971009777, 'validation/loss': 0.2963294274497046, 'validation/num_examples': 3554, 'test/ssim': 0.7288023078618053, 'test/loss': 0.2982390104675719, 'test/num_examples': 3581, 'score': 2031.719271659851, 'total_duration': 2137.048096179962, 'accumulated_submission_time': 2031.719271659851, 'accumulated_eval_time': 104.35645294189453, 'accumulated_logging_time': 0.6381211280822754}
I0208 18:14:38.605845 140244451907328 logging_writer.py:48] [8661] accumulated_eval_time=104.356453, accumulated_logging_time=0.638121, accumulated_submission_time=2031.719272, global_step=8661, preemption_count=0, score=2031.719272, test/loss=0.298239, test/num_examples=3581, test/ssim=0.728802, total_duration=2137.048096, train/loss=0.278804, train/ssim=0.732375, validation/loss=0.296329, validation/num_examples=3554, validation/ssim=0.711755
I0208 18:14:45.812658 140244460300032 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.07882273942232132, loss=0.2241624891757965
I0208 18:15:09.614242 140244451907328 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.06797729432582855, loss=0.34867674112319946
I0208 18:15:33.112920 140244460300032 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.1146339550614357, loss=0.2855484187602997
I0208 18:15:56.596065 140244451907328 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.4850504398345947, loss=0.24208877980709076
I0208 18:15:58.716575 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:16:00.089579 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:16:01.412126 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:16:02.734218 140466628462400 submission_runner.py:408] Time since start: 2221.19s, 	Step: 9010, 	{'train/ssim': 0.7443432807922363, 'train/loss': 0.2709218774523054, 'validation/ssim': 0.7221872032393079, 'validation/loss': 0.289655952689751, 'validation/num_examples': 3554, 'test/ssim': 0.7392850149879573, 'test/loss': 0.29116046631745673, 'test/num_examples': 3581, 'score': 2111.8080835342407, 'total_duration': 2221.1938774585724, 'accumulated_submission_time': 2111.8080835342407, 'accumulated_eval_time': 108.37405753135681, 'accumulated_logging_time': 0.664588451385498}
I0208 18:16:02.751296 140244460300032 logging_writer.py:48] [9010] accumulated_eval_time=108.374058, accumulated_logging_time=0.664588, accumulated_submission_time=2111.808084, global_step=9010, preemption_count=0, score=2111.808084, test/loss=0.291160, test/num_examples=3581, test/ssim=0.739285, total_duration=2221.193877, train/loss=0.270922, train/ssim=0.744343, validation/loss=0.289656, validation/num_examples=3554, validation/ssim=0.722187
I0208 18:16:21.775392 140244451907328 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.18261562287807465, loss=0.2861331105232239
I0208 18:16:45.489928 140244460300032 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.10485871881246567, loss=0.23910266160964966
I0208 18:17:09.446512 140244451907328 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.028828153386712074, loss=0.4166886806488037
I0208 18:17:22.897431 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:17:24.272327 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:17:25.589557 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:17:26.914907 140466628462400 submission_runner.py:408] Time since start: 2305.37s, 	Step: 9358, 	{'train/ssim': 0.7424185616629464, 'train/loss': 0.2705019201551165, 'validation/ssim': 0.7198816749173467, 'validation/loss': 0.28904089554683104, 'validation/num_examples': 3554, 'test/ssim': 0.7372185121998045, 'test/loss': 0.2904191814764556, 'test/num_examples': 3581, 'score': 2191.9307548999786, 'total_duration': 2305.374571084976, 'accumulated_submission_time': 2191.9307548999786, 'accumulated_eval_time': 112.39150047302246, 'accumulated_logging_time': 0.6922500133514404}
I0208 18:17:26.932182 140244460300032 logging_writer.py:48] [9358] accumulated_eval_time=112.391500, accumulated_logging_time=0.692250, accumulated_submission_time=2191.930755, global_step=9358, preemption_count=0, score=2191.930755, test/loss=0.290419, test/num_examples=3581, test/ssim=0.737219, total_duration=2305.374571, train/loss=0.270502, train/ssim=0.742419, validation/loss=0.289041, validation/num_examples=3554, validation/ssim=0.719882
I0208 18:17:34.795290 140244451907328 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.16030246019363403, loss=0.30424925684928894
I0208 18:17:58.644047 140244460300032 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.05861488729715347, loss=0.2781617045402527
I0208 18:18:22.638582 140244451907328 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.05668967217206955, loss=0.33321377635002136
I0208 18:18:46.372637 140244460300032 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.06845296174287796, loss=0.4011078476905823
I0208 18:18:47.013029 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:18:48.386731 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:18:49.707416 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:18:51.028617 140466628462400 submission_runner.py:408] Time since start: 2389.49s, 	Step: 9704, 	{'train/ssim': 0.7448130335126605, 'train/loss': 0.26915022305079866, 'validation/ssim': 0.7223689004686621, 'validation/loss': 0.2876758307101154, 'validation/num_examples': 3554, 'test/ssim': 0.7396080360103672, 'test/loss': 0.28906123873176137, 'test/num_examples': 3581, 'score': 2271.9885540008545, 'total_duration': 2389.488274335861, 'accumulated_submission_time': 2271.9885540008545, 'accumulated_eval_time': 116.40704345703125, 'accumulated_logging_time': 0.7198827266693115}
I0208 18:18:51.045486 140244451907328 logging_writer.py:48] [9704] accumulated_eval_time=116.407043, accumulated_logging_time=0.719883, accumulated_submission_time=2271.988554, global_step=9704, preemption_count=0, score=2271.988554, test/loss=0.289061, test/num_examples=3581, test/ssim=0.739608, total_duration=2389.488274, train/loss=0.269150, train/ssim=0.744813, validation/loss=0.287676, validation/num_examples=3554, validation/ssim=0.722369
I0208 18:19:12.042907 140244460300032 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.11833547800779343, loss=0.24694305658340454
I0208 18:19:35.531717 140244451907328 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.038163647055625916, loss=0.27915865182876587
I0208 18:19:59.215125 140244460300032 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.04421735182404518, loss=0.2965332269668579
I0208 18:20:11.044435 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:20:12.416306 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:20:13.738641 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:20:15.061745 140466628462400 submission_runner.py:408] Time since start: 2473.52s, 	Step: 10051, 	{'train/ssim': 0.7456962721688407, 'train/loss': 0.26879189695630756, 'validation/ssim': 0.7229699095649268, 'validation/loss': 0.28772884577127006, 'validation/num_examples': 3554, 'test/ssim': 0.7401323827143256, 'test/loss': 0.28912334767043074, 'test/num_examples': 3581, 'score': 2351.9646701812744, 'total_duration': 2473.5214030742645, 'accumulated_submission_time': 2351.9646701812744, 'accumulated_eval_time': 120.42432022094727, 'accumulated_logging_time': 0.7467184066772461}
I0208 18:20:15.079471 140244451907328 logging_writer.py:48] [10051] accumulated_eval_time=120.424320, accumulated_logging_time=0.746718, accumulated_submission_time=2351.964670, global_step=10051, preemption_count=0, score=2351.964670, test/loss=0.289123, test/num_examples=3581, test/ssim=0.740132, total_duration=2473.521403, train/loss=0.268792, train/ssim=0.745696, validation/loss=0.287729, validation/num_examples=3554, validation/ssim=0.722970
I0208 18:20:24.705048 140244460300032 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.2005985677242279, loss=0.24283647537231445
I0208 18:20:48.079041 140244451907328 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.1370636224746704, loss=0.3683386445045471
I0208 18:21:11.573978 140244460300032 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.0628228709101677, loss=0.2964716851711273
I0208 18:21:35.192257 140244451907328 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.04932607337832451, loss=0.28236356377601624
I0208 18:21:35.197606 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:21:36.515766 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:21:37.834959 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:21:39.158014 140466628462400 submission_runner.py:408] Time since start: 2557.62s, 	Step: 10401, 	{'train/ssim': 0.7442936897277832, 'train/loss': 0.2693566083908081, 'validation/ssim': 0.722090962098164, 'validation/loss': 0.2877130803594981, 'validation/num_examples': 3554, 'test/ssim': 0.739315762662315, 'test/loss': 0.28910688300666715, 'test/num_examples': 3581, 'score': 2432.060645341873, 'total_duration': 2557.617630958557, 'accumulated_submission_time': 2432.060645341873, 'accumulated_eval_time': 124.38462400436401, 'accumulated_logging_time': 0.773712158203125}
I0208 18:21:39.178112 140244460300032 logging_writer.py:48] [10401] accumulated_eval_time=124.384624, accumulated_logging_time=0.773712, accumulated_submission_time=2432.060645, global_step=10401, preemption_count=0, score=2432.060645, test/loss=0.289107, test/num_examples=3581, test/ssim=0.739316, total_duration=2557.617631, train/loss=0.269357, train/ssim=0.744294, validation/loss=0.287713, validation/num_examples=3554, validation/ssim=0.722091
I0208 18:22:00.380966 140244451907328 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.12012164294719696, loss=0.24631625413894653
I0208 18:22:24.027073 140244460300032 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.10266629606485367, loss=0.24720370769500732
I0208 18:22:47.983905 140244451907328 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.048920888453722, loss=0.25151512026786804
I0208 18:22:59.342514 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:23:00.714136 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:23:02.038834 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:23:03.361135 140466628462400 submission_runner.py:408] Time since start: 2641.82s, 	Step: 10748, 	{'train/ssim': 0.7448418481009347, 'train/loss': 0.26893132073538645, 'validation/ssim': 0.7225382326691756, 'validation/loss': 0.2874220900141126, 'validation/num_examples': 3554, 'test/ssim': 0.7397670921617565, 'test/loss': 0.2888093600556758, 'test/num_examples': 3581, 'score': 2512.202274799347, 'total_duration': 2641.820770740509, 'accumulated_submission_time': 2512.202274799347, 'accumulated_eval_time': 128.40318179130554, 'accumulated_logging_time': 0.8037357330322266}
I0208 18:23:03.383877 140244460300032 logging_writer.py:48] [10748] accumulated_eval_time=128.403182, accumulated_logging_time=0.803736, accumulated_submission_time=2512.202275, global_step=10748, preemption_count=0, score=2512.202275, test/loss=0.288809, test/num_examples=3581, test/ssim=0.739767, total_duration=2641.820771, train/loss=0.268931, train/ssim=0.744842, validation/loss=0.287422, validation/num_examples=3554, validation/ssim=0.722538
I0208 18:23:13.552504 140244451907328 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.07049545645713806, loss=0.2335483729839325
I0208 18:23:37.339105 140244460300032 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.08049668371677399, loss=0.2469538450241089
I0208 18:24:01.338458 140244451907328 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.05687088891863823, loss=0.2684076428413391
I0208 18:24:23.620533 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:24:24.994946 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:24:26.313953 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:24:27.633519 140466628462400 submission_runner.py:408] Time since start: 2726.09s, 	Step: 11093, 	{'train/ssim': 0.7452192306518555, 'train/loss': 0.26873513630458284, 'validation/ssim': 0.7224126589318374, 'validation/loss': 0.28779384804093977, 'validation/num_examples': 3554, 'test/ssim': 0.7395489950214674, 'test/loss': 0.289260280495148, 'test/num_examples': 3581, 'score': 2592.4162380695343, 'total_duration': 2726.093177318573, 'accumulated_submission_time': 2592.4162380695343, 'accumulated_eval_time': 132.41613030433655, 'accumulated_logging_time': 0.836331844329834}
I0208 18:24:27.651653 140244460300032 logging_writer.py:48] [11093] accumulated_eval_time=132.416130, accumulated_logging_time=0.836332, accumulated_submission_time=2592.416238, global_step=11093, preemption_count=0, score=2592.416238, test/loss=0.289260, test/num_examples=3581, test/ssim=0.739549, total_duration=2726.093177, train/loss=0.268735, train/ssim=0.745219, validation/loss=0.287794, validation/num_examples=3554, validation/ssim=0.722413
I0208 18:24:28.251765 140244451907328 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.0967581495642662, loss=0.24520346522331238
I0208 18:24:50.586585 140244460300032 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.08024623245000839, loss=0.3864123225212097
I0208 18:25:14.299373 140244451907328 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.08972285687923431, loss=0.28140026330947876
I0208 18:25:37.909742 140244460300032 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.08012346923351288, loss=0.26918214559555054
I0208 18:25:47.740900 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:25:49.110727 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:25:50.431118 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:25:51.753900 140466628462400 submission_runner.py:408] Time since start: 2810.21s, 	Step: 11443, 	{'train/ssim': 0.7452154840741839, 'train/loss': 0.2697348083768572, 'validation/ssim': 0.7223850437007597, 'validation/loss': 0.28835425862584413, 'validation/num_examples': 3554, 'test/ssim': 0.7395929007915037, 'test/loss': 0.28987714292882577, 'test/num_examples': 3581, 'score': 2672.483766078949, 'total_duration': 2810.2135293483734, 'accumulated_submission_time': 2672.483766078949, 'accumulated_eval_time': 136.42907905578613, 'accumulated_logging_time': 0.8633337020874023}
I0208 18:25:51.775462 140244451907328 logging_writer.py:48] [11443] accumulated_eval_time=136.429079, accumulated_logging_time=0.863334, accumulated_submission_time=2672.483766, global_step=11443, preemption_count=0, score=2672.483766, test/loss=0.289877, test/num_examples=3581, test/ssim=0.739593, total_duration=2810.213529, train/loss=0.269735, train/ssim=0.745215, validation/loss=0.288354, validation/num_examples=3554, validation/ssim=0.722385
I0208 18:26:03.478722 140244460300032 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.052150659263134, loss=0.36824649572372437
I0208 18:26:27.080784 140244451907328 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.15910597145557404, loss=0.25775182247161865
I0208 18:26:50.469785 140244460300032 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.13672135770320892, loss=0.24162396788597107
I0208 18:27:11.755209 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:27:13.128856 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:27:14.450843 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:27:15.770619 140466628462400 submission_runner.py:408] Time since start: 2894.23s, 	Step: 11789, 	{'train/ssim': 0.7447735241481236, 'train/loss': 0.26923320974622456, 'validation/ssim': 0.7227943261553883, 'validation/loss': 0.2875390082312623, 'validation/num_examples': 3554, 'test/ssim': 0.7399063089046356, 'test/loss': 0.28899190306696804, 'test/num_examples': 3581, 'score': 2752.4405829906464, 'total_duration': 2894.2302720546722, 'accumulated_submission_time': 2752.4405829906464, 'accumulated_eval_time': 140.4444704055786, 'accumulated_logging_time': 0.8953886032104492}
I0208 18:27:15.788725 140244451907328 logging_writer.py:48] [11789] accumulated_eval_time=140.444470, accumulated_logging_time=0.895389, accumulated_submission_time=2752.440583, global_step=11789, preemption_count=0, score=2752.440583, test/loss=0.288992, test/num_examples=3581, test/ssim=0.739906, total_duration=2894.230272, train/loss=0.269233, train/ssim=0.744774, validation/loss=0.287539, validation/num_examples=3554, validation/ssim=0.722794
I0208 18:27:16.681052 140244460300032 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.09120775014162064, loss=0.2730172872543335
I0208 18:27:40.001520 140244451907328 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.08077502250671387, loss=0.31511950492858887
I0208 18:28:04.173745 140244460300032 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.0660085454583168, loss=0.3395029306411743
I0208 18:28:27.659522 140244451907328 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.039210230112075806, loss=0.32745304703712463
I0208 18:28:36.022312 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:28:37.396419 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:28:38.717714 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:28:40.039971 140466628462400 submission_runner.py:408] Time since start: 2978.50s, 	Step: 12137, 	{'train/ssim': 0.7456636428833008, 'train/loss': 0.26853067534310476, 'validation/ssim': 0.7233629800928532, 'validation/loss': 0.2873849434066369, 'validation/num_examples': 3554, 'test/ssim': 0.7404592216297822, 'test/loss': 0.28867897219046706, 'test/num_examples': 3581, 'score': 2832.651171684265, 'total_duration': 2978.4996314048767, 'accumulated_submission_time': 2832.651171684265, 'accumulated_eval_time': 144.46209335327148, 'accumulated_logging_time': 0.9224934577941895}
I0208 18:28:40.058060 140244460300032 logging_writer.py:48] [12137] accumulated_eval_time=144.462093, accumulated_logging_time=0.922493, accumulated_submission_time=2832.651172, global_step=12137, preemption_count=0, score=2832.651172, test/loss=0.288679, test/num_examples=3581, test/ssim=0.740459, total_duration=2978.499631, train/loss=0.268531, train/ssim=0.745664, validation/loss=0.287385, validation/num_examples=3554, validation/ssim=0.723363
I0208 18:28:52.753297 140244451907328 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.06904323399066925, loss=0.2686222493648529
I0208 18:29:16.629945 140244460300032 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.1234050989151001, loss=0.23005245625972748
I0208 18:29:40.412515 140244451907328 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.11860107630491257, loss=0.26653602719306946
I0208 18:30:00.278187 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:30:01.648968 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:30:02.972987 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:30:04.295627 140466628462400 submission_runner.py:408] Time since start: 3062.76s, 	Step: 12485, 	{'train/ssim': 0.7451457296098981, 'train/loss': 0.2689953531537737, 'validation/ssim': 0.722774129941615, 'validation/loss': 0.28749842689355304, 'validation/num_examples': 3554, 'test/ssim': 0.7399579186374267, 'test/loss': 0.2889450316121544, 'test/num_examples': 3581, 'score': 2912.848475217819, 'total_duration': 3062.7552905082703, 'accumulated_submission_time': 2912.848475217819, 'accumulated_eval_time': 148.47949981689453, 'accumulated_logging_time': 0.9494554996490479}
I0208 18:30:04.313614 140244460300032 logging_writer.py:48] [12485] accumulated_eval_time=148.479500, accumulated_logging_time=0.949455, accumulated_submission_time=2912.848475, global_step=12485, preemption_count=0, score=2912.848475, test/loss=0.288945, test/num_examples=3581, test/ssim=0.739958, total_duration=3062.755291, train/loss=0.268995, train/ssim=0.745146, validation/loss=0.287498, validation/num_examples=3554, validation/ssim=0.722774
I0208 18:30:05.787858 140244451907328 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.07222481071949005, loss=0.348638653755188
I0208 18:30:29.395708 140244460300032 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.05696205049753189, loss=0.2782365083694458
I0208 18:30:52.952248 140244451907328 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.10961069166660309, loss=0.30662158131599426
I0208 18:31:16.716673 140244460300032 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.1305082142353058, loss=0.26346325874328613
I0208 18:31:24.487555 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:31:25.863471 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:31:27.185113 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:31:28.504725 140466628462400 submission_runner.py:408] Time since start: 3146.96s, 	Step: 12834, 	{'train/ssim': 0.7460318974086216, 'train/loss': 0.2684512138366699, 'validation/ssim': 0.7233857180069991, 'validation/loss': 0.2871742742277627, 'validation/num_examples': 3554, 'test/ssim': 0.7405707586480732, 'test/loss': 0.2885619810392523, 'test/num_examples': 3581, 'score': 2992.999326467514, 'total_duration': 3146.9643874168396, 'accumulated_submission_time': 2992.999326467514, 'accumulated_eval_time': 152.49664402008057, 'accumulated_logging_time': 0.9763846397399902}
I0208 18:31:28.522902 140244451907328 logging_writer.py:48] [12834] accumulated_eval_time=152.496644, accumulated_logging_time=0.976385, accumulated_submission_time=2992.999326, global_step=12834, preemption_count=0, score=2992.999326, test/loss=0.288562, test/num_examples=3581, test/ssim=0.740571, total_duration=3146.964387, train/loss=0.268451, train/ssim=0.746032, validation/loss=0.287174, validation/num_examples=3554, validation/ssim=0.723386
I0208 18:31:42.459387 140244460300032 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.12291937321424484, loss=0.3053669333457947
I0208 18:32:06.154870 140244451907328 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.08919283747673035, loss=0.31177768111228943
I0208 18:32:30.225397 140244460300032 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.06285210698843002, loss=0.2559717297554016
I0208 18:32:48.534044 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:32:49.906683 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:32:51.227967 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:32:52.549323 140466628462400 submission_runner.py:408] Time since start: 3231.01s, 	Step: 13179, 	{'train/ssim': 0.745182854788644, 'train/loss': 0.26859872681753977, 'validation/ssim': 0.7225593219128095, 'validation/loss': 0.2874176076911579, 'validation/num_examples': 3554, 'test/ssim': 0.7396684405324979, 'test/loss': 0.28886632165639836, 'test/num_examples': 3581, 'score': 3072.988017320633, 'total_duration': 3231.0089824199677, 'accumulated_submission_time': 3072.988017320633, 'accumulated_eval_time': 156.51189756393433, 'accumulated_logging_time': 1.0034832954406738}
I0208 18:32:52.567003 140244451907328 logging_writer.py:48] [13179] accumulated_eval_time=156.511898, accumulated_logging_time=1.003483, accumulated_submission_time=3072.988017, global_step=13179, preemption_count=0, score=3072.988017, test/loss=0.288866, test/num_examples=3581, test/ssim=0.739668, total_duration=3231.008982, train/loss=0.268599, train/ssim=0.745183, validation/loss=0.287418, validation/num_examples=3554, validation/ssim=0.722559
I0208 18:32:55.426111 140244460300032 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.09600850194692612, loss=0.24050918221473694
I0208 18:33:19.254256 140244451907328 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.0669802650809288, loss=0.24198609590530396
I0208 18:33:42.825243 140244460300032 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.06300106644630432, loss=0.29468387365341187
I0208 18:34:06.787760 140244451907328 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.0382961668074131, loss=0.24924403429031372
I0208 18:34:12.634016 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:34:14.006392 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:34:15.328653 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:34:16.649898 140466628462400 submission_runner.py:408] Time since start: 3315.11s, 	Step: 13526, 	{'train/ssim': 0.7462560108729771, 'train/loss': 0.2681436708995274, 'validation/ssim': 0.7231661700504713, 'validation/loss': 0.28716347200117825, 'validation/num_examples': 3554, 'test/ssim': 0.7403992943442823, 'test/loss': 0.28855373166320514, 'test/num_examples': 3581, 'score': 3153.0304362773895, 'total_duration': 3315.10955786705, 'accumulated_submission_time': 3153.0304362773895, 'accumulated_eval_time': 160.52774262428284, 'accumulated_logging_time': 1.0317604541778564}
I0208 18:34:16.667761 140244460300032 logging_writer.py:48] [13526] accumulated_eval_time=160.527743, accumulated_logging_time=1.031760, accumulated_submission_time=3153.030436, global_step=13526, preemption_count=0, score=3153.030436, test/loss=0.288554, test/num_examples=3581, test/ssim=0.740399, total_duration=3315.109558, train/loss=0.268144, train/ssim=0.746256, validation/loss=0.287163, validation/num_examples=3554, validation/ssim=0.723166
I0208 18:34:32.063095 140244451907328 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.08773250877857208, loss=0.20642651617527008
I0208 18:34:55.625112 140244460300032 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.1104675754904747, loss=0.2820495069026947
I0208 18:35:19.007483 140244451907328 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.10585982352495193, loss=0.32918447256088257
I0208 18:35:36.779865 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:35:38.152608 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:35:39.476373 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:35:40.798874 140466628462400 submission_runner.py:408] Time since start: 3399.26s, 	Step: 13876, 	{'train/ssim': 0.7469626835414341, 'train/loss': 0.26831698417663574, 'validation/ssim': 0.7242131445202589, 'validation/loss': 0.287253771059018, 'validation/num_examples': 3554, 'test/ssim': 0.7413314056609537, 'test/loss': 0.28866107581681094, 'test/num_examples': 3581, 'score': 3233.1198103427887, 'total_duration': 3399.258532524109, 'accumulated_submission_time': 3233.1198103427887, 'accumulated_eval_time': 164.54671454429626, 'accumulated_logging_time': 1.0586469173431396}
I0208 18:35:40.817291 140244460300032 logging_writer.py:48] [13876] accumulated_eval_time=164.546715, accumulated_logging_time=1.058647, accumulated_submission_time=3233.119810, global_step=13876, preemption_count=0, score=3233.119810, test/loss=0.288661, test/num_examples=3581, test/ssim=0.741331, total_duration=3399.258533, train/loss=0.268317, train/ssim=0.746963, validation/loss=0.287254, validation/num_examples=3554, validation/ssim=0.724213
I0208 18:35:44.668517 140244451907328 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.1275986284017563, loss=0.2534174919128418
I0208 18:36:08.821742 140244460300032 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.07639966905117035, loss=0.24659402668476105
I0208 18:36:32.733248 140244451907328 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.06624554842710495, loss=0.31972843408584595
I0208 18:36:56.507140 140244460300032 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.08199730515480042, loss=0.246845543384552
I0208 18:37:00.878395 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:37:02.251652 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:37:03.574311 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:37:04.895181 140466628462400 submission_runner.py:408] Time since start: 3483.35s, 	Step: 14220, 	{'train/ssim': 0.7435752323695591, 'train/loss': 0.26951163155691965, 'validation/ssim': 0.721224379660242, 'validation/loss': 0.2880564846882474, 'validation/num_examples': 3554, 'test/ssim': 0.7383425408187309, 'test/loss': 0.2895751203181723, 'test/num_examples': 3581, 'score': 3313.1567661762238, 'total_duration': 3483.3548295497894, 'accumulated_submission_time': 3313.1567661762238, 'accumulated_eval_time': 168.5634524822235, 'accumulated_logging_time': 1.0875027179718018}
I0208 18:37:04.913343 140244451907328 logging_writer.py:48] [14220] accumulated_eval_time=168.563452, accumulated_logging_time=1.087503, accumulated_submission_time=3313.156766, global_step=14220, preemption_count=0, score=3313.156766, test/loss=0.289575, test/num_examples=3581, test/ssim=0.738343, total_duration=3483.354830, train/loss=0.269512, train/ssim=0.743575, validation/loss=0.288056, validation/num_examples=3554, validation/ssim=0.721224
I0208 18:37:21.857318 140244460300032 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.04677924886345863, loss=0.2756337523460388
I0208 18:37:45.753183 140244451907328 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.03386487066745758, loss=0.2895433008670807
I0208 18:38:09.471623 140244460300032 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.08743918687105179, loss=0.3328264653682709
I0208 18:38:25.082682 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:38:26.455338 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:38:27.778206 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:38:29.100393 140466628462400 submission_runner.py:408] Time since start: 3567.56s, 	Step: 14567, 	{'train/ssim': 0.7471098899841309, 'train/loss': 0.26741351400102886, 'validation/ssim': 0.7242367754642656, 'validation/loss': 0.28640202665570486, 'validation/num_examples': 3554, 'test/ssim': 0.7413343372574002, 'test/loss': 0.28780746992591105, 'test/num_examples': 3581, 'score': 3393.3027589321136, 'total_duration': 3567.560054063797, 'accumulated_submission_time': 3393.3027589321136, 'accumulated_eval_time': 172.5811402797699, 'accumulated_logging_time': 1.1148772239685059}
I0208 18:38:29.119040 140244451907328 logging_writer.py:48] [14567] accumulated_eval_time=172.581140, accumulated_logging_time=1.114877, accumulated_submission_time=3393.302759, global_step=14567, preemption_count=0, score=3393.302759, test/loss=0.287807, test/num_examples=3581, test/ssim=0.741334, total_duration=3567.560054, train/loss=0.267414, train/ssim=0.747110, validation/loss=0.286402, validation/num_examples=3554, validation/ssim=0.724237
I0208 18:38:34.864024 140244460300032 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.10360925644636154, loss=0.22122399508953094
I0208 18:38:58.525993 140244451907328 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.05309376120567322, loss=0.27107253670692444
I0208 18:39:22.432130 140244460300032 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.05490070953965187, loss=0.28604283928871155
I0208 18:39:46.171554 140244451907328 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.06873461604118347, loss=0.27929067611694336
I0208 18:39:49.268092 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:39:50.641162 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:39:51.962402 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:39:53.285182 140466628462400 submission_runner.py:408] Time since start: 3651.74s, 	Step: 14914, 	{'train/ssim': 0.7454605102539062, 'train/loss': 0.26764837333134245, 'validation/ssim': 0.7230939720209623, 'validation/loss': 0.2864320290242948, 'validation/num_examples': 3554, 'test/ssim': 0.7402175353645979, 'test/loss': 0.2878112878189577, 'test/num_examples': 3581, 'score': 3473.428725004196, 'total_duration': 3651.744841337204, 'accumulated_submission_time': 3473.428725004196, 'accumulated_eval_time': 176.59819197654724, 'accumulated_logging_time': 1.1427075862884521}
I0208 18:39:53.304174 140244460300032 logging_writer.py:48] [14914] accumulated_eval_time=176.598192, accumulated_logging_time=1.142708, accumulated_submission_time=3473.428725, global_step=14914, preemption_count=0, score=3473.428725, test/loss=0.287811, test/num_examples=3581, test/ssim=0.740218, total_duration=3651.744841, train/loss=0.267648, train/ssim=0.745461, validation/loss=0.286432, validation/num_examples=3554, validation/ssim=0.723094
I0208 18:40:11.787294 140244451907328 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.15449675917625427, loss=0.2381875365972519
I0208 18:40:35.618772 140244460300032 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.05939826741814613, loss=0.19426673650741577
I0208 18:40:59.429096 140244451907328 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.07253029197454453, loss=0.19482624530792236
I0208 18:41:13.475739 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:41:14.845927 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:41:16.168467 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:41:17.492091 140466628462400 submission_runner.py:408] Time since start: 3735.95s, 	Step: 15260, 	{'train/ssim': 0.7476382255554199, 'train/loss': 0.2672039951596941, 'validation/ssim': 0.7246152827360017, 'validation/loss': 0.28637049583216095, 'validation/num_examples': 3554, 'test/ssim': 0.7417507603061295, 'test/loss': 0.28775234909505026, 'test/num_examples': 3581, 'score': 3553.576901912689, 'total_duration': 3735.9517509937286, 'accumulated_submission_time': 3553.576901912689, 'accumulated_eval_time': 180.614520072937, 'accumulated_logging_time': 1.1707472801208496}
I0208 18:41:17.510741 140244460300032 logging_writer.py:48] [15260] accumulated_eval_time=180.614520, accumulated_logging_time=1.170747, accumulated_submission_time=3553.576902, global_step=15260, preemption_count=0, score=3553.576902, test/loss=0.287752, test/num_examples=3581, test/ssim=0.741751, total_duration=3735.951751, train/loss=0.267204, train/ssim=0.747638, validation/loss=0.286370, validation/num_examples=3554, validation/ssim=0.724615
I0208 18:41:24.805121 140244451907328 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.18667535483837128, loss=0.22841902077198029
I0208 18:41:48.376763 140244460300032 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.05958487093448639, loss=0.2976619303226471
I0208 18:42:12.138814 140244451907328 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.057056982070207596, loss=0.2627606689929962
I0208 18:42:35.703784 140244460300032 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.05676677078008652, loss=0.3596774637699127
I0208 18:42:37.736026 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:42:39.107983 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:42:40.429764 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:42:41.751700 140466628462400 submission_runner.py:408] Time since start: 3820.21s, 	Step: 15610, 	{'train/ssim': 0.7465495382036481, 'train/loss': 0.26757264137268066, 'validation/ssim': 0.7237017818830894, 'validation/loss': 0.2865305542610439, 'validation/num_examples': 3554, 'test/ssim': 0.7408511010803547, 'test/loss': 0.28797876378804804, 'test/num_examples': 3581, 'score': 3633.7790439128876, 'total_duration': 3820.211359500885, 'accumulated_submission_time': 3633.7790439128876, 'accumulated_eval_time': 184.63018488883972, 'accumulated_logging_time': 1.1982817649841309}
I0208 18:42:41.770201 140244451907328 logging_writer.py:48] [15610] accumulated_eval_time=184.630185, accumulated_logging_time=1.198282, accumulated_submission_time=3633.779044, global_step=15610, preemption_count=0, score=3633.779044, test/loss=0.287979, test/num_examples=3581, test/ssim=0.740851, total_duration=3820.211360, train/loss=0.267573, train/ssim=0.746550, validation/loss=0.286531, validation/num_examples=3554, validation/ssim=0.723702
I0208 18:43:00.920970 140244460300032 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.24777664244174957, loss=0.2567729651927948
I0208 18:43:24.756577 140244451907328 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.029096389189362526, loss=0.2668686509132385
I0208 18:43:48.382988 140244460300032 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.09381110966205597, loss=0.19022461771965027
I0208 18:44:01.833841 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:44:03.205073 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:44:04.528075 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:44:05.849985 140466628462400 submission_runner.py:408] Time since start: 3904.31s, 	Step: 15958, 	{'train/ssim': 0.7465058735438755, 'train/loss': 0.26753524371555876, 'validation/ssim': 0.7236025868739449, 'validation/loss': 0.2864478459570203, 'validation/num_examples': 3554, 'test/ssim': 0.7408671907724798, 'test/loss': 0.28775504207318137, 'test/num_examples': 3581, 'score': 3713.8195548057556, 'total_duration': 3904.3096396923065, 'accumulated_submission_time': 3713.8195548057556, 'accumulated_eval_time': 188.6462926864624, 'accumulated_logging_time': 1.2263374328613281}
I0208 18:44:05.870061 140244451907328 logging_writer.py:48] [15958] accumulated_eval_time=188.646293, accumulated_logging_time=1.226337, accumulated_submission_time=3713.819555, global_step=15958, preemption_count=0, score=3713.819555, test/loss=0.287755, test/num_examples=3581, test/ssim=0.740867, total_duration=3904.309640, train/loss=0.267535, train/ssim=0.746506, validation/loss=0.286448, validation/num_examples=3554, validation/ssim=0.723603
I0208 18:44:13.664659 140244460300032 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.13156725466251373, loss=0.26222237944602966
I0208 18:44:37.863390 140244451907328 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.035629790276288986, loss=0.24279022216796875
I0208 18:45:01.421013 140244460300032 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.06344441324472427, loss=0.2138945758342743
I0208 18:45:25.208800 140244451907328 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.09459954500198364, loss=0.24193087220191956
I0208 18:45:26.062857 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:45:27.437866 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:45:28.762220 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:45:30.084353 140466628462400 submission_runner.py:408] Time since start: 3988.54s, 	Step: 16305, 	{'train/ssim': 0.7472934722900391, 'train/loss': 0.2676750591823033, 'validation/ssim': 0.7245056461469471, 'validation/loss': 0.28667465836799205, 'validation/num_examples': 3554, 'test/ssim': 0.7417191263351718, 'test/loss': 0.2879381645860968, 'test/num_examples': 3581, 'score': 3793.9894206523895, 'total_duration': 3988.544013738632, 'accumulated_submission_time': 3793.9894206523895, 'accumulated_eval_time': 192.66775226593018, 'accumulated_logging_time': 1.255561113357544}
I0208 18:45:30.103426 140244460300032 logging_writer.py:48] [16305] accumulated_eval_time=192.667752, accumulated_logging_time=1.255561, accumulated_submission_time=3793.989421, global_step=16305, preemption_count=0, score=3793.989421, test/loss=0.287938, test/num_examples=3581, test/ssim=0.741719, total_duration=3988.544014, train/loss=0.267675, train/ssim=0.747293, validation/loss=0.286675, validation/num_examples=3554, validation/ssim=0.724506
I0208 18:45:50.571792 140244451907328 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.043313149362802505, loss=0.286835640668869
I0208 18:46:14.408258 140244460300032 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.07372119277715683, loss=0.33365488052368164
I0208 18:46:37.797494 140244451907328 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.12566709518432617, loss=0.32669317722320557
I0208 18:46:50.240010 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:46:51.612351 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:46:52.934125 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:46:54.254814 140466628462400 submission_runner.py:408] Time since start: 4072.71s, 	Step: 16653, 	{'train/ssim': 0.7460013798304966, 'train/loss': 0.26769552912030903, 'validation/ssim': 0.72336675829611, 'validation/loss': 0.2865367024281619, 'validation/num_examples': 3554, 'test/ssim': 0.7405575323757331, 'test/loss': 0.28791178021807806, 'test/num_examples': 3581, 'score': 3874.1030700206757, 'total_duration': 4072.714470386505, 'accumulated_submission_time': 3874.1030700206757, 'accumulated_eval_time': 196.6825180053711, 'accumulated_logging_time': 1.2838151454925537}
I0208 18:46:54.276719 140244460300032 logging_writer.py:48] [16653] accumulated_eval_time=196.682518, accumulated_logging_time=1.283815, accumulated_submission_time=3874.103070, global_step=16653, preemption_count=0, score=3874.103070, test/loss=0.287912, test/num_examples=3581, test/ssim=0.740558, total_duration=4072.714470, train/loss=0.267696, train/ssim=0.746001, validation/loss=0.286537, validation/num_examples=3554, validation/ssim=0.723367
I0208 18:47:03.526401 140244451907328 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.05436118692159653, loss=0.2335008829832077
I0208 18:47:27.207674 140244460300032 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.07544293254613876, loss=0.22663477063179016
I0208 18:47:50.945022 140244451907328 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.032261885702610016, loss=0.43366533517837524
I0208 18:48:14.322167 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:48:15.696930 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:48:17.017930 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:48:18.342002 140466628462400 submission_runner.py:408] Time since start: 4156.80s, 	Step: 16999, 	{'train/ssim': 0.7481280054364886, 'train/loss': 0.2673676184245518, 'validation/ssim': 0.7252748883300506, 'validation/loss': 0.2864205398516636, 'validation/num_examples': 3554, 'test/ssim': 0.7424530480967257, 'test/loss': 0.28772518069542374, 'test/num_examples': 3581, 'score': 3954.1229753494263, 'total_duration': 4156.801654577255, 'accumulated_submission_time': 3954.1229753494263, 'accumulated_eval_time': 200.70232272148132, 'accumulated_logging_time': 1.3174071311950684}
I0208 18:48:18.360729 140244460300032 logging_writer.py:48] [16999] accumulated_eval_time=200.702323, accumulated_logging_time=1.317407, accumulated_submission_time=3954.122975, global_step=16999, preemption_count=0, score=3954.122975, test/loss=0.287725, test/num_examples=3581, test/ssim=0.742453, total_duration=4156.801655, train/loss=0.267368, train/ssim=0.748128, validation/loss=0.286421, validation/num_examples=3554, validation/ssim=0.725275
I0208 18:48:18.525617 140244451907328 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.06641296297311783, loss=0.2249804139137268
I0208 18:48:40.184877 140244460300032 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.043611012399196625, loss=0.2698776423931122
I0208 18:49:04.202649 140244451907328 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.10514993965625763, loss=0.2730516791343689
I0208 18:49:28.466959 140244460300032 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.05099064111709595, loss=0.30803439021110535
I0208 18:49:38.387330 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:49:39.761144 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:49:41.082723 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:49:42.407987 140466628462400 submission_runner.py:408] Time since start: 4240.87s, 	Step: 17344, 	{'train/ssim': 0.746361528124128, 'train/loss': 0.2677748032978603, 'validation/ssim': 0.7239071787510551, 'validation/loss': 0.28663830174847005, 'validation/num_examples': 3554, 'test/ssim': 0.7410125434148981, 'test/loss': 0.28796458304244626, 'test/num_examples': 3581, 'score': 4034.1249663829803, 'total_duration': 4240.8676471710205, 'accumulated_submission_time': 4034.1249663829803, 'accumulated_eval_time': 204.7229642868042, 'accumulated_logging_time': 1.3461709022521973}
I0208 18:49:42.426525 140244451907328 logging_writer.py:48] [17344] accumulated_eval_time=204.722964, accumulated_logging_time=1.346171, accumulated_submission_time=4034.124966, global_step=17344, preemption_count=0, score=4034.124966, test/loss=0.287965, test/num_examples=3581, test/ssim=0.741013, total_duration=4240.867647, train/loss=0.267775, train/ssim=0.746362, validation/loss=0.286638, validation/num_examples=3554, validation/ssim=0.723907
I0208 18:49:53.659390 140244460300032 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.10437580198049545, loss=0.29690563678741455
I0208 18:50:17.313110 140244451907328 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.06761067360639572, loss=0.28368091583251953
I0208 18:50:40.921015 140244460300032 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.06677240133285522, loss=0.27523374557495117
I0208 18:51:02.511183 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:51:03.882105 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:51:05.201393 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:51:06.527825 140466628462400 submission_runner.py:408] Time since start: 4324.99s, 	Step: 17693, 	{'train/ssim': 0.748692240033831, 'train/loss': 0.26730574880327496, 'validation/ssim': 0.7252666449774902, 'validation/loss': 0.28687419902090955, 'validation/num_examples': 3554, 'test/ssim': 0.7423913482180257, 'test/loss': 0.28826963951453854, 'test/num_examples': 3581, 'score': 4114.188055753708, 'total_duration': 4324.98748755455, 'accumulated_submission_time': 4114.188055753708, 'accumulated_eval_time': 208.73958683013916, 'accumulated_logging_time': 1.3738317489624023}
I0208 18:51:06.547241 140244451907328 logging_writer.py:48] [17693] accumulated_eval_time=208.739587, accumulated_logging_time=1.373832, accumulated_submission_time=4114.188056, global_step=17693, preemption_count=0, score=4114.188056, test/loss=0.288270, test/num_examples=3581, test/ssim=0.742391, total_duration=4324.987488, train/loss=0.267306, train/ssim=0.748692, validation/loss=0.286874, validation/num_examples=3554, validation/ssim=0.725267
I0208 18:51:07.150215 140244460300032 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.03673509880900383, loss=0.21688397228717804
I0208 18:51:29.650965 140244451907328 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.11296140402555466, loss=0.3055378198623657
I0208 18:51:53.199095 140244460300032 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.044012077152729034, loss=0.33988523483276367
I0208 18:52:17.110770 140244451907328 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.04670536518096924, loss=0.2756301164627075
I0208 18:52:26.730782 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:52:28.106184 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:52:29.427969 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:52:30.747280 140466628462400 submission_runner.py:408] Time since start: 4409.21s, 	Step: 18042, 	{'train/ssim': 0.7466691562107631, 'train/loss': 0.2669903721128191, 'validation/ssim': 0.7238836165016531, 'validation/loss': 0.28597083062218626, 'validation/num_examples': 3554, 'test/ssim': 0.7410724025237364, 'test/loss': 0.2873323808599204, 'test/num_examples': 3581, 'score': 4194.349546909332, 'total_duration': 4409.206943273544, 'accumulated_submission_time': 4194.349546909332, 'accumulated_eval_time': 212.75606155395508, 'accumulated_logging_time': 1.402545690536499}
I0208 18:52:30.766146 140244460300032 logging_writer.py:48] [18042] accumulated_eval_time=212.756062, accumulated_logging_time=1.402546, accumulated_submission_time=4194.349547, global_step=18042, preemption_count=0, score=4194.349547, test/loss=0.287332, test/num_examples=3581, test/ssim=0.741072, total_duration=4409.206943, train/loss=0.266990, train/ssim=0.746669, validation/loss=0.285971, validation/num_examples=3554, validation/ssim=0.723884
I0208 18:52:42.342853 140244451907328 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.07098177820444107, loss=0.2290954291820526
I0208 18:53:05.795830 140244460300032 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.03584900498390198, loss=0.23658853769302368
I0208 18:53:29.924642 140244451907328 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.07798344641923904, loss=0.3100932538509369
I0208 18:53:50.879342 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:53:52.249998 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:53:53.573998 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:53:54.896463 140466628462400 submission_runner.py:408] Time since start: 4493.36s, 	Step: 18389, 	{'train/ssim': 0.7479186739240374, 'train/loss': 0.2667764595576695, 'validation/ssim': 0.7248502869785804, 'validation/loss': 0.28601907140831634, 'validation/num_examples': 3554, 'test/ssim': 0.7420026730705459, 'test/loss': 0.28740887507417623, 'test/num_examples': 3581, 'score': 4274.440649032593, 'total_duration': 4493.3561198711395, 'accumulated_submission_time': 4274.440649032593, 'accumulated_eval_time': 216.77316308021545, 'accumulated_logging_time': 1.4304280281066895}
I0208 18:53:54.919311 140244460300032 logging_writer.py:48] [18389] accumulated_eval_time=216.773163, accumulated_logging_time=1.430428, accumulated_submission_time=4274.440649, global_step=18389, preemption_count=0, score=4274.440649, test/loss=0.287409, test/num_examples=3581, test/ssim=0.742003, total_duration=4493.356120, train/loss=0.266776, train/ssim=0.747919, validation/loss=0.286019, validation/num_examples=3554, validation/ssim=0.724850
I0208 18:53:59.098977 140244451907328 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.05123644322156906, loss=0.3329923748970032
I0208 18:54:22.893959 140244460300032 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.0747217983007431, loss=0.2547711133956909
I0208 18:54:47.054568 140244451907328 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.03824590519070625, loss=0.293435662984848
I0208 18:55:10.786594 140244460300032 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.09790103882551193, loss=0.2787012457847595
I0208 18:55:15.146873 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:55:16.522215 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:55:17.842723 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:55:19.163786 140466628462400 submission_runner.py:408] Time since start: 4577.62s, 	Step: 18720, 	{'train/ssim': 0.7479407446725028, 'train/loss': 0.26627884592328754, 'validation/ssim': 0.7245068826498312, 'validation/loss': 0.285733319026537, 'validation/num_examples': 3554, 'test/ssim': 0.7416746069751815, 'test/loss': 0.28710596616692263, 'test/num_examples': 3581, 'score': 4351.382478237152, 'total_duration': 4577.62344622612, 'accumulated_submission_time': 4351.382478237152, 'accumulated_eval_time': 220.79004406929016, 'accumulated_logging_time': 4.727059602737427}
I0208 18:55:19.184052 140244451907328 logging_writer.py:48] [18720] accumulated_eval_time=220.790044, accumulated_logging_time=4.727060, accumulated_submission_time=4351.382478, global_step=18720, preemption_count=0, score=4351.382478, test/loss=0.287106, test/num_examples=3581, test/ssim=0.741675, total_duration=4577.623446, train/loss=0.266279, train/ssim=0.747941, validation/loss=0.285733, validation/num_examples=3554, validation/ssim=0.724507
I0208 18:55:35.921052 140244460300032 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.10152677446603775, loss=0.2851381301879883
I0208 18:55:59.589432 140244451907328 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.07170262187719345, loss=0.2432592213153839
I0208 18:56:23.204919 140244460300032 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.05466786026954651, loss=0.2728983461856842
I0208 18:56:39.306586 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:56:40.679810 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:56:42.000692 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:56:43.319645 140466628462400 submission_runner.py:408] Time since start: 4661.78s, 	Step: 19068, 	{'train/ssim': 0.7482282093593052, 'train/loss': 0.2664348908833095, 'validation/ssim': 0.7249527106341446, 'validation/loss': 0.2857875362432734, 'validation/num_examples': 3554, 'test/ssim': 0.7421484347729336, 'test/loss': 0.2871270327553407, 'test/num_examples': 3581, 'score': 4431.4831800460815, 'total_duration': 4661.779294967651, 'accumulated_submission_time': 4431.4831800460815, 'accumulated_eval_time': 224.80307006835938, 'accumulated_logging_time': 4.756349325180054}
I0208 18:56:43.339762 140244451907328 logging_writer.py:48] [19068] accumulated_eval_time=224.803070, accumulated_logging_time=4.756349, accumulated_submission_time=4431.483180, global_step=19068, preemption_count=0, score=4431.483180, test/loss=0.287127, test/num_examples=3581, test/ssim=0.742148, total_duration=4661.779295, train/loss=0.266435, train/ssim=0.748228, validation/loss=0.285788, validation/num_examples=3554, validation/ssim=0.724953
I0208 18:56:48.848336 140244460300032 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.06460481137037277, loss=0.3035511076450348
I0208 18:57:12.834490 140244451907328 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.11344452202320099, loss=0.2253667414188385
I0208 18:57:36.414122 140244460300032 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.08486169576644897, loss=0.23728781938552856
I0208 18:58:00.549971 140244451907328 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.08872193843126297, loss=0.22213447093963623
I0208 18:58:03.538415 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:58:04.910038 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:58:06.229670 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:58:07.550006 140466628462400 submission_runner.py:408] Time since start: 4746.01s, 	Step: 19413, 	{'train/ssim': 0.747701713017055, 'train/loss': 0.2666091578347342, 'validation/ssim': 0.7246733296769485, 'validation/loss': 0.28584989377066333, 'validation/num_examples': 3554, 'test/ssim': 0.7418394581428023, 'test/loss': 0.28721603738699036, 'test/num_examples': 3581, 'score': 4511.659183979034, 'total_duration': 4746.009649276733, 'accumulated_submission_time': 4511.659183979034, 'accumulated_eval_time': 228.81460237503052, 'accumulated_logging_time': 4.786910057067871}
I0208 18:58:07.569548 140244460300032 logging_writer.py:48] [19413] accumulated_eval_time=228.814602, accumulated_logging_time=4.786910, accumulated_submission_time=4511.659184, global_step=19413, preemption_count=0, score=4511.659184, test/loss=0.287216, test/num_examples=3581, test/ssim=0.741839, total_duration=4746.009649, train/loss=0.266609, train/ssim=0.747702, validation/loss=0.285850, validation/num_examples=3554, validation/ssim=0.724673
I0208 18:58:25.878324 140244451907328 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.11727526038885117, loss=0.3287206292152405
I0208 18:58:49.887194 140244460300032 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.035288456827402115, loss=0.2930935323238373
I0208 18:59:14.132663 140244451907328 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.1051492691040039, loss=0.3334423899650574
I0208 18:59:27.764882 140466628462400 spec.py:321] Evaluating on the training split.
I0208 18:59:29.136453 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 18:59:30.459181 140466628462400 spec.py:349] Evaluating on the test split.
I0208 18:59:31.780555 140466628462400 submission_runner.py:408] Time since start: 4830.24s, 	Step: 19760, 	{'train/ssim': 0.7489380155290876, 'train/loss': 0.26600561823163715, 'validation/ssim': 0.7252018659652856, 'validation/loss': 0.28576849066412846, 'validation/num_examples': 3554, 'test/ssim': 0.7423292392793563, 'test/loss': 0.28718453976935565, 'test/num_examples': 3581, 'score': 4591.8332052230835, 'total_duration': 4830.240214586258, 'accumulated_submission_time': 4591.8332052230835, 'accumulated_eval_time': 232.8302583694458, 'accumulated_logging_time': 4.815237998962402}
I0208 18:59:31.800354 140244460300032 logging_writer.py:48] [19760] accumulated_eval_time=232.830258, accumulated_logging_time=4.815238, accumulated_submission_time=4591.833205, global_step=19760, preemption_count=0, score=4591.833205, test/loss=0.287185, test/num_examples=3581, test/ssim=0.742329, total_duration=4830.240215, train/loss=0.266006, train/ssim=0.748938, validation/loss=0.285768, validation/num_examples=3554, validation/ssim=0.725202
I0208 18:59:39.157922 140244451907328 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.06571169942617416, loss=0.2487373650074005
I0208 19:00:02.790169 140244460300032 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.05725422129034996, loss=0.23147764801979065
I0208 19:00:26.376272 140244451907328 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.05232858657836914, loss=0.23396556079387665
I0208 19:00:49.825685 140244460300032 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.03635398671030998, loss=0.35237279534339905
I0208 19:00:51.892655 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:00:53.267082 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:00:54.589184 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:00:55.911642 140466628462400 submission_runner.py:408] Time since start: 4914.37s, 	Step: 20110, 	{'train/ssim': 0.7484143120901925, 'train/loss': 0.26632281712123324, 'validation/ssim': 0.724964320022334, 'validation/loss': 0.28584302431019626, 'validation/num_examples': 3554, 'test/ssim': 0.7421734556077213, 'test/loss': 0.28721054916573585, 'test/num_examples': 3581, 'score': 4671.902544498444, 'total_duration': 4914.371288776398, 'accumulated_submission_time': 4671.902544498444, 'accumulated_eval_time': 236.84919047355652, 'accumulated_logging_time': 4.845395565032959}
I0208 19:00:55.932655 140244451907328 logging_writer.py:48] [20110] accumulated_eval_time=236.849190, accumulated_logging_time=4.845396, accumulated_submission_time=4671.902544, global_step=20110, preemption_count=0, score=4671.902544, test/loss=0.287211, test/num_examples=3581, test/ssim=0.742173, total_duration=4914.371289, train/loss=0.266323, train/ssim=0.748414, validation/loss=0.285843, validation/num_examples=3554, validation/ssim=0.724964
I0208 19:01:15.407828 140244460300032 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.10722703486680984, loss=0.2806961238384247
I0208 19:01:39.187745 140244451907328 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.0646694228053093, loss=0.2634599208831787
I0208 19:02:03.135513 140244460300032 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.1125420406460762, loss=0.28128454089164734
I0208 19:02:16.100255 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:02:17.472507 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:02:18.794757 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:02:20.115983 140466628462400 submission_runner.py:408] Time since start: 4998.58s, 	Step: 20456, 	{'train/ssim': 0.7484644481113979, 'train/loss': 0.2665191377912249, 'validation/ssim': 0.7253575279394696, 'validation/loss': 0.2858613657696434, 'validation/num_examples': 3554, 'test/ssim': 0.7424498437936331, 'test/loss': 0.28725380725748745, 'test/num_examples': 3581, 'score': 4752.0476224422455, 'total_duration': 4998.575645685196, 'accumulated_submission_time': 4752.0476224422455, 'accumulated_eval_time': 240.86488962173462, 'accumulated_logging_time': 4.876446485519409}
I0208 19:02:20.135835 140244451907328 logging_writer.py:48] [20456] accumulated_eval_time=240.864890, accumulated_logging_time=4.876446, accumulated_submission_time=4752.047622, global_step=20456, preemption_count=0, score=4752.047622, test/loss=0.287254, test/num_examples=3581, test/ssim=0.742450, total_duration=4998.575646, train/loss=0.266519, train/ssim=0.748464, validation/loss=0.285861, validation/num_examples=3554, validation/ssim=0.725358
I0208 19:02:28.909824 140244460300032 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.11890465021133423, loss=0.23478753864765167
I0208 19:02:52.486341 140244451907328 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.1017528846859932, loss=0.2897319793701172
I0208 19:03:16.109576 140244460300032 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.05778784677386284, loss=0.2632291615009308
I0208 19:03:39.432503 140244451907328 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.05991637706756592, loss=0.2588481605052948
I0208 19:03:40.299604 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:03:41.673288 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:03:42.993934 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:03:44.317123 140466628462400 submission_runner.py:408] Time since start: 5082.78s, 	Step: 20805, 	{'train/ssim': 0.7486716679164341, 'train/loss': 0.26592150756290983, 'validation/ssim': 0.7250687358214336, 'validation/loss': 0.28558404565058737, 'validation/num_examples': 3554, 'test/ssim': 0.7422169523177883, 'test/loss': 0.2869579205463732, 'test/num_examples': 3581, 'score': 4832.189853668213, 'total_duration': 5082.776785135269, 'accumulated_submission_time': 4832.189853668213, 'accumulated_eval_time': 244.88236665725708, 'accumulated_logging_time': 4.90512490272522}
I0208 19:03:44.337560 140244460300032 logging_writer.py:48] [20805] accumulated_eval_time=244.882367, accumulated_logging_time=4.905125, accumulated_submission_time=4832.189854, global_step=20805, preemption_count=0, score=4832.189854, test/loss=0.286958, test/num_examples=3581, test/ssim=0.742217, total_duration=5082.776785, train/loss=0.265922, train/ssim=0.748672, validation/loss=0.285584, validation/num_examples=3554, validation/ssim=0.725069
I0208 19:04:04.868747 140244451907328 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.04432998597621918, loss=0.3344815671443939
I0208 19:04:28.770687 140244460300032 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.07248468697071075, loss=0.30827420949935913
I0208 19:04:52.539897 140244451907328 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.048814501613378525, loss=0.2332744300365448
I0208 19:05:04.478765 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:05:05.850372 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:05:07.170243 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:05:08.490217 140466628462400 submission_runner.py:408] Time since start: 5166.95s, 	Step: 21151, 	{'train/ssim': 0.748410837990897, 'train/loss': 0.2661462851933071, 'validation/ssim': 0.7249383534617684, 'validation/loss': 0.2856016486430343, 'validation/num_examples': 3554, 'test/ssim': 0.7421067788327282, 'test/loss': 0.28694370571244066, 'test/num_examples': 3581, 'score': 4912.309539794922, 'total_duration': 5166.949881315231, 'accumulated_submission_time': 4912.309539794922, 'accumulated_eval_time': 248.89379501342773, 'accumulated_logging_time': 4.9343202114105225}
I0208 19:05:08.510372 140244460300032 logging_writer.py:48] [21151] accumulated_eval_time=248.893795, accumulated_logging_time=4.934320, accumulated_submission_time=4912.309540, global_step=21151, preemption_count=0, score=4912.309540, test/loss=0.286944, test/num_examples=3581, test/ssim=0.742107, total_duration=5166.949881, train/loss=0.266146, train/ssim=0.748411, validation/loss=0.285602, validation/num_examples=3554, validation/ssim=0.724938
I0208 19:05:18.073845 140244451907328 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.0784749910235405, loss=0.28608810901641846
I0208 19:05:41.559816 140244460300032 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.05561314895749092, loss=0.31147971749305725
I0208 19:06:05.323247 140244451907328 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.08286160230636597, loss=0.2624039947986603
I0208 19:06:28.545895 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:06:29.921545 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:06:31.242912 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:06:32.562538 140466628462400 submission_runner.py:408] Time since start: 5251.02s, 	Step: 21499, 	{'train/ssim': 0.7486587933131627, 'train/loss': 0.26630115509033203, 'validation/ssim': 0.7253595200830051, 'validation/loss': 0.28571490887248524, 'validation/num_examples': 3554, 'test/ssim': 0.7424884999607303, 'test/loss': 0.2870643443150482, 'test/num_examples': 3581, 'score': 4992.323907136917, 'total_duration': 5251.02219581604, 'accumulated_submission_time': 4992.323907136917, 'accumulated_eval_time': 252.9103980064392, 'accumulated_logging_time': 4.963292837142944}
I0208 19:06:32.582998 140244460300032 logging_writer.py:48] [21499] accumulated_eval_time=252.910398, accumulated_logging_time=4.963293, accumulated_submission_time=4992.323907, global_step=21499, preemption_count=0, score=4992.323907, test/loss=0.287064, test/num_examples=3581, test/ssim=0.742488, total_duration=5251.022196, train/loss=0.266301, train/ssim=0.748659, validation/loss=0.285715, validation/num_examples=3554, validation/ssim=0.725360
I0208 19:06:32.747578 140244451907328 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.05664854496717453, loss=0.216708242893219
I0208 19:06:54.892937 140244460300032 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.0641094222664833, loss=0.24879758059978485
I0208 19:07:18.988158 140244451907328 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.037364661693573, loss=0.3287077844142914
I0208 19:07:42.436797 140244460300032 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.12735705077648163, loss=0.2670353055000305
I0208 19:07:52.698740 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:07:54.071037 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:07:55.394166 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:07:56.718076 140466628462400 submission_runner.py:408] Time since start: 5335.18s, 	Step: 21844, 	{'train/ssim': 0.7488077027457101, 'train/loss': 0.26583780561174664, 'validation/ssim': 0.7251955460616559, 'validation/loss': 0.28563822852002146, 'validation/num_examples': 3554, 'test/ssim': 0.74234614709142, 'test/loss': 0.28698955451733105, 'test/num_examples': 3581, 'score': 5072.416844844818, 'total_duration': 5335.177726268768, 'accumulated_submission_time': 5072.416844844818, 'accumulated_eval_time': 256.9296944141388, 'accumulated_logging_time': 4.993821382522583}
I0208 19:07:56.739124 140244451907328 logging_writer.py:48] [21844] accumulated_eval_time=256.929694, accumulated_logging_time=4.993821, accumulated_submission_time=5072.416845, global_step=21844, preemption_count=0, score=5072.416845, test/loss=0.286990, test/num_examples=3581, test/ssim=0.742346, total_duration=5335.177726, train/loss=0.265838, train/ssim=0.748808, validation/loss=0.285638, validation/num_examples=3554, validation/ssim=0.725196
I0208 19:08:08.039693 140244460300032 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.052334196865558624, loss=0.22983813285827637
I0208 19:08:31.519911 140244451907328 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.0645688995718956, loss=0.2395162582397461
I0208 19:08:55.257190 140244460300032 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.05769426003098488, loss=0.30429214239120483
I0208 19:09:16.889311 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:09:18.263409 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:09:19.586172 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:09:20.910832 140466628462400 submission_runner.py:408] Time since start: 5419.37s, 	Step: 22193, 	{'train/ssim': 0.7486767087663923, 'train/loss': 0.2658830199922834, 'validation/ssim': 0.7250403649497046, 'validation/loss': 0.2855381576546673, 'validation/num_examples': 3554, 'test/ssim': 0.7422395869694219, 'test/loss': 0.2869001408257121, 'test/num_examples': 3581, 'score': 5152.545783519745, 'total_duration': 5419.370491504669, 'accumulated_submission_time': 5152.545783519745, 'accumulated_eval_time': 260.95118141174316, 'accumulated_logging_time': 5.023503065109253}
I0208 19:09:20.931289 140244451907328 logging_writer.py:48] [22193] accumulated_eval_time=260.951181, accumulated_logging_time=5.023503, accumulated_submission_time=5152.545784, global_step=22193, preemption_count=0, score=5152.545784, test/loss=0.286900, test/num_examples=3581, test/ssim=0.742240, total_duration=5419.370492, train/loss=0.265883, train/ssim=0.748677, validation/loss=0.285538, validation/num_examples=3554, validation/ssim=0.725040
I0208 19:09:21.529828 140244460300032 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.07434592396020889, loss=0.2585563063621521
I0208 19:09:44.108484 140244451907328 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.0676276832818985, loss=0.32847926020622253
I0208 19:10:08.031807 140244460300032 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.04067966714501381, loss=0.22608107328414917
I0208 19:10:31.478153 140244451907328 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.09638819098472595, loss=0.2249898761510849
I0208 19:10:41.161161 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:10:42.535032 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:10:43.854646 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:10:45.177670 140466628462400 submission_runner.py:408] Time since start: 5503.64s, 	Step: 22543, 	{'train/ssim': 0.7485130855015346, 'train/loss': 0.26599107469831196, 'validation/ssim': 0.7248971366989659, 'validation/loss': 0.2855696197836065, 'validation/num_examples': 3554, 'test/ssim': 0.7420529192701061, 'test/loss': 0.2869052881636589, 'test/num_examples': 3581, 'score': 5232.754349708557, 'total_duration': 5503.637329339981, 'accumulated_submission_time': 5232.754349708557, 'accumulated_eval_time': 264.9676489830017, 'accumulated_logging_time': 5.052587985992432}
I0208 19:10:45.199785 140244460300032 logging_writer.py:48] [22543] accumulated_eval_time=264.967649, accumulated_logging_time=5.052588, accumulated_submission_time=5232.754350, global_step=22543, preemption_count=0, score=5232.754350, test/loss=0.286905, test/num_examples=3581, test/ssim=0.742053, total_duration=5503.637329, train/loss=0.265991, train/ssim=0.748513, validation/loss=0.285570, validation/num_examples=3554, validation/ssim=0.724897
I0208 19:10:56.786102 140244451907328 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.07929487526416779, loss=0.21658442914485931
I0208 19:11:21.207222 140244460300032 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.08714699745178223, loss=0.29739171266555786
I0208 19:11:45.165695 140244451907328 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.05737670883536339, loss=0.26417145133018494
I0208 19:12:05.383781 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:12:06.758817 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:12:08.078137 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:12:09.401505 140466628462400 submission_runner.py:408] Time since start: 5587.86s, 	Step: 22886, 	{'train/ssim': 0.748805318559919, 'train/loss': 0.26593383720942904, 'validation/ssim': 0.7251649769625774, 'validation/loss': 0.2858411352085678, 'validation/num_examples': 3554, 'test/ssim': 0.7422529495950851, 'test/loss': 0.2871465653688739, 'test/num_examples': 3581, 'score': 5312.916896104813, 'total_duration': 5587.861164093018, 'accumulated_submission_time': 5312.916896104813, 'accumulated_eval_time': 268.98533368110657, 'accumulated_logging_time': 5.083728313446045}
I0208 19:12:09.422158 140244460300032 logging_writer.py:48] [22886] accumulated_eval_time=268.985334, accumulated_logging_time=5.083728, accumulated_submission_time=5312.916896, global_step=22886, preemption_count=0, score=5312.916896, test/loss=0.287147, test/num_examples=3581, test/ssim=0.742253, total_duration=5587.861164, train/loss=0.265934, train/ssim=0.748805, validation/loss=0.285841, validation/num_examples=3554, validation/ssim=0.725165
I0208 19:12:10.727122 140244451907328 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.06882065534591675, loss=0.20583325624465942
I0208 19:12:34.424025 140244460300032 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.05668063089251518, loss=0.2571927607059479
I0208 19:12:58.044808 140244451907328 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.04001922160387039, loss=0.31600627303123474
I0208 19:13:22.290830 140244460300032 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.03430871665477753, loss=0.27276352047920227
I0208 19:13:29.407333 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:13:30.782070 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:13:32.103071 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:13:33.423535 140466628462400 submission_runner.py:408] Time since start: 5671.88s, 	Step: 23231, 	{'train/ssim': 0.7487833840506417, 'train/loss': 0.2657624823706491, 'validation/ssim': 0.7251254775648917, 'validation/loss': 0.28551413171668366, 'validation/num_examples': 3554, 'test/ssim': 0.7422787885498116, 'test/loss': 0.2868351002905962, 'test/num_examples': 3581, 'score': 5392.880267381668, 'total_duration': 5671.883190155029, 'accumulated_submission_time': 5392.880267381668, 'accumulated_eval_time': 273.00149416923523, 'accumulated_logging_time': 5.113495111465454}
I0208 19:13:33.444123 140244451907328 logging_writer.py:48] [23231] accumulated_eval_time=273.001494, accumulated_logging_time=5.113495, accumulated_submission_time=5392.880267, global_step=23231, preemption_count=0, score=5392.880267, test/loss=0.286835, test/num_examples=3581, test/ssim=0.742279, total_duration=5671.883190, train/loss=0.265762, train/ssim=0.748783, validation/loss=0.285514, validation/num_examples=3554, validation/ssim=0.725125
I0208 19:13:47.627863 140244460300032 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.051335640251636505, loss=0.2627224028110504
I0208 19:14:11.517153 140244451907328 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.03099445067346096, loss=0.30057811737060547
I0208 19:14:35.468518 140244460300032 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.057876862585544586, loss=0.27158305048942566
I0208 19:14:53.468353 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:14:54.842960 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:14:56.163404 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:14:57.483927 140466628462400 submission_runner.py:408] Time since start: 5755.94s, 	Step: 23577, 	{'train/ssim': 0.7490690095084054, 'train/loss': 0.2659006799970354, 'validation/ssim': 0.725525623637099, 'validation/loss': 0.28556184011962754, 'validation/num_examples': 3554, 'test/ssim': 0.7426354206663641, 'test/loss': 0.2869184462593375, 'test/num_examples': 3581, 'score': 5472.882793188095, 'total_duration': 5755.94358754158, 'accumulated_submission_time': 5472.882793188095, 'accumulated_eval_time': 277.0170331001282, 'accumulated_logging_time': 5.143171548843384}
I0208 19:14:57.505194 140244451907328 logging_writer.py:48] [23577] accumulated_eval_time=277.017033, accumulated_logging_time=5.143172, accumulated_submission_time=5472.882793, global_step=23577, preemption_count=0, score=5472.882793, test/loss=0.286918, test/num_examples=3581, test/ssim=0.742635, total_duration=5755.943588, train/loss=0.265901, train/ssim=0.749069, validation/loss=0.285562, validation/num_examples=3554, validation/ssim=0.725526
I0208 19:15:00.865854 140244460300032 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.1335948407649994, loss=0.2570532262325287
I0208 19:15:25.201208 140244451907328 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.04158831015229225, loss=0.2851256728172302
I0208 19:15:48.918782 140244460300032 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.053166791796684265, loss=0.2913908362388611
I0208 19:16:12.786877 140244451907328 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.05474826321005821, loss=0.22818902134895325
I0208 19:16:17.588966 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:16:18.962338 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:16:20.283523 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:16:21.606599 140466628462400 submission_runner.py:408] Time since start: 5840.07s, 	Step: 23922, 	{'train/ssim': 0.749016353062221, 'train/loss': 0.2657322883605957, 'validation/ssim': 0.7253279205648565, 'validation/loss': 0.28553977197787705, 'validation/num_examples': 3554, 'test/ssim': 0.7424687287288816, 'test/loss': 0.28693204750331613, 'test/num_examples': 3581, 'score': 5552.945104598999, 'total_duration': 5840.066252231598, 'accumulated_submission_time': 5552.945104598999, 'accumulated_eval_time': 281.03462076187134, 'accumulated_logging_time': 5.173579931259155}
I0208 19:16:21.627603 140244460300032 logging_writer.py:48] [23922] accumulated_eval_time=281.034621, accumulated_logging_time=5.173580, accumulated_submission_time=5552.945105, global_step=23922, preemption_count=0, score=5552.945105, test/loss=0.286932, test/num_examples=3581, test/ssim=0.742469, total_duration=5840.066252, train/loss=0.265732, train/ssim=0.749016, validation/loss=0.285540, validation/num_examples=3554, validation/ssim=0.725328
I0208 19:16:38.222744 140244451907328 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.05222874879837036, loss=0.1887497454881668
I0208 19:17:02.055815 140244460300032 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.040443118661642075, loss=0.3495168089866638
I0208 19:17:25.963835 140244451907328 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.11366317421197891, loss=0.2744722068309784
I0208 19:17:41.612981 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:17:42.987783 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:17:44.313284 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:17:45.637011 140466628462400 submission_runner.py:408] Time since start: 5924.10s, 	Step: 24267, 	{'train/ssim': 0.7493527276175362, 'train/loss': 0.2656536953789847, 'validation/ssim': 0.7255556431793402, 'validation/loss': 0.2854886288446996, 'validation/num_examples': 3554, 'test/ssim': 0.742668554523876, 'test/loss': 0.2868933231595574, 'test/num_examples': 3581, 'score': 5632.908239126205, 'total_duration': 5924.096672773361, 'accumulated_submission_time': 5632.908239126205, 'accumulated_eval_time': 285.0586128234863, 'accumulated_logging_time': 5.204019546508789}
I0208 19:17:45.658456 140244460300032 logging_writer.py:48] [24267] accumulated_eval_time=285.058613, accumulated_logging_time=5.204020, accumulated_submission_time=5632.908239, global_step=24267, preemption_count=0, score=5632.908239, test/loss=0.286893, test/num_examples=3581, test/ssim=0.742669, total_duration=5924.096673, train/loss=0.265654, train/ssim=0.749353, validation/loss=0.285489, validation/num_examples=3554, validation/ssim=0.725556
I0208 19:17:51.477266 140244451907328 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.07509545236825943, loss=0.2704859673976898
I0208 19:18:15.350127 140244460300032 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.07935914397239685, loss=0.3300488293170929
I0208 19:18:38.973732 140244451907328 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.031024038791656494, loss=0.30664682388305664
I0208 19:19:02.606523 140244460300032 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.0911702886223793, loss=0.17378190159797668
I0208 19:19:05.641772 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:19:07.015822 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:19:08.335919 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:19:09.658250 140466628462400 submission_runner.py:408] Time since start: 6008.12s, 	Step: 24614, 	{'train/ssim': 0.749849796295166, 'train/loss': 0.2658327988215855, 'validation/ssim': 0.7261342578344823, 'validation/loss': 0.28566762981082056, 'validation/num_examples': 3554, 'test/ssim': 0.7432403521842712, 'test/loss': 0.28705173163266196, 'test/num_examples': 3581, 'score': 5712.8686356544495, 'total_duration': 6008.117910861969, 'accumulated_submission_time': 5712.8686356544495, 'accumulated_eval_time': 289.0750644207001, 'accumulated_logging_time': 5.235795736312866}
I0208 19:19:09.679577 140244451907328 logging_writer.py:48] [24614] accumulated_eval_time=289.075064, accumulated_logging_time=5.235796, accumulated_submission_time=5712.868636, global_step=24614, preemption_count=0, score=5712.868636, test/loss=0.287052, test/num_examples=3581, test/ssim=0.743240, total_duration=6008.117911, train/loss=0.265833, train/ssim=0.749850, validation/loss=0.285668, validation/num_examples=3554, validation/ssim=0.726134
I0208 19:19:28.019408 140244460300032 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.04991655796766281, loss=0.23188072443008423
I0208 19:19:51.940874 140244451907328 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.034853097051382065, loss=0.31973502039909363
I0208 19:20:16.123799 140244460300032 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.026076726615428925, loss=0.3157634139060974
I0208 19:20:29.787762 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:20:31.163057 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:20:32.484069 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:20:33.805906 140466628462400 submission_runner.py:408] Time since start: 6092.27s, 	Step: 24958, 	{'train/ssim': 0.7492024557931083, 'train/loss': 0.265755363873073, 'validation/ssim': 0.725492238059229, 'validation/loss': 0.2856205568329699, 'validation/num_examples': 3554, 'test/ssim': 0.7426132632513613, 'test/loss': 0.28698297546949175, 'test/num_examples': 3581, 'score': 5792.95509147644, 'total_duration': 6092.265564203262, 'accumulated_submission_time': 5792.95509147644, 'accumulated_eval_time': 293.0931673049927, 'accumulated_logging_time': 5.266326189041138}
I0208 19:20:33.828850 140244451907328 logging_writer.py:48] [24958] accumulated_eval_time=293.093167, accumulated_logging_time=5.266326, accumulated_submission_time=5792.955091, global_step=24958, preemption_count=0, score=5792.955091, test/loss=0.286983, test/num_examples=3581, test/ssim=0.742613, total_duration=6092.265564, train/loss=0.265755, train/ssim=0.749202, validation/loss=0.285621, validation/num_examples=3554, validation/ssim=0.725492
I0208 19:20:41.846936 140244460300032 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.07521729171276093, loss=0.2565869092941284
I0208 19:21:05.686784 140244451907328 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.03397944197058678, loss=0.23636150360107422
I0208 19:21:29.537449 140244460300032 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.03252711147069931, loss=0.23399320244789124
I0208 19:21:53.437671 140244451907328 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.042388126254081726, loss=0.2932758629322052
I0208 19:21:53.843674 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:21:55.216506 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:21:56.538304 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:21:57.861820 140466628462400 submission_runner.py:408] Time since start: 6176.32s, 	Step: 25303, 	{'train/ssim': 0.7492395809718541, 'train/loss': 0.26547603947775705, 'validation/ssim': 0.7254227878139069, 'validation/loss': 0.2854243306947278, 'validation/num_examples': 3554, 'test/ssim': 0.7425200657550265, 'test/loss': 0.2868363615588348, 'test/num_examples': 3581, 'score': 5872.948161840439, 'total_duration': 6176.321474313736, 'accumulated_submission_time': 5872.948161840439, 'accumulated_eval_time': 297.111275434494, 'accumulated_logging_time': 5.2984983921051025}
I0208 19:21:57.884116 140244460300032 logging_writer.py:48] [25303] accumulated_eval_time=297.111275, accumulated_logging_time=5.298498, accumulated_submission_time=5872.948162, global_step=25303, preemption_count=0, score=5872.948162, test/loss=0.286836, test/num_examples=3581, test/ssim=0.742520, total_duration=6176.321474, train/loss=0.265476, train/ssim=0.749240, validation/loss=0.285424, validation/num_examples=3554, validation/ssim=0.725423
I0208 19:22:19.157342 140244451907328 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.05052151158452034, loss=0.23113124072551727
I0208 19:22:42.927823 140244460300032 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.03541326895356178, loss=0.25521865487098694
I0208 19:23:06.677317 140244451907328 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.04073376581072807, loss=0.2224748432636261
I0208 19:23:17.987895 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:23:19.360991 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:23:20.682765 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:23:22.005044 140466628462400 submission_runner.py:408] Time since start: 6260.46s, 	Step: 25649, 	{'train/ssim': 0.7495963232857841, 'train/loss': 0.2655596562794277, 'validation/ssim': 0.7257776641416361, 'validation/loss': 0.28545438458427125, 'validation/num_examples': 3554, 'test/ssim': 0.7429180811051382, 'test/loss': 0.2868049662061924, 'test/num_examples': 3581, 'score': 5953.030558347702, 'total_duration': 6260.4646916389465, 'accumulated_submission_time': 5953.030558347702, 'accumulated_eval_time': 301.1283836364746, 'accumulated_logging_time': 5.329797029495239}
I0208 19:23:22.026615 140244460300032 logging_writer.py:48] [25649] accumulated_eval_time=301.128384, accumulated_logging_time=5.329797, accumulated_submission_time=5953.030558, global_step=25649, preemption_count=0, score=5953.030558, test/loss=0.286805, test/num_examples=3581, test/ssim=0.742918, total_duration=6260.464692, train/loss=0.265560, train/ssim=0.749596, validation/loss=0.285454, validation/num_examples=3554, validation/ssim=0.725778
I0208 19:23:31.989948 140244451907328 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.042481679469347, loss=0.2699548602104187
I0208 19:23:55.442185 140244460300032 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.03224676102399826, loss=0.21695289015769958
I0208 19:24:19.457222 140244451907328 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.06981579959392548, loss=0.2819910943508148
I0208 19:24:42.122027 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:24:43.496171 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:24:44.817947 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:24:46.139318 140466628462400 submission_runner.py:408] Time since start: 6344.60s, 	Step: 25994, 	{'train/ssim': 0.7489735058375767, 'train/loss': 0.26555395126342773, 'validation/ssim': 0.7251500015387592, 'validation/loss': 0.28540963004932823, 'validation/num_examples': 3554, 'test/ssim': 0.7422948782419366, 'test/loss': 0.2868030572596691, 'test/num_examples': 3581, 'score': 6033.104256391525, 'total_duration': 6344.598982095718, 'accumulated_submission_time': 6033.104256391525, 'accumulated_eval_time': 305.14564299583435, 'accumulated_logging_time': 5.360304832458496}
I0208 19:24:46.160893 140244460300032 logging_writer.py:48] [25994] accumulated_eval_time=305.145643, accumulated_logging_time=5.360305, accumulated_submission_time=6033.104256, global_step=25994, preemption_count=0, score=6033.104256, test/loss=0.286803, test/num_examples=3581, test/ssim=0.742295, total_duration=6344.598982, train/loss=0.265554, train/ssim=0.748974, validation/loss=0.285410, validation/num_examples=3554, validation/ssim=0.725150
I0208 19:24:46.687882 140244451907328 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.04415694624185562, loss=0.36045822501182556
I0208 19:25:09.588829 140244460300032 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.05092855542898178, loss=0.2922050356864929
I0208 19:25:33.373045 140244451907328 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.04624154418706894, loss=0.28929951786994934
I0208 19:25:56.836545 140244460300032 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.0411149300634861, loss=0.24412156641483307
I0208 19:26:06.159104 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:26:07.534438 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:26:08.855358 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:26:10.174898 140466628462400 submission_runner.py:408] Time since start: 6428.63s, 	Step: 26340, 	{'train/ssim': 0.749401501246861, 'train/loss': 0.26525565556117464, 'validation/ssim': 0.7253881657331528, 'validation/loss': 0.28532582263162987, 'validation/num_examples': 3554, 'test/ssim': 0.7425187703984572, 'test/loss': 0.28670897346673413, 'test/num_examples': 3581, 'score': 6113.080691099167, 'total_duration': 6428.634559392929, 'accumulated_submission_time': 6113.080691099167, 'accumulated_eval_time': 309.16142416000366, 'accumulated_logging_time': 5.391079664230347}
I0208 19:26:10.201289 140244451907328 logging_writer.py:48] [26340] accumulated_eval_time=309.161424, accumulated_logging_time=5.391080, accumulated_submission_time=6113.080691, global_step=26340, preemption_count=0, score=6113.080691, test/loss=0.286709, test/num_examples=3581, test/ssim=0.742519, total_duration=6428.634559, train/loss=0.265256, train/ssim=0.749402, validation/loss=0.285326, validation/num_examples=3554, validation/ssim=0.725388
I0208 19:26:22.138720 140244460300032 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.04734579846262932, loss=0.32906970381736755
I0208 19:26:45.925437 140244451907328 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.0597890168428421, loss=0.2843753397464752
I0208 19:27:09.561061 140244460300032 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.028577882796525955, loss=0.31444239616394043
I0208 19:27:30.204026 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:27:31.577259 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:27:32.899609 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:27:34.220167 140466628462400 submission_runner.py:408] Time since start: 6512.68s, 	Step: 26688, 	{'train/ssim': 0.7494032042367118, 'train/loss': 0.26542052200862337, 'validation/ssim': 0.7254571351162422, 'validation/loss': 0.28544629579457126, 'validation/num_examples': 3554, 'test/ssim': 0.7425824474003421, 'test/loss': 0.28681355646554735, 'test/num_examples': 3581, 'score': 6193.06077671051, 'total_duration': 6512.6798322200775, 'accumulated_submission_time': 6193.06077671051, 'accumulated_eval_time': 313.17753505706787, 'accumulated_logging_time': 5.427402496337891}
I0208 19:27:34.241574 140244451907328 logging_writer.py:48] [26688] accumulated_eval_time=313.177535, accumulated_logging_time=5.427402, accumulated_submission_time=6193.060777, global_step=26688, preemption_count=0, score=6193.060777, test/loss=0.286814, test/num_examples=3581, test/ssim=0.742582, total_duration=6512.679832, train/loss=0.265421, train/ssim=0.749403, validation/loss=0.285446, validation/num_examples=3554, validation/ssim=0.725457
I0208 19:27:35.200782 140244460300032 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.05146776884794235, loss=0.24761447310447693
I0208 19:27:58.595527 140244451907328 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.02629188820719719, loss=0.22227352857589722
I0208 19:28:22.400453 140244460300032 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.04532298818230629, loss=0.24955317378044128
I0208 19:28:46.847875 140244451907328 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.037237849086523056, loss=0.2541942298412323
I0208 19:28:54.286725 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:28:55.658515 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:28:56.978936 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:28:58.300097 140466628462400 submission_runner.py:408] Time since start: 6596.76s, 	Step: 27033, 	{'train/ssim': 0.7493421009608677, 'train/loss': 0.2654526914869036, 'validation/ssim': 0.7255051526449071, 'validation/loss': 0.28537818509404017, 'validation/num_examples': 3554, 'test/ssim': 0.7426219216873778, 'test/loss': 0.2867420732359153, 'test/num_examples': 3581, 'score': 6273.084081888199, 'total_duration': 6596.759754896164, 'accumulated_submission_time': 6273.084081888199, 'accumulated_eval_time': 317.19087767601013, 'accumulated_logging_time': 5.4581146240234375}
I0208 19:28:58.322565 140244460300032 logging_writer.py:48] [27033] accumulated_eval_time=317.190878, accumulated_logging_time=5.458115, accumulated_submission_time=6273.084082, global_step=27033, preemption_count=0, score=6273.084082, test/loss=0.286742, test/num_examples=3581, test/ssim=0.742622, total_duration=6596.759755, train/loss=0.265453, train/ssim=0.749342, validation/loss=0.285378, validation/num_examples=3554, validation/ssim=0.725505
I0208 19:29:12.297207 140244451907328 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.08392342180013657, loss=0.28901851177215576
I0208 19:29:36.260860 140244460300032 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.040243472903966904, loss=0.2660350501537323
I0208 19:29:59.931809 140244451907328 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.06396452337503433, loss=0.2495088428258896
I0208 19:30:18.332578 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:30:19.707407 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:30:21.029790 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:30:22.352991 140466628462400 submission_runner.py:408] Time since start: 6680.81s, 	Step: 27380, 	{'train/ssim': 0.7501442773001534, 'train/loss': 0.26509480816977365, 'validation/ssim': 0.7259720011782499, 'validation/loss': 0.28541230913891036, 'validation/num_examples': 3554, 'test/ssim': 0.7430699105304035, 'test/loss': 0.28683428217065765, 'test/num_examples': 3581, 'score': 6353.071182966232, 'total_duration': 6680.812620401382, 'accumulated_submission_time': 6353.071182966232, 'accumulated_eval_time': 321.21122121810913, 'accumulated_logging_time': 5.4910569190979}
I0208 19:30:22.375293 140244460300032 logging_writer.py:48] [27380] accumulated_eval_time=321.211221, accumulated_logging_time=5.491057, accumulated_submission_time=6353.071183, global_step=27380, preemption_count=0, score=6353.071183, test/loss=0.286834, test/num_examples=3581, test/ssim=0.743070, total_duration=6680.812620, train/loss=0.265095, train/ssim=0.750144, validation/loss=0.285412, validation/num_examples=3554, validation/ssim=0.725972
I0208 19:30:25.077421 140244451907328 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.036918316036462784, loss=0.24790756404399872
I0208 19:30:48.790097 140244460300032 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.04776003211736679, loss=0.36462876200675964
I0208 19:31:12.694823 140244451907328 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.06041872501373291, loss=0.2835451662540436
I0208 19:31:36.128510 140244460300032 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.0422828383743763, loss=0.30571746826171875
I0208 19:31:42.424563 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:31:43.801105 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:31:45.123311 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:31:46.445436 140466628462400 submission_runner.py:408] Time since start: 6764.91s, 	Step: 27728, 	{'train/ssim': 0.7496339934212821, 'train/loss': 0.2653770787375314, 'validation/ssim': 0.7256522277935074, 'validation/loss': 0.2854231972337507, 'validation/num_examples': 3554, 'test/ssim': 0.7427992491840617, 'test/loss': 0.2867781727782044, 'test/num_examples': 3581, 'score': 6433.0986251831055, 'total_duration': 6764.905099153519, 'accumulated_submission_time': 6433.0986251831055, 'accumulated_eval_time': 325.23206520080566, 'accumulated_logging_time': 5.522183656692505}
I0208 19:31:46.467097 140244451907328 logging_writer.py:48] [27728] accumulated_eval_time=325.232065, accumulated_logging_time=5.522184, accumulated_submission_time=6433.098625, global_step=27728, preemption_count=0, score=6433.098625, test/loss=0.286778, test/num_examples=3581, test/ssim=0.742799, total_duration=6764.905099, train/loss=0.265377, train/ssim=0.749634, validation/loss=0.285423, validation/num_examples=3554, validation/ssim=0.725652
I0208 19:32:01.512779 140244460300032 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.03034464828670025, loss=0.2670953869819641
I0208 19:32:25.357713 140244451907328 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.036728423088788986, loss=0.2583659291267395
I0208 19:32:49.032153 140244460300032 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.05900149047374725, loss=0.1767333447933197
I0208 19:33:06.565289 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:33:07.938797 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:33:09.262766 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:33:10.584398 140466628462400 submission_runner.py:408] Time since start: 6849.04s, 	Step: 28073, 	{'train/ssim': 0.749655042375837, 'train/loss': 0.26534245695386616, 'validation/ssim': 0.7257410499173467, 'validation/loss': 0.2853482342464037, 'validation/num_examples': 3554, 'test/ssim': 0.7428340874581123, 'test/loss': 0.28674350494580775, 'test/num_examples': 3581, 'score': 6513.174396276474, 'total_duration': 6849.044062137604, 'accumulated_submission_time': 6513.174396276474, 'accumulated_eval_time': 329.251145362854, 'accumulated_logging_time': 5.553809642791748}
I0208 19:33:10.606621 140244451907328 logging_writer.py:48] [28073] accumulated_eval_time=329.251145, accumulated_logging_time=5.553810, accumulated_submission_time=6513.174396, global_step=28073, preemption_count=0, score=6513.174396, test/loss=0.286744, test/num_examples=3581, test/ssim=0.742834, total_duration=6849.044062, train/loss=0.265342, train/ssim=0.749655, validation/loss=0.285348, validation/num_examples=3554, validation/ssim=0.725741
I0208 19:33:14.930757 140244460300032 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.08026929944753647, loss=0.23882931470870972
I0208 19:33:38.553865 140244451907328 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.02626822516322136, loss=0.30992934107780457
I0208 19:34:02.624372 140244460300032 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.02698986604809761, loss=0.3091645836830139
I0208 19:34:26.607153 140244451907328 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.03290604427456856, loss=0.32190850377082825
I0208 19:34:30.772906 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:34:32.145879 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:34:33.467966 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:34:34.790691 140466628462400 submission_runner.py:408] Time since start: 6933.25s, 	Step: 28419, 	{'train/ssim': 0.7501136234828404, 'train/loss': 0.26499782289777485, 'validation/ssim': 0.7258814616892938, 'validation/loss': 0.2853657857178971, 'validation/num_examples': 3554, 'test/ssim': 0.7429455562997417, 'test/loss': 0.2867419709709229, 'test/num_examples': 3581, 'score': 6593.317857980728, 'total_duration': 6933.250350475311, 'accumulated_submission_time': 6593.317857980728, 'accumulated_eval_time': 333.2688903808594, 'accumulated_logging_time': 5.586345434188843}
I0208 19:34:34.813308 140244460300032 logging_writer.py:48] [28419] accumulated_eval_time=333.268890, accumulated_logging_time=5.586345, accumulated_submission_time=6593.317858, global_step=28419, preemption_count=0, score=6593.317858, test/loss=0.286742, test/num_examples=3581, test/ssim=0.742946, total_duration=6933.250350, train/loss=0.264998, train/ssim=0.750114, validation/loss=0.285366, validation/num_examples=3554, validation/ssim=0.725881
I0208 19:34:51.902712 140244451907328 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.03761366009712219, loss=0.2873227000236511
I0208 19:35:15.924947 140244460300032 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.025715461000800133, loss=0.31715548038482666
I0208 19:35:39.461613 140244451907328 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.03501570224761963, loss=0.29183802008628845
I0208 19:35:54.950778 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:35:56.326331 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:35:57.649458 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:35:58.969286 140466628462400 submission_runner.py:408] Time since start: 7017.43s, 	Step: 28766, 	{'train/ssim': 0.74993896484375, 'train/loss': 0.2651689052581787, 'validation/ssim': 0.7257976542715954, 'validation/loss': 0.285333516427353, 'validation/num_examples': 3554, 'test/ssim': 0.7429291257243088, 'test/loss': 0.2867050533086952, 'test/num_examples': 3581, 'score': 6673.433345794678, 'total_duration': 7017.428941488266, 'accumulated_submission_time': 6673.433345794678, 'accumulated_eval_time': 337.28736329078674, 'accumulated_logging_time': 5.618357419967651}
I0208 19:35:58.994840 140244460300032 logging_writer.py:48] [28766] accumulated_eval_time=337.287363, accumulated_logging_time=5.618357, accumulated_submission_time=6673.433346, global_step=28766, preemption_count=0, score=6673.433346, test/loss=0.286705, test/num_examples=3581, test/ssim=0.742929, total_duration=7017.428941, train/loss=0.265169, train/ssim=0.749939, validation/loss=0.285334, validation/num_examples=3554, validation/ssim=0.725798
I0208 19:36:05.169051 140244451907328 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.04603086784482002, loss=0.23056422173976898
I0208 19:36:28.580328 140244460300032 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.026689687743782997, loss=0.24958199262619019
I0208 19:36:52.252151 140244451907328 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.04902144894003868, loss=0.29036781191825867
I0208 19:37:16.775043 140244460300032 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.03238973021507263, loss=0.238027423620224
I0208 19:37:19.046073 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:37:20.418276 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:37:21.740766 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:37:23.062973 140466628462400 submission_runner.py:408] Time since start: 7101.52s, 	Step: 29111, 	{'train/ssim': 0.7497790881565639, 'train/loss': 0.2652667249952044, 'validation/ssim': 0.7257436603123242, 'validation/loss': 0.28534964248579947, 'validation/num_examples': 3554, 'test/ssim': 0.7428636761292237, 'test/loss': 0.2867233246539898, 'test/num_examples': 3581, 'score': 6753.462169647217, 'total_duration': 7101.522633552551, 'accumulated_submission_time': 6753.462169647217, 'accumulated_eval_time': 341.3042325973511, 'accumulated_logging_time': 5.653614521026611}
I0208 19:37:23.086121 140244451907328 logging_writer.py:48] [29111] accumulated_eval_time=341.304233, accumulated_logging_time=5.653615, accumulated_submission_time=6753.462170, global_step=29111, preemption_count=0, score=6753.462170, test/loss=0.286723, test/num_examples=3581, test/ssim=0.742864, total_duration=7101.522634, train/loss=0.265267, train/ssim=0.749779, validation/loss=0.285350, validation/num_examples=3554, validation/ssim=0.725744
I0208 19:37:42.342808 140244460300032 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.032695721834897995, loss=0.24650418758392334
I0208 19:38:06.447854 140244451907328 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.03004714660346508, loss=0.27658185362815857
I0208 19:38:30.317069 140244460300032 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.04356813058257103, loss=0.19718307256698608
I0208 19:38:43.188707 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:38:44.561678 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:38:45.884166 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:38:47.205665 140466628462400 submission_runner.py:408] Time since start: 7185.67s, 	Step: 29455, 	{'train/ssim': 0.7503256797790527, 'train/loss': 0.2649745089667184, 'validation/ssim': 0.7260548468714828, 'validation/loss': 0.28538472825513506, 'validation/num_examples': 3554, 'test/ssim': 0.7431262926295029, 'test/loss': 0.28681168160735476, 'test/num_examples': 3581, 'score': 6833.543080806732, 'total_duration': 7185.665328025818, 'accumulated_submission_time': 6833.543080806732, 'accumulated_eval_time': 345.3211672306061, 'accumulated_logging_time': 5.685898780822754}
I0208 19:38:47.227762 140244451907328 logging_writer.py:48] [29455] accumulated_eval_time=345.321167, accumulated_logging_time=5.685899, accumulated_submission_time=6833.543081, global_step=29455, preemption_count=0, score=6833.543081, test/loss=0.286812, test/num_examples=3581, test/ssim=0.743126, total_duration=7185.665328, train/loss=0.264975, train/ssim=0.750326, validation/loss=0.285385, validation/num_examples=3554, validation/ssim=0.726055
I0208 19:38:55.943992 140244460300032 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.026262765750288963, loss=0.22420118749141693
I0208 19:39:19.660892 140244451907328 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.06121344119310379, loss=0.2615998685359955
I0208 19:39:43.429859 140244460300032 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.025533052161335945, loss=0.30334603786468506
I0208 19:40:07.372478 140244451907328 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.05403989180922508, loss=0.25718870759010315
I0208 19:40:07.378589 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:40:08.696198 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:40:10.020166 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:40:11.344463 140466628462400 submission_runner.py:408] Time since start: 7269.80s, 	Step: 29801, 	{'train/ssim': 0.7499323572431292, 'train/loss': 0.2650454044342041, 'validation/ssim': 0.7257351421813449, 'validation/loss': 0.2852960950414586, 'validation/num_examples': 3554, 'test/ssim': 0.742863471599239, 'test/loss': 0.2866652722266825, 'test/num_examples': 3581, 'score': 6913.672247648239, 'total_duration': 7269.804100990295, 'accumulated_submission_time': 6913.672247648239, 'accumulated_eval_time': 349.28695940971375, 'accumulated_logging_time': 5.716902494430542}
I0208 19:40:11.369753 140244460300032 logging_writer.py:48] [29801] accumulated_eval_time=349.286959, accumulated_logging_time=5.716902, accumulated_submission_time=6913.672248, global_step=29801, preemption_count=0, score=6913.672248, test/loss=0.286665, test/num_examples=3581, test/ssim=0.742863, total_duration=7269.804101, train/loss=0.265045, train/ssim=0.749932, validation/loss=0.285296, validation/num_examples=3554, validation/ssim=0.725735
I0208 19:40:32.645362 140244451907328 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.032955002039670944, loss=0.2398253232240677
I0208 19:40:56.497644 140244460300032 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.033742647618055344, loss=0.2952091693878174
I0208 19:41:20.530035 140244451907328 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.01939973421394825, loss=0.24972717463970184
I0208 19:41:31.385449 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:41:32.760847 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:41:34.083755 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:41:35.407605 140466628462400 submission_runner.py:408] Time since start: 7353.87s, 	Step: 30146, 	{'train/ssim': 0.7499641690935407, 'train/loss': 0.2652068478720529, 'validation/ssim': 0.725912923818233, 'validation/loss': 0.28535984363459305, 'validation/num_examples': 3554, 'test/ssim': 0.7429881667132086, 'test/loss': 0.28673989158274577, 'test/num_examples': 3581, 'score': 6993.665600538254, 'total_duration': 7353.8672597408295, 'accumulated_submission_time': 6993.665600538254, 'accumulated_eval_time': 353.3090696334839, 'accumulated_logging_time': 5.7517173290252686}
I0208 19:41:35.430616 140244460300032 logging_writer.py:48] [30146] accumulated_eval_time=353.309070, accumulated_logging_time=5.751717, accumulated_submission_time=6993.665601, global_step=30146, preemption_count=0, score=6993.665601, test/loss=0.286740, test/num_examples=3581, test/ssim=0.742988, total_duration=7353.867260, train/loss=0.265207, train/ssim=0.749964, validation/loss=0.285360, validation/num_examples=3554, validation/ssim=0.725913
I0208 19:41:46.045361 140244451907328 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.04339194297790527, loss=0.25631624460220337
I0208 19:42:10.415059 140244460300032 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.033444445580244064, loss=0.18018504977226257
I0208 19:42:34.173990 140244451907328 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.039285674691200256, loss=0.2539796531200409
I0208 19:42:55.452308 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:42:56.824340 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:42:58.145807 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:42:59.465346 140466628462400 submission_runner.py:408] Time since start: 7437.93s, 	Step: 30491, 	{'train/ssim': 0.7503576959882464, 'train/loss': 0.264944110597883, 'validation/ssim': 0.7260252394968697, 'validation/loss': 0.2854310284186832, 'validation/num_examples': 3554, 'test/ssim': 0.7430889318189752, 'test/loss': 0.28682920300937237, 'test/num_examples': 3581, 'score': 7073.665458440781, 'total_duration': 7437.925004243851, 'accumulated_submission_time': 7073.665458440781, 'accumulated_eval_time': 357.32208609580994, 'accumulated_logging_time': 5.783747434616089}
I0208 19:42:59.492854 140244460300032 logging_writer.py:48] [30491] accumulated_eval_time=357.322086, accumulated_logging_time=5.783747, accumulated_submission_time=7073.665458, global_step=30491, preemption_count=0, score=7073.665458, test/loss=0.286829, test/num_examples=3581, test/ssim=0.743089, total_duration=7437.925004, train/loss=0.264944, train/ssim=0.750358, validation/loss=0.285431, validation/num_examples=3554, validation/ssim=0.726025
I0208 19:43:00.240529 140244451907328 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.03845443204045296, loss=0.21702821552753448
I0208 19:43:23.625666 140244460300032 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.026828382164239883, loss=0.3439006805419922
I0208 19:43:47.567843 140244451907328 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.031686533242464066, loss=0.2860991358757019
I0208 19:44:11.074943 140244460300032 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.02084888145327568, loss=0.3236589729785919
I0208 19:44:19.690821 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:44:21.065697 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:44:22.387115 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:44:23.709522 140466628462400 submission_runner.py:408] Time since start: 7522.17s, 	Step: 30838, 	{'train/ssim': 0.7499535424368722, 'train/loss': 0.26497530937194824, 'validation/ssim': 0.7257873500808948, 'validation/loss': 0.28530131583141355, 'validation/num_examples': 3554, 'test/ssim': 0.7428631307159314, 'test/loss': 0.2866669084665596, 'test/num_examples': 3581, 'score': 7153.841228246689, 'total_duration': 7522.169150829315, 'accumulated_submission_time': 7153.841228246689, 'accumulated_eval_time': 361.3407151699066, 'accumulated_logging_time': 5.820956230163574}
I0208 19:44:23.737127 140244451907328 logging_writer.py:48] [30838] accumulated_eval_time=361.340715, accumulated_logging_time=5.820956, accumulated_submission_time=7153.841228, global_step=30838, preemption_count=0, score=7153.841228, test/loss=0.286667, test/num_examples=3581, test/ssim=0.742863, total_duration=7522.169151, train/loss=0.264975, train/ssim=0.749954, validation/loss=0.285301, validation/num_examples=3554, validation/ssim=0.725787
I0208 19:44:36.448350 140244460300032 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.016430843621492386, loss=0.24844005703926086
I0208 19:45:00.496249 140244451907328 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.01922483742237091, loss=0.2910991609096527
I0208 19:45:24.531687 140244460300032 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.024745222181081772, loss=0.20381993055343628
I0208 19:45:43.799904 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:45:45.172515 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:45:46.493805 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:45:47.814993 140466628462400 submission_runner.py:408] Time since start: 7606.27s, 	Step: 31183, 	{'train/ssim': 0.7500086511884417, 'train/loss': 0.26507064274379183, 'validation/ssim': 0.7258787139051069, 'validation/loss': 0.285347959467985, 'validation/num_examples': 3554, 'test/ssim': 0.7429502604893884, 'test/loss': 0.2867455502456541, 'test/num_examples': 3581, 'score': 7233.882091283798, 'total_duration': 7606.274645090103, 'accumulated_submission_time': 7233.882091283798, 'accumulated_eval_time': 365.355765581131, 'accumulated_logging_time': 5.85828971862793}
I0208 19:45:47.838731 140244451907328 logging_writer.py:48] [31183] accumulated_eval_time=365.355766, accumulated_logging_time=5.858290, accumulated_submission_time=7233.882091, global_step=31183, preemption_count=0, score=7233.882091, test/loss=0.286746, test/num_examples=3581, test/ssim=0.742950, total_duration=7606.274645, train/loss=0.265071, train/ssim=0.750009, validation/loss=0.285348, validation/num_examples=3554, validation/ssim=0.725879
I0208 19:45:49.766328 140244460300032 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.025368329137563705, loss=0.19089800119400024
I0208 19:46:13.874382 140244451907328 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.021382974460721016, loss=0.30646541714668274
I0208 19:46:38.070579 140244460300032 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.027424734085798264, loss=0.19025647640228271
I0208 19:47:01.967509 140244451907328 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.028853006660938263, loss=0.32677385210990906
I0208 19:47:07.835390 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:47:09.210432 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:47:10.532435 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:47:11.854920 140466628462400 submission_runner.py:408] Time since start: 7690.31s, 	Step: 31525, 	{'train/ssim': 0.7500947543552944, 'train/loss': 0.2649495601654053, 'validation/ssim': 0.7257277918586452, 'validation/loss': 0.2854118454503288, 'validation/num_examples': 3554, 'test/ssim': 0.7428442457806828, 'test/loss': 0.2868032617896537, 'test/num_examples': 3581, 'score': 7313.855280160904, 'total_duration': 7690.314583301544, 'accumulated_submission_time': 7313.855280160904, 'accumulated_eval_time': 369.37527203559875, 'accumulated_logging_time': 5.89311146736145}
I0208 19:47:11.877544 140244460300032 logging_writer.py:48] [31525] accumulated_eval_time=369.375272, accumulated_logging_time=5.893111, accumulated_submission_time=7313.855280, global_step=31525, preemption_count=0, score=7313.855280, test/loss=0.286803, test/num_examples=3581, test/ssim=0.742844, total_duration=7690.314583, train/loss=0.264950, train/ssim=0.750095, validation/loss=0.285412, validation/num_examples=3554, validation/ssim=0.725728
I0208 19:47:27.745938 140244451907328 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.04063824564218521, loss=0.22495028376579285
I0208 19:47:51.612382 140244460300032 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.022333908826112747, loss=0.23068879544734955
I0208 19:48:15.600761 140244451907328 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.02024819329380989, loss=0.24458003044128418
I0208 19:48:31.893796 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:48:33.269402 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:48:34.593127 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:48:35.917771 140466628462400 submission_runner.py:408] Time since start: 7774.38s, 	Step: 31870, 	{'train/ssim': 0.7500623975481305, 'train/loss': 0.26489038126809256, 'validation/ssim': 0.7257400194982766, 'validation/loss': 0.28527347734287073, 'validation/num_examples': 3554, 'test/ssim': 0.7428506543868681, 'test/loss': 0.2866636359868054, 'test/num_examples': 3581, 'score': 7393.850246191025, 'total_duration': 7774.377434492111, 'accumulated_submission_time': 7393.850246191025, 'accumulated_eval_time': 373.39921855926514, 'accumulated_logging_time': 5.924740552902222}
I0208 19:48:35.940500 140244460300032 logging_writer.py:48] [31870] accumulated_eval_time=373.399219, accumulated_logging_time=5.924741, accumulated_submission_time=7393.850246, global_step=31870, preemption_count=0, score=7393.850246, test/loss=0.286664, test/num_examples=3581, test/ssim=0.742851, total_duration=7774.377434, train/loss=0.264890, train/ssim=0.750062, validation/loss=0.285273, validation/num_examples=3554, validation/ssim=0.725740
I0208 19:48:41.017869 140244451907328 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.021311050280928612, loss=0.29869112372398376
I0208 19:49:04.741662 140244460300032 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.04459080100059509, loss=0.30447036027908325
I0208 19:49:28.394894 140244451907328 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.018732432276010513, loss=0.3120592534542084
I0208 19:49:52.266778 140244460300032 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.021464167162775993, loss=0.2202676236629486
I0208 19:49:55.980989 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:49:57.356366 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:49:58.680928 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:50:00.002854 140466628462400 submission_runner.py:408] Time since start: 7858.46s, 	Step: 32217, 	{'train/ssim': 0.7503595352172852, 'train/loss': 0.26500085421970915, 'validation/ssim': 0.7261762302379361, 'validation/loss': 0.28532025836865155, 'validation/num_examples': 3554, 'test/ssim': 0.7432891666739389, 'test/loss': 0.28666840835311364, 'test/num_examples': 3581, 'score': 7473.869105577469, 'total_duration': 7858.462511301041, 'accumulated_submission_time': 7473.869105577469, 'accumulated_eval_time': 377.42104148864746, 'accumulated_logging_time': 5.95652961730957}
I0208 19:50:00.025836 140244451907328 logging_writer.py:48] [32217] accumulated_eval_time=377.421041, accumulated_logging_time=5.956530, accumulated_submission_time=7473.869106, global_step=32217, preemption_count=0, score=7473.869106, test/loss=0.286668, test/num_examples=3581, test/ssim=0.743289, total_duration=7858.462511, train/loss=0.265001, train/ssim=0.750360, validation/loss=0.285320, validation/num_examples=3554, validation/ssim=0.726176
I0208 19:50:17.999174 140244460300032 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.03176138922572136, loss=0.27733442187309265
I0208 19:50:41.858081 140244451907328 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.026207612827420235, loss=0.2611754536628723
I0208 19:51:05.819799 140244460300032 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.021511953324079514, loss=0.3063003718852997
I0208 19:51:20.050917 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:51:21.427141 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:51:22.747929 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:51:24.069181 140466628462400 submission_runner.py:408] Time since start: 7942.53s, 	Step: 32561, 	{'train/ssim': 0.7500896453857422, 'train/loss': 0.26509114674159456, 'validation/ssim': 0.7257870753024761, 'validation/loss': 0.2854902431679094, 'validation/num_examples': 3554, 'test/ssim': 0.742864085189193, 'test/loss': 0.28693194523832377, 'test/num_examples': 3581, 'score': 7553.872319459915, 'total_duration': 7942.528846740723, 'accumulated_submission_time': 7553.872319459915, 'accumulated_eval_time': 381.439279794693, 'accumulated_logging_time': 5.988731384277344}
I0208 19:51:24.092380 140244451907328 logging_writer.py:48] [32561] accumulated_eval_time=381.439280, accumulated_logging_time=5.988731, accumulated_submission_time=7553.872319, global_step=32561, preemption_count=0, score=7553.872319, test/loss=0.286932, test/num_examples=3581, test/ssim=0.742864, total_duration=7942.528847, train/loss=0.265091, train/ssim=0.750090, validation/loss=0.285490, validation/num_examples=3554, validation/ssim=0.725787
I0208 19:51:31.194475 140244460300032 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.02491733618080616, loss=0.26912355422973633
I0208 19:51:55.146372 140244451907328 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.02445422299206257, loss=0.261181503534317
I0208 19:52:18.834896 140244460300032 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.032569024711847305, loss=0.2312617152929306
I0208 19:52:42.610675 140244451907328 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.0272018201649189, loss=0.24691666662693024
I0208 19:52:44.222950 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:52:45.599300 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:52:46.921009 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:52:48.242100 140466628462400 submission_runner.py:408] Time since start: 8026.70s, 	Step: 32908, 	{'train/ssim': 0.750241756439209, 'train/loss': 0.2648369073867798, 'validation/ssim': 0.7258719131392445, 'validation/loss': 0.28530545468134494, 'validation/num_examples': 3554, 'test/ssim': 0.7429668955948059, 'test/loss': 0.286711257384896, 'test/num_examples': 3581, 'score': 7633.981284618378, 'total_duration': 8026.701743841171, 'accumulated_submission_time': 7633.981284618378, 'accumulated_eval_time': 385.458370923996, 'accumulated_logging_time': 6.020787715911865}
I0208 19:52:48.265759 140244460300032 logging_writer.py:48] [32908] accumulated_eval_time=385.458371, accumulated_logging_time=6.020788, accumulated_submission_time=7633.981285, global_step=32908, preemption_count=0, score=7633.981285, test/loss=0.286711, test/num_examples=3581, test/ssim=0.742967, total_duration=8026.701744, train/loss=0.264837, train/ssim=0.750242, validation/loss=0.285305, validation/num_examples=3554, validation/ssim=0.725872
I0208 19:53:07.891836 140244451907328 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.02531065233051777, loss=0.32301849126815796
I0208 19:53:31.839869 140244460300032 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.020486975088715553, loss=0.25637492537498474
I0208 19:53:55.511702 140244451907328 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.018359223380684853, loss=0.330127477645874
I0208 19:54:08.360417 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:54:09.733866 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:54:11.054941 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:54:12.378158 140466628462400 submission_runner.py:408] Time since start: 8110.84s, 	Step: 33255, 	{'train/ssim': 0.7501583780561175, 'train/loss': 0.26490340914045063, 'validation/ssim': 0.7258987727296707, 'validation/loss': 0.28526111231402995, 'validation/num_examples': 3554, 'test/ssim': 0.7429962797359327, 'test/loss': 0.2866541935191811, 'test/num_examples': 3581, 'score': 7714.053889751434, 'total_duration': 8110.837794303894, 'accumulated_submission_time': 7714.053889751434, 'accumulated_eval_time': 389.4760494232178, 'accumulated_logging_time': 6.053780794143677}
I0208 19:54:12.405012 140244460300032 logging_writer.py:48] [33255] accumulated_eval_time=389.476049, accumulated_logging_time=6.053781, accumulated_submission_time=7714.053890, global_step=33255, preemption_count=0, score=7714.053890, test/loss=0.286654, test/num_examples=3581, test/ssim=0.742996, total_duration=8110.837794, train/loss=0.264903, train/ssim=0.750158, validation/loss=0.285261, validation/num_examples=3554, validation/ssim=0.725899
I0208 19:54:21.012821 140244451907328 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.02630101516842842, loss=0.19762150943279266
I0208 19:54:44.806799 140244460300032 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.02593236416578293, loss=0.26717689633369446
I0208 19:55:08.971088 140244451907328 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.025524981319904327, loss=0.25370025634765625
I0208 19:55:32.574603 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:55:33.948822 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:55:35.270183 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:55:36.594549 140466628462400 submission_runner.py:408] Time since start: 8195.05s, 	Step: 33598, 	{'train/ssim': 0.7500778606959752, 'train/loss': 0.2648886442184448, 'validation/ssim': 0.7257746415790307, 'validation/loss': 0.2852774788035928, 'validation/num_examples': 3554, 'test/ssim': 0.7428910831471656, 'test/loss': 0.2866700445929908, 'test/num_examples': 3581, 'score': 7794.201321601868, 'total_duration': 8195.054210424423, 'accumulated_submission_time': 7794.201321601868, 'accumulated_eval_time': 393.4959604740143, 'accumulated_logging_time': 6.090385913848877}
I0208 19:55:36.617945 140244460300032 logging_writer.py:48] [33598] accumulated_eval_time=393.495960, accumulated_logging_time=6.090386, accumulated_submission_time=7794.201322, global_step=33598, preemption_count=0, score=7794.201322, test/loss=0.286670, test/num_examples=3581, test/ssim=0.742891, total_duration=8195.054210, train/loss=0.264889, train/ssim=0.750078, validation/loss=0.285277, validation/num_examples=3554, validation/ssim=0.725775
I0208 19:55:36.856667 140244451907328 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.020953822880983353, loss=0.2857890725135803
I0208 19:55:59.017938 140244460300032 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.020564209669828415, loss=0.2459181696176529
I0208 19:56:22.821702 140244451907328 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.03371254727244377, loss=0.327380895614624
I0208 19:56:46.572169 140244460300032 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.017585279420018196, loss=0.21402090787887573
I0208 19:56:56.734718 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:56:58.108186 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:56:59.429823 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:57:00.752117 140466628462400 submission_runner.py:408] Time since start: 8279.21s, 	Step: 33945, 	{'train/ssim': 0.7502149173191616, 'train/loss': 0.26476570538112093, 'validation/ssim': 0.7258221095508582, 'validation/loss': 0.2852540195960977, 'validation/num_examples': 3554, 'test/ssim': 0.7429065592493368, 'test/loss': 0.2866699423279985, 'test/num_examples': 3581, 'score': 7874.296406030655, 'total_duration': 8279.21177649498, 'accumulated_submission_time': 7874.296406030655, 'accumulated_eval_time': 397.5133173465729, 'accumulated_logging_time': 6.123018741607666}
I0208 19:57:00.775342 140244451907328 logging_writer.py:48] [33945] accumulated_eval_time=397.513317, accumulated_logging_time=6.123019, accumulated_submission_time=7874.296406, global_step=33945, preemption_count=0, score=7874.296406, test/loss=0.286670, test/num_examples=3581, test/ssim=0.742907, total_duration=8279.211776, train/loss=0.264766, train/ssim=0.750215, validation/loss=0.285254, validation/num_examples=3554, validation/ssim=0.725822
I0208 19:57:11.883052 140244460300032 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.028174111619591713, loss=0.262931764125824
I0208 19:57:35.483607 140244451907328 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.024651112034916878, loss=0.22349749505519867
I0208 19:57:58.815548 140244460300032 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.021357055753469467, loss=0.23199798166751862
I0208 19:58:20.761731 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:58:22.135481 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:58:23.453642 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:58:24.777709 140466628462400 submission_runner.py:408] Time since start: 8363.24s, 	Step: 34293, 	{'train/ssim': 0.7502946172441755, 'train/loss': 0.26481943471091135, 'validation/ssim': 0.7260055241453293, 'validation/loss': 0.2852201703296462, 'validation/num_examples': 3554, 'test/ssim': 0.7431016808546844, 'test/loss': 0.2866239912581158, 'test/num_examples': 3581, 'score': 7954.259927272797, 'total_duration': 8363.237367153168, 'accumulated_submission_time': 7954.259927272797, 'accumulated_eval_time': 401.5292658805847, 'accumulated_logging_time': 6.1560492515563965}
I0208 19:58:24.801534 140244451907328 logging_writer.py:48] [34293] accumulated_eval_time=401.529266, accumulated_logging_time=6.156049, accumulated_submission_time=7954.259927, global_step=34293, preemption_count=0, score=7954.259927, test/loss=0.286624, test/num_examples=3581, test/ssim=0.743102, total_duration=8363.237367, train/loss=0.264819, train/ssim=0.750295, validation/loss=0.285220, validation/num_examples=3554, validation/ssim=0.726006
I0208 19:58:25.403046 140244460300032 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.018528593704104424, loss=0.2504156529903412
I0208 19:58:48.044081 140244451907328 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.016657572239637375, loss=0.18702025711536407
I0208 19:59:11.879486 140244460300032 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.03190149739384651, loss=0.24910269677639008
I0208 19:59:36.081591 140244451907328 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.018834248185157776, loss=0.22472050786018372
I0208 19:59:44.979613 140466628462400 spec.py:321] Evaluating on the training split.
I0208 19:59:46.354215 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 19:59:47.674153 140466628462400 spec.py:349] Evaluating on the test split.
I0208 19:59:48.996135 140466628462400 submission_runner.py:408] Time since start: 8447.46s, 	Step: 34639, 	{'train/ssim': 0.7502439362662179, 'train/loss': 0.26481923035212923, 'validation/ssim': 0.7259190376380487, 'validation/loss': 0.2852440760520716, 'validation/num_examples': 3554, 'test/ssim': 0.7430262092903519, 'test/loss': 0.286623650374808, 'test/num_examples': 3581, 'score': 8034.41494178772, 'total_duration': 8447.455779075623, 'accumulated_submission_time': 8034.41494178772, 'accumulated_eval_time': 405.54572916030884, 'accumulated_logging_time': 6.190333127975464}
I0208 19:59:49.020318 140244460300032 logging_writer.py:48] [34639] accumulated_eval_time=405.545729, accumulated_logging_time=6.190333, accumulated_submission_time=8034.414942, global_step=34639, preemption_count=0, score=8034.414942, test/loss=0.286624, test/num_examples=3581, test/ssim=0.743026, total_duration=8447.455779, train/loss=0.264819, train/ssim=0.750244, validation/loss=0.285244, validation/num_examples=3554, validation/ssim=0.725919
I0208 20:00:01.361282 140244451907328 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.04299468174576759, loss=0.3966756761074066
I0208 20:00:25.224559 140244460300032 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.029705863445997238, loss=0.3404885530471802
I0208 20:00:48.910486 140244451907328 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.029450396075844765, loss=0.2458927482366562
I0208 20:01:09.222613 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:01:10.596613 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:01:11.916280 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:01:13.240023 140466628462400 submission_runner.py:408] Time since start: 8531.70s, 	Step: 34986, 	{'train/ssim': 0.7504809924534389, 'train/loss': 0.264769230570112, 'validation/ssim': 0.7261091843037775, 'validation/loss': 0.28525249114114376, 'validation/num_examples': 3554, 'test/ssim': 0.7431830837885717, 'test/loss': 0.28666776067482896, 'test/num_examples': 3581, 'score': 8114.595928907394, 'total_duration': 8531.699686050415, 'accumulated_submission_time': 8114.595928907394, 'accumulated_eval_time': 409.5631048679352, 'accumulated_logging_time': 6.223457336425781}
I0208 20:01:13.267699 140244460300032 logging_writer.py:48] [34986] accumulated_eval_time=409.563105, accumulated_logging_time=6.223457, accumulated_submission_time=8114.595929, global_step=34986, preemption_count=0, score=8114.595929, test/loss=0.286668, test/num_examples=3581, test/ssim=0.743183, total_duration=8531.699686, train/loss=0.264769, train/ssim=0.750481, validation/loss=0.285252, validation/num_examples=3554, validation/ssim=0.726109
I0208 20:01:14.529258 140244451907328 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.016729507595300674, loss=0.324751615524292
I0208 20:01:37.929908 140244460300032 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.021755004301667213, loss=0.2808896005153656
I0208 20:02:01.763011 140244451907328 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.01671314612030983, loss=0.25406208634376526
I0208 20:02:25.544601 140244460300032 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.01910525932908058, loss=0.3031962811946869
I0208 20:02:33.385329 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:02:34.757567 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:02:36.081710 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:02:37.402498 140466628462400 submission_runner.py:408] Time since start: 8615.86s, 	Step: 35334, 	{'train/ssim': 0.7502155985151019, 'train/loss': 0.26476430892944336, 'validation/ssim': 0.7258480761114238, 'validation/loss': 0.2852156708330402, 'validation/num_examples': 3554, 'test/ssim': 0.7429592598087127, 'test/loss': 0.2866166963553302, 'test/num_examples': 3581, 'score': 8194.691151618958, 'total_duration': 8615.862161159515, 'accumulated_submission_time': 8194.691151618958, 'accumulated_eval_time': 413.5802364349365, 'accumulated_logging_time': 6.2608723640441895}
I0208 20:02:37.426249 140244451907328 logging_writer.py:48] [35334] accumulated_eval_time=413.580236, accumulated_logging_time=6.260872, accumulated_submission_time=8194.691152, global_step=35334, preemption_count=0, score=8194.691152, test/loss=0.286617, test/num_examples=3581, test/ssim=0.742959, total_duration=8615.862161, train/loss=0.264764, train/ssim=0.750216, validation/loss=0.285216, validation/num_examples=3554, validation/ssim=0.725848
I0208 20:02:50.838721 140244460300032 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.021918119862675667, loss=0.30955472588539124
I0208 20:03:14.193060 140244451907328 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.025307990610599518, loss=0.26402747631073
I0208 20:03:38.127409 140244460300032 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.02407042868435383, loss=0.19554688036441803
I0208 20:03:57.429199 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:03:58.802665 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:04:00.124812 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:04:01.449211 140466628462400 submission_runner.py:408] Time since start: 8699.91s, 	Step: 35681, 	{'train/ssim': 0.7504230907985142, 'train/loss': 0.26478004455566406, 'validation/ssim': 0.7260905680659117, 'validation/loss': 0.28522551133515933, 'validation/num_examples': 3554, 'test/ssim': 0.7431732663493088, 'test/loss': 0.28662709329621616, 'test/num_examples': 3581, 'score': 8274.671577215195, 'total_duration': 8699.908791542053, 'accumulated_submission_time': 8274.671577215195, 'accumulated_eval_time': 417.60013151168823, 'accumulated_logging_time': 6.293979644775391}
I0208 20:04:01.480162 140244451907328 logging_writer.py:48] [35681] accumulated_eval_time=417.600132, accumulated_logging_time=6.293980, accumulated_submission_time=8274.671577, global_step=35681, preemption_count=0, score=8274.671577, test/loss=0.286627, test/num_examples=3581, test/ssim=0.743173, total_duration=8699.908792, train/loss=0.264780, train/ssim=0.750423, validation/loss=0.285226, validation/num_examples=3554, validation/ssim=0.726091
I0208 20:04:03.959967 140244460300032 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.02774495631456375, loss=0.31052350997924805
I0208 20:04:27.845335 140244451907328 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.0266034584492445, loss=0.2298983484506607
I0208 20:04:51.634856 140244460300032 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.02674642764031887, loss=0.2906050682067871
I0208 20:05:15.380390 140244451907328 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.029041165485978127, loss=0.22448094189167023
I0208 20:05:21.452326 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:05:22.826753 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:05:24.147224 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:05:25.468199 140466628462400 submission_runner.py:408] Time since start: 8783.93s, 	Step: 36027, 	{'train/ssim': 0.7503397805350167, 'train/loss': 0.2647636617933001, 'validation/ssim': 0.7259813436444851, 'validation/loss': 0.2852229009401818, 'validation/num_examples': 3554, 'test/ssim': 0.7430758418999581, 'test/loss': 0.2866263774412699, 'test/num_examples': 3581, 'score': 8354.620125293732, 'total_duration': 8783.927860736847, 'accumulated_submission_time': 8354.620125293732, 'accumulated_eval_time': 421.61596393585205, 'accumulated_logging_time': 6.335568904876709}
I0208 20:05:25.492492 140244460300032 logging_writer.py:48] [36027] accumulated_eval_time=421.615964, accumulated_logging_time=6.335569, accumulated_submission_time=8354.620125, global_step=36027, preemption_count=0, score=8354.620125, test/loss=0.286626, test/num_examples=3581, test/ssim=0.743076, total_duration=8783.927861, train/loss=0.264764, train/ssim=0.750340, validation/loss=0.285223, validation/num_examples=3554, validation/ssim=0.725981
I0208 20:05:40.892509 140244451907328 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.012491676025092602, loss=0.3968718945980072
I0208 20:06:01.852550 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:06:03.224639 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:06:04.544721 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:06:05.865880 140466628462400 submission_runner.py:408] Time since start: 8824.33s, 	Step: 36189, 	{'train/ssim': 0.7503502709524972, 'train/loss': 0.2647658245904105, 'validation/ssim': 0.7259957008168613, 'validation/loss': 0.2852237252754379, 'validation/num_examples': 3554, 'test/ssim': 0.7430886591123289, 'test/loss': 0.286627570532847, 'test/num_examples': 3581, 'score': 8390.96516919136, 'total_duration': 8824.325541734695, 'accumulated_submission_time': 8390.96516919136, 'accumulated_eval_time': 425.62926030158997, 'accumulated_logging_time': 6.368803024291992}
I0208 20:06:05.889966 140244460300032 logging_writer.py:48] [36189] accumulated_eval_time=425.629260, accumulated_logging_time=6.368803, accumulated_submission_time=8390.965169, global_step=36189, preemption_count=0, score=8390.965169, test/loss=0.286628, test/num_examples=3581, test/ssim=0.743089, total_duration=8824.325542, train/loss=0.264766, train/ssim=0.750350, validation/loss=0.285224, validation/num_examples=3554, validation/ssim=0.725996
I0208 20:06:05.911686 140244451907328 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8390.965169
I0208 20:06:05.958361 140466628462400 checkpoints.py:490] Saving checkpoint at step: 36189
I0208 20:06:06.178812 140466628462400 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2/checkpoint_36189
I0208 20:06:06.179583 140466628462400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_2/checkpoint_36189.
I0208 20:06:06.860416 140466628462400 submission_runner.py:583] Tuning trial 2/5
I0208 20:06:06.860712 140466628462400 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0208 20:06:06.866021 140466628462400 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 29.176573991775513, 'total_duration': 33.137226819992065, 'accumulated_submission_time': 29.176573991775513, 'accumulated_eval_time': 3.9605116844177246, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (345, {'train/ssim': 0.7004432678222656, 'train/loss': 0.30544791902814594, 'validation/ssim': 0.6780527057980444, 'validation/loss': 0.32312870401308386, 'validation/num_examples': 3554, 'test/ssim': 0.6965224312124756, 'test/loss': 0.3249313665548206, 'test/num_examples': 3581, 'score': 109.27268695831299, 'total_duration': 117.27683687210083, 'accumulated_submission_time': 109.27268695831299, 'accumulated_eval_time': 7.9727394580841064, 'accumulated_logging_time': 0.018121719360351562, 'global_step': 345, 'preemption_count': 0}), (684, {'train/ssim': 0.719583238874163, 'train/loss': 0.29089525767735075, 'validation/ssim': 0.6983924912950197, 'validation/loss': 0.3081439033813133, 'validation/num_examples': 3554, 'test/ssim': 0.7156626198818417, 'test/loss': 0.3102621692613795, 'test/num_examples': 3581, 'score': 189.41457438468933, 'total_duration': 201.46821546554565, 'accumulated_submission_time': 189.41457438468933, 'accumulated_eval_time': 11.985413312911987, 'accumulated_logging_time': 0.0421442985534668, 'global_step': 684, 'preemption_count': 0}), (1026, {'train/ssim': 0.7229753902980259, 'train/loss': 0.2880307946886335, 'validation/ssim': 0.70181561214037, 'validation/loss': 0.305126321134637, 'validation/num_examples': 3554, 'test/ssim': 0.7192106015254119, 'test/loss': 0.3069072980116413, 'test/num_examples': 3581, 'score': 269.56817269325256, 'total_duration': 285.6784076690674, 'accumulated_submission_time': 269.56817269325256, 'accumulated_eval_time': 16.004467010498047, 'accumulated_logging_time': 0.06655621528625488, 'global_step': 1026, 'preemption_count': 0}), (1372, {'train/ssim': 0.7281092916216169, 'train/loss': 0.2867491585867746, 'validation/ssim': 0.7068357451551069, 'validation/loss': 0.3044106607431767, 'validation/num_examples': 3554, 'test/ssim': 0.7239998756457693, 'test/loss': 0.30622972426085593, 'test/num_examples': 3581, 'score': 349.55478286743164, 'total_duration': 369.7181885242462, 'accumulated_submission_time': 349.55478286743164, 'accumulated_eval_time': 20.019661903381348, 'accumulated_logging_time': 0.09123992919921875, 'global_step': 1372, 'preemption_count': 0}), (1719, {'train/ssim': 0.7329938752310616, 'train/loss': 0.2795459202357701, 'validation/ssim': 0.7116876450830051, 'validation/loss': 0.29747734864105585, 'validation/num_examples': 3554, 'test/ssim': 0.728800262561959, 'test/loss': 0.2991478394543249, 'test/num_examples': 3581, 'score': 429.73734307289124, 'total_duration': 453.9560031890869, 'accumulated_submission_time': 429.73734307289124, 'accumulated_eval_time': 24.035717964172363, 'accumulated_logging_time': 0.11692500114440918, 'global_step': 1719, 'preemption_count': 0}), (2067, {'train/ssim': 0.7248802185058594, 'train/loss': 0.2891953672681536, 'validation/ssim': 0.7033233213236846, 'validation/loss': 0.30676850000659467, 'validation/num_examples': 3554, 'test/ssim': 0.7207346226176348, 'test/loss': 0.3087029349234676, 'test/num_examples': 3581, 'score': 509.9147651195526, 'total_duration': 538.1823544502258, 'accumulated_submission_time': 509.9147651195526, 'accumulated_eval_time': 28.04653525352478, 'accumulated_logging_time': 0.14153599739074707, 'global_step': 2067, 'preemption_count': 0}), (2415, {'train/ssim': 0.72991943359375, 'train/loss': 0.28169032505580355, 'validation/ssim': 0.7089212446583075, 'validation/loss': 0.2988491112017269, 'validation/num_examples': 3554, 'test/ssim': 0.7260800819428931, 'test/loss': 0.30067448534801733, 'test/num_examples': 3581, 'score': 590.0707066059113, 'total_duration': 622.3923435211182, 'accumulated_submission_time': 590.0707066059113, 'accumulated_eval_time': 32.063100814819336, 'accumulated_logging_time': 0.16549324989318848, 'global_step': 2415, 'preemption_count': 0}), (2762, {'train/ssim': 0.735365731375558, 'train/loss': 0.2765935829707554, 'validation/ssim': 0.713966107730726, 'validation/loss': 0.294382897131753, 'validation/num_examples': 3554, 'test/ssim': 0.7312001492250768, 'test/loss': 0.2960129061147375, 'test/num_examples': 3581, 'score': 670.0614335536957, 'total_duration': 706.4358239173889, 'accumulated_submission_time': 670.0614335536957, 'accumulated_eval_time': 36.077672481536865, 'accumulated_logging_time': 0.19008660316467285, 'global_step': 2762, 'preemption_count': 0}), (3107, {'train/ssim': 0.7322643143790108, 'train/loss': 0.2801121303013393, 'validation/ssim': 0.7105216915579277, 'validation/loss': 0.2975265683253025, 'validation/num_examples': 3554, 'test/ssim': 0.7275827637400517, 'test/loss': 0.29931974690641583, 'test/num_examples': 3581, 'score': 750.1785328388214, 'total_duration': 790.608763217926, 'accumulated_submission_time': 750.1785328388214, 'accumulated_eval_time': 40.0933940410614, 'accumulated_logging_time': 0.21664667129516602, 'global_step': 3107, 'preemption_count': 0}), (3455, {'train/ssim': 0.7370850699288505, 'train/loss': 0.27470595496041433, 'validation/ssim': 0.7150101970271173, 'validation/loss': 0.29273261229644415, 'validation/num_examples': 3554, 'test/ssim': 0.7320430854684445, 'test/loss': 0.2944108909217048, 'test/num_examples': 3581, 'score': 830.3153464794159, 'total_duration': 874.7988729476929, 'accumulated_submission_time': 830.3153464794159, 'accumulated_eval_time': 44.107200622558594, 'accumulated_logging_time': 0.24260187149047852, 'global_step': 3455, 'preemption_count': 0}), (3803, {'train/ssim': 0.7389027050563267, 'train/loss': 0.2740594318934849, 'validation/ssim': 0.7170717221132878, 'validation/loss': 0.2919730217052969, 'validation/num_examples': 3554, 'test/ssim': 0.7343342985330564, 'test/loss': 0.29355793270908964, 'test/num_examples': 3581, 'score': 910.3621096611023, 'total_duration': 958.8977530002594, 'accumulated_submission_time': 910.3621096611023, 'accumulated_eval_time': 48.12011766433716, 'accumulated_logging_time': 0.2682778835296631, 'global_step': 3803, 'preemption_count': 0}), (4149, {'train/ssim': 0.7399940490722656, 'train/loss': 0.2729658229010446, 'validation/ssim': 0.7180402473445414, 'validation/loss': 0.2910110224614871, 'validation/num_examples': 3554, 'test/ssim': 0.7352640236665736, 'test/loss': 0.29254370260358487, 'test/num_examples': 3581, 'score': 990.4565176963806, 'total_duration': 1043.0497572422028, 'accumulated_submission_time': 990.4565176963806, 'accumulated_eval_time': 52.13883900642395, 'accumulated_logging_time': 0.29352760314941406, 'global_step': 4149, 'preemption_count': 0}), (4496, {'train/ssim': 0.7390618324279785, 'train/loss': 0.2744659355708531, 'validation/ssim': 0.7164873371113534, 'validation/loss': 0.2924563912910629, 'validation/num_examples': 3554, 'test/ssim': 0.7336459187814158, 'test/loss': 0.29424372174759145, 'test/num_examples': 3581, 'score': 1070.5930817127228, 'total_duration': 1127.2398805618286, 'accumulated_submission_time': 1070.5930817127228, 'accumulated_eval_time': 56.15374946594238, 'accumulated_logging_time': 0.31876206398010254, 'global_step': 4496, 'preemption_count': 0}), (4843, {'train/ssim': 0.7348019736153739, 'train/loss': 0.2777554307665144, 'validation/ssim': 0.7128869154913478, 'validation/loss': 0.2955745424389772, 'validation/num_examples': 3554, 'test/ssim': 0.7299596748682281, 'test/loss': 0.29721179270804243, 'test/num_examples': 3581, 'score': 1150.773977279663, 'total_duration': 1211.4776709079742, 'accumulated_submission_time': 1150.773977279663, 'accumulated_eval_time': 60.17170739173889, 'accumulated_logging_time': 0.3441455364227295, 'global_step': 4843, 'preemption_count': 0}), (5192, {'train/ssim': 0.7410356657845634, 'train/loss': 0.27177795342036654, 'validation/ssim': 0.7192005679120357, 'validation/loss': 0.28972268949818863, 'validation/num_examples': 3554, 'test/ssim': 0.7364080962239947, 'test/loss': 0.29136526900874404, 'test/num_examples': 3581, 'score': 1230.8901679515839, 'total_duration': 1295.6464822292328, 'accumulated_submission_time': 1230.8901679515839, 'accumulated_eval_time': 64.18590641021729, 'accumulated_logging_time': 0.3689992427825928, 'global_step': 5192, 'preemption_count': 0}), (5538, {'train/ssim': 0.7400689806256976, 'train/loss': 0.2726975509098598, 'validation/ssim': 0.7185819729969752, 'validation/loss': 0.2905688352912212, 'validation/num_examples': 3554, 'test/ssim': 0.7357066265533371, 'test/loss': 0.2921690718483838, 'test/num_examples': 3581, 'score': 1310.9333474636078, 'total_duration': 1379.7466549873352, 'accumulated_submission_time': 1310.9333474636078, 'accumulated_eval_time': 68.20439505577087, 'accumulated_logging_time': 0.39395570755004883, 'global_step': 5538, 'preemption_count': 0}), (5887, {'train/ssim': 0.7430743489946637, 'train/loss': 0.2713005372456142, 'validation/ssim': 0.7210018091411086, 'validation/loss': 0.28938642940832515, 'validation/num_examples': 3554, 'test/ssim': 0.7382192092379922, 'test/loss': 0.2909360287476438, 'test/num_examples': 3581, 'score': 1390.9299306869507, 'total_duration': 1463.8018777370453, 'accumulated_submission_time': 1390.9299306869507, 'accumulated_eval_time': 72.22309613227844, 'accumulated_logging_time': 0.42021870613098145, 'global_step': 5887, 'preemption_count': 0}), (6236, {'train/ssim': 0.7420650890895298, 'train/loss': 0.27099316460745676, 'validation/ssim': 0.7202885530608117, 'validation/loss': 0.2892046634843662, 'validation/num_examples': 3554, 'test/ssim': 0.7374493583758028, 'test/loss': 0.2907333395328644, 'test/num_examples': 3581, 'score': 1471.0121450424194, 'total_duration': 1547.9339079856873, 'accumulated_submission_time': 1471.0121450424194, 'accumulated_eval_time': 76.23468589782715, 'accumulated_logging_time': 0.4449434280395508, 'global_step': 6236, 'preemption_count': 0}), (6579, {'train/ssim': 0.7435024806431362, 'train/loss': 0.2706704991204398, 'validation/ssim': 0.720853978351857, 'validation/loss': 0.2891689422899374, 'validation/num_examples': 3554, 'test/ssim': 0.7380951277139766, 'test/loss': 0.29070808007976123, 'test/num_examples': 3581, 'score': 1551.1771442890167, 'total_duration': 1632.15380692482, 'accumulated_submission_time': 1551.1771442890167, 'accumulated_eval_time': 80.25021290779114, 'accumulated_logging_time': 0.4702737331390381, 'global_step': 6579, 'preemption_count': 0}), (6928, {'train/ssim': 0.7426629747663226, 'train/loss': 0.2704187972205026, 'validation/ssim': 0.720276600199599, 'validation/loss': 0.28866671603518923, 'validation/num_examples': 3554, 'test/ssim': 0.7376407302647654, 'test/loss': 0.2901382936308817, 'test/num_examples': 3581, 'score': 1631.2922222614288, 'total_duration': 1716.3261096477509, 'accumulated_submission_time': 1631.2922222614288, 'accumulated_eval_time': 84.26713466644287, 'accumulated_logging_time': 0.49689340591430664, 'global_step': 6928, 'preemption_count': 0}), (7279, {'train/ssim': 0.7441093581063407, 'train/loss': 0.2699455533708845, 'validation/ssim': 0.7217107374613112, 'validation/loss': 0.2883482821952378, 'validation/num_examples': 3554, 'test/ssim': 0.7389450179768221, 'test/loss': 0.2898458498411757, 'test/num_examples': 3581, 'score': 1711.3607697486877, 'total_duration': 1800.455798149109, 'accumulated_submission_time': 1711.3607697486877, 'accumulated_eval_time': 88.28663372993469, 'accumulated_logging_time': 0.5245425701141357, 'global_step': 7279, 'preemption_count': 0}), (7623, {'train/ssim': 0.7333408083234515, 'train/loss': 0.27960704054151264, 'validation/ssim': 0.7108606307373734, 'validation/loss': 0.29829945132245356, 'validation/num_examples': 3554, 'test/ssim': 0.7279741659539933, 'test/loss': 0.29984678658850533, 'test/num_examples': 3581, 'score': 1791.4479806423187, 'total_duration': 1884.6018981933594, 'accumulated_submission_time': 1791.4479806423187, 'accumulated_eval_time': 92.30220317840576, 'accumulated_logging_time': 0.5551633834838867, 'global_step': 7623, 'preemption_count': 0}), (7970, {'train/ssim': 0.7422810282026019, 'train/loss': 0.2711213656834194, 'validation/ssim': 0.7199205560635903, 'validation/loss': 0.2898536557619935, 'validation/num_examples': 3554, 'test/ssim': 0.737044593536198, 'test/loss': 0.2914284687739982, 'test/num_examples': 3581, 'score': 1871.6037764549255, 'total_duration': 1968.8186626434326, 'accumulated_submission_time': 1871.6037764549255, 'accumulated_eval_time': 96.32317352294922, 'accumulated_logging_time': 0.5827598571777344, 'global_step': 7970, 'preemption_count': 0}), (8317, {'train/ssim': 0.7444945062909808, 'train/loss': 0.2702023983001709, 'validation/ssim': 0.7221898136342854, 'validation/loss': 0.2886703911965391, 'validation/num_examples': 3554, 'test/ssim': 0.7393386700205948, 'test/loss': 0.2901830516091874, 'test/num_examples': 3581, 'score': 1951.662151813507, 'total_duration': 2052.933934688568, 'accumulated_submission_time': 1951.662151813507, 'accumulated_eval_time': 100.34027457237244, 'accumulated_logging_time': 0.6097853183746338, 'global_step': 8317, 'preemption_count': 0}), (8661, {'train/ssim': 0.732374940599714, 'train/loss': 0.27880374022892546, 'validation/ssim': 0.7117548971009777, 'validation/loss': 0.2963294274497046, 'validation/num_examples': 3554, 'test/ssim': 0.7288023078618053, 'test/loss': 0.2982390104675719, 'test/num_examples': 3581, 'score': 2031.719271659851, 'total_duration': 2137.048096179962, 'accumulated_submission_time': 2031.719271659851, 'accumulated_eval_time': 104.35645294189453, 'accumulated_logging_time': 0.6381211280822754, 'global_step': 8661, 'preemption_count': 0}), (9010, {'train/ssim': 0.7443432807922363, 'train/loss': 0.2709218774523054, 'validation/ssim': 0.7221872032393079, 'validation/loss': 0.289655952689751, 'validation/num_examples': 3554, 'test/ssim': 0.7392850149879573, 'test/loss': 0.29116046631745673, 'test/num_examples': 3581, 'score': 2111.8080835342407, 'total_duration': 2221.1938774585724, 'accumulated_submission_time': 2111.8080835342407, 'accumulated_eval_time': 108.37405753135681, 'accumulated_logging_time': 0.664588451385498, 'global_step': 9010, 'preemption_count': 0}), (9358, {'train/ssim': 0.7424185616629464, 'train/loss': 0.2705019201551165, 'validation/ssim': 0.7198816749173467, 'validation/loss': 0.28904089554683104, 'validation/num_examples': 3554, 'test/ssim': 0.7372185121998045, 'test/loss': 0.2904191814764556, 'test/num_examples': 3581, 'score': 2191.9307548999786, 'total_duration': 2305.374571084976, 'accumulated_submission_time': 2191.9307548999786, 'accumulated_eval_time': 112.39150047302246, 'accumulated_logging_time': 0.6922500133514404, 'global_step': 9358, 'preemption_count': 0}), (9704, {'train/ssim': 0.7448130335126605, 'train/loss': 0.26915022305079866, 'validation/ssim': 0.7223689004686621, 'validation/loss': 0.2876758307101154, 'validation/num_examples': 3554, 'test/ssim': 0.7396080360103672, 'test/loss': 0.28906123873176137, 'test/num_examples': 3581, 'score': 2271.9885540008545, 'total_duration': 2389.488274335861, 'accumulated_submission_time': 2271.9885540008545, 'accumulated_eval_time': 116.40704345703125, 'accumulated_logging_time': 0.7198827266693115, 'global_step': 9704, 'preemption_count': 0}), (10051, {'train/ssim': 0.7456962721688407, 'train/loss': 0.26879189695630756, 'validation/ssim': 0.7229699095649268, 'validation/loss': 0.28772884577127006, 'validation/num_examples': 3554, 'test/ssim': 0.7401323827143256, 'test/loss': 0.28912334767043074, 'test/num_examples': 3581, 'score': 2351.9646701812744, 'total_duration': 2473.5214030742645, 'accumulated_submission_time': 2351.9646701812744, 'accumulated_eval_time': 120.42432022094727, 'accumulated_logging_time': 0.7467184066772461, 'global_step': 10051, 'preemption_count': 0}), (10401, {'train/ssim': 0.7442936897277832, 'train/loss': 0.2693566083908081, 'validation/ssim': 0.722090962098164, 'validation/loss': 0.2877130803594981, 'validation/num_examples': 3554, 'test/ssim': 0.739315762662315, 'test/loss': 0.28910688300666715, 'test/num_examples': 3581, 'score': 2432.060645341873, 'total_duration': 2557.617630958557, 'accumulated_submission_time': 2432.060645341873, 'accumulated_eval_time': 124.38462400436401, 'accumulated_logging_time': 0.773712158203125, 'global_step': 10401, 'preemption_count': 0}), (10748, {'train/ssim': 0.7448418481009347, 'train/loss': 0.26893132073538645, 'validation/ssim': 0.7225382326691756, 'validation/loss': 0.2874220900141126, 'validation/num_examples': 3554, 'test/ssim': 0.7397670921617565, 'test/loss': 0.2888093600556758, 'test/num_examples': 3581, 'score': 2512.202274799347, 'total_duration': 2641.820770740509, 'accumulated_submission_time': 2512.202274799347, 'accumulated_eval_time': 128.40318179130554, 'accumulated_logging_time': 0.8037357330322266, 'global_step': 10748, 'preemption_count': 0}), (11093, {'train/ssim': 0.7452192306518555, 'train/loss': 0.26873513630458284, 'validation/ssim': 0.7224126589318374, 'validation/loss': 0.28779384804093977, 'validation/num_examples': 3554, 'test/ssim': 0.7395489950214674, 'test/loss': 0.289260280495148, 'test/num_examples': 3581, 'score': 2592.4162380695343, 'total_duration': 2726.093177318573, 'accumulated_submission_time': 2592.4162380695343, 'accumulated_eval_time': 132.41613030433655, 'accumulated_logging_time': 0.836331844329834, 'global_step': 11093, 'preemption_count': 0}), (11443, {'train/ssim': 0.7452154840741839, 'train/loss': 0.2697348083768572, 'validation/ssim': 0.7223850437007597, 'validation/loss': 0.28835425862584413, 'validation/num_examples': 3554, 'test/ssim': 0.7395929007915037, 'test/loss': 0.28987714292882577, 'test/num_examples': 3581, 'score': 2672.483766078949, 'total_duration': 2810.2135293483734, 'accumulated_submission_time': 2672.483766078949, 'accumulated_eval_time': 136.42907905578613, 'accumulated_logging_time': 0.8633337020874023, 'global_step': 11443, 'preemption_count': 0}), (11789, {'train/ssim': 0.7447735241481236, 'train/loss': 0.26923320974622456, 'validation/ssim': 0.7227943261553883, 'validation/loss': 0.2875390082312623, 'validation/num_examples': 3554, 'test/ssim': 0.7399063089046356, 'test/loss': 0.28899190306696804, 'test/num_examples': 3581, 'score': 2752.4405829906464, 'total_duration': 2894.2302720546722, 'accumulated_submission_time': 2752.4405829906464, 'accumulated_eval_time': 140.4444704055786, 'accumulated_logging_time': 0.8953886032104492, 'global_step': 11789, 'preemption_count': 0}), (12137, {'train/ssim': 0.7456636428833008, 'train/loss': 0.26853067534310476, 'validation/ssim': 0.7233629800928532, 'validation/loss': 0.2873849434066369, 'validation/num_examples': 3554, 'test/ssim': 0.7404592216297822, 'test/loss': 0.28867897219046706, 'test/num_examples': 3581, 'score': 2832.651171684265, 'total_duration': 2978.4996314048767, 'accumulated_submission_time': 2832.651171684265, 'accumulated_eval_time': 144.46209335327148, 'accumulated_logging_time': 0.9224934577941895, 'global_step': 12137, 'preemption_count': 0}), (12485, {'train/ssim': 0.7451457296098981, 'train/loss': 0.2689953531537737, 'validation/ssim': 0.722774129941615, 'validation/loss': 0.28749842689355304, 'validation/num_examples': 3554, 'test/ssim': 0.7399579186374267, 'test/loss': 0.2889450316121544, 'test/num_examples': 3581, 'score': 2912.848475217819, 'total_duration': 3062.7552905082703, 'accumulated_submission_time': 2912.848475217819, 'accumulated_eval_time': 148.47949981689453, 'accumulated_logging_time': 0.9494554996490479, 'global_step': 12485, 'preemption_count': 0}), (12834, {'train/ssim': 0.7460318974086216, 'train/loss': 0.2684512138366699, 'validation/ssim': 0.7233857180069991, 'validation/loss': 0.2871742742277627, 'validation/num_examples': 3554, 'test/ssim': 0.7405707586480732, 'test/loss': 0.2885619810392523, 'test/num_examples': 3581, 'score': 2992.999326467514, 'total_duration': 3146.9643874168396, 'accumulated_submission_time': 2992.999326467514, 'accumulated_eval_time': 152.49664402008057, 'accumulated_logging_time': 0.9763846397399902, 'global_step': 12834, 'preemption_count': 0}), (13179, {'train/ssim': 0.745182854788644, 'train/loss': 0.26859872681753977, 'validation/ssim': 0.7225593219128095, 'validation/loss': 0.2874176076911579, 'validation/num_examples': 3554, 'test/ssim': 0.7396684405324979, 'test/loss': 0.28886632165639836, 'test/num_examples': 3581, 'score': 3072.988017320633, 'total_duration': 3231.0089824199677, 'accumulated_submission_time': 3072.988017320633, 'accumulated_eval_time': 156.51189756393433, 'accumulated_logging_time': 1.0034832954406738, 'global_step': 13179, 'preemption_count': 0}), (13526, {'train/ssim': 0.7462560108729771, 'train/loss': 0.2681436708995274, 'validation/ssim': 0.7231661700504713, 'validation/loss': 0.28716347200117825, 'validation/num_examples': 3554, 'test/ssim': 0.7403992943442823, 'test/loss': 0.28855373166320514, 'test/num_examples': 3581, 'score': 3153.0304362773895, 'total_duration': 3315.10955786705, 'accumulated_submission_time': 3153.0304362773895, 'accumulated_eval_time': 160.52774262428284, 'accumulated_logging_time': 1.0317604541778564, 'global_step': 13526, 'preemption_count': 0}), (13876, {'train/ssim': 0.7469626835414341, 'train/loss': 0.26831698417663574, 'validation/ssim': 0.7242131445202589, 'validation/loss': 0.287253771059018, 'validation/num_examples': 3554, 'test/ssim': 0.7413314056609537, 'test/loss': 0.28866107581681094, 'test/num_examples': 3581, 'score': 3233.1198103427887, 'total_duration': 3399.258532524109, 'accumulated_submission_time': 3233.1198103427887, 'accumulated_eval_time': 164.54671454429626, 'accumulated_logging_time': 1.0586469173431396, 'global_step': 13876, 'preemption_count': 0}), (14220, {'train/ssim': 0.7435752323695591, 'train/loss': 0.26951163155691965, 'validation/ssim': 0.721224379660242, 'validation/loss': 0.2880564846882474, 'validation/num_examples': 3554, 'test/ssim': 0.7383425408187309, 'test/loss': 0.2895751203181723, 'test/num_examples': 3581, 'score': 3313.1567661762238, 'total_duration': 3483.3548295497894, 'accumulated_submission_time': 3313.1567661762238, 'accumulated_eval_time': 168.5634524822235, 'accumulated_logging_time': 1.0875027179718018, 'global_step': 14220, 'preemption_count': 0}), (14567, {'train/ssim': 0.7471098899841309, 'train/loss': 0.26741351400102886, 'validation/ssim': 0.7242367754642656, 'validation/loss': 0.28640202665570486, 'validation/num_examples': 3554, 'test/ssim': 0.7413343372574002, 'test/loss': 0.28780746992591105, 'test/num_examples': 3581, 'score': 3393.3027589321136, 'total_duration': 3567.560054063797, 'accumulated_submission_time': 3393.3027589321136, 'accumulated_eval_time': 172.5811402797699, 'accumulated_logging_time': 1.1148772239685059, 'global_step': 14567, 'preemption_count': 0}), (14914, {'train/ssim': 0.7454605102539062, 'train/loss': 0.26764837333134245, 'validation/ssim': 0.7230939720209623, 'validation/loss': 0.2864320290242948, 'validation/num_examples': 3554, 'test/ssim': 0.7402175353645979, 'test/loss': 0.2878112878189577, 'test/num_examples': 3581, 'score': 3473.428725004196, 'total_duration': 3651.744841337204, 'accumulated_submission_time': 3473.428725004196, 'accumulated_eval_time': 176.59819197654724, 'accumulated_logging_time': 1.1427075862884521, 'global_step': 14914, 'preemption_count': 0}), (15260, {'train/ssim': 0.7476382255554199, 'train/loss': 0.2672039951596941, 'validation/ssim': 0.7246152827360017, 'validation/loss': 0.28637049583216095, 'validation/num_examples': 3554, 'test/ssim': 0.7417507603061295, 'test/loss': 0.28775234909505026, 'test/num_examples': 3581, 'score': 3553.576901912689, 'total_duration': 3735.9517509937286, 'accumulated_submission_time': 3553.576901912689, 'accumulated_eval_time': 180.614520072937, 'accumulated_logging_time': 1.1707472801208496, 'global_step': 15260, 'preemption_count': 0}), (15610, {'train/ssim': 0.7465495382036481, 'train/loss': 0.26757264137268066, 'validation/ssim': 0.7237017818830894, 'validation/loss': 0.2865305542610439, 'validation/num_examples': 3554, 'test/ssim': 0.7408511010803547, 'test/loss': 0.28797876378804804, 'test/num_examples': 3581, 'score': 3633.7790439128876, 'total_duration': 3820.211359500885, 'accumulated_submission_time': 3633.7790439128876, 'accumulated_eval_time': 184.63018488883972, 'accumulated_logging_time': 1.1982817649841309, 'global_step': 15610, 'preemption_count': 0}), (15958, {'train/ssim': 0.7465058735438755, 'train/loss': 0.26753524371555876, 'validation/ssim': 0.7236025868739449, 'validation/loss': 0.2864478459570203, 'validation/num_examples': 3554, 'test/ssim': 0.7408671907724798, 'test/loss': 0.28775504207318137, 'test/num_examples': 3581, 'score': 3713.8195548057556, 'total_duration': 3904.3096396923065, 'accumulated_submission_time': 3713.8195548057556, 'accumulated_eval_time': 188.6462926864624, 'accumulated_logging_time': 1.2263374328613281, 'global_step': 15958, 'preemption_count': 0}), (16305, {'train/ssim': 0.7472934722900391, 'train/loss': 0.2676750591823033, 'validation/ssim': 0.7245056461469471, 'validation/loss': 0.28667465836799205, 'validation/num_examples': 3554, 'test/ssim': 0.7417191263351718, 'test/loss': 0.2879381645860968, 'test/num_examples': 3581, 'score': 3793.9894206523895, 'total_duration': 3988.544013738632, 'accumulated_submission_time': 3793.9894206523895, 'accumulated_eval_time': 192.66775226593018, 'accumulated_logging_time': 1.255561113357544, 'global_step': 16305, 'preemption_count': 0}), (16653, {'train/ssim': 0.7460013798304966, 'train/loss': 0.26769552912030903, 'validation/ssim': 0.72336675829611, 'validation/loss': 0.2865367024281619, 'validation/num_examples': 3554, 'test/ssim': 0.7405575323757331, 'test/loss': 0.28791178021807806, 'test/num_examples': 3581, 'score': 3874.1030700206757, 'total_duration': 4072.714470386505, 'accumulated_submission_time': 3874.1030700206757, 'accumulated_eval_time': 196.6825180053711, 'accumulated_logging_time': 1.2838151454925537, 'global_step': 16653, 'preemption_count': 0}), (16999, {'train/ssim': 0.7481280054364886, 'train/loss': 0.2673676184245518, 'validation/ssim': 0.7252748883300506, 'validation/loss': 0.2864205398516636, 'validation/num_examples': 3554, 'test/ssim': 0.7424530480967257, 'test/loss': 0.28772518069542374, 'test/num_examples': 3581, 'score': 3954.1229753494263, 'total_duration': 4156.801654577255, 'accumulated_submission_time': 3954.1229753494263, 'accumulated_eval_time': 200.70232272148132, 'accumulated_logging_time': 1.3174071311950684, 'global_step': 16999, 'preemption_count': 0}), (17344, {'train/ssim': 0.746361528124128, 'train/loss': 0.2677748032978603, 'validation/ssim': 0.7239071787510551, 'validation/loss': 0.28663830174847005, 'validation/num_examples': 3554, 'test/ssim': 0.7410125434148981, 'test/loss': 0.28796458304244626, 'test/num_examples': 3581, 'score': 4034.1249663829803, 'total_duration': 4240.8676471710205, 'accumulated_submission_time': 4034.1249663829803, 'accumulated_eval_time': 204.7229642868042, 'accumulated_logging_time': 1.3461709022521973, 'global_step': 17344, 'preemption_count': 0}), (17693, {'train/ssim': 0.748692240033831, 'train/loss': 0.26730574880327496, 'validation/ssim': 0.7252666449774902, 'validation/loss': 0.28687419902090955, 'validation/num_examples': 3554, 'test/ssim': 0.7423913482180257, 'test/loss': 0.28826963951453854, 'test/num_examples': 3581, 'score': 4114.188055753708, 'total_duration': 4324.98748755455, 'accumulated_submission_time': 4114.188055753708, 'accumulated_eval_time': 208.73958683013916, 'accumulated_logging_time': 1.3738317489624023, 'global_step': 17693, 'preemption_count': 0}), (18042, {'train/ssim': 0.7466691562107631, 'train/loss': 0.2669903721128191, 'validation/ssim': 0.7238836165016531, 'validation/loss': 0.28597083062218626, 'validation/num_examples': 3554, 'test/ssim': 0.7410724025237364, 'test/loss': 0.2873323808599204, 'test/num_examples': 3581, 'score': 4194.349546909332, 'total_duration': 4409.206943273544, 'accumulated_submission_time': 4194.349546909332, 'accumulated_eval_time': 212.75606155395508, 'accumulated_logging_time': 1.402545690536499, 'global_step': 18042, 'preemption_count': 0}), (18389, {'train/ssim': 0.7479186739240374, 'train/loss': 0.2667764595576695, 'validation/ssim': 0.7248502869785804, 'validation/loss': 0.28601907140831634, 'validation/num_examples': 3554, 'test/ssim': 0.7420026730705459, 'test/loss': 0.28740887507417623, 'test/num_examples': 3581, 'score': 4274.440649032593, 'total_duration': 4493.3561198711395, 'accumulated_submission_time': 4274.440649032593, 'accumulated_eval_time': 216.77316308021545, 'accumulated_logging_time': 1.4304280281066895, 'global_step': 18389, 'preemption_count': 0}), (18720, {'train/ssim': 0.7479407446725028, 'train/loss': 0.26627884592328754, 'validation/ssim': 0.7245068826498312, 'validation/loss': 0.285733319026537, 'validation/num_examples': 3554, 'test/ssim': 0.7416746069751815, 'test/loss': 0.28710596616692263, 'test/num_examples': 3581, 'score': 4351.382478237152, 'total_duration': 4577.62344622612, 'accumulated_submission_time': 4351.382478237152, 'accumulated_eval_time': 220.79004406929016, 'accumulated_logging_time': 4.727059602737427, 'global_step': 18720, 'preemption_count': 0}), (19068, {'train/ssim': 0.7482282093593052, 'train/loss': 0.2664348908833095, 'validation/ssim': 0.7249527106341446, 'validation/loss': 0.2857875362432734, 'validation/num_examples': 3554, 'test/ssim': 0.7421484347729336, 'test/loss': 0.2871270327553407, 'test/num_examples': 3581, 'score': 4431.4831800460815, 'total_duration': 4661.779294967651, 'accumulated_submission_time': 4431.4831800460815, 'accumulated_eval_time': 224.80307006835938, 'accumulated_logging_time': 4.756349325180054, 'global_step': 19068, 'preemption_count': 0}), (19413, {'train/ssim': 0.747701713017055, 'train/loss': 0.2666091578347342, 'validation/ssim': 0.7246733296769485, 'validation/loss': 0.28584989377066333, 'validation/num_examples': 3554, 'test/ssim': 0.7418394581428023, 'test/loss': 0.28721603738699036, 'test/num_examples': 3581, 'score': 4511.659183979034, 'total_duration': 4746.009649276733, 'accumulated_submission_time': 4511.659183979034, 'accumulated_eval_time': 228.81460237503052, 'accumulated_logging_time': 4.786910057067871, 'global_step': 19413, 'preemption_count': 0}), (19760, {'train/ssim': 0.7489380155290876, 'train/loss': 0.26600561823163715, 'validation/ssim': 0.7252018659652856, 'validation/loss': 0.28576849066412846, 'validation/num_examples': 3554, 'test/ssim': 0.7423292392793563, 'test/loss': 0.28718453976935565, 'test/num_examples': 3581, 'score': 4591.8332052230835, 'total_duration': 4830.240214586258, 'accumulated_submission_time': 4591.8332052230835, 'accumulated_eval_time': 232.8302583694458, 'accumulated_logging_time': 4.815237998962402, 'global_step': 19760, 'preemption_count': 0}), (20110, {'train/ssim': 0.7484143120901925, 'train/loss': 0.26632281712123324, 'validation/ssim': 0.724964320022334, 'validation/loss': 0.28584302431019626, 'validation/num_examples': 3554, 'test/ssim': 0.7421734556077213, 'test/loss': 0.28721054916573585, 'test/num_examples': 3581, 'score': 4671.902544498444, 'total_duration': 4914.371288776398, 'accumulated_submission_time': 4671.902544498444, 'accumulated_eval_time': 236.84919047355652, 'accumulated_logging_time': 4.845395565032959, 'global_step': 20110, 'preemption_count': 0}), (20456, {'train/ssim': 0.7484644481113979, 'train/loss': 0.2665191377912249, 'validation/ssim': 0.7253575279394696, 'validation/loss': 0.2858613657696434, 'validation/num_examples': 3554, 'test/ssim': 0.7424498437936331, 'test/loss': 0.28725380725748745, 'test/num_examples': 3581, 'score': 4752.0476224422455, 'total_duration': 4998.575645685196, 'accumulated_submission_time': 4752.0476224422455, 'accumulated_eval_time': 240.86488962173462, 'accumulated_logging_time': 4.876446485519409, 'global_step': 20456, 'preemption_count': 0}), (20805, {'train/ssim': 0.7486716679164341, 'train/loss': 0.26592150756290983, 'validation/ssim': 0.7250687358214336, 'validation/loss': 0.28558404565058737, 'validation/num_examples': 3554, 'test/ssim': 0.7422169523177883, 'test/loss': 0.2869579205463732, 'test/num_examples': 3581, 'score': 4832.189853668213, 'total_duration': 5082.776785135269, 'accumulated_submission_time': 4832.189853668213, 'accumulated_eval_time': 244.88236665725708, 'accumulated_logging_time': 4.90512490272522, 'global_step': 20805, 'preemption_count': 0}), (21151, {'train/ssim': 0.748410837990897, 'train/loss': 0.2661462851933071, 'validation/ssim': 0.7249383534617684, 'validation/loss': 0.2856016486430343, 'validation/num_examples': 3554, 'test/ssim': 0.7421067788327282, 'test/loss': 0.28694370571244066, 'test/num_examples': 3581, 'score': 4912.309539794922, 'total_duration': 5166.949881315231, 'accumulated_submission_time': 4912.309539794922, 'accumulated_eval_time': 248.89379501342773, 'accumulated_logging_time': 4.9343202114105225, 'global_step': 21151, 'preemption_count': 0}), (21499, {'train/ssim': 0.7486587933131627, 'train/loss': 0.26630115509033203, 'validation/ssim': 0.7253595200830051, 'validation/loss': 0.28571490887248524, 'validation/num_examples': 3554, 'test/ssim': 0.7424884999607303, 'test/loss': 0.2870643443150482, 'test/num_examples': 3581, 'score': 4992.323907136917, 'total_duration': 5251.02219581604, 'accumulated_submission_time': 4992.323907136917, 'accumulated_eval_time': 252.9103980064392, 'accumulated_logging_time': 4.963292837142944, 'global_step': 21499, 'preemption_count': 0}), (21844, {'train/ssim': 0.7488077027457101, 'train/loss': 0.26583780561174664, 'validation/ssim': 0.7251955460616559, 'validation/loss': 0.28563822852002146, 'validation/num_examples': 3554, 'test/ssim': 0.74234614709142, 'test/loss': 0.28698955451733105, 'test/num_examples': 3581, 'score': 5072.416844844818, 'total_duration': 5335.177726268768, 'accumulated_submission_time': 5072.416844844818, 'accumulated_eval_time': 256.9296944141388, 'accumulated_logging_time': 4.993821382522583, 'global_step': 21844, 'preemption_count': 0}), (22193, {'train/ssim': 0.7486767087663923, 'train/loss': 0.2658830199922834, 'validation/ssim': 0.7250403649497046, 'validation/loss': 0.2855381576546673, 'validation/num_examples': 3554, 'test/ssim': 0.7422395869694219, 'test/loss': 0.2869001408257121, 'test/num_examples': 3581, 'score': 5152.545783519745, 'total_duration': 5419.370491504669, 'accumulated_submission_time': 5152.545783519745, 'accumulated_eval_time': 260.95118141174316, 'accumulated_logging_time': 5.023503065109253, 'global_step': 22193, 'preemption_count': 0}), (22543, {'train/ssim': 0.7485130855015346, 'train/loss': 0.26599107469831196, 'validation/ssim': 0.7248971366989659, 'validation/loss': 0.2855696197836065, 'validation/num_examples': 3554, 'test/ssim': 0.7420529192701061, 'test/loss': 0.2869052881636589, 'test/num_examples': 3581, 'score': 5232.754349708557, 'total_duration': 5503.637329339981, 'accumulated_submission_time': 5232.754349708557, 'accumulated_eval_time': 264.9676489830017, 'accumulated_logging_time': 5.052587985992432, 'global_step': 22543, 'preemption_count': 0}), (22886, {'train/ssim': 0.748805318559919, 'train/loss': 0.26593383720942904, 'validation/ssim': 0.7251649769625774, 'validation/loss': 0.2858411352085678, 'validation/num_examples': 3554, 'test/ssim': 0.7422529495950851, 'test/loss': 0.2871465653688739, 'test/num_examples': 3581, 'score': 5312.916896104813, 'total_duration': 5587.861164093018, 'accumulated_submission_time': 5312.916896104813, 'accumulated_eval_time': 268.98533368110657, 'accumulated_logging_time': 5.083728313446045, 'global_step': 22886, 'preemption_count': 0}), (23231, {'train/ssim': 0.7487833840506417, 'train/loss': 0.2657624823706491, 'validation/ssim': 0.7251254775648917, 'validation/loss': 0.28551413171668366, 'validation/num_examples': 3554, 'test/ssim': 0.7422787885498116, 'test/loss': 0.2868351002905962, 'test/num_examples': 3581, 'score': 5392.880267381668, 'total_duration': 5671.883190155029, 'accumulated_submission_time': 5392.880267381668, 'accumulated_eval_time': 273.00149416923523, 'accumulated_logging_time': 5.113495111465454, 'global_step': 23231, 'preemption_count': 0}), (23577, {'train/ssim': 0.7490690095084054, 'train/loss': 0.2659006799970354, 'validation/ssim': 0.725525623637099, 'validation/loss': 0.28556184011962754, 'validation/num_examples': 3554, 'test/ssim': 0.7426354206663641, 'test/loss': 0.2869184462593375, 'test/num_examples': 3581, 'score': 5472.882793188095, 'total_duration': 5755.94358754158, 'accumulated_submission_time': 5472.882793188095, 'accumulated_eval_time': 277.0170331001282, 'accumulated_logging_time': 5.143171548843384, 'global_step': 23577, 'preemption_count': 0}), (23922, {'train/ssim': 0.749016353062221, 'train/loss': 0.2657322883605957, 'validation/ssim': 0.7253279205648565, 'validation/loss': 0.28553977197787705, 'validation/num_examples': 3554, 'test/ssim': 0.7424687287288816, 'test/loss': 0.28693204750331613, 'test/num_examples': 3581, 'score': 5552.945104598999, 'total_duration': 5840.066252231598, 'accumulated_submission_time': 5552.945104598999, 'accumulated_eval_time': 281.03462076187134, 'accumulated_logging_time': 5.173579931259155, 'global_step': 23922, 'preemption_count': 0}), (24267, {'train/ssim': 0.7493527276175362, 'train/loss': 0.2656536953789847, 'validation/ssim': 0.7255556431793402, 'validation/loss': 0.2854886288446996, 'validation/num_examples': 3554, 'test/ssim': 0.742668554523876, 'test/loss': 0.2868933231595574, 'test/num_examples': 3581, 'score': 5632.908239126205, 'total_duration': 5924.096672773361, 'accumulated_submission_time': 5632.908239126205, 'accumulated_eval_time': 285.0586128234863, 'accumulated_logging_time': 5.204019546508789, 'global_step': 24267, 'preemption_count': 0}), (24614, {'train/ssim': 0.749849796295166, 'train/loss': 0.2658327988215855, 'validation/ssim': 0.7261342578344823, 'validation/loss': 0.28566762981082056, 'validation/num_examples': 3554, 'test/ssim': 0.7432403521842712, 'test/loss': 0.28705173163266196, 'test/num_examples': 3581, 'score': 5712.8686356544495, 'total_duration': 6008.117910861969, 'accumulated_submission_time': 5712.8686356544495, 'accumulated_eval_time': 289.0750644207001, 'accumulated_logging_time': 5.235795736312866, 'global_step': 24614, 'preemption_count': 0}), (24958, {'train/ssim': 0.7492024557931083, 'train/loss': 0.265755363873073, 'validation/ssim': 0.725492238059229, 'validation/loss': 0.2856205568329699, 'validation/num_examples': 3554, 'test/ssim': 0.7426132632513613, 'test/loss': 0.28698297546949175, 'test/num_examples': 3581, 'score': 5792.95509147644, 'total_duration': 6092.265564203262, 'accumulated_submission_time': 5792.95509147644, 'accumulated_eval_time': 293.0931673049927, 'accumulated_logging_time': 5.266326189041138, 'global_step': 24958, 'preemption_count': 0}), (25303, {'train/ssim': 0.7492395809718541, 'train/loss': 0.26547603947775705, 'validation/ssim': 0.7254227878139069, 'validation/loss': 0.2854243306947278, 'validation/num_examples': 3554, 'test/ssim': 0.7425200657550265, 'test/loss': 0.2868363615588348, 'test/num_examples': 3581, 'score': 5872.948161840439, 'total_duration': 6176.321474313736, 'accumulated_submission_time': 5872.948161840439, 'accumulated_eval_time': 297.111275434494, 'accumulated_logging_time': 5.2984983921051025, 'global_step': 25303, 'preemption_count': 0}), (25649, {'train/ssim': 0.7495963232857841, 'train/loss': 0.2655596562794277, 'validation/ssim': 0.7257776641416361, 'validation/loss': 0.28545438458427125, 'validation/num_examples': 3554, 'test/ssim': 0.7429180811051382, 'test/loss': 0.2868049662061924, 'test/num_examples': 3581, 'score': 5953.030558347702, 'total_duration': 6260.4646916389465, 'accumulated_submission_time': 5953.030558347702, 'accumulated_eval_time': 301.1283836364746, 'accumulated_logging_time': 5.329797029495239, 'global_step': 25649, 'preemption_count': 0}), (25994, {'train/ssim': 0.7489735058375767, 'train/loss': 0.26555395126342773, 'validation/ssim': 0.7251500015387592, 'validation/loss': 0.28540963004932823, 'validation/num_examples': 3554, 'test/ssim': 0.7422948782419366, 'test/loss': 0.2868030572596691, 'test/num_examples': 3581, 'score': 6033.104256391525, 'total_duration': 6344.598982095718, 'accumulated_submission_time': 6033.104256391525, 'accumulated_eval_time': 305.14564299583435, 'accumulated_logging_time': 5.360304832458496, 'global_step': 25994, 'preemption_count': 0}), (26340, {'train/ssim': 0.749401501246861, 'train/loss': 0.26525565556117464, 'validation/ssim': 0.7253881657331528, 'validation/loss': 0.28532582263162987, 'validation/num_examples': 3554, 'test/ssim': 0.7425187703984572, 'test/loss': 0.28670897346673413, 'test/num_examples': 3581, 'score': 6113.080691099167, 'total_duration': 6428.634559392929, 'accumulated_submission_time': 6113.080691099167, 'accumulated_eval_time': 309.16142416000366, 'accumulated_logging_time': 5.391079664230347, 'global_step': 26340, 'preemption_count': 0}), (26688, {'train/ssim': 0.7494032042367118, 'train/loss': 0.26542052200862337, 'validation/ssim': 0.7254571351162422, 'validation/loss': 0.28544629579457126, 'validation/num_examples': 3554, 'test/ssim': 0.7425824474003421, 'test/loss': 0.28681355646554735, 'test/num_examples': 3581, 'score': 6193.06077671051, 'total_duration': 6512.6798322200775, 'accumulated_submission_time': 6193.06077671051, 'accumulated_eval_time': 313.17753505706787, 'accumulated_logging_time': 5.427402496337891, 'global_step': 26688, 'preemption_count': 0}), (27033, {'train/ssim': 0.7493421009608677, 'train/loss': 0.2654526914869036, 'validation/ssim': 0.7255051526449071, 'validation/loss': 0.28537818509404017, 'validation/num_examples': 3554, 'test/ssim': 0.7426219216873778, 'test/loss': 0.2867420732359153, 'test/num_examples': 3581, 'score': 6273.084081888199, 'total_duration': 6596.759754896164, 'accumulated_submission_time': 6273.084081888199, 'accumulated_eval_time': 317.19087767601013, 'accumulated_logging_time': 5.4581146240234375, 'global_step': 27033, 'preemption_count': 0}), (27380, {'train/ssim': 0.7501442773001534, 'train/loss': 0.26509480816977365, 'validation/ssim': 0.7259720011782499, 'validation/loss': 0.28541230913891036, 'validation/num_examples': 3554, 'test/ssim': 0.7430699105304035, 'test/loss': 0.28683428217065765, 'test/num_examples': 3581, 'score': 6353.071182966232, 'total_duration': 6680.812620401382, 'accumulated_submission_time': 6353.071182966232, 'accumulated_eval_time': 321.21122121810913, 'accumulated_logging_time': 5.4910569190979, 'global_step': 27380, 'preemption_count': 0}), (27728, {'train/ssim': 0.7496339934212821, 'train/loss': 0.2653770787375314, 'validation/ssim': 0.7256522277935074, 'validation/loss': 0.2854231972337507, 'validation/num_examples': 3554, 'test/ssim': 0.7427992491840617, 'test/loss': 0.2867781727782044, 'test/num_examples': 3581, 'score': 6433.0986251831055, 'total_duration': 6764.905099153519, 'accumulated_submission_time': 6433.0986251831055, 'accumulated_eval_time': 325.23206520080566, 'accumulated_logging_time': 5.522183656692505, 'global_step': 27728, 'preemption_count': 0}), (28073, {'train/ssim': 0.749655042375837, 'train/loss': 0.26534245695386616, 'validation/ssim': 0.7257410499173467, 'validation/loss': 0.2853482342464037, 'validation/num_examples': 3554, 'test/ssim': 0.7428340874581123, 'test/loss': 0.28674350494580775, 'test/num_examples': 3581, 'score': 6513.174396276474, 'total_duration': 6849.044062137604, 'accumulated_submission_time': 6513.174396276474, 'accumulated_eval_time': 329.251145362854, 'accumulated_logging_time': 5.553809642791748, 'global_step': 28073, 'preemption_count': 0}), (28419, {'train/ssim': 0.7501136234828404, 'train/loss': 0.26499782289777485, 'validation/ssim': 0.7258814616892938, 'validation/loss': 0.2853657857178971, 'validation/num_examples': 3554, 'test/ssim': 0.7429455562997417, 'test/loss': 0.2867419709709229, 'test/num_examples': 3581, 'score': 6593.317857980728, 'total_duration': 6933.250350475311, 'accumulated_submission_time': 6593.317857980728, 'accumulated_eval_time': 333.2688903808594, 'accumulated_logging_time': 5.586345434188843, 'global_step': 28419, 'preemption_count': 0}), (28766, {'train/ssim': 0.74993896484375, 'train/loss': 0.2651689052581787, 'validation/ssim': 0.7257976542715954, 'validation/loss': 0.285333516427353, 'validation/num_examples': 3554, 'test/ssim': 0.7429291257243088, 'test/loss': 0.2867050533086952, 'test/num_examples': 3581, 'score': 6673.433345794678, 'total_duration': 7017.428941488266, 'accumulated_submission_time': 6673.433345794678, 'accumulated_eval_time': 337.28736329078674, 'accumulated_logging_time': 5.618357419967651, 'global_step': 28766, 'preemption_count': 0}), (29111, {'train/ssim': 0.7497790881565639, 'train/loss': 0.2652667249952044, 'validation/ssim': 0.7257436603123242, 'validation/loss': 0.28534964248579947, 'validation/num_examples': 3554, 'test/ssim': 0.7428636761292237, 'test/loss': 0.2867233246539898, 'test/num_examples': 3581, 'score': 6753.462169647217, 'total_duration': 7101.522633552551, 'accumulated_submission_time': 6753.462169647217, 'accumulated_eval_time': 341.3042325973511, 'accumulated_logging_time': 5.653614521026611, 'global_step': 29111, 'preemption_count': 0}), (29455, {'train/ssim': 0.7503256797790527, 'train/loss': 0.2649745089667184, 'validation/ssim': 0.7260548468714828, 'validation/loss': 0.28538472825513506, 'validation/num_examples': 3554, 'test/ssim': 0.7431262926295029, 'test/loss': 0.28681168160735476, 'test/num_examples': 3581, 'score': 6833.543080806732, 'total_duration': 7185.665328025818, 'accumulated_submission_time': 6833.543080806732, 'accumulated_eval_time': 345.3211672306061, 'accumulated_logging_time': 5.685898780822754, 'global_step': 29455, 'preemption_count': 0}), (29801, {'train/ssim': 0.7499323572431292, 'train/loss': 0.2650454044342041, 'validation/ssim': 0.7257351421813449, 'validation/loss': 0.2852960950414586, 'validation/num_examples': 3554, 'test/ssim': 0.742863471599239, 'test/loss': 0.2866652722266825, 'test/num_examples': 3581, 'score': 6913.672247648239, 'total_duration': 7269.804100990295, 'accumulated_submission_time': 6913.672247648239, 'accumulated_eval_time': 349.28695940971375, 'accumulated_logging_time': 5.716902494430542, 'global_step': 29801, 'preemption_count': 0}), (30146, {'train/ssim': 0.7499641690935407, 'train/loss': 0.2652068478720529, 'validation/ssim': 0.725912923818233, 'validation/loss': 0.28535984363459305, 'validation/num_examples': 3554, 'test/ssim': 0.7429881667132086, 'test/loss': 0.28673989158274577, 'test/num_examples': 3581, 'score': 6993.665600538254, 'total_duration': 7353.8672597408295, 'accumulated_submission_time': 6993.665600538254, 'accumulated_eval_time': 353.3090696334839, 'accumulated_logging_time': 5.7517173290252686, 'global_step': 30146, 'preemption_count': 0}), (30491, {'train/ssim': 0.7503576959882464, 'train/loss': 0.264944110597883, 'validation/ssim': 0.7260252394968697, 'validation/loss': 0.2854310284186832, 'validation/num_examples': 3554, 'test/ssim': 0.7430889318189752, 'test/loss': 0.28682920300937237, 'test/num_examples': 3581, 'score': 7073.665458440781, 'total_duration': 7437.925004243851, 'accumulated_submission_time': 7073.665458440781, 'accumulated_eval_time': 357.32208609580994, 'accumulated_logging_time': 5.783747434616089, 'global_step': 30491, 'preemption_count': 0}), (30838, {'train/ssim': 0.7499535424368722, 'train/loss': 0.26497530937194824, 'validation/ssim': 0.7257873500808948, 'validation/loss': 0.28530131583141355, 'validation/num_examples': 3554, 'test/ssim': 0.7428631307159314, 'test/loss': 0.2866669084665596, 'test/num_examples': 3581, 'score': 7153.841228246689, 'total_duration': 7522.169150829315, 'accumulated_submission_time': 7153.841228246689, 'accumulated_eval_time': 361.3407151699066, 'accumulated_logging_time': 5.820956230163574, 'global_step': 30838, 'preemption_count': 0}), (31183, {'train/ssim': 0.7500086511884417, 'train/loss': 0.26507064274379183, 'validation/ssim': 0.7258787139051069, 'validation/loss': 0.285347959467985, 'validation/num_examples': 3554, 'test/ssim': 0.7429502604893884, 'test/loss': 0.2867455502456541, 'test/num_examples': 3581, 'score': 7233.882091283798, 'total_duration': 7606.274645090103, 'accumulated_submission_time': 7233.882091283798, 'accumulated_eval_time': 365.355765581131, 'accumulated_logging_time': 5.85828971862793, 'global_step': 31183, 'preemption_count': 0}), (31525, {'train/ssim': 0.7500947543552944, 'train/loss': 0.2649495601654053, 'validation/ssim': 0.7257277918586452, 'validation/loss': 0.2854118454503288, 'validation/num_examples': 3554, 'test/ssim': 0.7428442457806828, 'test/loss': 0.2868032617896537, 'test/num_examples': 3581, 'score': 7313.855280160904, 'total_duration': 7690.314583301544, 'accumulated_submission_time': 7313.855280160904, 'accumulated_eval_time': 369.37527203559875, 'accumulated_logging_time': 5.89311146736145, 'global_step': 31525, 'preemption_count': 0}), (31870, {'train/ssim': 0.7500623975481305, 'train/loss': 0.26489038126809256, 'validation/ssim': 0.7257400194982766, 'validation/loss': 0.28527347734287073, 'validation/num_examples': 3554, 'test/ssim': 0.7428506543868681, 'test/loss': 0.2866636359868054, 'test/num_examples': 3581, 'score': 7393.850246191025, 'total_duration': 7774.377434492111, 'accumulated_submission_time': 7393.850246191025, 'accumulated_eval_time': 373.39921855926514, 'accumulated_logging_time': 5.924740552902222, 'global_step': 31870, 'preemption_count': 0}), (32217, {'train/ssim': 0.7503595352172852, 'train/loss': 0.26500085421970915, 'validation/ssim': 0.7261762302379361, 'validation/loss': 0.28532025836865155, 'validation/num_examples': 3554, 'test/ssim': 0.7432891666739389, 'test/loss': 0.28666840835311364, 'test/num_examples': 3581, 'score': 7473.869105577469, 'total_duration': 7858.462511301041, 'accumulated_submission_time': 7473.869105577469, 'accumulated_eval_time': 377.42104148864746, 'accumulated_logging_time': 5.95652961730957, 'global_step': 32217, 'preemption_count': 0}), (32561, {'train/ssim': 0.7500896453857422, 'train/loss': 0.26509114674159456, 'validation/ssim': 0.7257870753024761, 'validation/loss': 0.2854902431679094, 'validation/num_examples': 3554, 'test/ssim': 0.742864085189193, 'test/loss': 0.28693194523832377, 'test/num_examples': 3581, 'score': 7553.872319459915, 'total_duration': 7942.528846740723, 'accumulated_submission_time': 7553.872319459915, 'accumulated_eval_time': 381.439279794693, 'accumulated_logging_time': 5.988731384277344, 'global_step': 32561, 'preemption_count': 0}), (32908, {'train/ssim': 0.750241756439209, 'train/loss': 0.2648369073867798, 'validation/ssim': 0.7258719131392445, 'validation/loss': 0.28530545468134494, 'validation/num_examples': 3554, 'test/ssim': 0.7429668955948059, 'test/loss': 0.286711257384896, 'test/num_examples': 3581, 'score': 7633.981284618378, 'total_duration': 8026.701743841171, 'accumulated_submission_time': 7633.981284618378, 'accumulated_eval_time': 385.458370923996, 'accumulated_logging_time': 6.020787715911865, 'global_step': 32908, 'preemption_count': 0}), (33255, {'train/ssim': 0.7501583780561175, 'train/loss': 0.26490340914045063, 'validation/ssim': 0.7258987727296707, 'validation/loss': 0.28526111231402995, 'validation/num_examples': 3554, 'test/ssim': 0.7429962797359327, 'test/loss': 0.2866541935191811, 'test/num_examples': 3581, 'score': 7714.053889751434, 'total_duration': 8110.837794303894, 'accumulated_submission_time': 7714.053889751434, 'accumulated_eval_time': 389.4760494232178, 'accumulated_logging_time': 6.053780794143677, 'global_step': 33255, 'preemption_count': 0}), (33598, {'train/ssim': 0.7500778606959752, 'train/loss': 0.2648886442184448, 'validation/ssim': 0.7257746415790307, 'validation/loss': 0.2852774788035928, 'validation/num_examples': 3554, 'test/ssim': 0.7428910831471656, 'test/loss': 0.2866700445929908, 'test/num_examples': 3581, 'score': 7794.201321601868, 'total_duration': 8195.054210424423, 'accumulated_submission_time': 7794.201321601868, 'accumulated_eval_time': 393.4959604740143, 'accumulated_logging_time': 6.090385913848877, 'global_step': 33598, 'preemption_count': 0}), (33945, {'train/ssim': 0.7502149173191616, 'train/loss': 0.26476570538112093, 'validation/ssim': 0.7258221095508582, 'validation/loss': 0.2852540195960977, 'validation/num_examples': 3554, 'test/ssim': 0.7429065592493368, 'test/loss': 0.2866699423279985, 'test/num_examples': 3581, 'score': 7874.296406030655, 'total_duration': 8279.21177649498, 'accumulated_submission_time': 7874.296406030655, 'accumulated_eval_time': 397.5133173465729, 'accumulated_logging_time': 6.123018741607666, 'global_step': 33945, 'preemption_count': 0}), (34293, {'train/ssim': 0.7502946172441755, 'train/loss': 0.26481943471091135, 'validation/ssim': 0.7260055241453293, 'validation/loss': 0.2852201703296462, 'validation/num_examples': 3554, 'test/ssim': 0.7431016808546844, 'test/loss': 0.2866239912581158, 'test/num_examples': 3581, 'score': 7954.259927272797, 'total_duration': 8363.237367153168, 'accumulated_submission_time': 7954.259927272797, 'accumulated_eval_time': 401.5292658805847, 'accumulated_logging_time': 6.1560492515563965, 'global_step': 34293, 'preemption_count': 0}), (34639, {'train/ssim': 0.7502439362662179, 'train/loss': 0.26481923035212923, 'validation/ssim': 0.7259190376380487, 'validation/loss': 0.2852440760520716, 'validation/num_examples': 3554, 'test/ssim': 0.7430262092903519, 'test/loss': 0.286623650374808, 'test/num_examples': 3581, 'score': 8034.41494178772, 'total_duration': 8447.455779075623, 'accumulated_submission_time': 8034.41494178772, 'accumulated_eval_time': 405.54572916030884, 'accumulated_logging_time': 6.190333127975464, 'global_step': 34639, 'preemption_count': 0}), (34986, {'train/ssim': 0.7504809924534389, 'train/loss': 0.264769230570112, 'validation/ssim': 0.7261091843037775, 'validation/loss': 0.28525249114114376, 'validation/num_examples': 3554, 'test/ssim': 0.7431830837885717, 'test/loss': 0.28666776067482896, 'test/num_examples': 3581, 'score': 8114.595928907394, 'total_duration': 8531.699686050415, 'accumulated_submission_time': 8114.595928907394, 'accumulated_eval_time': 409.5631048679352, 'accumulated_logging_time': 6.223457336425781, 'global_step': 34986, 'preemption_count': 0}), (35334, {'train/ssim': 0.7502155985151019, 'train/loss': 0.26476430892944336, 'validation/ssim': 0.7258480761114238, 'validation/loss': 0.2852156708330402, 'validation/num_examples': 3554, 'test/ssim': 0.7429592598087127, 'test/loss': 0.2866166963553302, 'test/num_examples': 3581, 'score': 8194.691151618958, 'total_duration': 8615.862161159515, 'accumulated_submission_time': 8194.691151618958, 'accumulated_eval_time': 413.5802364349365, 'accumulated_logging_time': 6.2608723640441895, 'global_step': 35334, 'preemption_count': 0}), (35681, {'train/ssim': 0.7504230907985142, 'train/loss': 0.26478004455566406, 'validation/ssim': 0.7260905680659117, 'validation/loss': 0.28522551133515933, 'validation/num_examples': 3554, 'test/ssim': 0.7431732663493088, 'test/loss': 0.28662709329621616, 'test/num_examples': 3581, 'score': 8274.671577215195, 'total_duration': 8699.908791542053, 'accumulated_submission_time': 8274.671577215195, 'accumulated_eval_time': 417.60013151168823, 'accumulated_logging_time': 6.293979644775391, 'global_step': 35681, 'preemption_count': 0}), (36027, {'train/ssim': 0.7503397805350167, 'train/loss': 0.2647636617933001, 'validation/ssim': 0.7259813436444851, 'validation/loss': 0.2852229009401818, 'validation/num_examples': 3554, 'test/ssim': 0.7430758418999581, 'test/loss': 0.2866263774412699, 'test/num_examples': 3581, 'score': 8354.620125293732, 'total_duration': 8783.927860736847, 'accumulated_submission_time': 8354.620125293732, 'accumulated_eval_time': 421.61596393585205, 'accumulated_logging_time': 6.335568904876709, 'global_step': 36027, 'preemption_count': 0}), (36189, {'train/ssim': 0.7503502709524972, 'train/loss': 0.2647658245904105, 'validation/ssim': 0.7259957008168613, 'validation/loss': 0.2852237252754379, 'validation/num_examples': 3554, 'test/ssim': 0.7430886591123289, 'test/loss': 0.286627570532847, 'test/num_examples': 3581, 'score': 8390.96516919136, 'total_duration': 8824.325541734695, 'accumulated_submission_time': 8390.96516919136, 'accumulated_eval_time': 425.62926030158997, 'accumulated_logging_time': 6.368803024291992, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0208 20:06:06.866247 140466628462400 submission_runner.py:586] Timing: 8390.96516919136
I0208 20:06:06.866303 140466628462400 submission_runner.py:588] Total number of evals: 106
I0208 20:06:06.866347 140466628462400 submission_runner.py:589] ====================
I0208 20:06:06.866400 140466628462400 submission_runner.py:542] Using RNG seed 1572671891
I0208 20:06:06.868420 140466628462400 submission_runner.py:551] --- Tuning run 3/5 ---
I0208 20:06:06.868572 140466628462400 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3.
I0208 20:06:06.868873 140466628462400 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3/hparams.json.
I0208 20:06:06.869980 140466628462400 submission_runner.py:206] Initializing dataset.
I0208 20:06:07.230597 140466628462400 submission_runner.py:213] Initializing model.
I0208 20:06:09.361665 140466628462400 submission_runner.py:255] Initializing optimizer.
I0208 20:06:09.446650 140466628462400 submission_runner.py:262] Initializing metrics bundle.
I0208 20:06:09.446805 140466628462400 submission_runner.py:280] Initializing checkpoint and logger.
I0208 20:06:09.447447 140466628462400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3 with prefix checkpoint_
I0208 20:06:09.447583 140466628462400 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3/meta_data_0.json.
I0208 20:06:09.447819 140466628462400 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0208 20:06:09.447883 140466628462400 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0208 20:06:13.924632 140466628462400 logger_utils.py:220] Unable to record git information. Continuing without it.
I0208 20:06:18.264087 140466628462400 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3/flags_0.json.
I0208 20:06:18.267644 140466628462400 submission_runner.py:314] Starting training loop.
I0208 20:06:52.932136 140249942763264 logging_writer.py:48] [0] global_step=0, grad_norm=4.160696983337402, loss=0.8857511878013611
I0208 20:06:52.940092 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:06:54.260774 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:06:55.580353 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:06:56.898165 140466628462400 submission_runner.py:408] Time since start: 38.63s, 	Step: 1, 	{'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 34.67232370376587, 'total_duration': 38.630457639694214, 'accumulated_submission_time': 34.67232370376587, 'accumulated_eval_time': 3.9580185413360596, 'accumulated_logging_time': 0}
I0208 20:06:56.907767 140250622109440 logging_writer.py:48] [1] accumulated_eval_time=3.958019, accumulated_logging_time=0, accumulated_submission_time=34.672324, global_step=1, preemption_count=0, score=34.672324, test/loss=0.894958, test/num_examples=3581, test/ssim=0.283672, total_duration=38.630458, train/loss=0.892833, train/ssim=0.265677, validation/loss=0.895667, validation/num_examples=3554, validation/ssim=0.261322
I0208 20:07:18.820289 140249942763264 logging_writer.py:48] [100] global_step=100, grad_norm=1.004542589187622, loss=0.3827035427093506
I0208 20:07:42.802073 140250622109440 logging_writer.py:48] [200] global_step=200, grad_norm=0.2570411264896393, loss=0.2843663990497589
I0208 20:08:07.051349 140249942763264 logging_writer.py:48] [300] global_step=300, grad_norm=0.1027025356888771, loss=0.3261135518550873
I0208 20:08:17.079704 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:08:18.455168 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:08:19.775272 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:08:21.095009 140466628462400 submission_runner.py:408] Time since start: 122.83s, 	Step: 343, 	{'train/ssim': 0.6874906676156181, 'train/loss': 0.32034478868756977, 'validation/ssim': 0.665604968653278, 'validation/loss': 0.3383400251037563, 'validation/num_examples': 3554, 'test/ssim': 0.6846410116980243, 'test/loss': 0.3396532303193068, 'test/num_examples': 3581, 'score': 114.82151770591736, 'total_duration': 122.82729887962341, 'accumulated_submission_time': 114.82151770591736, 'accumulated_eval_time': 7.97329568862915, 'accumulated_logging_time': 0.018859386444091797}
I0208 20:08:21.108939 140250622109440 logging_writer.py:48] [343] accumulated_eval_time=7.973296, accumulated_logging_time=0.018859, accumulated_submission_time=114.821518, global_step=343, preemption_count=0, score=114.821518, test/loss=0.339653, test/num_examples=3581, test/ssim=0.684641, total_duration=122.827299, train/loss=0.320345, train/ssim=0.687491, validation/loss=0.338340, validation/num_examples=3554, validation/ssim=0.665605
I0208 20:08:32.881058 140249942763264 logging_writer.py:48] [400] global_step=400, grad_norm=0.13150356709957123, loss=0.29917991161346436
I0208 20:08:57.198725 140250622109440 logging_writer.py:48] [500] global_step=500, grad_norm=0.16758057475090027, loss=0.30704203248023987
I0208 20:09:21.386370 140249942763264 logging_writer.py:48] [600] global_step=600, grad_norm=0.09708158671855927, loss=0.27753138542175293
I0208 20:09:41.163021 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:09:42.536715 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:09:43.858098 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:09:45.177729 140466628462400 submission_runner.py:408] Time since start: 206.91s, 	Step: 683, 	{'train/ssim': 0.7154259000505719, 'train/loss': 0.2942925861903599, 'validation/ssim': 0.6941251137582654, 'validation/loss': 0.3114802629409644, 'validation/num_examples': 3554, 'test/ssim': 0.7119667630593759, 'test/loss': 0.31328897441575326, 'test/num_examples': 3581, 'score': 194.85300540924072, 'total_duration': 206.91001749038696, 'accumulated_submission_time': 194.85300540924072, 'accumulated_eval_time': 11.987972736358643, 'accumulated_logging_time': 0.04272103309631348}
I0208 20:09:45.191913 140250622109440 logging_writer.py:48] [683] accumulated_eval_time=11.987973, accumulated_logging_time=0.042721, accumulated_submission_time=194.853005, global_step=683, preemption_count=0, score=194.853005, test/loss=0.313289, test/num_examples=3581, test/ssim=0.711967, total_duration=206.910017, train/loss=0.294293, train/ssim=0.715426, validation/loss=0.311480, validation/num_examples=3554, validation/ssim=0.694125
I0208 20:09:47.277063 140249942763264 logging_writer.py:48] [700] global_step=700, grad_norm=0.14231498539447784, loss=0.24069492518901825
I0208 20:10:11.684745 140250622109440 logging_writer.py:48] [800] global_step=800, grad_norm=0.12847377359867096, loss=0.35613957047462463
I0208 20:10:36.181591 140249942763264 logging_writer.py:48] [900] global_step=900, grad_norm=0.12614387273788452, loss=0.3696114420890808
I0208 20:11:00.637488 140250622109440 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.13489927351474762, loss=0.2839598059654236
I0208 20:11:05.340887 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:11:06.712002 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:11:08.031371 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:11:09.348870 140466628462400 submission_runner.py:408] Time since start: 291.08s, 	Step: 1021, 	{'train/ssim': 0.7261792591639927, 'train/loss': 0.28449693747929167, 'validation/ssim': 0.7047837686189856, 'validation/loss': 0.301730059879713, 'validation/num_examples': 3554, 'test/ssim': 0.722000731399225, 'test/loss': 0.30372324338740925, 'test/num_examples': 3581, 'score': 274.98014783859253, 'total_duration': 291.08116149902344, 'accumulated_submission_time': 274.98014783859253, 'accumulated_eval_time': 15.995911598205566, 'accumulated_logging_time': 0.0665290355682373}
I0208 20:11:09.362932 140249942763264 logging_writer.py:48] [1021] accumulated_eval_time=15.995912, accumulated_logging_time=0.066529, accumulated_submission_time=274.980148, global_step=1021, preemption_count=0, score=274.980148, test/loss=0.303723, test/num_examples=3581, test/ssim=0.722001, total_duration=291.081161, train/loss=0.284497, train/ssim=0.726179, validation/loss=0.301730, validation/num_examples=3554, validation/ssim=0.704784
I0208 20:11:26.458317 140250622109440 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.5156921148300171, loss=0.27037161588668823
I0208 20:11:50.180268 140249942763264 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.15660271048545837, loss=0.2698405683040619
I0208 20:12:14.159686 140250622109440 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.19416390359401703, loss=0.2941124439239502
I0208 20:12:29.610224 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:12:30.982439 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:12:32.304331 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:12:33.628535 140466628462400 submission_runner.py:408] Time since start: 375.36s, 	Step: 1367, 	{'train/ssim': 0.7311660902840751, 'train/loss': 0.2801398549761091, 'validation/ssim': 0.7096444614562817, 'validation/loss': 0.29759728942081104, 'validation/num_examples': 3554, 'test/ssim': 0.7267269421076515, 'test/loss': 0.29945388448800964, 'test/num_examples': 3581, 'score': 355.20496368408203, 'total_duration': 375.3608241081238, 'accumulated_submission_time': 355.20496368408203, 'accumulated_eval_time': 20.014185190200806, 'accumulated_logging_time': 0.09003257751464844}
I0208 20:12:33.643018 140249942763264 logging_writer.py:48] [1367] accumulated_eval_time=20.014185, accumulated_logging_time=0.090033, accumulated_submission_time=355.204964, global_step=1367, preemption_count=0, score=355.204964, test/loss=0.299454, test/num_examples=3581, test/ssim=0.726727, total_duration=375.360824, train/loss=0.280140, train/ssim=0.731166, validation/loss=0.297597, validation/num_examples=3554, validation/ssim=0.709644
I0208 20:12:39.469020 140250622109440 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.31304848194122314, loss=0.2962490916252136
I0208 20:13:03.617325 140249942763264 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.24462836980819702, loss=0.27619731426239014
I0208 20:13:27.359059 140250622109440 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.6670853495597839, loss=0.2530709505081177
I0208 20:13:51.190765 140249942763264 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.12604518234729767, loss=0.4142249822616577
I0208 20:13:53.758260 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:13:55.133231 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:13:56.454875 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:13:57.777588 140466628462400 submission_runner.py:408] Time since start: 459.51s, 	Step: 1712, 	{'train/ssim': 0.7326619284493583, 'train/loss': 0.27829464844294954, 'validation/ssim': 0.7117603926693514, 'validation/loss': 0.29559721165851854, 'validation/num_examples': 3554, 'test/ssim': 0.7288269878132854, 'test/loss': 0.29723896110766895, 'test/num_examples': 3581, 'score': 435.2983305454254, 'total_duration': 459.5098702907562, 'accumulated_submission_time': 435.2983305454254, 'accumulated_eval_time': 24.033470630645752, 'accumulated_logging_time': 0.11382746696472168}
I0208 20:13:57.792400 140250622109440 logging_writer.py:48] [1712] accumulated_eval_time=24.033471, accumulated_logging_time=0.113827, accumulated_submission_time=435.298331, global_step=1712, preemption_count=0, score=435.298331, test/loss=0.297239, test/num_examples=3581, test/ssim=0.728827, total_duration=459.509870, train/loss=0.278295, train/ssim=0.732662, validation/loss=0.295597, validation/num_examples=3554, validation/ssim=0.711760
I0208 20:14:16.790892 140249942763264 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.19629326462745667, loss=0.2579001784324646
I0208 20:14:41.087572 140250622109440 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.3530130684375763, loss=0.31869423389434814
I0208 20:15:05.367585 140249942763264 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.08947258442640305, loss=0.2746122181415558
I0208 20:15:17.851098 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:15:19.222227 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:15:20.543052 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:15:21.864323 140466628462400 submission_runner.py:408] Time since start: 543.60s, 	Step: 2053, 	{'train/ssim': 0.7352352823529925, 'train/loss': 0.2767984867095947, 'validation/ssim': 0.714054586381542, 'validation/loss': 0.2942941437025183, 'validation/num_examples': 3554, 'test/ssim': 0.731076544937692, 'test/loss': 0.29598001087554104, 'test/num_examples': 3581, 'score': 515.3351848125458, 'total_duration': 543.5966114997864, 'accumulated_submission_time': 515.3351848125458, 'accumulated_eval_time': 28.046659469604492, 'accumulated_logging_time': 0.13770151138305664}
I0208 20:15:21.879466 140250622109440 logging_writer.py:48] [2053] accumulated_eval_time=28.046659, accumulated_logging_time=0.137702, accumulated_submission_time=515.335185, global_step=2053, preemption_count=0, score=515.335185, test/loss=0.295980, test/num_examples=3581, test/ssim=0.731077, total_duration=543.596611, train/loss=0.276798, train/ssim=0.735235, validation/loss=0.294294, validation/num_examples=3554, validation/ssim=0.714055
I0208 20:15:31.140936 140249942763264 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.16081944108009338, loss=0.3111933171749115
I0208 20:15:55.168464 140250622109440 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.30054736137390137, loss=0.28056561946868896
I0208 20:16:18.896737 140249942763264 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.19027751684188843, loss=0.27832016348838806
I0208 20:16:41.881398 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:16:43.254557 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:16:44.577345 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:16:45.899705 140466628462400 submission_runner.py:408] Time since start: 627.63s, 	Step: 2399, 	{'train/ssim': 0.7378204890659877, 'train/loss': 0.27462734494890484, 'validation/ssim': 0.715780881796919, 'validation/loss': 0.2926793739778243, 'validation/num_examples': 3554, 'test/ssim': 0.7328256853663432, 'test/loss': 0.2943691327165073, 'test/num_examples': 3581, 'score': 595.3161046504974, 'total_duration': 627.6319966316223, 'accumulated_submission_time': 595.3161046504974, 'accumulated_eval_time': 32.06492805480957, 'accumulated_logging_time': 0.16156339645385742}
I0208 20:16:45.914669 140250622109440 logging_writer.py:48] [2399] accumulated_eval_time=32.064928, accumulated_logging_time=0.161563, accumulated_submission_time=595.316105, global_step=2399, preemption_count=0, score=595.316105, test/loss=0.294369, test/num_examples=3581, test/ssim=0.732826, total_duration=627.631997, train/loss=0.274627, train/ssim=0.737820, validation/loss=0.292679, validation/num_examples=3554, validation/ssim=0.715781
I0208 20:16:46.077339 140249942763264 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.20696724951267242, loss=0.3375500440597534
I0208 20:17:07.822975 140250622109440 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.31388869881629944, loss=0.30295440554618835
I0208 20:17:31.677170 140249942763264 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.19783389568328857, loss=0.24734866619110107
I0208 20:17:55.380781 140250622109440 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.1055276021361351, loss=0.29929494857788086
I0208 20:18:06.027449 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:18:07.400511 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:18:08.721744 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:18:10.043996 140466628462400 submission_runner.py:408] Time since start: 711.78s, 	Step: 2745, 	{'train/ssim': 0.736846787588937, 'train/loss': 0.27468367985316683, 'validation/ssim': 0.7157350624956036, 'validation/loss': 0.2923017597359489, 'validation/num_examples': 3554, 'test/ssim': 0.7329012932839989, 'test/loss': 0.29392206425841244, 'test/num_examples': 3581, 'score': 675.4076058864594, 'total_duration': 711.7762885093689, 'accumulated_submission_time': 675.4076058864594, 'accumulated_eval_time': 36.081443786621094, 'accumulated_logging_time': 0.1853799819946289}
I0208 20:18:10.058723 140249942763264 logging_writer.py:48] [2745] accumulated_eval_time=36.081444, accumulated_logging_time=0.185380, accumulated_submission_time=675.407606, global_step=2745, preemption_count=0, score=675.407606, test/loss=0.293922, test/num_examples=3581, test/ssim=0.732901, total_duration=711.776289, train/loss=0.274684, train/ssim=0.736847, validation/loss=0.292302, validation/num_examples=3554, validation/ssim=0.715735
I0208 20:18:21.256676 140250622109440 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.24613435566425323, loss=0.2374478578567505
I0208 20:18:45.083472 140249942763264 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.24171000719070435, loss=0.25138357281684875
I0208 20:19:08.977024 140250622109440 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.07837303727865219, loss=0.26424121856689453
I0208 20:19:30.155424 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:19:31.525851 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:19:32.843338 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:19:34.166337 140466628462400 submission_runner.py:408] Time since start: 795.90s, 	Step: 3089, 	{'train/ssim': 0.738483156476702, 'train/loss': 0.2738098076411656, 'validation/ssim': 0.7173665593565349, 'validation/loss': 0.2915166490991664, 'validation/num_examples': 3554, 'test/ssim': 0.7343056643352066, 'test/loss': 0.293090513517523, 'test/num_examples': 3581, 'score': 755.4829206466675, 'total_duration': 795.8983507156372, 'accumulated_submission_time': 755.4829206466675, 'accumulated_eval_time': 40.09206223487854, 'accumulated_logging_time': 0.2090139389038086}
I0208 20:19:34.181877 140249942763264 logging_writer.py:48] [3089] accumulated_eval_time=40.092062, accumulated_logging_time=0.209014, accumulated_submission_time=755.482921, global_step=3089, preemption_count=0, score=755.482921, test/loss=0.293091, test/num_examples=3581, test/ssim=0.734306, total_duration=795.898351, train/loss=0.273810, train/ssim=0.738483, validation/loss=0.291517, validation/num_examples=3554, validation/ssim=0.717367
I0208 20:19:35.071940 140250622109440 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.14384335279464722, loss=0.2868608236312866
I0208 20:19:58.422298 140249942763264 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.11545193195343018, loss=0.2656305134296417
I0208 20:20:22.474985 140250622109440 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10635659098625183, loss=0.2642063498497009
I0208 20:20:46.252387 140249942763264 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.11530604213476181, loss=0.2849971652030945
I0208 20:20:54.281591 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:20:55.655766 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:20:56.976516 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:20:58.299736 140466628462400 submission_runner.py:408] Time since start: 880.03s, 	Step: 3435, 	{'train/ssim': 0.7398324693952288, 'train/loss': 0.2729310819080898, 'validation/ssim': 0.7178401399611354, 'validation/loss': 0.29103674859093626, 'validation/num_examples': 3554, 'test/ssim': 0.7349787043379992, 'test/loss': 0.29263458209342713, 'test/num_examples': 3581, 'score': 835.5611155033112, 'total_duration': 880.0320289134979, 'accumulated_submission_time': 835.5611155033112, 'accumulated_eval_time': 44.11016654968262, 'accumulated_logging_time': 0.23378396034240723}
I0208 20:20:58.314846 140250622109440 logging_writer.py:48] [3435] accumulated_eval_time=44.110167, accumulated_logging_time=0.233784, accumulated_submission_time=835.561116, global_step=3435, preemption_count=0, score=835.561116, test/loss=0.292635, test/num_examples=3581, test/ssim=0.734979, total_duration=880.032029, train/loss=0.272931, train/ssim=0.739832, validation/loss=0.291037, validation/num_examples=3554, validation/ssim=0.717840
I0208 20:21:11.869933 140249942763264 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.17004281282424927, loss=0.32802337408065796
I0208 20:21:35.589114 140250622109440 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.14316019415855408, loss=0.24652785062789917
I0208 20:21:59.413851 140249942763264 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.214020773768425, loss=0.25237688422203064
I0208 20:22:18.507523 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:22:19.882894 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:22:21.201575 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:22:22.524331 140466628462400 submission_runner.py:408] Time since start: 964.26s, 	Step: 3781, 	{'train/ssim': 0.7399343763078962, 'train/loss': 0.27259365149906706, 'validation/ssim': 0.7179940845702026, 'validation/loss': 0.2906307978246342, 'validation/num_examples': 3554, 'test/ssim': 0.7351857568591176, 'test/loss': 0.2921319155678407, 'test/num_examples': 3581, 'score': 915.7322247028351, 'total_duration': 964.2566239833832, 'accumulated_submission_time': 915.7322247028351, 'accumulated_eval_time': 48.12693548202515, 'accumulated_logging_time': 0.25774526596069336}
I0208 20:22:22.539725 140250622109440 logging_writer.py:48] [3781] accumulated_eval_time=48.126935, accumulated_logging_time=0.257745, accumulated_submission_time=915.732225, global_step=3781, preemption_count=0, score=915.732225, test/loss=0.292132, test/num_examples=3581, test/ssim=0.735186, total_duration=964.256624, train/loss=0.272594, train/ssim=0.739934, validation/loss=0.290631, validation/num_examples=3554, validation/ssim=0.717994
I0208 20:22:28.383570 140249942763264 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.10147099941968918, loss=0.26435837149620056
I0208 20:22:52.116093 140250622109440 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.16121256351470947, loss=0.3218473792076111
I0208 20:23:16.055786 140249942763264 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.27313199639320374, loss=0.23337340354919434
I0208 20:23:39.951693 140250622109440 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.12034504860639572, loss=0.24135875701904297
I0208 20:23:42.697616 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:23:44.071359 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:23:45.391907 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:23:46.714669 140466628462400 submission_runner.py:408] Time since start: 1048.45s, 	Step: 4113, 	{'train/ssim': 0.7397107396806989, 'train/loss': 0.2726095233644758, 'validation/ssim': 0.7185598533342712, 'validation/loss': 0.2903784825416784, 'validation/num_examples': 3554, 'test/ssim': 0.7355518655316252, 'test/loss': 0.29191978388543705, 'test/num_examples': 3581, 'score': 992.5416581630707, 'total_duration': 1048.4469621181488, 'accumulated_submission_time': 992.5416581630707, 'accumulated_eval_time': 52.14394688606262, 'accumulated_logging_time': 3.6097893714904785}
I0208 20:23:46.729668 140249942763264 logging_writer.py:48] [4113] accumulated_eval_time=52.143947, accumulated_logging_time=3.609789, accumulated_submission_time=992.541658, global_step=4113, preemption_count=0, score=992.541658, test/loss=0.291920, test/num_examples=3581, test/ssim=0.735552, total_duration=1048.446962, train/loss=0.272610, train/ssim=0.739711, validation/loss=0.290378, validation/num_examples=3554, validation/ssim=0.718560
I0208 20:24:06.034314 140250622109440 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.15105222165584564, loss=0.29368916153907776
I0208 20:24:30.471827 140249942763264 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.17530672252178192, loss=0.2950309216976166
I0208 20:24:54.698637 140250622109440 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.10832761973142624, loss=0.29505446553230286
I0208 20:25:06.809265 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:25:08.181404 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:25:09.502070 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:25:10.824040 140466628462400 submission_runner.py:408] Time since start: 1132.56s, 	Step: 4452, 	{'train/ssim': 0.7406341007777623, 'train/loss': 0.2726199116025652, 'validation/ssim': 0.7184141520777645, 'validation/loss': 0.2907874902178883, 'validation/num_examples': 3554, 'test/ssim': 0.7355363212527926, 'test/loss': 0.2924081333120986, 'test/num_examples': 3581, 'score': 1072.5993592739105, 'total_duration': 1132.556327342987, 'accumulated_submission_time': 1072.5993592739105, 'accumulated_eval_time': 56.158693075180054, 'accumulated_logging_time': 3.634568214416504}
I0208 20:25:10.840582 140249942763264 logging_writer.py:48] [4452] accumulated_eval_time=56.158693, accumulated_logging_time=3.634568, accumulated_submission_time=1072.599359, global_step=4452, preemption_count=0, score=1072.599359, test/loss=0.292408, test/num_examples=3581, test/ssim=0.735536, total_duration=1132.556327, train/loss=0.272620, train/ssim=0.740634, validation/loss=0.290787, validation/num_examples=3554, validation/ssim=0.718414
I0208 20:25:20.434526 140250622109440 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.2016986757516861, loss=0.25392574071884155
I0208 20:25:44.268131 140249942763264 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.13326860964298248, loss=0.2513974606990814
I0208 20:26:08.086126 140250622109440 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.10194464772939682, loss=0.2799539268016815
I0208 20:26:30.938985 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:26:32.313755 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:26:33.635095 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:26:34.956160 140466628462400 submission_runner.py:408] Time since start: 1216.69s, 	Step: 4797, 	{'train/ssim': 0.7394133976527623, 'train/loss': 0.2729235887527466, 'validation/ssim': 0.717810807364941, 'validation/loss': 0.2907678435609524, 'validation/num_examples': 3554, 'test/ssim': 0.7350659022881179, 'test/loss': 0.29228633570624474, 'test/num_examples': 3581, 'score': 1152.6758415699005, 'total_duration': 1216.6884505748749, 'accumulated_submission_time': 1152.6758415699005, 'accumulated_eval_time': 60.17582702636719, 'accumulated_logging_time': 3.66079044342041}
I0208 20:26:34.971686 140249942763264 logging_writer.py:48] [4797] accumulated_eval_time=60.175827, accumulated_logging_time=3.660790, accumulated_submission_time=1152.675842, global_step=4797, preemption_count=0, score=1152.675842, test/loss=0.292286, test/num_examples=3581, test/ssim=0.735066, total_duration=1216.688451, train/loss=0.272924, train/ssim=0.739413, validation/loss=0.290768, validation/num_examples=3554, validation/ssim=0.717811
I0208 20:26:35.282818 140250622109440 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.1633770614862442, loss=0.25300922989845276
I0208 20:26:57.605607 140249942763264 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.07305674999952316, loss=0.2843235731124878
I0208 20:27:21.731584 140250622109440 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.17270337045192719, loss=0.25745534896850586
I0208 20:27:45.647651 140249942763264 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.13278517127037048, loss=0.23265279829502106
I0208 20:27:55.125541 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:27:56.498504 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:27:57.820435 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:27:59.144579 140466628462400 submission_runner.py:408] Time since start: 1300.88s, 	Step: 5141, 	{'train/ssim': 0.7423439707074847, 'train/loss': 0.27140653133392334, 'validation/ssim': 0.720104863687922, 'validation/loss': 0.28983789035022156, 'validation/num_examples': 3554, 'test/ssim': 0.7372924838775831, 'test/loss': 0.2913546334495427, 'test/num_examples': 3581, 'score': 1232.8069953918457, 'total_duration': 1300.8768427371979, 'accumulated_submission_time': 1232.8069953918457, 'accumulated_eval_time': 64.19480657577515, 'accumulated_logging_time': 3.686720371246338}
I0208 20:27:59.163089 140250622109440 logging_writer.py:48] [5141] accumulated_eval_time=64.194807, accumulated_logging_time=3.686720, accumulated_submission_time=1232.806995, global_step=5141, preemption_count=0, score=1232.806995, test/loss=0.291355, test/num_examples=3581, test/ssim=0.737292, total_duration=1300.876843, train/loss=0.271407, train/ssim=0.742344, validation/loss=0.289838, validation/num_examples=3554, validation/ssim=0.720105
I0208 20:28:11.218722 140249942763264 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.135942280292511, loss=0.2573392689228058
I0208 20:28:35.729879 140250622109440 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.2709082365036011, loss=0.257902592420578
I0208 20:28:59.685264 140249942763264 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.10118920356035233, loss=0.32120245695114136
I0208 20:29:19.224413 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:29:20.596285 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:29:21.919989 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:29:23.241529 140466628462400 submission_runner.py:408] Time since start: 1384.97s, 	Step: 5482, 	{'train/ssim': 0.7426614080156598, 'train/loss': 0.2708125114440918, 'validation/ssim': 0.7199558650903911, 'validation/loss': 0.28943049699722145, 'validation/num_examples': 3554, 'test/ssim': 0.7371058161782672, 'test/loss': 0.2909789459560877, 'test/num_examples': 3581, 'score': 1312.845635175705, 'total_duration': 1384.973824262619, 'accumulated_submission_time': 1312.845635175705, 'accumulated_eval_time': 68.21188974380493, 'accumulated_logging_time': 3.7150466442108154}
I0208 20:29:23.257604 140250622109440 logging_writer.py:48] [5482] accumulated_eval_time=68.211890, accumulated_logging_time=3.715047, accumulated_submission_time=1312.845635, global_step=5482, preemption_count=0, score=1312.845635, test/loss=0.290979, test/num_examples=3581, test/ssim=0.737106, total_duration=1384.973824, train/loss=0.270813, train/ssim=0.742661, validation/loss=0.289430, validation/num_examples=3554, validation/ssim=0.719956
I0208 20:29:25.480403 140249942763264 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.10188990831375122, loss=0.27427059412002563
I0208 20:29:49.337183 140250622109440 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.13558050990104675, loss=0.21688300371170044
I0208 20:30:13.409315 140249942763264 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.1746370494365692, loss=0.25457024574279785
I0208 20:30:37.364080 140250622109440 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.18724533915519714, loss=0.3604092597961426
I0208 20:30:43.314335 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:30:44.687342 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:30:46.007689 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:30:47.331658 140466628462400 submission_runner.py:408] Time since start: 1469.06s, 	Step: 5826, 	{'train/ssim': 0.7421904972621373, 'train/loss': 0.2719070741108486, 'validation/ssim': 0.7206405442151449, 'validation/loss': 0.28988024057400114, 'validation/num_examples': 3554, 'test/ssim': 0.7378205802979265, 'test/loss': 0.2913603262007819, 'test/num_examples': 3581, 'score': 1392.8805315494537, 'total_duration': 1469.0639517307281, 'accumulated_submission_time': 1392.8805315494537, 'accumulated_eval_time': 72.22917580604553, 'accumulated_logging_time': 3.7401299476623535}
I0208 20:30:47.346997 140249942763264 logging_writer.py:48] [5826] accumulated_eval_time=72.229176, accumulated_logging_time=3.740130, accumulated_submission_time=1392.880532, global_step=5826, preemption_count=0, score=1392.880532, test/loss=0.291360, test/num_examples=3581, test/ssim=0.737821, total_duration=1469.063952, train/loss=0.271907, train/ssim=0.742190, validation/loss=0.289880, validation/num_examples=3554, validation/ssim=0.720641
I0208 20:31:02.972193 140250622109440 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.2664735019207001, loss=0.2531282603740692
I0208 20:31:26.847535 140249942763264 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.17962044477462769, loss=0.22758959233760834
I0208 20:31:50.738771 140250622109440 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.03940571844577789, loss=0.3441898226737976
I0208 20:32:07.333021 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:32:08.705163 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:32:10.028431 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:32:11.350794 140466628462400 submission_runner.py:408] Time since start: 1553.08s, 	Step: 6170, 	{'train/ssim': 0.743617125919887, 'train/loss': 0.2700311115809849, 'validation/ssim': 0.7214869991338985, 'validation/loss': 0.2883799847552933, 'validation/num_examples': 3554, 'test/ssim': 0.7387264435999022, 'test/loss': 0.2897655377338732, 'test/num_examples': 3581, 'score': 1472.8445675373077, 'total_duration': 1553.0830590724945, 'accumulated_submission_time': 1472.8445675373077, 'accumulated_eval_time': 76.24688148498535, 'accumulated_logging_time': 3.7643887996673584}
I0208 20:32:11.370150 140249942763264 logging_writer.py:48] [6170] accumulated_eval_time=76.246881, accumulated_logging_time=3.764389, accumulated_submission_time=1472.844568, global_step=6170, preemption_count=0, score=1472.844568, test/loss=0.289766, test/num_examples=3581, test/ssim=0.738726, total_duration=1553.083059, train/loss=0.270031, train/ssim=0.743617, validation/loss=0.288380, validation/num_examples=3554, validation/ssim=0.721487
I0208 20:32:16.477795 140250622109440 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.11505488306283951, loss=0.2352677881717682
I0208 20:32:40.228174 140249942763264 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.16105705499649048, loss=0.26223304867744446
I0208 20:33:04.604916 140250622109440 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.2085782140493393, loss=0.21379780769348145
I0208 20:33:28.336193 140249942763264 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.08332753926515579, loss=0.30014708638191223
I0208 20:33:31.516438 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:33:32.889891 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:33:34.209702 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:33:35.533836 140466628462400 submission_runner.py:408] Time since start: 1637.27s, 	Step: 6515, 	{'train/ssim': 0.7408600534711566, 'train/loss': 0.2711503676005772, 'validation/ssim': 0.7199719396278841, 'validation/loss': 0.2892438537563309, 'validation/num_examples': 3554, 'test/ssim': 0.736829496169017, 'test/loss': 0.29071564768919295, 'test/num_examples': 3581, 'score': 1552.9671349525452, 'total_duration': 1637.2661266326904, 'accumulated_submission_time': 1552.9671349525452, 'accumulated_eval_time': 80.26424646377563, 'accumulated_logging_time': 3.7941737174987793}
I0208 20:33:35.550484 140250622109440 logging_writer.py:48] [6515] accumulated_eval_time=80.264246, accumulated_logging_time=3.794174, accumulated_submission_time=1552.967135, global_step=6515, preemption_count=0, score=1552.967135, test/loss=0.290716, test/num_examples=3581, test/ssim=0.736829, total_duration=1637.266127, train/loss=0.271150, train/ssim=0.740860, validation/loss=0.289244, validation/num_examples=3554, validation/ssim=0.719972
I0208 20:33:53.753998 140249942763264 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.28011423349380493, loss=0.33763256669044495
I0208 20:34:17.738172 140250622109440 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.09772515296936035, loss=0.2302771359682083
I0208 20:34:41.965760 140249942763264 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.12646783888339996, loss=0.3648526072502136
I0208 20:34:55.616314 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:34:56.989089 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:34:58.309513 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:34:59.632843 140466628462400 submission_runner.py:408] Time since start: 1721.37s, 	Step: 6858, 	{'train/ssim': 0.7428475788661412, 'train/loss': 0.2702873434339251, 'validation/ssim': 0.7205947249138295, 'validation/loss': 0.2885929380297728, 'validation/num_examples': 3554, 'test/ssim': 0.7378659177778554, 'test/loss': 0.2900368808468305, 'test/num_examples': 3581, 'score': 1633.011125087738, 'total_duration': 1721.365136384964, 'accumulated_submission_time': 1633.011125087738, 'accumulated_eval_time': 84.28073906898499, 'accumulated_logging_time': 3.8197827339172363}
I0208 20:34:59.648860 140250622109440 logging_writer.py:48] [6858] accumulated_eval_time=84.280739, accumulated_logging_time=3.819783, accumulated_submission_time=1633.011125, global_step=6858, preemption_count=0, score=1633.011125, test/loss=0.290037, test/num_examples=3581, test/ssim=0.737866, total_duration=1721.365136, train/loss=0.270287, train/ssim=0.742848, validation/loss=0.288593, validation/num_examples=3554, validation/ssim=0.720595
I0208 20:35:07.752667 140249942763264 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.09745600074529648, loss=0.32782480120658875
I0208 20:35:31.464133 140250622109440 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.16416257619857788, loss=0.2514248788356781
I0208 20:35:55.535858 140249942763264 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.21528370678424835, loss=0.23112988471984863
I0208 20:36:19.591205 140250622109440 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.0977177768945694, loss=0.2661825120449066
I0208 20:36:19.772731 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:36:21.145543 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:36:22.466481 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:36:23.788342 140466628462400 submission_runner.py:408] Time since start: 1805.52s, 	Step: 7202, 	{'train/ssim': 0.7438455990382603, 'train/loss': 0.26998632294791086, 'validation/ssim': 0.7213912388549873, 'validation/loss': 0.2882636847895857, 'validation/num_examples': 3554, 'test/ssim': 0.7387140354475007, 'test/loss': 0.28963351362878736, 'test/num_examples': 3581, 'score': 1713.1123294830322, 'total_duration': 1805.5205924510956, 'accumulated_submission_time': 1713.1123294830322, 'accumulated_eval_time': 88.29626941680908, 'accumulated_logging_time': 3.8452749252319336}
I0208 20:36:23.805165 140249942763264 logging_writer.py:48] [7202] accumulated_eval_time=88.296269, accumulated_logging_time=3.845275, accumulated_submission_time=1713.112329, global_step=7202, preemption_count=0, score=1713.112329, test/loss=0.289634, test/num_examples=3581, test/ssim=0.738714, total_duration=1805.520592, train/loss=0.269986, train/ssim=0.743846, validation/loss=0.288264, validation/num_examples=3554, validation/ssim=0.721391
I0208 20:36:45.437153 140250622109440 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.16961224377155304, loss=0.28825297951698303
I0208 20:37:09.587894 140249942763264 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.18188083171844482, loss=0.2195289582014084
I0208 20:37:33.781658 140250622109440 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.13294215500354767, loss=0.1609397977590561
I0208 20:37:43.913474 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:37:45.286144 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:37:46.609537 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:37:47.932005 140466628462400 submission_runner.py:408] Time since start: 1889.66s, 	Step: 7544, 	{'train/ssim': 0.7445081983293805, 'train/loss': 0.2692584310259138, 'validation/ssim': 0.7220048190639069, 'validation/loss': 0.2876641011063678, 'validation/num_examples': 3554, 'test/ssim': 0.7392936734239738, 'test/loss': 0.2890629090599693, 'test/num_examples': 3581, 'score': 1793.1978707313538, 'total_duration': 1889.664298772812, 'accumulated_submission_time': 1793.1978707313538, 'accumulated_eval_time': 92.31477165222168, 'accumulated_logging_time': 3.871781349182129}
I0208 20:37:47.948579 140249942763264 logging_writer.py:48] [7544] accumulated_eval_time=92.314772, accumulated_logging_time=3.871781, accumulated_submission_time=1793.197871, global_step=7544, preemption_count=0, score=1793.197871, test/loss=0.289063, test/num_examples=3581, test/ssim=0.739294, total_duration=1889.664299, train/loss=0.269258, train/ssim=0.744508, validation/loss=0.287664, validation/num_examples=3554, validation/ssim=0.722005
I0208 20:37:59.431781 140250622109440 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.13804398477077484, loss=0.2880167067050934
I0208 20:38:23.191797 140249942763264 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.33848923444747925, loss=0.24549072980880737
I0208 20:38:46.928915 140250622109440 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.10840710997581482, loss=0.30214759707450867
I0208 20:39:08.119024 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:39:09.491448 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:39:10.814418 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:39:12.137868 140466628462400 submission_runner.py:408] Time since start: 1973.87s, 	Step: 7890, 	{'train/ssim': 0.7442601067679269, 'train/loss': 0.26919327463422504, 'validation/ssim': 0.7217778520900746, 'validation/loss': 0.2877252049572225, 'validation/num_examples': 3554, 'test/ssim': 0.7390526689254049, 'test/loss': 0.2891253588819464, 'test/num_examples': 3581, 'score': 1873.3463337421417, 'total_duration': 1973.8701612949371, 'accumulated_submission_time': 1873.3463337421417, 'accumulated_eval_time': 96.33357906341553, 'accumulated_logging_time': 3.897242546081543}
I0208 20:39:12.154593 140249942763264 logging_writer.py:48] [7890] accumulated_eval_time=96.333579, accumulated_logging_time=3.897243, accumulated_submission_time=1873.346334, global_step=7890, preemption_count=0, score=1873.346334, test/loss=0.289125, test/num_examples=3581, test/ssim=0.739053, total_duration=1973.870161, train/loss=0.269193, train/ssim=0.744260, validation/loss=0.287725, validation/num_examples=3554, validation/ssim=0.721778
I0208 20:39:12.972608 140250622109440 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.15146410465240479, loss=0.2938336431980133
I0208 20:39:36.443430 140249942763264 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.1404070109128952, loss=0.29476961493492126
I0208 20:40:00.236483 140250622109440 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.2316480129957199, loss=0.2559213638305664
I0208 20:40:24.241476 140249942763264 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.06913849711418152, loss=0.2947613000869751
I0208 20:40:32.306622 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:40:33.678202 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:40:35.000821 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:40:36.321293 140466628462400 submission_runner.py:408] Time since start: 2058.05s, 	Step: 8235, 	{'train/ssim': 0.7455815587724958, 'train/loss': 0.268533672605242, 'validation/ssim': 0.72304437451639, 'validation/loss': 0.2871241099927019, 'validation/num_examples': 3554, 'test/ssim': 0.7402122175849972, 'test/loss': 0.2885202910107163, 'test/num_examples': 3581, 'score': 1953.4747865200043, 'total_duration': 2058.0535831451416, 'accumulated_submission_time': 1953.4747865200043, 'accumulated_eval_time': 100.34822511672974, 'accumulated_logging_time': 3.9240989685058594}
I0208 20:40:36.339228 140250622109440 logging_writer.py:48] [8235] accumulated_eval_time=100.348225, accumulated_logging_time=3.924099, accumulated_submission_time=1953.474787, global_step=8235, preemption_count=0, score=1953.474787, test/loss=0.288520, test/num_examples=3581, test/ssim=0.740212, total_duration=2058.053583, train/loss=0.268534, train/ssim=0.745582, validation/loss=0.287124, validation/num_examples=3554, validation/ssim=0.723044
I0208 20:40:49.823112 140249942763264 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.28536131978034973, loss=0.21304236352443695
I0208 20:41:13.841167 140250622109440 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.14716210961341858, loss=0.2677426040172577
I0208 20:41:37.924233 140249942763264 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.1826159954071045, loss=0.2631416618824005
I0208 20:41:56.560065 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:41:57.933782 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:41:59.254324 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:42:00.577043 140466628462400 submission_runner.py:408] Time since start: 2142.31s, 	Step: 8579, 	{'train/ssim': 0.7400757244655064, 'train/loss': 0.272737979888916, 'validation/ssim': 0.7171354707064224, 'validation/loss': 0.29154141350415025, 'validation/num_examples': 3554, 'test/ssim': 0.7344478126745323, 'test/loss': 0.2928813134315659, 'test/num_examples': 3581, 'score': 2033.6733074188232, 'total_duration': 2142.3093214035034, 'accumulated_submission_time': 2033.6733074188232, 'accumulated_eval_time': 104.36516261100769, 'accumulated_logging_time': 3.9511842727661133}
I0208 20:42:00.593704 140250622109440 logging_writer.py:48] [8579] accumulated_eval_time=104.365163, accumulated_logging_time=3.951184, accumulated_submission_time=2033.673307, global_step=8579, preemption_count=0, score=2033.673307, test/loss=0.292881, test/num_examples=3581, test/ssim=0.734448, total_duration=2142.309321, train/loss=0.272738, train/ssim=0.740076, validation/loss=0.291541, validation/num_examples=3554, validation/ssim=0.717135
I0208 20:42:03.742837 140249942763264 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.12161155790090561, loss=0.2883591949939728
I0208 20:42:27.494274 140250622109440 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.14791956543922424, loss=0.21719186007976532
I0208 20:42:51.361926 140249942763264 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.11127659678459167, loss=0.3469148874282837
I0208 20:43:15.388293 140250622109440 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.14025089144706726, loss=0.2832080125808716
I0208 20:43:20.632834 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:43:22.006053 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:43:23.327952 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:43:24.649744 140466628462400 submission_runner.py:408] Time since start: 2226.38s, 	Step: 8923, 	{'train/ssim': 0.7457260404314313, 'train/loss': 0.26832311494009836, 'validation/ssim': 0.7229087713667698, 'validation/loss': 0.28722660234287073, 'validation/num_examples': 3554, 'test/ssim': 0.7400754552019339, 'test/loss': 0.2886678253063041, 'test/num_examples': 3581, 'score': 2113.6891655921936, 'total_duration': 2226.3820304870605, 'accumulated_submission_time': 2113.6891655921936, 'accumulated_eval_time': 108.38202714920044, 'accumulated_logging_time': 3.977944850921631}
I0208 20:43:24.665867 140249942763264 logging_writer.py:48] [8923] accumulated_eval_time=108.382027, accumulated_logging_time=3.977945, accumulated_submission_time=2113.689166, global_step=8923, preemption_count=0, score=2113.689166, test/loss=0.288668, test/num_examples=3581, test/ssim=0.740075, total_duration=2226.382030, train/loss=0.268323, train/ssim=0.745726, validation/loss=0.287227, validation/num_examples=3554, validation/ssim=0.722909
I0208 20:43:40.996452 140250622109440 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5251572728157043, loss=0.2385345846414566
I0208 20:44:04.762114 140249942763264 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.18496058881282806, loss=0.28307658433914185
I0208 20:44:28.908439 140250622109440 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.19853781163692474, loss=0.23747655749320984
I0208 20:44:44.895899 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:44:46.268800 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:44:47.591917 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:44:48.912787 140466628462400 submission_runner.py:408] Time since start: 2310.65s, 	Step: 9269, 	{'train/ssim': 0.7454257011413574, 'train/loss': 0.2683753967285156, 'validation/ssim': 0.7227186933956458, 'validation/loss': 0.2870310974979776, 'validation/num_examples': 3554, 'test/ssim': 0.7400321630218515, 'test/loss': 0.2883772904631213, 'test/num_examples': 3581, 'score': 2193.8962202072144, 'total_duration': 2310.645069360733, 'accumulated_submission_time': 2193.8962202072144, 'accumulated_eval_time': 112.39886569976807, 'accumulated_logging_time': 4.004060506820679}
I0208 20:44:48.929438 140249942763264 logging_writer.py:48] [9269] accumulated_eval_time=112.398866, accumulated_logging_time=4.004061, accumulated_submission_time=2193.896220, global_step=9269, preemption_count=0, score=2193.896220, test/loss=0.288377, test/num_examples=3581, test/ssim=0.740032, total_duration=2310.645069, train/loss=0.268375, train/ssim=0.745426, validation/loss=0.287031, validation/num_examples=3554, validation/ssim=0.722719
I0208 20:44:54.305634 140250622109440 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.08492672443389893, loss=0.41591018438339233
I0208 20:45:18.416129 140249942763264 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.14880384504795074, loss=0.30259448289871216
I0208 20:45:42.225568 140250622109440 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.0975407063961029, loss=0.2771289050579071
I0208 20:46:06.584927 140249942763264 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.09783016890287399, loss=0.3321094512939453
I0208 20:46:09.067728 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:46:10.438428 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:46:11.761871 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:46:13.085920 140466628462400 submission_runner.py:408] Time since start: 2394.82s, 	Step: 9611, 	{'train/ssim': 0.7463662964957101, 'train/loss': 0.26838016510009766, 'validation/ssim': 0.7238779148494654, 'validation/loss': 0.28694761637965144, 'validation/num_examples': 3554, 'test/ssim': 0.741056653714919, 'test/loss': 0.2883160337327213, 'test/num_examples': 3581, 'score': 2274.0123538970947, 'total_duration': 2394.818213224411, 'accumulated_submission_time': 2274.0123538970947, 'accumulated_eval_time': 116.41702151298523, 'accumulated_logging_time': 4.029884099960327}
I0208 20:46:13.105947 140250622109440 logging_writer.py:48] [9611] accumulated_eval_time=116.417022, accumulated_logging_time=4.029884, accumulated_submission_time=2274.012354, global_step=9611, preemption_count=0, score=2274.012354, test/loss=0.288316, test/num_examples=3581, test/ssim=0.741057, total_duration=2394.818213, train/loss=0.268380, train/ssim=0.746366, validation/loss=0.286948, validation/num_examples=3554, validation/ssim=0.723878
I0208 20:46:31.877696 140249942763264 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.07092924416065216, loss=0.3997633755207062
I0208 20:46:55.967255 140250622109440 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.15830634534358978, loss=0.24533319473266602
I0208 20:47:19.858110 140249942763264 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.08744218945503235, loss=0.2783085107803345
I0208 20:47:33.195924 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:47:34.568322 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:47:35.889353 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:47:37.210911 140466628462400 submission_runner.py:408] Time since start: 2478.94s, 	Step: 9957, 	{'train/ssim': 0.7377515520368304, 'train/loss': 0.2757884774889265, 'validation/ssim': 0.7153397250457231, 'validation/loss': 0.2945271214542593, 'validation/num_examples': 3554, 'test/ssim': 0.7323646066043005, 'test/loss': 0.2962296397217956, 'test/num_examples': 3581, 'score': 2354.080169200897, 'total_duration': 2478.943204164505, 'accumulated_submission_time': 2354.080169200897, 'accumulated_eval_time': 120.43198204040527, 'accumulated_logging_time': 4.058996915817261}
I0208 20:47:37.228788 140250622109440 logging_writer.py:48] [9957] accumulated_eval_time=120.431982, accumulated_logging_time=4.058997, accumulated_submission_time=2354.080169, global_step=9957, preemption_count=0, score=2354.080169, test/loss=0.296230, test/num_examples=3581, test/ssim=0.732365, total_duration=2478.943204, train/loss=0.275788, train/ssim=0.737752, validation/loss=0.294527, validation/num_examples=3554, validation/ssim=0.715340
I0208 20:47:45.421376 140249942763264 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.14505349099636078, loss=0.2978231906890869
I0208 20:48:09.225176 140250622109440 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.28129222989082336, loss=0.24388597905635834
I0208 20:48:32.932887 140249942763264 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.1558055430650711, loss=0.3656768202781677
I0208 20:48:56.694514 140250622109440 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.09325551241636276, loss=0.29484322667121887
I0208 20:48:57.341549 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:48:58.713348 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:49:00.034334 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:49:01.356454 140466628462400 submission_runner.py:408] Time since start: 2563.09s, 	Step: 10304, 	{'train/ssim': 0.7443478448050362, 'train/loss': 0.2687504972730364, 'validation/ssim': 0.722362031008195, 'validation/loss': 0.28724710768236494, 'validation/num_examples': 3554, 'test/ssim': 0.7394697737407497, 'test/loss': 0.2885957625750489, 'test/num_examples': 3581, 'score': 2434.170556306839, 'total_duration': 2563.088749408722, 'accumulated_submission_time': 2434.170556306839, 'accumulated_eval_time': 124.446848154068, 'accumulated_logging_time': 4.085970640182495}
I0208 20:49:01.373179 140249942763264 logging_writer.py:48] [10304] accumulated_eval_time=124.446848, accumulated_logging_time=4.085971, accumulated_submission_time=2434.170556, global_step=10304, preemption_count=0, score=2434.170556, test/loss=0.288596, test/num_examples=3581, test/ssim=0.739470, total_duration=2563.088749, train/loss=0.268750, train/ssim=0.744348, validation/loss=0.287247, validation/num_examples=3554, validation/ssim=0.722362
I0208 20:49:22.475973 140250622109440 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.12318364530801773, loss=0.2814507782459259
I0208 20:49:46.243608 140249942763264 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.11337869614362717, loss=0.24492523074150085
I0208 20:50:10.239222 140250622109440 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.09076502919197083, loss=0.2462427169084549
I0208 20:50:21.515489 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:50:22.888688 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:50:24.208805 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:50:25.532204 140466628462400 submission_runner.py:408] Time since start: 2647.26s, 	Step: 10648, 	{'train/ssim': 0.7457329886300224, 'train/loss': 0.2680527653012957, 'validation/ssim': 0.723326915425401, 'validation/loss': 0.2866149799301843, 'validation/num_examples': 3554, 'test/ssim': 0.7404704026022759, 'test/loss': 0.2880172836018221, 'test/num_examples': 3581, 'score': 2514.290768623352, 'total_duration': 2647.2644975185394, 'accumulated_submission_time': 2514.290768623352, 'accumulated_eval_time': 128.46352362632751, 'accumulated_logging_time': 4.111758708953857}
I0208 20:50:25.549092 140249942763264 logging_writer.py:48] [10648] accumulated_eval_time=128.463524, accumulated_logging_time=4.111759, accumulated_submission_time=2514.290769, global_step=10648, preemption_count=0, score=2514.290769, test/loss=0.288017, test/num_examples=3581, test/ssim=0.740470, total_duration=2647.264498, train/loss=0.268053, train/ssim=0.745733, validation/loss=0.286615, validation/num_examples=3554, validation/ssim=0.723327
I0208 20:50:35.995798 140250622109440 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.08976222574710846, loss=0.25052839517593384
I0208 20:51:00.138254 140249942763264 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.08961556106805801, loss=0.23235520720481873
I0208 20:51:24.304200 140250622109440 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.4098890721797943, loss=0.24811597168445587
I0208 20:51:45.703769 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:51:47.077921 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:51:48.400143 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:51:49.724168 140466628462400 submission_runner.py:408] Time since start: 2731.46s, 	Step: 10992, 	{'train/ssim': 0.746624265398298, 'train/loss': 0.26770830154418945, 'validation/ssim': 0.7237021253561128, 'validation/loss': 0.28674936375057153, 'validation/num_examples': 3554, 'test/ssim': 0.7408430562342921, 'test/loss': 0.28809575493926276, 'test/num_examples': 3581, 'score': 2594.4230313301086, 'total_duration': 2731.456456422806, 'accumulated_submission_time': 2594.4230313301086, 'accumulated_eval_time': 132.48388409614563, 'accumulated_logging_time': 4.137834072113037}
I0208 20:51:49.741377 140249942763264 logging_writer.py:48] [10992] accumulated_eval_time=132.483884, accumulated_logging_time=4.137834, accumulated_submission_time=2594.423031, global_step=10992, preemption_count=0, score=2594.423031, test/loss=0.288096, test/num_examples=3581, test/ssim=0.740843, total_duration=2731.456456, train/loss=0.267708, train/ssim=0.746624, validation/loss=0.286749, validation/num_examples=3554, validation/ssim=0.723702
I0208 20:51:50.413989 140250622109440 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.17555484175682068, loss=0.2679784893989563
I0208 20:52:13.501348 140249942763264 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.1598557084798813, loss=0.24492985010147095
I0208 20:52:37.241323 140250622109440 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.11477052420377731, loss=0.38689592480659485
I0208 20:53:00.801836 140249942763264 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.13277892768383026, loss=0.2810034155845642
I0208 20:53:09.861695 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:53:11.235289 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:53:12.559617 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:53:13.882232 140466628462400 submission_runner.py:408] Time since start: 2815.61s, 	Step: 11339, 	{'train/ssim': 0.7461288315909249, 'train/loss': 0.2680037702832903, 'validation/ssim': 0.7235591031891883, 'validation/loss': 0.2868198787622661, 'validation/num_examples': 3554, 'test/ssim': 0.7407568127574351, 'test/loss': 0.2881150148461498, 'test/num_examples': 3581, 'score': 2674.5201218128204, 'total_duration': 2815.6145203113556, 'accumulated_submission_time': 2674.5201218128204, 'accumulated_eval_time': 136.50437474250793, 'accumulated_logging_time': 4.165032148361206}
I0208 20:53:13.900730 140250622109440 logging_writer.py:48] [11339] accumulated_eval_time=136.504375, accumulated_logging_time=4.165032, accumulated_submission_time=2674.520122, global_step=11339, preemption_count=0, score=2674.520122, test/loss=0.288115, test/num_examples=3581, test/ssim=0.740757, total_duration=2815.614520, train/loss=0.268004, train/ssim=0.746129, validation/loss=0.286820, validation/num_examples=3554, validation/ssim=0.723559
I0208 20:53:26.408527 140249942763264 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.13072964549064636, loss=0.26810702681541443
I0208 20:53:50.237780 140250622109440 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.1083914265036583, loss=0.3676074743270874
I0208 20:54:14.120870 140249942763264 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.25572362542152405, loss=0.25693023204803467
I0208 20:54:34.002061 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:54:35.374076 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:54:36.696213 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:54:38.021174 140466628462400 submission_runner.py:408] Time since start: 2899.75s, 	Step: 11685, 	{'train/ssim': 0.7460990633283343, 'train/loss': 0.26770567893981934, 'validation/ssim': 0.7235476998848129, 'validation/loss': 0.28640745352947383, 'validation/num_examples': 3554, 'test/ssim': 0.7407115434541678, 'test/loss': 0.2877580077579587, 'test/num_examples': 3581, 'score': 2754.5981678962708, 'total_duration': 2899.753466129303, 'accumulated_submission_time': 2754.5981678962708, 'accumulated_eval_time': 140.52345037460327, 'accumulated_logging_time': 4.1935601234436035}
I0208 20:54:38.038317 140250622109440 logging_writer.py:48] [11685] accumulated_eval_time=140.523450, accumulated_logging_time=4.193560, accumulated_submission_time=2754.598168, global_step=11685, preemption_count=0, score=2754.598168, test/loss=0.287758, test/num_examples=3581, test/ssim=0.740712, total_duration=2899.753466, train/loss=0.267706, train/ssim=0.746099, validation/loss=0.286407, validation/num_examples=3554, validation/ssim=0.723548
I0208 20:54:39.588751 140249942763264 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.21454018354415894, loss=0.24051707983016968
I0208 20:55:03.917507 140250622109440 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.10206442326307297, loss=0.2724912762641907
I0208 20:55:27.762393 140249942763264 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.13233080506324768, loss=0.31392595171928406
I0208 20:55:51.890669 140250622109440 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.13392038643360138, loss=0.33880946040153503
I0208 20:55:58.125906 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:55:59.498306 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:56:00.820820 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:56:02.145486 140466628462400 submission_runner.py:408] Time since start: 2983.88s, 	Step: 12028, 	{'train/ssim': 0.7467365946088519, 'train/loss': 0.2680112634386335, 'validation/ssim': 0.7236964237039252, 'validation/loss': 0.2872677504110685, 'validation/num_examples': 3554, 'test/ssim': 0.7407484952047263, 'test/loss': 0.2886041142160884, 'test/num_examples': 3581, 'score': 2834.6626737117767, 'total_duration': 2983.8777344226837, 'accumulated_submission_time': 2834.6626737117767, 'accumulated_eval_time': 144.54294848442078, 'accumulated_logging_time': 4.220882415771484}
I0208 20:56:02.169710 140249942763264 logging_writer.py:48] [12028] accumulated_eval_time=144.542948, accumulated_logging_time=4.220882, accumulated_submission_time=2834.662674, global_step=12028, preemption_count=0, score=2834.662674, test/loss=0.288604, test/num_examples=3581, test/ssim=0.740748, total_duration=2983.877734, train/loss=0.268011, train/ssim=0.746737, validation/loss=0.287268, validation/num_examples=3554, validation/ssim=0.723696
I0208 20:56:17.243457 140250622109440 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.07559484243392944, loss=0.3269807696342468
I0208 20:56:40.815328 140249942763264 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.11704274266958237, loss=0.26831552386283875
I0208 20:57:04.844175 140250622109440 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.10962260514497757, loss=0.22917404770851135
I0208 20:57:22.334348 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:57:23.707687 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:57:25.028439 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:57:26.353260 140466628462400 submission_runner.py:408] Time since start: 3068.09s, 	Step: 12375, 	{'train/ssim': 0.7449325834001813, 'train/loss': 0.26895018986293245, 'validation/ssim': 0.7220681554894134, 'validation/loss': 0.28792215238881363, 'validation/num_examples': 3554, 'test/ssim': 0.7391867042420064, 'test/loss': 0.2893144127644164, 'test/num_examples': 3581, 'score': 2914.8029844760895, 'total_duration': 3068.0855479240417, 'accumulated_submission_time': 2914.8029844760895, 'accumulated_eval_time': 148.56185173988342, 'accumulated_logging_time': 4.256128311157227}
I0208 20:57:26.372196 140249942763264 logging_writer.py:48] [12375] accumulated_eval_time=148.561852, accumulated_logging_time=4.256128, accumulated_submission_time=2914.802984, global_step=12375, preemption_count=0, score=2914.802984, test/loss=0.289314, test/num_examples=3581, test/ssim=0.739187, total_duration=3068.085548, train/loss=0.268950, train/ssim=0.744933, validation/loss=0.287922, validation/num_examples=3554, validation/ssim=0.722068
I0208 20:57:30.348232 140250622109440 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.17500923573970795, loss=0.26424533128738403
I0208 20:57:54.327210 140249942763264 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.09087026864290237, loss=0.346958726644516
I0208 20:58:17.744313 140250622109440 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.14626544713974, loss=0.277401864528656
I0208 20:58:41.663335 140249942763264 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.11834035068750381, loss=0.3055417239665985
I0208 20:58:46.543934 140466628462400 spec.py:321] Evaluating on the training split.
I0208 20:58:47.916135 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 20:58:49.237770 140466628462400 spec.py:349] Evaluating on the test split.
I0208 20:58:50.559291 140466628462400 submission_runner.py:408] Time since start: 3152.29s, 	Step: 12722, 	{'train/ssim': 0.7473699024745396, 'train/loss': 0.2685403653553554, 'validation/ssim': 0.7248627207020258, 'validation/loss': 0.28711866594528174, 'validation/num_examples': 3554, 'test/ssim': 0.7420470560772131, 'test/loss': 0.2884791463954726, 'test/num_examples': 3581, 'score': 2994.950837135315, 'total_duration': 3152.291583776474, 'accumulated_submission_time': 2994.950837135315, 'accumulated_eval_time': 152.57717752456665, 'accumulated_logging_time': 4.285537481307983}
I0208 20:58:50.577904 140250622109440 logging_writer.py:48] [12722] accumulated_eval_time=152.577178, accumulated_logging_time=4.285537, accumulated_submission_time=2994.950837, global_step=12722, preemption_count=0, score=2994.950837, test/loss=0.288479, test/num_examples=3581, test/ssim=0.742047, total_duration=3152.291584, train/loss=0.268540, train/ssim=0.747370, validation/loss=0.287119, validation/num_examples=3554, validation/ssim=0.724863
I0208 20:59:06.993685 140249942763264 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.1303383857011795, loss=0.26210251450538635
I0208 20:59:31.368986 140250622109440 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.1487996131181717, loss=0.3043278157711029
I0208 20:59:55.217891 140249942763264 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.10984102636575699, loss=0.3105969727039337
I0208 21:00:10.733341 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:00:12.104920 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:00:13.426676 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:00:14.749328 140466628462400 submission_runner.py:408] Time since start: 3236.48s, 	Step: 13065, 	{'train/ssim': 0.7461308070591518, 'train/loss': 0.26766501154218403, 'validation/ssim': 0.7229474464291995, 'validation/loss': 0.28673495505724184, 'validation/num_examples': 3554, 'test/ssim': 0.7402109222284278, 'test/loss': 0.28803115755244696, 'test/num_examples': 3581, 'score': 3075.084317445755, 'total_duration': 3236.4816160202026, 'accumulated_submission_time': 3075.084317445755, 'accumulated_eval_time': 156.59312415122986, 'accumulated_logging_time': 4.313032388687134}
I0208 21:00:14.767813 140250622109440 logging_writer.py:48] [13065] accumulated_eval_time=156.593124, accumulated_logging_time=4.313032, accumulated_submission_time=3075.084317, global_step=13065, preemption_count=0, score=3075.084317, test/loss=0.288031, test/num_examples=3581, test/ssim=0.740211, total_duration=3236.481616, train/loss=0.267665, train/ssim=0.746131, validation/loss=0.286735, validation/num_examples=3554, validation/ssim=0.722947
I0208 21:00:21.084161 140249942763264 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.19267423450946808, loss=0.25542399287223816
I0208 21:00:44.889594 140250622109440 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.15753276646137238, loss=0.23979970812797546
I0208 21:01:08.987731 140249942763264 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.08427790552377701, loss=0.2413882464170456
I0208 21:01:32.777140 140250622109440 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.09952215105295181, loss=0.2943934202194214
I0208 21:01:34.821362 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:01:36.195545 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:01:37.515917 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:01:38.839825 140466628462400 submission_runner.py:408] Time since start: 3320.57s, 	Step: 13410, 	{'train/ssim': 0.7395822661263602, 'train/loss': 0.2715660844530378, 'validation/ssim': 0.7169801522052617, 'validation/loss': 0.2904655186057963, 'validation/num_examples': 3554, 'test/ssim': 0.7346096640690449, 'test/loss': 0.29159802413126573, 'test/num_examples': 3581, 'score': 3155.1144280433655, 'total_duration': 3320.5721111297607, 'accumulated_submission_time': 3155.1144280433655, 'accumulated_eval_time': 160.61153936386108, 'accumulated_logging_time': 4.341656446456909}
I0208 21:01:38.859851 140249942763264 logging_writer.py:48] [13410] accumulated_eval_time=160.611539, accumulated_logging_time=4.341656, accumulated_submission_time=3155.114428, global_step=13410, preemption_count=0, score=3155.114428, test/loss=0.291598, test/num_examples=3581, test/ssim=0.734610, total_duration=3320.572111, train/loss=0.271566, train/ssim=0.739582, validation/loss=0.290466, validation/num_examples=3554, validation/ssim=0.716980
I0208 21:01:58.174827 140250622109440 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.12127529829740524, loss=0.24884355068206787
I0208 21:02:22.420479 140249942763264 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.14960896968841553, loss=0.20554344356060028
I0208 21:02:46.309467 140250622109440 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.12675663828849792, loss=0.28128355741500854
I0208 21:02:59.048288 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:03:00.421600 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:03:01.742894 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:03:03.065636 140466628462400 submission_runner.py:408] Time since start: 3404.80s, 	Step: 13754, 	{'train/ssim': 0.7470260347638812, 'train/loss': 0.26718645436423166, 'validation/ssim': 0.7241098965294387, 'validation/loss': 0.28617504250822134, 'validation/num_examples': 3554, 'test/ssim': 0.7413727888945127, 'test/loss': 0.28743277099404846, 'test/num_examples': 3581, 'score': 3235.2807846069336, 'total_duration': 3404.797929763794, 'accumulated_submission_time': 3235.2807846069336, 'accumulated_eval_time': 164.62888169288635, 'accumulated_logging_time': 4.370457410812378}
I0208 21:03:03.083447 140249942763264 logging_writer.py:48] [13754] accumulated_eval_time=164.628882, accumulated_logging_time=4.370457, accumulated_submission_time=3235.280785, global_step=13754, preemption_count=0, score=3235.280785, test/loss=0.287433, test/num_examples=3581, test/ssim=0.741373, total_duration=3404.797930, train/loss=0.267186, train/ssim=0.747026, validation/loss=0.286175, validation/num_examples=3554, validation/ssim=0.724110
I0208 21:03:11.999880 140250622109440 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.18439136445522308, loss=0.32870301604270935
I0208 21:03:36.114256 140249942763264 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.2605232298374176, loss=0.25286513566970825
I0208 21:04:00.146041 140250622109440 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.1260402500629425, loss=0.24591755867004395
I0208 21:04:23.418437 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:04:24.792541 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:04:26.114120 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:04:27.436122 140466628462400 submission_runner.py:408] Time since start: 3489.17s, 	Step: 14098, 	{'train/ssim': 0.7473585265023368, 'train/loss': 0.2675982883998326, 'validation/ssim': 0.7245061957037845, 'validation/loss': 0.28663218792865436, 'validation/num_examples': 3554, 'test/ssim': 0.7416673802490575, 'test/loss': 0.2879964215433887, 'test/num_examples': 3581, 'score': 3315.593653202057, 'total_duration': 3489.1684036254883, 'accumulated_submission_time': 3315.593653202057, 'accumulated_eval_time': 168.64652037620544, 'accumulated_logging_time': 4.3972272872924805}
I0208 21:04:27.454506 140249942763264 logging_writer.py:48] [14098] accumulated_eval_time=168.646520, accumulated_logging_time=4.397227, accumulated_submission_time=3315.593653, global_step=14098, preemption_count=0, score=3315.593653, test/loss=0.287996, test/num_examples=3581, test/ssim=0.741667, total_duration=3489.168404, train/loss=0.267598, train/ssim=0.747359, validation/loss=0.286632, validation/num_examples=3554, validation/ssim=0.724506
I0208 21:04:27.695006 140250622109440 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.1976030319929123, loss=0.319001168012619
I0208 21:04:49.660198 140249942763264 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.25387194752693176, loss=0.2465369552373886
I0208 21:05:13.812724 140250622109440 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.07951965928077698, loss=0.2752147912979126
I0208 21:05:37.728214 140249942763264 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.18295793235301971, loss=0.2891518473625183
I0208 21:05:47.454105 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:05:48.826701 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:05:50.149071 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:05:51.472243 140466628462400 submission_runner.py:408] Time since start: 3573.20s, 	Step: 14442, 	{'train/ssim': 0.7471727643694196, 'train/loss': 0.26753958633967806, 'validation/ssim': 0.7243391991198298, 'validation/loss': 0.28657620182584764, 'validation/num_examples': 3554, 'test/ssim': 0.7415121419907149, 'test/loss': 0.2878864525883133, 'test/num_examples': 3581, 'score': 3395.570848941803, 'total_duration': 3573.2045345306396, 'accumulated_submission_time': 3395.570848941803, 'accumulated_eval_time': 172.66461992263794, 'accumulated_logging_time': 4.424889802932739}
I0208 21:05:51.490609 140250622109440 logging_writer.py:48] [14442] accumulated_eval_time=172.664620, accumulated_logging_time=4.424890, accumulated_submission_time=3395.570849, global_step=14442, preemption_count=0, score=3395.570849, test/loss=0.287886, test/num_examples=3581, test/ssim=0.741512, total_duration=3573.204535, train/loss=0.267540, train/ssim=0.747173, validation/loss=0.286576, validation/num_examples=3554, validation/ssim=0.724339
I0208 21:06:03.357437 140249942763264 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.16085323691368103, loss=0.3324127197265625
I0208 21:06:26.861708 140250622109440 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.1987217664718628, loss=0.22065314650535583
I0208 21:06:50.937463 140249942763264 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.14899960160255432, loss=0.270698606967926
I0208 21:07:11.507999 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:07:12.879168 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:07:14.201809 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:07:15.525272 140466628462400 submission_runner.py:408] Time since start: 3657.26s, 	Step: 14787, 	{'train/ssim': 0.748114994594029, 'train/loss': 0.26720190048217773, 'validation/ssim': 0.725114967290377, 'validation/loss': 0.2862941761263717, 'validation/num_examples': 3554, 'test/ssim': 0.7423192854867705, 'test/loss': 0.28757676010323585, 'test/num_examples': 3581, 'score': 3475.565026283264, 'total_duration': 3657.257560491562, 'accumulated_submission_time': 3475.565026283264, 'accumulated_eval_time': 176.68185997009277, 'accumulated_logging_time': 4.453326225280762}
I0208 21:07:15.544833 140250622109440 logging_writer.py:48] [14787] accumulated_eval_time=176.681860, accumulated_logging_time=4.453326, accumulated_submission_time=3475.565026, global_step=14787, preemption_count=0, score=3475.565026, test/loss=0.287577, test/num_examples=3581, test/ssim=0.742319, total_duration=3657.257560, train/loss=0.267202, train/ssim=0.748115, validation/loss=0.286294, validation/num_examples=3554, validation/ssim=0.725115
I0208 21:07:16.580632 140249942763264 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.09353883564472198, loss=0.28547605872154236
I0208 21:07:40.158008 140250622109440 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.11941744387149811, loss=0.27919265627861023
I0208 21:08:04.234216 140249942763264 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.37102174758911133, loss=0.23807400465011597
I0208 21:08:28.560597 140250622109440 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.09521537274122238, loss=0.19367879629135132
I0208 21:08:35.577936 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:08:36.948735 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:08:38.271505 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:08:39.594840 140466628462400 submission_runner.py:408] Time since start: 3741.33s, 	Step: 15130, 	{'train/ssim': 0.7476911544799805, 'train/loss': 0.26705855982644217, 'validation/ssim': 0.7246122601733962, 'validation/loss': 0.28614526339709656, 'validation/num_examples': 3554, 'test/ssim': 0.7418366628996789, 'test/loss': 0.2874424179916574, 'test/num_examples': 3581, 'score': 3555.575869321823, 'total_duration': 3741.3271055221558, 'accumulated_submission_time': 3555.575869321823, 'accumulated_eval_time': 180.69870519638062, 'accumulated_logging_time': 4.48215651512146}
I0208 21:08:39.618008 140249942763264 logging_writer.py:48] [15130] accumulated_eval_time=180.698705, accumulated_logging_time=4.482157, accumulated_submission_time=3555.575869, global_step=15130, preemption_count=0, score=3555.575869, test/loss=0.287442, test/num_examples=3581, test/ssim=0.741837, total_duration=3741.327106, train/loss=0.267059, train/ssim=0.747691, validation/loss=0.286145, validation/num_examples=3554, validation/ssim=0.724612
I0208 21:08:54.476457 140250622109440 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.08298923820257187, loss=0.1944299191236496
I0208 21:09:18.507886 140249942763264 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.1868736445903778, loss=0.22709649801254272
I0208 21:09:42.112634 140250622109440 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.09224123507738113, loss=0.29725486040115356
I0208 21:09:59.733465 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:10:01.108574 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:10:02.429522 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:10:03.751683 140466628462400 submission_runner.py:408] Time since start: 3825.48s, 	Step: 15475, 	{'train/ssim': 0.7482358387538365, 'train/loss': 0.2666790655681065, 'validation/ssim': 0.7250108262696962, 'validation/loss': 0.2860073761518711, 'validation/num_examples': 3554, 'test/ssim': 0.7421833412236456, 'test/loss': 0.2873672873106325, 'test/num_examples': 3581, 'score': 3635.6679487228394, 'total_duration': 3825.483948945999, 'accumulated_submission_time': 3635.6679487228394, 'accumulated_eval_time': 184.71685791015625, 'accumulated_logging_time': 4.515713930130005}
I0208 21:10:03.773382 140249942763264 logging_writer.py:48] [15475] accumulated_eval_time=184.716858, accumulated_logging_time=4.515714, accumulated_submission_time=3635.667949, global_step=15475, preemption_count=0, score=3635.667949, test/loss=0.287367, test/num_examples=3581, test/ssim=0.742183, total_duration=3825.483949, train/loss=0.266679, train/ssim=0.748236, validation/loss=0.286007, validation/num_examples=3554, validation/ssim=0.725011
I0208 21:10:07.744779 140250622109440 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.11073464155197144, loss=0.262473464012146
I0208 21:10:31.596051 140249942763264 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.08752600848674774, loss=0.35879313945770264
I0208 21:10:55.254691 140250622109440 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.29408836364746094, loss=0.2549118101596832
I0208 21:11:19.155342 140249942763264 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.08533524721860886, loss=0.26637428998947144
I0208 21:11:23.915030 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:11:25.288228 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:11:26.609789 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:11:27.932956 140466628462400 submission_runner.py:408] Time since start: 3909.67s, 	Step: 15821, 	{'train/ssim': 0.748002120426723, 'train/loss': 0.26682211671556744, 'validation/ssim': 0.7250834364668332, 'validation/loss': 0.2859135736691932, 'validation/num_examples': 3554, 'test/ssim': 0.7422936510620287, 'test/loss': 0.28716562074577634, 'test/num_examples': 3581, 'score': 3715.785654783249, 'total_duration': 3909.665248632431, 'accumulated_submission_time': 3715.785654783249, 'accumulated_eval_time': 188.73474383354187, 'accumulated_logging_time': 4.548308849334717}
I0208 21:11:27.951835 140250622109440 logging_writer.py:48] [15821] accumulated_eval_time=188.734744, accumulated_logging_time=4.548309, accumulated_submission_time=3715.785655, global_step=15821, preemption_count=0, score=3715.785655, test/loss=0.287166, test/num_examples=3581, test/ssim=0.742294, total_duration=3909.665249, train/loss=0.266822, train/ssim=0.748002, validation/loss=0.285914, validation/num_examples=3554, validation/ssim=0.725083
I0208 21:11:44.656803 140249942763264 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.11665894836187363, loss=0.18971861898899078
I0208 21:12:08.576068 140250622109440 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.24344956874847412, loss=0.2618594765663147
I0208 21:12:32.635601 140249942763264 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.12438090890645981, loss=0.24246542155742645
I0208 21:12:48.187750 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:12:49.561206 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:12:50.882126 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:12:52.204806 140466628462400 submission_runner.py:408] Time since start: 3993.94s, 	Step: 16165, 	{'train/ssim': 0.7476752144949776, 'train/loss': 0.266790543283735, 'validation/ssim': 0.7244753518262873, 'validation/loss': 0.28586541875131893, 'validation/num_examples': 3554, 'test/ssim': 0.7417378067404357, 'test/loss': 0.28719422085529533, 'test/num_examples': 3581, 'score': 3795.99942445755, 'total_duration': 3993.9370975494385, 'accumulated_submission_time': 3795.99942445755, 'accumulated_eval_time': 192.75176310539246, 'accumulated_logging_time': 4.576169013977051}
I0208 21:12:52.223490 140250622109440 logging_writer.py:48] [16165] accumulated_eval_time=192.751763, accumulated_logging_time=4.576169, accumulated_submission_time=3795.999424, global_step=16165, preemption_count=0, score=3795.999424, test/loss=0.287194, test/num_examples=3581, test/ssim=0.741738, total_duration=3993.937098, train/loss=0.266791, train/ssim=0.747675, validation/loss=0.285865, validation/num_examples=3554, validation/ssim=0.724475
I0208 21:12:58.471765 140249942763264 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.16730307042598724, loss=0.21328116953372955
I0208 21:13:22.621247 140250622109440 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.18969401717185974, loss=0.241712749004364
I0208 21:13:46.287826 140249942763264 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.08453192561864853, loss=0.2876043915748596
I0208 21:14:10.023041 140250622109440 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.11668560653924942, loss=0.333469420671463
I0208 21:14:12.363640 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:14:13.736117 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:14:15.057475 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:14:16.375999 140466628462400 submission_runner.py:408] Time since start: 4078.11s, 	Step: 16511, 	{'train/ssim': 0.7478722163609096, 'train/loss': 0.2664880411965506, 'validation/ssim': 0.7244973340997819, 'validation/loss': 0.28587290646322805, 'validation/num_examples': 3554, 'test/ssim': 0.7417247168214186, 'test/loss': 0.2872465123547019, 'test/num_examples': 3581, 'score': 3876.117094039917, 'total_duration': 4078.1082940101624, 'accumulated_submission_time': 3876.117094039917, 'accumulated_eval_time': 196.76408624649048, 'accumulated_logging_time': 4.604237794876099}
I0208 21:14:16.394256 140249942763264 logging_writer.py:48] [16511] accumulated_eval_time=196.764086, accumulated_logging_time=4.604238, accumulated_submission_time=3876.117094, global_step=16511, preemption_count=0, score=3876.117094, test/loss=0.287247, test/num_examples=3581, test/ssim=0.741725, total_duration=4078.108294, train/loss=0.266488, train/ssim=0.747872, validation/loss=0.285873, validation/num_examples=3554, validation/ssim=0.724497
I0208 21:14:35.615842 140250622109440 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.14015719294548035, loss=0.32467132806777954
I0208 21:14:59.401089 140249942763264 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.12911167740821838, loss=0.23308521509170532
I0208 21:15:23.309833 140250622109440 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.13499684631824493, loss=0.22607854008674622
I0208 21:15:36.523382 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:15:37.896974 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:15:39.219073 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:15:40.539417 140466628462400 submission_runner.py:408] Time since start: 4162.27s, 	Step: 16856, 	{'train/ssim': 0.7484268460954938, 'train/loss': 0.26669842856270926, 'validation/ssim': 0.7252970079927546, 'validation/loss': 0.2859993045358223, 'validation/num_examples': 3554, 'test/ssim': 0.7425804702771572, 'test/loss': 0.28726229525185004, 'test/num_examples': 3581, 'score': 3956.22412109375, 'total_duration': 4162.271712303162, 'accumulated_submission_time': 3956.22412109375, 'accumulated_eval_time': 200.78008460998535, 'accumulated_logging_time': 4.63153338432312}
I0208 21:15:40.558372 140249942763264 logging_writer.py:48] [16856] accumulated_eval_time=200.780085, accumulated_logging_time=4.631533, accumulated_submission_time=3956.224121, global_step=16856, preemption_count=0, score=3956.224121, test/loss=0.287262, test/num_examples=3581, test/ssim=0.742580, total_duration=4162.271712, train/loss=0.266698, train/ssim=0.748427, validation/loss=0.285999, validation/num_examples=3554, validation/ssim=0.725297
I0208 21:15:49.048398 140250622109440 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.08846881240606308, loss=0.4333585500717163
I0208 21:16:12.758410 140249942763264 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.2428349405527115, loss=0.2247242033481598
I0208 21:16:36.911964 140250622109440 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.1487535834312439, loss=0.26953187584877014
I0208 21:17:00.724087 140249942763264 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.1466909497976303, loss=0.27243930101394653
I0208 21:17:00.730588 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:17:02.046199 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:17:03.363672 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:17:04.686073 140466628462400 submission_runner.py:408] Time since start: 4246.42s, 	Step: 17201, 	{'train/ssim': 0.7476682662963867, 'train/loss': 0.26664754322596956, 'validation/ssim': 0.72458849184018, 'validation/loss': 0.2857119550044844, 'validation/num_examples': 3554, 'test/ssim': 0.7419232472598436, 'test/loss': 0.2869837254127688, 'test/num_examples': 3581, 'score': 4036.3730313777924, 'total_duration': 4246.418367147446, 'accumulated_submission_time': 4036.3730313777924, 'accumulated_eval_time': 204.73551487922668, 'accumulated_logging_time': 4.660937786102295}
I0208 21:17:04.704295 140250622109440 logging_writer.py:48] [17201] accumulated_eval_time=204.735515, accumulated_logging_time=4.660938, accumulated_submission_time=4036.373031, global_step=17201, preemption_count=0, score=4036.373031, test/loss=0.286984, test/num_examples=3581, test/ssim=0.741923, total_duration=4246.418367, train/loss=0.266648, train/ssim=0.747668, validation/loss=0.285712, validation/num_examples=3554, validation/ssim=0.724588
I0208 21:17:26.580324 140249942763264 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.12350163608789444, loss=0.3076671361923218
I0208 21:17:50.415156 140250622109440 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.14643771946430206, loss=0.29647913575172424
I0208 21:18:14.476657 140249942763264 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.20171500742435455, loss=0.2838216722011566
I0208 21:18:24.842530 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:18:26.212655 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:18:27.533329 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:18:28.855530 140466628462400 submission_runner.py:408] Time since start: 4330.59s, 	Step: 17545, 	{'train/ssim': 0.7476886340550014, 'train/loss': 0.2663342441831316, 'validation/ssim': 0.7242569716780388, 'validation/loss': 0.2857955048174152, 'validation/num_examples': 3554, 'test/ssim': 0.7414532373551382, 'test/loss': 0.2871294189384948, 'test/num_examples': 3581, 'score': 4116.48851108551, 'total_duration': 4330.587821722031, 'accumulated_submission_time': 4116.48851108551, 'accumulated_eval_time': 208.74849247932434, 'accumulated_logging_time': 4.688414573669434}
I0208 21:18:28.874426 140250622109440 logging_writer.py:48] [17545] accumulated_eval_time=208.748492, accumulated_logging_time=4.688415, accumulated_submission_time=4116.488511, global_step=17545, preemption_count=0, score=4116.488511, test/loss=0.287129, test/num_examples=3581, test/ssim=0.741453, total_duration=4330.587822, train/loss=0.266334, train/ssim=0.747689, validation/loss=0.285796, validation/num_examples=3554, validation/ssim=0.724257
I0208 21:18:39.975285 140249942763264 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.10365252196788788, loss=0.27514031529426575
I0208 21:19:03.770267 140250622109440 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.08348997682332993, loss=0.21646030247211456
I0208 21:19:27.561333 140249942763264 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.1935906708240509, loss=0.3056797683238983
I0208 21:19:49.006126 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:19:50.378725 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:19:51.701814 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:19:53.024396 140466628462400 submission_runner.py:408] Time since start: 4414.76s, 	Step: 17892, 	{'train/ssim': 0.7475626809256417, 'train/loss': 0.2668954474585397, 'validation/ssim': 0.7244492478765123, 'validation/loss': 0.28598833057272616, 'validation/num_examples': 3554, 'test/ssim': 0.7417253985880341, 'test/loss': 0.2873294151751431, 'test/num_examples': 3581, 'score': 4196.598222017288, 'total_duration': 4414.756689548492, 'accumulated_submission_time': 4196.598222017288, 'accumulated_eval_time': 212.76672649383545, 'accumulated_logging_time': 4.716022253036499}
I0208 21:19:53.042836 140250622109440 logging_writer.py:48] [17892] accumulated_eval_time=212.766726, accumulated_logging_time=4.716022, accumulated_submission_time=4196.598222, global_step=17892, preemption_count=0, score=4196.598222, test/loss=0.287329, test/num_examples=3581, test/ssim=0.741725, total_duration=4414.756690, train/loss=0.266895, train/ssim=0.747563, validation/loss=0.285988, validation/num_examples=3554, validation/ssim=0.724449
I0208 21:19:53.716187 140249942763264 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.11259946972131729, loss=0.33956819772720337
I0208 21:20:16.676330 140250622109440 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.10038498789072037, loss=0.2753226161003113
I0208 21:20:40.465590 140249942763264 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.19289563596248627, loss=0.2289348989725113
I0208 21:21:04.170005 140250622109440 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.07519864290952682, loss=0.23634843528270721
I0208 21:21:13.250359 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:21:14.621953 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:21:15.944811 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:21:17.269195 140466628462400 submission_runner.py:408] Time since start: 4499.00s, 	Step: 18239, 	{'train/ssim': 0.7490292276654925, 'train/loss': 0.2666161571230207, 'validation/ssim': 0.7260106075460748, 'validation/loss': 0.2858516626567336, 'validation/num_examples': 3554, 'test/ssim': 0.7431509044043214, 'test/loss': 0.2871809945829552, 'test/num_examples': 3581, 'score': 4276.7827315330505, 'total_duration': 4499.0014860630035, 'accumulated_submission_time': 4276.7827315330505, 'accumulated_eval_time': 216.78552794456482, 'accumulated_logging_time': 4.743778467178345}
I0208 21:21:17.288037 140249942763264 logging_writer.py:48] [18239] accumulated_eval_time=216.785528, accumulated_logging_time=4.743778, accumulated_submission_time=4276.782732, global_step=18239, preemption_count=0, score=4276.782732, test/loss=0.287181, test/num_examples=3581, test/ssim=0.743151, total_duration=4499.001486, train/loss=0.266616, train/ssim=0.749029, validation/loss=0.285852, validation/num_examples=3554, validation/ssim=0.726011
I0208 21:21:29.656244 140250622109440 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.13920071721076965, loss=0.30987295508384705
I0208 21:21:53.865799 140249942763264 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.0682358592748642, loss=0.3327068090438843
I0208 21:22:17.939050 140250622109440 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.19748654961585999, loss=0.2546694576740265
I0208 21:22:37.326839 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:22:38.698465 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:22:40.019974 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:22:41.340938 140466628462400 submission_runner.py:408] Time since start: 4583.07s, 	Step: 18583, 	{'train/ssim': 0.7473668370928083, 'train/loss': 0.26663053035736084, 'validation/ssim': 0.7240039007544317, 'validation/loss': 0.2860666939430044, 'validation/num_examples': 3554, 'test/ssim': 0.7413240425815065, 'test/loss': 0.28735808346132363, 'test/num_examples': 3581, 'score': 4356.798830032349, 'total_duration': 4583.0732300281525, 'accumulated_submission_time': 4356.798830032349, 'accumulated_eval_time': 220.7995901107788, 'accumulated_logging_time': 4.771770715713501}
I0208 21:22:41.359511 140249942763264 logging_writer.py:48] [18583] accumulated_eval_time=220.799590, accumulated_logging_time=4.771771, accumulated_submission_time=4356.798830, global_step=18583, preemption_count=0, score=4356.798830, test/loss=0.287358, test/num_examples=3581, test/ssim=0.741324, total_duration=4583.073230, train/loss=0.266631, train/ssim=0.747367, validation/loss=0.286067, validation/num_examples=3554, validation/ssim=0.724004
I0208 21:22:43.386617 140250622109440 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.09347912669181824, loss=0.29343998432159424
I0208 21:23:07.221959 140249942763264 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.17245082557201385, loss=0.278338223695755
I0208 21:23:30.845230 140250622109440 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.08406442403793335, loss=0.28426873683929443
I0208 21:23:54.717747 140249942763264 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.11915557831525803, loss=0.24314439296722412
I0208 21:24:01.398779 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:24:02.770151 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:24:04.092457 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:24:05.415175 140466628462400 submission_runner.py:408] Time since start: 4667.15s, 	Step: 18929, 	{'train/ssim': 0.7481992585318429, 'train/loss': 0.2665919235774449, 'validation/ssim': 0.7250225043524902, 'validation/loss': 0.2858412897714283, 'validation/num_examples': 3554, 'test/ssim': 0.742283833622766, 'test/loss': 0.2871458154255969, 'test/num_examples': 3581, 'score': 4436.8140461444855, 'total_duration': 4667.147452354431, 'accumulated_submission_time': 4436.8140461444855, 'accumulated_eval_time': 224.81593370437622, 'accumulated_logging_time': 4.800743103027344}
I0208 21:24:05.433502 140250622109440 logging_writer.py:48] [18929] accumulated_eval_time=224.815934, accumulated_logging_time=4.800743, accumulated_submission_time=4436.814046, global_step=18929, preemption_count=0, score=4436.814046, test/loss=0.287146, test/num_examples=3581, test/ssim=0.742284, total_duration=4667.147452, train/loss=0.266592, train/ssim=0.748199, validation/loss=0.285841, validation/num_examples=3554, validation/ssim=0.725023
I0208 21:24:20.409718 140249942763264 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.1075572520494461, loss=0.2724963128566742
I0208 21:24:44.438868 140250622109440 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.1314050257205963, loss=0.3031567633152008
I0208 21:25:08.310228 140249942763264 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.09521806985139847, loss=0.2249053418636322
I0208 21:25:25.678130 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:25:27.052370 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:25:28.369555 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:25:29.692538 140466628462400 submission_runner.py:408] Time since start: 4751.42s, 	Step: 19275, 	{'train/ssim': 0.7471611840384347, 'train/loss': 0.2664503370012556, 'validation/ssim': 0.7239721638470737, 'validation/loss': 0.28568368717466236, 'validation/num_examples': 3554, 'test/ssim': 0.7412129827998464, 'test/loss': 0.28697411250349064, 'test/num_examples': 3581, 'score': 4517.03516125679, 'total_duration': 4751.42479133606, 'accumulated_submission_time': 4517.03516125679, 'accumulated_eval_time': 228.83026695251465, 'accumulated_logging_time': 4.829066753387451}
I0208 21:25:29.714144 140250622109440 logging_writer.py:48] [19275] accumulated_eval_time=228.830267, accumulated_logging_time=4.829067, accumulated_submission_time=4517.035161, global_step=19275, preemption_count=0, score=4517.035161, test/loss=0.286974, test/num_examples=3581, test/ssim=0.741213, total_duration=4751.424791, train/loss=0.266450, train/ssim=0.747161, validation/loss=0.285684, validation/num_examples=3554, validation/ssim=0.723972
I0208 21:25:33.632020 140249942763264 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.19026318192481995, loss=0.23728767037391663
I0208 21:25:58.015072 140250622109440 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.2034136950969696, loss=0.22144758701324463
I0208 21:26:21.993992 140249942763264 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.27137625217437744, loss=0.32499751448631287
I0208 21:26:45.977212 140250622109440 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.10448537021875381, loss=0.2927565574645996
I0208 21:26:49.887712 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:26:51.259268 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:26:52.580120 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:26:53.900011 140466628462400 submission_runner.py:408] Time since start: 4835.63s, 	Step: 19618, 	{'train/ssim': 0.7494119235447475, 'train/loss': 0.2661271776471819, 'validation/ssim': 0.7260501756383653, 'validation/loss': 0.2857512483183561, 'validation/num_examples': 3554, 'test/ssim': 0.7430842958059899, 'test/loss': 0.28706308304680955, 'test/num_examples': 3581, 'score': 4597.184770107269, 'total_duration': 4835.632307052612, 'accumulated_submission_time': 4597.184770107269, 'accumulated_eval_time': 232.84253406524658, 'accumulated_logging_time': 4.8612940311431885}
I0208 21:26:53.919243 140249942763264 logging_writer.py:48] [19618] accumulated_eval_time=232.842534, accumulated_logging_time=4.861294, accumulated_submission_time=4597.184770, global_step=19618, preemption_count=0, score=4597.184770, test/loss=0.287063, test/num_examples=3581, test/ssim=0.743084, total_duration=4835.632307, train/loss=0.266127, train/ssim=0.749412, validation/loss=0.285751, validation/num_examples=3554, validation/ssim=0.726050
I0208 21:27:11.498904 140250622109440 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.1699592024087906, loss=0.3333117663860321
I0208 21:27:35.404592 140249942763264 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.13788078725337982, loss=0.24832408130168915
I0208 21:27:58.925832 140250622109440 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.09130275249481201, loss=0.23089490830898285
I0208 21:28:14.099379 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:28:15.470801 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:28:16.790536 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:28:18.114673 140466628462400 submission_runner.py:408] Time since start: 4919.85s, 	Step: 19964, 	{'train/ssim': 0.7486386980329242, 'train/loss': 0.26623306955610004, 'validation/ssim': 0.7253936613015265, 'validation/loss': 0.28563850329844015, 'validation/num_examples': 3554, 'test/ssim': 0.7426314664199944, 'test/loss': 0.28695205735348017, 'test/num_examples': 3581, 'score': 4677.3404042720795, 'total_duration': 4919.846963167191, 'accumulated_submission_time': 4677.3404042720795, 'accumulated_eval_time': 236.85779643058777, 'accumulated_logging_time': 4.890937805175781}
I0208 21:28:18.134524 140249942763264 logging_writer.py:48] [19964] accumulated_eval_time=236.857796, accumulated_logging_time=4.890938, accumulated_submission_time=4677.340404, global_step=19964, preemption_count=0, score=4677.340404, test/loss=0.286952, test/num_examples=3581, test/ssim=0.742631, total_duration=4919.846963, train/loss=0.266233, train/ssim=0.748639, validation/loss=0.285639, validation/num_examples=3554, validation/ssim=0.725394
I0208 21:28:24.692457 140250622109440 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.15702831745147705, loss=0.2341625988483429
I0208 21:28:48.821105 140249942763264 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.07084263116121292, loss=0.35234537720680237
I0208 21:29:12.731968 140250622109440 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.11854636669158936, loss=0.28036969900131226
I0208 21:29:36.562412 140249942763264 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.10573960095643997, loss=0.26299118995666504
I0208 21:29:38.192242 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:29:39.563687 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:29:40.883250 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:29:42.204944 140466628462400 submission_runner.py:408] Time since start: 5003.94s, 	Step: 20308, 	{'train/ssim': 0.7491888999938965, 'train/loss': 0.2662207569394793, 'validation/ssim': 0.7260768978395822, 'validation/loss': 0.28552568958391955, 'validation/num_examples': 3554, 'test/ssim': 0.7432166948827144, 'test/loss': 0.28683939542027365, 'test/num_examples': 3581, 'score': 4757.374995470047, 'total_duration': 5003.937238454819, 'accumulated_submission_time': 4757.374995470047, 'accumulated_eval_time': 240.87046551704407, 'accumulated_logging_time': 4.920657634735107}
I0208 21:29:42.225037 140250622109440 logging_writer.py:48] [20308] accumulated_eval_time=240.870466, accumulated_logging_time=4.920658, accumulated_submission_time=4757.374995, global_step=20308, preemption_count=0, score=4757.374995, test/loss=0.286839, test/num_examples=3581, test/ssim=0.743217, total_duration=5003.937238, train/loss=0.266221, train/ssim=0.749189, validation/loss=0.285526, validation/num_examples=3554, validation/ssim=0.726077
I0208 21:30:02.486246 140249942763264 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.18292537331581116, loss=0.28084826469421387
I0208 21:30:26.786261 140250622109440 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.18654030561447144, loss=0.23431146144866943
I0208 21:30:50.615733 140249942763264 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.18280942738056183, loss=0.28974634408950806
I0208 21:31:02.420446 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:31:03.795467 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:31:05.116807 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:31:06.437752 140466628462400 submission_runner.py:408] Time since start: 5088.17s, 	Step: 20650, 	{'train/ssim': 0.7485660825456891, 'train/loss': 0.2663572515760149, 'validation/ssim': 0.7249621217949845, 'validation/loss': 0.28597709900486246, 'validation/num_examples': 3554, 'test/ssim': 0.7420767811016475, 'test/loss': 0.28731312095303335, 'test/num_examples': 3581, 'score': 4837.548028469086, 'total_duration': 5088.170040607452, 'accumulated_submission_time': 4837.548028469086, 'accumulated_eval_time': 244.88773012161255, 'accumulated_logging_time': 4.949784517288208}
I0208 21:31:06.457302 140250622109440 logging_writer.py:48] [20650] accumulated_eval_time=244.887730, accumulated_logging_time=4.949785, accumulated_submission_time=4837.548028, global_step=20650, preemption_count=0, score=4837.548028, test/loss=0.287313, test/num_examples=3581, test/ssim=0.742077, total_duration=5088.170041, train/loss=0.266357, train/ssim=0.748566, validation/loss=0.285977, validation/num_examples=3554, validation/ssim=0.724962
I0208 21:31:16.123433 140249942763264 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.15731221437454224, loss=0.26291027665138245
I0208 21:31:40.125965 140250622109440 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.1405918449163437, loss=0.2590581774711609
I0208 21:32:04.065023 140249942763264 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.3008853793144226, loss=0.33486950397491455
I0208 21:32:26.525641 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:32:27.898208 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:32:29.219906 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:32:30.541032 140466628462400 submission_runner.py:408] Time since start: 5172.27s, 	Step: 20995, 	{'train/ssim': 0.7492354256766183, 'train/loss': 0.2659975971494402, 'validation/ssim': 0.7259607352630838, 'validation/loss': 0.28547178149290414, 'validation/num_examples': 3554, 'test/ssim': 0.743107612224239, 'test/loss': 0.2868216013116099, 'test/num_examples': 3581, 'score': 4917.593822479248, 'total_duration': 5172.273324012756, 'accumulated_submission_time': 4917.593822479248, 'accumulated_eval_time': 248.90308475494385, 'accumulated_logging_time': 4.978290319442749}
I0208 21:32:30.561016 140250622109440 logging_writer.py:48] [20995] accumulated_eval_time=248.903085, accumulated_logging_time=4.978290, accumulated_submission_time=4917.593822, global_step=20995, preemption_count=0, score=4917.593822, test/loss=0.286822, test/num_examples=3581, test/ssim=0.743108, total_duration=5172.273324, train/loss=0.265998, train/ssim=0.749235, validation/loss=0.285472, validation/num_examples=3554, validation/ssim=0.725961
I0208 21:32:31.016417 140249942763264 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.15312643349170685, loss=0.30845433473587036
I0208 21:32:53.369389 140250622109440 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.15275266766548157, loss=0.23327887058258057
I0208 21:33:17.503391 140249942763264 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.15215805172920227, loss=0.285833477973938
I0208 21:33:41.278078 140250622109440 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.08354580402374268, loss=0.3112107813358307
I0208 21:33:50.774907 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:33:52.147838 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:33:53.470092 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:33:54.794100 140466628462400 submission_runner.py:408] Time since start: 5256.53s, 	Step: 21341, 	{'train/ssim': 0.748748915536063, 'train/loss': 0.26592990330287386, 'validation/ssim': 0.7255290583673326, 'validation/loss': 0.28535144571917204, 'validation/num_examples': 3554, 'test/ssim': 0.7427538435274714, 'test/loss': 0.2865837329394722, 'test/num_examples': 3581, 'score': 4997.784978628159, 'total_duration': 5256.526384115219, 'accumulated_submission_time': 4997.784978628159, 'accumulated_eval_time': 252.92223858833313, 'accumulated_logging_time': 5.0073583126068115}
I0208 21:33:54.814414 140249942763264 logging_writer.py:48] [21341] accumulated_eval_time=252.922239, accumulated_logging_time=5.007358, accumulated_submission_time=4997.784979, global_step=21341, preemption_count=0, score=4997.784979, test/loss=0.286584, test/num_examples=3581, test/ssim=0.742754, total_duration=5256.526384, train/loss=0.265930, train/ssim=0.748749, validation/loss=0.285351, validation/num_examples=3554, validation/ssim=0.725529
I0208 21:34:07.062876 140250622109440 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.21381422877311707, loss=0.2622373104095459
I0208 21:34:31.304485 140249942763264 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.18736045062541962, loss=0.2165067195892334
I0208 21:34:55.662371 140250622109440 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.14358751475811005, loss=0.24855618178844452
I0208 21:35:14.891856 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:35:16.263230 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:35:17.588590 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:35:18.909229 140466628462400 submission_runner.py:408] Time since start: 5340.64s, 	Step: 21680, 	{'train/ssim': 0.7451433454241071, 'train/loss': 0.2684741360800607, 'validation/ssim': 0.7219432686981219, 'validation/loss': 0.2879481876439839, 'validation/num_examples': 3554, 'test/ssim': 0.7392589715032463, 'test/loss': 0.28925070167420064, 'test/num_examples': 3581, 'score': 5077.8388476371765, 'total_duration': 5340.641524076462, 'accumulated_submission_time': 5077.8388476371765, 'accumulated_eval_time': 256.93958377838135, 'accumulated_logging_time': 5.038073301315308}
I0208 21:35:18.929404 140249942763264 logging_writer.py:48] [21680] accumulated_eval_time=256.939584, accumulated_logging_time=5.038073, accumulated_submission_time=5077.838848, global_step=21680, preemption_count=0, score=5077.838848, test/loss=0.289251, test/num_examples=3581, test/ssim=0.739259, total_duration=5340.641524, train/loss=0.268474, train/ssim=0.745143, validation/loss=0.287948, validation/num_examples=3554, validation/ssim=0.721943
I0208 21:35:21.815117 140250622109440 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.16453664004802704, loss=0.328757107257843
I0208 21:35:45.713299 140249942763264 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.372077077627182, loss=0.2665044367313385
I0208 21:36:09.443525 140250622109440 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.1308649331331253, loss=0.2295771837234497
I0208 21:36:33.177010 140249942763264 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.10846877843141556, loss=0.2393510341644287
I0208 21:36:39.054529 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:36:40.426077 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:36:41.750075 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:36:43.074637 140466628462400 submission_runner.py:408] Time since start: 5424.81s, 	Step: 22026, 	{'train/ssim': 0.7494405337742397, 'train/loss': 0.2656904969896589, 'validation/ssim': 0.7258220408562536, 'validation/loss': 0.28542017467114517, 'validation/num_examples': 3554, 'test/ssim': 0.7429517603759425, 'test/loss': 0.2867683894272724, 'test/num_examples': 3581, 'score': 5157.941499471664, 'total_duration': 5424.806901931763, 'accumulated_submission_time': 5157.941499471664, 'accumulated_eval_time': 260.9596357345581, 'accumulated_logging_time': 5.067148923873901}
I0208 21:36:43.098539 140250622109440 logging_writer.py:48] [22026] accumulated_eval_time=260.959636, accumulated_logging_time=5.067149, accumulated_submission_time=5157.941499, global_step=22026, preemption_count=0, score=5157.941499, test/loss=0.286768, test/num_examples=3581, test/ssim=0.742952, total_duration=5424.806902, train/loss=0.265690, train/ssim=0.749441, validation/loss=0.285420, validation/num_examples=3554, validation/ssim=0.725822
I0208 21:36:58.850699 140249942763264 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.3061043918132782, loss=0.30239996314048767
I0208 21:37:22.612534 140250622109440 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.17235024273395538, loss=0.25820863246917725
I0208 21:37:46.520518 140249942763264 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.15542224049568176, loss=0.32834768295288086
I0208 21:38:03.204431 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:38:04.576367 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:38:05.898246 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:38:07.219290 140466628462400 submission_runner.py:408] Time since start: 5508.95s, 	Step: 22371, 	{'train/ssim': 0.74909394127982, 'train/loss': 0.2657301425933838, 'validation/ssim': 0.7256988714300788, 'validation/loss': 0.28520481708550227, 'validation/num_examples': 3554, 'test/ssim': 0.7429030140629364, 'test/loss': 0.2864998074691078, 'test/num_examples': 3581, 'score': 5238.024378061295, 'total_duration': 5508.9515812397, 'accumulated_submission_time': 5238.024378061295, 'accumulated_eval_time': 264.9744710922241, 'accumulated_logging_time': 5.100812196731567}
I0208 21:38:07.238824 140250622109440 logging_writer.py:48] [22371] accumulated_eval_time=264.974471, accumulated_logging_time=5.100812, accumulated_submission_time=5238.024378, global_step=22371, preemption_count=0, score=5238.024378, test/loss=0.286500, test/num_examples=3581, test/ssim=0.742903, total_duration=5508.951581, train/loss=0.265730, train/ssim=0.749094, validation/loss=0.285205, validation/num_examples=3554, validation/ssim=0.725699
I0208 21:38:12.183412 140249942763264 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.11315298080444336, loss=0.22587920725345612
I0208 21:38:36.008646 140250622109440 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.1330907940864563, loss=0.22456541657447815
I0208 21:38:59.802121 140249942763264 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.14592549204826355, loss=0.2161465585231781
I0208 21:39:24.543311 140250622109440 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.2828216850757599, loss=0.29707610607147217
I0208 21:39:27.246239 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:39:28.618834 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:39:29.940980 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:39:31.264925 140466628462400 submission_runner.py:408] Time since start: 5593.00s, 	Step: 22713, 	{'train/ssim': 0.7492767742701939, 'train/loss': 0.2658064535685948, 'validation/ssim': 0.7258655245410102, 'validation/loss': 0.2852625892480304, 'validation/num_examples': 3554, 'test/ssim': 0.7430842276293284, 'test/loss': 0.28655578050823793, 'test/num_examples': 3581, 'score': 5318.00970864296, 'total_duration': 5592.997215270996, 'accumulated_submission_time': 5318.00970864296, 'accumulated_eval_time': 268.993115901947, 'accumulated_logging_time': 5.129384994506836}
I0208 21:39:31.285092 140249942763264 logging_writer.py:48] [22713] accumulated_eval_time=268.993116, accumulated_logging_time=5.129385, accumulated_submission_time=5318.009709, global_step=22713, preemption_count=0, score=5318.009709, test/loss=0.286556, test/num_examples=3581, test/ssim=0.743084, total_duration=5592.997215, train/loss=0.265806, train/ssim=0.749277, validation/loss=0.285263, validation/num_examples=3554, validation/ssim=0.725866
I0208 21:39:50.144528 140250622109440 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.13730674982070923, loss=0.26426708698272705
I0208 21:40:14.267776 140249942763264 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.16763068735599518, loss=0.20579439401626587
I0208 21:40:37.850486 140250622109440 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.20586709678173065, loss=0.25728583335876465
I0208 21:40:51.417139 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:40:52.791500 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:40:54.109450 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:40:55.429472 140466628462400 submission_runner.py:408] Time since start: 5677.16s, 	Step: 23058, 	{'train/ssim': 0.7493971415928432, 'train/loss': 0.2653361899512155, 'validation/ssim': 0.7256113545037282, 'validation/loss': 0.28526276098454206, 'validation/num_examples': 3554, 'test/ssim': 0.7427997945973541, 'test/loss': 0.28663002489266265, 'test/num_examples': 3581, 'score': 5398.11927318573, 'total_duration': 5677.161759853363, 'accumulated_submission_time': 5398.11927318573, 'accumulated_eval_time': 273.005410194397, 'accumulated_logging_time': 5.15982985496521}
I0208 21:40:55.449807 140249942763264 logging_writer.py:48] [23058] accumulated_eval_time=273.005410, accumulated_logging_time=5.159830, accumulated_submission_time=5398.119273, global_step=23058, preemption_count=0, score=5398.119273, test/loss=0.286630, test/num_examples=3581, test/ssim=0.742800, total_duration=5677.161760, train/loss=0.265336, train/ssim=0.749397, validation/loss=0.285263, validation/num_examples=3554, validation/ssim=0.725611
I0208 21:41:03.564397 140250622109440 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.15437987446784973, loss=0.3160514831542969
I0208 21:41:27.541350 140249942763264 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.132324680685997, loss=0.27271199226379395
I0208 21:41:51.308771 140250622109440 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.1611216962337494, loss=0.26260069012641907
I0208 21:42:15.279492 140249942763264 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.10832452774047852, loss=0.3002939224243164
I0208 21:42:15.457518 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:42:16.831354 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:42:18.153183 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:42:19.474392 140466628462400 submission_runner.py:408] Time since start: 5761.21s, 	Step: 23402, 	{'train/ssim': 0.7490113803318569, 'train/loss': 0.2655630792890276, 'validation/ssim': 0.725430275525816, 'validation/loss': 0.2852217503055536, 'validation/num_examples': 3554, 'test/ssim': 0.7426350116063949, 'test/loss': 0.2865171584294715, 'test/num_examples': 3581, 'score': 5478.105720996857, 'total_duration': 5761.20668721199, 'accumulated_submission_time': 5478.105720996857, 'accumulated_eval_time': 277.02224564552307, 'accumulated_logging_time': 5.189005136489868}
I0208 21:42:19.494354 140250622109440 logging_writer.py:48] [23402] accumulated_eval_time=277.022246, accumulated_logging_time=5.189005, accumulated_submission_time=5478.105721, global_step=23402, preemption_count=0, score=5478.105721, test/loss=0.286517, test/num_examples=3581, test/ssim=0.742635, total_duration=5761.206687, train/loss=0.265563, train/ssim=0.749011, validation/loss=0.285222, validation/num_examples=3554, validation/ssim=0.725430
I0208 21:42:41.180417 140249942763264 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.10134629905223846, loss=0.27118584513664246
I0208 21:43:05.025260 140250622109440 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.19904540479183197, loss=0.2566348612308502
I0208 21:43:29.251083 140249942763264 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.09504689276218414, loss=0.284848690032959
I0208 21:43:39.683829 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:43:41.057127 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:43:42.377085 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:43:43.698245 140466628462400 submission_runner.py:408] Time since start: 5845.43s, 	Step: 23744, 	{'train/ssim': 0.7494708469935826, 'train/loss': 0.2656279632023403, 'validation/ssim': 0.7260391845016179, 'validation/loss': 0.2851841915304498, 'validation/num_examples': 3554, 'test/ssim': 0.7431993780106814, 'test/loss': 0.28651470406965585, 'test/num_examples': 3581, 'score': 5558.272310495377, 'total_duration': 5845.430538654327, 'accumulated_submission_time': 5558.272310495377, 'accumulated_eval_time': 281.0366368293762, 'accumulated_logging_time': 5.219642877578735}
I0208 21:43:43.719342 140250622109440 logging_writer.py:48] [23744] accumulated_eval_time=281.036637, accumulated_logging_time=5.219643, accumulated_submission_time=5558.272310, global_step=23744, preemption_count=0, score=5558.272310, test/loss=0.286515, test/num_examples=3581, test/ssim=0.743199, total_duration=5845.430539, train/loss=0.265628, train/ssim=0.749471, validation/loss=0.285184, validation/num_examples=3554, validation/ssim=0.726039
I0208 21:43:55.113610 140249942763264 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.13764460384845734, loss=0.2915254533290863
I0208 21:44:19.198324 140250622109440 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.1297590136528015, loss=0.2281649261713028
I0208 21:44:43.142885 140249942763264 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.13004621863365173, loss=0.18882888555526733
I0208 21:45:03.748340 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:45:05.120850 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:45:06.441041 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:45:07.764644 140466628462400 submission_runner.py:408] Time since start: 5929.50s, 	Step: 24088, 	{'train/ssim': 0.7504288128444127, 'train/loss': 0.2651689904076712, 'validation/ssim': 0.7265264353325478, 'validation/loss': 0.2852026016845016, 'validation/num_examples': 3554, 'test/ssim': 0.7436515256300614, 'test/loss': 0.28659266408213485, 'test/num_examples': 3581, 'score': 5638.279019832611, 'total_duration': 5929.496938467026, 'accumulated_submission_time': 5638.279019832611, 'accumulated_eval_time': 285.0529205799103, 'accumulated_logging_time': 5.249758005142212}
I0208 21:45:07.785166 140250622109440 logging_writer.py:48] [24088] accumulated_eval_time=285.052921, accumulated_logging_time=5.249758, accumulated_submission_time=5638.279020, global_step=24088, preemption_count=0, score=5638.279020, test/loss=0.286593, test/num_examples=3581, test/ssim=0.743652, total_duration=5929.496938, train/loss=0.265169, train/ssim=0.750429, validation/loss=0.285203, validation/num_examples=3554, validation/ssim=0.726526
I0208 21:45:08.749410 140249942763264 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.07040643692016602, loss=0.3493751883506775
I0208 21:45:32.313971 140250622109440 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.20849217474460602, loss=0.2742180824279785
I0208 21:45:56.260199 140249942763264 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.25593680143356323, loss=0.2702495753765106
I0208 21:46:20.117393 140250622109440 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.2107265740633011, loss=0.32984089851379395
I0208 21:46:27.848628 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:46:29.221359 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:46:30.542175 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:46:31.866294 140466628462400 submission_runner.py:408] Time since start: 6013.60s, 	Step: 24433, 	{'train/ssim': 0.7496530669076102, 'train/loss': 0.2654334136417934, 'validation/ssim': 0.7260332767656162, 'validation/loss': 0.2851277073917593, 'validation/num_examples': 3554, 'test/ssim': 0.7432730088051522, 'test/loss': 0.2864014285464954, 'test/num_examples': 3581, 'score': 5718.319184303284, 'total_duration': 6013.598551034927, 'accumulated_submission_time': 5718.319184303284, 'accumulated_eval_time': 289.0705211162567, 'accumulated_logging_time': 5.280286550521851}
I0208 21:46:31.889597 140249942763264 logging_writer.py:48] [24433] accumulated_eval_time=289.070521, accumulated_logging_time=5.280287, accumulated_submission_time=5718.319184, global_step=24433, preemption_count=0, score=5718.319184, test/loss=0.286401, test/num_examples=3581, test/ssim=0.743273, total_duration=6013.598551, train/loss=0.265433, train/ssim=0.749653, validation/loss=0.285128, validation/num_examples=3554, validation/ssim=0.726033
I0208 21:46:45.743289 140250622109440 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.11675973236560822, loss=0.3064405918121338
I0208 21:47:09.835250 140249942763264 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.16066525876522064, loss=0.17353615164756775
I0208 21:47:33.375553 140250622109440 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.15109768509864807, loss=0.2316913902759552
I0208 21:47:52.013525 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:47:53.384778 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:47:54.707108 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:47:56.029682 140466628462400 submission_runner.py:408] Time since start: 6097.76s, 	Step: 24780, 	{'train/ssim': 0.7496503421238491, 'train/loss': 0.2656197888510568, 'validation/ssim': 0.7260538851470174, 'validation/loss': 0.28528658083871167, 'validation/num_examples': 3554, 'test/ssim': 0.7432156722327912, 'test/loss': 0.28662112783833077, 'test/num_examples': 3581, 'score': 5798.420118570328, 'total_duration': 6097.761975288391, 'accumulated_submission_time': 5798.420118570328, 'accumulated_eval_time': 293.0866525173187, 'accumulated_logging_time': 5.3132641315460205}
I0208 21:47:56.051031 140249942763264 logging_writer.py:48] [24780] accumulated_eval_time=293.086653, accumulated_logging_time=5.313264, accumulated_submission_time=5798.420119, global_step=24780, preemption_count=0, score=5798.420119, test/loss=0.286621, test/num_examples=3581, test/ssim=0.743216, total_duration=6097.761975, train/loss=0.265620, train/ssim=0.749650, validation/loss=0.285287, validation/num_examples=3554, validation/ssim=0.726054
I0208 21:47:58.753064 140250622109440 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.1452481746673584, loss=0.3194129467010498
I0208 21:48:23.032302 140249942763264 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.11043299734592438, loss=0.3154299855232239
I0208 21:48:46.957571 140250622109440 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.10330292582511902, loss=0.2564276456832886
I0208 21:49:10.905305 140249942763264 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.09995158016681671, loss=0.2363661825656891
I0208 21:49:16.056669 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:49:17.431433 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:49:18.752774 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:49:20.072324 140466628462400 submission_runner.py:408] Time since start: 6181.80s, 	Step: 25123, 	{'train/ssim': 0.7507190023149762, 'train/loss': 0.2650500876562936, 'validation/ssim': 0.7268040302300225, 'validation/loss': 0.2852178862340409, 'validation/num_examples': 3554, 'test/ssim': 0.7439480259311295, 'test/loss': 0.28658727812587265, 'test/num_examples': 3581, 'score': 5878.403662443161, 'total_duration': 6181.804616928101, 'accumulated_submission_time': 5878.403662443161, 'accumulated_eval_time': 297.10226798057556, 'accumulated_logging_time': 5.3443520069122314}
I0208 21:49:20.092419 140250622109440 logging_writer.py:48] [25123] accumulated_eval_time=297.102268, accumulated_logging_time=5.344352, accumulated_submission_time=5878.403662, global_step=25123, preemption_count=0, score=5878.403662, test/loss=0.286587, test/num_examples=3581, test/ssim=0.743948, total_duration=6181.804617, train/loss=0.265050, train/ssim=0.750719, validation/loss=0.285218, validation/num_examples=3554, validation/ssim=0.726804
I0208 21:49:36.524883 140249942763264 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.08105088025331497, loss=0.23393994569778442
I0208 21:50:00.355953 140250622109440 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.12408564239740372, loss=0.29326558113098145
I0208 21:50:24.219719 140249942763264 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.15938502550125122, loss=0.23107598721981049
I0208 21:50:40.088027 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:50:41.461709 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:50:42.782400 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:50:44.106044 140466628462400 submission_runner.py:408] Time since start: 6265.84s, 	Step: 25467, 	{'train/ssim': 0.7501741136823382, 'train/loss': 0.2652744735990252, 'validation/ssim': 0.7264499782375492, 'validation/loss': 0.28510332080710116, 'validation/num_examples': 3554, 'test/ssim': 0.7436492076235688, 'test/loss': 0.28641683647200505, 'test/num_examples': 3581, 'score': 5958.376376628876, 'total_duration': 6265.838335990906, 'accumulated_submission_time': 5958.376376628876, 'accumulated_eval_time': 301.12024998664856, 'accumulated_logging_time': 5.3743064403533936}
I0208 21:50:44.126511 140250622109440 logging_writer.py:48] [25467] accumulated_eval_time=301.120250, accumulated_logging_time=5.374306, accumulated_submission_time=5958.376377, global_step=25467, preemption_count=0, score=5958.376377, test/loss=0.286417, test/num_examples=3581, test/ssim=0.743649, total_duration=6265.838336, train/loss=0.265274, train/ssim=0.750174, validation/loss=0.285103, validation/num_examples=3554, validation/ssim=0.726450
I0208 21:50:49.895803 140249942763264 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.08284198492765427, loss=0.2549859285354614
I0208 21:51:14.011937 140250622109440 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.09341340512037277, loss=0.22227412462234497
I0208 21:51:38.027105 140249942763264 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.2158021330833435, loss=0.2698673903942108
I0208 21:52:02.049829 140250622109440 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.08083603531122208, loss=0.21667778491973877
I0208 21:52:04.137662 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:52:05.509311 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:52:06.832026 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:52:08.155078 140466628462400 submission_runner.py:408] Time since start: 6349.89s, 	Step: 25810, 	{'train/ssim': 0.7493463924952916, 'train/loss': 0.26540415627615793, 'validation/ssim': 0.7256698823069077, 'validation/loss': 0.28520301385212965, 'validation/num_examples': 3554, 'test/ssim': 0.7428756070449944, 'test/loss': 0.28646970747303474, 'test/num_examples': 3581, 'score': 6038.365174293518, 'total_duration': 6349.887370347977, 'accumulated_submission_time': 6038.365174293518, 'accumulated_eval_time': 305.1376292705536, 'accumulated_logging_time': 5.405126094818115}
I0208 21:52:08.175961 140249942763264 logging_writer.py:48] [25810] accumulated_eval_time=305.137629, accumulated_logging_time=5.405126, accumulated_submission_time=6038.365174, global_step=25810, preemption_count=0, score=6038.365174, test/loss=0.286470, test/num_examples=3581, test/ssim=0.742876, total_duration=6349.887370, train/loss=0.265404, train/ssim=0.749346, validation/loss=0.285203, validation/num_examples=3554, validation/ssim=0.725670
I0208 21:52:27.761952 140250622109440 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.16135630011558533, loss=0.28154468536376953
I0208 21:52:51.950072 140249942763264 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.09576714783906937, loss=0.3603634536266327
I0208 21:53:16.410105 140250622109440 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.11411085724830627, loss=0.291925847530365
I0208 21:53:28.320885 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:53:29.694522 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:53:31.015770 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:53:32.337178 140466628462400 submission_runner.py:408] Time since start: 6434.07s, 	Step: 26151, 	{'train/ssim': 0.7501864433288574, 'train/loss': 0.2650456428527832, 'validation/ssim': 0.7261618730655599, 'validation/loss': 0.2852682737265669, 'validation/num_examples': 3554, 'test/ssim': 0.7432468289671181, 'test/loss': 0.2866675561448443, 'test/num_examples': 3581, 'score': 6118.489009618759, 'total_duration': 6434.069468021393, 'accumulated_submission_time': 6118.489009618759, 'accumulated_eval_time': 309.15387773513794, 'accumulated_logging_time': 5.434753894805908}
I0208 21:53:32.358924 140249942763264 logging_writer.py:48] [26151] accumulated_eval_time=309.153878, accumulated_logging_time=5.434754, accumulated_submission_time=6118.489010, global_step=26151, preemption_count=0, score=6118.489010, test/loss=0.286668, test/num_examples=3581, test/ssim=0.743247, total_duration=6434.069468, train/loss=0.265046, train/ssim=0.750186, validation/loss=0.285268, validation/num_examples=3554, validation/ssim=0.726162
I0208 21:53:41.987475 140250622109440 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.11940155178308487, loss=0.28910014033317566
I0208 21:54:05.974425 140249942763264 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.15473870933055878, loss=0.24399365484714508
I0208 21:54:30.019106 140250622109440 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.15317092835903168, loss=0.32880210876464844
I0208 21:54:52.403752 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:54:53.778442 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:54:55.099842 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:54:56.420137 140466628462400 submission_runner.py:408] Time since start: 6518.15s, 	Step: 26495, 	{'train/ssim': 0.7501932552882603, 'train/loss': 0.2651315076010568, 'validation/ssim': 0.726330243541608, 'validation/loss': 0.28513608813352914, 'validation/num_examples': 3554, 'test/ssim': 0.7435073319908894, 'test/loss': 0.2864623443935877, 'test/num_examples': 3581, 'score': 6198.512864589691, 'total_duration': 6518.152428388596, 'accumulated_submission_time': 6198.512864589691, 'accumulated_eval_time': 313.1702241897583, 'accumulated_logging_time': 5.465415954589844}
I0208 21:54:56.441964 140249942763264 logging_writer.py:48] [26495] accumulated_eval_time=313.170224, accumulated_logging_time=5.465416, accumulated_submission_time=6198.512865, global_step=26495, preemption_count=0, score=6198.512865, test/loss=0.286462, test/num_examples=3581, test/ssim=0.743507, total_duration=6518.152428, train/loss=0.265132, train/ssim=0.750193, validation/loss=0.285136, validation/num_examples=3554, validation/ssim=0.726330
I0208 21:54:56.900823 140250622109440 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.1128852367401123, loss=0.28385913372039795
I0208 21:55:19.540581 140249942763264 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.09267372637987137, loss=0.31418612599372864
I0208 21:55:43.395836 140250622109440 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.10426298528909683, loss=0.24727165699005127
I0208 21:56:07.206225 140249942763264 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.10593263059854507, loss=0.22202850878238678
I0208 21:56:16.530496 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:56:17.901672 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:56:19.223272 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:56:20.546952 140466628462400 submission_runner.py:408] Time since start: 6602.28s, 	Step: 26840, 	{'train/ssim': 0.7490963935852051, 'train/loss': 0.26524414334978375, 'validation/ssim': 0.7254626993792206, 'validation/loss': 0.2850785735757685, 'validation/num_examples': 3554, 'test/ssim': 0.7426230806906241, 'test/loss': 0.2863978151834334, 'test/num_examples': 3581, 'score': 6278.578718662262, 'total_duration': 6602.2792291641235, 'accumulated_submission_time': 6278.578718662262, 'accumulated_eval_time': 317.18662691116333, 'accumulated_logging_time': 5.4974143505096436}
I0208 21:56:20.567710 140250622109440 logging_writer.py:48] [26840] accumulated_eval_time=317.186627, accumulated_logging_time=5.497414, accumulated_submission_time=6278.578719, global_step=26840, preemption_count=0, score=6278.578719, test/loss=0.286398, test/num_examples=3581, test/ssim=0.742623, total_duration=6602.279229, train/loss=0.265244, train/ssim=0.749096, validation/loss=0.285079, validation/num_examples=3554, validation/ssim=0.725463
I0208 21:56:32.689618 140249942763264 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.10990766435861588, loss=0.24921086430549622
I0208 21:56:57.068561 140250622109440 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.14766471087932587, loss=0.2538151741027832
I0208 21:57:21.121421 140249942763264 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.40479201078414917, loss=0.28900963068008423
I0208 21:57:40.807714 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:57:42.181155 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:57:43.502470 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:57:44.826694 140466628462400 submission_runner.py:408] Time since start: 6686.56s, 	Step: 27183, 	{'train/ssim': 0.7498324257986886, 'train/loss': 0.2650856801441738, 'validation/ssim': 0.7258750043964547, 'validation/loss': 0.2851935168230339, 'validation/num_examples': 3554, 'test/ssim': 0.7430782962597738, 'test/loss': 0.2865224762090722, 'test/num_examples': 3581, 'score': 6358.797013282776, 'total_duration': 6686.558983802795, 'accumulated_submission_time': 6358.797013282776, 'accumulated_eval_time': 321.2055685520172, 'accumulated_logging_time': 5.527190208435059}
I0208 21:57:44.848752 140250622109440 logging_writer.py:48] [27183] accumulated_eval_time=321.205569, accumulated_logging_time=5.527190, accumulated_submission_time=6358.797013, global_step=27183, preemption_count=0, score=6358.797013, test/loss=0.286522, test/num_examples=3581, test/ssim=0.743078, total_duration=6686.558984, train/loss=0.265086, train/ssim=0.749832, validation/loss=0.285194, validation/num_examples=3554, validation/ssim=0.725875
I0208 21:57:46.801197 140249942763264 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.08792507648468018, loss=0.2659539580345154
I0208 21:58:10.753736 140250622109440 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.1610608994960785, loss=0.24928930401802063
I0208 21:58:34.512510 140249942763264 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.06720175594091415, loss=0.24777589738368988
I0208 21:58:58.539839 140250622109440 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.16949695348739624, loss=0.36445581912994385
I0208 21:59:04.881118 140466628462400 spec.py:321] Evaluating on the training split.
I0208 21:59:06.252424 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 21:59:07.571315 140466628462400 spec.py:349] Evaluating on the test split.
I0208 21:59:08.894463 140466628462400 submission_runner.py:408] Time since start: 6770.63s, 	Step: 27528, 	{'train/ssim': 0.7499326297215053, 'train/loss': 0.26494300365448, 'validation/ssim': 0.7259978990442107, 'validation/loss': 0.28501042852793507, 'validation/num_examples': 3554, 'test/ssim': 0.7431881970381876, 'test/loss': 0.28637132855042235, 'test/num_examples': 3581, 'score': 6438.806653022766, 'total_duration': 6770.626757621765, 'accumulated_submission_time': 6438.806653022766, 'accumulated_eval_time': 325.2188792228699, 'accumulated_logging_time': 5.559579610824585}
I0208 21:59:08.915996 140249942763264 logging_writer.py:48] [27528] accumulated_eval_time=325.218879, accumulated_logging_time=5.559580, accumulated_submission_time=6438.806653, global_step=27528, preemption_count=0, score=6438.806653, test/loss=0.286371, test/num_examples=3581, test/ssim=0.743188, total_duration=6770.626758, train/loss=0.264943, train/ssim=0.749933, validation/loss=0.285010, validation/num_examples=3554, validation/ssim=0.725998
I0208 21:59:24.083771 140250622109440 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.18441666662693024, loss=0.283244788646698
I0208 21:59:47.971973 140249942763264 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.1737312376499176, loss=0.30522629618644714
I0208 22:00:12.056397 140250622109440 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.10709118098020554, loss=0.2667204439640045
I0208 22:00:29.142477 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:00:30.514920 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:00:31.838120 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:00:33.159303 140466628462400 submission_runner.py:408] Time since start: 6854.89s, 	Step: 27873, 	{'train/ssim': 0.7503581728254046, 'train/loss': 0.26502556460244314, 'validation/ssim': 0.726517230255522, 'validation/loss': 0.2850092435460045, 'validation/num_examples': 3554, 'test/ssim': 0.7436978175832519, 'test/loss': 0.2863230253857163, 'test/num_examples': 3581, 'score': 6519.011382341385, 'total_duration': 6854.8912081718445, 'accumulated_submission_time': 6519.011382341385, 'accumulated_eval_time': 329.2352783679962, 'accumulated_logging_time': 5.590218782424927}
I0208 22:00:33.180678 140249942763264 logging_writer.py:48] [27873] accumulated_eval_time=329.235278, accumulated_logging_time=5.590219, accumulated_submission_time=6519.011382, global_step=27873, preemption_count=0, score=6519.011382, test/loss=0.286323, test/num_examples=3581, test/ssim=0.743698, total_duration=6854.891208, train/loss=0.265026, train/ssim=0.750358, validation/loss=0.285009, validation/num_examples=3554, validation/ssim=0.726517
I0208 22:00:37.566292 140250622109440 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.08368759602308273, loss=0.25790935754776
I0208 22:01:01.677516 140249942763264 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.14402924478054047, loss=0.1763990819454193
I0208 22:01:25.896353 140250622109440 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.17883047461509705, loss=0.23839472234249115
I0208 22:01:49.649720 140249942763264 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.1354326754808426, loss=0.3096693754196167
I0208 22:01:53.421940 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:01:54.791487 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:01:56.114544 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:01:57.438176 140466628462400 submission_runner.py:408] Time since start: 6939.17s, 	Step: 28216, 	{'train/ssim': 0.7501605578831264, 'train/loss': 0.26524795804704937, 'validation/ssim': 0.7263499588931486, 'validation/loss': 0.2852860828028278, 'validation/num_examples': 3554, 'test/ssim': 0.7434523816016825, 'test/loss': 0.2867345056264835, 'test/num_examples': 3581, 'score': 6599.230717420578, 'total_duration': 6939.170467376709, 'accumulated_submission_time': 6599.230717420578, 'accumulated_eval_time': 333.2514762878418, 'accumulated_logging_time': 5.620994567871094}
I0208 22:01:57.459416 140250622109440 logging_writer.py:48] [28216] accumulated_eval_time=333.251476, accumulated_logging_time=5.620995, accumulated_submission_time=6599.230717, global_step=28216, preemption_count=0, score=6599.230717, test/loss=0.286735, test/num_examples=3581, test/ssim=0.743452, total_duration=6939.170467, train/loss=0.265248, train/ssim=0.750161, validation/loss=0.285286, validation/num_examples=3554, validation/ssim=0.726350
I0208 22:02:15.659867 140249942763264 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.16291405260562897, loss=0.3088529109954834
I0208 22:02:39.288612 140250622109440 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.14918452501296997, loss=0.32171323895454407
I0208 22:03:03.150236 140249942763264 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.12826181948184967, loss=0.2871710956096649
I0208 22:03:17.710765 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:03:19.085051 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:03:20.405075 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:03:21.724822 140466628462400 submission_runner.py:408] Time since start: 7023.46s, 	Step: 28561, 	{'train/ssim': 0.7503539494105748, 'train/loss': 0.26469622339521137, 'validation/ssim': 0.7262106462348762, 'validation/loss': 0.28498805126046356, 'validation/num_examples': 3554, 'test/ssim': 0.7433470486595923, 'test/loss': 0.28637858936487715, 'test/num_examples': 3581, 'score': 6679.461097002029, 'total_duration': 7023.457095623016, 'accumulated_submission_time': 6679.461097002029, 'accumulated_eval_time': 337.26547598838806, 'accumulated_logging_time': 5.651025295257568}
I0208 22:03:21.746776 140250622109440 logging_writer.py:48] [28561] accumulated_eval_time=337.265476, accumulated_logging_time=5.651025, accumulated_submission_time=6679.461097, global_step=28561, preemption_count=0, score=6679.461097, test/loss=0.286379, test/num_examples=3581, test/ssim=0.743347, total_duration=7023.457096, train/loss=0.264696, train/ssim=0.750354, validation/loss=0.284988, validation/num_examples=3554, validation/ssim=0.726211
I0208 22:03:29.115206 140249942763264 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.1077791079878807, loss=0.31667405366897583
I0208 22:03:52.854708 140250622109440 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.08460813760757446, loss=0.2914190888404846
I0208 22:04:17.090288 140249942763264 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.13348019123077393, loss=0.23001474142074585
I0208 22:04:40.858900 140250622109440 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.07510706782341003, loss=0.24915564060211182
I0208 22:04:41.731017 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:04:43.104470 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:04:44.425589 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:04:45.747090 140466628462400 submission_runner.py:408] Time since start: 7107.48s, 	Step: 28905, 	{'train/ssim': 0.7502357619149345, 'train/loss': 0.2648711545126779, 'validation/ssim': 0.7262302241972074, 'validation/loss': 0.2849589934426878, 'validation/num_examples': 3554, 'test/ssim': 0.743408953068277, 'test/loss': 0.2863066288986142, 'test/num_examples': 3581, 'score': 6759.423446655273, 'total_duration': 7107.479385375977, 'accumulated_submission_time': 6759.423446655273, 'accumulated_eval_time': 341.2815098762512, 'accumulated_logging_time': 5.682204484939575}
I0208 22:04:45.768351 140249942763264 logging_writer.py:48] [28905] accumulated_eval_time=341.281510, accumulated_logging_time=5.682204, accumulated_submission_time=6759.423447, global_step=28905, preemption_count=0, score=6759.423447, test/loss=0.286307, test/num_examples=3581, test/ssim=0.743409, total_duration=7107.479385, train/loss=0.264871, train/ssim=0.750236, validation/loss=0.284959, validation/num_examples=3554, validation/ssim=0.726230
I0208 22:05:06.547928 140250622109440 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.16204209625720978, loss=0.2899045944213867
I0208 22:05:30.286257 140249942763264 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.08179052919149399, loss=0.23747237026691437
I0208 22:05:54.584322 140250622109440 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.09272558242082596, loss=0.24595528841018677
I0208 22:06:05.802304 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:06:07.175172 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:06:08.498433 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:06:09.817790 140466628462400 submission_runner.py:408] Time since start: 7191.55s, 	Step: 29248, 	{'train/ssim': 0.750530515398298, 'train/loss': 0.264979498726981, 'validation/ssim': 0.7264658466912282, 'validation/loss': 0.2850998860768676, 'validation/num_examples': 3554, 'test/ssim': 0.7435973933607931, 'test/loss': 0.28650553430867776, 'test/num_examples': 3581, 'score': 6839.43584895134, 'total_duration': 7191.550079584122, 'accumulated_submission_time': 6839.43584895134, 'accumulated_eval_time': 345.2969605922699, 'accumulated_logging_time': 5.712467908859253}
I0208 22:06:09.840209 140249942763264 logging_writer.py:48] [29248] accumulated_eval_time=345.296961, accumulated_logging_time=5.712468, accumulated_submission_time=6839.435849, global_step=29248, preemption_count=0, score=6839.435849, test/loss=0.286506, test/num_examples=3581, test/ssim=0.743597, total_duration=7191.550080, train/loss=0.264979, train/ssim=0.750531, validation/loss=0.285100, validation/num_examples=3554, validation/ssim=0.726466
I0208 22:06:20.186988 140250622109440 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.07961690425872803, loss=0.2762395739555359
I0208 22:06:43.949306 140249942763264 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.126642644405365, loss=0.19680483639240265
I0208 22:07:07.882394 140250622109440 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.08169608563184738, loss=0.22382819652557373
I0208 22:07:29.964185 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:07:31.338366 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:07:32.659457 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:07:33.981061 140466628462400 submission_runner.py:408] Time since start: 7275.71s, 	Step: 29595, 	{'train/ssim': 0.7509183202471051, 'train/loss': 0.2644538879394531, 'validation/ssim': 0.7266162191808525, 'validation/loss': 0.2848655859539867, 'validation/num_examples': 3554, 'test/ssim': 0.7437091349090686, 'test/loss': 0.28625068994781483, 'test/num_examples': 3581, 'score': 6919.53741979599, 'total_duration': 7275.713355302811, 'accumulated_submission_time': 6919.53741979599, 'accumulated_eval_time': 349.3138077259064, 'accumulated_logging_time': 5.7450034618377686}
I0208 22:07:34.002901 140249942763264 logging_writer.py:48] [29595] accumulated_eval_time=349.313808, accumulated_logging_time=5.745003, accumulated_submission_time=6919.537420, global_step=29595, preemption_count=0, score=6919.537420, test/loss=0.286251, test/num_examples=3581, test/ssim=0.743709, total_duration=7275.713355, train/loss=0.264454, train/ssim=0.750918, validation/loss=0.284866, validation/num_examples=3554, validation/ssim=0.726616
I0208 22:07:34.459275 140250622109440 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.1616288274526596, loss=0.261011004447937
I0208 22:07:56.623600 140249942763264 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.1045689731836319, loss=0.30272752046585083
I0208 22:08:20.539414 140250622109440 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.13022062182426453, loss=0.2563866972923279
I0208 22:08:44.511431 140249942763264 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.12656916677951813, loss=0.23921158909797668
I0208 22:08:54.018487 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:08:55.388797 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:08:56.709759 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:08:58.029932 140466628462400 submission_runner.py:408] Time since start: 7359.76s, 	Step: 29941, 	{'train/ssim': 0.7506739071437291, 'train/loss': 0.2646848814828055, 'validation/ssim': 0.7265805666810284, 'validation/loss': 0.2849207305478862, 'validation/num_examples': 3554, 'test/ssim': 0.7437569949254748, 'test/loss': 0.2862475197330529, 'test/num_examples': 3581, 'score': 6999.530682325363, 'total_duration': 7359.7621948719025, 'accumulated_submission_time': 6999.530682325363, 'accumulated_eval_time': 353.32518696784973, 'accumulated_logging_time': 5.7767322063446045}
I0208 22:08:58.054054 140250622109440 logging_writer.py:48] [29941] accumulated_eval_time=353.325187, accumulated_logging_time=5.776732, accumulated_submission_time=6999.530682, global_step=29941, preemption_count=0, score=6999.530682, test/loss=0.286248, test/num_examples=3581, test/ssim=0.743757, total_duration=7359.762195, train/loss=0.264685, train/ssim=0.750674, validation/loss=0.284921, validation/num_examples=3554, validation/ssim=0.726581
I0208 22:09:10.163496 140249942763264 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.11161905527114868, loss=0.29443615674972534
I0208 22:09:34.148216 140250622109440 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.04415619745850563, loss=0.24897046387195587
I0208 22:09:57.891076 140249942763264 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.13110600411891937, loss=0.2557247281074524
I0208 22:10:18.197420 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:10:19.572295 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:10:20.892409 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:10:22.212738 140466628462400 submission_runner.py:408] Time since start: 7443.95s, 	Step: 30283, 	{'train/ssim': 0.7503796986171177, 'train/loss': 0.26477156366620747, 'validation/ssim': 0.7263325104635622, 'validation/loss': 0.2849135519616981, 'validation/num_examples': 3554, 'test/ssim': 0.7434573584979755, 'test/loss': 0.28630018620409803, 'test/num_examples': 3581, 'score': 7079.652544736862, 'total_duration': 7443.945029020309, 'accumulated_submission_time': 7079.652544736862, 'accumulated_eval_time': 357.34046387672424, 'accumulated_logging_time': 5.810181140899658}
I0208 22:10:22.234636 140250622109440 logging_writer.py:48] [30283] accumulated_eval_time=357.340464, accumulated_logging_time=5.810181, accumulated_submission_time=7079.652545, global_step=30283, preemption_count=0, score=7079.652545, test/loss=0.286300, test/num_examples=3581, test/ssim=0.743457, total_duration=7443.945029, train/loss=0.264772, train/ssim=0.750380, validation/loss=0.284914, validation/num_examples=3554, validation/ssim=0.726333
I0208 22:10:24.162134 140249942763264 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.10577689856290817, loss=0.17941053211688995
I0208 22:10:47.927754 140250622109440 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.09397488832473755, loss=0.25353434681892395
I0208 22:11:11.830930 140249942763264 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.12796953320503235, loss=0.21646913886070251
I0208 22:11:35.416557 140250622109440 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.07158424705266953, loss=0.3437509834766388
I0208 22:11:42.351949 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:11:43.723020 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:11:45.042870 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:11:46.362477 140466628462400 submission_runner.py:408] Time since start: 7528.09s, 	Step: 30631, 	{'train/ssim': 0.7510991777692523, 'train/loss': 0.2642929894583566, 'validation/ssim': 0.726567720789955, 'validation/loss': 0.28485447460168123, 'validation/num_examples': 3554, 'test/ssim': 0.7437173161084544, 'test/loss': 0.2862401225652751, 'test/num_examples': 3581, 'score': 7159.747346639633, 'total_duration': 7528.094771146774, 'accumulated_submission_time': 7159.747346639633, 'accumulated_eval_time': 361.350955247879, 'accumulated_logging_time': 5.84227180480957}
I0208 22:11:46.383788 140249942763264 logging_writer.py:48] [30631] accumulated_eval_time=361.350955, accumulated_logging_time=5.842272, accumulated_submission_time=7159.747347, global_step=30631, preemption_count=0, score=7159.747347, test/loss=0.286240, test/num_examples=3581, test/ssim=0.743717, total_duration=7528.094771, train/loss=0.264293, train/ssim=0.751099, validation/loss=0.284854, validation/num_examples=3554, validation/ssim=0.726568
I0208 22:12:00.549424 140250622109440 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.05460628122091293, loss=0.2855037748813629
I0208 22:12:24.479670 140249942763264 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.08154400438070297, loss=0.3230346739292145
I0208 22:12:48.107435 140250622109440 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.07558323442935944, loss=0.24775280058383942
I0208 22:13:06.558462 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:13:07.932734 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:13:09.253655 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:13:10.575170 140466628462400 submission_runner.py:408] Time since start: 7612.31s, 	Step: 30978, 	{'train/ssim': 0.7507302420479911, 'train/loss': 0.2645713601793562, 'validation/ssim': 0.7265148259443585, 'validation/loss': 0.2848851810899691, 'validation/num_examples': 3554, 'test/ssim': 0.7437042943660989, 'test/loss': 0.2862286007094736, 'test/num_examples': 3581, 'score': 7239.900948047638, 'total_duration': 7612.307431459427, 'accumulated_submission_time': 7239.900948047638, 'accumulated_eval_time': 365.36758971214294, 'accumulated_logging_time': 5.872438192367554}
I0208 22:13:10.597516 140249942763264 logging_writer.py:48] [30978] accumulated_eval_time=365.367590, accumulated_logging_time=5.872438, accumulated_submission_time=7239.900948, global_step=30978, preemption_count=0, score=7239.900948, test/loss=0.286229, test/num_examples=3581, test/ssim=0.743704, total_duration=7612.307431, train/loss=0.264571, train/ssim=0.750730, validation/loss=0.284885, validation/num_examples=3554, validation/ssim=0.726515
I0208 22:13:14.155953 140250622109440 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.08456189930438995, loss=0.2902037799358368
I0208 22:13:38.026753 140249942763264 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.08809457719326019, loss=0.2030148208141327
I0208 22:14:01.886887 140250622109440 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.10524255782365799, loss=0.19028882682323456
I0208 22:14:26.165810 140249942763264 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.0668022409081459, loss=0.3054417669773102
I0208 22:14:30.673034 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:14:32.046205 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:14:33.368071 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:14:34.688463 140466628462400 submission_runner.py:408] Time since start: 7696.42s, 	Step: 31320, 	{'train/ssim': 0.7506299700055804, 'train/loss': 0.26464121682303293, 'validation/ssim': 0.7264860429050014, 'validation/loss': 0.28487726403678076, 'validation/num_examples': 3554, 'test/ssim': 0.7436085743332868, 'test/loss': 0.2862563145223925, 'test/num_examples': 3581, 'score': 7319.6549961566925, 'total_duration': 7696.420757055283, 'accumulated_submission_time': 7319.6549961566925, 'accumulated_eval_time': 369.3829791545868, 'accumulated_logging_time': 6.204082012176514}
I0208 22:14:34.711009 140250622109440 logging_writer.py:48] [31320] accumulated_eval_time=369.382979, accumulated_logging_time=6.204082, accumulated_submission_time=7319.654996, global_step=31320, preemption_count=0, score=7319.654996, test/loss=0.286256, test/num_examples=3581, test/ssim=0.743609, total_duration=7696.420757, train/loss=0.264641, train/ssim=0.750630, validation/loss=0.284877, validation/num_examples=3554, validation/ssim=0.726486
I0208 22:14:51.975980 140249942763264 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.07304282486438751, loss=0.1893642544746399
I0208 22:15:16.156488 140250622109440 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.1482166200876236, loss=0.3262445032596588
I0208 22:15:39.948770 140249942763264 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.07054407894611359, loss=0.22440272569656372
I0208 22:15:54.857779 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:15:56.232475 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:15:57.554722 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:15:58.876194 140466628462400 submission_runner.py:408] Time since start: 7780.61s, 	Step: 31664, 	{'train/ssim': 0.7513968603951591, 'train/loss': 0.2642252445220947, 'validation/ssim': 0.72686193978176, 'validation/loss': 0.28489806132834483, 'validation/num_examples': 3554, 'test/ssim': 0.7439497985243297, 'test/loss': 0.28631262844483035, 'test/num_examples': 3581, 'score': 7399.781029224396, 'total_duration': 7780.608487844467, 'accumulated_submission_time': 7399.781029224396, 'accumulated_eval_time': 373.4013526439667, 'accumulated_logging_time': 6.235177278518677}
I0208 22:15:58.899842 140250622109440 logging_writer.py:48] [31664] accumulated_eval_time=373.401353, accumulated_logging_time=6.235177, accumulated_submission_time=7399.781029, global_step=31664, preemption_count=0, score=7399.781029, test/loss=0.286313, test/num_examples=3581, test/ssim=0.743950, total_duration=7780.608488, train/loss=0.264225, train/ssim=0.751397, validation/loss=0.284898, validation/num_examples=3554, validation/ssim=0.726862
I0208 22:16:05.591876 140249942763264 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.08837146311998367, loss=0.23005729913711548
I0208 22:16:29.176081 140250622109440 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.061752449721097946, loss=0.24420347809791565
I0208 22:16:53.135845 140249942763264 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.08571075648069382, loss=0.29804110527038574
I0208 22:17:17.022581 140250622109440 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.07760396599769592, loss=0.3038232922554016
I0208 22:17:19.030340 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:17:20.403340 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:17:21.726866 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:17:23.048724 140466628462400 submission_runner.py:408] Time since start: 7864.78s, 	Step: 32010, 	{'train/ssim': 0.7509576252528599, 'train/loss': 0.26443988936288015, 'validation/ssim': 0.7266498108425365, 'validation/loss': 0.28484056394423535, 'validation/num_examples': 3554, 'test/ssim': 0.7437827657035395, 'test/loss': 0.2862076704743787, 'test/num_examples': 3581, 'score': 7479.888315439224, 'total_duration': 7864.781018733978, 'accumulated_submission_time': 7479.888315439224, 'accumulated_eval_time': 377.4197075366974, 'accumulated_logging_time': 6.269732475280762}
I0208 22:17:23.071309 140249942763264 logging_writer.py:48] [32010] accumulated_eval_time=377.419708, accumulated_logging_time=6.269732, accumulated_submission_time=7479.888315, global_step=32010, preemption_count=0, score=7479.888315, test/loss=0.286208, test/num_examples=3581, test/ssim=0.743783, total_duration=7864.781019, train/loss=0.264440, train/ssim=0.750958, validation/loss=0.284841, validation/num_examples=3554, validation/ssim=0.726650
I0208 22:17:42.400465 140250622109440 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.0783776119351387, loss=0.3111271858215332
I0208 22:18:06.404543 140249942763264 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.053709253668785095, loss=0.21944451332092285
I0208 22:18:30.262408 140250622109440 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.0620497427880764, loss=0.2765026390552521
I0208 22:18:43.082541 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:18:44.455762 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:18:45.778226 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:18:47.101035 140466628462400 submission_runner.py:408] Time since start: 7948.83s, 	Step: 32355, 	{'train/ssim': 0.7508602823529925, 'train/loss': 0.26451633657727924, 'validation/ssim': 0.7266644427933314, 'validation/loss': 0.28487049761822064, 'validation/num_examples': 3554, 'test/ssim': 0.7437727437342921, 'test/loss': 0.28624475857826026, 'test/num_examples': 3581, 'score': 7559.8783304691315, 'total_duration': 7948.833317041397, 'accumulated_submission_time': 7559.8783304691315, 'accumulated_eval_time': 381.4381649494171, 'accumulated_logging_time': 6.301154613494873}
I0208 22:18:47.124254 140249942763264 logging_writer.py:48] [32355] accumulated_eval_time=381.438165, accumulated_logging_time=6.301155, accumulated_submission_time=7559.878330, global_step=32355, preemption_count=0, score=7559.878330, test/loss=0.286245, test/num_examples=3581, test/ssim=0.743773, total_duration=7948.833317, train/loss=0.264516, train/ssim=0.750860, validation/loss=0.284870, validation/num_examples=3554, validation/ssim=0.726664
I0208 22:18:55.943831 140250622109440 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.09993524849414825, loss=0.26049697399139404
I0208 22:19:20.113009 140249942763264 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.043521516025066376, loss=0.30552223324775696
I0208 22:19:44.208796 140250622109440 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.0899834856390953, loss=0.2685666084289551
I0208 22:20:07.313364 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:20:08.686801 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:20:10.008040 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:20:11.332229 140466628462400 submission_runner.py:408] Time since start: 8033.06s, 	Step: 32698, 	{'train/ssim': 0.751176289149693, 'train/loss': 0.2641677345548357, 'validation/ssim': 0.7266272790122046, 'validation/loss': 0.28480858660576114, 'validation/num_examples': 3554, 'test/ssim': 0.7437449276563809, 'test/loss': 0.28622594181967326, 'test/num_examples': 3581, 'score': 7640.045894861221, 'total_duration': 8033.064491033554, 'accumulated_submission_time': 7640.045894861221, 'accumulated_eval_time': 385.4569594860077, 'accumulated_logging_time': 6.333528757095337}
I0208 22:20:11.360207 140249942763264 logging_writer.py:48] [32698] accumulated_eval_time=385.456959, accumulated_logging_time=6.333529, accumulated_submission_time=7640.045895, global_step=32698, preemption_count=0, score=7640.045895, test/loss=0.286226, test/num_examples=3581, test/ssim=0.743745, total_duration=8033.064491, train/loss=0.264168, train/ssim=0.751176, validation/loss=0.284809, validation/num_examples=3554, validation/ssim=0.726627
I0208 22:20:11.598145 140250622109440 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.09139706194400787, loss=0.2602841854095459
I0208 22:20:33.958865 140249942763264 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.07749156653881073, loss=0.23072059452533722
I0208 22:20:57.730818 140250622109440 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.12323999404907227, loss=0.24610425531864166
I0208 22:21:21.773729 140249942763264 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.08081065118312836, loss=0.32204824686050415
I0208 22:21:31.351484 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:21:32.722830 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:21:34.043827 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:21:35.365160 140466628462400 submission_runner.py:408] Time since start: 8117.10s, 	Step: 33041, 	{'train/ssim': 0.7510192053658622, 'train/loss': 0.2642357519694737, 'validation/ssim': 0.726567720789955, 'validation/loss': 0.28475174182039603, 'validation/num_examples': 3554, 'test/ssim': 0.7437026581262217, 'test/loss': 0.286153435940118, 'test/num_examples': 3581, 'score': 7720.015320777893, 'total_duration': 8117.097451686859, 'accumulated_submission_time': 7720.015320777893, 'accumulated_eval_time': 389.47060203552246, 'accumulated_logging_time': 6.371289491653442}
I0208 22:21:35.388213 140250622109440 logging_writer.py:48] [33041] accumulated_eval_time=389.470602, accumulated_logging_time=6.371289, accumulated_submission_time=7720.015321, global_step=33041, preemption_count=0, score=7720.015321, test/loss=0.286153, test/num_examples=3581, test/ssim=0.743703, total_duration=8117.097452, train/loss=0.264236, train/ssim=0.751019, validation/loss=0.284752, validation/num_examples=3554, validation/ssim=0.726568
I0208 22:21:47.533143 140249942763264 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.09521529823541641, loss=0.2556164860725403
I0208 22:22:11.493264 140250622109440 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.04690280556678772, loss=0.3293590545654297
I0208 22:22:35.516340 140249942763264 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.07756197452545166, loss=0.19701139628887177
I0208 22:22:55.383516 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:22:56.755553 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:22:58.076427 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:22:59.397339 140466628462400 submission_runner.py:408] Time since start: 8201.13s, 	Step: 33384, 	{'train/ssim': 0.7508604867117745, 'train/loss': 0.26435419491359163, 'validation/ssim': 0.7265020487478897, 'validation/loss': 0.284828542388418, 'validation/num_examples': 3554, 'test/ssim': 0.7436151192927953, 'test/loss': 0.28619492143866937, 'test/num_examples': 3581, 'score': 7799.988336086273, 'total_duration': 8201.129628896713, 'accumulated_submission_time': 7799.988336086273, 'accumulated_eval_time': 393.484384059906, 'accumulated_logging_time': 6.404409885406494}
I0208 22:22:59.420322 140250622109440 logging_writer.py:48] [33384] accumulated_eval_time=393.484384, accumulated_logging_time=6.404410, accumulated_submission_time=7799.988336, global_step=33384, preemption_count=0, score=7799.988336, test/loss=0.286195, test/num_examples=3581, test/ssim=0.743615, total_duration=8201.129629, train/loss=0.264354, train/ssim=0.750860, validation/loss=0.284829, validation/num_examples=3554, validation/ssim=0.726502
I0208 22:23:01.290731 140249942763264 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.09229081124067307, loss=0.266327440738678
I0208 22:23:25.625360 140250622109440 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.06015226989984512, loss=0.2527131736278534
I0208 22:23:49.899605 140249942763264 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.08394826203584671, loss=0.28493252396583557
I0208 22:24:13.896416 140250622109440 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.06386474519968033, loss=0.24514104425907135
I0208 22:24:19.513741 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:24:20.885943 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:24:22.206166 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:24:23.529777 140466628462400 submission_runner.py:408] Time since start: 8285.26s, 	Step: 33725, 	{'train/ssim': 0.7511130741664341, 'train/loss': 0.26417667525155203, 'validation/ssim': 0.7266970040359454, 'validation/loss': 0.28475381983218734, 'validation/num_examples': 3554, 'test/ssim': 0.7437837883534627, 'test/loss': 0.2861725594936819, 'test/num_examples': 3581, 'score': 7880.060120820999, 'total_duration': 8285.262045621872, 'accumulated_submission_time': 7880.060120820999, 'accumulated_eval_time': 397.50036454200745, 'accumulated_logging_time': 6.436081647872925}
I0208 22:24:23.553510 140249942763264 logging_writer.py:48] [33725] accumulated_eval_time=397.500365, accumulated_logging_time=6.436082, accumulated_submission_time=7880.060121, global_step=33725, preemption_count=0, score=7880.060121, test/loss=0.286173, test/num_examples=3581, test/ssim=0.743784, total_duration=8285.262046, train/loss=0.264177, train/ssim=0.751113, validation/loss=0.284754, validation/num_examples=3554, validation/ssim=0.726697
I0208 22:24:39.713546 140250622109440 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.09230712056159973, loss=0.32656773924827576
I0208 22:25:03.683316 140249942763264 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.049024440348148346, loss=0.2134396880865097
I0208 22:25:27.481575 140250622109440 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.07322484999895096, loss=0.26201215386390686
I0208 22:25:43.653708 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:25:45.025064 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:25:46.347403 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:25:47.669815 140466628462400 submission_runner.py:408] Time since start: 8369.40s, 	Step: 34069, 	{'train/ssim': 0.7512414796011788, 'train/loss': 0.26408260209219797, 'validation/ssim': 0.7267279166080473, 'validation/loss': 0.28469503442424027, 'validation/num_examples': 3554, 'test/ssim': 0.7438623278675649, 'test/loss': 0.28607885067238553, 'test/num_examples': 3581, 'score': 7960.137799978256, 'total_duration': 8369.402106523514, 'accumulated_submission_time': 7960.137799978256, 'accumulated_eval_time': 401.5164318084717, 'accumulated_logging_time': 6.469133138656616}
I0208 22:25:47.693384 140249942763264 logging_writer.py:48] [34069] accumulated_eval_time=401.516432, accumulated_logging_time=6.469133, accumulated_submission_time=7960.137800, global_step=34069, preemption_count=0, score=7960.137800, test/loss=0.286079, test/num_examples=3581, test/ssim=0.743862, total_duration=8369.402107, train/loss=0.264083, train/ssim=0.751241, validation/loss=0.284695, validation/num_examples=3554, validation/ssim=0.726728
I0208 22:25:52.953702 140250622109440 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.06506332755088806, loss=0.22267954051494598
I0208 22:26:16.926378 140249942763264 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.0745488628745079, loss=0.23097015917301178
I0208 22:26:40.549000 140250622109440 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.05107288435101509, loss=0.24954137206077576
I0208 22:27:04.574410 140249942763264 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.08150892704725266, loss=0.1860991269350052
I0208 22:27:07.816975 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:27:09.190944 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:27:10.511492 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:27:11.834147 140466628462400 submission_runner.py:408] Time since start: 8453.57s, 	Step: 34415, 	{'train/ssim': 0.7512760162353516, 'train/loss': 0.2641456127166748, 'validation/ssim': 0.7268698396612971, 'validation/loss': 0.2846884912631454, 'validation/num_examples': 3554, 'test/ssim': 0.7440084304532603, 'test/loss': 0.2860408762719038, 'test/num_examples': 3581, 'score': 8040.238317012787, 'total_duration': 8453.566410779953, 'accumulated_submission_time': 8040.238317012787, 'accumulated_eval_time': 405.53353238105774, 'accumulated_logging_time': 6.502725839614868}
I0208 22:27:11.861486 140250622109440 logging_writer.py:48] [34415] accumulated_eval_time=405.533532, accumulated_logging_time=6.502726, accumulated_submission_time=8040.238317, global_step=34415, preemption_count=0, score=8040.238317, test/loss=0.286041, test/num_examples=3581, test/ssim=0.744008, total_duration=8453.566411, train/loss=0.264146, train/ssim=0.751276, validation/loss=0.284688, validation/num_examples=3554, validation/ssim=0.726870
I0208 22:27:30.024677 140249942763264 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.08046041429042816, loss=0.24794259667396545
I0208 22:27:54.287698 140250622109440 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.05749359354376793, loss=0.22366446256637573
I0208 22:28:18.301371 140249942763264 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.1133006364107132, loss=0.3958341181278229
I0208 22:28:32.042065 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:28:33.412273 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:28:34.733258 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:28:36.058573 140466628462400 submission_runner.py:408] Time since start: 8537.79s, 	Step: 34758, 	{'train/ssim': 0.7510401862008231, 'train/loss': 0.26416145052228657, 'validation/ssim': 0.726607563660664, 'validation/loss': 0.28470788031531374, 'validation/num_examples': 3554, 'test/ssim': 0.7437508590259355, 'test/loss': 0.28610533730539656, 'test/num_examples': 3581, 'score': 8120.395667791367, 'total_duration': 8537.790835618973, 'accumulated_submission_time': 8120.395667791367, 'accumulated_eval_time': 409.54997205734253, 'accumulated_logging_time': 6.540175437927246}
I0208 22:28:36.087449 140250622109440 logging_writer.py:48] [34758] accumulated_eval_time=409.549972, accumulated_logging_time=6.540175, accumulated_submission_time=8120.395668, global_step=34758, preemption_count=0, score=8120.395668, test/loss=0.286105, test/num_examples=3581, test/ssim=0.743751, total_duration=8537.790836, train/loss=0.264161, train/ssim=0.751040, validation/loss=0.284708, validation/num_examples=3554, validation/ssim=0.726608
I0208 22:28:44.072328 140249942763264 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.08699886500835419, loss=0.3398746848106384
I0208 22:29:07.971980 140250622109440 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.0855085700750351, loss=0.24511393904685974
I0208 22:29:32.046529 140249942763264 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.044556472450494766, loss=0.32412052154541016
I0208 22:29:55.991303 140250622109440 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.07313619554042816, loss=0.27984675765037537
I0208 22:29:56.124078 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:29:57.494317 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:29:58.817332 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:30:00.142894 140466628462400 submission_runner.py:408] Time since start: 8621.88s, 	Step: 35102, 	{'train/ssim': 0.7514004707336426, 'train/loss': 0.2640484060559954, 'validation/ssim': 0.726867778823157, 'validation/loss': 0.28468699715549384, 'validation/num_examples': 3554, 'test/ssim': 0.7439925452911198, 'test/loss': 0.2860836912153554, 'test/num_examples': 3581, 'score': 8200.408621549606, 'total_duration': 8621.87518954277, 'accumulated_submission_time': 8200.408621549606, 'accumulated_eval_time': 413.56875348091125, 'accumulated_logging_time': 6.579923152923584}
I0208 22:30:00.165995 140249942763264 logging_writer.py:48] [35102] accumulated_eval_time=413.568753, accumulated_logging_time=6.579923, accumulated_submission_time=8200.408622, global_step=35102, preemption_count=0, score=8200.408622, test/loss=0.286084, test/num_examples=3581, test/ssim=0.743993, total_duration=8621.875190, train/loss=0.264048, train/ssim=0.751400, validation/loss=0.284687, validation/num_examples=3554, validation/ssim=0.726868
I0208 22:30:21.664887 140250622109440 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.05799221992492676, loss=0.2532948851585388
I0208 22:30:45.485596 140249942763264 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.0639190599322319, loss=0.3022472560405731
I0208 22:31:09.457070 140250622109440 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.07287789136171341, loss=0.3088209927082062
I0208 22:31:20.168497 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:31:21.542800 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:31:22.865348 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:31:24.188675 140466628462400 submission_runner.py:408] Time since start: 8705.92s, 	Step: 35446, 	{'train/ssim': 0.7513203620910645, 'train/loss': 0.26405378750392366, 'validation/ssim': 0.7268525973155248, 'validation/loss': 0.2846417445846669, 'validation/num_examples': 3554, 'test/ssim': 0.7439716832326864, 'test/loss': 0.28602604784801733, 'test/num_examples': 3581, 'score': 8280.389010429382, 'total_duration': 8705.920965194702, 'accumulated_submission_time': 8280.389010429382, 'accumulated_eval_time': 417.58889985084534, 'accumulated_logging_time': 6.61214542388916}
I0208 22:31:24.212481 140249942763264 logging_writer.py:48] [35446] accumulated_eval_time=417.588900, accumulated_logging_time=6.612145, accumulated_submission_time=8280.389010, global_step=35446, preemption_count=0, score=8280.389010, test/loss=0.286026, test/num_examples=3581, test/ssim=0.743972, total_duration=8705.920965, train/loss=0.264054, train/ssim=0.751320, validation/loss=0.284642, validation/num_examples=3554, validation/ssim=0.726853
I0208 22:31:35.080055 140250622109440 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.07365206629037857, loss=0.2629133462905884
I0208 22:31:58.770196 140249942763264 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.052120763808488846, loss=0.19465722143650055
I0208 22:32:23.148142 140250622109440 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.06030389666557312, loss=0.30947980284690857
I0208 22:32:44.199105 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:32:45.573157 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:32:46.893342 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:32:48.216852 140466628462400 submission_runner.py:408] Time since start: 8789.95s, 	Step: 35790, 	{'train/ssim': 0.7514446122305733, 'train/loss': 0.26404803139822824, 'validation/ssim': 0.7269441672235509, 'validation/loss': 0.2846638985946733, 'validation/num_examples': 3554, 'test/ssim': 0.7440648125523597, 'test/loss': 0.2860469099064507, 'test/num_examples': 3581, 'score': 8360.353709697723, 'total_duration': 8789.949140787125, 'accumulated_submission_time': 8360.353709697723, 'accumulated_eval_time': 421.60661602020264, 'accumulated_logging_time': 6.645025968551636}
I0208 22:32:48.239993 140249942763264 logging_writer.py:48] [35790] accumulated_eval_time=421.606616, accumulated_logging_time=6.645026, accumulated_submission_time=8360.353710, global_step=35790, preemption_count=0, score=8360.353710, test/loss=0.286047, test/num_examples=3581, test/ssim=0.744065, total_duration=8789.949141, train/loss=0.264048, train/ssim=0.751445, validation/loss=0.284664, validation/num_examples=3554, validation/ssim=0.726944
I0208 22:32:49.058575 140250622109440 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.07486429810523987, loss=0.2291620820760727
I0208 22:33:12.763848 140249942763264 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.07645566016435623, loss=0.2897312641143799
I0208 22:33:36.454102 140250622109440 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.08537815511226654, loss=0.22342202067375183
I0208 22:34:00.380366 140249942763264 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.043525878340005875, loss=0.39614152908325195
I0208 22:34:08.359714 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:34:09.732286 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:34:11.056347 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:34:12.379677 140466628462400 submission_runner.py:408] Time since start: 8874.11s, 	Step: 36134, 	{'train/ssim': 0.7513912064688546, 'train/loss': 0.2640267610549927, 'validation/ssim': 0.7269162772140546, 'validation/loss': 0.28463406796259494, 'validation/num_examples': 3554, 'test/ssim': 0.7440346102912944, 'test/loss': 0.2860179007369624, 'test/num_examples': 3581, 'score': 8440.450272083282, 'total_duration': 8874.111963510513, 'accumulated_submission_time': 8440.450272083282, 'accumulated_eval_time': 425.62653613090515, 'accumulated_logging_time': 6.677982568740845}
I0208 22:34:12.403643 140250622109440 logging_writer.py:48] [36134] accumulated_eval_time=425.626536, accumulated_logging_time=6.677983, accumulated_submission_time=8440.450272, global_step=36134, preemption_count=0, score=8440.450272, test/loss=0.286018, test/num_examples=3581, test/ssim=0.744035, total_duration=8874.111964, train/loss=0.264027, train/ssim=0.751391, validation/loss=0.284634, validation/num_examples=3554, validation/ssim=0.726916
I0208 22:34:23.231770 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:34:24.604891 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:34:25.928529 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:34:27.249196 140466628462400 submission_runner.py:408] Time since start: 8888.98s, 	Step: 36189, 	{'train/ssim': 0.7513892991202218, 'train/loss': 0.2640261820384434, 'validation/ssim': 0.7269135294298678, 'validation/loss': 0.2846337244895716, 'validation/num_examples': 3554, 'test/ssim': 0.7440320877548171, 'test/loss': 0.2860175257653239, 'test/num_examples': 3581, 'score': 8451.264714956284, 'total_duration': 8888.98148393631, 'accumulated_submission_time': 8451.264714956284, 'accumulated_eval_time': 429.6439287662506, 'accumulated_logging_time': 6.712190389633179}
I0208 22:34:27.275828 140249942763264 logging_writer.py:48] [36189] accumulated_eval_time=429.643929, accumulated_logging_time=6.712190, accumulated_submission_time=8451.264715, global_step=36189, preemption_count=0, score=8451.264715, test/loss=0.286018, test/num_examples=3581, test/ssim=0.744032, total_duration=8888.981484, train/loss=0.264026, train/ssim=0.751389, validation/loss=0.284634, validation/num_examples=3554, validation/ssim=0.726914
I0208 22:34:27.298234 140250622109440 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8451.264715
I0208 22:34:27.399430 140466628462400 checkpoints.py:490] Saving checkpoint at step: 36189
I0208 22:34:27.881247 140466628462400 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3/checkpoint_36189
I0208 22:34:27.881981 140466628462400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_3/checkpoint_36189.
I0208 22:34:28.768089 140466628462400 submission_runner.py:583] Tuning trial 3/5
I0208 22:34:28.768378 140466628462400 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0208 22:34:28.774396 140466628462400 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 34.67232370376587, 'total_duration': 38.630457639694214, 'accumulated_submission_time': 34.67232370376587, 'accumulated_eval_time': 3.9580185413360596, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (343, {'train/ssim': 0.6874906676156181, 'train/loss': 0.32034478868756977, 'validation/ssim': 0.665604968653278, 'validation/loss': 0.3383400251037563, 'validation/num_examples': 3554, 'test/ssim': 0.6846410116980243, 'test/loss': 0.3396532303193068, 'test/num_examples': 3581, 'score': 114.82151770591736, 'total_duration': 122.82729887962341, 'accumulated_submission_time': 114.82151770591736, 'accumulated_eval_time': 7.97329568862915, 'accumulated_logging_time': 0.018859386444091797, 'global_step': 343, 'preemption_count': 0}), (683, {'train/ssim': 0.7154259000505719, 'train/loss': 0.2942925861903599, 'validation/ssim': 0.6941251137582654, 'validation/loss': 0.3114802629409644, 'validation/num_examples': 3554, 'test/ssim': 0.7119667630593759, 'test/loss': 0.31328897441575326, 'test/num_examples': 3581, 'score': 194.85300540924072, 'total_duration': 206.91001749038696, 'accumulated_submission_time': 194.85300540924072, 'accumulated_eval_time': 11.987972736358643, 'accumulated_logging_time': 0.04272103309631348, 'global_step': 683, 'preemption_count': 0}), (1021, {'train/ssim': 0.7261792591639927, 'train/loss': 0.28449693747929167, 'validation/ssim': 0.7047837686189856, 'validation/loss': 0.301730059879713, 'validation/num_examples': 3554, 'test/ssim': 0.722000731399225, 'test/loss': 0.30372324338740925, 'test/num_examples': 3581, 'score': 274.98014783859253, 'total_duration': 291.08116149902344, 'accumulated_submission_time': 274.98014783859253, 'accumulated_eval_time': 15.995911598205566, 'accumulated_logging_time': 0.0665290355682373, 'global_step': 1021, 'preemption_count': 0}), (1367, {'train/ssim': 0.7311660902840751, 'train/loss': 0.2801398549761091, 'validation/ssim': 0.7096444614562817, 'validation/loss': 0.29759728942081104, 'validation/num_examples': 3554, 'test/ssim': 0.7267269421076515, 'test/loss': 0.29945388448800964, 'test/num_examples': 3581, 'score': 355.20496368408203, 'total_duration': 375.3608241081238, 'accumulated_submission_time': 355.20496368408203, 'accumulated_eval_time': 20.014185190200806, 'accumulated_logging_time': 0.09003257751464844, 'global_step': 1367, 'preemption_count': 0}), (1712, {'train/ssim': 0.7326619284493583, 'train/loss': 0.27829464844294954, 'validation/ssim': 0.7117603926693514, 'validation/loss': 0.29559721165851854, 'validation/num_examples': 3554, 'test/ssim': 0.7288269878132854, 'test/loss': 0.29723896110766895, 'test/num_examples': 3581, 'score': 435.2983305454254, 'total_duration': 459.5098702907562, 'accumulated_submission_time': 435.2983305454254, 'accumulated_eval_time': 24.033470630645752, 'accumulated_logging_time': 0.11382746696472168, 'global_step': 1712, 'preemption_count': 0}), (2053, {'train/ssim': 0.7352352823529925, 'train/loss': 0.2767984867095947, 'validation/ssim': 0.714054586381542, 'validation/loss': 0.2942941437025183, 'validation/num_examples': 3554, 'test/ssim': 0.731076544937692, 'test/loss': 0.29598001087554104, 'test/num_examples': 3581, 'score': 515.3351848125458, 'total_duration': 543.5966114997864, 'accumulated_submission_time': 515.3351848125458, 'accumulated_eval_time': 28.046659469604492, 'accumulated_logging_time': 0.13770151138305664, 'global_step': 2053, 'preemption_count': 0}), (2399, {'train/ssim': 0.7378204890659877, 'train/loss': 0.27462734494890484, 'validation/ssim': 0.715780881796919, 'validation/loss': 0.2926793739778243, 'validation/num_examples': 3554, 'test/ssim': 0.7328256853663432, 'test/loss': 0.2943691327165073, 'test/num_examples': 3581, 'score': 595.3161046504974, 'total_duration': 627.6319966316223, 'accumulated_submission_time': 595.3161046504974, 'accumulated_eval_time': 32.06492805480957, 'accumulated_logging_time': 0.16156339645385742, 'global_step': 2399, 'preemption_count': 0}), (2745, {'train/ssim': 0.736846787588937, 'train/loss': 0.27468367985316683, 'validation/ssim': 0.7157350624956036, 'validation/loss': 0.2923017597359489, 'validation/num_examples': 3554, 'test/ssim': 0.7329012932839989, 'test/loss': 0.29392206425841244, 'test/num_examples': 3581, 'score': 675.4076058864594, 'total_duration': 711.7762885093689, 'accumulated_submission_time': 675.4076058864594, 'accumulated_eval_time': 36.081443786621094, 'accumulated_logging_time': 0.1853799819946289, 'global_step': 2745, 'preemption_count': 0}), (3089, {'train/ssim': 0.738483156476702, 'train/loss': 0.2738098076411656, 'validation/ssim': 0.7173665593565349, 'validation/loss': 0.2915166490991664, 'validation/num_examples': 3554, 'test/ssim': 0.7343056643352066, 'test/loss': 0.293090513517523, 'test/num_examples': 3581, 'score': 755.4829206466675, 'total_duration': 795.8983507156372, 'accumulated_submission_time': 755.4829206466675, 'accumulated_eval_time': 40.09206223487854, 'accumulated_logging_time': 0.2090139389038086, 'global_step': 3089, 'preemption_count': 0}), (3435, {'train/ssim': 0.7398324693952288, 'train/loss': 0.2729310819080898, 'validation/ssim': 0.7178401399611354, 'validation/loss': 0.29103674859093626, 'validation/num_examples': 3554, 'test/ssim': 0.7349787043379992, 'test/loss': 0.29263458209342713, 'test/num_examples': 3581, 'score': 835.5611155033112, 'total_duration': 880.0320289134979, 'accumulated_submission_time': 835.5611155033112, 'accumulated_eval_time': 44.11016654968262, 'accumulated_logging_time': 0.23378396034240723, 'global_step': 3435, 'preemption_count': 0}), (3781, {'train/ssim': 0.7399343763078962, 'train/loss': 0.27259365149906706, 'validation/ssim': 0.7179940845702026, 'validation/loss': 0.2906307978246342, 'validation/num_examples': 3554, 'test/ssim': 0.7351857568591176, 'test/loss': 0.2921319155678407, 'test/num_examples': 3581, 'score': 915.7322247028351, 'total_duration': 964.2566239833832, 'accumulated_submission_time': 915.7322247028351, 'accumulated_eval_time': 48.12693548202515, 'accumulated_logging_time': 0.25774526596069336, 'global_step': 3781, 'preemption_count': 0}), (4113, {'train/ssim': 0.7397107396806989, 'train/loss': 0.2726095233644758, 'validation/ssim': 0.7185598533342712, 'validation/loss': 0.2903784825416784, 'validation/num_examples': 3554, 'test/ssim': 0.7355518655316252, 'test/loss': 0.29191978388543705, 'test/num_examples': 3581, 'score': 992.5416581630707, 'total_duration': 1048.4469621181488, 'accumulated_submission_time': 992.5416581630707, 'accumulated_eval_time': 52.14394688606262, 'accumulated_logging_time': 3.6097893714904785, 'global_step': 4113, 'preemption_count': 0}), (4452, {'train/ssim': 0.7406341007777623, 'train/loss': 0.2726199116025652, 'validation/ssim': 0.7184141520777645, 'validation/loss': 0.2907874902178883, 'validation/num_examples': 3554, 'test/ssim': 0.7355363212527926, 'test/loss': 0.2924081333120986, 'test/num_examples': 3581, 'score': 1072.5993592739105, 'total_duration': 1132.556327342987, 'accumulated_submission_time': 1072.5993592739105, 'accumulated_eval_time': 56.158693075180054, 'accumulated_logging_time': 3.634568214416504, 'global_step': 4452, 'preemption_count': 0}), (4797, {'train/ssim': 0.7394133976527623, 'train/loss': 0.2729235887527466, 'validation/ssim': 0.717810807364941, 'validation/loss': 0.2907678435609524, 'validation/num_examples': 3554, 'test/ssim': 0.7350659022881179, 'test/loss': 0.29228633570624474, 'test/num_examples': 3581, 'score': 1152.6758415699005, 'total_duration': 1216.6884505748749, 'accumulated_submission_time': 1152.6758415699005, 'accumulated_eval_time': 60.17582702636719, 'accumulated_logging_time': 3.66079044342041, 'global_step': 4797, 'preemption_count': 0}), (5141, {'train/ssim': 0.7423439707074847, 'train/loss': 0.27140653133392334, 'validation/ssim': 0.720104863687922, 'validation/loss': 0.28983789035022156, 'validation/num_examples': 3554, 'test/ssim': 0.7372924838775831, 'test/loss': 0.2913546334495427, 'test/num_examples': 3581, 'score': 1232.8069953918457, 'total_duration': 1300.8768427371979, 'accumulated_submission_time': 1232.8069953918457, 'accumulated_eval_time': 64.19480657577515, 'accumulated_logging_time': 3.686720371246338, 'global_step': 5141, 'preemption_count': 0}), (5482, {'train/ssim': 0.7426614080156598, 'train/loss': 0.2708125114440918, 'validation/ssim': 0.7199558650903911, 'validation/loss': 0.28943049699722145, 'validation/num_examples': 3554, 'test/ssim': 0.7371058161782672, 'test/loss': 0.2909789459560877, 'test/num_examples': 3581, 'score': 1312.845635175705, 'total_duration': 1384.973824262619, 'accumulated_submission_time': 1312.845635175705, 'accumulated_eval_time': 68.21188974380493, 'accumulated_logging_time': 3.7150466442108154, 'global_step': 5482, 'preemption_count': 0}), (5826, {'train/ssim': 0.7421904972621373, 'train/loss': 0.2719070741108486, 'validation/ssim': 0.7206405442151449, 'validation/loss': 0.28988024057400114, 'validation/num_examples': 3554, 'test/ssim': 0.7378205802979265, 'test/loss': 0.2913603262007819, 'test/num_examples': 3581, 'score': 1392.8805315494537, 'total_duration': 1469.0639517307281, 'accumulated_submission_time': 1392.8805315494537, 'accumulated_eval_time': 72.22917580604553, 'accumulated_logging_time': 3.7401299476623535, 'global_step': 5826, 'preemption_count': 0}), (6170, {'train/ssim': 0.743617125919887, 'train/loss': 0.2700311115809849, 'validation/ssim': 0.7214869991338985, 'validation/loss': 0.2883799847552933, 'validation/num_examples': 3554, 'test/ssim': 0.7387264435999022, 'test/loss': 0.2897655377338732, 'test/num_examples': 3581, 'score': 1472.8445675373077, 'total_duration': 1553.0830590724945, 'accumulated_submission_time': 1472.8445675373077, 'accumulated_eval_time': 76.24688148498535, 'accumulated_logging_time': 3.7643887996673584, 'global_step': 6170, 'preemption_count': 0}), (6515, {'train/ssim': 0.7408600534711566, 'train/loss': 0.2711503676005772, 'validation/ssim': 0.7199719396278841, 'validation/loss': 0.2892438537563309, 'validation/num_examples': 3554, 'test/ssim': 0.736829496169017, 'test/loss': 0.29071564768919295, 'test/num_examples': 3581, 'score': 1552.9671349525452, 'total_duration': 1637.2661266326904, 'accumulated_submission_time': 1552.9671349525452, 'accumulated_eval_time': 80.26424646377563, 'accumulated_logging_time': 3.7941737174987793, 'global_step': 6515, 'preemption_count': 0}), (6858, {'train/ssim': 0.7428475788661412, 'train/loss': 0.2702873434339251, 'validation/ssim': 0.7205947249138295, 'validation/loss': 0.2885929380297728, 'validation/num_examples': 3554, 'test/ssim': 0.7378659177778554, 'test/loss': 0.2900368808468305, 'test/num_examples': 3581, 'score': 1633.011125087738, 'total_duration': 1721.365136384964, 'accumulated_submission_time': 1633.011125087738, 'accumulated_eval_time': 84.28073906898499, 'accumulated_logging_time': 3.8197827339172363, 'global_step': 6858, 'preemption_count': 0}), (7202, {'train/ssim': 0.7438455990382603, 'train/loss': 0.26998632294791086, 'validation/ssim': 0.7213912388549873, 'validation/loss': 0.2882636847895857, 'validation/num_examples': 3554, 'test/ssim': 0.7387140354475007, 'test/loss': 0.28963351362878736, 'test/num_examples': 3581, 'score': 1713.1123294830322, 'total_duration': 1805.5205924510956, 'accumulated_submission_time': 1713.1123294830322, 'accumulated_eval_time': 88.29626941680908, 'accumulated_logging_time': 3.8452749252319336, 'global_step': 7202, 'preemption_count': 0}), (7544, {'train/ssim': 0.7445081983293805, 'train/loss': 0.2692584310259138, 'validation/ssim': 0.7220048190639069, 'validation/loss': 0.2876641011063678, 'validation/num_examples': 3554, 'test/ssim': 0.7392936734239738, 'test/loss': 0.2890629090599693, 'test/num_examples': 3581, 'score': 1793.1978707313538, 'total_duration': 1889.664298772812, 'accumulated_submission_time': 1793.1978707313538, 'accumulated_eval_time': 92.31477165222168, 'accumulated_logging_time': 3.871781349182129, 'global_step': 7544, 'preemption_count': 0}), (7890, {'train/ssim': 0.7442601067679269, 'train/loss': 0.26919327463422504, 'validation/ssim': 0.7217778520900746, 'validation/loss': 0.2877252049572225, 'validation/num_examples': 3554, 'test/ssim': 0.7390526689254049, 'test/loss': 0.2891253588819464, 'test/num_examples': 3581, 'score': 1873.3463337421417, 'total_duration': 1973.8701612949371, 'accumulated_submission_time': 1873.3463337421417, 'accumulated_eval_time': 96.33357906341553, 'accumulated_logging_time': 3.897242546081543, 'global_step': 7890, 'preemption_count': 0}), (8235, {'train/ssim': 0.7455815587724958, 'train/loss': 0.268533672605242, 'validation/ssim': 0.72304437451639, 'validation/loss': 0.2871241099927019, 'validation/num_examples': 3554, 'test/ssim': 0.7402122175849972, 'test/loss': 0.2885202910107163, 'test/num_examples': 3581, 'score': 1953.4747865200043, 'total_duration': 2058.0535831451416, 'accumulated_submission_time': 1953.4747865200043, 'accumulated_eval_time': 100.34822511672974, 'accumulated_logging_time': 3.9240989685058594, 'global_step': 8235, 'preemption_count': 0}), (8579, {'train/ssim': 0.7400757244655064, 'train/loss': 0.272737979888916, 'validation/ssim': 0.7171354707064224, 'validation/loss': 0.29154141350415025, 'validation/num_examples': 3554, 'test/ssim': 0.7344478126745323, 'test/loss': 0.2928813134315659, 'test/num_examples': 3581, 'score': 2033.6733074188232, 'total_duration': 2142.3093214035034, 'accumulated_submission_time': 2033.6733074188232, 'accumulated_eval_time': 104.36516261100769, 'accumulated_logging_time': 3.9511842727661133, 'global_step': 8579, 'preemption_count': 0}), (8923, {'train/ssim': 0.7457260404314313, 'train/loss': 0.26832311494009836, 'validation/ssim': 0.7229087713667698, 'validation/loss': 0.28722660234287073, 'validation/num_examples': 3554, 'test/ssim': 0.7400754552019339, 'test/loss': 0.2886678253063041, 'test/num_examples': 3581, 'score': 2113.6891655921936, 'total_duration': 2226.3820304870605, 'accumulated_submission_time': 2113.6891655921936, 'accumulated_eval_time': 108.38202714920044, 'accumulated_logging_time': 3.977944850921631, 'global_step': 8923, 'preemption_count': 0}), (9269, {'train/ssim': 0.7454257011413574, 'train/loss': 0.2683753967285156, 'validation/ssim': 0.7227186933956458, 'validation/loss': 0.2870310974979776, 'validation/num_examples': 3554, 'test/ssim': 0.7400321630218515, 'test/loss': 0.2883772904631213, 'test/num_examples': 3581, 'score': 2193.8962202072144, 'total_duration': 2310.645069360733, 'accumulated_submission_time': 2193.8962202072144, 'accumulated_eval_time': 112.39886569976807, 'accumulated_logging_time': 4.004060506820679, 'global_step': 9269, 'preemption_count': 0}), (9611, {'train/ssim': 0.7463662964957101, 'train/loss': 0.26838016510009766, 'validation/ssim': 0.7238779148494654, 'validation/loss': 0.28694761637965144, 'validation/num_examples': 3554, 'test/ssim': 0.741056653714919, 'test/loss': 0.2883160337327213, 'test/num_examples': 3581, 'score': 2274.0123538970947, 'total_duration': 2394.818213224411, 'accumulated_submission_time': 2274.0123538970947, 'accumulated_eval_time': 116.41702151298523, 'accumulated_logging_time': 4.029884099960327, 'global_step': 9611, 'preemption_count': 0}), (9957, {'train/ssim': 0.7377515520368304, 'train/loss': 0.2757884774889265, 'validation/ssim': 0.7153397250457231, 'validation/loss': 0.2945271214542593, 'validation/num_examples': 3554, 'test/ssim': 0.7323646066043005, 'test/loss': 0.2962296397217956, 'test/num_examples': 3581, 'score': 2354.080169200897, 'total_duration': 2478.943204164505, 'accumulated_submission_time': 2354.080169200897, 'accumulated_eval_time': 120.43198204040527, 'accumulated_logging_time': 4.058996915817261, 'global_step': 9957, 'preemption_count': 0}), (10304, {'train/ssim': 0.7443478448050362, 'train/loss': 0.2687504972730364, 'validation/ssim': 0.722362031008195, 'validation/loss': 0.28724710768236494, 'validation/num_examples': 3554, 'test/ssim': 0.7394697737407497, 'test/loss': 0.2885957625750489, 'test/num_examples': 3581, 'score': 2434.170556306839, 'total_duration': 2563.088749408722, 'accumulated_submission_time': 2434.170556306839, 'accumulated_eval_time': 124.446848154068, 'accumulated_logging_time': 4.085970640182495, 'global_step': 10304, 'preemption_count': 0}), (10648, {'train/ssim': 0.7457329886300224, 'train/loss': 0.2680527653012957, 'validation/ssim': 0.723326915425401, 'validation/loss': 0.2866149799301843, 'validation/num_examples': 3554, 'test/ssim': 0.7404704026022759, 'test/loss': 0.2880172836018221, 'test/num_examples': 3581, 'score': 2514.290768623352, 'total_duration': 2647.2644975185394, 'accumulated_submission_time': 2514.290768623352, 'accumulated_eval_time': 128.46352362632751, 'accumulated_logging_time': 4.111758708953857, 'global_step': 10648, 'preemption_count': 0}), (10992, {'train/ssim': 0.746624265398298, 'train/loss': 0.26770830154418945, 'validation/ssim': 0.7237021253561128, 'validation/loss': 0.28674936375057153, 'validation/num_examples': 3554, 'test/ssim': 0.7408430562342921, 'test/loss': 0.28809575493926276, 'test/num_examples': 3581, 'score': 2594.4230313301086, 'total_duration': 2731.456456422806, 'accumulated_submission_time': 2594.4230313301086, 'accumulated_eval_time': 132.48388409614563, 'accumulated_logging_time': 4.137834072113037, 'global_step': 10992, 'preemption_count': 0}), (11339, {'train/ssim': 0.7461288315909249, 'train/loss': 0.2680037702832903, 'validation/ssim': 0.7235591031891883, 'validation/loss': 0.2868198787622661, 'validation/num_examples': 3554, 'test/ssim': 0.7407568127574351, 'test/loss': 0.2881150148461498, 'test/num_examples': 3581, 'score': 2674.5201218128204, 'total_duration': 2815.6145203113556, 'accumulated_submission_time': 2674.5201218128204, 'accumulated_eval_time': 136.50437474250793, 'accumulated_logging_time': 4.165032148361206, 'global_step': 11339, 'preemption_count': 0}), (11685, {'train/ssim': 0.7460990633283343, 'train/loss': 0.26770567893981934, 'validation/ssim': 0.7235476998848129, 'validation/loss': 0.28640745352947383, 'validation/num_examples': 3554, 'test/ssim': 0.7407115434541678, 'test/loss': 0.2877580077579587, 'test/num_examples': 3581, 'score': 2754.5981678962708, 'total_duration': 2899.753466129303, 'accumulated_submission_time': 2754.5981678962708, 'accumulated_eval_time': 140.52345037460327, 'accumulated_logging_time': 4.1935601234436035, 'global_step': 11685, 'preemption_count': 0}), (12028, {'train/ssim': 0.7467365946088519, 'train/loss': 0.2680112634386335, 'validation/ssim': 0.7236964237039252, 'validation/loss': 0.2872677504110685, 'validation/num_examples': 3554, 'test/ssim': 0.7407484952047263, 'test/loss': 0.2886041142160884, 'test/num_examples': 3581, 'score': 2834.6626737117767, 'total_duration': 2983.8777344226837, 'accumulated_submission_time': 2834.6626737117767, 'accumulated_eval_time': 144.54294848442078, 'accumulated_logging_time': 4.220882415771484, 'global_step': 12028, 'preemption_count': 0}), (12375, {'train/ssim': 0.7449325834001813, 'train/loss': 0.26895018986293245, 'validation/ssim': 0.7220681554894134, 'validation/loss': 0.28792215238881363, 'validation/num_examples': 3554, 'test/ssim': 0.7391867042420064, 'test/loss': 0.2893144127644164, 'test/num_examples': 3581, 'score': 2914.8029844760895, 'total_duration': 3068.0855479240417, 'accumulated_submission_time': 2914.8029844760895, 'accumulated_eval_time': 148.56185173988342, 'accumulated_logging_time': 4.256128311157227, 'global_step': 12375, 'preemption_count': 0}), (12722, {'train/ssim': 0.7473699024745396, 'train/loss': 0.2685403653553554, 'validation/ssim': 0.7248627207020258, 'validation/loss': 0.28711866594528174, 'validation/num_examples': 3554, 'test/ssim': 0.7420470560772131, 'test/loss': 0.2884791463954726, 'test/num_examples': 3581, 'score': 2994.950837135315, 'total_duration': 3152.291583776474, 'accumulated_submission_time': 2994.950837135315, 'accumulated_eval_time': 152.57717752456665, 'accumulated_logging_time': 4.285537481307983, 'global_step': 12722, 'preemption_count': 0}), (13065, {'train/ssim': 0.7461308070591518, 'train/loss': 0.26766501154218403, 'validation/ssim': 0.7229474464291995, 'validation/loss': 0.28673495505724184, 'validation/num_examples': 3554, 'test/ssim': 0.7402109222284278, 'test/loss': 0.28803115755244696, 'test/num_examples': 3581, 'score': 3075.084317445755, 'total_duration': 3236.4816160202026, 'accumulated_submission_time': 3075.084317445755, 'accumulated_eval_time': 156.59312415122986, 'accumulated_logging_time': 4.313032388687134, 'global_step': 13065, 'preemption_count': 0}), (13410, {'train/ssim': 0.7395822661263602, 'train/loss': 0.2715660844530378, 'validation/ssim': 0.7169801522052617, 'validation/loss': 0.2904655186057963, 'validation/num_examples': 3554, 'test/ssim': 0.7346096640690449, 'test/loss': 0.29159802413126573, 'test/num_examples': 3581, 'score': 3155.1144280433655, 'total_duration': 3320.5721111297607, 'accumulated_submission_time': 3155.1144280433655, 'accumulated_eval_time': 160.61153936386108, 'accumulated_logging_time': 4.341656446456909, 'global_step': 13410, 'preemption_count': 0}), (13754, {'train/ssim': 0.7470260347638812, 'train/loss': 0.26718645436423166, 'validation/ssim': 0.7241098965294387, 'validation/loss': 0.28617504250822134, 'validation/num_examples': 3554, 'test/ssim': 0.7413727888945127, 'test/loss': 0.28743277099404846, 'test/num_examples': 3581, 'score': 3235.2807846069336, 'total_duration': 3404.797929763794, 'accumulated_submission_time': 3235.2807846069336, 'accumulated_eval_time': 164.62888169288635, 'accumulated_logging_time': 4.370457410812378, 'global_step': 13754, 'preemption_count': 0}), (14098, {'train/ssim': 0.7473585265023368, 'train/loss': 0.2675982883998326, 'validation/ssim': 0.7245061957037845, 'validation/loss': 0.28663218792865436, 'validation/num_examples': 3554, 'test/ssim': 0.7416673802490575, 'test/loss': 0.2879964215433887, 'test/num_examples': 3581, 'score': 3315.593653202057, 'total_duration': 3489.1684036254883, 'accumulated_submission_time': 3315.593653202057, 'accumulated_eval_time': 168.64652037620544, 'accumulated_logging_time': 4.3972272872924805, 'global_step': 14098, 'preemption_count': 0}), (14442, {'train/ssim': 0.7471727643694196, 'train/loss': 0.26753958633967806, 'validation/ssim': 0.7243391991198298, 'validation/loss': 0.28657620182584764, 'validation/num_examples': 3554, 'test/ssim': 0.7415121419907149, 'test/loss': 0.2878864525883133, 'test/num_examples': 3581, 'score': 3395.570848941803, 'total_duration': 3573.2045345306396, 'accumulated_submission_time': 3395.570848941803, 'accumulated_eval_time': 172.66461992263794, 'accumulated_logging_time': 4.424889802932739, 'global_step': 14442, 'preemption_count': 0}), (14787, {'train/ssim': 0.748114994594029, 'train/loss': 0.26720190048217773, 'validation/ssim': 0.725114967290377, 'validation/loss': 0.2862941761263717, 'validation/num_examples': 3554, 'test/ssim': 0.7423192854867705, 'test/loss': 0.28757676010323585, 'test/num_examples': 3581, 'score': 3475.565026283264, 'total_duration': 3657.257560491562, 'accumulated_submission_time': 3475.565026283264, 'accumulated_eval_time': 176.68185997009277, 'accumulated_logging_time': 4.453326225280762, 'global_step': 14787, 'preemption_count': 0}), (15130, {'train/ssim': 0.7476911544799805, 'train/loss': 0.26705855982644217, 'validation/ssim': 0.7246122601733962, 'validation/loss': 0.28614526339709656, 'validation/num_examples': 3554, 'test/ssim': 0.7418366628996789, 'test/loss': 0.2874424179916574, 'test/num_examples': 3581, 'score': 3555.575869321823, 'total_duration': 3741.3271055221558, 'accumulated_submission_time': 3555.575869321823, 'accumulated_eval_time': 180.69870519638062, 'accumulated_logging_time': 4.48215651512146, 'global_step': 15130, 'preemption_count': 0}), (15475, {'train/ssim': 0.7482358387538365, 'train/loss': 0.2666790655681065, 'validation/ssim': 0.7250108262696962, 'validation/loss': 0.2860073761518711, 'validation/num_examples': 3554, 'test/ssim': 0.7421833412236456, 'test/loss': 0.2873672873106325, 'test/num_examples': 3581, 'score': 3635.6679487228394, 'total_duration': 3825.483948945999, 'accumulated_submission_time': 3635.6679487228394, 'accumulated_eval_time': 184.71685791015625, 'accumulated_logging_time': 4.515713930130005, 'global_step': 15475, 'preemption_count': 0}), (15821, {'train/ssim': 0.748002120426723, 'train/loss': 0.26682211671556744, 'validation/ssim': 0.7250834364668332, 'validation/loss': 0.2859135736691932, 'validation/num_examples': 3554, 'test/ssim': 0.7422936510620287, 'test/loss': 0.28716562074577634, 'test/num_examples': 3581, 'score': 3715.785654783249, 'total_duration': 3909.665248632431, 'accumulated_submission_time': 3715.785654783249, 'accumulated_eval_time': 188.73474383354187, 'accumulated_logging_time': 4.548308849334717, 'global_step': 15821, 'preemption_count': 0}), (16165, {'train/ssim': 0.7476752144949776, 'train/loss': 0.266790543283735, 'validation/ssim': 0.7244753518262873, 'validation/loss': 0.28586541875131893, 'validation/num_examples': 3554, 'test/ssim': 0.7417378067404357, 'test/loss': 0.28719422085529533, 'test/num_examples': 3581, 'score': 3795.99942445755, 'total_duration': 3993.9370975494385, 'accumulated_submission_time': 3795.99942445755, 'accumulated_eval_time': 192.75176310539246, 'accumulated_logging_time': 4.576169013977051, 'global_step': 16165, 'preemption_count': 0}), (16511, {'train/ssim': 0.7478722163609096, 'train/loss': 0.2664880411965506, 'validation/ssim': 0.7244973340997819, 'validation/loss': 0.28587290646322805, 'validation/num_examples': 3554, 'test/ssim': 0.7417247168214186, 'test/loss': 0.2872465123547019, 'test/num_examples': 3581, 'score': 3876.117094039917, 'total_duration': 4078.1082940101624, 'accumulated_submission_time': 3876.117094039917, 'accumulated_eval_time': 196.76408624649048, 'accumulated_logging_time': 4.604237794876099, 'global_step': 16511, 'preemption_count': 0}), (16856, {'train/ssim': 0.7484268460954938, 'train/loss': 0.26669842856270926, 'validation/ssim': 0.7252970079927546, 'validation/loss': 0.2859993045358223, 'validation/num_examples': 3554, 'test/ssim': 0.7425804702771572, 'test/loss': 0.28726229525185004, 'test/num_examples': 3581, 'score': 3956.22412109375, 'total_duration': 4162.271712303162, 'accumulated_submission_time': 3956.22412109375, 'accumulated_eval_time': 200.78008460998535, 'accumulated_logging_time': 4.63153338432312, 'global_step': 16856, 'preemption_count': 0}), (17201, {'train/ssim': 0.7476682662963867, 'train/loss': 0.26664754322596956, 'validation/ssim': 0.72458849184018, 'validation/loss': 0.2857119550044844, 'validation/num_examples': 3554, 'test/ssim': 0.7419232472598436, 'test/loss': 0.2869837254127688, 'test/num_examples': 3581, 'score': 4036.3730313777924, 'total_duration': 4246.418367147446, 'accumulated_submission_time': 4036.3730313777924, 'accumulated_eval_time': 204.73551487922668, 'accumulated_logging_time': 4.660937786102295, 'global_step': 17201, 'preemption_count': 0}), (17545, {'train/ssim': 0.7476886340550014, 'train/loss': 0.2663342441831316, 'validation/ssim': 0.7242569716780388, 'validation/loss': 0.2857955048174152, 'validation/num_examples': 3554, 'test/ssim': 0.7414532373551382, 'test/loss': 0.2871294189384948, 'test/num_examples': 3581, 'score': 4116.48851108551, 'total_duration': 4330.587821722031, 'accumulated_submission_time': 4116.48851108551, 'accumulated_eval_time': 208.74849247932434, 'accumulated_logging_time': 4.688414573669434, 'global_step': 17545, 'preemption_count': 0}), (17892, {'train/ssim': 0.7475626809256417, 'train/loss': 0.2668954474585397, 'validation/ssim': 0.7244492478765123, 'validation/loss': 0.28598833057272616, 'validation/num_examples': 3554, 'test/ssim': 0.7417253985880341, 'test/loss': 0.2873294151751431, 'test/num_examples': 3581, 'score': 4196.598222017288, 'total_duration': 4414.756689548492, 'accumulated_submission_time': 4196.598222017288, 'accumulated_eval_time': 212.76672649383545, 'accumulated_logging_time': 4.716022253036499, 'global_step': 17892, 'preemption_count': 0}), (18239, {'train/ssim': 0.7490292276654925, 'train/loss': 0.2666161571230207, 'validation/ssim': 0.7260106075460748, 'validation/loss': 0.2858516626567336, 'validation/num_examples': 3554, 'test/ssim': 0.7431509044043214, 'test/loss': 0.2871809945829552, 'test/num_examples': 3581, 'score': 4276.7827315330505, 'total_duration': 4499.0014860630035, 'accumulated_submission_time': 4276.7827315330505, 'accumulated_eval_time': 216.78552794456482, 'accumulated_logging_time': 4.743778467178345, 'global_step': 18239, 'preemption_count': 0}), (18583, {'train/ssim': 0.7473668370928083, 'train/loss': 0.26663053035736084, 'validation/ssim': 0.7240039007544317, 'validation/loss': 0.2860666939430044, 'validation/num_examples': 3554, 'test/ssim': 0.7413240425815065, 'test/loss': 0.28735808346132363, 'test/num_examples': 3581, 'score': 4356.798830032349, 'total_duration': 4583.0732300281525, 'accumulated_submission_time': 4356.798830032349, 'accumulated_eval_time': 220.7995901107788, 'accumulated_logging_time': 4.771770715713501, 'global_step': 18583, 'preemption_count': 0}), (18929, {'train/ssim': 0.7481992585318429, 'train/loss': 0.2665919235774449, 'validation/ssim': 0.7250225043524902, 'validation/loss': 0.2858412897714283, 'validation/num_examples': 3554, 'test/ssim': 0.742283833622766, 'test/loss': 0.2871458154255969, 'test/num_examples': 3581, 'score': 4436.8140461444855, 'total_duration': 4667.147452354431, 'accumulated_submission_time': 4436.8140461444855, 'accumulated_eval_time': 224.81593370437622, 'accumulated_logging_time': 4.800743103027344, 'global_step': 18929, 'preemption_count': 0}), (19275, {'train/ssim': 0.7471611840384347, 'train/loss': 0.2664503370012556, 'validation/ssim': 0.7239721638470737, 'validation/loss': 0.28568368717466236, 'validation/num_examples': 3554, 'test/ssim': 0.7412129827998464, 'test/loss': 0.28697411250349064, 'test/num_examples': 3581, 'score': 4517.03516125679, 'total_duration': 4751.42479133606, 'accumulated_submission_time': 4517.03516125679, 'accumulated_eval_time': 228.83026695251465, 'accumulated_logging_time': 4.829066753387451, 'global_step': 19275, 'preemption_count': 0}), (19618, {'train/ssim': 0.7494119235447475, 'train/loss': 0.2661271776471819, 'validation/ssim': 0.7260501756383653, 'validation/loss': 0.2857512483183561, 'validation/num_examples': 3554, 'test/ssim': 0.7430842958059899, 'test/loss': 0.28706308304680955, 'test/num_examples': 3581, 'score': 4597.184770107269, 'total_duration': 4835.632307052612, 'accumulated_submission_time': 4597.184770107269, 'accumulated_eval_time': 232.84253406524658, 'accumulated_logging_time': 4.8612940311431885, 'global_step': 19618, 'preemption_count': 0}), (19964, {'train/ssim': 0.7486386980329242, 'train/loss': 0.26623306955610004, 'validation/ssim': 0.7253936613015265, 'validation/loss': 0.28563850329844015, 'validation/num_examples': 3554, 'test/ssim': 0.7426314664199944, 'test/loss': 0.28695205735348017, 'test/num_examples': 3581, 'score': 4677.3404042720795, 'total_duration': 4919.846963167191, 'accumulated_submission_time': 4677.3404042720795, 'accumulated_eval_time': 236.85779643058777, 'accumulated_logging_time': 4.890937805175781, 'global_step': 19964, 'preemption_count': 0}), (20308, {'train/ssim': 0.7491888999938965, 'train/loss': 0.2662207569394793, 'validation/ssim': 0.7260768978395822, 'validation/loss': 0.28552568958391955, 'validation/num_examples': 3554, 'test/ssim': 0.7432166948827144, 'test/loss': 0.28683939542027365, 'test/num_examples': 3581, 'score': 4757.374995470047, 'total_duration': 5003.937238454819, 'accumulated_submission_time': 4757.374995470047, 'accumulated_eval_time': 240.87046551704407, 'accumulated_logging_time': 4.920657634735107, 'global_step': 20308, 'preemption_count': 0}), (20650, {'train/ssim': 0.7485660825456891, 'train/loss': 0.2663572515760149, 'validation/ssim': 0.7249621217949845, 'validation/loss': 0.28597709900486246, 'validation/num_examples': 3554, 'test/ssim': 0.7420767811016475, 'test/loss': 0.28731312095303335, 'test/num_examples': 3581, 'score': 4837.548028469086, 'total_duration': 5088.170040607452, 'accumulated_submission_time': 4837.548028469086, 'accumulated_eval_time': 244.88773012161255, 'accumulated_logging_time': 4.949784517288208, 'global_step': 20650, 'preemption_count': 0}), (20995, {'train/ssim': 0.7492354256766183, 'train/loss': 0.2659975971494402, 'validation/ssim': 0.7259607352630838, 'validation/loss': 0.28547178149290414, 'validation/num_examples': 3554, 'test/ssim': 0.743107612224239, 'test/loss': 0.2868216013116099, 'test/num_examples': 3581, 'score': 4917.593822479248, 'total_duration': 5172.273324012756, 'accumulated_submission_time': 4917.593822479248, 'accumulated_eval_time': 248.90308475494385, 'accumulated_logging_time': 4.978290319442749, 'global_step': 20995, 'preemption_count': 0}), (21341, {'train/ssim': 0.748748915536063, 'train/loss': 0.26592990330287386, 'validation/ssim': 0.7255290583673326, 'validation/loss': 0.28535144571917204, 'validation/num_examples': 3554, 'test/ssim': 0.7427538435274714, 'test/loss': 0.2865837329394722, 'test/num_examples': 3581, 'score': 4997.784978628159, 'total_duration': 5256.526384115219, 'accumulated_submission_time': 4997.784978628159, 'accumulated_eval_time': 252.92223858833313, 'accumulated_logging_time': 5.0073583126068115, 'global_step': 21341, 'preemption_count': 0}), (21680, {'train/ssim': 0.7451433454241071, 'train/loss': 0.2684741360800607, 'validation/ssim': 0.7219432686981219, 'validation/loss': 0.2879481876439839, 'validation/num_examples': 3554, 'test/ssim': 0.7392589715032463, 'test/loss': 0.28925070167420064, 'test/num_examples': 3581, 'score': 5077.8388476371765, 'total_duration': 5340.641524076462, 'accumulated_submission_time': 5077.8388476371765, 'accumulated_eval_time': 256.93958377838135, 'accumulated_logging_time': 5.038073301315308, 'global_step': 21680, 'preemption_count': 0}), (22026, {'train/ssim': 0.7494405337742397, 'train/loss': 0.2656904969896589, 'validation/ssim': 0.7258220408562536, 'validation/loss': 0.28542017467114517, 'validation/num_examples': 3554, 'test/ssim': 0.7429517603759425, 'test/loss': 0.2867683894272724, 'test/num_examples': 3581, 'score': 5157.941499471664, 'total_duration': 5424.806901931763, 'accumulated_submission_time': 5157.941499471664, 'accumulated_eval_time': 260.9596357345581, 'accumulated_logging_time': 5.067148923873901, 'global_step': 22026, 'preemption_count': 0}), (22371, {'train/ssim': 0.74909394127982, 'train/loss': 0.2657301425933838, 'validation/ssim': 0.7256988714300788, 'validation/loss': 0.28520481708550227, 'validation/num_examples': 3554, 'test/ssim': 0.7429030140629364, 'test/loss': 0.2864998074691078, 'test/num_examples': 3581, 'score': 5238.024378061295, 'total_duration': 5508.9515812397, 'accumulated_submission_time': 5238.024378061295, 'accumulated_eval_time': 264.9744710922241, 'accumulated_logging_time': 5.100812196731567, 'global_step': 22371, 'preemption_count': 0}), (22713, {'train/ssim': 0.7492767742701939, 'train/loss': 0.2658064535685948, 'validation/ssim': 0.7258655245410102, 'validation/loss': 0.2852625892480304, 'validation/num_examples': 3554, 'test/ssim': 0.7430842276293284, 'test/loss': 0.28655578050823793, 'test/num_examples': 3581, 'score': 5318.00970864296, 'total_duration': 5592.997215270996, 'accumulated_submission_time': 5318.00970864296, 'accumulated_eval_time': 268.993115901947, 'accumulated_logging_time': 5.129384994506836, 'global_step': 22713, 'preemption_count': 0}), (23058, {'train/ssim': 0.7493971415928432, 'train/loss': 0.2653361899512155, 'validation/ssim': 0.7256113545037282, 'validation/loss': 0.28526276098454206, 'validation/num_examples': 3554, 'test/ssim': 0.7427997945973541, 'test/loss': 0.28663002489266265, 'test/num_examples': 3581, 'score': 5398.11927318573, 'total_duration': 5677.161759853363, 'accumulated_submission_time': 5398.11927318573, 'accumulated_eval_time': 273.005410194397, 'accumulated_logging_time': 5.15982985496521, 'global_step': 23058, 'preemption_count': 0}), (23402, {'train/ssim': 0.7490113803318569, 'train/loss': 0.2655630792890276, 'validation/ssim': 0.725430275525816, 'validation/loss': 0.2852217503055536, 'validation/num_examples': 3554, 'test/ssim': 0.7426350116063949, 'test/loss': 0.2865171584294715, 'test/num_examples': 3581, 'score': 5478.105720996857, 'total_duration': 5761.20668721199, 'accumulated_submission_time': 5478.105720996857, 'accumulated_eval_time': 277.02224564552307, 'accumulated_logging_time': 5.189005136489868, 'global_step': 23402, 'preemption_count': 0}), (23744, {'train/ssim': 0.7494708469935826, 'train/loss': 0.2656279632023403, 'validation/ssim': 0.7260391845016179, 'validation/loss': 0.2851841915304498, 'validation/num_examples': 3554, 'test/ssim': 0.7431993780106814, 'test/loss': 0.28651470406965585, 'test/num_examples': 3581, 'score': 5558.272310495377, 'total_duration': 5845.430538654327, 'accumulated_submission_time': 5558.272310495377, 'accumulated_eval_time': 281.0366368293762, 'accumulated_logging_time': 5.219642877578735, 'global_step': 23744, 'preemption_count': 0}), (24088, {'train/ssim': 0.7504288128444127, 'train/loss': 0.2651689904076712, 'validation/ssim': 0.7265264353325478, 'validation/loss': 0.2852026016845016, 'validation/num_examples': 3554, 'test/ssim': 0.7436515256300614, 'test/loss': 0.28659266408213485, 'test/num_examples': 3581, 'score': 5638.279019832611, 'total_duration': 5929.496938467026, 'accumulated_submission_time': 5638.279019832611, 'accumulated_eval_time': 285.0529205799103, 'accumulated_logging_time': 5.249758005142212, 'global_step': 24088, 'preemption_count': 0}), (24433, {'train/ssim': 0.7496530669076102, 'train/loss': 0.2654334136417934, 'validation/ssim': 0.7260332767656162, 'validation/loss': 0.2851277073917593, 'validation/num_examples': 3554, 'test/ssim': 0.7432730088051522, 'test/loss': 0.2864014285464954, 'test/num_examples': 3581, 'score': 5718.319184303284, 'total_duration': 6013.598551034927, 'accumulated_submission_time': 5718.319184303284, 'accumulated_eval_time': 289.0705211162567, 'accumulated_logging_time': 5.280286550521851, 'global_step': 24433, 'preemption_count': 0}), (24780, {'train/ssim': 0.7496503421238491, 'train/loss': 0.2656197888510568, 'validation/ssim': 0.7260538851470174, 'validation/loss': 0.28528658083871167, 'validation/num_examples': 3554, 'test/ssim': 0.7432156722327912, 'test/loss': 0.28662112783833077, 'test/num_examples': 3581, 'score': 5798.420118570328, 'total_duration': 6097.761975288391, 'accumulated_submission_time': 5798.420118570328, 'accumulated_eval_time': 293.0866525173187, 'accumulated_logging_time': 5.3132641315460205, 'global_step': 24780, 'preemption_count': 0}), (25123, {'train/ssim': 0.7507190023149762, 'train/loss': 0.2650500876562936, 'validation/ssim': 0.7268040302300225, 'validation/loss': 0.2852178862340409, 'validation/num_examples': 3554, 'test/ssim': 0.7439480259311295, 'test/loss': 0.28658727812587265, 'test/num_examples': 3581, 'score': 5878.403662443161, 'total_duration': 6181.804616928101, 'accumulated_submission_time': 5878.403662443161, 'accumulated_eval_time': 297.10226798057556, 'accumulated_logging_time': 5.3443520069122314, 'global_step': 25123, 'preemption_count': 0}), (25467, {'train/ssim': 0.7501741136823382, 'train/loss': 0.2652744735990252, 'validation/ssim': 0.7264499782375492, 'validation/loss': 0.28510332080710116, 'validation/num_examples': 3554, 'test/ssim': 0.7436492076235688, 'test/loss': 0.28641683647200505, 'test/num_examples': 3581, 'score': 5958.376376628876, 'total_duration': 6265.838335990906, 'accumulated_submission_time': 5958.376376628876, 'accumulated_eval_time': 301.12024998664856, 'accumulated_logging_time': 5.3743064403533936, 'global_step': 25467, 'preemption_count': 0}), (25810, {'train/ssim': 0.7493463924952916, 'train/loss': 0.26540415627615793, 'validation/ssim': 0.7256698823069077, 'validation/loss': 0.28520301385212965, 'validation/num_examples': 3554, 'test/ssim': 0.7428756070449944, 'test/loss': 0.28646970747303474, 'test/num_examples': 3581, 'score': 6038.365174293518, 'total_duration': 6349.887370347977, 'accumulated_submission_time': 6038.365174293518, 'accumulated_eval_time': 305.1376292705536, 'accumulated_logging_time': 5.405126094818115, 'global_step': 25810, 'preemption_count': 0}), (26151, {'train/ssim': 0.7501864433288574, 'train/loss': 0.2650456428527832, 'validation/ssim': 0.7261618730655599, 'validation/loss': 0.2852682737265669, 'validation/num_examples': 3554, 'test/ssim': 0.7432468289671181, 'test/loss': 0.2866675561448443, 'test/num_examples': 3581, 'score': 6118.489009618759, 'total_duration': 6434.069468021393, 'accumulated_submission_time': 6118.489009618759, 'accumulated_eval_time': 309.15387773513794, 'accumulated_logging_time': 5.434753894805908, 'global_step': 26151, 'preemption_count': 0}), (26495, {'train/ssim': 0.7501932552882603, 'train/loss': 0.2651315076010568, 'validation/ssim': 0.726330243541608, 'validation/loss': 0.28513608813352914, 'validation/num_examples': 3554, 'test/ssim': 0.7435073319908894, 'test/loss': 0.2864623443935877, 'test/num_examples': 3581, 'score': 6198.512864589691, 'total_duration': 6518.152428388596, 'accumulated_submission_time': 6198.512864589691, 'accumulated_eval_time': 313.1702241897583, 'accumulated_logging_time': 5.465415954589844, 'global_step': 26495, 'preemption_count': 0}), (26840, {'train/ssim': 0.7490963935852051, 'train/loss': 0.26524414334978375, 'validation/ssim': 0.7254626993792206, 'validation/loss': 0.2850785735757685, 'validation/num_examples': 3554, 'test/ssim': 0.7426230806906241, 'test/loss': 0.2863978151834334, 'test/num_examples': 3581, 'score': 6278.578718662262, 'total_duration': 6602.2792291641235, 'accumulated_submission_time': 6278.578718662262, 'accumulated_eval_time': 317.18662691116333, 'accumulated_logging_time': 5.4974143505096436, 'global_step': 26840, 'preemption_count': 0}), (27183, {'train/ssim': 0.7498324257986886, 'train/loss': 0.2650856801441738, 'validation/ssim': 0.7258750043964547, 'validation/loss': 0.2851935168230339, 'validation/num_examples': 3554, 'test/ssim': 0.7430782962597738, 'test/loss': 0.2865224762090722, 'test/num_examples': 3581, 'score': 6358.797013282776, 'total_duration': 6686.558983802795, 'accumulated_submission_time': 6358.797013282776, 'accumulated_eval_time': 321.2055685520172, 'accumulated_logging_time': 5.527190208435059, 'global_step': 27183, 'preemption_count': 0}), (27528, {'train/ssim': 0.7499326297215053, 'train/loss': 0.26494300365448, 'validation/ssim': 0.7259978990442107, 'validation/loss': 0.28501042852793507, 'validation/num_examples': 3554, 'test/ssim': 0.7431881970381876, 'test/loss': 0.28637132855042235, 'test/num_examples': 3581, 'score': 6438.806653022766, 'total_duration': 6770.626757621765, 'accumulated_submission_time': 6438.806653022766, 'accumulated_eval_time': 325.2188792228699, 'accumulated_logging_time': 5.559579610824585, 'global_step': 27528, 'preemption_count': 0}), (27873, {'train/ssim': 0.7503581728254046, 'train/loss': 0.26502556460244314, 'validation/ssim': 0.726517230255522, 'validation/loss': 0.2850092435460045, 'validation/num_examples': 3554, 'test/ssim': 0.7436978175832519, 'test/loss': 0.2863230253857163, 'test/num_examples': 3581, 'score': 6519.011382341385, 'total_duration': 6854.8912081718445, 'accumulated_submission_time': 6519.011382341385, 'accumulated_eval_time': 329.2352783679962, 'accumulated_logging_time': 5.590218782424927, 'global_step': 27873, 'preemption_count': 0}), (28216, {'train/ssim': 0.7501605578831264, 'train/loss': 0.26524795804704937, 'validation/ssim': 0.7263499588931486, 'validation/loss': 0.2852860828028278, 'validation/num_examples': 3554, 'test/ssim': 0.7434523816016825, 'test/loss': 0.2867345056264835, 'test/num_examples': 3581, 'score': 6599.230717420578, 'total_duration': 6939.170467376709, 'accumulated_submission_time': 6599.230717420578, 'accumulated_eval_time': 333.2514762878418, 'accumulated_logging_time': 5.620994567871094, 'global_step': 28216, 'preemption_count': 0}), (28561, {'train/ssim': 0.7503539494105748, 'train/loss': 0.26469622339521137, 'validation/ssim': 0.7262106462348762, 'validation/loss': 0.28498805126046356, 'validation/num_examples': 3554, 'test/ssim': 0.7433470486595923, 'test/loss': 0.28637858936487715, 'test/num_examples': 3581, 'score': 6679.461097002029, 'total_duration': 7023.457095623016, 'accumulated_submission_time': 6679.461097002029, 'accumulated_eval_time': 337.26547598838806, 'accumulated_logging_time': 5.651025295257568, 'global_step': 28561, 'preemption_count': 0}), (28905, {'train/ssim': 0.7502357619149345, 'train/loss': 0.2648711545126779, 'validation/ssim': 0.7262302241972074, 'validation/loss': 0.2849589934426878, 'validation/num_examples': 3554, 'test/ssim': 0.743408953068277, 'test/loss': 0.2863066288986142, 'test/num_examples': 3581, 'score': 6759.423446655273, 'total_duration': 7107.479385375977, 'accumulated_submission_time': 6759.423446655273, 'accumulated_eval_time': 341.2815098762512, 'accumulated_logging_time': 5.682204484939575, 'global_step': 28905, 'preemption_count': 0}), (29248, {'train/ssim': 0.750530515398298, 'train/loss': 0.264979498726981, 'validation/ssim': 0.7264658466912282, 'validation/loss': 0.2850998860768676, 'validation/num_examples': 3554, 'test/ssim': 0.7435973933607931, 'test/loss': 0.28650553430867776, 'test/num_examples': 3581, 'score': 6839.43584895134, 'total_duration': 7191.550079584122, 'accumulated_submission_time': 6839.43584895134, 'accumulated_eval_time': 345.2969605922699, 'accumulated_logging_time': 5.712467908859253, 'global_step': 29248, 'preemption_count': 0}), (29595, {'train/ssim': 0.7509183202471051, 'train/loss': 0.2644538879394531, 'validation/ssim': 0.7266162191808525, 'validation/loss': 0.2848655859539867, 'validation/num_examples': 3554, 'test/ssim': 0.7437091349090686, 'test/loss': 0.28625068994781483, 'test/num_examples': 3581, 'score': 6919.53741979599, 'total_duration': 7275.713355302811, 'accumulated_submission_time': 6919.53741979599, 'accumulated_eval_time': 349.3138077259064, 'accumulated_logging_time': 5.7450034618377686, 'global_step': 29595, 'preemption_count': 0}), (29941, {'train/ssim': 0.7506739071437291, 'train/loss': 0.2646848814828055, 'validation/ssim': 0.7265805666810284, 'validation/loss': 0.2849207305478862, 'validation/num_examples': 3554, 'test/ssim': 0.7437569949254748, 'test/loss': 0.2862475197330529, 'test/num_examples': 3581, 'score': 6999.530682325363, 'total_duration': 7359.7621948719025, 'accumulated_submission_time': 6999.530682325363, 'accumulated_eval_time': 353.32518696784973, 'accumulated_logging_time': 5.7767322063446045, 'global_step': 29941, 'preemption_count': 0}), (30283, {'train/ssim': 0.7503796986171177, 'train/loss': 0.26477156366620747, 'validation/ssim': 0.7263325104635622, 'validation/loss': 0.2849135519616981, 'validation/num_examples': 3554, 'test/ssim': 0.7434573584979755, 'test/loss': 0.28630018620409803, 'test/num_examples': 3581, 'score': 7079.652544736862, 'total_duration': 7443.945029020309, 'accumulated_submission_time': 7079.652544736862, 'accumulated_eval_time': 357.34046387672424, 'accumulated_logging_time': 5.810181140899658, 'global_step': 30283, 'preemption_count': 0}), (30631, {'train/ssim': 0.7510991777692523, 'train/loss': 0.2642929894583566, 'validation/ssim': 0.726567720789955, 'validation/loss': 0.28485447460168123, 'validation/num_examples': 3554, 'test/ssim': 0.7437173161084544, 'test/loss': 0.2862401225652751, 'test/num_examples': 3581, 'score': 7159.747346639633, 'total_duration': 7528.094771146774, 'accumulated_submission_time': 7159.747346639633, 'accumulated_eval_time': 361.350955247879, 'accumulated_logging_time': 5.84227180480957, 'global_step': 30631, 'preemption_count': 0}), (30978, {'train/ssim': 0.7507302420479911, 'train/loss': 0.2645713601793562, 'validation/ssim': 0.7265148259443585, 'validation/loss': 0.2848851810899691, 'validation/num_examples': 3554, 'test/ssim': 0.7437042943660989, 'test/loss': 0.2862286007094736, 'test/num_examples': 3581, 'score': 7239.900948047638, 'total_duration': 7612.307431459427, 'accumulated_submission_time': 7239.900948047638, 'accumulated_eval_time': 365.36758971214294, 'accumulated_logging_time': 5.872438192367554, 'global_step': 30978, 'preemption_count': 0}), (31320, {'train/ssim': 0.7506299700055804, 'train/loss': 0.26464121682303293, 'validation/ssim': 0.7264860429050014, 'validation/loss': 0.28487726403678076, 'validation/num_examples': 3554, 'test/ssim': 0.7436085743332868, 'test/loss': 0.2862563145223925, 'test/num_examples': 3581, 'score': 7319.6549961566925, 'total_duration': 7696.420757055283, 'accumulated_submission_time': 7319.6549961566925, 'accumulated_eval_time': 369.3829791545868, 'accumulated_logging_time': 6.204082012176514, 'global_step': 31320, 'preemption_count': 0}), (31664, {'train/ssim': 0.7513968603951591, 'train/loss': 0.2642252445220947, 'validation/ssim': 0.72686193978176, 'validation/loss': 0.28489806132834483, 'validation/num_examples': 3554, 'test/ssim': 0.7439497985243297, 'test/loss': 0.28631262844483035, 'test/num_examples': 3581, 'score': 7399.781029224396, 'total_duration': 7780.608487844467, 'accumulated_submission_time': 7399.781029224396, 'accumulated_eval_time': 373.4013526439667, 'accumulated_logging_time': 6.235177278518677, 'global_step': 31664, 'preemption_count': 0}), (32010, {'train/ssim': 0.7509576252528599, 'train/loss': 0.26443988936288015, 'validation/ssim': 0.7266498108425365, 'validation/loss': 0.28484056394423535, 'validation/num_examples': 3554, 'test/ssim': 0.7437827657035395, 'test/loss': 0.2862076704743787, 'test/num_examples': 3581, 'score': 7479.888315439224, 'total_duration': 7864.781018733978, 'accumulated_submission_time': 7479.888315439224, 'accumulated_eval_time': 377.4197075366974, 'accumulated_logging_time': 6.269732475280762, 'global_step': 32010, 'preemption_count': 0}), (32355, {'train/ssim': 0.7508602823529925, 'train/loss': 0.26451633657727924, 'validation/ssim': 0.7266644427933314, 'validation/loss': 0.28487049761822064, 'validation/num_examples': 3554, 'test/ssim': 0.7437727437342921, 'test/loss': 0.28624475857826026, 'test/num_examples': 3581, 'score': 7559.8783304691315, 'total_duration': 7948.833317041397, 'accumulated_submission_time': 7559.8783304691315, 'accumulated_eval_time': 381.4381649494171, 'accumulated_logging_time': 6.301154613494873, 'global_step': 32355, 'preemption_count': 0}), (32698, {'train/ssim': 0.751176289149693, 'train/loss': 0.2641677345548357, 'validation/ssim': 0.7266272790122046, 'validation/loss': 0.28480858660576114, 'validation/num_examples': 3554, 'test/ssim': 0.7437449276563809, 'test/loss': 0.28622594181967326, 'test/num_examples': 3581, 'score': 7640.045894861221, 'total_duration': 8033.064491033554, 'accumulated_submission_time': 7640.045894861221, 'accumulated_eval_time': 385.4569594860077, 'accumulated_logging_time': 6.333528757095337, 'global_step': 32698, 'preemption_count': 0}), (33041, {'train/ssim': 0.7510192053658622, 'train/loss': 0.2642357519694737, 'validation/ssim': 0.726567720789955, 'validation/loss': 0.28475174182039603, 'validation/num_examples': 3554, 'test/ssim': 0.7437026581262217, 'test/loss': 0.286153435940118, 'test/num_examples': 3581, 'score': 7720.015320777893, 'total_duration': 8117.097451686859, 'accumulated_submission_time': 7720.015320777893, 'accumulated_eval_time': 389.47060203552246, 'accumulated_logging_time': 6.371289491653442, 'global_step': 33041, 'preemption_count': 0}), (33384, {'train/ssim': 0.7508604867117745, 'train/loss': 0.26435419491359163, 'validation/ssim': 0.7265020487478897, 'validation/loss': 0.284828542388418, 'validation/num_examples': 3554, 'test/ssim': 0.7436151192927953, 'test/loss': 0.28619492143866937, 'test/num_examples': 3581, 'score': 7799.988336086273, 'total_duration': 8201.129628896713, 'accumulated_submission_time': 7799.988336086273, 'accumulated_eval_time': 393.484384059906, 'accumulated_logging_time': 6.404409885406494, 'global_step': 33384, 'preemption_count': 0}), (33725, {'train/ssim': 0.7511130741664341, 'train/loss': 0.26417667525155203, 'validation/ssim': 0.7266970040359454, 'validation/loss': 0.28475381983218734, 'validation/num_examples': 3554, 'test/ssim': 0.7437837883534627, 'test/loss': 0.2861725594936819, 'test/num_examples': 3581, 'score': 7880.060120820999, 'total_duration': 8285.262045621872, 'accumulated_submission_time': 7880.060120820999, 'accumulated_eval_time': 397.50036454200745, 'accumulated_logging_time': 6.436081647872925, 'global_step': 33725, 'preemption_count': 0}), (34069, {'train/ssim': 0.7512414796011788, 'train/loss': 0.26408260209219797, 'validation/ssim': 0.7267279166080473, 'validation/loss': 0.28469503442424027, 'validation/num_examples': 3554, 'test/ssim': 0.7438623278675649, 'test/loss': 0.28607885067238553, 'test/num_examples': 3581, 'score': 7960.137799978256, 'total_duration': 8369.402106523514, 'accumulated_submission_time': 7960.137799978256, 'accumulated_eval_time': 401.5164318084717, 'accumulated_logging_time': 6.469133138656616, 'global_step': 34069, 'preemption_count': 0}), (34415, {'train/ssim': 0.7512760162353516, 'train/loss': 0.2641456127166748, 'validation/ssim': 0.7268698396612971, 'validation/loss': 0.2846884912631454, 'validation/num_examples': 3554, 'test/ssim': 0.7440084304532603, 'test/loss': 0.2860408762719038, 'test/num_examples': 3581, 'score': 8040.238317012787, 'total_duration': 8453.566410779953, 'accumulated_submission_time': 8040.238317012787, 'accumulated_eval_time': 405.53353238105774, 'accumulated_logging_time': 6.502725839614868, 'global_step': 34415, 'preemption_count': 0}), (34758, {'train/ssim': 0.7510401862008231, 'train/loss': 0.26416145052228657, 'validation/ssim': 0.726607563660664, 'validation/loss': 0.28470788031531374, 'validation/num_examples': 3554, 'test/ssim': 0.7437508590259355, 'test/loss': 0.28610533730539656, 'test/num_examples': 3581, 'score': 8120.395667791367, 'total_duration': 8537.790835618973, 'accumulated_submission_time': 8120.395667791367, 'accumulated_eval_time': 409.54997205734253, 'accumulated_logging_time': 6.540175437927246, 'global_step': 34758, 'preemption_count': 0}), (35102, {'train/ssim': 0.7514004707336426, 'train/loss': 0.2640484060559954, 'validation/ssim': 0.726867778823157, 'validation/loss': 0.28468699715549384, 'validation/num_examples': 3554, 'test/ssim': 0.7439925452911198, 'test/loss': 0.2860836912153554, 'test/num_examples': 3581, 'score': 8200.408621549606, 'total_duration': 8621.87518954277, 'accumulated_submission_time': 8200.408621549606, 'accumulated_eval_time': 413.56875348091125, 'accumulated_logging_time': 6.579923152923584, 'global_step': 35102, 'preemption_count': 0}), (35446, {'train/ssim': 0.7513203620910645, 'train/loss': 0.26405378750392366, 'validation/ssim': 0.7268525973155248, 'validation/loss': 0.2846417445846669, 'validation/num_examples': 3554, 'test/ssim': 0.7439716832326864, 'test/loss': 0.28602604784801733, 'test/num_examples': 3581, 'score': 8280.389010429382, 'total_duration': 8705.920965194702, 'accumulated_submission_time': 8280.389010429382, 'accumulated_eval_time': 417.58889985084534, 'accumulated_logging_time': 6.61214542388916, 'global_step': 35446, 'preemption_count': 0}), (35790, {'train/ssim': 0.7514446122305733, 'train/loss': 0.26404803139822824, 'validation/ssim': 0.7269441672235509, 'validation/loss': 0.2846638985946733, 'validation/num_examples': 3554, 'test/ssim': 0.7440648125523597, 'test/loss': 0.2860469099064507, 'test/num_examples': 3581, 'score': 8360.353709697723, 'total_duration': 8789.949140787125, 'accumulated_submission_time': 8360.353709697723, 'accumulated_eval_time': 421.60661602020264, 'accumulated_logging_time': 6.645025968551636, 'global_step': 35790, 'preemption_count': 0}), (36134, {'train/ssim': 0.7513912064688546, 'train/loss': 0.2640267610549927, 'validation/ssim': 0.7269162772140546, 'validation/loss': 0.28463406796259494, 'validation/num_examples': 3554, 'test/ssim': 0.7440346102912944, 'test/loss': 0.2860179007369624, 'test/num_examples': 3581, 'score': 8440.450272083282, 'total_duration': 8874.111963510513, 'accumulated_submission_time': 8440.450272083282, 'accumulated_eval_time': 425.62653613090515, 'accumulated_logging_time': 6.677982568740845, 'global_step': 36134, 'preemption_count': 0}), (36189, {'train/ssim': 0.7513892991202218, 'train/loss': 0.2640261820384434, 'validation/ssim': 0.7269135294298678, 'validation/loss': 0.2846337244895716, 'validation/num_examples': 3554, 'test/ssim': 0.7440320877548171, 'test/loss': 0.2860175257653239, 'test/num_examples': 3581, 'score': 8451.264714956284, 'total_duration': 8888.98148393631, 'accumulated_submission_time': 8451.264714956284, 'accumulated_eval_time': 429.6439287662506, 'accumulated_logging_time': 6.712190389633179, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0208 22:34:28.774632 140466628462400 submission_runner.py:586] Timing: 8451.264714956284
I0208 22:34:28.774688 140466628462400 submission_runner.py:588] Total number of evals: 107
I0208 22:34:28.774736 140466628462400 submission_runner.py:589] ====================
I0208 22:34:28.774787 140466628462400 submission_runner.py:542] Using RNG seed 1572671891
I0208 22:34:28.776560 140466628462400 submission_runner.py:551] --- Tuning run 4/5 ---
I0208 22:34:28.776690 140466628462400 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4.
I0208 22:34:28.777013 140466628462400 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4/hparams.json.
I0208 22:34:28.777958 140466628462400 submission_runner.py:206] Initializing dataset.
I0208 22:34:29.114224 140466628462400 submission_runner.py:213] Initializing model.
I0208 22:34:31.715788 140466628462400 submission_runner.py:255] Initializing optimizer.
I0208 22:34:31.784279 140466628462400 submission_runner.py:262] Initializing metrics bundle.
I0208 22:34:31.784424 140466628462400 submission_runner.py:280] Initializing checkpoint and logger.
I0208 22:34:31.785083 140466628462400 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4 with prefix checkpoint_
I0208 22:34:31.785215 140466628462400 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4/meta_data_0.json.
I0208 22:34:31.785430 140466628462400 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0208 22:34:31.785534 140466628462400 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0208 22:34:36.540382 140466628462400 logger_utils.py:220] Unable to record git information. Continuing without it.
I0208 22:34:41.270228 140466628462400 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4/flags_0.json.
I0208 22:34:41.273567 140466628462400 submission_runner.py:314] Starting training loop.
I0208 22:35:11.651325 140250672465664 logging_writer.py:48] [0] global_step=0, grad_norm=4.160696983337402, loss=0.8857511878013611
I0208 22:35:11.657519 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:35:12.981194 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:35:14.299911 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:35:15.616908 140466628462400 submission_runner.py:408] Time since start: 34.34s, 	Step: 1, 	{'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 30.383830070495605, 'total_duration': 34.343270778656006, 'accumulated_submission_time': 30.383830070495605, 'accumulated_eval_time': 3.9593241214752197, 'accumulated_logging_time': 0}
I0208 22:35:15.626253 140250680858368 logging_writer.py:48] [1] accumulated_eval_time=3.959324, accumulated_logging_time=0, accumulated_submission_time=30.383830, global_step=1, preemption_count=0, score=30.383830, test/loss=0.894958, test/num_examples=3581, test/ssim=0.283672, total_duration=34.343271, train/loss=0.892833, train/ssim=0.265677, validation/loss=0.895667, validation/num_examples=3554, validation/ssim=0.261322
I0208 22:35:37.528921 140250672465664 logging_writer.py:48] [100] global_step=100, grad_norm=0.5909863114356995, loss=0.24547427892684937
I0208 22:36:01.421139 140250680858368 logging_writer.py:48] [200] global_step=200, grad_norm=0.7926095128059387, loss=0.2555074095726013
I0208 22:36:25.478463 140250672465664 logging_writer.py:48] [300] global_step=300, grad_norm=0.35765621066093445, loss=0.29698601365089417
I0208 22:36:35.766265 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:36:37.139010 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:36:38.459015 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:36:39.781919 140466628462400 submission_runner.py:408] Time since start: 118.51s, 	Step: 344, 	{'train/ssim': 0.714498588017055, 'train/loss': 0.2980813298906599, 'validation/ssim': 0.6943832680826182, 'validation/loss': 0.3143779387551878, 'validation/num_examples': 3554, 'test/ssim': 0.7118314323862049, 'test/loss': 0.3160043485801801, 'test/num_examples': 3581, 'score': 110.5013530254364, 'total_duration': 118.50828313827515, 'accumulated_submission_time': 110.5013530254364, 'accumulated_eval_time': 7.9749369621276855, 'accumulated_logging_time': 0.01961350440979004}
I0208 22:36:39.796139 140250680858368 logging_writer.py:48] [344] accumulated_eval_time=7.974937, accumulated_logging_time=0.019614, accumulated_submission_time=110.501353, global_step=344, preemption_count=0, score=110.501353, test/loss=0.316004, test/num_examples=3581, test/ssim=0.711831, total_duration=118.508283, train/loss=0.298081, train/ssim=0.714499, validation/loss=0.314378, validation/num_examples=3554, validation/ssim=0.694383
I0208 22:36:51.115140 140250672465664 logging_writer.py:48] [400] global_step=400, grad_norm=0.29695644974708557, loss=0.2838609516620636
I0208 22:37:15.210497 140250680858368 logging_writer.py:48] [500] global_step=500, grad_norm=0.21928945183753967, loss=0.2802581787109375
I0208 22:37:39.659785 140250672465664 logging_writer.py:48] [600] global_step=600, grad_norm=0.2697354853153229, loss=0.27077609300613403
I0208 22:37:59.976123 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:38:01.347070 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:38:02.668409 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:38:03.991282 140466628462400 submission_runner.py:408] Time since start: 202.72s, 	Step: 686, 	{'train/ssim': 0.7243420055934361, 'train/loss': 0.2890401227133615, 'validation/ssim': 0.7042416994935284, 'validation/loss': 0.30667016368000843, 'validation/num_examples': 3554, 'test/ssim': 0.7214672490226194, 'test/loss': 0.3079342089761938, 'test/num_examples': 3581, 'score': 190.65867400169373, 'total_duration': 202.71763038635254, 'accumulated_submission_time': 190.65867400169373, 'accumulated_eval_time': 11.9900643825531, 'accumulated_logging_time': 0.04378843307495117}
I0208 22:38:04.005932 140250680858368 logging_writer.py:48] [686] accumulated_eval_time=11.990064, accumulated_logging_time=0.043788, accumulated_submission_time=190.658674, global_step=686, preemption_count=0, score=190.658674, test/loss=0.307934, test/num_examples=3581, test/ssim=0.721467, total_duration=202.717630, train/loss=0.289040, train/ssim=0.724342, validation/loss=0.306670, validation/num_examples=3554, validation/ssim=0.704242
I0208 22:38:05.336282 140250672465664 logging_writer.py:48] [700] global_step=700, grad_norm=0.1369701474905014, loss=0.2361033409833908
I0208 22:38:29.300408 140250680858368 logging_writer.py:48] [800] global_step=800, grad_norm=0.21198950707912445, loss=0.34579354524612427
I0208 22:38:53.553045 140250672465664 logging_writer.py:48] [900] global_step=900, grad_norm=0.11316706985235214, loss=0.3536968231201172
I0208 22:39:17.883779 140250680858368 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.20282471179962158, loss=0.276533305644989
I0208 22:39:24.143903 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:39:25.518949 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:39:26.840468 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:39:28.162197 140466628462400 submission_runner.py:408] Time since start: 286.89s, 	Step: 1028, 	{'train/ssim': 0.7297190938677106, 'train/loss': 0.2809634378978184, 'validation/ssim': 0.7084653185671075, 'validation/loss': 0.2987067072862444, 'validation/num_examples': 3554, 'test/ssim': 0.7258220332789375, 'test/loss': 0.30014066208810386, 'test/num_examples': 3581, 'score': 270.77397561073303, 'total_duration': 286.888560295105, 'accumulated_submission_time': 270.77397561073303, 'accumulated_eval_time': 16.00831699371338, 'accumulated_logging_time': 0.06842851638793945}
I0208 22:39:28.176786 140250672465664 logging_writer.py:48] [1028] accumulated_eval_time=16.008317, accumulated_logging_time=0.068429, accumulated_submission_time=270.773976, global_step=1028, preemption_count=0, score=270.773976, test/loss=0.300141, test/num_examples=3581, test/ssim=0.725822, total_duration=286.888560, train/loss=0.280963, train/ssim=0.729719, validation/loss=0.298707, validation/num_examples=3554, validation/ssim=0.708465
I0208 22:39:43.480301 140250680858368 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.185904860496521, loss=0.2670013904571533
I0208 22:40:07.504917 140250672465664 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.17391140758991241, loss=0.2702938914299011
I0208 22:40:30.901035 140250680858368 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.290695458650589, loss=0.2950056493282318
I0208 22:40:48.197215 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:40:49.569656 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:40:50.892860 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:40:52.215202 140466628462400 submission_runner.py:408] Time since start: 370.94s, 	Step: 1375, 	{'train/ssim': 0.7327919006347656, 'train/loss': 0.27697156156812397, 'validation/ssim': 0.7112662036833497, 'validation/loss': 0.29444090972539744, 'validation/num_examples': 3554, 'test/ssim': 0.728854599361212, 'test/loss': 0.29598590815676484, 'test/num_examples': 3581, 'score': 350.7723970413208, 'total_duration': 370.9412474632263, 'accumulated_submission_time': 350.7723970413208, 'accumulated_eval_time': 20.025943994522095, 'accumulated_logging_time': 0.09221529960632324}
I0208 22:40:52.229893 140250672465664 logging_writer.py:48] [1375] accumulated_eval_time=20.025944, accumulated_logging_time=0.092215, accumulated_submission_time=350.772397, global_step=1375, preemption_count=0, score=350.772397, test/loss=0.295986, test/num_examples=3581, test/ssim=0.728855, total_duration=370.941247, train/loss=0.276972, train/ssim=0.732792, validation/loss=0.294441, validation/num_examples=3554, validation/ssim=0.711266
I0208 22:40:56.189095 140250680858368 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.13724593818187714, loss=0.29032692313194275
I0208 22:41:19.965280 140250672465664 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.09734281897544861, loss=0.27498695254325867
I0208 22:41:43.678162 140250680858368 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.1554095596075058, loss=0.2487393021583557
I0208 22:42:07.622219 140250672465664 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.0921071395277977, loss=0.40882816910743713
I0208 22:42:12.300422 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:42:13.673100 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:42:14.996951 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:42:16.319592 140466628462400 submission_runner.py:408] Time since start: 455.05s, 	Step: 1721, 	{'train/ssim': 0.7358476775033134, 'train/loss': 0.27680504322052, 'validation/ssim': 0.7154141213025816, 'validation/loss': 0.29407511095552546, 'validation/num_examples': 3554, 'test/ssim': 0.7323106788650168, 'test/loss': 0.29586608767409595, 'test/num_examples': 3581, 'score': 430.8206250667572, 'total_duration': 455.04565238952637, 'accumulated_submission_time': 430.8206250667572, 'accumulated_eval_time': 24.044773817062378, 'accumulated_logging_time': 0.11644697189331055}
I0208 22:42:16.334304 140250680858368 logging_writer.py:48] [1721] accumulated_eval_time=24.044774, accumulated_logging_time=0.116447, accumulated_submission_time=430.820625, global_step=1721, preemption_count=0, score=430.820625, test/loss=0.295866, test/num_examples=3581, test/ssim=0.732311, total_duration=455.045652, train/loss=0.276805, train/ssim=0.735848, validation/loss=0.294075, validation/num_examples=3554, validation/ssim=0.715414
I0208 22:42:33.177569 140250672465664 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.2043771594762802, loss=0.2589693069458008
I0208 22:42:56.772484 140250680858368 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.36033377051353455, loss=0.3162814676761627
I0208 22:43:20.663822 140250672465664 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.33095788955688477, loss=0.276245653629303
I0208 22:43:36.452227 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:43:37.825082 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:43:39.148718 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:43:40.469166 140466628462400 submission_runner.py:408] Time since start: 539.20s, 	Step: 2066, 	{'train/ssim': 0.7291966165815081, 'train/loss': 0.27790061065128874, 'validation/ssim': 0.7088859356315067, 'validation/loss': 0.2951964816821715, 'validation/num_examples': 3554, 'test/ssim': 0.7263692191645141, 'test/loss': 0.2966501874585486, 'test/num_examples': 3581, 'score': 510.91701436042786, 'total_duration': 539.1955320835114, 'accumulated_submission_time': 510.91701436042786, 'accumulated_eval_time': 28.061689853668213, 'accumulated_logging_time': 0.13985133171081543}
I0208 22:43:40.484085 140250680858368 logging_writer.py:48] [2066] accumulated_eval_time=28.061690, accumulated_logging_time=0.139851, accumulated_submission_time=510.917014, global_step=2066, preemption_count=0, score=510.917014, test/loss=0.296650, test/num_examples=3581, test/ssim=0.726369, total_duration=539.195532, train/loss=0.277901, train/ssim=0.729197, validation/loss=0.295196, validation/num_examples=3554, validation/ssim=0.708886
I0208 22:43:46.384361 140250672465664 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.19061784446239471, loss=0.3138633966445923
I0208 22:44:10.373123 140250680858368 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.15518008172512054, loss=0.2809334397315979
I0208 22:44:34.249785 140250672465664 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.13613355159759521, loss=0.27774569392204285
I0208 22:44:57.901549 140250680858368 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.20346660912036896, loss=0.3373495042324066
I0208 22:45:00.607060 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:45:01.980246 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:45:03.301414 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:45:04.625054 140466628462400 submission_runner.py:408] Time since start: 623.35s, 	Step: 2413, 	{'train/ssim': 0.7348235675266811, 'train/loss': 0.275118316922869, 'validation/ssim': 0.7122574668287492, 'validation/loss': 0.29325087874138295, 'validation/num_examples': 3554, 'test/ssim': 0.7297532359370636, 'test/loss': 0.2949290335494624, 'test/num_examples': 3581, 'score': 591.0181603431702, 'total_duration': 623.3513972759247, 'accumulated_submission_time': 591.0181603431702, 'accumulated_eval_time': 32.079628467559814, 'accumulated_logging_time': 0.1638176441192627}
I0208 22:45:04.643121 140250672465664 logging_writer.py:48] [2413] accumulated_eval_time=32.079628, accumulated_logging_time=0.163818, accumulated_submission_time=591.018160, global_step=2413, preemption_count=0, score=591.018160, test/loss=0.294929, test/num_examples=3581, test/ssim=0.729753, total_duration=623.351397, train/loss=0.275118, train/ssim=0.734824, validation/loss=0.293251, validation/num_examples=3554, validation/ssim=0.712257
I0208 22:45:23.091516 140250680858368 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.11383269727230072, loss=0.30091601610183716
I0208 22:45:46.294112 140250672465664 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.22648923099040985, loss=0.24881477653980255
I0208 22:46:10.254441 140250680858368 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.09893739968538284, loss=0.30047354102134705
I0208 22:46:24.862703 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:46:26.235785 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:46:27.557585 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:46:28.880801 140466628462400 submission_runner.py:408] Time since start: 707.61s, 	Step: 2763, 	{'train/ssim': 0.7348286764962333, 'train/loss': 0.2760927677154541, 'validation/ssim': 0.714132005201006, 'validation/loss': 0.2936104263022299, 'validation/num_examples': 3554, 'test/ssim': 0.7313912484073932, 'test/loss': 0.29503474146319114, 'test/num_examples': 3581, 'score': 671.2152290344238, 'total_duration': 707.6071050167084, 'accumulated_submission_time': 671.2152290344238, 'accumulated_eval_time': 36.097635984420776, 'accumulated_logging_time': 0.1916062831878662}
I0208 22:46:28.898311 140250672465664 logging_writer.py:48] [2763] accumulated_eval_time=36.097636, accumulated_logging_time=0.191606, accumulated_submission_time=671.215229, global_step=2763, preemption_count=0, score=671.215229, test/loss=0.295035, test/num_examples=3581, test/ssim=0.731391, total_duration=707.607105, train/loss=0.276093, train/ssim=0.734829, validation/loss=0.293610, validation/num_examples=3554, validation/ssim=0.714132
I0208 22:46:35.570221 140250680858368 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.16045786440372467, loss=0.23834145069122314
I0208 22:46:59.064426 140250672465664 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.14489492774009705, loss=0.25266411900520325
I0208 22:47:23.080280 140250680858368 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.1685999631881714, loss=0.2645011842250824
I0208 22:47:46.721707 140250672465664 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.05965646356344223, loss=0.2861216068267822
I0208 22:47:49.094711 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:47:50.468153 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:47:51.788812 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:47:53.110193 140466628462400 submission_runner.py:408] Time since start: 791.84s, 	Step: 3110, 	{'train/ssim': 0.7333554540361676, 'train/loss': 0.2742685760770525, 'validation/ssim': 0.7119192145953503, 'validation/loss': 0.2919274084877954, 'validation/num_examples': 3554, 'test/ssim': 0.7293849456113864, 'test/loss': 0.2933647200502653, 'test/num_examples': 3581, 'score': 751.3892691135406, 'total_duration': 791.8365585803986, 'accumulated_submission_time': 751.3892691135406, 'accumulated_eval_time': 40.113075733184814, 'accumulated_logging_time': 0.21895051002502441}
I0208 22:47:53.125219 140250680858368 logging_writer.py:48] [3110] accumulated_eval_time=40.113076, accumulated_logging_time=0.218951, accumulated_submission_time=751.389269, global_step=3110, preemption_count=0, score=751.389269, test/loss=0.293365, test/num_examples=3581, test/ssim=0.729385, total_duration=791.836559, train/loss=0.274269, train/ssim=0.733355, validation/loss=0.291927, validation/num_examples=3554, validation/ssim=0.711919
I0208 22:48:12.285854 140250672465664 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.23811423778533936, loss=0.2676088213920593
I0208 22:48:36.257468 140250680858368 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.10677934437990189, loss=0.2627077102661133
I0208 22:48:59.958446 140250672465664 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.13500194251537323, loss=0.28628209233283997
I0208 22:49:13.128346 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:49:14.502684 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:49:15.824048 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:49:17.144256 140466628462400 submission_runner.py:408] Time since start: 875.87s, 	Step: 3457, 	{'train/ssim': 0.7428291184561593, 'train/loss': 0.27256126063210623, 'validation/ssim': 0.7211998556863745, 'validation/loss': 0.2903749791168402, 'validation/num_examples': 3554, 'test/ssim': 0.7382981578120636, 'test/loss': 0.29195196326968725, 'test/num_examples': 3581, 'score': 831.370644569397, 'total_duration': 875.8706209659576, 'accumulated_submission_time': 831.370644569397, 'accumulated_eval_time': 44.12899589538574, 'accumulated_logging_time': 0.2428901195526123}
I0208 22:49:17.162830 140250680858368 logging_writer.py:48] [3457] accumulated_eval_time=44.128996, accumulated_logging_time=0.242890, accumulated_submission_time=831.370645, global_step=3457, preemption_count=0, score=831.370645, test/loss=0.291952, test/num_examples=3581, test/ssim=0.738298, total_duration=875.870621, train/loss=0.272561, train/ssim=0.742829, validation/loss=0.290375, validation/num_examples=3554, validation/ssim=0.721200
I0208 22:49:25.071931 140250672465664 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.14067479968070984, loss=0.32838255167007446
I0208 22:49:48.509428 140250680858368 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.16952113807201385, loss=0.24667252600193024
I0208 22:50:12.415213 140250672465664 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.14531506597995758, loss=0.25330615043640137
I0208 22:50:36.435029 140250680858368 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.21037866175174713, loss=0.26654160022735596
I0208 22:50:37.305663 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:50:38.680792 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:50:40.004787 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:50:41.328710 140466628462400 submission_runner.py:408] Time since start: 960.06s, 	Step: 3805, 	{'train/ssim': 0.7386627197265625, 'train/loss': 0.273552485874721, 'validation/ssim': 0.7167989358381401, 'validation/loss': 0.29171521085396734, 'validation/num_examples': 3554, 'test/ssim': 0.7343574785979824, 'test/loss': 0.29303873334307806, 'test/num_examples': 3581, 'score': 911.4902095794678, 'total_duration': 960.0550758838654, 'accumulated_submission_time': 911.4902095794678, 'accumulated_eval_time': 48.15200138092041, 'accumulated_logging_time': 0.27216148376464844}
I0208 22:50:41.343949 140250672465664 logging_writer.py:48] [3805] accumulated_eval_time=48.152001, accumulated_logging_time=0.272161, accumulated_submission_time=911.490210, global_step=3805, preemption_count=0, score=911.490210, test/loss=0.293039, test/num_examples=3581, test/ssim=0.734357, total_duration=960.055076, train/loss=0.273552, train/ssim=0.738663, validation/loss=0.291715, validation/num_examples=3554, validation/ssim=0.716799
I0208 22:51:01.737727 140250680858368 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.16723068058490753, loss=0.32252633571624756
I0208 22:51:25.539441 140250672465664 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.275806725025177, loss=0.23572410643100739
I0208 22:51:48.957609 140250680858368 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.1665298044681549, loss=0.24278724193572998
I0208 22:52:01.569787 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:52:02.942787 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:52:04.267956 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:52:05.591726 140466628462400 submission_runner.py:408] Time since start: 1044.32s, 	Step: 4153, 	{'train/ssim': 0.735229355948312, 'train/loss': 0.27429260526384625, 'validation/ssim': 0.7141856556872538, 'validation/loss': 0.29196893437631893, 'validation/num_examples': 3554, 'test/ssim': 0.7317198599160499, 'test/loss': 0.293230650645333, 'test/num_examples': 3581, 'score': 991.6942865848541, 'total_duration': 1044.3180837631226, 'accumulated_submission_time': 991.6942865848541, 'accumulated_eval_time': 52.17389678955078, 'accumulated_logging_time': 0.2966139316558838}
I0208 22:52:05.607626 140250672465664 logging_writer.py:48] [4153] accumulated_eval_time=52.173897, accumulated_logging_time=0.296614, accumulated_submission_time=991.694287, global_step=4153, preemption_count=0, score=991.694287, test/loss=0.293231, test/num_examples=3581, test/ssim=0.731720, total_duration=1044.318084, train/loss=0.274293, train/ssim=0.735229, validation/loss=0.291969, validation/num_examples=3554, validation/ssim=0.714186
I0208 22:52:15.113579 140250680858368 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.0985698252916336, loss=0.29406723380088806
I0208 22:52:38.712627 140250672465664 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.16659145057201385, loss=0.2920399308204651
I0208 22:53:02.617208 140250680858368 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.16915388405323029, loss=0.2937864661216736
I0208 22:53:25.631056 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:53:27.006180 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:53:28.328570 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:53:29.652926 140466628462400 submission_runner.py:408] Time since start: 1128.38s, 	Step: 4498, 	{'train/ssim': 0.7424945150102887, 'train/loss': 0.27370435850960867, 'validation/ssim': 0.7206746167390616, 'validation/loss': 0.29175642761676984, 'validation/num_examples': 3554, 'test/ssim': 0.737751721869764, 'test/loss': 0.2934164661363795, 'test/num_examples': 3581, 'score': 1071.6959915161133, 'total_duration': 1128.3792896270752, 'accumulated_submission_time': 1071.6959915161133, 'accumulated_eval_time': 56.19573616981506, 'accumulated_logging_time': 0.3215329647064209}
I0208 22:53:29.668236 140250672465664 logging_writer.py:48] [4498] accumulated_eval_time=56.195736, accumulated_logging_time=0.321533, accumulated_submission_time=1071.695992, global_step=4498, preemption_count=0, score=1071.695992, test/loss=0.293416, test/num_examples=3581, test/ssim=0.737752, total_duration=1128.379290, train/loss=0.273704, train/ssim=0.742495, validation/loss=0.291756, validation/num_examples=3554, validation/ssim=0.720675
I0208 22:53:29.907097 140250680858368 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.15772728621959686, loss=0.25464996695518494
I0208 22:53:51.521621 140250672465664 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.11456400156021118, loss=0.24845346808433533
I0208 22:54:15.069676 140250680858368 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.1270199418067932, loss=0.2805284857749939
I0208 22:54:38.820130 140250672465664 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.17705070972442627, loss=0.25394827127456665
I0208 22:54:49.755357 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:54:51.129141 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:54:52.452231 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:54:53.774171 140466628462400 submission_runner.py:408] Time since start: 1212.50s, 	Step: 4848, 	{'train/ssim': 0.732649530683245, 'train/loss': 0.2749983923775809, 'validation/ssim': 0.7118654267198931, 'validation/loss': 0.2926891629589899, 'validation/num_examples': 3554, 'test/ssim': 0.7292635229771712, 'test/loss': 0.294008682706908, 'test/num_examples': 3581, 'score': 1151.760767698288, 'total_duration': 1212.5005338191986, 'accumulated_submission_time': 1151.760767698288, 'accumulated_eval_time': 60.21451163291931, 'accumulated_logging_time': 0.3464336395263672}
I0208 22:54:53.790463 140250680858368 logging_writer.py:48] [4848] accumulated_eval_time=60.214512, accumulated_logging_time=0.346434, accumulated_submission_time=1151.760768, global_step=4848, preemption_count=0, score=1151.760768, test/loss=0.294009, test/num_examples=3581, test/ssim=0.729264, total_duration=1212.500534, train/loss=0.274998, train/ssim=0.732650, validation/loss=0.292689, validation/num_examples=3554, validation/ssim=0.711865
I0208 22:55:04.307016 140250672465664 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.18852739036083221, loss=0.2850683033466339
I0208 22:55:27.892891 140250680858368 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.06529057025909424, loss=0.2578969895839691
I0208 22:55:51.396635 140250672465664 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.140218123793602, loss=0.23524096608161926
I0208 22:56:13.898738 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:56:15.272390 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:56:16.596326 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:56:17.919491 140466628462400 submission_runner.py:408] Time since start: 1296.65s, 	Step: 5197, 	{'train/ssim': 0.7398488180977958, 'train/loss': 0.2722815786089216, 'validation/ssim': 0.7179851542715954, 'validation/loss': 0.2904013921923361, 'validation/num_examples': 3554, 'test/ssim': 0.7350328366072675, 'test/loss': 0.2919204315637217, 'test/num_examples': 3581, 'score': 1231.8473672866821, 'total_duration': 1296.645854473114, 'accumulated_submission_time': 1231.8473672866821, 'accumulated_eval_time': 64.23522353172302, 'accumulated_logging_time': 0.37164998054504395}
I0208 22:56:17.938001 140250680858368 logging_writer.py:48] [5197] accumulated_eval_time=64.235224, accumulated_logging_time=0.371650, accumulated_submission_time=1231.847367, global_step=5197, preemption_count=0, score=1231.847367, test/loss=0.291920, test/num_examples=3581, test/ssim=0.735033, total_duration=1296.645854, train/loss=0.272282, train/ssim=0.739849, validation/loss=0.290401, validation/num_examples=3554, validation/ssim=0.717985
I0208 22:56:18.246753 140250672465664 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.22772754728794098, loss=0.25950169563293457
I0208 22:56:40.839830 140250680858368 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.14852109551429749, loss=0.2593163549900055
I0208 22:57:04.600299 140250672465664 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.13048794865608215, loss=0.3225708305835724
I0208 22:57:28.335432 140250680858368 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.2635411024093628, loss=0.2776329815387726
I0208 22:57:37.988333 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:57:39.361785 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:57:40.682606 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:57:42.004276 140466628462400 submission_runner.py:408] Time since start: 1380.73s, 	Step: 5542, 	{'train/ssim': 0.7362847328186035, 'train/loss': 0.2749585935047695, 'validation/ssim': 0.7142758517031865, 'validation/loss': 0.2929826263101435, 'validation/num_examples': 3554, 'test/ssim': 0.7318219203783859, 'test/loss': 0.29443570722650797, 'test/num_examples': 3581, 'score': 1311.8751652240753, 'total_duration': 1380.730637550354, 'accumulated_submission_time': 1311.8751652240753, 'accumulated_eval_time': 68.25117325782776, 'accumulated_logging_time': 0.3998067378997803}
I0208 22:57:42.020934 140250672465664 logging_writer.py:48] [5542] accumulated_eval_time=68.251173, accumulated_logging_time=0.399807, accumulated_submission_time=1311.875165, global_step=5542, preemption_count=0, score=1311.875165, test/loss=0.294436, test/num_examples=3581, test/ssim=0.731822, total_duration=1380.730638, train/loss=0.274959, train/ssim=0.736285, validation/loss=0.292983, validation/num_examples=3554, validation/ssim=0.714276
I0208 22:57:53.627852 140250680858368 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.21083660423755646, loss=0.2191377431154251
I0208 22:58:17.178251 140250672465664 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.10898561030626297, loss=0.25542908906936646
I0208 22:58:40.434529 140250680858368 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.12268351018428802, loss=0.3612183928489685
I0208 22:59:02.016550 140466628462400 spec.py:321] Evaluating on the training split.
I0208 22:59:03.390669 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 22:59:04.711084 140466628462400 spec.py:349] Evaluating on the test split.
I0208 22:59:06.032624 140466628462400 submission_runner.py:408] Time since start: 1464.76s, 	Step: 5892, 	{'train/ssim': 0.7424530301775251, 'train/loss': 0.27154687472752165, 'validation/ssim': 0.7202798975406233, 'validation/loss': 0.28991355745726644, 'validation/num_examples': 3554, 'test/ssim': 0.7376195954996858, 'test/loss': 0.29129320627748884, 'test/num_examples': 3581, 'score': 1391.8485069274902, 'total_duration': 1464.7589864730835, 'accumulated_submission_time': 1391.8485069274902, 'accumulated_eval_time': 72.26720786094666, 'accumulated_logging_time': 0.42597007751464844}
I0208 22:59:06.048181 140250672465664 logging_writer.py:48] [5892] accumulated_eval_time=72.267208, accumulated_logging_time=0.425970, accumulated_submission_time=1391.848507, global_step=5892, preemption_count=0, score=1391.848507, test/loss=0.291293, test/num_examples=3581, test/ssim=0.737620, total_duration=1464.758986, train/loss=0.271547, train/ssim=0.742453, validation/loss=0.289914, validation/num_examples=3554, validation/ssim=0.720280
I0208 22:59:06.720740 140250680858368 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.17178815603256226, loss=0.25415676832199097
I0208 22:59:29.877789 140250672465664 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.15754182636737823, loss=0.22972813248634338
I0208 22:59:53.141619 140250680858368 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.07526066899299622, loss=0.34507814049720764
I0208 23:00:17.170645 140250672465664 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.20961663126945496, loss=0.2375117987394333
I0208 23:00:26.086905 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:00:27.460778 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:00:28.783541 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:00:30.107486 140466628462400 submission_runner.py:408] Time since start: 1548.83s, 	Step: 6239, 	{'train/ssim': 0.7378379276820591, 'train/loss': 0.2722529854093279, 'validation/ssim': 0.715315956712507, 'validation/loss': 0.2903406661618071, 'validation/num_examples': 3554, 'test/ssim': 0.7331954074019129, 'test/loss': 0.29166568946785115, 'test/num_examples': 3581, 'score': 1471.865632534027, 'total_duration': 1548.8338203430176, 'accumulated_submission_time': 1471.865632534027, 'accumulated_eval_time': 76.28772187232971, 'accumulated_logging_time': 0.450514554977417}
I0208 23:00:30.127383 140250680858368 logging_writer.py:48] [6239] accumulated_eval_time=76.287722, accumulated_logging_time=0.450515, accumulated_submission_time=1471.865633, global_step=6239, preemption_count=0, score=1471.865633, test/loss=0.291666, test/num_examples=3581, test/ssim=0.733195, total_duration=1548.833820, train/loss=0.272253, train/ssim=0.737838, validation/loss=0.290341, validation/num_examples=3554, validation/ssim=0.715316
I0208 23:00:42.623185 140250672465664 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.07762351632118225, loss=0.2629319727420807
I0208 23:01:06.858814 140250680858368 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.17759451270103455, loss=0.21591834723949432
I0208 23:01:30.649839 140250672465664 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.10006986558437347, loss=0.30167776346206665
I0208 23:01:50.139524 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:01:51.511948 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:01:52.833609 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:01:54.156375 140466628462400 submission_runner.py:408] Time since start: 1632.88s, 	Step: 6584, 	{'train/ssim': 0.7387582915169852, 'train/loss': 0.2715438093457903, 'validation/ssim': 0.7162649039814294, 'validation/loss': 0.289883915735351, 'validation/num_examples': 3554, 'test/ssim': 0.7338993996090477, 'test/loss': 0.29118596438887534, 'test/num_examples': 3581, 'score': 1551.8551013469696, 'total_duration': 1632.882734298706, 'accumulated_submission_time': 1551.8551013469696, 'accumulated_eval_time': 80.30454111099243, 'accumulated_logging_time': 0.48056650161743164}
I0208 23:01:54.173509 140250680858368 logging_writer.py:48] [6584] accumulated_eval_time=80.304541, accumulated_logging_time=0.480567, accumulated_submission_time=1551.855101, global_step=6584, preemption_count=0, score=1551.855101, test/loss=0.291186, test/num_examples=3581, test/ssim=0.733899, total_duration=1632.882734, train/loss=0.271544, train/ssim=0.738758, validation/loss=0.289884, validation/num_examples=3554, validation/ssim=0.716265
I0208 23:01:55.959144 140250672465664 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.2916577160358429, loss=0.33805763721466064
I0208 23:02:19.743383 140250680858368 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.24496690928936005, loss=0.23377399146556854
I0208 23:02:43.465884 140250672465664 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.1510290950536728, loss=0.3671340048313141
I0208 23:03:07.369142 140250680858368 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.06638848781585693, loss=0.3288312256336212
I0208 23:03:14.241833 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:03:15.618298 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:03:16.939214 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:03:18.262794 140466628462400 submission_runner.py:408] Time since start: 1716.99s, 	Step: 6930, 	{'train/ssim': 0.7413247653416225, 'train/loss': 0.2723818676812308, 'validation/ssim': 0.7200253840303179, 'validation/loss': 0.29050707884162214, 'validation/num_examples': 3554, 'test/ssim': 0.7372944610007679, 'test/loss': 0.29179406612154424, 'test/num_examples': 3581, 'score': 1631.901466369629, 'total_duration': 1716.9891197681427, 'accumulated_submission_time': 1631.901466369629, 'accumulated_eval_time': 84.32542157173157, 'accumulated_logging_time': 0.5068538188934326}
I0208 23:03:18.283090 140250672465664 logging_writer.py:48] [6930] accumulated_eval_time=84.325422, accumulated_logging_time=0.506854, accumulated_submission_time=1631.901466, global_step=6930, preemption_count=0, score=1631.901466, test/loss=0.291794, test/num_examples=3581, test/ssim=0.737294, total_duration=1716.989120, train/loss=0.272382, train/ssim=0.741325, validation/loss=0.290507, validation/num_examples=3554, validation/ssim=0.720025
I0208 23:03:32.729156 140250680858368 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.17841078341007233, loss=0.2536088824272156
I0208 23:03:56.241151 140250672465664 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.18225112557411194, loss=0.23319995403289795
I0208 23:04:20.116049 140250680858368 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.08796266466379166, loss=0.26913416385650635
I0208 23:04:38.296118 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:04:39.669051 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:04:40.992057 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:04:42.313919 140466628462400 submission_runner.py:408] Time since start: 1801.04s, 	Step: 7277, 	{'train/ssim': 0.7432306153433663, 'train/loss': 0.27117463520595003, 'validation/ssim': 0.721642317635059, 'validation/loss': 0.2892516162466587, 'validation/num_examples': 3554, 'test/ssim': 0.7388227772226682, 'test/loss': 0.2905993042162629, 'test/num_examples': 3581, 'score': 1711.8922002315521, 'total_duration': 1801.0402827262878, 'accumulated_submission_time': 1711.8922002315521, 'accumulated_eval_time': 88.34319472312927, 'accumulated_logging_time': 0.5372030735015869}
I0208 23:04:42.330126 140250672465664 logging_writer.py:48] [7277] accumulated_eval_time=88.343195, accumulated_logging_time=0.537203, accumulated_submission_time=1711.892200, global_step=7277, preemption_count=0, score=1711.892200, test/loss=0.290599, test/num_examples=3581, test/ssim=0.738823, total_duration=1801.040283, train/loss=0.271175, train/ssim=0.743231, validation/loss=0.289252, validation/num_examples=3554, validation/ssim=0.721642
I0208 23:04:45.734680 140250680858368 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.07629892975091934, loss=0.28989535570144653
I0208 23:05:09.641253 140250672465664 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.1036233901977539, loss=0.22140583395957947
I0208 23:05:33.802587 140250680858368 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.3097222149372101, loss=0.1657843142747879
I0208 23:05:57.722929 140250672465664 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.07307573407888412, loss=0.28888338804244995
I0208 23:06:02.466693 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:06:03.842175 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:06:05.167023 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:06:06.488177 140466628462400 submission_runner.py:408] Time since start: 1885.21s, 	Step: 7621, 	{'train/ssim': 0.7414225169590541, 'train/loss': 0.272381067276001, 'validation/ssim': 0.7186626204628588, 'validation/loss': 0.2906780597126477, 'validation/num_examples': 3554, 'test/ssim': 0.7362754926172856, 'test/loss': 0.2919793361992984, 'test/num_examples': 3581, 'score': 1792.0071773529053, 'total_duration': 1885.2145402431488, 'accumulated_submission_time': 1792.0071773529053, 'accumulated_eval_time': 92.36465859413147, 'accumulated_logging_time': 0.5624737739562988}
I0208 23:06:06.506927 140250680858368 logging_writer.py:48] [7621] accumulated_eval_time=92.364659, accumulated_logging_time=0.562474, accumulated_submission_time=1792.007177, global_step=7621, preemption_count=0, score=1792.007177, test/loss=0.291979, test/num_examples=3581, test/ssim=0.736275, total_duration=1885.214540, train/loss=0.272381, train/ssim=0.741423, validation/loss=0.290678, validation/num_examples=3554, validation/ssim=0.718663
I0208 23:06:23.076061 140250672465664 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.10128858685493469, loss=0.24584950506687164
I0208 23:06:46.207635 140250680858368 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.29470404982566833, loss=0.3082220256328583
I0208 23:07:10.350660 140250672465664 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.12524309754371643, loss=0.29683351516723633
I0208 23:07:26.709935 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:07:28.083759 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:07:29.406920 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:07:30.729851 140466628462400 submission_runner.py:408] Time since start: 1969.46s, 	Step: 7971, 	{'train/ssim': 0.7419336863926479, 'train/loss': 0.27214648042406353, 'validation/ssim': 0.7195013128912845, 'validation/loss': 0.29101002638971935, 'validation/num_examples': 3554, 'test/ssim': 0.736703369345155, 'test/loss': 0.29253044224291397, 'test/num_examples': 3581, 'score': 1872.1870954036713, 'total_duration': 1969.4562158584595, 'accumulated_submission_time': 1872.1870954036713, 'accumulated_eval_time': 96.38457012176514, 'accumulated_logging_time': 0.5911064147949219}
I0208 23:07:30.746163 140250680858368 logging_writer.py:48] [7971] accumulated_eval_time=96.384570, accumulated_logging_time=0.591106, accumulated_submission_time=1872.187095, global_step=7971, preemption_count=0, score=1872.187095, test/loss=0.292530, test/num_examples=3581, test/ssim=0.736703, total_duration=1969.456216, train/loss=0.272146, train/ssim=0.741934, validation/loss=0.291010, validation/num_examples=3554, validation/ssim=0.719501
I0208 23:07:35.566644 140250672465664 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.14265577495098114, loss=0.2962496280670166
I0208 23:07:58.958295 140250680858368 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.09695791453123093, loss=0.25676044821739197
I0208 23:08:22.797052 140250672465664 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.1578461229801178, loss=0.2970031201839447
I0208 23:08:46.573584 140250680858368 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.18640458583831787, loss=0.21614086627960205
I0208 23:08:50.763959 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:08:52.138565 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:08:53.462308 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:08:54.783309 140466628462400 submission_runner.py:408] Time since start: 2053.51s, 	Step: 8319, 	{'train/ssim': 0.7445854459490094, 'train/loss': 0.26996030126299175, 'validation/ssim': 0.7223544059070766, 'validation/loss': 0.28818822376635483, 'validation/num_examples': 3554, 'test/ssim': 0.7396412380445406, 'test/loss': 0.28960392495767595, 'test/num_examples': 3581, 'score': 1952.1830134391785, 'total_duration': 2053.50967502594, 'accumulated_submission_time': 1952.1830134391785, 'accumulated_eval_time': 100.40389037132263, 'accumulated_logging_time': 0.6165444850921631}
I0208 23:08:54.799683 140250672465664 logging_writer.py:48] [8319] accumulated_eval_time=100.403890, accumulated_logging_time=0.616544, accumulated_submission_time=1952.183013, global_step=8319, preemption_count=0, score=1952.183013, test/loss=0.289604, test/num_examples=3581, test/ssim=0.739641, total_duration=2053.509675, train/loss=0.269960, train/ssim=0.744585, validation/loss=0.288188, validation/num_examples=3554, validation/ssim=0.722354
I0208 23:09:12.062364 140250680858368 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.11138567328453064, loss=0.2692393958568573
I0208 23:09:35.623351 140250672465664 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.1076488271355629, loss=0.26461830735206604
I0208 23:09:59.694225 140250680858368 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.08348012715578079, loss=0.2899729907512665
I0208 23:10:14.862297 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:10:16.237446 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:10:17.560177 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:10:18.884247 140466628462400 submission_runner.py:408] Time since start: 2137.61s, 	Step: 8665, 	{'train/ssim': 0.7385866982596261, 'train/loss': 0.2723539727074759, 'validation/ssim': 0.7161103411209201, 'validation/loss': 0.290498972878271, 'validation/num_examples': 3554, 'test/ssim': 0.7338329955407009, 'test/loss': 0.2918098149303616, 'test/num_examples': 3581, 'score': 2032.2230477333069, 'total_duration': 2137.6106107234955, 'accumulated_submission_time': 2032.2230477333069, 'accumulated_eval_time': 104.42580008506775, 'accumulated_logging_time': 0.6430308818817139}
I0208 23:10:18.900929 140250672465664 logging_writer.py:48] [8665] accumulated_eval_time=104.425800, accumulated_logging_time=0.643031, accumulated_submission_time=2032.223048, global_step=8665, preemption_count=0, score=2032.223048, test/loss=0.291810, test/num_examples=3581, test/ssim=0.733833, total_duration=2137.610611, train/loss=0.272354, train/ssim=0.738587, validation/loss=0.290499, validation/num_examples=3554, validation/ssim=0.716110
I0208 23:10:25.195417 140250680858368 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.32541540265083313, loss=0.2212311327457428
I0208 23:10:48.678822 140250672465664 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.11257262527942657, loss=0.34656429290771484
I0208 23:11:12.369567 140250680858368 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.1493900716304779, loss=0.28518375754356384
I0208 23:11:36.217653 140250672465664 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.3589401841163635, loss=0.24162746965885162
I0208 23:11:38.992411 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:11:40.365600 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:11:41.688513 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:11:43.011464 140466628462400 submission_runner.py:408] Time since start: 2221.74s, 	Step: 9013, 	{'train/ssim': 0.7424891335623605, 'train/loss': 0.2706210272652762, 'validation/ssim': 0.7202015169966939, 'validation/loss': 0.28911707786341095, 'validation/num_examples': 3554, 'test/ssim': 0.737618981909732, 'test/loss': 0.29053078667140814, 'test/num_examples': 3581, 'score': 2112.292769908905, 'total_duration': 2221.7378239631653, 'accumulated_submission_time': 2112.292769908905, 'accumulated_eval_time': 108.44480562210083, 'accumulated_logging_time': 0.6688551902770996}
I0208 23:11:43.028626 140250680858368 logging_writer.py:48] [9013] accumulated_eval_time=108.444806, accumulated_logging_time=0.668855, accumulated_submission_time=2112.292770, global_step=9013, preemption_count=0, score=2112.292770, test/loss=0.290531, test/num_examples=3581, test/ssim=0.737619, total_duration=2221.737824, train/loss=0.270621, train/ssim=0.742489, validation/loss=0.289117, validation/num_examples=3554, validation/ssim=0.720202
I0208 23:12:01.531008 140250672465664 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.22787624597549438, loss=0.28628847002983093
I0208 23:12:25.309806 140250680858368 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.15747064352035522, loss=0.23910720646381378
I0208 23:12:48.934238 140250672465664 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.1282431036233902, loss=0.41851934790611267
I0208 23:13:03.189351 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:13:04.564990 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:13:05.886526 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:13:07.208997 140466628462400 submission_runner.py:408] Time since start: 2305.94s, 	Step: 9361, 	{'train/ssim': 0.7465317589896066, 'train/loss': 0.2700404099055699, 'validation/ssim': 0.7243574718846723, 'validation/loss': 0.28854945434501617, 'validation/num_examples': 3554, 'test/ssim': 0.7415535934009355, 'test/loss': 0.2898749271873255, 'test/num_examples': 3581, 'score': 2192.431623697281, 'total_duration': 2305.935366868973, 'accumulated_submission_time': 2192.431623697281, 'accumulated_eval_time': 112.46442103385925, 'accumulated_logging_time': 0.6951453685760498}
I0208 23:13:07.225196 140250680858368 logging_writer.py:48] [9361] accumulated_eval_time=112.464421, accumulated_logging_time=0.695145, accumulated_submission_time=2192.431624, global_step=9361, preemption_count=0, score=2192.431624, test/loss=0.289875, test/num_examples=3581, test/ssim=0.741554, total_duration=2305.935367, train/loss=0.270040, train/ssim=0.746532, validation/loss=0.288549, validation/num_examples=3554, validation/ssim=0.724357
I0208 23:13:14.347462 140250672465664 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.18445302546024323, loss=0.3046833574771881
I0208 23:13:37.955136 140250680858368 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.0629941001534462, loss=0.27872908115386963
I0208 23:14:01.836692 140250672465664 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.0715717077255249, loss=0.3343580365180969
I0208 23:14:26.141435 140250680858368 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.10400775074958801, loss=0.4022862911224365
I0208 23:14:27.339320 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:14:28.714720 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:14:30.037489 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:14:31.361851 140466628462400 submission_runner.py:408] Time since start: 2390.09s, 	Step: 9706, 	{'train/ssim': 0.7407120295933315, 'train/loss': 0.27192156655447824, 'validation/ssim': 0.7184759085273635, 'validation/loss': 0.290316073493335, 'validation/num_examples': 3554, 'test/ssim': 0.736225314594387, 'test/loss': 0.2915895020485723, 'test/num_examples': 3581, 'score': 2272.5230610370636, 'total_duration': 2390.088215827942, 'accumulated_submission_time': 2272.5230610370636, 'accumulated_eval_time': 116.48691987991333, 'accumulated_logging_time': 0.7215027809143066}
I0208 23:14:31.378539 140250672465664 logging_writer.py:48] [9706] accumulated_eval_time=116.486920, accumulated_logging_time=0.721503, accumulated_submission_time=2272.523061, global_step=9706, preemption_count=0, score=2272.523061, test/loss=0.291590, test/num_examples=3581, test/ssim=0.736225, total_duration=2390.088216, train/loss=0.271922, train/ssim=0.740712, validation/loss=0.290316, validation/num_examples=3554, validation/ssim=0.718476
I0208 23:14:51.801722 140250680858368 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.0874863713979721, loss=0.24650631844997406
I0208 23:15:15.309846 140250672465664 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.18288280069828033, loss=0.2812637686729431
I0208 23:15:39.162800 140250680858368 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.11051851511001587, loss=0.29798635840415955
I0208 23:15:51.574046 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:15:52.946490 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:15:54.270335 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:15:55.593002 140466628462400 submission_runner.py:408] Time since start: 2474.32s, 	Step: 10054, 	{'train/ssim': 0.7451527459280831, 'train/loss': 0.2696514810834612, 'validation/ssim': 0.7231413026035804, 'validation/loss': 0.2880908835115363, 'validation/num_examples': 3554, 'test/ssim': 0.7403175505270874, 'test/loss': 0.28941947299986037, 'test/num_examples': 3581, 'score': 2352.6956446170807, 'total_duration': 2474.3193640708923, 'accumulated_submission_time': 2352.6956446170807, 'accumulated_eval_time': 120.50583410263062, 'accumulated_logging_time': 0.7481822967529297}
I0208 23:15:55.610033 140250672465664 logging_writer.py:48] [10054] accumulated_eval_time=120.505834, accumulated_logging_time=0.748182, accumulated_submission_time=2352.695645, global_step=10054, preemption_count=0, score=2352.695645, test/loss=0.289419, test/num_examples=3581, test/ssim=0.740318, total_duration=2474.319364, train/loss=0.269651, train/ssim=0.745153, validation/loss=0.288091, validation/num_examples=3554, validation/ssim=0.723141
I0208 23:16:04.627681 140250680858368 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.06922174990177155, loss=0.24269089102745056
I0208 23:16:28.169568 140250672465664 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.11532547324895859, loss=0.36681613326072693
I0208 23:16:51.766457 140250680858368 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.1481986790895462, loss=0.29659608006477356
I0208 23:17:15.345180 140250672465664 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.20600956678390503, loss=0.284775972366333
I0208 23:17:15.725547 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:17:17.101760 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:17:18.424602 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:17:19.748825 140466628462400 submission_runner.py:408] Time since start: 2558.48s, 	Step: 10403, 	{'train/ssim': 0.7408154351370675, 'train/loss': 0.2704327957970755, 'validation/ssim': 0.717867136940771, 'validation/loss': 0.2889557829316439, 'validation/num_examples': 3554, 'test/ssim': 0.7356155425335102, 'test/loss': 0.2902749537489528, 'test/num_examples': 3581, 'score': 2432.7886712551117, 'total_duration': 2558.4751613140106, 'accumulated_submission_time': 2432.7886712551117, 'accumulated_eval_time': 124.52903652191162, 'accumulated_logging_time': 0.7753183841705322}
I0208 23:17:19.768496 140250680858368 logging_writer.py:48] [10403] accumulated_eval_time=124.529037, accumulated_logging_time=0.775318, accumulated_submission_time=2432.788671, global_step=10403, preemption_count=0, score=2432.788671, test/loss=0.290275, test/num_examples=3581, test/ssim=0.735616, total_duration=2558.475161, train/loss=0.270433, train/ssim=0.740815, validation/loss=0.288956, validation/num_examples=3554, validation/ssim=0.717867
I0208 23:17:40.654841 140250672465664 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.11256785690784454, loss=0.24719932675361633
I0208 23:18:04.478251 140250680858368 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.22251661121845245, loss=0.24942030012607574
I0208 23:18:28.492875 140250672465664 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.1576921045780182, loss=0.25378692150115967
I0208 23:18:39.801413 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:18:41.174017 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:18:42.496672 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:18:43.818887 140466628462400 submission_runner.py:408] Time since start: 2642.55s, 	Step: 10748, 	{'train/ssim': 0.7433472360883441, 'train/loss': 0.27003611837114605, 'validation/ssim': 0.7214320434501618, 'validation/loss': 0.28838386600045723, 'validation/num_examples': 3554, 'test/ssim': 0.7389399729038676, 'test/loss': 0.2895765861163956, 'test/num_examples': 3581, 'score': 2512.798567056656, 'total_duration': 2642.545251607895, 'accumulated_submission_time': 2512.798567056656, 'accumulated_eval_time': 128.54647755622864, 'accumulated_logging_time': 0.805931568145752}
I0208 23:18:43.835867 140250680858368 logging_writer.py:48] [10748] accumulated_eval_time=128.546478, accumulated_logging_time=0.805932, accumulated_submission_time=2512.798567, global_step=10748, preemption_count=0, score=2512.798567, test/loss=0.289577, test/num_examples=3581, test/ssim=0.738940, total_duration=2642.545252, train/loss=0.270036, train/ssim=0.743347, validation/loss=0.288384, validation/num_examples=3554, validation/ssim=0.721432
I0208 23:18:54.028748 140250672465664 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.09081423282623291, loss=0.23415648937225342
I0208 23:19:17.877099 140250680858368 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.11995568871498108, loss=0.24841833114624023
I0208 23:19:41.683077 140250672465664 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.06554171442985535, loss=0.268450528383255
I0208 23:20:03.874429 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:20:05.245870 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:20:06.571299 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:20:07.895902 140466628462400 submission_runner.py:408] Time since start: 2726.62s, 	Step: 11094, 	{'train/ssim': 0.7452190944126674, 'train/loss': 0.2699331215449742, 'validation/ssim': 0.7226893607994513, 'validation/loss': 0.2884922317393254, 'validation/num_examples': 3554, 'test/ssim': 0.7398847650795867, 'test/loss': 0.28990441359344454, 'test/num_examples': 3581, 'score': 2592.8142914772034, 'total_duration': 2726.6222710609436, 'accumulated_submission_time': 2592.8142914772034, 'accumulated_eval_time': 132.5679280757904, 'accumulated_logging_time': 0.8328738212585449}
I0208 23:20:07.913100 140250680858368 logging_writer.py:48] [11094] accumulated_eval_time=132.567928, accumulated_logging_time=0.832874, accumulated_submission_time=2592.814291, global_step=11094, preemption_count=0, score=2592.814291, test/loss=0.289904, test/num_examples=3581, test/ssim=0.739885, total_duration=2726.622271, train/loss=0.269933, train/ssim=0.745219, validation/loss=0.288492, validation/num_examples=3554, validation/ssim=0.722689
I0208 23:20:08.441309 140250672465664 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.09333528578281403, loss=0.24591796100139618
I0208 23:20:31.104446 140250680858368 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.10944376140832901, loss=0.39043280482292175
I0208 23:20:54.811277 140250672465664 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.18979023396968842, loss=0.2826850116252899
I0208 23:21:18.321574 140250680858368 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.10605478286743164, loss=0.26976507902145386
I0208 23:21:28.120959 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:21:29.494531 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:21:30.816821 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:21:32.140146 140466628462400 submission_runner.py:408] Time since start: 2810.87s, 	Step: 11442, 	{'train/ssim': 0.7470412254333496, 'train/loss': 0.26985042435782297, 'validation/ssim': 0.7249382847671637, 'validation/loss': 0.28855941506269345, 'validation/num_examples': 3554, 'test/ssim': 0.7421258001212999, 'test/loss': 0.289955068852974, 'test/num_examples': 3581, 'score': 2672.999428987503, 'total_duration': 2810.8664784431458, 'accumulated_submission_time': 2672.999428987503, 'accumulated_eval_time': 136.58704543113708, 'accumulated_logging_time': 0.8600804805755615}
I0208 23:21:32.160867 140250672465664 logging_writer.py:48] [11442] accumulated_eval_time=136.587045, accumulated_logging_time=0.860080, accumulated_submission_time=2672.999429, global_step=11442, preemption_count=0, score=2672.999429, test/loss=0.289955, test/num_examples=3581, test/ssim=0.742126, total_duration=2810.866478, train/loss=0.269850, train/ssim=0.747041, validation/loss=0.288559, validation/num_examples=3554, validation/ssim=0.724938
I0208 23:21:43.586463 140250680858368 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.1860312968492508, loss=0.3717363178730011
I0208 23:22:07.410721 140250672465664 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.18794932961463928, loss=0.2592937648296356
I0208 23:22:31.493519 140250680858368 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.11137092858552933, loss=0.24233436584472656
I0208 23:22:52.319886 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:22:53.693667 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:22:55.015399 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:22:56.336624 140466628462400 submission_runner.py:408] Time since start: 2895.06s, 	Step: 11788, 	{'train/ssim': 0.7438268661499023, 'train/loss': 0.2697876010622297, 'validation/ssim': 0.7216566748074353, 'validation/loss': 0.28804715939566333, 'validation/num_examples': 3554, 'test/ssim': 0.7389654709752862, 'test/loss': 0.2894258134293842, 'test/num_examples': 3581, 'score': 2753.135874271393, 'total_duration': 2895.062990665436, 'accumulated_submission_time': 2753.135874271393, 'accumulated_eval_time': 140.6037676334381, 'accumulated_logging_time': 0.8904705047607422}
I0208 23:22:56.354176 140250672465664 logging_writer.py:48] [11788] accumulated_eval_time=140.603768, accumulated_logging_time=0.890471, accumulated_submission_time=2753.135874, global_step=11788, preemption_count=0, score=2753.135874, test/loss=0.289426, test/num_examples=3581, test/ssim=0.738965, total_duration=2895.062991, train/loss=0.269788, train/ssim=0.743827, validation/loss=0.288047, validation/num_examples=3554, validation/ssim=0.721657
I0208 23:22:57.316312 140250680858368 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.18500155210494995, loss=0.27472448348999023
I0208 23:23:20.882645 140250672465664 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.16926585137844086, loss=0.3163546919822693
I0208 23:23:44.552001 140250680858368 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.12760929763317108, loss=0.34094110131263733
I0208 23:24:08.280007 140250672465664 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.11352658271789551, loss=0.3288048207759857
I0208 23:24:16.513432 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:24:17.884438 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:24:19.207208 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:24:20.529451 140466628462400 submission_runner.py:408] Time since start: 2979.26s, 	Step: 12137, 	{'train/ssim': 0.7457892554146903, 'train/loss': 0.2697081225258963, 'validation/ssim': 0.7239719577632597, 'validation/loss': 0.2881403779742016, 'validation/num_examples': 3554, 'test/ssim': 0.7408732584953575, 'test/loss': 0.28960931091393816, 'test/num_examples': 3581, 'score': 2833.2737278938293, 'total_duration': 2979.2558150291443, 'accumulated_submission_time': 2833.2737278938293, 'accumulated_eval_time': 144.61974668502808, 'accumulated_logging_time': 0.9170408248901367}
I0208 23:24:20.550006 140250680858368 logging_writer.py:48] [12137] accumulated_eval_time=144.619747, accumulated_logging_time=0.917041, accumulated_submission_time=2833.273728, global_step=12137, preemption_count=0, score=2833.273728, test/loss=0.289609, test/num_examples=3581, test/ssim=0.740873, total_duration=2979.255815, train/loss=0.269708, train/ssim=0.745789, validation/loss=0.288140, validation/num_examples=3554, validation/ssim=0.723972
I0208 23:24:33.516829 140250672465664 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.07785212248563766, loss=0.2706177234649658
I0208 23:24:57.356784 140250680858368 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.16013383865356445, loss=0.2317941039800644
I0208 23:25:21.019000 140250672465664 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.09178853034973145, loss=0.2661980986595154
I0208 23:25:40.714485 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:25:42.088915 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:25:43.411917 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:25:44.735128 140466628462400 submission_runner.py:408] Time since start: 3063.46s, 	Step: 12485, 	{'train/ssim': 0.7406058992658343, 'train/loss': 0.2698268549782889, 'validation/ssim': 0.7178359495902504, 'validation/loss': 0.28838668247924876, 'validation/num_examples': 3554, 'test/ssim': 0.7355890899888299, 'test/loss': 0.2895721887217258, 'test/num_examples': 3581, 'score': 2913.4148364067078, 'total_duration': 3063.4614906311035, 'accumulated_submission_time': 2913.4148364067078, 'accumulated_eval_time': 148.6403510570526, 'accumulated_logging_time': 0.9478676319122314}
I0208 23:25:44.752836 140250680858368 logging_writer.py:48] [12485] accumulated_eval_time=148.640351, accumulated_logging_time=0.947868, accumulated_submission_time=2913.414836, global_step=12485, preemption_count=0, score=2913.414836, test/loss=0.289572, test/num_examples=3581, test/ssim=0.735589, total_duration=3063.461491, train/loss=0.269827, train/ssim=0.740606, validation/loss=0.288387, validation/num_examples=3554, validation/ssim=0.717836
I0208 23:25:46.280048 140250672465664 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.13615432381629944, loss=0.34957295656204224
I0208 23:26:10.392188 140250680858368 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.10756320506334305, loss=0.2790956497192383
I0208 23:26:34.080633 140250672465664 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.16494010388851166, loss=0.3085731565952301
I0208 23:26:57.529305 140250680858368 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.09128899872303009, loss=0.26405590772628784
I0208 23:27:04.744691 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:27:06.119231 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:27:07.440773 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:27:08.763680 140466628462400 submission_runner.py:408] Time since start: 3147.49s, 	Step: 12831, 	{'train/ssim': 0.7433413096836635, 'train/loss': 0.27062998499189106, 'validation/ssim': 0.720636972095702, 'validation/loss': 0.2892357134456774, 'validation/num_examples': 3554, 'test/ssim': 0.7379370260358489, 'test/loss': 0.2906425963963453, 'test/num_examples': 3581, 'score': 2993.3852968215942, 'total_duration': 3147.490044116974, 'accumulated_submission_time': 2993.3852968215942, 'accumulated_eval_time': 152.65930891036987, 'accumulated_logging_time': 0.9745488166809082}
I0208 23:27:08.781665 140250672465664 logging_writer.py:48] [12831] accumulated_eval_time=152.659309, accumulated_logging_time=0.974549, accumulated_submission_time=2993.385297, global_step=12831, preemption_count=0, score=2993.385297, test/loss=0.290643, test/num_examples=3581, test/ssim=0.737937, total_duration=3147.490044, train/loss=0.270630, train/ssim=0.743341, validation/loss=0.289236, validation/num_examples=3554, validation/ssim=0.720637
I0208 23:27:23.473972 140250680858368 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.2442099004983902, loss=0.3083069920539856
I0208 23:27:47.160471 140250672465664 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.12552013993263245, loss=0.3145677447319031
I0208 23:28:11.004557 140250680858368 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.09307590126991272, loss=0.2569342255592346
I0208 23:28:28.994049 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:28:30.368905 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:28:31.691121 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:28:33.015497 140466628462400 submission_runner.py:408] Time since start: 3231.74s, 	Step: 13177, 	{'train/ssim': 0.7466381617954799, 'train/loss': 0.2701584611620222, 'validation/ssim': 0.723888837291608, 'validation/loss': 0.2892952029733223, 'validation/num_examples': 3554, 'test/ssim': 0.7409575248490295, 'test/loss': 0.29067855958531136, 'test/num_examples': 3581, 'score': 3073.576206445694, 'total_duration': 3231.741859436035, 'accumulated_submission_time': 3073.576206445694, 'accumulated_eval_time': 156.68073511123657, 'accumulated_logging_time': 1.001333236694336}
I0208 23:28:33.033185 140250672465664 logging_writer.py:48] [13177] accumulated_eval_time=156.680735, accumulated_logging_time=1.001333, accumulated_submission_time=3073.576206, global_step=13177, preemption_count=0, score=3073.576206, test/loss=0.290679, test/num_examples=3581, test/ssim=0.740958, total_duration=3231.741859, train/loss=0.270158, train/ssim=0.746638, validation/loss=0.289295, validation/num_examples=3554, validation/ssim=0.723889
I0208 23:28:36.358264 140250680858368 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.20138588547706604, loss=0.24302977323532104
I0208 23:29:00.057111 140250672465664 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.0953923687338829, loss=0.24364995956420898
I0208 23:29:23.716559 140250680858368 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.19600653648376465, loss=0.29753053188323975
I0208 23:29:47.254590 140250672465664 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.09299792349338531, loss=0.25028663873672485
I0208 23:29:53.018280 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:29:54.391641 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:29:55.713518 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:29:57.035965 140466628462400 submission_runner.py:408] Time since start: 3315.76s, 	Step: 13526, 	{'train/ssim': 0.7466552598135812, 'train/loss': 0.26982525416782926, 'validation/ssim': 0.7241531741303813, 'validation/loss': 0.28852585774831174, 'validation/num_examples': 3554, 'test/ssim': 0.7412572294531905, 'test/loss': 0.28988934655124265, 'test/num_examples': 3581, 'score': 3153.5380742549896, 'total_duration': 3315.7623331546783, 'accumulated_submission_time': 3153.5380742549896, 'accumulated_eval_time': 160.6983847618103, 'accumulated_logging_time': 1.0293962955474854}
I0208 23:29:57.054445 140250680858368 logging_writer.py:48] [13526] accumulated_eval_time=160.698385, accumulated_logging_time=1.029396, accumulated_submission_time=3153.538074, global_step=13526, preemption_count=0, score=3153.538074, test/loss=0.289889, test/num_examples=3581, test/ssim=0.741257, total_duration=3315.762333, train/loss=0.269825, train/ssim=0.746655, validation/loss=0.288526, validation/num_examples=3554, validation/ssim=0.724153
I0208 23:30:12.809041 140250672465664 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.23880510032176971, loss=0.20890045166015625
I0208 23:30:36.400949 140250680858368 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.22740669548511505, loss=0.2844984531402588
I0208 23:31:00.158234 140250672465664 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.2661875784397125, loss=0.3333011269569397
I0208 23:31:17.070088 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:31:18.445598 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:31:19.769779 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:31:21.092855 140466628462400 submission_runner.py:408] Time since start: 3399.82s, 	Step: 13872, 	{'train/ssim': 0.7463925906590053, 'train/loss': 0.27034829344068256, 'validation/ssim': 0.7245600522738463, 'validation/loss': 0.28894386441773356, 'validation/num_examples': 3554, 'test/ssim': 0.7415183460669157, 'test/loss': 0.2902640795714361, 'test/num_examples': 3581, 'score': 3233.532235622406, 'total_duration': 3399.819220304489, 'accumulated_submission_time': 3233.532235622406, 'accumulated_eval_time': 164.72112107276917, 'accumulated_logging_time': 1.0566694736480713}
I0208 23:31:21.110983 140250680858368 logging_writer.py:48] [13872] accumulated_eval_time=164.721121, accumulated_logging_time=1.056669, accumulated_submission_time=3233.532236, global_step=13872, preemption_count=0, score=3233.532236, test/loss=0.290264, test/num_examples=3581, test/ssim=0.741518, total_duration=3399.819220, train/loss=0.270348, train/ssim=0.746393, validation/loss=0.288944, validation/num_examples=3554, validation/ssim=0.724560
I0208 23:31:25.712666 140250672465664 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.09347239881753922, loss=0.25518572330474854
I0208 23:31:49.657012 140250680858368 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.1997627466917038, loss=0.24866817891597748
I0208 23:32:13.256620 140250672465664 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.11328084766864777, loss=0.3212531507015228
I0208 23:32:36.862741 140250680858368 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.07241538166999817, loss=0.24849022924900055
I0208 23:32:41.261287 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:32:42.636497 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:32:43.960098 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:32:45.282913 140466628462400 submission_runner.py:408] Time since start: 3484.01s, 	Step: 14220, 	{'train/ssim': 0.7378207615443638, 'train/loss': 0.27081310749053955, 'validation/ssim': 0.715547801003271, 'validation/loss': 0.2894396333796427, 'validation/num_examples': 3554, 'test/ssim': 0.7331411387793214, 'test/loss': 0.2906963536939752, 'test/num_examples': 3581, 'score': 3313.6611313819885, 'total_duration': 3484.0092494487762, 'accumulated_submission_time': 3313.6611313819885, 'accumulated_eval_time': 168.74269700050354, 'accumulated_logging_time': 1.0836646556854248}
I0208 23:32:45.303830 140250672465664 logging_writer.py:48] [14220] accumulated_eval_time=168.742697, accumulated_logging_time=1.083665, accumulated_submission_time=3313.661131, global_step=14220, preemption_count=0, score=3313.661131, test/loss=0.290696, test/num_examples=3581, test/ssim=0.733141, total_duration=3484.009249, train/loss=0.270813, train/ssim=0.737821, validation/loss=0.289440, validation/num_examples=3554, validation/ssim=0.715548
I0208 23:33:02.389839 140250680858368 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.1394985318183899, loss=0.2777191698551178
I0208 23:33:26.256087 140250672465664 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.10164640098810196, loss=0.291745662689209
I0208 23:33:49.856207 140250680858368 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.09591391682624817, loss=0.3340076208114624
I0208 23:34:05.462711 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:34:06.836940 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:34:08.160295 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:34:09.484482 140466628462400 submission_runner.py:408] Time since start: 3568.21s, 	Step: 14567, 	{'train/ssim': 0.7457613263811383, 'train/loss': 0.26930121013096403, 'validation/ssim': 0.7233533628481992, 'validation/loss': 0.28807522114167133, 'validation/num_examples': 3554, 'test/ssim': 0.7405100814192963, 'test/loss': 0.28943058579569253, 'test/num_examples': 3581, 'score': 3393.7974298000336, 'total_duration': 3568.210847377777, 'accumulated_submission_time': 3393.7974298000336, 'accumulated_eval_time': 172.76443004608154, 'accumulated_logging_time': 1.1147141456604004}
I0208 23:34:09.502434 140250672465664 logging_writer.py:48] [14567] accumulated_eval_time=172.764430, accumulated_logging_time=1.114714, accumulated_submission_time=3393.797430, global_step=14567, preemption_count=0, score=3393.797430, test/loss=0.289431, test/num_examples=3581, test/ssim=0.740510, total_duration=3568.210847, train/loss=0.269301, train/ssim=0.745761, validation/loss=0.288075, validation/num_examples=3554, validation/ssim=0.723353
I0208 23:34:15.204126 140250680858368 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.146745502948761, loss=0.2235087752342224
I0208 23:34:39.157941 140250672465664 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.057204823940992355, loss=0.27194640040397644
I0208 23:35:02.891997 140250680858368 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.11216005682945251, loss=0.28766050934791565
I0208 23:35:26.825510 140250672465664 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.1576852798461914, loss=0.281978964805603
I0208 23:35:29.511011 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:35:30.882448 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:35:32.203922 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:35:33.525034 140466628462400 submission_runner.py:408] Time since start: 3652.25s, 	Step: 14912, 	{'train/ssim': 0.745074885232108, 'train/loss': 0.26903135435921804, 'validation/ssim': 0.722156908918648, 'validation/loss': 0.2877203276402909, 'validation/num_examples': 3554, 'test/ssim': 0.7394592745348716, 'test/loss': 0.2891287677150237, 'test/num_examples': 3581, 'score': 3473.7841737270355, 'total_duration': 3652.251398086548, 'accumulated_submission_time': 3473.7841737270355, 'accumulated_eval_time': 176.778422832489, 'accumulated_logging_time': 1.1418116092681885}
I0208 23:35:33.542718 140250680858368 logging_writer.py:48] [14912] accumulated_eval_time=176.778423, accumulated_logging_time=1.141812, accumulated_submission_time=3473.784174, global_step=14912, preemption_count=0, score=3473.784174, test/loss=0.289129, test/num_examples=3581, test/ssim=0.739459, total_duration=3652.251398, train/loss=0.269031, train/ssim=0.745075, validation/loss=0.287720, validation/num_examples=3554, validation/ssim=0.722157
I0208 23:35:52.541333 140250672465664 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.20302923023700714, loss=0.24096083641052246
I0208 23:36:16.679949 140250680858368 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.1383713334798813, loss=0.1965005099773407
I0208 23:36:40.621511 140250672465664 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.1665797084569931, loss=0.1966460794210434
I0208 23:36:53.738975 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:36:55.110863 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:36:56.434795 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:36:57.755997 140466628462400 submission_runner.py:408] Time since start: 3736.48s, 	Step: 15256, 	{'train/ssim': 0.7442522048950195, 'train/loss': 0.2690439905439104, 'validation/ssim': 0.7211128196222566, 'validation/loss': 0.2880876892124191, 'validation/num_examples': 3554, 'test/ssim': 0.7385002334368891, 'test/loss': 0.28935910256606046, 'test/num_examples': 3581, 'score': 3553.9577605724335, 'total_duration': 3736.482356786728, 'accumulated_submission_time': 3553.9577605724335, 'accumulated_eval_time': 180.79540133476257, 'accumulated_logging_time': 1.169428825378418}
I0208 23:36:57.774492 140250680858368 logging_writer.py:48] [15256] accumulated_eval_time=180.795401, accumulated_logging_time=1.169429, accumulated_submission_time=3553.957761, global_step=15256, preemption_count=0, score=3553.957761, test/loss=0.289359, test/num_examples=3581, test/ssim=0.738500, total_duration=3736.482357, train/loss=0.269044, train/ssim=0.744252, validation/loss=0.288088, validation/num_examples=3554, validation/ssim=0.721113
I0208 23:37:06.266096 140250672465664 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.11132977157831192, loss=0.2285822480916977
I0208 23:37:29.932551 140250680858368 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.04753121733665466, loss=0.29909124970436096
I0208 23:37:53.501908 140250672465664 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.09376096725463867, loss=0.26432907581329346
I0208 23:38:17.899821 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:38:19.271342 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:38:20.593385 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:38:21.916441 140466628462400 submission_runner.py:408] Time since start: 3820.64s, 	Step: 15593, 	{'train/ssim': 0.7427872249058315, 'train/loss': 0.2695131301879883, 'validation/ssim': 0.720087552647545, 'validation/loss': 0.2880110260336065, 'validation/num_examples': 3554, 'test/ssim': 0.7376525248272131, 'test/loss': 0.28930629974169225, 'test/num_examples': 3581, 'score': 3634.0620753765106, 'total_duration': 3820.6428010463715, 'accumulated_submission_time': 3634.0620753765106, 'accumulated_eval_time': 184.81198024749756, 'accumulated_logging_time': 1.1967723369598389}
I0208 23:38:21.938107 140250680858368 logging_writer.py:48] [15593] accumulated_eval_time=184.811980, accumulated_logging_time=1.196772, accumulated_submission_time=3634.062075, global_step=15593, preemption_count=0, score=3634.062075, test/loss=0.289306, test/num_examples=3581, test/ssim=0.737653, total_duration=3820.642801, train/loss=0.269513, train/ssim=0.742787, validation/loss=0.288011, validation/num_examples=3554, validation/ssim=0.720088
I0208 23:38:22.538568 140250672465664 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.05237424373626709, loss=0.3603874444961548
I0208 23:38:45.225288 140250680858368 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.09093254059553146, loss=0.2563164234161377
I0208 23:39:09.210668 140250672465664 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.05529229715466499, loss=0.26803457736968994
I0208 23:39:33.070963 140250680858368 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.12368331104516983, loss=0.1920984983444214
I0208 23:39:42.039021 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:39:43.412058 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:39:44.734265 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:39:46.055643 140466628462400 submission_runner.py:408] Time since start: 3904.78s, 	Step: 15940, 	{'train/ssim': 0.7473726953778949, 'train/loss': 0.26929732731410433, 'validation/ssim': 0.7248972740881753, 'validation/loss': 0.288025005385657, 'validation/num_examples': 3554, 'test/ssim': 0.7420830533545099, 'test/loss': 0.28933322952300333, 'test/num_examples': 3581, 'score': 3714.1404304504395, 'total_duration': 3904.782006263733, 'accumulated_submission_time': 3714.1404304504395, 'accumulated_eval_time': 188.8285722732544, 'accumulated_logging_time': 1.2282922267913818}
I0208 23:39:46.074872 140250672465664 logging_writer.py:48] [15940] accumulated_eval_time=188.828572, accumulated_logging_time=1.228292, accumulated_submission_time=3714.140430, global_step=15940, preemption_count=0, score=3714.140430, test/loss=0.289333, test/num_examples=3581, test/ssim=0.742083, total_duration=3904.782006, train/loss=0.269297, train/ssim=0.747373, validation/loss=0.288025, validation/num_examples=3554, validation/ssim=0.724897
I0208 23:39:58.019272 140250680858368 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.1260831505060196, loss=0.2632597088813782
I0208 23:40:22.285621 140250672465664 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.14399303495883942, loss=0.24479997158050537
I0208 23:40:46.432356 140250680858368 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.08308298885822296, loss=0.2152094841003418
I0208 23:41:06.105712 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:41:07.479439 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:41:08.800288 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:41:10.120351 140466628462400 submission_runner.py:408] Time since start: 3988.85s, 	Step: 16283, 	{'train/ssim': 0.742541858128139, 'train/loss': 0.26914950779506136, 'validation/ssim': 0.7198662873259004, 'validation/loss': 0.28761373078749297, 'validation/num_examples': 3554, 'test/ssim': 0.7375420104588453, 'test/loss': 0.28884648224788817, 'test/num_examples': 3581, 'score': 3794.149676799774, 'total_duration': 3988.8467185497284, 'accumulated_submission_time': 3794.149676799774, 'accumulated_eval_time': 192.84317064285278, 'accumulated_logging_time': 1.2567307949066162}
I0208 23:41:10.139440 140250672465664 logging_writer.py:48] [16283] accumulated_eval_time=192.843171, accumulated_logging_time=1.256731, accumulated_submission_time=3794.149677, global_step=16283, preemption_count=0, score=3794.149677, test/loss=0.288846, test/num_examples=3581, test/ssim=0.737542, total_duration=3988.846719, train/loss=0.269150, train/ssim=0.742542, validation/loss=0.287614, validation/num_examples=3554, validation/ssim=0.719866
I0208 23:41:12.125149 140250680858368 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.1437954157590866, loss=0.24428880214691162
I0208 23:41:35.899838 140250672465664 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.11248739808797836, loss=0.2895943522453308
I0208 23:41:59.618571 140250680858368 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.0995054766535759, loss=0.33561623096466064
I0208 23:42:23.779043 140250672465664 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.07349603623151779, loss=0.32655325531959534
I0208 23:42:30.269817 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:42:31.644607 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:42:32.966530 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:42:34.288106 140466628462400 submission_runner.py:408] Time since start: 4073.01s, 	Step: 16628, 	{'train/ssim': 0.7466435432434082, 'train/loss': 0.27033313683101107, 'validation/ssim': 0.7241068052722285, 'validation/loss': 0.2894760758674205, 'validation/num_examples': 3554, 'test/ssim': 0.7411906890315205, 'test/loss': 0.2908273551491378, 'test/num_examples': 3581, 'score': 3874.2583525180817, 'total_duration': 4073.014472723007, 'accumulated_submission_time': 3874.2583525180817, 'accumulated_eval_time': 196.8614206314087, 'accumulated_logging_time': 1.2849531173706055}
I0208 23:42:34.306809 140250680858368 logging_writer.py:48] [16628] accumulated_eval_time=196.861421, accumulated_logging_time=1.284953, accumulated_submission_time=3874.258353, global_step=16628, preemption_count=0, score=3874.258353, test/loss=0.290827, test/num_examples=3581, test/ssim=0.741191, total_duration=4073.014473, train/loss=0.270333, train/ssim=0.746644, validation/loss=0.289476, validation/num_examples=3554, validation/ssim=0.724107
I0208 23:42:49.353750 140250672465664 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.12018349766731262, loss=0.23486948013305664
I0208 23:43:13.029078 140250680858368 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.07299859821796417, loss=0.22808173298835754
I0208 23:43:36.787861 140250672465664 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.12129011005163193, loss=0.4361514449119568
I0208 23:43:54.419133 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:43:55.794318 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:43:57.116080 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:43:58.439783 140466628462400 submission_runner.py:408] Time since start: 4157.17s, 	Step: 16976, 	{'train/ssim': 0.7484711919512067, 'train/loss': 0.26864796025412424, 'validation/ssim': 0.726306681292206, 'validation/loss': 0.2872895952953538, 'validation/num_examples': 3554, 'test/ssim': 0.7434004991622452, 'test/loss': 0.2886493494310248, 'test/num_examples': 3581, 'score': 3954.3488595485687, 'total_duration': 4157.166150331497, 'accumulated_submission_time': 3954.3488595485687, 'accumulated_eval_time': 200.88203167915344, 'accumulated_logging_time': 1.3127756118774414}
I0208 23:43:58.458867 140250680858368 logging_writer.py:48] [16976] accumulated_eval_time=200.882032, accumulated_logging_time=1.312776, accumulated_submission_time=3954.348860, global_step=16976, preemption_count=0, score=3954.348860, test/loss=0.288649, test/num_examples=3581, test/ssim=0.743400, total_duration=4157.166150, train/loss=0.268648, train/ssim=0.748471, validation/loss=0.287290, validation/num_examples=3554, validation/ssim=0.726307
I0208 23:44:02.242640 140250672465664 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.05295293778181076, loss=0.22637872397899628
I0208 23:44:26.309225 140250680858368 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.09378612786531448, loss=0.2709735333919525
I0208 23:44:50.234695 140250672465664 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.0938308835029602, loss=0.2741777002811432
I0208 23:45:14.392332 140250680858368 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.07130342721939087, loss=0.309548556804657
I0208 23:45:18.512929 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:45:19.886934 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:45:21.211449 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:45:22.533720 140466628462400 submission_runner.py:408] Time since start: 4241.26s, 	Step: 17319, 	{'train/ssim': 0.7472654070172992, 'train/loss': 0.2685943841934204, 'validation/ssim': 0.7247833097390265, 'validation/loss': 0.2873271884177599, 'validation/num_examples': 3554, 'test/ssim': 0.7419237244964745, 'test/loss': 0.2886111705005585, 'test/num_examples': 3581, 'score': 4034.3800785541534, 'total_duration': 4241.2600877285, 'accumulated_submission_time': 4034.3800785541534, 'accumulated_eval_time': 204.9027829170227, 'accumulated_logging_time': 1.3420863151550293}
I0208 23:45:22.553067 140250672465664 logging_writer.py:48] [17319] accumulated_eval_time=204.902783, accumulated_logging_time=1.342086, accumulated_submission_time=4034.380079, global_step=17319, preemption_count=0, score=4034.380079, test/loss=0.288611, test/num_examples=3581, test/ssim=0.741924, total_duration=4241.260088, train/loss=0.268594, train/ssim=0.747265, validation/loss=0.287327, validation/num_examples=3554, validation/ssim=0.724783
I0208 23:45:39.990364 140250680858368 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.07881199568510056, loss=0.2978057861328125
I0208 23:46:03.736330 140250672465664 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.05075356364250183, loss=0.28555721044540405
I0208 23:46:27.220161 140250680858368 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.04996008053421974, loss=0.2768878936767578
I0208 23:46:42.600284 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:46:43.972955 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:46:45.293927 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:46:46.614721 140466628462400 submission_runner.py:408] Time since start: 4325.34s, 	Step: 17665, 	{'train/ssim': 0.7432973044259208, 'train/loss': 0.2685637984957014, 'validation/ssim': 0.7210903564865293, 'validation/loss': 0.2872054959255856, 'validation/num_examples': 3554, 'test/ssim': 0.7382647512479056, 'test/loss': 0.2885156209094003, 'test/num_examples': 3581, 'score': 4114.4050397872925, 'total_duration': 4325.3410885334015, 'accumulated_submission_time': 4114.4050397872925, 'accumulated_eval_time': 208.91718530654907, 'accumulated_logging_time': 1.3709430694580078}
I0208 23:46:46.633909 140250672465664 logging_writer.py:48] [17665] accumulated_eval_time=208.917185, accumulated_logging_time=1.370943, accumulated_submission_time=4114.405040, global_step=17665, preemption_count=0, score=4114.405040, test/loss=0.288516, test/num_examples=3581, test/ssim=0.738265, total_duration=4325.341089, train/loss=0.268564, train/ssim=0.743297, validation/loss=0.287205, validation/num_examples=3554, validation/ssim=0.721090
I0208 23:46:52.962406 140250680858368 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.09256652742624283, loss=0.21843063831329346
I0208 23:47:16.864526 140250672465664 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.0980411171913147, loss=0.3069428503513336
I0208 23:47:40.563068 140250680858368 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.08095546066761017, loss=0.34118685126304626
I0208 23:48:04.568576 140250672465664 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.06795904040336609, loss=0.2773633301258087
I0208 23:48:06.711624 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:48:08.082875 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:48:09.404047 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:48:10.728613 140466628462400 submission_runner.py:408] Time since start: 4409.45s, 	Step: 18010, 	{'train/ssim': 0.7477449008396694, 'train/loss': 0.2679294858660017, 'validation/ssim': 0.7250144670837436, 'validation/loss': 0.2867555806122942, 'validation/num_examples': 3554, 'test/ssim': 0.7421997036224169, 'test/loss': 0.28814341042568414, 'test/num_examples': 3581, 'score': 4194.4614062309265, 'total_duration': 4409.454977273941, 'accumulated_submission_time': 4194.4614062309265, 'accumulated_eval_time': 212.93413639068604, 'accumulated_logging_time': 1.3991119861602783}
I0208 23:48:10.748184 140250680858368 logging_writer.py:48] [18010] accumulated_eval_time=212.934136, accumulated_logging_time=1.399112, accumulated_submission_time=4194.461406, global_step=18010, preemption_count=0, score=4194.461406, test/loss=0.288143, test/num_examples=3581, test/ssim=0.742200, total_duration=4409.454977, train/loss=0.267929, train/ssim=0.747745, validation/loss=0.286756, validation/num_examples=3554, validation/ssim=0.725014
I0208 23:48:30.139918 140250672465664 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.05870095640420914, loss=0.23049259185791016
I0208 23:48:53.717238 140250680858368 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.129232257604599, loss=0.23840467631816864
I0208 23:49:17.897130 140250672465664 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.11344204843044281, loss=0.3116646707057953
I0208 23:49:30.948044 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:49:32.320479 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:49:33.645958 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:49:34.968862 140466628462400 submission_runner.py:408] Time since start: 4493.70s, 	Step: 18354, 	{'train/ssim': 0.7455470221383231, 'train/loss': 0.2684933287756784, 'validation/ssim': 0.723333166634426, 'validation/loss': 0.2871022135874631, 'validation/num_examples': 3554, 'test/ssim': 0.7405550780159174, 'test/loss': 0.2883986297581856, 'test/num_examples': 3581, 'score': 4274.639910936356, 'total_duration': 4493.69522857666, 'accumulated_submission_time': 4274.639910936356, 'accumulated_eval_time': 216.95491862297058, 'accumulated_logging_time': 1.4276528358459473}
I0208 23:49:34.988262 140250680858368 logging_writer.py:48] [18354] accumulated_eval_time=216.954919, accumulated_logging_time=1.427653, accumulated_submission_time=4274.639911, global_step=18354, preemption_count=0, score=4274.639911, test/loss=0.288399, test/num_examples=3581, test/ssim=0.740555, total_duration=4493.695229, train/loss=0.268493, train/ssim=0.745547, validation/loss=0.287102, validation/num_examples=3554, validation/ssim=0.723333
I0208 23:49:43.785292 140250672465664 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.08076997101306915, loss=0.3349853456020355
I0208 23:50:07.767264 140250680858368 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.0759718045592308, loss=0.2566241919994354
I0208 23:50:31.290228 140250672465664 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.1278005987405777, loss=0.29570186138153076
I0208 23:50:54.853157 140250680858368 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.0499609149992466, loss=0.2797917127609253
I0208 23:50:55.033131 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:50:56.407255 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:50:57.730174 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:50:59.052031 140466628462400 submission_runner.py:408] Time since start: 4577.78s, 	Step: 18702, 	{'train/ssim': 0.7455432074410575, 'train/loss': 0.26904252597263884, 'validation/ssim': 0.7224505783536156, 'validation/loss': 0.2881686458040236, 'validation/num_examples': 3554, 'test/ssim': 0.7397161641955808, 'test/loss': 0.28954106607572955, 'test/num_examples': 3581, 'score': 4354.662460803986, 'total_duration': 4577.778399944305, 'accumulated_submission_time': 4354.662460803986, 'accumulated_eval_time': 220.97378945350647, 'accumulated_logging_time': 1.456956148147583}
I0208 23:50:59.071541 140250672465664 logging_writer.py:48] [18702] accumulated_eval_time=220.973789, accumulated_logging_time=1.456956, accumulated_submission_time=4354.662461, global_step=18702, preemption_count=0, score=4354.662461, test/loss=0.289541, test/num_examples=3581, test/ssim=0.739716, total_duration=4577.778400, train/loss=0.269043, train/ssim=0.745543, validation/loss=0.288169, validation/num_examples=3554, validation/ssim=0.722451
I0208 23:51:20.224564 140250680858368 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.10970089584589005, loss=0.28650403022766113
I0208 23:51:43.776124 140250672465664 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.1927509754896164, loss=0.245507150888443
I0208 23:52:07.601551 140250680858368 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.1533287912607193, loss=0.27506157755851746
I0208 23:52:19.062312 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:52:20.434721 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:52:21.757411 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:52:23.078915 140466628462400 submission_runner.py:408] Time since start: 4661.81s, 	Step: 19050, 	{'train/ssim': 0.7460323061261859, 'train/loss': 0.26802403586251394, 'validation/ssim': 0.7234105167592854, 'validation/loss': 0.2866896681391126, 'validation/num_examples': 3554, 'test/ssim': 0.7406949765254119, 'test/loss': 0.2879860927791643, 'test/num_examples': 3581, 'score': 4434.6307945251465, 'total_duration': 4661.805282831192, 'accumulated_submission_time': 4434.6307945251465, 'accumulated_eval_time': 224.99038195610046, 'accumulated_logging_time': 1.4863619804382324}
I0208 23:52:23.099521 140250672465664 logging_writer.py:48] [19050] accumulated_eval_time=224.990382, accumulated_logging_time=1.486362, accumulated_submission_time=4434.630795, global_step=19050, preemption_count=0, score=4434.630795, test/loss=0.287986, test/num_examples=3581, test/ssim=0.740695, total_duration=4661.805283, train/loss=0.268024, train/ssim=0.746032, validation/loss=0.286690, validation/num_examples=3554, validation/ssim=0.723411
I0208 23:52:32.643000 140250680858368 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.08773716539144516, loss=0.3056087791919708
I0208 23:52:56.247502 140250672465664 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.13286791741847992, loss=0.22696973383426666
I0208 23:53:20.257074 140250680858368 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.13891583681106567, loss=0.23976607620716095
I0208 23:53:43.206659 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:53:44.579475 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:53:45.901857 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:53:47.223648 140466628462400 submission_runner.py:408] Time since start: 4745.95s, 	Step: 19396, 	{'train/ssim': 0.7468460627964565, 'train/loss': 0.268166184425354, 'validation/ssim': 0.7243975895338, 'validation/loss': 0.28674500164317496, 'validation/num_examples': 3554, 'test/ssim': 0.7415834547786931, 'test/loss': 0.28810015233393255, 'test/num_examples': 3581, 'score': 4514.7168889045715, 'total_duration': 4745.949978351593, 'accumulated_submission_time': 4514.7168889045715, 'accumulated_eval_time': 229.00729703903198, 'accumulated_logging_time': 1.5158488750457764}
I0208 23:53:47.243083 140250672465664 logging_writer.py:48] [19396] accumulated_eval_time=229.007297, accumulated_logging_time=1.515849, accumulated_submission_time=4514.716889, global_step=19396, preemption_count=0, score=4514.716889, test/loss=0.288100, test/num_examples=3581, test/ssim=0.741583, total_duration=4745.949978, train/loss=0.268166, train/ssim=0.746846, validation/loss=0.286745, validation/num_examples=3554, validation/ssim=0.724398
I0208 23:53:47.623417 140250680858368 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.11287055909633636, loss=0.22392630577087402
I0208 23:54:09.921543 140250672465664 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.0888105183839798, loss=0.3324633538722992
I0208 23:54:33.984184 140250680858368 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.10204119980335236, loss=0.2943650484085083
I0208 23:54:57.930814 140250672465664 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.13885630667209625, loss=0.33515098690986633
I0208 23:55:07.251533 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:55:08.625174 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:55:09.945574 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:55:11.266142 140466628462400 submission_runner.py:408] Time since start: 4829.99s, 	Step: 19741, 	{'train/ssim': 0.7431297983442035, 'train/loss': 0.26822473321642193, 'validation/ssim': 0.7199703596519766, 'validation/loss': 0.2873446196736951, 'validation/num_examples': 3554, 'test/ssim': 0.7374969456855627, 'test/loss': 0.288564435399068, 'test/num_examples': 3581, 'score': 4594.704051733017, 'total_duration': 4829.992509126663, 'accumulated_submission_time': 4594.704051733017, 'accumulated_eval_time': 233.02187514305115, 'accumulated_logging_time': 1.544053554534912}
I0208 23:55:11.285423 140250680858368 logging_writer.py:48] [19741] accumulated_eval_time=233.021875, accumulated_logging_time=1.544054, accumulated_submission_time=4594.704052, global_step=19741, preemption_count=0, score=4594.704052, test/loss=0.288564, test/num_examples=3581, test/ssim=0.737497, total_duration=4829.992509, train/loss=0.268225, train/ssim=0.743130, validation/loss=0.287345, validation/num_examples=3554, validation/ssim=0.719970
I0208 23:55:23.322322 140250672465664 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.07454825192689896, loss=0.25016868114471436
I0208 23:55:46.869933 140250680858368 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.1393757462501526, loss=0.23358875513076782
I0208 23:56:10.531799 140250672465664 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.061595041304826736, loss=0.2351347804069519
I0208 23:56:31.405687 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:56:32.780254 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:56:34.103463 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:56:35.427836 140466628462400 submission_runner.py:408] Time since start: 4914.15s, 	Step: 20089, 	{'train/ssim': 0.745450496673584, 'train/loss': 0.2684863635471889, 'validation/ssim': 0.7224317560319359, 'validation/loss': 0.28741750464925087, 'validation/num_examples': 3554, 'test/ssim': 0.7398124978183468, 'test/loss': 0.2886755633573897, 'test/num_examples': 3581, 'score': 4674.802278280258, 'total_duration': 4914.1542048454285, 'accumulated_submission_time': 4674.802278280258, 'accumulated_eval_time': 237.04399013519287, 'accumulated_logging_time': 1.5727825164794922}
I0208 23:56:35.447386 140250680858368 logging_writer.py:48] [20089] accumulated_eval_time=237.043990, accumulated_logging_time=1.572783, accumulated_submission_time=4674.802278, global_step=20089, preemption_count=0, score=4674.802278, test/loss=0.288676, test/num_examples=3581, test/ssim=0.739812, total_duration=4914.154205, train/loss=0.268486, train/ssim=0.745450, validation/loss=0.287418, validation/num_examples=3554, validation/ssim=0.722432
I0208 23:56:36.339962 140250672465664 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.11772524565458298, loss=0.35406479239463806
I0208 23:56:59.799005 140250680858368 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.07872334122657776, loss=0.2818068861961365
I0208 23:57:23.379114 140250672465664 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.08287546038627625, loss=0.2647348940372467
I0208 23:57:47.165935 140250680858368 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.043660301715135574, loss=0.28215304017066956
I0208 23:57:55.434554 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:57:56.809775 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:57:58.130812 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:57:59.450397 140466628462400 submission_runner.py:408] Time since start: 4998.18s, 	Step: 20436, 	{'train/ssim': 0.7470994676862445, 'train/loss': 0.2675222669328962, 'validation/ssim': 0.7241141555949282, 'validation/loss': 0.2864648135243739, 'validation/num_examples': 3554, 'test/ssim': 0.7414250122172578, 'test/loss': 0.28776472315912105, 'test/num_examples': 3581, 'score': 4754.768115282059, 'total_duration': 4998.176766395569, 'accumulated_submission_time': 4754.768115282059, 'accumulated_eval_time': 241.05979704856873, 'accumulated_logging_time': 1.6012942790985107}
I0208 23:57:59.470447 140250672465664 logging_writer.py:48] [20436] accumulated_eval_time=241.059797, accumulated_logging_time=1.601294, accumulated_submission_time=4754.768115, global_step=20436, preemption_count=0, score=4754.768115, test/loss=0.287765, test/num_examples=3581, test/ssim=0.741425, total_duration=4998.176766, train/loss=0.267522, train/ssim=0.747099, validation/loss=0.286465, validation/num_examples=3554, validation/ssim=0.724114
I0208 23:58:12.869359 140250680858368 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.14597204327583313, loss=0.23644928634166718
I0208 23:58:36.825877 140250672465664 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.1181393563747406, loss=0.29112914204597473
I0208 23:59:00.969069 140250680858368 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.09773453325033188, loss=0.26482364535331726
I0208 23:59:19.698928 140466628462400 spec.py:321] Evaluating on the training split.
I0208 23:59:21.075582 140466628462400 spec.py:333] Evaluating on the validation split.
I0208 23:59:22.396824 140466628462400 spec.py:349] Evaluating on the test split.
I0208 23:59:23.719137 140466628462400 submission_runner.py:408] Time since start: 5082.45s, 	Step: 20780, 	{'train/ssim': 0.7483934674944196, 'train/loss': 0.26714554854801725, 'validation/ssim': 0.7249244084570202, 'validation/loss': 0.2866048818232977, 'validation/num_examples': 3554, 'test/ssim': 0.7421225958182072, 'test/loss': 0.2879269154369415, 'test/num_examples': 3581, 'score': 4834.975478887558, 'total_duration': 5082.445472002029, 'accumulated_submission_time': 4834.975478887558, 'accumulated_eval_time': 245.07993698120117, 'accumulated_logging_time': 1.6300930976867676}
I0208 23:59:23.742436 140250672465664 logging_writer.py:48] [20780] accumulated_eval_time=245.079937, accumulated_logging_time=1.630093, accumulated_submission_time=4834.975479, global_step=20780, preemption_count=0, score=4834.975479, test/loss=0.287927, test/num_examples=3581, test/ssim=0.742123, total_duration=5082.445472, train/loss=0.267146, train/ssim=0.748393, validation/loss=0.286605, validation/num_examples=3554, validation/ssim=0.724924
I0208 23:59:26.447066 140250680858368 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.07363471388816833, loss=0.26028233766555786
I0208 23:59:50.146163 140250672465664 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.06467347592115402, loss=0.33657389879226685
I0209 00:00:13.973202 140250680858368 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.060549188405275345, loss=0.3096059262752533
I0209 00:00:37.582683 140250672465664 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.11146338284015656, loss=0.23496690392494202
I0209 00:00:43.751561 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:00:45.124680 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:00:46.446887 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:00:47.767463 140466628462400 submission_runner.py:408] Time since start: 5166.49s, 	Step: 21127, 	{'train/ssim': 0.74561950138637, 'train/loss': 0.26815039770943777, 'validation/ssim': 0.7225248372212648, 'validation/loss': 0.287237490437711, 'validation/num_examples': 3554, 'test/ssim': 0.7398913782157568, 'test/loss': 0.2884889297464046, 'test/num_examples': 3581, 'score': 4914.961860656738, 'total_duration': 5166.493827342987, 'accumulated_submission_time': 4914.961860656738, 'accumulated_eval_time': 249.09580183029175, 'accumulated_logging_time': 1.663682460784912}
I0209 00:00:47.788435 140250680858368 logging_writer.py:48] [21127] accumulated_eval_time=249.095802, accumulated_logging_time=1.663682, accumulated_submission_time=4914.961861, global_step=21127, preemption_count=0, score=4914.961861, test/loss=0.288489, test/num_examples=3581, test/ssim=0.739891, total_duration=5166.493827, train/loss=0.268150, train/ssim=0.745620, validation/loss=0.287237, validation/num_examples=3554, validation/ssim=0.722525
I0209 00:01:03.240280 140250672465664 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.10087768733501434, loss=0.2879069745540619
I0209 00:01:26.972353 140250680858368 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.10510419309139252, loss=0.31302040815353394
I0209 00:01:50.739309 140250672465664 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.13356615602970123, loss=0.26431143283843994
I0209 00:02:07.802852 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:02:09.176943 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:02:10.497398 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:02:11.818179 140466628462400 submission_runner.py:408] Time since start: 5250.54s, 	Step: 21473, 	{'train/ssim': 0.7491350173950195, 'train/loss': 0.2679614509854998, 'validation/ssim': 0.7267961303504854, 'validation/loss': 0.28670936631700195, 'validation/num_examples': 3554, 'test/ssim': 0.7438104454281276, 'test/loss': 0.28804823580616445, 'test/num_examples': 3581, 'score': 4994.953593254089, 'total_duration': 5250.544547796249, 'accumulated_submission_time': 4994.953593254089, 'accumulated_eval_time': 253.1110918521881, 'accumulated_logging_time': 1.6949870586395264}
I0209 00:02:11.838476 140250680858368 logging_writer.py:48] [21473] accumulated_eval_time=253.111092, accumulated_logging_time=1.694987, accumulated_submission_time=4994.953593, global_step=21473, preemption_count=0, score=4994.953593, test/loss=0.288048, test/num_examples=3581, test/ssim=0.743810, total_duration=5250.544548, train/loss=0.267961, train/ssim=0.749135, validation/loss=0.286709, validation/num_examples=3554, validation/ssim=0.726796
I0209 00:02:16.305282 140250672465664 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.06595871597528458, loss=0.21806327998638153
I0209 00:02:40.427807 140250680858368 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.11946260184049606, loss=0.2506099343299866
I0209 00:03:04.097291 140250672465664 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.1088399663567543, loss=0.33082449436187744
I0209 00:03:27.569231 140250680858368 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.10681839287281036, loss=0.26854801177978516
I0209 00:03:31.843092 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:03:33.216175 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:03:34.537736 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:03:35.859477 140466628462400 submission_runner.py:408] Time since start: 5334.59s, 	Step: 21819, 	{'train/ssim': 0.7484683990478516, 'train/loss': 0.26748708316258024, 'validation/ssim': 0.7248557825469542, 'validation/loss': 0.287353824750721, 'validation/num_examples': 3554, 'test/ssim': 0.742086053127618, 'test/loss': 0.2886547353872871, 'test/num_examples': 3581, 'score': 5074.936768531799, 'total_duration': 5334.585844755173, 'accumulated_submission_time': 5074.936768531799, 'accumulated_eval_time': 257.1274366378784, 'accumulated_logging_time': 1.7242553234100342}
I0209 00:03:35.879470 140250672465664 logging_writer.py:48] [21819] accumulated_eval_time=257.127437, accumulated_logging_time=1.724255, accumulated_submission_time=5074.936769, global_step=21819, preemption_count=0, score=5074.936769, test/loss=0.288655, test/num_examples=3581, test/ssim=0.742086, total_duration=5334.585845, train/loss=0.267487, train/ssim=0.748468, validation/loss=0.287354, validation/num_examples=3554, validation/ssim=0.724856
I0209 00:03:52.842856 140250680858368 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.1106477901339531, loss=0.231130912899971
I0209 00:04:16.575680 140250672465664 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.14985667169094086, loss=0.24223074316978455
I0209 00:04:40.469586 140250680858368 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.06338973343372345, loss=0.3053286373615265
I0209 00:04:56.038779 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:04:57.411228 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:04:58.732721 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:05:00.052460 140466628462400 submission_runner.py:408] Time since start: 5418.78s, 	Step: 22167, 	{'train/ssim': 0.7472255570547921, 'train/loss': 0.26763953481401714, 'validation/ssim': 0.7242740079399972, 'validation/loss': 0.2866872638279491, 'validation/num_examples': 3554, 'test/ssim': 0.7414715087004329, 'test/loss': 0.28797508224832447, 'test/num_examples': 3581, 'score': 5155.074422121048, 'total_duration': 5418.778828620911, 'accumulated_submission_time': 5155.074422121048, 'accumulated_eval_time': 261.1410791873932, 'accumulated_logging_time': 1.7532122135162354}
I0209 00:05:00.073082 140250672465664 logging_writer.py:48] [22167] accumulated_eval_time=261.141079, accumulated_logging_time=1.753212, accumulated_submission_time=5155.074422, global_step=22167, preemption_count=0, score=5155.074422, test/loss=0.287975, test/num_examples=3581, test/ssim=0.741472, total_duration=5418.778829, train/loss=0.267640, train/ssim=0.747226, validation/loss=0.286687, validation/num_examples=3554, validation/ssim=0.724274
I0209 00:05:06.096249 140250680858368 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.07059487700462341, loss=0.2601071000099182
I0209 00:05:29.902906 140250672465664 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.12689583003520966, loss=0.3299764394760132
I0209 00:05:53.133361 140250680858368 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.0877101942896843, loss=0.22771863639354706
I0209 00:06:17.197758 140250672465664 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.07628148049116135, loss=0.2262013852596283
I0209 00:06:20.203661 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:06:21.577542 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:06:22.900556 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:06:24.222627 140466628462400 submission_runner.py:408] Time since start: 5502.95s, 	Step: 22514, 	{'train/ssim': 0.745988300868443, 'train/loss': 0.26703642095838276, 'validation/ssim': 0.7230816069921215, 'validation/loss': 0.28604563904667274, 'validation/num_examples': 3554, 'test/ssim': 0.7404845151712162, 'test/loss': 0.28727286263438984, 'test/num_examples': 3581, 'score': 5235.182781457901, 'total_duration': 5502.94899559021, 'accumulated_submission_time': 5235.182781457901, 'accumulated_eval_time': 265.16000413894653, 'accumulated_logging_time': 1.7835183143615723}
I0209 00:06:24.242913 140250680858368 logging_writer.py:48] [22514] accumulated_eval_time=265.160004, accumulated_logging_time=1.783518, accumulated_submission_time=5235.182781, global_step=22514, preemption_count=0, score=5235.182781, test/loss=0.287273, test/num_examples=3581, test/ssim=0.740485, total_duration=5502.948996, train/loss=0.267036, train/ssim=0.745988, validation/loss=0.286046, validation/num_examples=3554, validation/ssim=0.723082
I0209 00:06:42.622400 140250672465664 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.04709000140428543, loss=0.21839454770088196
I0209 00:07:06.979229 140250680858368 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.1523749828338623, loss=0.2995602488517761
I0209 00:07:30.682052 140250672465664 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.08441919833421707, loss=0.2654019296169281
I0209 00:07:44.360488 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:07:45.733963 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:07:47.056477 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:07:48.379558 140466628462400 submission_runner.py:408] Time since start: 5587.11s, 	Step: 22859, 	{'train/ssim': 0.7471205166407994, 'train/loss': 0.26667356491088867, 'validation/ssim': 0.7236672284969401, 'validation/loss': 0.2860689608649585, 'validation/num_examples': 3554, 'test/ssim': 0.7409802276773247, 'test/loss': 0.28731458675125665, 'test/num_examples': 3581, 'score': 5315.278612852097, 'total_duration': 5587.105926513672, 'accumulated_submission_time': 5315.278612852097, 'accumulated_eval_time': 269.17903685569763, 'accumulated_logging_time': 1.8133699893951416}
I0209 00:07:48.400406 140250680858368 logging_writer.py:48] [22859] accumulated_eval_time=269.179037, accumulated_logging_time=1.813370, accumulated_submission_time=5315.278613, global_step=22859, preemption_count=0, score=5315.278613, test/loss=0.287315, test/num_examples=3581, test/ssim=0.740980, total_duration=5587.105927, train/loss=0.266674, train/ssim=0.747121, validation/loss=0.286069, validation/num_examples=3554, validation/ssim=0.723667
I0209 00:07:56.154784 140250672465664 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.10690199583768845, loss=0.20703727006912231
I0209 00:08:19.732838 140250680858368 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.10910653322935104, loss=0.2589946687221527
I0209 00:08:43.235416 140250672465664 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.056203700602054596, loss=0.31721389293670654
I0209 00:09:07.039758 140250680858368 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.10723567008972168, loss=0.27419590950012207
I0209 00:09:08.383947 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:09:09.756025 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:09:11.074877 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:09:12.395867 140466628462400 submission_runner.py:408] Time since start: 5671.12s, 	Step: 23207, 	{'train/ssim': 0.7486298424857003, 'train/loss': 0.26704018456595285, 'validation/ssim': 0.7255774880636255, 'validation/loss': 0.2862076209244865, 'validation/num_examples': 3554, 'test/ssim': 0.7427466849780089, 'test/loss': 0.2874790629472389, 'test/num_examples': 3581, 'score': 5395.240823984146, 'total_duration': 5671.12223815918, 'accumulated_submission_time': 5395.240823984146, 'accumulated_eval_time': 273.1909189224243, 'accumulated_logging_time': 1.843076229095459}
I0209 00:09:12.416605 140250672465664 logging_writer.py:48] [23207] accumulated_eval_time=273.190919, accumulated_logging_time=1.843076, accumulated_submission_time=5395.240824, global_step=23207, preemption_count=0, score=5395.240824, test/loss=0.287479, test/num_examples=3581, test/ssim=0.742747, total_duration=5671.122238, train/loss=0.267040, train/ssim=0.748630, validation/loss=0.286208, validation/num_examples=3554, validation/ssim=0.725577
I0209 00:09:32.381937 140250680858368 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.09333814680576324, loss=0.26387831568717957
I0209 00:09:56.124372 140250672465664 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.07925485074520111, loss=0.3022567331790924
I0209 00:10:20.015140 140250680858368 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.0639675110578537, loss=0.27383413910865784
I0209 00:10:32.407264 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:10:33.780316 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:10:35.100411 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:10:36.422756 140466628462400 submission_runner.py:408] Time since start: 5755.15s, 	Step: 23554, 	{'train/ssim': 0.7473702430725098, 'train/loss': 0.26693529742104666, 'validation/ssim': 0.7242064124490011, 'validation/loss': 0.2860737523136343, 'validation/num_examples': 3554, 'test/ssim': 0.7415203231901005, 'test/loss': 0.28728700929166084, 'test/num_examples': 3581, 'score': 5475.210396766663, 'total_duration': 5755.149123430252, 'accumulated_submission_time': 5475.210396766663, 'accumulated_eval_time': 277.20637464523315, 'accumulated_logging_time': 1.8724026679992676}
I0209 00:10:36.443129 140250672465664 logging_writer.py:48] [23554] accumulated_eval_time=277.206375, accumulated_logging_time=1.872403, accumulated_submission_time=5475.210397, global_step=23554, preemption_count=0, score=5475.210397, test/loss=0.287287, test/num_examples=3581, test/ssim=0.741520, total_duration=5755.149123, train/loss=0.266935, train/ssim=0.747370, validation/loss=0.286074, validation/num_examples=3554, validation/ssim=0.724206
I0209 00:10:45.166940 140250680858368 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.06215778738260269, loss=0.2580322027206421
I0209 00:11:09.104154 140250672465664 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.0740109533071518, loss=0.2864527404308319
I0209 00:11:33.063999 140250680858368 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.05653655529022217, loss=0.29270023107528687
I0209 00:11:56.584641 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:11:57.958066 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:11:59.280302 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:12:00.601508 140466628462400 submission_runner.py:408] Time since start: 5839.33s, 	Step: 23899, 	{'train/ssim': 0.7486155373709542, 'train/loss': 0.266871520451137, 'validation/ssim': 0.7250420823148214, 'validation/loss': 0.28631258628042344, 'validation/num_examples': 3554, 'test/ssim': 0.7424447987206786, 'test/loss': 0.28753435421975354, 'test/num_examples': 3581, 'score': 5555.329708099365, 'total_duration': 5839.32786488533, 'accumulated_submission_time': 5555.329708099365, 'accumulated_eval_time': 281.22319531440735, 'accumulated_logging_time': 1.9024322032928467}
I0209 00:12:00.623448 140250672465664 logging_writer.py:48] [23899] accumulated_eval_time=281.223195, accumulated_logging_time=1.902432, accumulated_submission_time=5555.329708, global_step=23899, preemption_count=0, score=5555.329708, test/loss=0.287534, test/num_examples=3581, test/ssim=0.742445, total_duration=5839.327865, train/loss=0.266872, train/ssim=0.748616, validation/loss=0.286313, validation/num_examples=3554, validation/ssim=0.725042
I0209 00:12:00.789210 140250680858368 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.08550761640071869, loss=0.22970300912857056
I0209 00:12:22.821563 140250672465664 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.0376460887491703, loss=0.1900610774755478
I0209 00:12:46.404992 140250680858368 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.03878698870539665, loss=0.35012441873550415
I0209 00:13:10.321672 140250672465664 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.08108685910701752, loss=0.2757056653499603
I0209 00:13:20.618268 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:13:21.992282 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:13:23.313891 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:13:24.634190 140466628462400 submission_runner.py:408] Time since start: 5923.36s, 	Step: 24245, 	{'train/ssim': 0.7487003462655204, 'train/loss': 0.2665752513068063, 'validation/ssim': 0.7254798043357836, 'validation/loss': 0.2859320009968961, 'validation/num_examples': 3554, 'test/ssim': 0.7427145055937587, 'test/loss': 0.28721412844046706, 'test/num_examples': 3581, 'score': 5635.302527427673, 'total_duration': 5923.360556364059, 'accumulated_submission_time': 5635.302527427673, 'accumulated_eval_time': 285.23908710479736, 'accumulated_logging_time': 1.9336822032928467}
I0209 00:13:24.655659 140250680858368 logging_writer.py:48] [24245] accumulated_eval_time=285.239087, accumulated_logging_time=1.933682, accumulated_submission_time=5635.302527, global_step=24245, preemption_count=0, score=5635.302527, test/loss=0.287214, test/num_examples=3581, test/ssim=0.742715, total_duration=5923.360556, train/loss=0.266575, train/ssim=0.748700, validation/loss=0.285932, validation/num_examples=3554, validation/ssim=0.725480
I0209 00:13:35.611584 140250672465664 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.03143882751464844, loss=0.2711777687072754
I0209 00:13:58.805635 140250680858368 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.05864674970507622, loss=0.3313595652580261
I0209 00:14:22.496694 140250672465664 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.08228488266468048, loss=0.30787110328674316
I0209 00:14:44.860543 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:14:46.233627 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:14:47.554872 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:14:48.876324 140466628462400 submission_runner.py:408] Time since start: 6007.60s, 	Step: 24594, 	{'train/ssim': 0.7478156770978656, 'train/loss': 0.26648034368242535, 'validation/ssim': 0.7245771572304094, 'validation/loss': 0.28561767165957375, 'validation/num_examples': 3554, 'test/ssim': 0.7419074302743647, 'test/loss': 0.2868927436579342, 'test/num_examples': 3581, 'score': 5715.485833406448, 'total_duration': 6007.602685213089, 'accumulated_submission_time': 5715.485833406448, 'accumulated_eval_time': 289.2548222541809, 'accumulated_logging_time': 1.9640848636627197}
I0209 00:14:48.898390 140250680858368 logging_writer.py:48] [24594] accumulated_eval_time=289.254822, accumulated_logging_time=1.964085, accumulated_submission_time=5715.485833, global_step=24594, preemption_count=0, score=5715.485833, test/loss=0.286893, test/num_examples=3581, test/ssim=0.741907, total_duration=6007.602685, train/loss=0.266480, train/ssim=0.747816, validation/loss=0.285618, validation/num_examples=3554, validation/ssim=0.724577
I0209 00:14:49.422946 140250672465664 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.09633942693471909, loss=0.17490777373313904
I0209 00:15:12.068103 140250680858368 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.058868274092674255, loss=0.23298059403896332
I0209 00:15:36.150443 140250672465664 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.04439394548535347, loss=0.3209271728992462
I0209 00:16:00.140328 140250680858368 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.08723833411931992, loss=0.3174148499965668
I0209 00:16:08.915716 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:16:10.285437 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:16:11.607478 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:16:12.928943 140466628462400 submission_runner.py:408] Time since start: 6091.66s, 	Step: 24938, 	{'train/ssim': 0.7481376784188407, 'train/loss': 0.26669812202453613, 'validation/ssim': 0.7249912483073649, 'validation/loss': 0.2858955241618159, 'validation/num_examples': 3554, 'test/ssim': 0.7421870909400308, 'test/loss': 0.28722510488297615, 'test/num_examples': 3581, 'score': 5795.482012271881, 'total_duration': 6091.655306100845, 'accumulated_submission_time': 5795.482012271881, 'accumulated_eval_time': 293.2680079936981, 'accumulated_logging_time': 1.9948859214782715}
I0209 00:16:12.953692 140250672465664 logging_writer.py:48] [24938] accumulated_eval_time=293.268008, accumulated_logging_time=1.994886, accumulated_submission_time=5795.482012, global_step=24938, preemption_count=0, score=5795.482012, test/loss=0.287225, test/num_examples=3581, test/ssim=0.742187, total_duration=6091.655306, train/loss=0.266698, train/ssim=0.748138, validation/loss=0.285896, validation/num_examples=3554, validation/ssim=0.724991
I0209 00:16:25.750429 140250680858368 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.08493415266275406, loss=0.25731462240219116
I0209 00:16:49.535937 140250672465664 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.05088777467608452, loss=0.23780792951583862
I0209 00:17:12.916455 140250680858368 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.05779396742582321, loss=0.23482178151607513
I0209 00:17:32.934693 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:17:34.307394 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:17:35.628192 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:17:36.952643 140466628462400 submission_runner.py:408] Time since start: 6175.68s, 	Step: 25284, 	{'train/ssim': 0.7477162906101772, 'train/loss': 0.26642952646527973, 'validation/ssim': 0.7241976882342079, 'validation/loss': 0.2860070498524989, 'validation/num_examples': 3554, 'test/ssim': 0.7414855530927116, 'test/loss': 0.2873365737246056, 'test/num_examples': 3581, 'score': 5875.4409856796265, 'total_duration': 6175.679006099701, 'accumulated_submission_time': 5875.4409856796265, 'accumulated_eval_time': 297.2859468460083, 'accumulated_logging_time': 2.02933931350708}
I0209 00:17:36.975255 140250672465664 logging_writer.py:48] [25284] accumulated_eval_time=297.285947, accumulated_logging_time=2.029339, accumulated_submission_time=5875.440986, global_step=25284, preemption_count=0, score=5875.440986, test/loss=0.287337, test/num_examples=3581, test/ssim=0.741486, total_duration=6175.679006, train/loss=0.266430, train/ssim=0.747716, validation/loss=0.286007, validation/num_examples=3554, validation/ssim=0.724198
I0209 00:17:38.731884 140250680858368 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.07912641763687134, loss=0.29445263743400574
I0209 00:18:02.594071 140250672465664 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.05896295607089996, loss=0.2322271168231964
I0209 00:18:26.592992 140250680858368 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.11207485944032669, loss=0.2563629448413849
I0209 00:18:50.241099 140250672465664 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.07754208892583847, loss=0.22361505031585693
I0209 00:18:57.216022 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:18:58.587785 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:18:59.908343 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:19:01.229800 140466628462400 submission_runner.py:408] Time since start: 6259.96s, 	Step: 25631, 	{'train/ssim': 0.7501141003199986, 'train/loss': 0.26636855942862375, 'validation/ssim': 0.7267898104468556, 'validation/loss': 0.28584886335159326, 'validation/num_examples': 3554, 'test/ssim': 0.7439213006798031, 'test/loss': 0.28717339288519267, 'test/num_examples': 3581, 'score': 5955.660590648651, 'total_duration': 6259.956165790558, 'accumulated_submission_time': 5955.660590648651, 'accumulated_eval_time': 301.29969024658203, 'accumulated_logging_time': 2.0605125427246094}
I0209 00:19:01.252712 140250680858368 logging_writer.py:48] [25631] accumulated_eval_time=301.299690, accumulated_logging_time=2.060513, accumulated_submission_time=5955.660591, global_step=25631, preemption_count=0, score=5955.660591, test/loss=0.287173, test/num_examples=3581, test/ssim=0.743921, total_duration=6259.956166, train/loss=0.266369, train/ssim=0.750114, validation/loss=0.285849, validation/num_examples=3554, validation/ssim=0.726790
I0209 00:19:15.477338 140250672465664 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.04028598591685295, loss=0.27122950553894043
I0209 00:19:39.077432 140250680858368 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.10266327112913132, loss=0.2180894911289215
I0209 00:20:03.274659 140250672465664 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.06498947739601135, loss=0.2831951379776001
I0209 00:20:21.305739 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:20:22.678074 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:20:24.000028 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:20:25.319836 140466628462400 submission_runner.py:408] Time since start: 6344.05s, 	Step: 25976, 	{'train/ssim': 0.748063496180943, 'train/loss': 0.26652256080082487, 'validation/ssim': 0.7249627400464266, 'validation/loss': 0.28572785780546567, 'validation/num_examples': 3554, 'test/ssim': 0.7422536313617006, 'test/loss': 0.286973158030229, 'test/num_examples': 3581, 'score': 6035.690726995468, 'total_duration': 6344.0462028980255, 'accumulated_submission_time': 6035.690726995468, 'accumulated_eval_time': 305.313759803772, 'accumulated_logging_time': 2.0938265323638916}
I0209 00:20:25.341322 140250680858368 logging_writer.py:48] [25976] accumulated_eval_time=305.313760, accumulated_logging_time=2.093827, accumulated_submission_time=6035.690727, global_step=25976, preemption_count=0, score=6035.690727, test/loss=0.286973, test/num_examples=3581, test/ssim=0.742254, total_duration=6344.046203, train/loss=0.266523, train/ssim=0.748063, validation/loss=0.285728, validation/num_examples=3554, validation/ssim=0.724963
I0209 00:20:28.901394 140250672465664 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.045003898441791534, loss=0.36188116669654846
I0209 00:20:52.495597 140250680858368 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.057000886648893356, loss=0.29325878620147705
I0209 00:21:16.216679 140250672465664 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.0610116645693779, loss=0.2901887893676758
I0209 00:21:39.847969 140250680858368 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.06208024173974991, loss=0.245223268866539
I0209 00:21:45.380028 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:21:46.754215 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:21:48.075571 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:21:49.397260 140466628462400 submission_runner.py:408] Time since start: 6428.12s, 	Step: 26325, 	{'train/ssim': 0.7494532721383231, 'train/loss': 0.26556929520198275, 'validation/ssim': 0.7256950932268219, 'validation/loss': 0.28531785405748805, 'validation/num_examples': 3554, 'test/ssim': 0.742955441915666, 'test/loss': 0.2866083447142907, 'test/num_examples': 3581, 'score': 6115.706563234329, 'total_duration': 6428.123630523682, 'accumulated_submission_time': 6115.706563234329, 'accumulated_eval_time': 309.33096265792847, 'accumulated_logging_time': 2.125617742538452}
I0209 00:21:49.418482 140250672465664 logging_writer.py:48] [26325] accumulated_eval_time=309.330963, accumulated_logging_time=2.125618, accumulated_submission_time=6115.706563, global_step=26325, preemption_count=0, score=6115.706563, test/loss=0.286608, test/num_examples=3581, test/ssim=0.742955, total_duration=6428.123631, train/loss=0.265569, train/ssim=0.749453, validation/loss=0.285318, validation/num_examples=3554, validation/ssim=0.725695
I0209 00:22:05.198800 140250680858368 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.056350089609622955, loss=0.33036166429519653
I0209 00:22:28.919342 140250672465664 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.028892746195197105, loss=0.284738689661026
I0209 00:22:52.251649 140250680858368 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.057189542800188065, loss=0.3150210976600647
I0209 00:23:09.417289 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:23:10.789243 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:23:12.111352 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:23:13.432344 140466628462400 submission_runner.py:408] Time since start: 6512.16s, 	Step: 26674, 	{'train/ssim': 0.7486578396388462, 'train/loss': 0.26593317304338726, 'validation/ssim': 0.7254540438590321, 'validation/loss': 0.2852956485265282, 'validation/num_examples': 3554, 'test/ssim': 0.7426701225870916, 'test/loss': 0.28660728797603674, 'test/num_examples': 3581, 'score': 6195.682910203934, 'total_duration': 6512.158713579178, 'accumulated_submission_time': 6195.682910203934, 'accumulated_eval_time': 313.3459963798523, 'accumulated_logging_time': 2.156813144683838}
I0209 00:23:13.453747 140250672465664 logging_writer.py:48] [26674] accumulated_eval_time=313.345996, accumulated_logging_time=2.156813, accumulated_submission_time=6195.682910, global_step=26674, preemption_count=0, score=6195.682910, test/loss=0.286607, test/num_examples=3581, test/ssim=0.742670, total_duration=6512.158714, train/loss=0.265933, train/ssim=0.748658, validation/loss=0.285296, validation/num_examples=3554, validation/ssim=0.725454
I0209 00:23:17.696763 140250680858368 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.09829695522785187, loss=0.248321533203125
I0209 00:23:41.207381 140250672465664 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.062419530004262924, loss=0.22293797135353088
I0209 00:24:04.743720 140250680858368 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.07841471582651138, loss=0.25082460045814514
I0209 00:24:29.404110 140250672465664 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.050284843891859055, loss=0.25490012764930725
I0209 00:24:33.474384 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:24:34.849833 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:24:36.173168 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:24:37.495916 140466628462400 submission_runner.py:408] Time since start: 6596.22s, 	Step: 27018, 	{'train/ssim': 0.7490175792149135, 'train/loss': 0.2657155820301601, 'validation/ssim': 0.725519784595702, 'validation/loss': 0.2851643903106535, 'validation/num_examples': 3554, 'test/ssim': 0.7428295877984502, 'test/loss': 0.2864416186884774, 'test/num_examples': 3581, 'score': 6275.682108402252, 'total_duration': 6596.222285270691, 'accumulated_submission_time': 6275.682108402252, 'accumulated_eval_time': 317.3675000667572, 'accumulated_logging_time': 2.1871368885040283}
I0209 00:24:37.517293 140250680858368 logging_writer.py:48] [27018] accumulated_eval_time=317.367500, accumulated_logging_time=2.187137, accumulated_submission_time=6275.682108, global_step=27018, preemption_count=0, score=6275.682108, test/loss=0.286442, test/num_examples=3581, test/ssim=0.742830, total_duration=6596.222285, train/loss=0.265716, train/ssim=0.749018, validation/loss=0.285164, validation/num_examples=3554, validation/ssim=0.725520
I0209 00:24:54.814017 140250672465664 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.07302994281053543, loss=0.29172250628471375
I0209 00:25:19.028738 140250680858368 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.0628771260380745, loss=0.2669612765312195
I0209 00:25:42.949155 140250672465664 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.08196724206209183, loss=0.2502622902393341
I0209 00:25:57.725884 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:25:59.098404 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:26:00.421275 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:26:01.745213 140466628462400 submission_runner.py:408] Time since start: 6680.47s, 	Step: 27364, 	{'train/ssim': 0.7507955006190709, 'train/loss': 0.26533545766557964, 'validation/ssim': 0.7269669738323016, 'validation/loss': 0.28537712032766777, 'validation/num_examples': 3554, 'test/ssim': 0.744054381523143, 'test/loss': 0.2866985083491867, 'test/num_examples': 3581, 'score': 6355.869081735611, 'total_duration': 6680.471506595612, 'accumulated_submission_time': 6355.869081735611, 'accumulated_eval_time': 321.38672494888306, 'accumulated_logging_time': 2.217285633087158}
I0209 00:26:01.775467 140250680858368 logging_writer.py:48] [27364] accumulated_eval_time=321.386725, accumulated_logging_time=2.217286, accumulated_submission_time=6355.869082, global_step=27364, preemption_count=0, score=6355.869082, test/loss=0.286699, test/num_examples=3581, test/ssim=0.744054, total_duration=6680.471507, train/loss=0.265335, train/ssim=0.750796, validation/loss=0.285377, validation/num_examples=3554, validation/ssim=0.726967
I0209 00:26:08.169202 140250672465664 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.05055329203605652, loss=0.24884851276874542
I0209 00:26:31.726945 140250680858368 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.08564859628677368, loss=0.36643677949905396
I0209 00:26:55.641709 140250672465664 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.03912016749382019, loss=0.28391486406326294
I0209 00:27:19.682139 140250680858368 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.0783923789858818, loss=0.3065643310546875
I0209 00:27:21.921451 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:27:23.292098 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:27:24.612547 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:27:25.934697 140466628462400 submission_runner.py:408] Time since start: 6764.66s, 	Step: 27711, 	{'train/ssim': 0.7491722106933594, 'train/loss': 0.26562431880405973, 'validation/ssim': 0.7254776748030388, 'validation/loss': 0.28529126924548043, 'validation/num_examples': 3554, 'test/ssim': 0.7427899771580914, 'test/loss': 0.28654374732747484, 'test/num_examples': 3581, 'score': 6435.99257683754, 'total_duration': 6764.661067485809, 'accumulated_submission_time': 6435.99257683754, 'accumulated_eval_time': 325.39993500709534, 'accumulated_logging_time': 2.257634401321411}
I0209 00:27:25.956555 140250672465664 logging_writer.py:48] [27711] accumulated_eval_time=325.399935, accumulated_logging_time=2.257634, accumulated_submission_time=6435.992577, global_step=27711, preemption_count=0, score=6435.992577, test/loss=0.286544, test/num_examples=3581, test/ssim=0.742790, total_duration=6764.661067, train/loss=0.265624, train/ssim=0.749172, validation/loss=0.285291, validation/num_examples=3554, validation/ssim=0.725478
I0209 00:27:44.940159 140250680858368 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.06401489675045013, loss=0.26750725507736206
I0209 00:28:08.830320 140250672465664 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.0625610426068306, loss=0.25887835025787354
I0209 00:28:32.649184 140250680858368 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.05587850511074066, loss=0.17756213247776031
I0209 00:28:46.096949 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:28:47.472041 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:28:48.794892 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:28:50.114271 140466628462400 submission_runner.py:408] Time since start: 6848.84s, 	Step: 28058, 	{'train/ssim': 0.7488178525652204, 'train/loss': 0.265708327293396, 'validation/ssim': 0.7253711294711944, 'validation/loss': 0.2851588260476752, 'validation/num_examples': 3554, 'test/ssim': 0.7426109452448687, 'test/loss': 0.28645293601429417, 'test/num_examples': 3581, 'score': 6516.111511468887, 'total_duration': 6848.8406393527985, 'accumulated_submission_time': 6516.111511468887, 'accumulated_eval_time': 329.4172194004059, 'accumulated_logging_time': 2.288557529449463}
I0209 00:28:50.136061 140250672465664 logging_writer.py:48] [28058] accumulated_eval_time=329.417219, accumulated_logging_time=2.288558, accumulated_submission_time=6516.111511, global_step=28058, preemption_count=0, score=6516.111511, test/loss=0.286453, test/num_examples=3581, test/ssim=0.742611, total_duration=6848.840639, train/loss=0.265708, train/ssim=0.748818, validation/loss=0.285159, validation/num_examples=3554, validation/ssim=0.725371
I0209 00:28:58.168366 140250680858368 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.05002763122320175, loss=0.2390829473733902
I0209 00:29:22.112737 140250672465664 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.06189746409654617, loss=0.3104751408100128
I0209 00:29:45.854460 140250680858368 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.05057096481323242, loss=0.3096959590911865
I0209 00:30:09.782484 140250672465664 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.056189052760601044, loss=0.32256680727005005
I0209 00:30:10.172907 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:30:11.546453 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:30:12.867653 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:30:14.189984 140466628462400 submission_runner.py:408] Time since start: 6932.92s, 	Step: 28403, 	{'train/ssim': 0.750096184866769, 'train/loss': 0.26494128363473074, 'validation/ssim': 0.7260181639525887, 'validation/loss': 0.2850630829424152, 'validation/num_examples': 3554, 'test/ssim': 0.7432273986185772, 'test/loss': 0.28636297690938284, 'test/num_examples': 3581, 'score': 6596.127126693726, 'total_duration': 6932.916352748871, 'accumulated_submission_time': 6596.127126693726, 'accumulated_eval_time': 333.43426752090454, 'accumulated_logging_time': 2.3191332817077637}
I0209 00:30:14.212277 140250680858368 logging_writer.py:48] [28403] accumulated_eval_time=333.434268, accumulated_logging_time=2.319133, accumulated_submission_time=6596.127127, global_step=28403, preemption_count=0, score=6596.127127, test/loss=0.286363, test/num_examples=3581, test/ssim=0.743227, total_duration=6932.916353, train/loss=0.264941, train/ssim=0.750096, validation/loss=0.285063, validation/num_examples=3554, validation/ssim=0.726018
I0209 00:30:35.084435 140250672465664 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.05866271257400513, loss=0.2879656255245209
I0209 00:30:58.795370 140250680858368 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.08506476134061813, loss=0.31752923130989075
I0209 00:31:22.259963 140250672465664 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.040571507066488266, loss=0.2919524013996124
I0209 00:31:34.216975 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:31:35.588351 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:31:36.911910 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:31:38.235915 140466628462400 submission_runner.py:408] Time since start: 7016.96s, 	Step: 28752, 	{'train/ssim': 0.7498783384050641, 'train/loss': 0.2653285094669887, 'validation/ssim': 0.7260880263655388, 'validation/loss': 0.2851461862404157, 'validation/num_examples': 3554, 'test/ssim': 0.7432734178651215, 'test/loss': 0.2864265857346063, 'test/num_examples': 3581, 'score': 6676.110071659088, 'total_duration': 7016.962255001068, 'accumulated_submission_time': 6676.110071659088, 'accumulated_eval_time': 337.45313835144043, 'accumulated_logging_time': 2.350611448287964}
I0209 00:31:38.260767 140250680858368 logging_writer.py:48] [28752] accumulated_eval_time=337.453138, accumulated_logging_time=2.350611, accumulated_submission_time=6676.110072, global_step=28752, preemption_count=0, score=6676.110072, test/loss=0.286427, test/num_examples=3581, test/ssim=0.743273, total_duration=7016.962255, train/loss=0.265329, train/ssim=0.749878, validation/loss=0.285146, validation/num_examples=3554, validation/ssim=0.726088
I0209 00:31:47.632505 140250672465664 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.046778157353401184, loss=0.23057116568088531
I0209 00:32:11.365010 140250680858368 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.03973928466439247, loss=0.24967624247074127
I0209 00:32:35.020298 140250672465664 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.030941341072320938, loss=0.2909608781337738
I0209 00:32:58.340839 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:32:59.713752 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:33:01.036393 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:33:02.359128 140466628462400 submission_runner.py:408] Time since start: 7101.09s, 	Step: 29100, 	{'train/ssim': 0.749572617667062, 'train/loss': 0.2654174736567906, 'validation/ssim': 0.726090087203679, 'validation/loss': 0.28512384332024654, 'validation/num_examples': 3554, 'test/ssim': 0.7432643503691357, 'test/loss': 0.2863883045391476, 'test/num_examples': 3581, 'score': 6756.167396783829, 'total_duration': 7101.085487127304, 'accumulated_submission_time': 6756.167396783829, 'accumulated_eval_time': 341.47138237953186, 'accumulated_logging_time': 2.385899305343628}
I0209 00:33:02.382103 140250680858368 logging_writer.py:48] [29100] accumulated_eval_time=341.471382, accumulated_logging_time=2.385899, accumulated_submission_time=6756.167397, global_step=29100, preemption_count=0, score=6756.167397, test/loss=0.286388, test/num_examples=3581, test/ssim=0.743264, total_duration=7101.085487, train/loss=0.265417, train/ssim=0.749573, validation/loss=0.285124, validation/num_examples=3554, validation/ssim=0.726090
I0209 00:33:02.471732 140250672465664 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.05823387950658798, loss=0.23835690319538116
I0209 00:33:24.421040 140250680858368 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.05796428397297859, loss=0.24674347043037415
I0209 00:33:48.179316 140250672465664 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.039825718849897385, loss=0.27691227197647095
I0209 00:34:11.906825 140250680858368 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.057665906846523285, loss=0.1974036544561386
I0209 00:34:22.494967 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:34:23.868277 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:34:25.191312 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:34:26.515928 140466628462400 submission_runner.py:408] Time since start: 7185.24s, 	Step: 29446, 	{'train/ssim': 0.7507331030709403, 'train/loss': 0.26469450337546213, 'validation/ssim': 0.7265406551157146, 'validation/loss': 0.2850275850054516, 'validation/num_examples': 3554, 'test/ssim': 0.7437386554035186, 'test/loss': 0.28629469798284346, 'test/num_examples': 3581, 'score': 6836.258863449097, 'total_duration': 7185.242262125015, 'accumulated_submission_time': 6836.258863449097, 'accumulated_eval_time': 345.49227356910706, 'accumulated_logging_time': 2.417950391769409}
I0209 00:34:26.542199 140250672465664 logging_writer.py:48] [29446] accumulated_eval_time=345.492274, accumulated_logging_time=2.417950, accumulated_submission_time=6836.258863, global_step=29446, preemption_count=0, score=6836.258863, test/loss=0.286295, test/num_examples=3581, test/ssim=0.743739, total_duration=7185.242262, train/loss=0.264695, train/ssim=0.750733, validation/loss=0.285028, validation/num_examples=3554, validation/ssim=0.726541
I0209 00:34:37.121455 140250680858368 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.05920654162764549, loss=0.22455748915672302
I0209 00:35:00.944671 140250672465664 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.05203884840011597, loss=0.26177534461021423
I0209 00:35:24.693658 140250680858368 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.039252642542123795, loss=0.30365443229675293
I0209 00:35:46.650236 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:35:48.025552 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:35:49.348333 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:35:50.669966 140466628462400 submission_runner.py:408] Time since start: 7269.40s, 	Step: 29793, 	{'train/ssim': 0.7498508180890765, 'train/loss': 0.2650007350104196, 'validation/ssim': 0.7257677034239589, 'validation/loss': 0.28504956727894626, 'validation/num_examples': 3554, 'test/ssim': 0.7430140738445965, 'test/loss': 0.2863362857463872, 'test/num_examples': 3581, 'score': 6916.343825817108, 'total_duration': 7269.396333932877, 'accumulated_submission_time': 6916.343825817108, 'accumulated_eval_time': 349.51197695732117, 'accumulated_logging_time': 2.4548652172088623}
I0209 00:35:50.692272 140250672465664 logging_writer.py:48] [29793] accumulated_eval_time=349.511977, accumulated_logging_time=2.454865, accumulated_submission_time=6916.343826, global_step=29793, preemption_count=0, score=6916.343826, test/loss=0.286336, test/num_examples=3581, test/ssim=0.743014, total_duration=7269.396334, train/loss=0.265001, train/ssim=0.749851, validation/loss=0.285050, validation/num_examples=3554, validation/ssim=0.725768
I0209 00:35:51.292769 140250680858368 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.0315299853682518, loss=0.2572862505912781
I0209 00:36:14.100742 140250672465664 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.04269176349043846, loss=0.23995597660541534
I0209 00:36:37.786589 140250680858368 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.02862688899040222, loss=0.2951146066188812
I0209 00:37:01.325591 140250672465664 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.028501851484179497, loss=0.24961142241954803
I0209 00:37:10.853432 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:37:12.227756 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:37:13.548696 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:37:14.871805 140466628462400 submission_runner.py:408] Time since start: 7353.60s, 	Step: 30142, 	{'train/ssim': 0.7498049054827008, 'train/loss': 0.26504012516566683, 'validation/ssim': 0.7257995777205262, 'validation/loss': 0.2849661376815736, 'validation/num_examples': 3554, 'test/ssim': 0.7429910301329936, 'test/loss': 0.2862814035338418, 'test/num_examples': 3581, 'score': 6996.4826691150665, 'total_duration': 7353.598170042038, 'accumulated_submission_time': 6996.4826691150665, 'accumulated_eval_time': 353.5303068161011, 'accumulated_logging_time': 2.487074136734009}
I0209 00:37:14.894335 140250680858368 logging_writer.py:48] [30142] accumulated_eval_time=353.530307, accumulated_logging_time=2.487074, accumulated_submission_time=6996.482669, global_step=30142, preemption_count=0, score=6996.482669, test/loss=0.286281, test/num_examples=3581, test/ssim=0.742991, total_duration=7353.598170, train/loss=0.265040, train/ssim=0.749805, validation/loss=0.284966, validation/num_examples=3554, validation/ssim=0.725800
I0209 00:37:26.650838 140250672465664 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.05722585693001747, loss=0.2565717101097107
I0209 00:37:50.670256 140250680858368 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.0772661417722702, loss=0.18032921850681305
I0209 00:38:14.562001 140250672465664 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.047192711383104324, loss=0.25408315658569336
I0209 00:38:34.908837 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:38:36.283159 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:38:37.604795 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:38:38.926487 140466628462400 submission_runner.py:408] Time since start: 7437.65s, 	Step: 30488, 	{'train/ssim': 0.7510360990251813, 'train/loss': 0.26464840344020296, 'validation/ssim': 0.7266652671285875, 'validation/loss': 0.28505743281118107, 'validation/num_examples': 3554, 'test/ssim': 0.7437524952658127, 'test/loss': 0.286356636479859, 'test/num_examples': 3581, 'score': 7076.474865198135, 'total_duration': 7437.652813434601, 'accumulated_submission_time': 7076.474865198135, 'accumulated_eval_time': 357.5478813648224, 'accumulated_logging_time': 2.5196094512939453}
I0209 00:38:38.953327 140250680858368 logging_writer.py:48] [30488] accumulated_eval_time=357.547881, accumulated_logging_time=2.519609, accumulated_submission_time=7076.474865, global_step=30488, preemption_count=0, score=7076.474865, test/loss=0.286357, test/num_examples=3581, test/ssim=0.743752, total_duration=7437.652813, train/loss=0.264648, train/ssim=0.751036, validation/loss=0.285057, validation/num_examples=3554, validation/ssim=0.726665
I0209 00:38:39.920777 140250672465664 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.04229012131690979, loss=0.21700018644332886
I0209 00:39:03.559659 140250680858368 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.033401161432266235, loss=0.34414952993392944
I0209 00:39:27.253996 140250672465664 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.026871507987380028, loss=0.2858320474624634
I0209 00:39:51.022088 140250680858368 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.04225099831819534, loss=0.3234686255455017
I0209 00:39:59.055283 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:40:00.428856 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:40:01.751631 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:40:03.074931 140466628462400 submission_runner.py:408] Time since start: 7521.80s, 	Step: 30836, 	{'train/ssim': 0.7507091249738421, 'train/loss': 0.26479778970990864, 'validation/ssim': 0.7265978090268008, 'validation/loss': 0.2849529483174768, 'validation/num_examples': 3554, 'test/ssim': 0.7437485410194429, 'test/loss': 0.2862277144128735, 'test/num_examples': 3581, 'score': 7156.552713394165, 'total_duration': 7521.801300287247, 'accumulated_submission_time': 7156.552713394165, 'accumulated_eval_time': 361.56754517555237, 'accumulated_logging_time': 2.5578672885894775}
I0209 00:40:03.097503 140250672465664 logging_writer.py:48] [30836] accumulated_eval_time=361.567545, accumulated_logging_time=2.557867, accumulated_submission_time=7156.552713, global_step=30836, preemption_count=0, score=7156.552713, test/loss=0.286228, test/num_examples=3581, test/ssim=0.743749, total_duration=7521.801300, train/loss=0.264798, train/ssim=0.750709, validation/loss=0.284953, validation/num_examples=3554, validation/ssim=0.726598
I0209 00:40:16.290108 140250680858368 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.03026672825217247, loss=0.24815905094146729
I0209 00:40:40.424524 140250672465664 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.034445811063051224, loss=0.2907438278198242
I0209 00:41:04.083139 140250680858368 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.04088440164923668, loss=0.20346802473068237
I0209 00:41:23.251903 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:41:24.626087 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:41:25.945853 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:41:27.267208 140466628462400 submission_runner.py:408] Time since start: 7605.99s, 	Step: 31182, 	{'train/ssim': 0.750427109854562, 'train/loss': 0.264832649912153, 'validation/ssim': 0.7264883098269556, 'validation/loss': 0.28488401328168966, 'validation/num_examples': 3554, 'test/ssim': 0.743651730160046, 'test/loss': 0.2861480499838558, 'test/num_examples': 3581, 'score': 7236.6859402656555, 'total_duration': 7605.993559360504, 'accumulated_submission_time': 7236.6859402656555, 'accumulated_eval_time': 365.5828056335449, 'accumulated_logging_time': 2.589299201965332}
I0209 00:41:27.290203 140250672465664 logging_writer.py:48] [31182] accumulated_eval_time=365.582806, accumulated_logging_time=2.589299, accumulated_submission_time=7236.685940, global_step=31182, preemption_count=0, score=7236.685940, test/loss=0.286148, test/num_examples=3581, test/ssim=0.743652, total_duration=7605.993559, train/loss=0.264833, train/ssim=0.750427, validation/loss=0.284884, validation/num_examples=3554, validation/ssim=0.726488
I0209 00:41:29.589237 140250680858368 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.027888931334018707, loss=0.19065088033676147
I0209 00:41:53.251530 140250672465664 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.03261551260948181, loss=0.306118905544281
I0209 00:42:16.917052 140250680858368 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.041127558797597885, loss=0.1899925023317337
I0209 00:42:40.767222 140250672465664 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.025253113359212875, loss=0.3265172243118286
I0209 00:42:47.329420 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:42:48.703499 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:42:50.023897 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:42:51.342478 140466628462400 submission_runner.py:408] Time since start: 7690.07s, 	Step: 31529, 	{'train/ssim': 0.7505290167672294, 'train/loss': 0.2645143951688494, 'validation/ssim': 0.7261004600889842, 'validation/loss': 0.2849139813029773, 'validation/num_examples': 3554, 'test/ssim': 0.7432802355312762, 'test/loss': 0.28622055586341105, 'test/num_examples': 3581, 'score': 7316.703558444977, 'total_duration': 7690.068843841553, 'accumulated_submission_time': 7316.703558444977, 'accumulated_eval_time': 369.5958352088928, 'accumulated_logging_time': 2.6212565898895264}
I0209 00:42:51.364802 140250680858368 logging_writer.py:48] [31529] accumulated_eval_time=369.595835, accumulated_logging_time=2.621257, accumulated_submission_time=7316.703558, global_step=31529, preemption_count=0, score=7316.703558, test/loss=0.286221, test/num_examples=3581, test/ssim=0.743280, total_duration=7690.068844, train/loss=0.264514, train/ssim=0.750529, validation/loss=0.284914, validation/num_examples=3554, validation/ssim=0.726100
I0209 00:43:06.454813 140250672465664 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.02986159920692444, loss=0.22463378310203552
I0209 00:43:30.013028 140250680858368 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.029527004808187485, loss=0.23015683889389038
I0209 00:43:53.703004 140250672465664 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.024275926873087883, loss=0.24435469508171082
I0209 00:44:11.443582 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:44:12.818567 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:44:14.139257 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:44:15.461976 140466628462400 submission_runner.py:408] Time since start: 7774.19s, 	Step: 31876, 	{'train/ssim': 0.7509726115635463, 'train/loss': 0.26455514771597727, 'validation/ssim': 0.7267222149558596, 'validation/loss': 0.2848580295474729, 'validation/num_examples': 3554, 'test/ssim': 0.7438690091803966, 'test/loss': 0.28612408588732197, 'test/num_examples': 3581, 'score': 7396.760830163956, 'total_duration': 7774.188344955444, 'accumulated_submission_time': 7396.760830163956, 'accumulated_eval_time': 373.6141917705536, 'accumulated_logging_time': 2.6523241996765137}
I0209 00:44:15.485051 140250680858368 logging_writer.py:48] [31876] accumulated_eval_time=373.614192, accumulated_logging_time=2.652324, accumulated_submission_time=7396.760830, global_step=31876, preemption_count=0, score=7396.760830, test/loss=0.286124, test/num_examples=3581, test/ssim=0.743869, total_duration=7774.188345, train/loss=0.264555, train/ssim=0.750973, validation/loss=0.284858, validation/num_examples=3554, validation/ssim=0.726722
I0209 00:44:19.150907 140250672465664 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.024925921112298965, loss=0.29814669489860535
I0209 00:44:42.812593 140250680858368 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.030342012643814087, loss=0.3039839565753937
I0209 00:45:06.758045 140250672465664 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.036220233887434006, loss=0.3116237223148346
I0209 00:45:30.440112 140250680858368 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.03433847427368164, loss=0.21966160833835602
I0209 00:45:35.665042 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:45:37.037759 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:45:38.360484 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:45:39.681844 140466628462400 submission_runner.py:408] Time since start: 7858.41s, 	Step: 32223, 	{'train/ssim': 0.7508950233459473, 'train/loss': 0.26465926851545063, 'validation/ssim': 0.7267572492042417, 'validation/loss': 0.2848581497630311, 'validation/num_examples': 3554, 'test/ssim': 0.7439353450720818, 'test/loss': 0.2861133821514591, 'test/num_examples': 3581, 'score': 7476.919148206711, 'total_duration': 7858.408213853836, 'accumulated_submission_time': 7476.919148206711, 'accumulated_eval_time': 377.63095784187317, 'accumulated_logging_time': 2.6843929290771484}
I0209 00:45:39.705442 140250672465664 logging_writer.py:48] [32223] accumulated_eval_time=377.630958, accumulated_logging_time=2.684393, accumulated_submission_time=7476.919148, global_step=32223, preemption_count=0, score=7476.919148, test/loss=0.286113, test/num_examples=3581, test/ssim=0.743935, total_duration=7858.408214, train/loss=0.264659, train/ssim=0.750895, validation/loss=0.284858, validation/num_examples=3554, validation/ssim=0.726757
I0209 00:45:55.799059 140250680858368 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.0275875311344862, loss=0.2768348753452301
I0209 00:46:19.943659 140250672465664 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.027351081371307373, loss=0.26065078377723694
I0209 00:46:43.793526 140250680858368 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.02121303416788578, loss=0.3058762550354004
I0209 00:46:59.877470 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:47:01.250480 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:47:02.574060 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:47:03.895596 140466628462400 submission_runner.py:408] Time since start: 7942.62s, 	Step: 32569, 	{'train/ssim': 0.750824110848563, 'train/loss': 0.26461204460689, 'validation/ssim': 0.7265723920230726, 'validation/loss': 0.28489869675343804, 'validation/num_examples': 3554, 'test/ssim': 0.7437707666111072, 'test/loss': 0.2861683666289968, 'test/num_examples': 3581, 'score': 7557.069484472275, 'total_duration': 7942.621923923492, 'accumulated_submission_time': 7557.069484472275, 'accumulated_eval_time': 381.6490135192871, 'accumulated_logging_time': 2.7174501419067383}
I0209 00:47:03.923100 140250672465664 logging_writer.py:48] [32569] accumulated_eval_time=381.649014, accumulated_logging_time=2.717450, accumulated_submission_time=7557.069484, global_step=32569, preemption_count=0, score=7557.069484, test/loss=0.286168, test/num_examples=3581, test/ssim=0.743771, total_duration=7942.621924, train/loss=0.264612, train/ssim=0.750824, validation/loss=0.284899, validation/num_examples=3554, validation/ssim=0.726572
I0209 00:47:09.136954 140250680858368 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.02422933652997017, loss=0.26866239309310913
I0209 00:47:32.760955 140250672465664 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.020004350692033768, loss=0.26060283184051514
I0209 00:47:56.113409 140250680858368 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.024486910551786423, loss=0.230632022023201
I0209 00:48:19.903623 140250672465664 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.023210013285279274, loss=0.24613606929779053
I0209 00:48:23.936312 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:48:25.309403 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:48:26.632818 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:48:27.955019 140466628462400 submission_runner.py:408] Time since start: 8026.68s, 	Step: 32918, 	{'train/ssim': 0.7510066713605609, 'train/loss': 0.26437413692474365, 'validation/ssim': 0.7264729222355093, 'validation/loss': 0.2848729706239888, 'validation/num_examples': 3554, 'test/ssim': 0.7436541845198618, 'test/loss': 0.2862069887077632, 'test/num_examples': 3581, 'score': 7637.059919595718, 'total_duration': 8026.681388616562, 'accumulated_submission_time': 7637.059919595718, 'accumulated_eval_time': 385.66769075393677, 'accumulated_logging_time': 2.7551095485687256}
I0209 00:48:27.977715 140250680858368 logging_writer.py:48] [32918] accumulated_eval_time=385.667691, accumulated_logging_time=2.755110, accumulated_submission_time=7637.059920, global_step=32918, preemption_count=0, score=7637.059920, test/loss=0.286207, test/num_examples=3581, test/ssim=0.743654, total_duration=8026.681389, train/loss=0.264374, train/ssim=0.751007, validation/loss=0.284873, validation/num_examples=3554, validation/ssim=0.726473
I0209 00:48:45.463940 140250672465664 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.030608084052801132, loss=0.3221043050289154
I0209 00:49:09.485338 140250680858368 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.023903632536530495, loss=0.2557535171508789
I0209 00:49:33.230632 140250672465664 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.019006311893463135, loss=0.32951614260673523
I0209 00:49:48.030949 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:49:49.404091 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:49:50.724665 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:49:52.045927 140466628462400 submission_runner.py:408] Time since start: 8110.77s, 	Step: 33264, 	{'train/ssim': 0.7508365086146763, 'train/loss': 0.2644939933504377, 'validation/ssim': 0.7264935993115152, 'validation/loss': 0.2848100635397615, 'validation/num_examples': 3554, 'test/ssim': 0.7436945451034976, 'test/loss': 0.28606838555483804, 'test/num_examples': 3581, 'score': 7717.092004537582, 'total_duration': 8110.772299528122, 'accumulated_submission_time': 7717.092004537582, 'accumulated_eval_time': 389.682653427124, 'accumulated_logging_time': 2.786450147628784}
I0209 00:49:52.068485 140250680858368 logging_writer.py:48] [33264] accumulated_eval_time=389.682653, accumulated_logging_time=2.786450, accumulated_submission_time=7717.092005, global_step=33264, preemption_count=0, score=7717.092005, test/loss=0.286068, test/num_examples=3581, test/ssim=0.743695, total_duration=8110.772300, train/loss=0.264494, train/ssim=0.750837, validation/loss=0.284810, validation/num_examples=3554, validation/ssim=0.726494
I0209 00:49:58.419290 140250672465664 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.030595185235142708, loss=0.19720757007598877
I0209 00:50:22.341239 140250680858368 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.037068065255880356, loss=0.26650384068489075
I0209 00:50:46.087121 140250672465664 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.02504817768931389, loss=0.25287875533103943
I0209 00:51:10.260711 140250680858368 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.032768361270427704, loss=0.28517070412635803
I0209 00:51:12.216705 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:51:13.592709 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:51:14.915740 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:51:16.237460 140466628462400 submission_runner.py:408] Time since start: 8194.96s, 	Step: 33610, 	{'train/ssim': 0.7514575549534389, 'train/loss': 0.264496956552778, 'validation/ssim': 0.7271822627233399, 'validation/loss': 0.28493361078626195, 'validation/num_examples': 3554, 'test/ssim': 0.7443005674479893, 'test/loss': 0.28621189742739456, 'test/num_examples': 3581, 'score': 7797.218616485596, 'total_duration': 8194.963827133179, 'accumulated_submission_time': 7797.218616485596, 'accumulated_eval_time': 393.70337677001953, 'accumulated_logging_time': 2.8181211948394775}
I0209 00:51:16.261280 140250672465664 logging_writer.py:48] [33610] accumulated_eval_time=393.703377, accumulated_logging_time=2.818121, accumulated_submission_time=7797.218616, global_step=33610, preemption_count=0, score=7797.218616, test/loss=0.286212, test/num_examples=3581, test/ssim=0.744301, total_duration=8194.963827, train/loss=0.264497, train/ssim=0.751458, validation/loss=0.284934, validation/num_examples=3554, validation/ssim=0.727182
I0209 00:51:35.593442 140250680858368 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.01598544232547283, loss=0.24527454376220703
I0209 00:51:59.489090 140250672465664 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.023171940818428993, loss=0.32647615671157837
I0209 00:52:23.039439 140250680858368 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.018504278734326363, loss=0.21318630874156952
I0209 00:52:36.447433 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:52:37.819685 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:52:39.140581 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:52:40.461982 140466628462400 submission_runner.py:408] Time since start: 8279.19s, 	Step: 33958, 	{'train/ssim': 0.7513347353254046, 'train/loss': 0.2641548088618687, 'validation/ssim': 0.7267312139490715, 'validation/loss': 0.28475407743695486, 'validation/num_examples': 3554, 'test/ssim': 0.7438889167655682, 'test/loss': 0.286054988840844, 'test/num_examples': 3581, 'score': 7877.383341789246, 'total_duration': 8279.188350439072, 'accumulated_submission_time': 7877.383341789246, 'accumulated_eval_time': 397.71788907051086, 'accumulated_logging_time': 2.850908041000366}
I0209 00:52:40.485344 140250672465664 logging_writer.py:48] [33958] accumulated_eval_time=397.717889, accumulated_logging_time=2.850908, accumulated_submission_time=7877.383342, global_step=33958, preemption_count=0, score=7877.383342, test/loss=0.286055, test/num_examples=3581, test/ssim=0.743889, total_duration=8279.188350, train/loss=0.264155, train/ssim=0.751335, validation/loss=0.284754, validation/num_examples=3554, validation/ssim=0.726731
I0209 00:52:48.403427 140250680858368 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.0167448278516531, loss=0.2619696855545044
I0209 00:53:12.483681 140250672465664 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.02072739228606224, loss=0.2226749062538147
I0209 00:53:36.187993 140250680858368 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.020913995802402496, loss=0.23096850514411926
I0209 00:53:59.953296 140250672465664 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.012468062341213226, loss=0.24961864948272705
I0209 00:54:00.576096 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:54:01.947318 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:54:03.268193 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:54:04.591842 140466628462400 submission_runner.py:408] Time since start: 8363.32s, 	Step: 34304, 	{'train/ssim': 0.7511395045689174, 'train/loss': 0.2642734391348703, 'validation/ssim': 0.7266988587902715, 'validation/loss': 0.28475948713707266, 'validation/num_examples': 3554, 'test/ssim': 0.7438610325109956, 'test/loss': 0.2860153782004852, 'test/num_examples': 3581, 'score': 7957.451696395874, 'total_duration': 8363.3182117939, 'accumulated_submission_time': 7957.451696395874, 'accumulated_eval_time': 401.73359990119934, 'accumulated_logging_time': 2.884448528289795}
I0209 00:54:04.616465 140250680858368 logging_writer.py:48] [34304] accumulated_eval_time=401.733600, accumulated_logging_time=2.884449, accumulated_submission_time=7957.451696, global_step=34304, preemption_count=0, score=7957.451696, test/loss=0.286015, test/num_examples=3581, test/ssim=0.743861, total_duration=8363.318212, train/loss=0.264273, train/ssim=0.751140, validation/loss=0.284759, validation/num_examples=3554, validation/ssim=0.726699
I0209 00:54:25.638227 140250672465664 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.021567028015851974, loss=0.18628540635108948
I0209 00:54:49.398040 140250680858368 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.030959520488977432, loss=0.2482154369354248
I0209 00:55:13.797728 140250672465664 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.020359335467219353, loss=0.22381728887557983
I0209 00:55:24.638929 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:55:26.013963 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:55:27.334436 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:55:28.655821 140466628462400 submission_runner.py:408] Time since start: 8447.38s, 	Step: 34647, 	{'train/ssim': 0.7512046950204032, 'train/loss': 0.26424758774893625, 'validation/ssim': 0.7267843835730866, 'validation/loss': 0.2847093915966165, 'validation/num_examples': 3554, 'test/ssim': 0.7439592750802848, 'test/loss': 0.2859457016523841, 'test/num_examples': 3581, 'score': 8037.453133821487, 'total_duration': 8447.382189512253, 'accumulated_submission_time': 8037.453133821487, 'accumulated_eval_time': 405.75045943260193, 'accumulated_logging_time': 2.918001174926758}
I0209 00:55:28.678966 140250680858368 logging_writer.py:48] [34647] accumulated_eval_time=405.750459, accumulated_logging_time=2.918001, accumulated_submission_time=8037.453134, global_step=34647, preemption_count=0, score=8037.453134, test/loss=0.285946, test/num_examples=3581, test/ssim=0.743959, total_duration=8447.382190, train/loss=0.264248, train/ssim=0.751205, validation/loss=0.284709, validation/num_examples=3554, validation/ssim=0.726784
I0209 00:55:39.288604 140250672465664 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.03850275278091431, loss=0.39594924449920654
I0209 00:56:03.202486 140250680858368 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.03363174945116043, loss=0.3400098383426666
I0209 00:56:26.913225 140250672465664 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.051140740513801575, loss=0.24509945511817932
I0209 00:56:48.783258 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:56:50.153377 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:56:51.474007 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:56:52.797442 140466628462400 submission_runner.py:408] Time since start: 8531.52s, 	Step: 34993, 	{'train/ssim': 0.7513880729675293, 'train/loss': 0.26407950265066965, 'validation/ssim': 0.72677325504713, 'validation/loss': 0.2847361824924381, 'validation/num_examples': 3554, 'test/ssim': 0.7439256639861421, 'test/loss': 0.28599922033169856, 'test/num_examples': 3581, 'score': 8117.535898685455, 'total_duration': 8531.523807525635, 'accumulated_submission_time': 8117.535898685455, 'accumulated_eval_time': 409.7646481990814, 'accumulated_logging_time': 2.950176954269409}
I0209 00:56:52.821296 140250680858368 logging_writer.py:48] [34993] accumulated_eval_time=409.764648, accumulated_logging_time=2.950177, accumulated_submission_time=8117.535899, global_step=34993, preemption_count=0, score=8117.535899, test/loss=0.285999, test/num_examples=3581, test/ssim=0.743926, total_duration=8531.523808, train/loss=0.264080, train/ssim=0.751388, validation/loss=0.284736, validation/num_examples=3554, validation/ssim=0.726773
I0209 00:56:53.419261 140250672465664 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.01881258748471737, loss=0.3240412473678589
I0209 00:57:16.057218 140250680858368 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.025758257135748863, loss=0.28016725182533264
I0209 00:57:39.525738 140250672465664 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.01537905540317297, loss=0.25313839316368103
I0209 00:58:03.384850 140250680858368 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.014867070131003857, loss=0.3021482229232788
I0209 00:58:13.043608 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:58:14.416967 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:58:15.738447 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:58:17.063150 140466628462400 submission_runner.py:408] Time since start: 8615.79s, 	Step: 35342, 	{'train/ssim': 0.751244136265346, 'train/loss': 0.26409123625074116, 'validation/ssim': 0.7266568863868177, 'validation/loss': 0.28468016204232904, 'validation/num_examples': 3554, 'test/ssim': 0.7438301484833147, 'test/loss': 0.2859374863646677, 'test/num_examples': 3581, 'score': 8197.736165523529, 'total_duration': 8615.789492368698, 'accumulated_submission_time': 8197.736165523529, 'accumulated_eval_time': 413.7841286659241, 'accumulated_logging_time': 2.983177423477173}
I0209 00:58:17.090553 140250672465664 logging_writer.py:48] [35342] accumulated_eval_time=413.784129, accumulated_logging_time=2.983177, accumulated_submission_time=8197.736166, global_step=35342, preemption_count=0, score=8197.736166, test/loss=0.285937, test/num_examples=3581, test/ssim=0.743830, total_duration=8615.789492, train/loss=0.264091, train/ssim=0.751244, validation/loss=0.284680, validation/num_examples=3554, validation/ssim=0.726657
I0209 00:58:28.866868 140250680858368 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.015985243022441864, loss=0.3087873160839081
I0209 00:58:52.543561 140250672465664 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.017524007707834244, loss=0.2631004750728607
I0209 00:59:16.513381 140250680858368 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.014222951605916023, loss=0.19494593143463135
I0209 00:59:37.106837 140466628462400 spec.py:321] Evaluating on the training split.
I0209 00:59:38.478398 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 00:59:39.797783 140466628462400 spec.py:349] Evaluating on the test split.
I0209 00:59:41.117096 140466628462400 submission_runner.py:408] Time since start: 8699.84s, 	Step: 35686, 	{'train/ssim': 0.7514269011361259, 'train/loss': 0.26410904952457975, 'validation/ssim': 0.7268992409520962, 'validation/loss': 0.2846793720543754, 'validation/num_examples': 3554, 'test/ssim': 0.7440562904696663, 'test/loss': 0.28592637356883555, 'test/num_examples': 3581, 'score': 8277.73072552681, 'total_duration': 8699.84346485138, 'accumulated_submission_time': 8277.73072552681, 'accumulated_eval_time': 417.794353723526, 'accumulated_logging_time': 3.0200717449188232}
I0209 00:59:41.140877 140250672465664 logging_writer.py:48] [35686] accumulated_eval_time=417.794354, accumulated_logging_time=3.020072, accumulated_submission_time=8277.730726, global_step=35686, preemption_count=0, score=8277.730726, test/loss=0.285926, test/num_examples=3581, test/ssim=0.744056, total_duration=8699.843465, train/loss=0.264109, train/ssim=0.751427, validation/loss=0.284679, validation/num_examples=3554, validation/ssim=0.726899
I0209 00:59:42.478093 140250680858368 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.01868460327386856, loss=0.3095875382423401
I0209 01:00:06.168816 140250672465664 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.01855933666229248, loss=0.22935357689857483
I0209 01:00:29.957321 140250680858368 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.021012818440794945, loss=0.2899060547351837
I0209 01:00:53.647067 140250672465664 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.02177470736205578, loss=0.22334592044353485
I0209 01:01:01.199480 140466628462400 spec.py:321] Evaluating on the training split.
I0209 01:01:02.573849 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 01:01:03.893219 140466628462400 spec.py:349] Evaluating on the test split.
I0209 01:01:05.216056 140466628462400 submission_runner.py:408] Time since start: 8783.94s, 	Step: 36033, 	{'train/ssim': 0.7513409342084613, 'train/loss': 0.26409052099500385, 'validation/ssim': 0.7267714689874085, 'validation/loss': 0.28468031660518955, 'validation/num_examples': 3554, 'test/ssim': 0.7439452306880061, 'test/loss': 0.28593486156319814, 'test/num_examples': 3581, 'score': 8357.767586946487, 'total_duration': 8783.942422628403, 'accumulated_submission_time': 8357.767586946487, 'accumulated_eval_time': 421.81088972091675, 'accumulated_logging_time': 3.0529043674468994}
I0209 01:01:05.239881 140250680858368 logging_writer.py:48] [36033] accumulated_eval_time=421.810890, accumulated_logging_time=3.052904, accumulated_submission_time=8357.767587, global_step=36033, preemption_count=0, score=8357.767587, test/loss=0.285935, test/num_examples=3581, test/ssim=0.743945, total_duration=8783.942423, train/loss=0.264091, train/ssim=0.751341, validation/loss=0.284680, validation/num_examples=3554, validation/ssim=0.726771
I0209 01:01:18.869007 140250672465664 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.015165559016168118, loss=0.39625489711761475
I0209 01:01:39.522059 140466628462400 spec.py:321] Evaluating on the training split.
I0209 01:01:40.896745 140466628462400 spec.py:333] Evaluating on the validation split.
I0209 01:01:42.219362 140466628462400 spec.py:349] Evaluating on the test split.
I0209 01:01:43.540957 140466628462400 submission_runner.py:408] Time since start: 8822.27s, 	Step: 36189, 	{'train/ssim': 0.751366410936628, 'train/loss': 0.26408934593200684, 'validation/ssim': 0.7267988781346723, 'validation/loss': 0.28467950944358467, 'validation/num_examples': 3554, 'test/ssim': 0.7439701833461324, 'test/loss': 0.28593445250322885, 'test/num_examples': 3581, 'score': 8392.034851789474, 'total_duration': 8822.267328739166, 'accumulated_submission_time': 8392.034851789474, 'accumulated_eval_time': 425.8297622203827, 'accumulated_logging_time': 3.0856668949127197}
I0209 01:01:43.564942 140250680858368 logging_writer.py:48] [36189] accumulated_eval_time=425.829762, accumulated_logging_time=3.085667, accumulated_submission_time=8392.034852, global_step=36189, preemption_count=0, score=8392.034852, test/loss=0.285934, test/num_examples=3581, test/ssim=0.743970, total_duration=8822.267329, train/loss=0.264089, train/ssim=0.751366, validation/loss=0.284680, validation/num_examples=3554, validation/ssim=0.726799
I0209 01:01:43.585782 140250672465664 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8392.034852
I0209 01:01:43.635206 140466628462400 checkpoints.py:490] Saving checkpoint at step: 36189
I0209 01:01:43.827258 140466628462400 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4/checkpoint_36189
I0209 01:01:43.828026 140466628462400 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_4/checkpoint_36189.
I0209 01:01:44.810096 140466628462400 submission_runner.py:583] Tuning trial 4/5
I0209 01:01:44.810347 140466628462400 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0209 01:01:44.817030 140466628462400 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2656774180276053, 'train/loss': 0.8928326879228864, 'validation/ssim': 0.26132172953230515, 'validation/loss': 0.8956671152882316, 'validation/num_examples': 3554, 'test/ssim': 0.28367214634311294, 'test/loss': 0.8949576268413153, 'test/num_examples': 3581, 'score': 30.383830070495605, 'total_duration': 34.343270778656006, 'accumulated_submission_time': 30.383830070495605, 'accumulated_eval_time': 3.9593241214752197, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (344, {'train/ssim': 0.714498588017055, 'train/loss': 0.2980813298906599, 'validation/ssim': 0.6943832680826182, 'validation/loss': 0.3143779387551878, 'validation/num_examples': 3554, 'test/ssim': 0.7118314323862049, 'test/loss': 0.3160043485801801, 'test/num_examples': 3581, 'score': 110.5013530254364, 'total_duration': 118.50828313827515, 'accumulated_submission_time': 110.5013530254364, 'accumulated_eval_time': 7.9749369621276855, 'accumulated_logging_time': 0.01961350440979004, 'global_step': 344, 'preemption_count': 0}), (686, {'train/ssim': 0.7243420055934361, 'train/loss': 0.2890401227133615, 'validation/ssim': 0.7042416994935284, 'validation/loss': 0.30667016368000843, 'validation/num_examples': 3554, 'test/ssim': 0.7214672490226194, 'test/loss': 0.3079342089761938, 'test/num_examples': 3581, 'score': 190.65867400169373, 'total_duration': 202.71763038635254, 'accumulated_submission_time': 190.65867400169373, 'accumulated_eval_time': 11.9900643825531, 'accumulated_logging_time': 0.04378843307495117, 'global_step': 686, 'preemption_count': 0}), (1028, {'train/ssim': 0.7297190938677106, 'train/loss': 0.2809634378978184, 'validation/ssim': 0.7084653185671075, 'validation/loss': 0.2987067072862444, 'validation/num_examples': 3554, 'test/ssim': 0.7258220332789375, 'test/loss': 0.30014066208810386, 'test/num_examples': 3581, 'score': 270.77397561073303, 'total_duration': 286.888560295105, 'accumulated_submission_time': 270.77397561073303, 'accumulated_eval_time': 16.00831699371338, 'accumulated_logging_time': 0.06842851638793945, 'global_step': 1028, 'preemption_count': 0}), (1375, {'train/ssim': 0.7327919006347656, 'train/loss': 0.27697156156812397, 'validation/ssim': 0.7112662036833497, 'validation/loss': 0.29444090972539744, 'validation/num_examples': 3554, 'test/ssim': 0.728854599361212, 'test/loss': 0.29598590815676484, 'test/num_examples': 3581, 'score': 350.7723970413208, 'total_duration': 370.9412474632263, 'accumulated_submission_time': 350.7723970413208, 'accumulated_eval_time': 20.025943994522095, 'accumulated_logging_time': 0.09221529960632324, 'global_step': 1375, 'preemption_count': 0}), (1721, {'train/ssim': 0.7358476775033134, 'train/loss': 0.27680504322052, 'validation/ssim': 0.7154141213025816, 'validation/loss': 0.29407511095552546, 'validation/num_examples': 3554, 'test/ssim': 0.7323106788650168, 'test/loss': 0.29586608767409595, 'test/num_examples': 3581, 'score': 430.8206250667572, 'total_duration': 455.04565238952637, 'accumulated_submission_time': 430.8206250667572, 'accumulated_eval_time': 24.044773817062378, 'accumulated_logging_time': 0.11644697189331055, 'global_step': 1721, 'preemption_count': 0}), (2066, {'train/ssim': 0.7291966165815081, 'train/loss': 0.27790061065128874, 'validation/ssim': 0.7088859356315067, 'validation/loss': 0.2951964816821715, 'validation/num_examples': 3554, 'test/ssim': 0.7263692191645141, 'test/loss': 0.2966501874585486, 'test/num_examples': 3581, 'score': 510.91701436042786, 'total_duration': 539.1955320835114, 'accumulated_submission_time': 510.91701436042786, 'accumulated_eval_time': 28.061689853668213, 'accumulated_logging_time': 0.13985133171081543, 'global_step': 2066, 'preemption_count': 0}), (2413, {'train/ssim': 0.7348235675266811, 'train/loss': 0.275118316922869, 'validation/ssim': 0.7122574668287492, 'validation/loss': 0.29325087874138295, 'validation/num_examples': 3554, 'test/ssim': 0.7297532359370636, 'test/loss': 0.2949290335494624, 'test/num_examples': 3581, 'score': 591.0181603431702, 'total_duration': 623.3513972759247, 'accumulated_submission_time': 591.0181603431702, 'accumulated_eval_time': 32.079628467559814, 'accumulated_logging_time': 0.1638176441192627, 'global_step': 2413, 'preemption_count': 0}), (2763, {'train/ssim': 0.7348286764962333, 'train/loss': 0.2760927677154541, 'validation/ssim': 0.714132005201006, 'validation/loss': 0.2936104263022299, 'validation/num_examples': 3554, 'test/ssim': 0.7313912484073932, 'test/loss': 0.29503474146319114, 'test/num_examples': 3581, 'score': 671.2152290344238, 'total_duration': 707.6071050167084, 'accumulated_submission_time': 671.2152290344238, 'accumulated_eval_time': 36.097635984420776, 'accumulated_logging_time': 0.1916062831878662, 'global_step': 2763, 'preemption_count': 0}), (3110, {'train/ssim': 0.7333554540361676, 'train/loss': 0.2742685760770525, 'validation/ssim': 0.7119192145953503, 'validation/loss': 0.2919274084877954, 'validation/num_examples': 3554, 'test/ssim': 0.7293849456113864, 'test/loss': 0.2933647200502653, 'test/num_examples': 3581, 'score': 751.3892691135406, 'total_duration': 791.8365585803986, 'accumulated_submission_time': 751.3892691135406, 'accumulated_eval_time': 40.113075733184814, 'accumulated_logging_time': 0.21895051002502441, 'global_step': 3110, 'preemption_count': 0}), (3457, {'train/ssim': 0.7428291184561593, 'train/loss': 0.27256126063210623, 'validation/ssim': 0.7211998556863745, 'validation/loss': 0.2903749791168402, 'validation/num_examples': 3554, 'test/ssim': 0.7382981578120636, 'test/loss': 0.29195196326968725, 'test/num_examples': 3581, 'score': 831.370644569397, 'total_duration': 875.8706209659576, 'accumulated_submission_time': 831.370644569397, 'accumulated_eval_time': 44.12899589538574, 'accumulated_logging_time': 0.2428901195526123, 'global_step': 3457, 'preemption_count': 0}), (3805, {'train/ssim': 0.7386627197265625, 'train/loss': 0.273552485874721, 'validation/ssim': 0.7167989358381401, 'validation/loss': 0.29171521085396734, 'validation/num_examples': 3554, 'test/ssim': 0.7343574785979824, 'test/loss': 0.29303873334307806, 'test/num_examples': 3581, 'score': 911.4902095794678, 'total_duration': 960.0550758838654, 'accumulated_submission_time': 911.4902095794678, 'accumulated_eval_time': 48.15200138092041, 'accumulated_logging_time': 0.27216148376464844, 'global_step': 3805, 'preemption_count': 0}), (4153, {'train/ssim': 0.735229355948312, 'train/loss': 0.27429260526384625, 'validation/ssim': 0.7141856556872538, 'validation/loss': 0.29196893437631893, 'validation/num_examples': 3554, 'test/ssim': 0.7317198599160499, 'test/loss': 0.293230650645333, 'test/num_examples': 3581, 'score': 991.6942865848541, 'total_duration': 1044.3180837631226, 'accumulated_submission_time': 991.6942865848541, 'accumulated_eval_time': 52.17389678955078, 'accumulated_logging_time': 0.2966139316558838, 'global_step': 4153, 'preemption_count': 0}), (4498, {'train/ssim': 0.7424945150102887, 'train/loss': 0.27370435850960867, 'validation/ssim': 0.7206746167390616, 'validation/loss': 0.29175642761676984, 'validation/num_examples': 3554, 'test/ssim': 0.737751721869764, 'test/loss': 0.2934164661363795, 'test/num_examples': 3581, 'score': 1071.6959915161133, 'total_duration': 1128.3792896270752, 'accumulated_submission_time': 1071.6959915161133, 'accumulated_eval_time': 56.19573616981506, 'accumulated_logging_time': 0.3215329647064209, 'global_step': 4498, 'preemption_count': 0}), (4848, {'train/ssim': 0.732649530683245, 'train/loss': 0.2749983923775809, 'validation/ssim': 0.7118654267198931, 'validation/loss': 0.2926891629589899, 'validation/num_examples': 3554, 'test/ssim': 0.7292635229771712, 'test/loss': 0.294008682706908, 'test/num_examples': 3581, 'score': 1151.760767698288, 'total_duration': 1212.5005338191986, 'accumulated_submission_time': 1151.760767698288, 'accumulated_eval_time': 60.21451163291931, 'accumulated_logging_time': 0.3464336395263672, 'global_step': 4848, 'preemption_count': 0}), (5197, {'train/ssim': 0.7398488180977958, 'train/loss': 0.2722815786089216, 'validation/ssim': 0.7179851542715954, 'validation/loss': 0.2904013921923361, 'validation/num_examples': 3554, 'test/ssim': 0.7350328366072675, 'test/loss': 0.2919204315637217, 'test/num_examples': 3581, 'score': 1231.8473672866821, 'total_duration': 1296.645854473114, 'accumulated_submission_time': 1231.8473672866821, 'accumulated_eval_time': 64.23522353172302, 'accumulated_logging_time': 0.37164998054504395, 'global_step': 5197, 'preemption_count': 0}), (5542, {'train/ssim': 0.7362847328186035, 'train/loss': 0.2749585935047695, 'validation/ssim': 0.7142758517031865, 'validation/loss': 0.2929826263101435, 'validation/num_examples': 3554, 'test/ssim': 0.7318219203783859, 'test/loss': 0.29443570722650797, 'test/num_examples': 3581, 'score': 1311.8751652240753, 'total_duration': 1380.730637550354, 'accumulated_submission_time': 1311.8751652240753, 'accumulated_eval_time': 68.25117325782776, 'accumulated_logging_time': 0.3998067378997803, 'global_step': 5542, 'preemption_count': 0}), (5892, {'train/ssim': 0.7424530301775251, 'train/loss': 0.27154687472752165, 'validation/ssim': 0.7202798975406233, 'validation/loss': 0.28991355745726644, 'validation/num_examples': 3554, 'test/ssim': 0.7376195954996858, 'test/loss': 0.29129320627748884, 'test/num_examples': 3581, 'score': 1391.8485069274902, 'total_duration': 1464.7589864730835, 'accumulated_submission_time': 1391.8485069274902, 'accumulated_eval_time': 72.26720786094666, 'accumulated_logging_time': 0.42597007751464844, 'global_step': 5892, 'preemption_count': 0}), (6239, {'train/ssim': 0.7378379276820591, 'train/loss': 0.2722529854093279, 'validation/ssim': 0.715315956712507, 'validation/loss': 0.2903406661618071, 'validation/num_examples': 3554, 'test/ssim': 0.7331954074019129, 'test/loss': 0.29166568946785115, 'test/num_examples': 3581, 'score': 1471.865632534027, 'total_duration': 1548.8338203430176, 'accumulated_submission_time': 1471.865632534027, 'accumulated_eval_time': 76.28772187232971, 'accumulated_logging_time': 0.450514554977417, 'global_step': 6239, 'preemption_count': 0}), (6584, {'train/ssim': 0.7387582915169852, 'train/loss': 0.2715438093457903, 'validation/ssim': 0.7162649039814294, 'validation/loss': 0.289883915735351, 'validation/num_examples': 3554, 'test/ssim': 0.7338993996090477, 'test/loss': 0.29118596438887534, 'test/num_examples': 3581, 'score': 1551.8551013469696, 'total_duration': 1632.882734298706, 'accumulated_submission_time': 1551.8551013469696, 'accumulated_eval_time': 80.30454111099243, 'accumulated_logging_time': 0.48056650161743164, 'global_step': 6584, 'preemption_count': 0}), (6930, {'train/ssim': 0.7413247653416225, 'train/loss': 0.2723818676812308, 'validation/ssim': 0.7200253840303179, 'validation/loss': 0.29050707884162214, 'validation/num_examples': 3554, 'test/ssim': 0.7372944610007679, 'test/loss': 0.29179406612154424, 'test/num_examples': 3581, 'score': 1631.901466369629, 'total_duration': 1716.9891197681427, 'accumulated_submission_time': 1631.901466369629, 'accumulated_eval_time': 84.32542157173157, 'accumulated_logging_time': 0.5068538188934326, 'global_step': 6930, 'preemption_count': 0}), (7277, {'train/ssim': 0.7432306153433663, 'train/loss': 0.27117463520595003, 'validation/ssim': 0.721642317635059, 'validation/loss': 0.2892516162466587, 'validation/num_examples': 3554, 'test/ssim': 0.7388227772226682, 'test/loss': 0.2905993042162629, 'test/num_examples': 3581, 'score': 1711.8922002315521, 'total_duration': 1801.0402827262878, 'accumulated_submission_time': 1711.8922002315521, 'accumulated_eval_time': 88.34319472312927, 'accumulated_logging_time': 0.5372030735015869, 'global_step': 7277, 'preemption_count': 0}), (7621, {'train/ssim': 0.7414225169590541, 'train/loss': 0.272381067276001, 'validation/ssim': 0.7186626204628588, 'validation/loss': 0.2906780597126477, 'validation/num_examples': 3554, 'test/ssim': 0.7362754926172856, 'test/loss': 0.2919793361992984, 'test/num_examples': 3581, 'score': 1792.0071773529053, 'total_duration': 1885.2145402431488, 'accumulated_submission_time': 1792.0071773529053, 'accumulated_eval_time': 92.36465859413147, 'accumulated_logging_time': 0.5624737739562988, 'global_step': 7621, 'preemption_count': 0}), (7971, {'train/ssim': 0.7419336863926479, 'train/loss': 0.27214648042406353, 'validation/ssim': 0.7195013128912845, 'validation/loss': 0.29101002638971935, 'validation/num_examples': 3554, 'test/ssim': 0.736703369345155, 'test/loss': 0.29253044224291397, 'test/num_examples': 3581, 'score': 1872.1870954036713, 'total_duration': 1969.4562158584595, 'accumulated_submission_time': 1872.1870954036713, 'accumulated_eval_time': 96.38457012176514, 'accumulated_logging_time': 0.5911064147949219, 'global_step': 7971, 'preemption_count': 0}), (8319, {'train/ssim': 0.7445854459490094, 'train/loss': 0.26996030126299175, 'validation/ssim': 0.7223544059070766, 'validation/loss': 0.28818822376635483, 'validation/num_examples': 3554, 'test/ssim': 0.7396412380445406, 'test/loss': 0.28960392495767595, 'test/num_examples': 3581, 'score': 1952.1830134391785, 'total_duration': 2053.50967502594, 'accumulated_submission_time': 1952.1830134391785, 'accumulated_eval_time': 100.40389037132263, 'accumulated_logging_time': 0.6165444850921631, 'global_step': 8319, 'preemption_count': 0}), (8665, {'train/ssim': 0.7385866982596261, 'train/loss': 0.2723539727074759, 'validation/ssim': 0.7161103411209201, 'validation/loss': 0.290498972878271, 'validation/num_examples': 3554, 'test/ssim': 0.7338329955407009, 'test/loss': 0.2918098149303616, 'test/num_examples': 3581, 'score': 2032.2230477333069, 'total_duration': 2137.6106107234955, 'accumulated_submission_time': 2032.2230477333069, 'accumulated_eval_time': 104.42580008506775, 'accumulated_logging_time': 0.6430308818817139, 'global_step': 8665, 'preemption_count': 0}), (9013, {'train/ssim': 0.7424891335623605, 'train/loss': 0.2706210272652762, 'validation/ssim': 0.7202015169966939, 'validation/loss': 0.28911707786341095, 'validation/num_examples': 3554, 'test/ssim': 0.737618981909732, 'test/loss': 0.29053078667140814, 'test/num_examples': 3581, 'score': 2112.292769908905, 'total_duration': 2221.7378239631653, 'accumulated_submission_time': 2112.292769908905, 'accumulated_eval_time': 108.44480562210083, 'accumulated_logging_time': 0.6688551902770996, 'global_step': 9013, 'preemption_count': 0}), (9361, {'train/ssim': 0.7465317589896066, 'train/loss': 0.2700404099055699, 'validation/ssim': 0.7243574718846723, 'validation/loss': 0.28854945434501617, 'validation/num_examples': 3554, 'test/ssim': 0.7415535934009355, 'test/loss': 0.2898749271873255, 'test/num_examples': 3581, 'score': 2192.431623697281, 'total_duration': 2305.935366868973, 'accumulated_submission_time': 2192.431623697281, 'accumulated_eval_time': 112.46442103385925, 'accumulated_logging_time': 0.6951453685760498, 'global_step': 9361, 'preemption_count': 0}), (9706, {'train/ssim': 0.7407120295933315, 'train/loss': 0.27192156655447824, 'validation/ssim': 0.7184759085273635, 'validation/loss': 0.290316073493335, 'validation/num_examples': 3554, 'test/ssim': 0.736225314594387, 'test/loss': 0.2915895020485723, 'test/num_examples': 3581, 'score': 2272.5230610370636, 'total_duration': 2390.088215827942, 'accumulated_submission_time': 2272.5230610370636, 'accumulated_eval_time': 116.48691987991333, 'accumulated_logging_time': 0.7215027809143066, 'global_step': 9706, 'preemption_count': 0}), (10054, {'train/ssim': 0.7451527459280831, 'train/loss': 0.2696514810834612, 'validation/ssim': 0.7231413026035804, 'validation/loss': 0.2880908835115363, 'validation/num_examples': 3554, 'test/ssim': 0.7403175505270874, 'test/loss': 0.28941947299986037, 'test/num_examples': 3581, 'score': 2352.6956446170807, 'total_duration': 2474.3193640708923, 'accumulated_submission_time': 2352.6956446170807, 'accumulated_eval_time': 120.50583410263062, 'accumulated_logging_time': 0.7481822967529297, 'global_step': 10054, 'preemption_count': 0}), (10403, {'train/ssim': 0.7408154351370675, 'train/loss': 0.2704327957970755, 'validation/ssim': 0.717867136940771, 'validation/loss': 0.2889557829316439, 'validation/num_examples': 3554, 'test/ssim': 0.7356155425335102, 'test/loss': 0.2902749537489528, 'test/num_examples': 3581, 'score': 2432.7886712551117, 'total_duration': 2558.4751613140106, 'accumulated_submission_time': 2432.7886712551117, 'accumulated_eval_time': 124.52903652191162, 'accumulated_logging_time': 0.7753183841705322, 'global_step': 10403, 'preemption_count': 0}), (10748, {'train/ssim': 0.7433472360883441, 'train/loss': 0.27003611837114605, 'validation/ssim': 0.7214320434501618, 'validation/loss': 0.28838386600045723, 'validation/num_examples': 3554, 'test/ssim': 0.7389399729038676, 'test/loss': 0.2895765861163956, 'test/num_examples': 3581, 'score': 2512.798567056656, 'total_duration': 2642.545251607895, 'accumulated_submission_time': 2512.798567056656, 'accumulated_eval_time': 128.54647755622864, 'accumulated_logging_time': 0.805931568145752, 'global_step': 10748, 'preemption_count': 0}), (11094, {'train/ssim': 0.7452190944126674, 'train/loss': 0.2699331215449742, 'validation/ssim': 0.7226893607994513, 'validation/loss': 0.2884922317393254, 'validation/num_examples': 3554, 'test/ssim': 0.7398847650795867, 'test/loss': 0.28990441359344454, 'test/num_examples': 3581, 'score': 2592.8142914772034, 'total_duration': 2726.6222710609436, 'accumulated_submission_time': 2592.8142914772034, 'accumulated_eval_time': 132.5679280757904, 'accumulated_logging_time': 0.8328738212585449, 'global_step': 11094, 'preemption_count': 0}), (11442, {'train/ssim': 0.7470412254333496, 'train/loss': 0.26985042435782297, 'validation/ssim': 0.7249382847671637, 'validation/loss': 0.28855941506269345, 'validation/num_examples': 3554, 'test/ssim': 0.7421258001212999, 'test/loss': 0.289955068852974, 'test/num_examples': 3581, 'score': 2672.999428987503, 'total_duration': 2810.8664784431458, 'accumulated_submission_time': 2672.999428987503, 'accumulated_eval_time': 136.58704543113708, 'accumulated_logging_time': 0.8600804805755615, 'global_step': 11442, 'preemption_count': 0}), (11788, {'train/ssim': 0.7438268661499023, 'train/loss': 0.2697876010622297, 'validation/ssim': 0.7216566748074353, 'validation/loss': 0.28804715939566333, 'validation/num_examples': 3554, 'test/ssim': 0.7389654709752862, 'test/loss': 0.2894258134293842, 'test/num_examples': 3581, 'score': 2753.135874271393, 'total_duration': 2895.062990665436, 'accumulated_submission_time': 2753.135874271393, 'accumulated_eval_time': 140.6037676334381, 'accumulated_logging_time': 0.8904705047607422, 'global_step': 11788, 'preemption_count': 0}), (12137, {'train/ssim': 0.7457892554146903, 'train/loss': 0.2697081225258963, 'validation/ssim': 0.7239719577632597, 'validation/loss': 0.2881403779742016, 'validation/num_examples': 3554, 'test/ssim': 0.7408732584953575, 'test/loss': 0.28960931091393816, 'test/num_examples': 3581, 'score': 2833.2737278938293, 'total_duration': 2979.2558150291443, 'accumulated_submission_time': 2833.2737278938293, 'accumulated_eval_time': 144.61974668502808, 'accumulated_logging_time': 0.9170408248901367, 'global_step': 12137, 'preemption_count': 0}), (12485, {'train/ssim': 0.7406058992658343, 'train/loss': 0.2698268549782889, 'validation/ssim': 0.7178359495902504, 'validation/loss': 0.28838668247924876, 'validation/num_examples': 3554, 'test/ssim': 0.7355890899888299, 'test/loss': 0.2895721887217258, 'test/num_examples': 3581, 'score': 2913.4148364067078, 'total_duration': 3063.4614906311035, 'accumulated_submission_time': 2913.4148364067078, 'accumulated_eval_time': 148.6403510570526, 'accumulated_logging_time': 0.9478676319122314, 'global_step': 12485, 'preemption_count': 0}), (12831, {'train/ssim': 0.7433413096836635, 'train/loss': 0.27062998499189106, 'validation/ssim': 0.720636972095702, 'validation/loss': 0.2892357134456774, 'validation/num_examples': 3554, 'test/ssim': 0.7379370260358489, 'test/loss': 0.2906425963963453, 'test/num_examples': 3581, 'score': 2993.3852968215942, 'total_duration': 3147.490044116974, 'accumulated_submission_time': 2993.3852968215942, 'accumulated_eval_time': 152.65930891036987, 'accumulated_logging_time': 0.9745488166809082, 'global_step': 12831, 'preemption_count': 0}), (13177, {'train/ssim': 0.7466381617954799, 'train/loss': 0.2701584611620222, 'validation/ssim': 0.723888837291608, 'validation/loss': 0.2892952029733223, 'validation/num_examples': 3554, 'test/ssim': 0.7409575248490295, 'test/loss': 0.29067855958531136, 'test/num_examples': 3581, 'score': 3073.576206445694, 'total_duration': 3231.741859436035, 'accumulated_submission_time': 3073.576206445694, 'accumulated_eval_time': 156.68073511123657, 'accumulated_logging_time': 1.001333236694336, 'global_step': 13177, 'preemption_count': 0}), (13526, {'train/ssim': 0.7466552598135812, 'train/loss': 0.26982525416782926, 'validation/ssim': 0.7241531741303813, 'validation/loss': 0.28852585774831174, 'validation/num_examples': 3554, 'test/ssim': 0.7412572294531905, 'test/loss': 0.28988934655124265, 'test/num_examples': 3581, 'score': 3153.5380742549896, 'total_duration': 3315.7623331546783, 'accumulated_submission_time': 3153.5380742549896, 'accumulated_eval_time': 160.6983847618103, 'accumulated_logging_time': 1.0293962955474854, 'global_step': 13526, 'preemption_count': 0}), (13872, {'train/ssim': 0.7463925906590053, 'train/loss': 0.27034829344068256, 'validation/ssim': 0.7245600522738463, 'validation/loss': 0.28894386441773356, 'validation/num_examples': 3554, 'test/ssim': 0.7415183460669157, 'test/loss': 0.2902640795714361, 'test/num_examples': 3581, 'score': 3233.532235622406, 'total_duration': 3399.819220304489, 'accumulated_submission_time': 3233.532235622406, 'accumulated_eval_time': 164.72112107276917, 'accumulated_logging_time': 1.0566694736480713, 'global_step': 13872, 'preemption_count': 0}), (14220, {'train/ssim': 0.7378207615443638, 'train/loss': 0.27081310749053955, 'validation/ssim': 0.715547801003271, 'validation/loss': 0.2894396333796427, 'validation/num_examples': 3554, 'test/ssim': 0.7331411387793214, 'test/loss': 0.2906963536939752, 'test/num_examples': 3581, 'score': 3313.6611313819885, 'total_duration': 3484.0092494487762, 'accumulated_submission_time': 3313.6611313819885, 'accumulated_eval_time': 168.74269700050354, 'accumulated_logging_time': 1.0836646556854248, 'global_step': 14220, 'preemption_count': 0}), (14567, {'train/ssim': 0.7457613263811383, 'train/loss': 0.26930121013096403, 'validation/ssim': 0.7233533628481992, 'validation/loss': 0.28807522114167133, 'validation/num_examples': 3554, 'test/ssim': 0.7405100814192963, 'test/loss': 0.28943058579569253, 'test/num_examples': 3581, 'score': 3393.7974298000336, 'total_duration': 3568.210847377777, 'accumulated_submission_time': 3393.7974298000336, 'accumulated_eval_time': 172.76443004608154, 'accumulated_logging_time': 1.1147141456604004, 'global_step': 14567, 'preemption_count': 0}), (14912, {'train/ssim': 0.745074885232108, 'train/loss': 0.26903135435921804, 'validation/ssim': 0.722156908918648, 'validation/loss': 0.2877203276402909, 'validation/num_examples': 3554, 'test/ssim': 0.7394592745348716, 'test/loss': 0.2891287677150237, 'test/num_examples': 3581, 'score': 3473.7841737270355, 'total_duration': 3652.251398086548, 'accumulated_submission_time': 3473.7841737270355, 'accumulated_eval_time': 176.778422832489, 'accumulated_logging_time': 1.1418116092681885, 'global_step': 14912, 'preemption_count': 0}), (15256, {'train/ssim': 0.7442522048950195, 'train/loss': 0.2690439905439104, 'validation/ssim': 0.7211128196222566, 'validation/loss': 0.2880876892124191, 'validation/num_examples': 3554, 'test/ssim': 0.7385002334368891, 'test/loss': 0.28935910256606046, 'test/num_examples': 3581, 'score': 3553.9577605724335, 'total_duration': 3736.482356786728, 'accumulated_submission_time': 3553.9577605724335, 'accumulated_eval_time': 180.79540133476257, 'accumulated_logging_time': 1.169428825378418, 'global_step': 15256, 'preemption_count': 0}), (15593, {'train/ssim': 0.7427872249058315, 'train/loss': 0.2695131301879883, 'validation/ssim': 0.720087552647545, 'validation/loss': 0.2880110260336065, 'validation/num_examples': 3554, 'test/ssim': 0.7376525248272131, 'test/loss': 0.28930629974169225, 'test/num_examples': 3581, 'score': 3634.0620753765106, 'total_duration': 3820.6428010463715, 'accumulated_submission_time': 3634.0620753765106, 'accumulated_eval_time': 184.81198024749756, 'accumulated_logging_time': 1.1967723369598389, 'global_step': 15593, 'preemption_count': 0}), (15940, {'train/ssim': 0.7473726953778949, 'train/loss': 0.26929732731410433, 'validation/ssim': 0.7248972740881753, 'validation/loss': 0.288025005385657, 'validation/num_examples': 3554, 'test/ssim': 0.7420830533545099, 'test/loss': 0.28933322952300333, 'test/num_examples': 3581, 'score': 3714.1404304504395, 'total_duration': 3904.782006263733, 'accumulated_submission_time': 3714.1404304504395, 'accumulated_eval_time': 188.8285722732544, 'accumulated_logging_time': 1.2282922267913818, 'global_step': 15940, 'preemption_count': 0}), (16283, {'train/ssim': 0.742541858128139, 'train/loss': 0.26914950779506136, 'validation/ssim': 0.7198662873259004, 'validation/loss': 0.28761373078749297, 'validation/num_examples': 3554, 'test/ssim': 0.7375420104588453, 'test/loss': 0.28884648224788817, 'test/num_examples': 3581, 'score': 3794.149676799774, 'total_duration': 3988.8467185497284, 'accumulated_submission_time': 3794.149676799774, 'accumulated_eval_time': 192.84317064285278, 'accumulated_logging_time': 1.2567307949066162, 'global_step': 16283, 'preemption_count': 0}), (16628, {'train/ssim': 0.7466435432434082, 'train/loss': 0.27033313683101107, 'validation/ssim': 0.7241068052722285, 'validation/loss': 0.2894760758674205, 'validation/num_examples': 3554, 'test/ssim': 0.7411906890315205, 'test/loss': 0.2908273551491378, 'test/num_examples': 3581, 'score': 3874.2583525180817, 'total_duration': 4073.014472723007, 'accumulated_submission_time': 3874.2583525180817, 'accumulated_eval_time': 196.8614206314087, 'accumulated_logging_time': 1.2849531173706055, 'global_step': 16628, 'preemption_count': 0}), (16976, {'train/ssim': 0.7484711919512067, 'train/loss': 0.26864796025412424, 'validation/ssim': 0.726306681292206, 'validation/loss': 0.2872895952953538, 'validation/num_examples': 3554, 'test/ssim': 0.7434004991622452, 'test/loss': 0.2886493494310248, 'test/num_examples': 3581, 'score': 3954.3488595485687, 'total_duration': 4157.166150331497, 'accumulated_submission_time': 3954.3488595485687, 'accumulated_eval_time': 200.88203167915344, 'accumulated_logging_time': 1.3127756118774414, 'global_step': 16976, 'preemption_count': 0}), (17319, {'train/ssim': 0.7472654070172992, 'train/loss': 0.2685943841934204, 'validation/ssim': 0.7247833097390265, 'validation/loss': 0.2873271884177599, 'validation/num_examples': 3554, 'test/ssim': 0.7419237244964745, 'test/loss': 0.2886111705005585, 'test/num_examples': 3581, 'score': 4034.3800785541534, 'total_duration': 4241.2600877285, 'accumulated_submission_time': 4034.3800785541534, 'accumulated_eval_time': 204.9027829170227, 'accumulated_logging_time': 1.3420863151550293, 'global_step': 17319, 'preemption_count': 0}), (17665, {'train/ssim': 0.7432973044259208, 'train/loss': 0.2685637984957014, 'validation/ssim': 0.7210903564865293, 'validation/loss': 0.2872054959255856, 'validation/num_examples': 3554, 'test/ssim': 0.7382647512479056, 'test/loss': 0.2885156209094003, 'test/num_examples': 3581, 'score': 4114.4050397872925, 'total_duration': 4325.3410885334015, 'accumulated_submission_time': 4114.4050397872925, 'accumulated_eval_time': 208.91718530654907, 'accumulated_logging_time': 1.3709430694580078, 'global_step': 17665, 'preemption_count': 0}), (18010, {'train/ssim': 0.7477449008396694, 'train/loss': 0.2679294858660017, 'validation/ssim': 0.7250144670837436, 'validation/loss': 0.2867555806122942, 'validation/num_examples': 3554, 'test/ssim': 0.7421997036224169, 'test/loss': 0.28814341042568414, 'test/num_examples': 3581, 'score': 4194.4614062309265, 'total_duration': 4409.454977273941, 'accumulated_submission_time': 4194.4614062309265, 'accumulated_eval_time': 212.93413639068604, 'accumulated_logging_time': 1.3991119861602783, 'global_step': 18010, 'preemption_count': 0}), (18354, {'train/ssim': 0.7455470221383231, 'train/loss': 0.2684933287756784, 'validation/ssim': 0.723333166634426, 'validation/loss': 0.2871022135874631, 'validation/num_examples': 3554, 'test/ssim': 0.7405550780159174, 'test/loss': 0.2883986297581856, 'test/num_examples': 3581, 'score': 4274.639910936356, 'total_duration': 4493.69522857666, 'accumulated_submission_time': 4274.639910936356, 'accumulated_eval_time': 216.95491862297058, 'accumulated_logging_time': 1.4276528358459473, 'global_step': 18354, 'preemption_count': 0}), (18702, {'train/ssim': 0.7455432074410575, 'train/loss': 0.26904252597263884, 'validation/ssim': 0.7224505783536156, 'validation/loss': 0.2881686458040236, 'validation/num_examples': 3554, 'test/ssim': 0.7397161641955808, 'test/loss': 0.28954106607572955, 'test/num_examples': 3581, 'score': 4354.662460803986, 'total_duration': 4577.778399944305, 'accumulated_submission_time': 4354.662460803986, 'accumulated_eval_time': 220.97378945350647, 'accumulated_logging_time': 1.456956148147583, 'global_step': 18702, 'preemption_count': 0}), (19050, {'train/ssim': 0.7460323061261859, 'train/loss': 0.26802403586251394, 'validation/ssim': 0.7234105167592854, 'validation/loss': 0.2866896681391126, 'validation/num_examples': 3554, 'test/ssim': 0.7406949765254119, 'test/loss': 0.2879860927791643, 'test/num_examples': 3581, 'score': 4434.6307945251465, 'total_duration': 4661.805282831192, 'accumulated_submission_time': 4434.6307945251465, 'accumulated_eval_time': 224.99038195610046, 'accumulated_logging_time': 1.4863619804382324, 'global_step': 19050, 'preemption_count': 0}), (19396, {'train/ssim': 0.7468460627964565, 'train/loss': 0.268166184425354, 'validation/ssim': 0.7243975895338, 'validation/loss': 0.28674500164317496, 'validation/num_examples': 3554, 'test/ssim': 0.7415834547786931, 'test/loss': 0.28810015233393255, 'test/num_examples': 3581, 'score': 4514.7168889045715, 'total_duration': 4745.949978351593, 'accumulated_submission_time': 4514.7168889045715, 'accumulated_eval_time': 229.00729703903198, 'accumulated_logging_time': 1.5158488750457764, 'global_step': 19396, 'preemption_count': 0}), (19741, {'train/ssim': 0.7431297983442035, 'train/loss': 0.26822473321642193, 'validation/ssim': 0.7199703596519766, 'validation/loss': 0.2873446196736951, 'validation/num_examples': 3554, 'test/ssim': 0.7374969456855627, 'test/loss': 0.288564435399068, 'test/num_examples': 3581, 'score': 4594.704051733017, 'total_duration': 4829.992509126663, 'accumulated_submission_time': 4594.704051733017, 'accumulated_eval_time': 233.02187514305115, 'accumulated_logging_time': 1.544053554534912, 'global_step': 19741, 'preemption_count': 0}), (20089, {'train/ssim': 0.745450496673584, 'train/loss': 0.2684863635471889, 'validation/ssim': 0.7224317560319359, 'validation/loss': 0.28741750464925087, 'validation/num_examples': 3554, 'test/ssim': 0.7398124978183468, 'test/loss': 0.2886755633573897, 'test/num_examples': 3581, 'score': 4674.802278280258, 'total_duration': 4914.1542048454285, 'accumulated_submission_time': 4674.802278280258, 'accumulated_eval_time': 237.04399013519287, 'accumulated_logging_time': 1.5727825164794922, 'global_step': 20089, 'preemption_count': 0}), (20436, {'train/ssim': 0.7470994676862445, 'train/loss': 0.2675222669328962, 'validation/ssim': 0.7241141555949282, 'validation/loss': 0.2864648135243739, 'validation/num_examples': 3554, 'test/ssim': 0.7414250122172578, 'test/loss': 0.28776472315912105, 'test/num_examples': 3581, 'score': 4754.768115282059, 'total_duration': 4998.176766395569, 'accumulated_submission_time': 4754.768115282059, 'accumulated_eval_time': 241.05979704856873, 'accumulated_logging_time': 1.6012942790985107, 'global_step': 20436, 'preemption_count': 0}), (20780, {'train/ssim': 0.7483934674944196, 'train/loss': 0.26714554854801725, 'validation/ssim': 0.7249244084570202, 'validation/loss': 0.2866048818232977, 'validation/num_examples': 3554, 'test/ssim': 0.7421225958182072, 'test/loss': 0.2879269154369415, 'test/num_examples': 3581, 'score': 4834.975478887558, 'total_duration': 5082.445472002029, 'accumulated_submission_time': 4834.975478887558, 'accumulated_eval_time': 245.07993698120117, 'accumulated_logging_time': 1.6300930976867676, 'global_step': 20780, 'preemption_count': 0}), (21127, {'train/ssim': 0.74561950138637, 'train/loss': 0.26815039770943777, 'validation/ssim': 0.7225248372212648, 'validation/loss': 0.287237490437711, 'validation/num_examples': 3554, 'test/ssim': 0.7398913782157568, 'test/loss': 0.2884889297464046, 'test/num_examples': 3581, 'score': 4914.961860656738, 'total_duration': 5166.493827342987, 'accumulated_submission_time': 4914.961860656738, 'accumulated_eval_time': 249.09580183029175, 'accumulated_logging_time': 1.663682460784912, 'global_step': 21127, 'preemption_count': 0}), (21473, {'train/ssim': 0.7491350173950195, 'train/loss': 0.2679614509854998, 'validation/ssim': 0.7267961303504854, 'validation/loss': 0.28670936631700195, 'validation/num_examples': 3554, 'test/ssim': 0.7438104454281276, 'test/loss': 0.28804823580616445, 'test/num_examples': 3581, 'score': 4994.953593254089, 'total_duration': 5250.544547796249, 'accumulated_submission_time': 4994.953593254089, 'accumulated_eval_time': 253.1110918521881, 'accumulated_logging_time': 1.6949870586395264, 'global_step': 21473, 'preemption_count': 0}), (21819, {'train/ssim': 0.7484683990478516, 'train/loss': 0.26748708316258024, 'validation/ssim': 0.7248557825469542, 'validation/loss': 0.287353824750721, 'validation/num_examples': 3554, 'test/ssim': 0.742086053127618, 'test/loss': 0.2886547353872871, 'test/num_examples': 3581, 'score': 5074.936768531799, 'total_duration': 5334.585844755173, 'accumulated_submission_time': 5074.936768531799, 'accumulated_eval_time': 257.1274366378784, 'accumulated_logging_time': 1.7242553234100342, 'global_step': 21819, 'preemption_count': 0}), (22167, {'train/ssim': 0.7472255570547921, 'train/loss': 0.26763953481401714, 'validation/ssim': 0.7242740079399972, 'validation/loss': 0.2866872638279491, 'validation/num_examples': 3554, 'test/ssim': 0.7414715087004329, 'test/loss': 0.28797508224832447, 'test/num_examples': 3581, 'score': 5155.074422121048, 'total_duration': 5418.778828620911, 'accumulated_submission_time': 5155.074422121048, 'accumulated_eval_time': 261.1410791873932, 'accumulated_logging_time': 1.7532122135162354, 'global_step': 22167, 'preemption_count': 0}), (22514, {'train/ssim': 0.745988300868443, 'train/loss': 0.26703642095838276, 'validation/ssim': 0.7230816069921215, 'validation/loss': 0.28604563904667274, 'validation/num_examples': 3554, 'test/ssim': 0.7404845151712162, 'test/loss': 0.28727286263438984, 'test/num_examples': 3581, 'score': 5235.182781457901, 'total_duration': 5502.94899559021, 'accumulated_submission_time': 5235.182781457901, 'accumulated_eval_time': 265.16000413894653, 'accumulated_logging_time': 1.7835183143615723, 'global_step': 22514, 'preemption_count': 0}), (22859, {'train/ssim': 0.7471205166407994, 'train/loss': 0.26667356491088867, 'validation/ssim': 0.7236672284969401, 'validation/loss': 0.2860689608649585, 'validation/num_examples': 3554, 'test/ssim': 0.7409802276773247, 'test/loss': 0.28731458675125665, 'test/num_examples': 3581, 'score': 5315.278612852097, 'total_duration': 5587.105926513672, 'accumulated_submission_time': 5315.278612852097, 'accumulated_eval_time': 269.17903685569763, 'accumulated_logging_time': 1.8133699893951416, 'global_step': 22859, 'preemption_count': 0}), (23207, {'train/ssim': 0.7486298424857003, 'train/loss': 0.26704018456595285, 'validation/ssim': 0.7255774880636255, 'validation/loss': 0.2862076209244865, 'validation/num_examples': 3554, 'test/ssim': 0.7427466849780089, 'test/loss': 0.2874790629472389, 'test/num_examples': 3581, 'score': 5395.240823984146, 'total_duration': 5671.12223815918, 'accumulated_submission_time': 5395.240823984146, 'accumulated_eval_time': 273.1909189224243, 'accumulated_logging_time': 1.843076229095459, 'global_step': 23207, 'preemption_count': 0}), (23554, {'train/ssim': 0.7473702430725098, 'train/loss': 0.26693529742104666, 'validation/ssim': 0.7242064124490011, 'validation/loss': 0.2860737523136343, 'validation/num_examples': 3554, 'test/ssim': 0.7415203231901005, 'test/loss': 0.28728700929166084, 'test/num_examples': 3581, 'score': 5475.210396766663, 'total_duration': 5755.149123430252, 'accumulated_submission_time': 5475.210396766663, 'accumulated_eval_time': 277.20637464523315, 'accumulated_logging_time': 1.8724026679992676, 'global_step': 23554, 'preemption_count': 0}), (23899, {'train/ssim': 0.7486155373709542, 'train/loss': 0.266871520451137, 'validation/ssim': 0.7250420823148214, 'validation/loss': 0.28631258628042344, 'validation/num_examples': 3554, 'test/ssim': 0.7424447987206786, 'test/loss': 0.28753435421975354, 'test/num_examples': 3581, 'score': 5555.329708099365, 'total_duration': 5839.32786488533, 'accumulated_submission_time': 5555.329708099365, 'accumulated_eval_time': 281.22319531440735, 'accumulated_logging_time': 1.9024322032928467, 'global_step': 23899, 'preemption_count': 0}), (24245, {'train/ssim': 0.7487003462655204, 'train/loss': 0.2665752513068063, 'validation/ssim': 0.7254798043357836, 'validation/loss': 0.2859320009968961, 'validation/num_examples': 3554, 'test/ssim': 0.7427145055937587, 'test/loss': 0.28721412844046706, 'test/num_examples': 3581, 'score': 5635.302527427673, 'total_duration': 5923.360556364059, 'accumulated_submission_time': 5635.302527427673, 'accumulated_eval_time': 285.23908710479736, 'accumulated_logging_time': 1.9336822032928467, 'global_step': 24245, 'preemption_count': 0}), (24594, {'train/ssim': 0.7478156770978656, 'train/loss': 0.26648034368242535, 'validation/ssim': 0.7245771572304094, 'validation/loss': 0.28561767165957375, 'validation/num_examples': 3554, 'test/ssim': 0.7419074302743647, 'test/loss': 0.2868927436579342, 'test/num_examples': 3581, 'score': 5715.485833406448, 'total_duration': 6007.602685213089, 'accumulated_submission_time': 5715.485833406448, 'accumulated_eval_time': 289.2548222541809, 'accumulated_logging_time': 1.9640848636627197, 'global_step': 24594, 'preemption_count': 0}), (24938, {'train/ssim': 0.7481376784188407, 'train/loss': 0.26669812202453613, 'validation/ssim': 0.7249912483073649, 'validation/loss': 0.2858955241618159, 'validation/num_examples': 3554, 'test/ssim': 0.7421870909400308, 'test/loss': 0.28722510488297615, 'test/num_examples': 3581, 'score': 5795.482012271881, 'total_duration': 6091.655306100845, 'accumulated_submission_time': 5795.482012271881, 'accumulated_eval_time': 293.2680079936981, 'accumulated_logging_time': 1.9948859214782715, 'global_step': 24938, 'preemption_count': 0}), (25284, {'train/ssim': 0.7477162906101772, 'train/loss': 0.26642952646527973, 'validation/ssim': 0.7241976882342079, 'validation/loss': 0.2860070498524989, 'validation/num_examples': 3554, 'test/ssim': 0.7414855530927116, 'test/loss': 0.2873365737246056, 'test/num_examples': 3581, 'score': 5875.4409856796265, 'total_duration': 6175.679006099701, 'accumulated_submission_time': 5875.4409856796265, 'accumulated_eval_time': 297.2859468460083, 'accumulated_logging_time': 2.02933931350708, 'global_step': 25284, 'preemption_count': 0}), (25631, {'train/ssim': 0.7501141003199986, 'train/loss': 0.26636855942862375, 'validation/ssim': 0.7267898104468556, 'validation/loss': 0.28584886335159326, 'validation/num_examples': 3554, 'test/ssim': 0.7439213006798031, 'test/loss': 0.28717339288519267, 'test/num_examples': 3581, 'score': 5955.660590648651, 'total_duration': 6259.956165790558, 'accumulated_submission_time': 5955.660590648651, 'accumulated_eval_time': 301.29969024658203, 'accumulated_logging_time': 2.0605125427246094, 'global_step': 25631, 'preemption_count': 0}), (25976, {'train/ssim': 0.748063496180943, 'train/loss': 0.26652256080082487, 'validation/ssim': 0.7249627400464266, 'validation/loss': 0.28572785780546567, 'validation/num_examples': 3554, 'test/ssim': 0.7422536313617006, 'test/loss': 0.286973158030229, 'test/num_examples': 3581, 'score': 6035.690726995468, 'total_duration': 6344.0462028980255, 'accumulated_submission_time': 6035.690726995468, 'accumulated_eval_time': 305.313759803772, 'accumulated_logging_time': 2.0938265323638916, 'global_step': 25976, 'preemption_count': 0}), (26325, {'train/ssim': 0.7494532721383231, 'train/loss': 0.26556929520198275, 'validation/ssim': 0.7256950932268219, 'validation/loss': 0.28531785405748805, 'validation/num_examples': 3554, 'test/ssim': 0.742955441915666, 'test/loss': 0.2866083447142907, 'test/num_examples': 3581, 'score': 6115.706563234329, 'total_duration': 6428.123630523682, 'accumulated_submission_time': 6115.706563234329, 'accumulated_eval_time': 309.33096265792847, 'accumulated_logging_time': 2.125617742538452, 'global_step': 26325, 'preemption_count': 0}), (26674, {'train/ssim': 0.7486578396388462, 'train/loss': 0.26593317304338726, 'validation/ssim': 0.7254540438590321, 'validation/loss': 0.2852956485265282, 'validation/num_examples': 3554, 'test/ssim': 0.7426701225870916, 'test/loss': 0.28660728797603674, 'test/num_examples': 3581, 'score': 6195.682910203934, 'total_duration': 6512.158713579178, 'accumulated_submission_time': 6195.682910203934, 'accumulated_eval_time': 313.3459963798523, 'accumulated_logging_time': 2.156813144683838, 'global_step': 26674, 'preemption_count': 0}), (27018, {'train/ssim': 0.7490175792149135, 'train/loss': 0.2657155820301601, 'validation/ssim': 0.725519784595702, 'validation/loss': 0.2851643903106535, 'validation/num_examples': 3554, 'test/ssim': 0.7428295877984502, 'test/loss': 0.2864416186884774, 'test/num_examples': 3581, 'score': 6275.682108402252, 'total_duration': 6596.222285270691, 'accumulated_submission_time': 6275.682108402252, 'accumulated_eval_time': 317.3675000667572, 'accumulated_logging_time': 2.1871368885040283, 'global_step': 27018, 'preemption_count': 0}), (27364, {'train/ssim': 0.7507955006190709, 'train/loss': 0.26533545766557964, 'validation/ssim': 0.7269669738323016, 'validation/loss': 0.28537712032766777, 'validation/num_examples': 3554, 'test/ssim': 0.744054381523143, 'test/loss': 0.2866985083491867, 'test/num_examples': 3581, 'score': 6355.869081735611, 'total_duration': 6680.471506595612, 'accumulated_submission_time': 6355.869081735611, 'accumulated_eval_time': 321.38672494888306, 'accumulated_logging_time': 2.217285633087158, 'global_step': 27364, 'preemption_count': 0}), (27711, {'train/ssim': 0.7491722106933594, 'train/loss': 0.26562431880405973, 'validation/ssim': 0.7254776748030388, 'validation/loss': 0.28529126924548043, 'validation/num_examples': 3554, 'test/ssim': 0.7427899771580914, 'test/loss': 0.28654374732747484, 'test/num_examples': 3581, 'score': 6435.99257683754, 'total_duration': 6764.661067485809, 'accumulated_submission_time': 6435.99257683754, 'accumulated_eval_time': 325.39993500709534, 'accumulated_logging_time': 2.257634401321411, 'global_step': 27711, 'preemption_count': 0}), (28058, {'train/ssim': 0.7488178525652204, 'train/loss': 0.265708327293396, 'validation/ssim': 0.7253711294711944, 'validation/loss': 0.2851588260476752, 'validation/num_examples': 3554, 'test/ssim': 0.7426109452448687, 'test/loss': 0.28645293601429417, 'test/num_examples': 3581, 'score': 6516.111511468887, 'total_duration': 6848.8406393527985, 'accumulated_submission_time': 6516.111511468887, 'accumulated_eval_time': 329.4172194004059, 'accumulated_logging_time': 2.288557529449463, 'global_step': 28058, 'preemption_count': 0}), (28403, {'train/ssim': 0.750096184866769, 'train/loss': 0.26494128363473074, 'validation/ssim': 0.7260181639525887, 'validation/loss': 0.2850630829424152, 'validation/num_examples': 3554, 'test/ssim': 0.7432273986185772, 'test/loss': 0.28636297690938284, 'test/num_examples': 3581, 'score': 6596.127126693726, 'total_duration': 6932.916352748871, 'accumulated_submission_time': 6596.127126693726, 'accumulated_eval_time': 333.43426752090454, 'accumulated_logging_time': 2.3191332817077637, 'global_step': 28403, 'preemption_count': 0}), (28752, {'train/ssim': 0.7498783384050641, 'train/loss': 0.2653285094669887, 'validation/ssim': 0.7260880263655388, 'validation/loss': 0.2851461862404157, 'validation/num_examples': 3554, 'test/ssim': 0.7432734178651215, 'test/loss': 0.2864265857346063, 'test/num_examples': 3581, 'score': 6676.110071659088, 'total_duration': 7016.962255001068, 'accumulated_submission_time': 6676.110071659088, 'accumulated_eval_time': 337.45313835144043, 'accumulated_logging_time': 2.350611448287964, 'global_step': 28752, 'preemption_count': 0}), (29100, {'train/ssim': 0.749572617667062, 'train/loss': 0.2654174736567906, 'validation/ssim': 0.726090087203679, 'validation/loss': 0.28512384332024654, 'validation/num_examples': 3554, 'test/ssim': 0.7432643503691357, 'test/loss': 0.2863883045391476, 'test/num_examples': 3581, 'score': 6756.167396783829, 'total_duration': 7101.085487127304, 'accumulated_submission_time': 6756.167396783829, 'accumulated_eval_time': 341.47138237953186, 'accumulated_logging_time': 2.385899305343628, 'global_step': 29100, 'preemption_count': 0}), (29446, {'train/ssim': 0.7507331030709403, 'train/loss': 0.26469450337546213, 'validation/ssim': 0.7265406551157146, 'validation/loss': 0.2850275850054516, 'validation/num_examples': 3554, 'test/ssim': 0.7437386554035186, 'test/loss': 0.28629469798284346, 'test/num_examples': 3581, 'score': 6836.258863449097, 'total_duration': 7185.242262125015, 'accumulated_submission_time': 6836.258863449097, 'accumulated_eval_time': 345.49227356910706, 'accumulated_logging_time': 2.417950391769409, 'global_step': 29446, 'preemption_count': 0}), (29793, {'train/ssim': 0.7498508180890765, 'train/loss': 0.2650007350104196, 'validation/ssim': 0.7257677034239589, 'validation/loss': 0.28504956727894626, 'validation/num_examples': 3554, 'test/ssim': 0.7430140738445965, 'test/loss': 0.2863362857463872, 'test/num_examples': 3581, 'score': 6916.343825817108, 'total_duration': 7269.396333932877, 'accumulated_submission_time': 6916.343825817108, 'accumulated_eval_time': 349.51197695732117, 'accumulated_logging_time': 2.4548652172088623, 'global_step': 29793, 'preemption_count': 0}), (30142, {'train/ssim': 0.7498049054827008, 'train/loss': 0.26504012516566683, 'validation/ssim': 0.7257995777205262, 'validation/loss': 0.2849661376815736, 'validation/num_examples': 3554, 'test/ssim': 0.7429910301329936, 'test/loss': 0.2862814035338418, 'test/num_examples': 3581, 'score': 6996.4826691150665, 'total_duration': 7353.598170042038, 'accumulated_submission_time': 6996.4826691150665, 'accumulated_eval_time': 353.5303068161011, 'accumulated_logging_time': 2.487074136734009, 'global_step': 30142, 'preemption_count': 0}), (30488, {'train/ssim': 0.7510360990251813, 'train/loss': 0.26464840344020296, 'validation/ssim': 0.7266652671285875, 'validation/loss': 0.28505743281118107, 'validation/num_examples': 3554, 'test/ssim': 0.7437524952658127, 'test/loss': 0.286356636479859, 'test/num_examples': 3581, 'score': 7076.474865198135, 'total_duration': 7437.652813434601, 'accumulated_submission_time': 7076.474865198135, 'accumulated_eval_time': 357.5478813648224, 'accumulated_logging_time': 2.5196094512939453, 'global_step': 30488, 'preemption_count': 0}), (30836, {'train/ssim': 0.7507091249738421, 'train/loss': 0.26479778970990864, 'validation/ssim': 0.7265978090268008, 'validation/loss': 0.2849529483174768, 'validation/num_examples': 3554, 'test/ssim': 0.7437485410194429, 'test/loss': 0.2862277144128735, 'test/num_examples': 3581, 'score': 7156.552713394165, 'total_duration': 7521.801300287247, 'accumulated_submission_time': 7156.552713394165, 'accumulated_eval_time': 361.56754517555237, 'accumulated_logging_time': 2.5578672885894775, 'global_step': 30836, 'preemption_count': 0}), (31182, {'train/ssim': 0.750427109854562, 'train/loss': 0.264832649912153, 'validation/ssim': 0.7264883098269556, 'validation/loss': 0.28488401328168966, 'validation/num_examples': 3554, 'test/ssim': 0.743651730160046, 'test/loss': 0.2861480499838558, 'test/num_examples': 3581, 'score': 7236.6859402656555, 'total_duration': 7605.993559360504, 'accumulated_submission_time': 7236.6859402656555, 'accumulated_eval_time': 365.5828056335449, 'accumulated_logging_time': 2.589299201965332, 'global_step': 31182, 'preemption_count': 0}), (31529, {'train/ssim': 0.7505290167672294, 'train/loss': 0.2645143951688494, 'validation/ssim': 0.7261004600889842, 'validation/loss': 0.2849139813029773, 'validation/num_examples': 3554, 'test/ssim': 0.7432802355312762, 'test/loss': 0.28622055586341105, 'test/num_examples': 3581, 'score': 7316.703558444977, 'total_duration': 7690.068843841553, 'accumulated_submission_time': 7316.703558444977, 'accumulated_eval_time': 369.5958352088928, 'accumulated_logging_time': 2.6212565898895264, 'global_step': 31529, 'preemption_count': 0}), (31876, {'train/ssim': 0.7509726115635463, 'train/loss': 0.26455514771597727, 'validation/ssim': 0.7267222149558596, 'validation/loss': 0.2848580295474729, 'validation/num_examples': 3554, 'test/ssim': 0.7438690091803966, 'test/loss': 0.28612408588732197, 'test/num_examples': 3581, 'score': 7396.760830163956, 'total_duration': 7774.188344955444, 'accumulated_submission_time': 7396.760830163956, 'accumulated_eval_time': 373.6141917705536, 'accumulated_logging_time': 2.6523241996765137, 'global_step': 31876, 'preemption_count': 0}), (32223, {'train/ssim': 0.7508950233459473, 'train/loss': 0.26465926851545063, 'validation/ssim': 0.7267572492042417, 'validation/loss': 0.2848581497630311, 'validation/num_examples': 3554, 'test/ssim': 0.7439353450720818, 'test/loss': 0.2861133821514591, 'test/num_examples': 3581, 'score': 7476.919148206711, 'total_duration': 7858.408213853836, 'accumulated_submission_time': 7476.919148206711, 'accumulated_eval_time': 377.63095784187317, 'accumulated_logging_time': 2.6843929290771484, 'global_step': 32223, 'preemption_count': 0}), (32569, {'train/ssim': 0.750824110848563, 'train/loss': 0.26461204460689, 'validation/ssim': 0.7265723920230726, 'validation/loss': 0.28489869675343804, 'validation/num_examples': 3554, 'test/ssim': 0.7437707666111072, 'test/loss': 0.2861683666289968, 'test/num_examples': 3581, 'score': 7557.069484472275, 'total_duration': 7942.621923923492, 'accumulated_submission_time': 7557.069484472275, 'accumulated_eval_time': 381.6490135192871, 'accumulated_logging_time': 2.7174501419067383, 'global_step': 32569, 'preemption_count': 0}), (32918, {'train/ssim': 0.7510066713605609, 'train/loss': 0.26437413692474365, 'validation/ssim': 0.7264729222355093, 'validation/loss': 0.2848729706239888, 'validation/num_examples': 3554, 'test/ssim': 0.7436541845198618, 'test/loss': 0.2862069887077632, 'test/num_examples': 3581, 'score': 7637.059919595718, 'total_duration': 8026.681388616562, 'accumulated_submission_time': 7637.059919595718, 'accumulated_eval_time': 385.66769075393677, 'accumulated_logging_time': 2.7551095485687256, 'global_step': 32918, 'preemption_count': 0}), (33264, {'train/ssim': 0.7508365086146763, 'train/loss': 0.2644939933504377, 'validation/ssim': 0.7264935993115152, 'validation/loss': 0.2848100635397615, 'validation/num_examples': 3554, 'test/ssim': 0.7436945451034976, 'test/loss': 0.28606838555483804, 'test/num_examples': 3581, 'score': 7717.092004537582, 'total_duration': 8110.772299528122, 'accumulated_submission_time': 7717.092004537582, 'accumulated_eval_time': 389.682653427124, 'accumulated_logging_time': 2.786450147628784, 'global_step': 33264, 'preemption_count': 0}), (33610, {'train/ssim': 0.7514575549534389, 'train/loss': 0.264496956552778, 'validation/ssim': 0.7271822627233399, 'validation/loss': 0.28493361078626195, 'validation/num_examples': 3554, 'test/ssim': 0.7443005674479893, 'test/loss': 0.28621189742739456, 'test/num_examples': 3581, 'score': 7797.218616485596, 'total_duration': 8194.963827133179, 'accumulated_submission_time': 7797.218616485596, 'accumulated_eval_time': 393.70337677001953, 'accumulated_logging_time': 2.8181211948394775, 'global_step': 33610, 'preemption_count': 0}), (33958, {'train/ssim': 0.7513347353254046, 'train/loss': 0.2641548088618687, 'validation/ssim': 0.7267312139490715, 'validation/loss': 0.28475407743695486, 'validation/num_examples': 3554, 'test/ssim': 0.7438889167655682, 'test/loss': 0.286054988840844, 'test/num_examples': 3581, 'score': 7877.383341789246, 'total_duration': 8279.188350439072, 'accumulated_submission_time': 7877.383341789246, 'accumulated_eval_time': 397.71788907051086, 'accumulated_logging_time': 2.850908041000366, 'global_step': 33958, 'preemption_count': 0}), (34304, {'train/ssim': 0.7511395045689174, 'train/loss': 0.2642734391348703, 'validation/ssim': 0.7266988587902715, 'validation/loss': 0.28475948713707266, 'validation/num_examples': 3554, 'test/ssim': 0.7438610325109956, 'test/loss': 0.2860153782004852, 'test/num_examples': 3581, 'score': 7957.451696395874, 'total_duration': 8363.3182117939, 'accumulated_submission_time': 7957.451696395874, 'accumulated_eval_time': 401.73359990119934, 'accumulated_logging_time': 2.884448528289795, 'global_step': 34304, 'preemption_count': 0}), (34647, {'train/ssim': 0.7512046950204032, 'train/loss': 0.26424758774893625, 'validation/ssim': 0.7267843835730866, 'validation/loss': 0.2847093915966165, 'validation/num_examples': 3554, 'test/ssim': 0.7439592750802848, 'test/loss': 0.2859457016523841, 'test/num_examples': 3581, 'score': 8037.453133821487, 'total_duration': 8447.382189512253, 'accumulated_submission_time': 8037.453133821487, 'accumulated_eval_time': 405.75045943260193, 'accumulated_logging_time': 2.918001174926758, 'global_step': 34647, 'preemption_count': 0}), (34993, {'train/ssim': 0.7513880729675293, 'train/loss': 0.26407950265066965, 'validation/ssim': 0.72677325504713, 'validation/loss': 0.2847361824924381, 'validation/num_examples': 3554, 'test/ssim': 0.7439256639861421, 'test/loss': 0.28599922033169856, 'test/num_examples': 3581, 'score': 8117.535898685455, 'total_duration': 8531.523807525635, 'accumulated_submission_time': 8117.535898685455, 'accumulated_eval_time': 409.7646481990814, 'accumulated_logging_time': 2.950176954269409, 'global_step': 34993, 'preemption_count': 0}), (35342, {'train/ssim': 0.751244136265346, 'train/loss': 0.26409123625074116, 'validation/ssim': 0.7266568863868177, 'validation/loss': 0.28468016204232904, 'validation/num_examples': 3554, 'test/ssim': 0.7438301484833147, 'test/loss': 0.2859374863646677, 'test/num_examples': 3581, 'score': 8197.736165523529, 'total_duration': 8615.789492368698, 'accumulated_submission_time': 8197.736165523529, 'accumulated_eval_time': 413.7841286659241, 'accumulated_logging_time': 2.983177423477173, 'global_step': 35342, 'preemption_count': 0}), (35686, {'train/ssim': 0.7514269011361259, 'train/loss': 0.26410904952457975, 'validation/ssim': 0.7268992409520962, 'validation/loss': 0.2846793720543754, 'validation/num_examples': 3554, 'test/ssim': 0.7440562904696663, 'test/loss': 0.28592637356883555, 'test/num_examples': 3581, 'score': 8277.73072552681, 'total_duration': 8699.84346485138, 'accumulated_submission_time': 8277.73072552681, 'accumulated_eval_time': 417.794353723526, 'accumulated_logging_time': 3.0200717449188232, 'global_step': 35686, 'preemption_count': 0}), (36033, {'train/ssim': 0.7513409342084613, 'train/loss': 0.26409052099500385, 'validation/ssim': 0.7267714689874085, 'validation/loss': 0.28468031660518955, 'validation/num_examples': 3554, 'test/ssim': 0.7439452306880061, 'test/loss': 0.28593486156319814, 'test/num_examples': 3581, 'score': 8357.767586946487, 'total_duration': 8783.942422628403, 'accumulated_submission_time': 8357.767586946487, 'accumulated_eval_time': 421.81088972091675, 'accumulated_logging_time': 3.0529043674468994, 'global_step': 36033, 'preemption_count': 0}), (36189, {'train/ssim': 0.751366410936628, 'train/loss': 0.26408934593200684, 'validation/ssim': 0.7267988781346723, 'validation/loss': 0.28467950944358467, 'validation/num_examples': 3554, 'test/ssim': 0.7439701833461324, 'test/loss': 0.28593445250322885, 'test/num_examples': 3581, 'score': 8392.034851789474, 'total_duration': 8822.267328739166, 'accumulated_submission_time': 8392.034851789474, 'accumulated_eval_time': 425.8297622203827, 'accumulated_logging_time': 3.0856668949127197, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0209 01:01:44.817285 140466628462400 submission_runner.py:586] Timing: 8392.034851789474
I0209 01:01:44.817342 140466628462400 submission_runner.py:588] Total number of evals: 106
I0209 01:01:44.817385 140466628462400 submission_runner.py:589] ====================
I0209 01:01:44.817436 140466628462400 submission_runner.py:542] Using RNG seed 1572671891
I0209 01:01:44.818986 140466628462400 submission_runner.py:551] --- Tuning run 5/5 ---
I0209 01:01:44.819123 140466628462400 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_5.
I0209 01:01:44.819446 140466628462400 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_3/fastmri_jax/trial_5/hparams.json.
I0209 01:01:44.820258 140466628462400 submission_runner.py:206] Initializing dataset.
I0209 01:01:45.183038 140466628462400 submission_runner.py:213] Initializing model.
Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 208, in cache_miss
    outs, out_flat, out_tree, args_flat = _python_pjit_helper(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 150, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _ = infer_params_fn(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 301, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 474, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat = _pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 935, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 345, in memoized_fun
    ans = call(fun, *args)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 888, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2150, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2172, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 188, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1640, in init
    _, v_out = self.init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1545, in init_with_output
    return init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 965, in wrapper
    return apply(fn, mutable=mutable, flags=init_flags)({}, *args, rngs=rngs,
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 933, in wrapper
    y = fn(root, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 2121, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1289, in make_rng
    return self.scope.make_rng(name)
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 711, in make_rng
    raise errors.InvalidRngError(f'{self.name} needs PRNG for "{name}"')
jax._src.traceback_util.UnfilteredStackTrace: flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)

The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)
