python3 submission_runner.py --framework=jax --workload=fastmri --submission_path=prize_qualification_baselines/external_tuning/jax_nadamw_full_budget.py --tuning_search_space=prize_qualification_baselines/external_tuning/tuning_search_space.json --data_dir=/data/fastmri --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=prize_qualification/study_0 --overwrite=true --save_checkpoints=false --num_tuning_trials=5 --rng_seed=3907440050 --max_global_steps=36189 2>&1 | tee -a /logs/fastmri_jax_02-04-2024-11-11-21.log
I0204 11:11:41.216603 140584300062528 logger_utils.py:76] Creating experiment directory at /experiment_runs/prize_qualification/study_0/fastmri_jax.
I0204 11:11:42.839864 140584300062528 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host CUDA Interpreter
I0204 11:11:42.840714 140584300062528 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0204 11:11:42.840854 140584300062528 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0204 11:11:42.842105 140584300062528 submission_runner.py:542] Using RNG seed 3907440050
I0204 11:11:43.977968 140584300062528 submission_runner.py:551] --- Tuning run 1/5 ---
I0204 11:11:43.978163 140584300062528 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1.
I0204 11:11:43.978383 140584300062528 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1/hparams.json.
I0204 11:11:44.162510 140584300062528 submission_runner.py:206] Initializing dataset.
I0204 11:11:50.670472 140584300062528 submission_runner.py:213] Initializing model.
I0204 11:11:57.497270 140584300062528 submission_runner.py:255] Initializing optimizer.
I0204 11:11:58.350412 140584300062528 submission_runner.py:262] Initializing metrics bundle.
I0204 11:11:58.350603 140584300062528 submission_runner.py:280] Initializing checkpoint and logger.
I0204 11:11:58.351476 140584300062528 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1 with prefix checkpoint_
I0204 11:11:58.351645 140584300062528 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1/meta_data_0.json.
I0204 11:11:58.351828 140584300062528 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 11:11:58.351887 140584300062528 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 11:11:58.708145 140584300062528 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 11:11:59.032165 140584300062528 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1/flags_0.json.
I0204 11:11:59.041794 140584300062528 submission_runner.py:314] Starting training loop.
I0204 11:12:54.607176 140421981902592 logging_writer.py:48] [0] global_step=0, grad_norm=4.385186672210693, loss=0.9066542387008667
I0204 11:12:54.620719 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:14:20.319160 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:15:19.119008 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:16:14.328846 140584300062528 submission_runner.py:408] Time since start: 255.29s, 	Step: 1, 	{'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 55.57856774330139, 'total_duration': 255.28697657585144, 'accumulated_submission_time': 55.57856774330139, 'accumulated_eval_time': 199.7080636024475, 'accumulated_logging_time': 0}
I0204 11:16:14.346459 140397019907840 logging_writer.py:48] [1] accumulated_eval_time=199.708064, accumulated_logging_time=0, accumulated_submission_time=55.578568, global_step=1, preemption_count=0, score=55.578568, test/loss=0.912514, test/num_examples=3581, test/ssim=0.282943, total_duration=255.286977, train/loss=0.903264, train/ssim=0.267076, validation/loss=0.915262, validation/num_examples=3554, validation/ssim=0.258797
I0204 11:16:36.060651 140397011515136 logging_writer.py:48] [100] global_step=100, grad_norm=0.7346821427345276, loss=0.29955631494522095
I0204 11:16:59.937965 140397019907840 logging_writer.py:48] [200] global_step=200, grad_norm=0.17182990908622742, loss=0.3412458598613739
I0204 11:17:23.854253 140397011515136 logging_writer.py:48] [300] global_step=300, grad_norm=0.12168355286121368, loss=0.3615769147872925
I0204 11:17:34.707643 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:17:36.487713 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:17:37.814434 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:17:39.145694 140584300062528 submission_runner.py:408] Time since start: 340.10s, 	Step: 340, 	{'train/ssim': 0.6899064608982631, 'train/loss': 0.31449713025774273, 'validation/ssim': 0.663529567256964, 'validation/loss': 0.34306793127022367, 'validation/num_examples': 3554, 'test/ssim': 0.6827848339107442, 'test/loss': 0.3440740777606639, 'test/num_examples': 3581, 'score': 135.91773223876953, 'total_duration': 340.1038362979889, 'accumulated_submission_time': 135.91773223876953, 'accumulated_eval_time': 204.1460680961609, 'accumulated_logging_time': 0.0274045467376709}
I0204 11:17:39.167071 140397019907840 logging_writer.py:48] [340] accumulated_eval_time=204.146068, accumulated_logging_time=0.027405, accumulated_submission_time=135.917732, global_step=340, preemption_count=0, score=135.917732, test/loss=0.344074, test/num_examples=3581, test/ssim=0.682785, total_duration=340.103836, train/loss=0.314497, train/ssim=0.689906, validation/loss=0.343068, validation/num_examples=3554, validation/ssim=0.663530
I0204 11:17:56.622283 140397011515136 logging_writer.py:48] [400] global_step=400, grad_norm=0.11726605147123337, loss=0.34984850883483887
I0204 11:18:31.477843 140397019907840 logging_writer.py:48] [500] global_step=500, grad_norm=0.18018889427185059, loss=0.28639137744903564
I0204 11:18:59.257857 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:19:00.637636 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:19:01.967691 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:19:03.296902 140584300062528 submission_runner.py:408] Time since start: 424.26s, 	Step: 584, 	{'train/ssim': 0.712254456111363, 'train/loss': 0.29293731280735563, 'validation/ssim': 0.6871440245585959, 'validation/loss': 0.31990369840760413, 'validation/num_examples': 3554, 'test/ssim': 0.7052362266781276, 'test/loss': 0.3218626327535954, 'test/num_examples': 3581, 'score': 215.98555970191956, 'total_duration': 424.25503969192505, 'accumulated_submission_time': 215.98555970191956, 'accumulated_eval_time': 208.18507623672485, 'accumulated_logging_time': 0.06345915794372559}
I0204 11:19:03.317651 140397011515136 logging_writer.py:48] [584] accumulated_eval_time=208.185076, accumulated_logging_time=0.063459, accumulated_submission_time=215.985560, global_step=584, preemption_count=0, score=215.985560, test/loss=0.321863, test/num_examples=3581, test/ssim=0.705236, total_duration=424.255040, train/loss=0.292937, train/ssim=0.712254, validation/loss=0.319904, validation/num_examples=3554, validation/ssim=0.687144
I0204 11:19:05.637044 140397019907840 logging_writer.py:48] [600] global_step=600, grad_norm=0.14617684483528137, loss=0.2795644700527191
I0204 11:19:39.446396 140397011515136 logging_writer.py:48] [700] global_step=700, grad_norm=0.1049552634358406, loss=0.27740705013275146
I0204 11:20:13.390331 140397019907840 logging_writer.py:48] [800] global_step=800, grad_norm=0.06420344859361649, loss=0.231135293841362
I0204 11:20:23.560813 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:20:24.941867 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:20:26.272938 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:20:27.604389 140584300062528 submission_runner.py:408] Time since start: 508.56s, 	Step: 831, 	{'train/ssim': 0.7251592363630023, 'train/loss': 0.28260299137660433, 'validation/ssim': 0.699622742970069, 'validation/loss': 0.30940015596423043, 'validation/num_examples': 3554, 'test/ssim': 0.7169947918484711, 'test/loss': 0.31175755615575257, 'test/num_examples': 3581, 'score': 296.20644450187683, 'total_duration': 508.56253838539124, 'accumulated_submission_time': 296.20644450187683, 'accumulated_eval_time': 212.22860860824585, 'accumulated_logging_time': 0.09788990020751953}
I0204 11:20:27.629267 140397011515136 logging_writer.py:48] [831] accumulated_eval_time=212.228609, accumulated_logging_time=0.097890, accumulated_submission_time=296.206445, global_step=831, preemption_count=0, score=296.206445, test/loss=0.311758, test/num_examples=3581, test/ssim=0.716995, total_duration=508.562538, train/loss=0.282603, train/ssim=0.725159, validation/loss=0.309400, validation/num_examples=3554, validation/ssim=0.699623
I0204 11:20:48.290132 140397019907840 logging_writer.py:48] [900] global_step=900, grad_norm=0.20888283848762512, loss=0.339708536863327
I0204 11:21:18.621609 140397011515136 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.1031404584646225, loss=0.23391956090927124
I0204 11:21:42.515797 140397019907840 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.16491258144378662, loss=0.358436644077301
I0204 11:21:47.703351 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:21:49.082431 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:21:50.415337 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:21:51.746821 140584300062528 submission_runner.py:408] Time since start: 592.70s, 	Step: 1123, 	{'train/ssim': 0.7318246705191476, 'train/loss': 0.2763338940484183, 'validation/ssim': 0.7060530388294879, 'validation/loss': 0.3028629369526414, 'validation/num_examples': 3554, 'test/ssim': 0.7230841949045309, 'test/loss': 0.3051949388918947, 'test/num_examples': 3581, 'score': 376.2559127807617, 'total_duration': 592.7049720287323, 'accumulated_submission_time': 376.2559127807617, 'accumulated_eval_time': 216.27203941345215, 'accumulated_logging_time': 0.1372833251953125}
I0204 11:21:51.762654 140397011515136 logging_writer.py:48] [1123] accumulated_eval_time=216.272039, accumulated_logging_time=0.137283, accumulated_submission_time=376.255913, global_step=1123, preemption_count=0, score=376.255913, test/loss=0.305195, test/num_examples=3581, test/ssim=0.723084, total_duration=592.704972, train/loss=0.276334, train/ssim=0.731825, validation/loss=0.302863, validation/num_examples=3554, validation/ssim=0.706053
I0204 11:22:08.102176 140397019907840 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.1195889487862587, loss=0.22728216648101807
I0204 11:22:32.214759 140397011515136 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.11732015013694763, loss=0.31527718901634216
I0204 11:22:55.994604 140397019907840 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.2997990548610687, loss=0.29784953594207764
I0204 11:23:11.860973 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:23:13.240928 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:23:14.571159 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:23:15.899626 140584300062528 submission_runner.py:408] Time since start: 676.86s, 	Step: 1468, 	{'train/ssim': 0.7371740341186523, 'train/loss': 0.2721036502293178, 'validation/ssim': 0.7114779891495498, 'validation/loss': 0.298528376092519, 'validation/num_examples': 3554, 'test/ssim': 0.7285530539871893, 'test/loss': 0.30065812294924604, 'test/num_examples': 3581, 'score': 456.3312237262726, 'total_duration': 676.8577456474304, 'accumulated_submission_time': 456.3312237262726, 'accumulated_eval_time': 220.31062197685242, 'accumulated_logging_time': 0.1638650894165039}
I0204 11:23:15.914629 140397011515136 logging_writer.py:48] [1468] accumulated_eval_time=220.310622, accumulated_logging_time=0.163865, accumulated_submission_time=456.331224, global_step=1468, preemption_count=0, score=456.331224, test/loss=0.300658, test/num_examples=3581, test/ssim=0.728553, total_duration=676.857746, train/loss=0.272104, train/ssim=0.737174, validation/loss=0.298528, validation/num_examples=3554, validation/ssim=0.711478
I0204 11:23:21.489417 140397019907840 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.18274597823619843, loss=0.40245819091796875
I0204 11:23:45.159786 140397011515136 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.11089633405208588, loss=0.22949260473251343
I0204 11:24:08.985925 140397019907840 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.05612098053097725, loss=0.3307388424873352
I0204 11:24:32.929764 140397011515136 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.3474728465080261, loss=0.2644314169883728
I0204 11:24:35.995602 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:24:37.370704 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:24:38.700711 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:24:40.031138 140584300062528 submission_runner.py:408] Time since start: 760.99s, 	Step: 1814, 	{'train/ssim': 0.739152022770473, 'train/loss': 0.2694324425288609, 'validation/ssim': 0.7133444902530599, 'validation/loss': 0.29575022889042274, 'validation/num_examples': 3554, 'test/ssim': 0.7304791128525552, 'test/loss': 0.2976562704529985, 'test/num_examples': 3581, 'score': 536.3904583454132, 'total_duration': 760.9892885684967, 'accumulated_submission_time': 536.3904583454132, 'accumulated_eval_time': 224.34614849090576, 'accumulated_logging_time': 0.18819332122802734}
I0204 11:24:40.046645 140397019907840 logging_writer.py:48] [1814] accumulated_eval_time=224.346148, accumulated_logging_time=0.188193, accumulated_submission_time=536.390458, global_step=1814, preemption_count=0, score=536.390458, test/loss=0.297656, test/num_examples=3581, test/ssim=0.730479, total_duration=760.989289, train/loss=0.269432, train/ssim=0.739152, validation/loss=0.295750, validation/num_examples=3554, validation/ssim=0.713344
I0204 11:24:58.518943 140397011515136 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.07635919004678726, loss=0.2604697644710541
I0204 11:25:22.709543 140397019907840 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.1861480325460434, loss=0.24523603916168213
I0204 11:25:46.722360 140397011515136 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.05460730567574501, loss=0.33118629455566406
I0204 11:26:00.174644 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:26:01.554985 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:26:02.883278 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:26:04.217027 140584300062528 submission_runner.py:408] Time since start: 845.18s, 	Step: 2158, 	{'train/ssim': 0.7400693893432617, 'train/loss': 0.2681713615145002, 'validation/ssim': 0.7146711891530669, 'validation/loss': 0.29411821681995637, 'validation/num_examples': 3554, 'test/ssim': 0.7317220415692195, 'test/loss': 0.2959929985295658, 'test/num_examples': 3581, 'score': 616.4971573352814, 'total_duration': 845.1751751899719, 'accumulated_submission_time': 616.4971573352814, 'accumulated_eval_time': 228.38849234580994, 'accumulated_logging_time': 0.21284890174865723}
I0204 11:26:04.232625 140397019907840 logging_writer.py:48] [2158] accumulated_eval_time=228.388492, accumulated_logging_time=0.212849, accumulated_submission_time=616.497157, global_step=2158, preemption_count=0, score=616.497157, test/loss=0.295993, test/num_examples=3581, test/ssim=0.731722, total_duration=845.175175, train/loss=0.268171, train/ssim=0.740069, validation/loss=0.294118, validation/num_examples=3554, validation/ssim=0.714671
I0204 11:26:12.391703 140397011515136 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.2439766526222229, loss=0.25460460782051086
I0204 11:26:35.902256 140397019907840 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.07635025680065155, loss=0.24986866116523743
I0204 11:26:59.637890 140397011515136 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.08576568961143494, loss=0.3539045453071594
I0204 11:27:23.848541 140397019907840 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.18861259520053864, loss=0.27224108576774597
I0204 11:27:24.266995 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:27:25.647968 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:27:26.977227 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:27:28.308227 140584300062528 submission_runner.py:408] Time since start: 929.27s, 	Step: 2503, 	{'train/ssim': 0.7419065747942243, 'train/loss': 0.26662564277648926, 'validation/ssim': 0.7160875345121693, 'validation/loss': 0.2928775579122995, 'validation/num_examples': 3554, 'test/ssim': 0.7332659702466141, 'test/loss': 0.29462564740557806, 'test/num_examples': 3581, 'score': 696.509119272232, 'total_duration': 929.2663757801056, 'accumulated_submission_time': 696.509119272232, 'accumulated_eval_time': 232.4296793937683, 'accumulated_logging_time': 0.2388749122619629}
I0204 11:27:28.323886 140397011515136 logging_writer.py:48] [2503] accumulated_eval_time=232.429679, accumulated_logging_time=0.238875, accumulated_submission_time=696.509119, global_step=2503, preemption_count=0, score=696.509119, test/loss=0.294626, test/num_examples=3581, test/ssim=0.733266, total_duration=929.266376, train/loss=0.266626, train/ssim=0.741907, validation/loss=0.292878, validation/num_examples=3554, validation/ssim=0.716088
I0204 11:27:49.338418 140397019907840 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.13163445889949799, loss=0.2762627601623535
I0204 11:28:13.308474 140397011515136 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.07579369097948074, loss=0.26048797369003296
I0204 11:28:37.101747 140397019907840 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.05522817373275757, loss=0.31255051493644714
I0204 11:28:48.436333 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:28:49.816316 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:28:51.147187 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:28:52.479209 140584300062528 submission_runner.py:408] Time since start: 1013.44s, 	Step: 2848, 	{'train/ssim': 0.7424797330583844, 'train/loss': 0.26656499930790495, 'validation/ssim': 0.7164755903339547, 'validation/loss': 0.29284032543656796, 'validation/num_examples': 3554, 'test/ssim': 0.7336256703129364, 'test/loss': 0.29447092047219703, 'test/num_examples': 3581, 'score': 776.5994248390198, 'total_duration': 1013.4373586177826, 'accumulated_submission_time': 776.5994248390198, 'accumulated_eval_time': 236.4725306034088, 'accumulated_logging_time': 0.26478075981140137}
I0204 11:28:52.493819 140397011515136 logging_writer.py:48] [2848] accumulated_eval_time=236.472531, accumulated_logging_time=0.264781, accumulated_submission_time=776.599425, global_step=2848, preemption_count=0, score=776.599425, test/loss=0.294471, test/num_examples=3581, test/ssim=0.733626, total_duration=1013.437359, train/loss=0.266565, train/ssim=0.742480, validation/loss=0.292840, validation/num_examples=3554, validation/ssim=0.716476
I0204 11:29:02.785283 140397019907840 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.09364072233438492, loss=0.2361563742160797
I0204 11:29:26.654964 140397011515136 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.07941757142543793, loss=0.26710131764411926
I0204 11:29:51.175240 140397019907840 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.29097771644592285, loss=0.2578977048397064
I0204 11:30:12.705778 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:30:14.086734 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:30:15.414737 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:30:16.747828 140584300062528 submission_runner.py:408] Time since start: 1097.71s, 	Step: 3190, 	{'train/ssim': 0.744572503226144, 'train/loss': 0.2646067312785557, 'validation/ssim': 0.7181011794588844, 'validation/loss': 0.2909685691958005, 'validation/num_examples': 3554, 'test/ssim': 0.7353150879860724, 'test/loss': 0.2926284121055571, 'test/num_examples': 3581, 'score': 856.7893908023834, 'total_duration': 1097.7059400081635, 'accumulated_submission_time': 856.7893908023834, 'accumulated_eval_time': 240.51452016830444, 'accumulated_logging_time': 0.28966665267944336}
I0204 11:30:16.765583 140397011515136 logging_writer.py:48] [3190] accumulated_eval_time=240.514520, accumulated_logging_time=0.289667, accumulated_submission_time=856.789391, global_step=3190, preemption_count=0, score=856.789391, test/loss=0.292628, test/num_examples=3581, test/ssim=0.735315, total_duration=1097.705940, train/loss=0.264607, train/ssim=0.744573, validation/loss=0.290969, validation/num_examples=3554, validation/ssim=0.718101
I0204 11:30:17.586840 140397019907840 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.22939148545265198, loss=0.3695374131202698
I0204 11:30:40.728947 140397011515136 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.07078976184129715, loss=0.3055516183376312
I0204 11:31:04.336116 140397019907840 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.12837375700473785, loss=0.28601834177970886
I0204 11:31:28.081048 140397011515136 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.12353231757879257, loss=0.2607426047325134
I0204 11:31:36.822514 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:31:38.205746 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:31:39.536499 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:31:40.869555 140584300062528 submission_runner.py:408] Time since start: 1181.83s, 	Step: 3538, 	{'train/ssim': 0.7460277421133858, 'train/loss': 0.2635725566319057, 'validation/ssim': 0.7194483493510833, 'validation/loss': 0.2902894199867227, 'validation/num_examples': 3554, 'test/ssim': 0.7366975061522619, 'test/loss': 0.2918307451654566, 'test/num_examples': 3581, 'score': 936.8239948749542, 'total_duration': 1181.8276615142822, 'accumulated_submission_time': 936.8239948749542, 'accumulated_eval_time': 244.56147742271423, 'accumulated_logging_time': 0.31770825386047363}
I0204 11:31:40.886762 140397019907840 logging_writer.py:48] [3538] accumulated_eval_time=244.561477, accumulated_logging_time=0.317708, accumulated_submission_time=936.823995, global_step=3538, preemption_count=0, score=936.823995, test/loss=0.291831, test/num_examples=3581, test/ssim=0.736698, total_duration=1181.827662, train/loss=0.263573, train/ssim=0.746028, validation/loss=0.290289, validation/num_examples=3554, validation/ssim=0.719448
I0204 11:31:53.500955 140397011515136 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.09336254745721817, loss=0.290967732667923
I0204 11:32:17.545818 140397019907840 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.3393097221851349, loss=0.28274232149124146
I0204 11:32:41.458173 140397011515136 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.16829724609851837, loss=0.2712627947330475
I0204 11:33:00.984266 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:33:02.367223 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:33:03.699024 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:33:05.026805 140584300062528 submission_runner.py:408] Time since start: 1265.98s, 	Step: 3884, 	{'train/ssim': 0.7463890484401158, 'train/loss': 0.2633559022630964, 'validation/ssim': 0.7203027728439786, 'validation/loss': 0.28958004515158975, 'validation/num_examples': 3554, 'test/ssim': 0.7373969305230732, 'test/loss': 0.2911783626911128, 'test/num_examples': 3581, 'score': 1016.8996806144714, 'total_duration': 1265.9849543571472, 'accumulated_submission_time': 1016.8996806144714, 'accumulated_eval_time': 248.6039776802063, 'accumulated_logging_time': 0.34499454498291016}
I0204 11:33:05.041803 140397019907840 logging_writer.py:48] [3884] accumulated_eval_time=248.603978, accumulated_logging_time=0.344995, accumulated_submission_time=1016.899681, global_step=3884, preemption_count=0, score=1016.899681, test/loss=0.291178, test/num_examples=3581, test/ssim=0.737397, total_duration=1265.984954, train/loss=0.263356, train/ssim=0.746389, validation/loss=0.289580, validation/num_examples=3554, validation/ssim=0.720303
I0204 11:33:06.682440 140397011515136 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.17287136614322662, loss=0.26688244938850403
I0204 11:33:30.240113 140397019907840 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.10843054950237274, loss=0.29593464732170105
I0204 11:33:53.698475 140397011515136 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.09796631336212158, loss=0.26851269602775574
I0204 11:34:18.172877 140397019907840 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.11621289700269699, loss=0.2435416430234909
I0204 11:34:25.074299 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:34:26.457154 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:34:27.787802 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:34:29.118943 140584300062528 submission_runner.py:408] Time since start: 1350.08s, 	Step: 4230, 	{'train/ssim': 0.745875494820731, 'train/loss': 0.26375818252563477, 'validation/ssim': 0.7200002418050084, 'validation/loss': 0.28997397436207445, 'validation/num_examples': 3554, 'test/ssim': 0.7372028315676487, 'test/loss': 0.2914835555165282, 'test/num_examples': 3581, 'score': 1096.9104199409485, 'total_duration': 1350.0770933628082, 'accumulated_submission_time': 1096.9104199409485, 'accumulated_eval_time': 252.64858031272888, 'accumulated_logging_time': 0.36988353729248047}
I0204 11:34:29.133822 140397011515136 logging_writer.py:48] [4230] accumulated_eval_time=252.648580, accumulated_logging_time=0.369884, accumulated_submission_time=1096.910420, global_step=4230, preemption_count=0, score=1096.910420, test/loss=0.291484, test/num_examples=3581, test/ssim=0.737203, total_duration=1350.077093, train/loss=0.263758, train/ssim=0.745875, validation/loss=0.289974, validation/num_examples=3554, validation/ssim=0.720000
I0204 11:34:43.688435 140397019907840 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.1810033768415451, loss=0.28664618730545044
I0204 11:35:07.602431 140397011515136 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.09352117031812668, loss=0.2939227223396301
I0204 11:35:31.478494 140397019907840 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.2551048696041107, loss=0.20209833979606628
I0204 11:35:49.147339 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:35:50.529082 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:35:51.859841 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:35:53.192778 140584300062528 submission_runner.py:408] Time since start: 1434.15s, 	Step: 4576, 	{'train/ssim': 0.7481837953839984, 'train/loss': 0.2624566214425223, 'validation/ssim': 0.7213690504976786, 'validation/loss': 0.2893379997120322, 'validation/num_examples': 3554, 'test/ssim': 0.7384671677560388, 'test/loss': 0.2909181323739877, 'test/num_examples': 3581, 'score': 1176.9021356105804, 'total_duration': 1434.1509294509888, 'accumulated_submission_time': 1176.9021356105804, 'accumulated_eval_time': 256.6939928531647, 'accumulated_logging_time': 0.39466309547424316}
I0204 11:35:53.208435 140397011515136 logging_writer.py:48] [4576] accumulated_eval_time=256.693993, accumulated_logging_time=0.394663, accumulated_submission_time=1176.902136, global_step=4576, preemption_count=0, score=1176.902136, test/loss=0.290918, test/num_examples=3581, test/ssim=0.738467, total_duration=1434.150929, train/loss=0.262457, train/ssim=0.748184, validation/loss=0.289338, validation/num_examples=3554, validation/ssim=0.721369
I0204 11:35:56.849153 140397019907840 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.14847683906555176, loss=0.20667123794555664
I0204 11:36:20.665912 140397011515136 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.29796522855758667, loss=0.22045017778873444
I0204 11:36:44.649847 140397019907840 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.16013894975185394, loss=0.313796728849411
I0204 11:37:08.356067 140397011515136 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.04174698516726494, loss=0.28914713859558105
I0204 11:37:13.205789 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:37:14.583173 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:37:15.914133 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:37:17.245747 140584300062528 submission_runner.py:408] Time since start: 1518.20s, 	Step: 4922, 	{'train/ssim': 0.7474816186087472, 'train/loss': 0.26262130056108746, 'validation/ssim': 0.7212315925937324, 'validation/loss': 0.2890369799543648, 'validation/num_examples': 3554, 'test/ssim': 0.7384208758028483, 'test/loss': 0.2905407063756632, 'test/num_examples': 3581, 'score': 1256.8783206939697, 'total_duration': 1518.2038979530334, 'accumulated_submission_time': 1256.8783206939697, 'accumulated_eval_time': 260.7339150905609, 'accumulated_logging_time': 0.4196033477783203}
I0204 11:37:17.261784 140397019907840 logging_writer.py:48] [4922] accumulated_eval_time=260.733915, accumulated_logging_time=0.419603, accumulated_submission_time=1256.878321, global_step=4922, preemption_count=0, score=1256.878321, test/loss=0.290541, test/num_examples=3581, test/ssim=0.738421, total_duration=1518.203898, train/loss=0.262621, train/ssim=0.747482, validation/loss=0.289037, validation/num_examples=3554, validation/ssim=0.721232
I0204 11:37:33.508414 140397011515136 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.43928635120391846, loss=0.37101152539253235
I0204 11:37:57.336431 140397019907840 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.20753023028373718, loss=0.32887059450149536
I0204 11:38:21.272042 140397011515136 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.08446183055639267, loss=0.23713336884975433
I0204 11:38:37.343158 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:38:38.725430 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:38:40.050353 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:38:41.379542 140584300062528 submission_runner.py:408] Time since start: 1602.34s, 	Step: 5268, 	{'train/ssim': 0.7481545039585659, 'train/loss': 0.262041585786002, 'validation/ssim': 0.7215776073174592, 'validation/loss': 0.28865782008388435, 'validation/num_examples': 3554, 'test/ssim': 0.7387660542402611, 'test/loss': 0.29012179487878736, 'test/num_examples': 3581, 'score': 1336.9380061626434, 'total_duration': 1602.3376910686493, 'accumulated_submission_time': 1336.9380061626434, 'accumulated_eval_time': 264.77026534080505, 'accumulated_logging_time': 0.44515347480773926}
I0204 11:38:41.395482 140397019907840 logging_writer.py:48] [5268] accumulated_eval_time=264.770265, accumulated_logging_time=0.445153, accumulated_submission_time=1336.938006, global_step=5268, preemption_count=0, score=1336.938006, test/loss=0.290122, test/num_examples=3581, test/ssim=0.738766, total_duration=1602.337691, train/loss=0.262042, train/ssim=0.748155, validation/loss=0.288658, validation/num_examples=3554, validation/ssim=0.721578
I0204 11:38:46.964075 140397011515136 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.33795708417892456, loss=0.22074340283870697
I0204 11:39:10.507918 140397019907840 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.29651570320129395, loss=0.33151882886886597
I0204 11:39:34.317256 140397011515136 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.04680575802922249, loss=0.2793098986148834
I0204 11:39:58.207643 140397019907840 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.14162805676460266, loss=0.25532791018486023
I0204 11:40:01.423765 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:40:02.805254 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:40:04.135156 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:40:05.463509 140584300062528 submission_runner.py:408] Time since start: 1686.42s, 	Step: 5615, 	{'train/ssim': 0.7481823648725238, 'train/loss': 0.2613209826605661, 'validation/ssim': 0.7214367146832794, 'validation/loss': 0.2880889772362567, 'validation/num_examples': 3554, 'test/ssim': 0.7386184517680118, 'test/loss': 0.2896329341271642, 'test/num_examples': 3581, 'score': 1416.9430875778198, 'total_duration': 1686.421659231186, 'accumulated_submission_time': 1416.9430875778198, 'accumulated_eval_time': 268.809974193573, 'accumulated_logging_time': 0.47231531143188477}
I0204 11:40:05.479684 140397011515136 logging_writer.py:48] [5615] accumulated_eval_time=268.809974, accumulated_logging_time=0.472315, accumulated_submission_time=1416.943088, global_step=5615, preemption_count=0, score=1416.943088, test/loss=0.289633, test/num_examples=3581, test/ssim=0.738618, total_duration=1686.421659, train/loss=0.261321, train/ssim=0.748182, validation/loss=0.288089, validation/num_examples=3554, validation/ssim=0.721437
I0204 11:40:23.642214 140397019907840 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.1823291927576065, loss=0.2958035469055176
I0204 11:40:47.435901 140397011515136 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.07097768783569336, loss=0.2936157286167145
I0204 11:41:11.441943 140397019907840 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.22834961116313934, loss=0.300050288438797
I0204 11:41:25.493565 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:41:26.873991 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:41:28.202538 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:41:29.533909 140584300062528 submission_runner.py:408] Time since start: 1770.49s, 	Step: 5961, 	{'train/ssim': 0.7485959189278739, 'train/loss': 0.2613769769668579, 'validation/ssim': 0.7219383226865855, 'validation/loss': 0.2880452015994302, 'validation/num_examples': 3554, 'test/ssim': 0.7390884616727171, 'test/loss': 0.28950298941025554, 'test/num_examples': 3581, 'score': 1496.9353461265564, 'total_duration': 1770.4920568466187, 'accumulated_submission_time': 1496.9353461265564, 'accumulated_eval_time': 272.85027623176575, 'accumulated_logging_time': 0.4980456829071045}
I0204 11:41:29.549511 140397011515136 logging_writer.py:48] [5961] accumulated_eval_time=272.850276, accumulated_logging_time=0.498046, accumulated_submission_time=1496.935346, global_step=5961, preemption_count=0, score=1496.935346, test/loss=0.289503, test/num_examples=3581, test/ssim=0.739088, total_duration=1770.492057, train/loss=0.261377, train/ssim=0.748596, validation/loss=0.288045, validation/num_examples=3554, validation/ssim=0.721938
I0204 11:41:36.720361 140397019907840 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.12412277609109879, loss=0.21122527122497559
I0204 11:42:01.299882 140397011515136 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.0744817852973938, loss=0.32171154022216797
I0204 11:42:25.104542 140397019907840 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17105573415756226, loss=0.29407158493995667
I0204 11:42:49.107795 140397011515136 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.1540769636631012, loss=0.23814551532268524
I0204 11:42:49.558026 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:42:50.938405 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:42:52.270108 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:42:53.598071 140584300062528 submission_runner.py:408] Time since start: 1854.56s, 	Step: 6303, 	{'train/ssim': 0.7485676492963519, 'train/loss': 0.2616139990942819, 'validation/ssim': 0.7227368287712789, 'validation/loss': 0.288008621722443, 'validation/num_examples': 3554, 'test/ssim': 0.7398391548930118, 'test/loss': 0.28943055170736176, 'test/num_examples': 3581, 'score': 1576.922093629837, 'total_duration': 1854.556218624115, 'accumulated_submission_time': 1576.922093629837, 'accumulated_eval_time': 276.8902978897095, 'accumulated_logging_time': 0.5235202312469482}
I0204 11:42:53.614421 140397019907840 logging_writer.py:48] [6303] accumulated_eval_time=276.890298, accumulated_logging_time=0.523520, accumulated_submission_time=1576.922094, global_step=6303, preemption_count=0, score=1576.922094, test/loss=0.289431, test/num_examples=3581, test/ssim=0.739839, total_duration=1854.556219, train/loss=0.261614, train/ssim=0.748568, validation/loss=0.288009, validation/num_examples=3554, validation/ssim=0.722737
I0204 11:43:15.339345 140397011515136 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.06664381921291351, loss=0.23205727338790894
I0204 11:43:39.318609 140397019907840 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.14899834990501404, loss=0.2565535604953766
I0204 11:44:03.101113 140397011515136 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.1786905974149704, loss=0.3014892637729645
I0204 11:44:13.697465 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:44:15.076968 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:44:16.413089 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:44:17.743119 140584300062528 submission_runner.py:408] Time since start: 1938.70s, 	Step: 6646, 	{'train/ssim': 0.7496201651436942, 'train/loss': 0.260679977280753, 'validation/ssim': 0.7227002145469893, 'validation/loss': 0.2876082523927705, 'validation/num_examples': 3554, 'test/ssim': 0.7399165354038676, 'test/loss': 0.2890858164182491, 'test/num_examples': 3581, 'score': 1656.9838755130768, 'total_duration': 1938.7012684345245, 'accumulated_submission_time': 1656.9838755130768, 'accumulated_eval_time': 280.935923576355, 'accumulated_logging_time': 0.5493738651275635}
I0204 11:44:17.759442 140397019907840 logging_writer.py:48] [6646] accumulated_eval_time=280.935924, accumulated_logging_time=0.549374, accumulated_submission_time=1656.983876, global_step=6646, preemption_count=0, score=1656.983876, test/loss=0.289086, test/num_examples=3581, test/ssim=0.739917, total_duration=1938.701268, train/loss=0.260680, train/ssim=0.749620, validation/loss=0.287608, validation/num_examples=3554, validation/ssim=0.722700
I0204 11:44:28.482489 140397011515136 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.13079410791397095, loss=0.2894107401371002
I0204 11:44:52.208399 140397019907840 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.12745290994644165, loss=0.30785441398620605
I0204 11:45:16.361337 140397011515136 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.1856081336736679, loss=0.3515515923500061
I0204 11:45:37.836491 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:45:39.217927 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:45:40.547588 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:45:41.876982 140584300062528 submission_runner.py:408] Time since start: 2022.84s, 	Step: 6991, 	{'train/ssim': 0.7485895838056292, 'train/loss': 0.2608584335872105, 'validation/ssim': 0.7222806279016601, 'validation/loss': 0.28743989909037354, 'validation/num_examples': 3554, 'test/ssim': 0.7394819091865051, 'test/loss': 0.288878116218846, 'test/num_examples': 3581, 'score': 1737.0378777980804, 'total_duration': 2022.8351304531097, 'accumulated_submission_time': 1737.0378777980804, 'accumulated_eval_time': 284.97637605667114, 'accumulated_logging_time': 0.5766260623931885}
I0204 11:45:41.893165 140397019907840 logging_writer.py:48] [6991] accumulated_eval_time=284.976376, accumulated_logging_time=0.576626, accumulated_submission_time=1737.037878, global_step=6991, preemption_count=0, score=1737.037878, test/loss=0.288878, test/num_examples=3581, test/ssim=0.739482, total_duration=2022.835130, train/loss=0.260858, train/ssim=0.748590, validation/loss=0.287440, validation/num_examples=3554, validation/ssim=0.722281
I0204 11:45:42.641987 140397011515136 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.16311870515346527, loss=0.24313613772392273
I0204 11:46:05.846817 140397019907840 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.22010111808776855, loss=0.2466227412223816
I0204 11:46:29.482623 140397011515136 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.19511057436466217, loss=0.27545952796936035
I0204 11:46:53.163957 140397019907840 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.09728065133094788, loss=0.2765957713127136
I0204 11:47:01.943160 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:47:03.324678 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:47:04.654400 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:47:05.982504 140584300062528 submission_runner.py:408] Time since start: 2106.94s, 	Step: 7338, 	{'train/ssim': 0.7492905344281878, 'train/loss': 0.2608873333249773, 'validation/ssim': 0.7231078483311058, 'validation/loss': 0.28731879050233894, 'validation/num_examples': 3554, 'test/ssim': 0.7403037106647934, 'test/loss': 0.28873088871823516, 'test/num_examples': 3581, 'score': 1817.0663664340973, 'total_duration': 2106.940655231476, 'accumulated_submission_time': 1817.0663664340973, 'accumulated_eval_time': 289.0156946182251, 'accumulated_logging_time': 0.6023619174957275}
I0204 11:47:05.999258 140397011515136 logging_writer.py:48] [7338] accumulated_eval_time=289.015695, accumulated_logging_time=0.602362, accumulated_submission_time=1817.066366, global_step=7338, preemption_count=0, score=1817.066366, test/loss=0.288731, test/num_examples=3581, test/ssim=0.740304, total_duration=2106.940655, train/loss=0.260887, train/ssim=0.749291, validation/loss=0.287319, validation/num_examples=3554, validation/ssim=0.723108
I0204 11:47:18.545152 140397019907840 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.24500206112861633, loss=0.25878775119781494
I0204 11:47:42.619541 140397011515136 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.14595772325992584, loss=0.2040378302335739
I0204 11:48:06.767303 140397019907840 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.24358080327510834, loss=0.2626020908355713
I0204 11:48:26.143503 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:48:27.521551 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:48:28.852640 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:48:30.184667 140584300062528 submission_runner.py:408] Time since start: 2191.14s, 	Step: 7683, 	{'train/ssim': 0.7503745215279716, 'train/loss': 0.26090713909694124, 'validation/ssim': 0.7233539810996412, 'validation/loss': 0.28783700542632423, 'validation/num_examples': 3554, 'test/ssim': 0.7404244515323932, 'test/loss': 0.2893348316745497, 'test/num_examples': 3581, 'score': 1897.189120054245, 'total_duration': 2191.1428146362305, 'accumulated_submission_time': 1897.189120054245, 'accumulated_eval_time': 293.05683064460754, 'accumulated_logging_time': 0.6286115646362305}
I0204 11:48:30.202934 140397011515136 logging_writer.py:48] [7683] accumulated_eval_time=293.056831, accumulated_logging_time=0.628612, accumulated_submission_time=1897.189120, global_step=7683, preemption_count=0, score=1897.189120, test/loss=0.289335, test/num_examples=3581, test/ssim=0.740424, total_duration=2191.142815, train/loss=0.260907, train/ssim=0.750375, validation/loss=0.287837, validation/num_examples=3554, validation/ssim=0.723354
I0204 11:48:32.260321 140397019907840 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.127951979637146, loss=0.26486891508102417
I0204 11:48:56.061356 140397011515136 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.05375587195158005, loss=0.2799219787120819
I0204 11:49:20.014872 140397019907840 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.6971505284309387, loss=0.27165526151657104
I0204 11:49:43.948114 140397011515136 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.07277041673660278, loss=0.2993999123573303
I0204 11:49:50.235131 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:49:51.616025 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:49:52.946541 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:49:54.278313 140584300062528 submission_runner.py:408] Time since start: 2275.24s, 	Step: 8027, 	{'train/ssim': 0.7490619250706264, 'train/loss': 0.2611512967518398, 'validation/ssim': 0.7230151106148002, 'validation/loss': 0.2876697168902997, 'validation/num_examples': 3554, 'test/ssim': 0.740137905023911, 'test/loss': 0.28910221290535115, 'test/num_examples': 3581, 'score': 1977.1989560127258, 'total_duration': 2275.2364633083344, 'accumulated_submission_time': 1977.1989560127258, 'accumulated_eval_time': 297.0999720096588, 'accumulated_logging_time': 0.6573379039764404}
I0204 11:49:54.294605 140397019907840 logging_writer.py:48] [8027] accumulated_eval_time=297.099972, accumulated_logging_time=0.657338, accumulated_submission_time=1977.198956, global_step=8027, preemption_count=0, score=1977.198956, test/loss=0.289102, test/num_examples=3581, test/ssim=0.740138, total_duration=2275.236463, train/loss=0.261151, train/ssim=0.749062, validation/loss=0.287670, validation/num_examples=3554, validation/ssim=0.723015
I0204 11:50:09.942338 140397011515136 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.26323291659355164, loss=0.21838633716106415
I0204 11:50:33.784619 140397019907840 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.05507832020521164, loss=0.274877667427063
I0204 11:50:57.544976 140397011515136 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.2498420774936676, loss=0.24837970733642578
I0204 11:51:14.482340 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:51:15.863765 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:51:17.191931 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:51:18.521180 140584300062528 submission_runner.py:408] Time since start: 2359.48s, 	Step: 8373, 	{'train/ssim': 0.7492820194789341, 'train/loss': 0.2605456454413278, 'validation/ssim': 0.722934188370498, 'validation/loss': 0.2869772581015669, 'validation/num_examples': 3554, 'test/ssim': 0.7401876739868403, 'test/loss': 0.2883704387086359, 'test/num_examples': 3581, 'score': 2057.3637301921844, 'total_duration': 2359.4793276786804, 'accumulated_submission_time': 2057.3637301921844, 'accumulated_eval_time': 301.13877034187317, 'accumulated_logging_time': 0.68442702293396}
I0204 11:51:18.538246 140397019907840 logging_writer.py:48] [8373] accumulated_eval_time=301.138770, accumulated_logging_time=0.684427, accumulated_submission_time=2057.363730, global_step=8373, preemption_count=0, score=2057.363730, test/loss=0.288370, test/num_examples=3581, test/ssim=0.740188, total_duration=2359.479328, train/loss=0.260546, train/ssim=0.749282, validation/loss=0.286977, validation/num_examples=3554, validation/ssim=0.722934
I0204 11:51:23.025208 140397011515136 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.11039117723703384, loss=0.26804319024086
I0204 11:51:47.010505 140397019907840 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.30501508712768555, loss=0.352125883102417
I0204 11:52:11.214240 140397011515136 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.07547356933355331, loss=0.3431856632232666
I0204 11:52:35.315043 140397019907840 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.4762499928474426, loss=0.20646052062511444
I0204 11:52:38.525257 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:52:39.905012 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:52:41.235388 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:52:42.565193 140584300062528 submission_runner.py:408] Time since start: 2443.52s, 	Step: 8715, 	{'train/ssim': 0.7499177796500069, 'train/loss': 0.2602596623556955, 'validation/ssim': 0.723055022180114, 'validation/loss': 0.28704102386835256, 'validation/num_examples': 3554, 'test/ssim': 0.7403200048869031, 'test/loss': 0.28843138864405893, 'test/num_examples': 3581, 'score': 2137.3297839164734, 'total_duration': 2443.523314476013, 'accumulated_submission_time': 2137.3297839164734, 'accumulated_eval_time': 305.17865443229675, 'accumulated_logging_time': 0.7108016014099121}
I0204 11:52:42.582874 140397011515136 logging_writer.py:48] [8715] accumulated_eval_time=305.178654, accumulated_logging_time=0.710802, accumulated_submission_time=2137.329784, global_step=8715, preemption_count=0, score=2137.329784, test/loss=0.288431, test/num_examples=3581, test/ssim=0.740320, total_duration=2443.523314, train/loss=0.260260, train/ssim=0.749918, validation/loss=0.287041, validation/num_examples=3554, validation/ssim=0.723055
I0204 11:53:00.844181 140397019907840 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.09579513967037201, loss=0.20313455164432526
I0204 11:53:25.018822 140397011515136 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.09248939156532288, loss=0.23289236426353455
I0204 11:53:48.576128 140397019907840 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.11359810829162598, loss=0.19820290803909302
I0204 11:54:02.765822 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:54:04.148026 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:54:05.480495 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:54:06.811126 140584300062528 submission_runner.py:408] Time since start: 2527.77s, 	Step: 9061, 	{'train/ssim': 0.750847407749721, 'train/loss': 0.26009057249341694, 'validation/ssim': 0.7241669817459201, 'validation/loss': 0.2869474618167909, 'validation/num_examples': 3554, 'test/ssim': 0.7413580627356186, 'test/loss': 0.2883768132264905, 'test/num_examples': 3581, 'score': 2217.4914298057556, 'total_duration': 2527.769276380539, 'accumulated_submission_time': 2217.4914298057556, 'accumulated_eval_time': 309.2239181995392, 'accumulated_logging_time': 0.7377052307128906}
I0204 11:54:06.828141 140397011515136 logging_writer.py:48] [9061] accumulated_eval_time=309.223918, accumulated_logging_time=0.737705, accumulated_submission_time=2217.491430, global_step=9061, preemption_count=0, score=2217.491430, test/loss=0.288377, test/num_examples=3581, test/ssim=0.741358, total_duration=2527.769276, train/loss=0.260091, train/ssim=0.750847, validation/loss=0.286947, validation/num_examples=3554, validation/ssim=0.724167
I0204 11:54:14.099720 140397019907840 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.20493677258491516, loss=0.30338001251220703
I0204 11:54:37.642849 140397011515136 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.35431984066963196, loss=0.2107713520526886
I0204 11:55:01.398659 140397019907840 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.053270019590854645, loss=0.31838977336883545
I0204 11:55:25.258535 140397011515136 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.1348092406988144, loss=0.23087632656097412
I0204 11:55:26.864123 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:55:28.245262 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:55:29.574383 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:55:30.904880 140584300062528 submission_runner.py:408] Time since start: 2611.86s, 	Step: 9408, 	{'train/ssim': 0.7499944823128837, 'train/loss': 0.2610064574650356, 'validation/ssim': 0.7235614388057471, 'validation/loss': 0.2875855488259268, 'validation/num_examples': 3554, 'test/ssim': 0.7408017411773946, 'test/loss': 0.28887542324071486, 'test/num_examples': 3581, 'score': 2297.5060591697693, 'total_duration': 2611.8630299568176, 'accumulated_submission_time': 2297.5060591697693, 'accumulated_eval_time': 313.26463556289673, 'accumulated_logging_time': 0.7639820575714111}
I0204 11:55:30.921905 140397019907840 logging_writer.py:48] [9408] accumulated_eval_time=313.264636, accumulated_logging_time=0.763982, accumulated_submission_time=2297.506059, global_step=9408, preemption_count=0, score=2297.506059, test/loss=0.288875, test/num_examples=3581, test/ssim=0.740802, total_duration=2611.863030, train/loss=0.261006, train/ssim=0.749994, validation/loss=0.287586, validation/num_examples=3554, validation/ssim=0.723561
I0204 11:55:50.634076 140397011515136 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.15714222192764282, loss=0.2692981958389282
I0204 11:56:14.961259 140397019907840 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.09349888563156128, loss=0.27039021253585815
I0204 11:56:39.201744 140397011515136 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.06163214519619942, loss=0.24741631746292114
I0204 11:56:50.995203 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:56:52.375994 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:56:53.707575 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:56:55.039912 140584300062528 submission_runner.py:408] Time since start: 2696.00s, 	Step: 9751, 	{'train/ssim': 0.7508278574262347, 'train/loss': 0.2601182460784912, 'validation/ssim': 0.7241959708690912, 'validation/loss': 0.28678190781953433, 'validation/num_examples': 3554, 'test/ssim': 0.7413401322736317, 'test/loss': 0.2882359943320651, 'test/num_examples': 3581, 'score': 2377.5569076538086, 'total_duration': 2695.998062610626, 'accumulated_submission_time': 2377.5569076538086, 'accumulated_eval_time': 317.30930352211, 'accumulated_logging_time': 0.7913625240325928}
I0204 11:56:55.056633 140397019907840 logging_writer.py:48] [9751] accumulated_eval_time=317.309304, accumulated_logging_time=0.791363, accumulated_submission_time=2377.556908, global_step=9751, preemption_count=0, score=2377.556908, test/loss=0.288236, test/num_examples=3581, test/ssim=0.741340, total_duration=2695.998063, train/loss=0.260118, train/ssim=0.750828, validation/loss=0.286782, validation/num_examples=3554, validation/ssim=0.724196
I0204 11:57:04.865617 140397011515136 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.394372820854187, loss=0.2624288499355316
I0204 11:57:28.683425 140397019907840 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.1807963103055954, loss=0.25315555930137634
I0204 11:57:52.382840 140397011515136 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.09160894900560379, loss=0.24943825602531433
I0204 11:58:15.278325 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:58:16.658112 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:58:17.986745 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:58:19.316396 140584300062528 submission_runner.py:408] Time since start: 2780.27s, 	Step: 10099, 	{'train/ssim': 0.7506995882306781, 'train/loss': 0.2599021536963327, 'validation/ssim': 0.723881967831141, 'validation/loss': 0.2867163731666784, 'validation/num_examples': 3554, 'test/ssim': 0.7411026729614633, 'test/loss': 0.28817647610653446, 'test/num_examples': 3581, 'score': 2457.756463766098, 'total_duration': 2780.274495124817, 'accumulated_submission_time': 2457.756463766098, 'accumulated_eval_time': 321.34729051589966, 'accumulated_logging_time': 0.818218469619751}
I0204 11:58:19.336852 140397019907840 logging_writer.py:48] [10099] accumulated_eval_time=321.347291, accumulated_logging_time=0.818218, accumulated_submission_time=2457.756464, global_step=10099, preemption_count=0, score=2457.756464, test/loss=0.288176, test/num_examples=3581, test/ssim=0.741103, total_duration=2780.274495, train/loss=0.259902, train/ssim=0.750700, validation/loss=0.286716, validation/num_examples=3554, validation/ssim=0.723882
I0204 11:58:19.504597 140397011515136 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.12931199371814728, loss=0.2863709330558777
I0204 11:58:41.324622 140397019907840 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.05847848951816559, loss=0.3516218960285187
I0204 11:59:04.993755 140397011515136 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.083248071372509, loss=0.24454328417778015
I0204 11:59:28.881349 140397019907840 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.1729954034090042, loss=0.3073505759239197
I0204 11:59:39.374637 140584300062528 spec.py:321] Evaluating on the training split.
I0204 11:59:40.758444 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 11:59:42.087191 140584300062528 spec.py:349] Evaluating on the test split.
I0204 11:59:43.417000 140584300062528 submission_runner.py:408] Time since start: 2864.38s, 	Step: 10445, 	{'train/ssim': 0.7509869847978864, 'train/loss': 0.25971748147692, 'validation/ssim': 0.7240853038609665, 'validation/loss': 0.2866183803131155, 'validation/num_examples': 3554, 'test/ssim': 0.7414004686191008, 'test/loss': 0.28797797975644024, 'test/num_examples': 3581, 'score': 2537.771735906601, 'total_duration': 2864.37513422966, 'accumulated_submission_time': 2537.771735906601, 'accumulated_eval_time': 325.3895990848541, 'accumulated_logging_time': 0.8493859767913818}
I0204 11:59:43.435933 140397011515136 logging_writer.py:48] [10445] accumulated_eval_time=325.389599, accumulated_logging_time=0.849386, accumulated_submission_time=2537.771736, global_step=10445, preemption_count=0, score=2537.771736, test/loss=0.287978, test/num_examples=3581, test/ssim=0.741400, total_duration=2864.375134, train/loss=0.259717, train/ssim=0.750987, validation/loss=0.286618, validation/num_examples=3554, validation/ssim=0.724085
I0204 11:59:54.730747 140397019907840 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.13516865670681, loss=0.21487586200237274
I0204 12:00:18.278262 140397011515136 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.10961780697107315, loss=0.2545098662376404
I0204 12:00:42.073072 140397019907840 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.1808970719575882, loss=0.3158538341522217
I0204 12:01:03.557808 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:01:04.940695 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:01:06.272203 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:01:07.602789 140584300062528 submission_runner.py:408] Time since start: 2948.56s, 	Step: 10790, 	{'train/ssim': 0.7511575562613351, 'train/loss': 0.25957843235560824, 'validation/ssim': 0.7242304555606359, 'validation/loss': 0.286358319713483, 'validation/num_examples': 3554, 'test/ssim': 0.741495575061959, 'test/loss': 0.28772633969867006, 'test/num_examples': 3581, 'score': 2617.872266769409, 'total_duration': 2948.560939311981, 'accumulated_submission_time': 2617.872266769409, 'accumulated_eval_time': 329.43454337120056, 'accumulated_logging_time': 0.8776884078979492}
I0204 12:01:07.621314 140397011515136 logging_writer.py:48] [10790] accumulated_eval_time=329.434543, accumulated_logging_time=0.877688, accumulated_submission_time=2617.872267, global_step=10790, preemption_count=0, score=2617.872267, test/loss=0.287726, test/num_examples=3581, test/ssim=0.741496, total_duration=2948.560939, train/loss=0.259578, train/ssim=0.751158, validation/loss=0.286358, validation/num_examples=3554, validation/ssim=0.724230
I0204 12:01:08.441312 140397019907840 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.15158335864543915, loss=0.19541636109352112
I0204 12:01:31.978105 140397011515136 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.059843868017196655, loss=0.25661471486091614
I0204 12:01:55.878766 140397019907840 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.09941762685775757, loss=0.3325715661048889
I0204 12:02:19.794194 140397011515136 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.3150574266910553, loss=0.250352144241333
I0204 12:02:27.635149 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:02:29.018632 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:02:30.351381 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:02:31.680539 140584300062528 submission_runner.py:408] Time since start: 3032.64s, 	Step: 11134, 	{'train/ssim': 0.7513892310006278, 'train/loss': 0.25928807258605957, 'validation/ssim': 0.7243891400974254, 'validation/loss': 0.2863875320941193, 'validation/num_examples': 3554, 'test/ssim': 0.7416386778745462, 'test/loss': 0.28777788125479964, 'test/num_examples': 3581, 'score': 2697.8649265766144, 'total_duration': 3032.638692140579, 'accumulated_submission_time': 2697.8649265766144, 'accumulated_eval_time': 333.47989439964294, 'accumulated_logging_time': 0.9055733680725098}
I0204 12:02:31.698429 140397019907840 logging_writer.py:48] [11134] accumulated_eval_time=333.479894, accumulated_logging_time=0.905573, accumulated_submission_time=2697.864927, global_step=11134, preemption_count=0, score=2697.864927, test/loss=0.287778, test/num_examples=3581, test/ssim=0.741639, total_duration=3032.638692, train/loss=0.259288, train/ssim=0.751389, validation/loss=0.286388, validation/num_examples=3554, validation/ssim=0.724389
I0204 12:02:45.411611 140397011515136 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.21840262413024902, loss=0.2470485419034958
I0204 12:03:09.264870 140397019907840 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.28333330154418945, loss=0.3005249500274658
I0204 12:03:33.054818 140397011515136 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.08247257769107819, loss=0.2592187821865082
I0204 12:03:51.721076 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:03:53.102353 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:03:54.431458 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:03:55.760302 140584300062528 submission_runner.py:408] Time since start: 3116.72s, 	Step: 11480, 	{'train/ssim': 0.7506914819989886, 'train/loss': 0.2594648599624634, 'validation/ssim': 0.7240741066404052, 'validation/loss': 0.2862425177836593, 'validation/num_examples': 3554, 'test/ssim': 0.74135724461568, 'test/loss': 0.28759359973863796, 'test/num_examples': 3581, 'score': 2777.8663704395294, 'total_duration': 3116.7184529304504, 'accumulated_submission_time': 2777.8663704395294, 'accumulated_eval_time': 337.51908659935, 'accumulated_logging_time': 0.9325578212738037}
I0204 12:03:55.777625 140397019907840 logging_writer.py:48] [11480] accumulated_eval_time=337.519087, accumulated_logging_time=0.932558, accumulated_submission_time=2777.866370, global_step=11480, preemption_count=0, score=2777.866370, test/loss=0.287594, test/num_examples=3581, test/ssim=0.741357, total_duration=3116.718453, train/loss=0.259465, train/ssim=0.750691, validation/loss=0.286243, validation/num_examples=3554, validation/ssim=0.724074
I0204 12:03:58.468425 140397011515136 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.2246047407388687, loss=0.2904142141342163
I0204 12:04:22.350472 140397019907840 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.2750805616378784, loss=0.24502088129520416
I0204 12:04:46.003959 140397011515136 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.06989757716655731, loss=0.2414810210466385
I0204 12:05:10.487732 140397019907840 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.22455091774463654, loss=0.2785114347934723
I0204 12:05:15.923635 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:05:17.300772 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:05:18.629477 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:05:19.959065 140584300062528 submission_runner.py:408] Time since start: 3200.92s, 	Step: 11824, 	{'train/ssim': 0.7505995886666434, 'train/loss': 0.26008808612823486, 'validation/ssim': 0.723615913627251, 'validation/loss': 0.2868656121953257, 'validation/num_examples': 3554, 'test/ssim': 0.7408781672149888, 'test/loss': 0.28832871459176906, 'test/num_examples': 3581, 'score': 2857.9913415908813, 'total_duration': 3200.917214870453, 'accumulated_submission_time': 2857.9913415908813, 'accumulated_eval_time': 341.55452609062195, 'accumulated_logging_time': 0.9591963291168213}
I0204 12:05:19.976091 140397011515136 logging_writer.py:48] [11824] accumulated_eval_time=341.554526, accumulated_logging_time=0.959196, accumulated_submission_time=2857.991342, global_step=11824, preemption_count=0, score=2857.991342, test/loss=0.288329, test/num_examples=3581, test/ssim=0.740878, total_duration=3200.917215, train/loss=0.260088, train/ssim=0.750600, validation/loss=0.286866, validation/num_examples=3554, validation/ssim=0.723616
I0204 12:05:36.220198 140397019907840 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.11766944825649261, loss=0.33841660618782043
I0204 12:06:00.019919 140397011515136 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.11247432976961136, loss=0.3244219422340393
I0204 12:06:23.959107 140397019907840 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.2893613576889038, loss=0.21942846477031708
I0204 12:06:40.109285 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:06:41.491472 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:06:42.819852 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:06:44.152177 140584300062528 submission_runner.py:408] Time since start: 3285.11s, 	Step: 12169, 	{'train/ssim': 0.7514924321855817, 'train/loss': 0.25900142533438547, 'validation/ssim': 0.7240672371799382, 'validation/loss': 0.28626415658413057, 'validation/num_examples': 3554, 'test/ssim': 0.7413234289915527, 'test/loss': 0.28767036665953993, 'test/num_examples': 3581, 'score': 2938.1020641326904, 'total_duration': 3285.1103279590607, 'accumulated_submission_time': 2938.1020641326904, 'accumulated_eval_time': 345.5973918437958, 'accumulated_logging_time': 0.9867033958435059}
I0204 12:06:44.169531 140397011515136 logging_writer.py:48] [12169] accumulated_eval_time=345.597392, accumulated_logging_time=0.986703, accumulated_submission_time=2938.102064, global_step=12169, preemption_count=0, score=2938.102064, test/loss=0.287670, test/num_examples=3581, test/ssim=0.741323, total_duration=3285.110328, train/loss=0.259001, train/ssim=0.751492, validation/loss=0.286264, validation/num_examples=3554, validation/ssim=0.724067
I0204 12:06:49.432585 140397019907840 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.19704879820346832, loss=0.2709173858165741
I0204 12:07:13.365087 140397011515136 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.06397709995508194, loss=0.279607355594635
I0204 12:07:37.095301 140397019907840 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.15001028776168823, loss=0.2524569630622864
I0204 12:08:01.035414 140397011515136 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.27270346879959106, loss=0.3328644633293152
I0204 12:08:04.226956 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:08:05.607036 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:08:06.937940 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:08:08.268344 140584300062528 submission_runner.py:408] Time since start: 3369.23s, 	Step: 12514, 	{'train/ssim': 0.7499089922223773, 'train/loss': 0.2597200189317976, 'validation/ssim': 0.7233776807382527, 'validation/loss': 0.286492978312289, 'validation/num_examples': 3554, 'test/ssim': 0.7406686603340548, 'test/loss': 0.2878473532729161, 'test/num_examples': 3581, 'score': 3018.1377742290497, 'total_duration': 3369.2264947891235, 'accumulated_submission_time': 3018.1377742290497, 'accumulated_eval_time': 349.6387412548065, 'accumulated_logging_time': 1.0136513710021973}
I0204 12:08:08.288057 140397019907840 logging_writer.py:48] [12514] accumulated_eval_time=349.638741, accumulated_logging_time=1.013651, accumulated_submission_time=3018.137774, global_step=12514, preemption_count=0, score=3018.137774, test/loss=0.287847, test/num_examples=3581, test/ssim=0.740669, total_duration=3369.226495, train/loss=0.259720, train/ssim=0.749909, validation/loss=0.286493, validation/num_examples=3554, validation/ssim=0.723378
I0204 12:08:26.609501 140397011515136 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.11049477756023407, loss=0.3711630702018738
I0204 12:08:50.525619 140397019907840 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.10157313942909241, loss=0.28917500376701355
I0204 12:09:14.404200 140397011515136 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.1530999094247818, loss=0.2490701973438263
I0204 12:09:28.353351 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:09:29.735077 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:09:31.064450 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:09:32.395032 140584300062528 submission_runner.py:408] Time since start: 3453.35s, 	Step: 12859, 	{'train/ssim': 0.7517422948564801, 'train/loss': 0.2592545918055943, 'validation/ssim': 0.7250731322761326, 'validation/loss': 0.2861169783936234, 'validation/num_examples': 3554, 'test/ssim': 0.7423111724640463, 'test/loss': 0.2875071517317963, 'test/num_examples': 3581, 'score': 3098.17995595932, 'total_duration': 3453.3531222343445, 'accumulated_submission_time': 3098.17995595932, 'accumulated_eval_time': 353.6803197860718, 'accumulated_logging_time': 1.04435133934021}
I0204 12:09:32.415944 140397019907840 logging_writer.py:48] [12859] accumulated_eval_time=353.680320, accumulated_logging_time=1.044351, accumulated_submission_time=3098.179956, global_step=12859, preemption_count=0, score=3098.179956, test/loss=0.287507, test/num_examples=3581, test/ssim=0.742311, total_duration=3453.353122, train/loss=0.259255, train/ssim=0.751742, validation/loss=0.286117, validation/num_examples=3554, validation/ssim=0.725073
I0204 12:09:40.568024 140397011515136 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.102836474776268, loss=0.21794365346431732
I0204 12:10:04.606240 140397019907840 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.10299307107925415, loss=0.2835899889469147
I0204 12:10:28.568552 140397011515136 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.18733727931976318, loss=0.24120566248893738
I0204 12:10:52.411870 140397019907840 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.2092963606119156, loss=0.19126161932945251
I0204 12:10:52.418036 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:10:53.743898 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:10:55.071405 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:10:56.404383 140584300062528 submission_runner.py:408] Time since start: 3537.36s, 	Step: 13201, 	{'train/ssim': 0.751594066619873, 'train/loss': 0.2592260496956961, 'validation/ssim': 0.7241303675216305, 'validation/loss': 0.28647570161921426, 'validation/num_examples': 3554, 'test/ssim': 0.7413691073547891, 'test/loss': 0.2878732944926347, 'test/num_examples': 3581, 'score': 3178.1596059799194, 'total_duration': 3537.362501144409, 'accumulated_submission_time': 3178.1596059799194, 'accumulated_eval_time': 357.6665780544281, 'accumulated_logging_time': 1.0757217407226562}
I0204 12:10:56.425370 140397011515136 logging_writer.py:48] [13201] accumulated_eval_time=357.666578, accumulated_logging_time=1.075722, accumulated_submission_time=3178.159606, global_step=13201, preemption_count=0, score=3178.159606, test/loss=0.287873, test/num_examples=3581, test/ssim=0.741369, total_duration=3537.362501, train/loss=0.259226, train/ssim=0.751594, validation/loss=0.286476, validation/num_examples=3554, validation/ssim=0.724130
I0204 12:11:17.888416 140397019907840 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.2264852672815323, loss=0.2551994323730469
I0204 12:11:41.561356 140397011515136 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.07402956485748291, loss=0.2866450250148773
I0204 12:12:05.366048 140397019907840 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.10528814047574997, loss=0.26903969049453735
I0204 12:12:16.654764 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:12:18.036801 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:12:19.369826 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:12:20.698390 140584300062528 submission_runner.py:408] Time since start: 3621.66s, 	Step: 13548, 	{'train/ssim': 0.7518584387642997, 'train/loss': 0.25964949812207905, 'validation/ssim': 0.7249348500369303, 'validation/loss': 0.28665308826212543, 'validation/num_examples': 3554, 'test/ssim': 0.7420486923170903, 'test/loss': 0.2880651095298974, 'test/num_examples': 3581, 'score': 3258.367030143738, 'total_duration': 3621.6565403938293, 'accumulated_submission_time': 3258.367030143738, 'accumulated_eval_time': 361.71016097068787, 'accumulated_logging_time': 1.1067495346069336}
I0204 12:12:20.715780 140397011515136 logging_writer.py:48] [13548] accumulated_eval_time=361.710161, accumulated_logging_time=1.106750, accumulated_submission_time=3258.367030, global_step=13548, preemption_count=0, score=3258.367030, test/loss=0.288065, test/num_examples=3581, test/ssim=0.742049, total_duration=3621.656540, train/loss=0.259649, train/ssim=0.751858, validation/loss=0.286653, validation/num_examples=3554, validation/ssim=0.724935
I0204 12:12:31.113833 140397019907840 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.08396407216787338, loss=0.2162521928548813
I0204 12:12:55.252241 140397011515136 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.1456776112318039, loss=0.3271693289279938
I0204 12:13:19.166978 140397019907840 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.16201964020729065, loss=0.2158288061618805
I0204 12:13:40.942659 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:13:42.323220 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:13:43.656537 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:13:44.988488 140584300062528 submission_runner.py:408] Time since start: 3705.95s, 	Step: 13893, 	{'train/ssim': 0.7509762900216239, 'train/loss': 0.2593644346509661, 'validation/ssim': 0.7240757553109173, 'validation/loss': 0.28617347970596513, 'validation/num_examples': 3554, 'test/ssim': 0.7411973703443522, 'test/loss': 0.287589679580599, 'test/num_examples': 3581, 'score': 3338.5711925029755, 'total_duration': 3705.9466314315796, 'accumulated_submission_time': 3338.5711925029755, 'accumulated_eval_time': 365.75594544410706, 'accumulated_logging_time': 1.1348917484283447}
I0204 12:13:45.007135 140397011515136 logging_writer.py:48] [13893] accumulated_eval_time=365.755945, accumulated_logging_time=1.134892, accumulated_submission_time=3338.571193, global_step=13893, preemption_count=0, score=3338.571193, test/loss=0.287590, test/num_examples=3581, test/ssim=0.741197, total_duration=3705.946631, train/loss=0.259364, train/ssim=0.750976, validation/loss=0.286173, validation/num_examples=3554, validation/ssim=0.724076
I0204 12:13:45.610324 140397019907840 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.3760530948638916, loss=0.23499688506126404
I0204 12:14:08.978559 140397011515136 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.18251684308052063, loss=0.33049309253692627
I0204 12:14:32.814825 140397019907840 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.18560419976711273, loss=0.27743053436279297
I0204 12:14:56.645183 140397011515136 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.21710464358329773, loss=0.23707059025764465
I0204 12:15:05.148814 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:15:06.529869 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:15:07.863415 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:15:09.194134 140584300062528 submission_runner.py:408] Time since start: 3790.15s, 	Step: 14237, 	{'train/ssim': 0.7518370492117745, 'train/loss': 0.2589819261005947, 'validation/ssim': 0.7242094350116066, 'validation/loss': 0.28632993166810283, 'validation/num_examples': 3554, 'test/ssim': 0.7414800989597877, 'test/loss': 0.28768618364501886, 'test/num_examples': 3581, 'score': 3418.6912846565247, 'total_duration': 3790.152283668518, 'accumulated_submission_time': 3418.6912846565247, 'accumulated_eval_time': 369.80122470855713, 'accumulated_logging_time': 1.1632394790649414}
I0204 12:15:09.212386 140397019907840 logging_writer.py:48] [14237] accumulated_eval_time=369.801225, accumulated_logging_time=1.163239, accumulated_submission_time=3418.691285, global_step=14237, preemption_count=0, score=3418.691285, test/loss=0.287686, test/num_examples=3581, test/ssim=0.741480, total_duration=3790.152284, train/loss=0.258982, train/ssim=0.751837, validation/loss=0.286330, validation/num_examples=3554, validation/ssim=0.724209
I0204 12:15:22.188972 140397011515136 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.09772567451000214, loss=0.2878841161727905
I0204 12:15:46.050913 140397019907840 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.09812094271183014, loss=0.22821085155010223
I0204 12:16:09.738919 140397011515136 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.0747692883014679, loss=0.36469143629074097
I0204 12:16:29.431410 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:16:30.812226 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:16:32.142616 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:16:33.471224 140584300062528 submission_runner.py:408] Time since start: 3874.43s, 	Step: 14583, 	{'train/ssim': 0.7517756053379604, 'train/loss': 0.25908333914620535, 'validation/ssim': 0.7246804739158342, 'validation/loss': 0.28622031225269945, 'validation/num_examples': 3554, 'test/ssim': 0.7419205201933817, 'test/loss': 0.28753363836480733, 'test/num_examples': 3581, 'score': 3498.888443470001, 'total_duration': 3874.429375886917, 'accumulated_submission_time': 3498.888443470001, 'accumulated_eval_time': 373.8409984111786, 'accumulated_logging_time': 1.191213607788086}
I0204 12:16:33.489507 140397019907840 logging_writer.py:48] [14583] accumulated_eval_time=373.840998, accumulated_logging_time=1.191214, accumulated_submission_time=3498.888443, global_step=14583, preemption_count=0, score=3498.888443, test/loss=0.287534, test/num_examples=3581, test/ssim=0.741921, total_duration=3874.429376, train/loss=0.259083, train/ssim=0.751776, validation/loss=0.286220, validation/num_examples=3554, validation/ssim=0.724680
I0204 12:16:35.390187 140397011515136 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.3682028353214264, loss=0.20449642837047577
I0204 12:16:59.404174 140397019907840 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.09355248510837555, loss=0.22360074520111084
I0204 12:17:23.194449 140397011515136 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.11135479062795639, loss=0.2661985754966736
I0204 12:17:46.773368 140397019907840 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.1425887793302536, loss=0.2345913201570511
I0204 12:17:53.603554 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:17:54.985186 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:17:56.316179 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:17:57.647422 140584300062528 submission_runner.py:408] Time since start: 3958.61s, 	Step: 14930, 	{'train/ssim': 0.7516927719116211, 'train/loss': 0.25924532754080637, 'validation/ssim': 0.7247757533325127, 'validation/loss': 0.2861635533355902, 'validation/num_examples': 3554, 'test/ssim': 0.7419288377460905, 'test/loss': 0.287559579584526, 'test/num_examples': 3581, 'score': 3578.980725288391, 'total_duration': 3958.6055693626404, 'accumulated_submission_time': 3578.980725288391, 'accumulated_eval_time': 377.8848206996918, 'accumulated_logging_time': 1.2186510562896729}
I0204 12:17:57.667159 140397011515136 logging_writer.py:48] [14930] accumulated_eval_time=377.884821, accumulated_logging_time=1.218651, accumulated_submission_time=3578.980725, global_step=14930, preemption_count=0, score=3578.980725, test/loss=0.287560, test/num_examples=3581, test/ssim=0.741929, total_duration=3958.605569, train/loss=0.259245, train/ssim=0.751693, validation/loss=0.286164, validation/num_examples=3554, validation/ssim=0.724776
I0204 12:18:12.347782 140397019907840 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.1280953586101532, loss=0.22765319049358368
I0204 12:18:36.614232 140397011515136 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.1291334182024002, loss=0.2076442986726761
I0204 12:19:00.308251 140397019907840 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.10618793964385986, loss=0.24450945854187012
I0204 12:19:17.679098 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:19:19.064806 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:19:20.396741 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:19:21.728939 140584300062528 submission_runner.py:408] Time since start: 4042.69s, 	Step: 15274, 	{'train/ssim': 0.7525625228881836, 'train/loss': 0.25946458748408724, 'validation/ssim': 0.7252395106086452, 'validation/loss': 0.28695113697814084, 'validation/num_examples': 3554, 'test/ssim': 0.7423833715486247, 'test/loss': 0.28831855626919856, 'test/num_examples': 3581, 'score': 3658.9713571071625, 'total_duration': 4042.6870880126953, 'accumulated_submission_time': 3658.9713571071625, 'accumulated_eval_time': 381.9346296787262, 'accumulated_logging_time': 1.2474379539489746}
I0204 12:19:21.748461 140397011515136 logging_writer.py:48] [15274] accumulated_eval_time=381.934630, accumulated_logging_time=1.247438, accumulated_submission_time=3658.971357, global_step=15274, preemption_count=0, score=3658.971357, test/loss=0.288319, test/num_examples=3581, test/ssim=0.742383, total_duration=4042.687088, train/loss=0.259465, train/ssim=0.752563, validation/loss=0.286951, validation/num_examples=3554, validation/ssim=0.725240
I0204 12:19:25.901633 140397019907840 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.165864959359169, loss=0.24184930324554443
I0204 12:19:50.096780 140397011515136 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.19719888269901276, loss=0.23460549116134644
I0204 12:20:13.912015 140397019907840 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.18847492337226868, loss=0.3465649485588074
I0204 12:20:37.853934 140397011515136 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.11462212353944778, loss=0.3039039969444275
I0204 12:20:41.973512 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:20:43.359724 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:20:44.692728 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:20:46.025028 140584300062528 submission_runner.py:408] Time since start: 4126.98s, 	Step: 15618, 	{'train/ssim': 0.7516856874738421, 'train/loss': 0.2591737338474819, 'validation/ssim': 0.7246266173457724, 'validation/loss': 0.28634938941487587, 'validation/num_examples': 3554, 'test/ssim': 0.741825345573862, 'test/loss': 0.287680593158772, 'test/num_examples': 3581, 'score': 3739.1749410629272, 'total_duration': 4126.983177185059, 'accumulated_submission_time': 3739.1749410629272, 'accumulated_eval_time': 385.9861137866974, 'accumulated_logging_time': 1.276132583618164}
I0204 12:20:46.043881 140397019907840 logging_writer.py:48] [15618] accumulated_eval_time=385.986114, accumulated_logging_time=1.276133, accumulated_submission_time=3739.174941, global_step=15618, preemption_count=0, score=3739.174941, test/loss=0.287681, test/num_examples=3581, test/ssim=0.741825, total_duration=4126.983177, train/loss=0.259174, train/ssim=0.751686, validation/loss=0.286349, validation/num_examples=3554, validation/ssim=0.724627
I0204 12:21:03.516574 140397011515136 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.1499776989221573, loss=0.24580822885036469
I0204 12:21:27.531882 140397019907840 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.10314340889453888, loss=0.30349910259246826
I0204 12:21:51.658421 140397011515136 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.2231847047805786, loss=0.2978680431842804
I0204 12:22:06.097464 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:22:07.483331 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:22:08.815104 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:22:10.146761 140584300062528 submission_runner.py:408] Time since start: 4211.10s, 	Step: 15962, 	{'train/ssim': 0.7520236968994141, 'train/loss': 0.2588274819510324, 'validation/ssim': 0.7249162337990644, 'validation/loss': 0.28589688088025816, 'validation/num_examples': 3554, 'test/ssim': 0.7421772735007679, 'test/loss': 0.28714755393046637, 'test/num_examples': 3581, 'score': 3819.2066938877106, 'total_duration': 4211.104909896851, 'accumulated_submission_time': 3819.2066938877106, 'accumulated_eval_time': 390.03538823127747, 'accumulated_logging_time': 1.3046724796295166}
I0204 12:22:10.165869 140397019907840 logging_writer.py:48] [15962] accumulated_eval_time=390.035388, accumulated_logging_time=1.304672, accumulated_submission_time=3819.206694, global_step=15962, preemption_count=0, score=3819.206694, test/loss=0.287148, test/num_examples=3581, test/ssim=0.742177, total_duration=4211.104910, train/loss=0.258827, train/ssim=0.752024, validation/loss=0.285897, validation/num_examples=3554, validation/ssim=0.724916
I0204 12:22:17.277134 140397011515136 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.2125878781080246, loss=0.22382456064224243
I0204 12:22:41.269800 140397019907840 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.13961517810821533, loss=0.27653759717941284
I0204 12:23:05.508120 140397011515136 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.12138053774833679, loss=0.25844624638557434
I0204 12:23:29.434661 140397019907840 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.3045817017555237, loss=0.22189012169837952
I0204 12:23:30.303155 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:23:31.683618 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:23:33.011638 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:23:34.342434 140584300062528 submission_runner.py:408] Time since start: 4295.30s, 	Step: 16305, 	{'train/ssim': 0.7516825539725167, 'train/loss': 0.2592099905014038, 'validation/ssim': 0.72449877668648, 'validation/loss': 0.28637911700504715, 'validation/num_examples': 3554, 'test/ssim': 0.7417084907759705, 'test/loss': 0.28774069088592574, 'test/num_examples': 3581, 'score': 3899.3228511810303, 'total_duration': 4295.300581455231, 'accumulated_submission_time': 3899.3228511810303, 'accumulated_eval_time': 394.0746328830719, 'accumulated_logging_time': 1.3331573009490967}
I0204 12:23:34.362149 140397011515136 logging_writer.py:48] [16305] accumulated_eval_time=394.074633, accumulated_logging_time=1.333157, accumulated_submission_time=3899.322851, global_step=16305, preemption_count=0, score=3899.322851, test/loss=0.287741, test/num_examples=3581, test/ssim=0.741708, total_duration=4295.300581, train/loss=0.259210, train/ssim=0.751683, validation/loss=0.286379, validation/num_examples=3554, validation/ssim=0.724499
I0204 12:23:54.996114 140397019907840 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.45000752806663513, loss=0.2425236850976944
I0204 12:24:18.506467 140397011515136 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.1283801943063736, loss=0.2080262154340744
I0204 12:24:42.251827 140397019907840 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.21806804835796356, loss=0.1888175904750824
I0204 12:24:54.547977 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:24:55.931311 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:24:57.260699 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:24:58.591850 140584300062528 submission_runner.py:408] Time since start: 4379.55s, 	Step: 16653, 	{'train/ssim': 0.7520562580653599, 'train/loss': 0.2589167526790074, 'validation/ssim': 0.7248071467668472, 'validation/loss': 0.2861561686655881, 'validation/num_examples': 3554, 'test/ssim': 0.7420754175684167, 'test/loss': 0.2875004022423031, 'test/num_examples': 3581, 'score': 3979.487622022629, 'total_duration': 4379.550000429153, 'accumulated_submission_time': 3979.487622022629, 'accumulated_eval_time': 398.1184675693512, 'accumulated_logging_time': 1.3620598316192627}
I0204 12:24:58.610275 140397011515136 logging_writer.py:48] [16653] accumulated_eval_time=398.118468, accumulated_logging_time=1.362060, accumulated_submission_time=3979.487622, global_step=16653, preemption_count=0, score=3979.487622, test/loss=0.287500, test/num_examples=3581, test/ssim=0.742075, total_duration=4379.550000, train/loss=0.258917, train/ssim=0.752056, validation/loss=0.286156, validation/num_examples=3554, validation/ssim=0.724807
I0204 12:25:07.927880 140397019907840 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.1291050761938095, loss=0.2658778429031372
I0204 12:25:31.753990 140397011515136 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.19101472198963165, loss=0.23761315643787384
I0204 12:25:55.561612 140397019907840 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.07006600499153137, loss=0.35467100143432617
I0204 12:26:18.608737 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:26:19.992040 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:26:21.321627 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:26:22.651930 140584300062528 submission_runner.py:408] Time since start: 4463.61s, 	Step: 16997, 	{'train/ssim': 0.7524524416242327, 'train/loss': 0.25853409085954937, 'validation/ssim': 0.7252197952571047, 'validation/loss': 0.2857100659028559, 'validation/num_examples': 3554, 'test/ssim': 0.7424610929427883, 'test/loss': 0.287021767989912, 'test/num_examples': 3581, 'score': 4059.4647312164307, 'total_duration': 4463.610082149506, 'accumulated_submission_time': 4059.4647312164307, 'accumulated_eval_time': 402.1616246700287, 'accumulated_logging_time': 1.389885425567627}
I0204 12:26:22.671463 140397011515136 logging_writer.py:48] [16997] accumulated_eval_time=402.161625, accumulated_logging_time=1.389885, accumulated_submission_time=4059.464731, global_step=16997, preemption_count=0, score=4059.464731, test/loss=0.287022, test/num_examples=3581, test/ssim=0.742461, total_duration=4463.610082, train/loss=0.258534, train/ssim=0.752452, validation/loss=0.285710, validation/num_examples=3554, validation/ssim=0.725220
I0204 12:26:22.982602 140397019907840 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.11027181148529053, loss=0.2398330718278885
I0204 12:26:45.369919 140397011515136 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.30282557010650635, loss=0.275288850069046
I0204 12:27:09.430510 140397019907840 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.39282509684562683, loss=0.3444563150405884
I0204 12:27:33.385779 140397011515136 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.10816707462072372, loss=0.30722618103027344
I0204 12:27:42.712238 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:27:44.093372 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:27:45.423496 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:27:46.753606 140584300062528 submission_runner.py:408] Time since start: 4547.71s, 	Step: 17340, 	{'train/ssim': 0.7515924998692104, 'train/loss': 0.2602828230176653, 'validation/ssim': 0.7249902178882949, 'validation/loss': 0.2872200420081246, 'validation/num_examples': 3554, 'test/ssim': 0.7420885756640953, 'test/loss': 0.28857786620139275, 'test/num_examples': 3581, 'score': 4139.484055280685, 'total_duration': 4547.71174955368, 'accumulated_submission_time': 4139.484055280685, 'accumulated_eval_time': 406.2029480934143, 'accumulated_logging_time': 1.4190490245819092}
I0204 12:27:46.772547 140397019907840 logging_writer.py:48] [17340] accumulated_eval_time=406.202948, accumulated_logging_time=1.419049, accumulated_submission_time=4139.484055, global_step=17340, preemption_count=0, score=4139.484055, test/loss=0.288578, test/num_examples=3581, test/ssim=0.742089, total_duration=4547.711750, train/loss=0.260283, train/ssim=0.751592, validation/loss=0.287220, validation/num_examples=3554, validation/ssim=0.724990
I0204 12:27:59.237397 140397011515136 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.16549330949783325, loss=0.2577900290489197
I0204 12:28:22.918487 140397019907840 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.1267928183078766, loss=0.301950067281723
I0204 12:28:46.587641 140397011515136 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.14878813922405243, loss=0.2571479082107544
I0204 12:29:06.896537 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:29:08.278141 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:29:09.608432 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:29:10.935902 140584300062528 submission_runner.py:408] Time since start: 4631.89s, 	Step: 17687, 	{'train/ssim': 0.7524777821132115, 'train/loss': 0.25873615060533794, 'validation/ssim': 0.725357871412493, 'validation/loss': 0.2860411052027645, 'validation/num_examples': 3554, 'test/ssim': 0.7425334965573513, 'test/loss': 0.28743795242032605, 'test/num_examples': 3581, 'score': 4219.586560964584, 'total_duration': 4631.894050359726, 'accumulated_submission_time': 4219.586560964584, 'accumulated_eval_time': 410.2422773838043, 'accumulated_logging_time': 1.4473683834075928}
I0204 12:29:10.955729 140397019907840 logging_writer.py:48] [17687] accumulated_eval_time=410.242277, accumulated_logging_time=1.447368, accumulated_submission_time=4219.586561, global_step=17687, preemption_count=0, score=4219.586561, test/loss=0.287438, test/num_examples=3581, test/ssim=0.742533, total_duration=4631.894050, train/loss=0.258736, train/ssim=0.752478, validation/loss=0.286041, validation/num_examples=3554, validation/ssim=0.725358
I0204 12:29:11.992352 140397011515136 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.1194213405251503, loss=0.2858178913593292
I0204 12:29:35.737784 140397019907840 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.2565319538116455, loss=0.36193498969078064
I0204 12:29:59.906433 140397011515136 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.08221141993999481, loss=0.3199671506881714
I0204 12:30:24.028688 140397019907840 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.10558865964412689, loss=0.36750328540802
I0204 12:30:30.957556 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:30:32.335967 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:30:33.667801 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:30:35.001911 140584300062528 submission_runner.py:408] Time since start: 4715.96s, 	Step: 18031, 	{'train/ssim': 0.7531301634652274, 'train/loss': 0.2585129737854004, 'validation/ssim': 0.7258307650710467, 'validation/loss': 0.28590819831637765, 'validation/num_examples': 3554, 'test/ssim': 0.743022118690659, 'test/loss': 0.28725223919427184, 'test/num_examples': 3581, 'score': 4299.56721663475, 'total_duration': 4715.960064649582, 'accumulated_submission_time': 4299.56721663475, 'accumulated_eval_time': 414.28659558296204, 'accumulated_logging_time': 1.4766151905059814}
I0204 12:30:35.020432 140397011515136 logging_writer.py:48] [18031] accumulated_eval_time=414.286596, accumulated_logging_time=1.476615, accumulated_submission_time=4299.567217, global_step=18031, preemption_count=0, score=4299.567217, test/loss=0.287252, test/num_examples=3581, test/ssim=0.743022, total_duration=4715.960065, train/loss=0.258513, train/ssim=0.753130, validation/loss=0.285908, validation/num_examples=3554, validation/ssim=0.725831
I0204 12:30:49.292825 140397019907840 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.24358899891376495, loss=0.22983703017234802
I0204 12:31:12.979946 140397011515136 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.10206398367881775, loss=0.358320415019989
I0204 12:31:37.023171 140397019907840 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.5786306858062744, loss=0.20253217220306396
I0204 12:31:55.067026 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:31:56.449704 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:31:57.782384 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:31:59.116037 140584300062528 submission_runner.py:408] Time since start: 4800.07s, 	Step: 18376, 	{'train/ssim': 0.7519820758274623, 'train/loss': 0.25845859731946674, 'validation/ssim': 0.7246246938968416, 'validation/loss': 0.2856576690931433, 'validation/num_examples': 3554, 'test/ssim': 0.7419246789697361, 'test/loss': 0.28695168238184166, 'test/num_examples': 3581, 'score': 4379.5926213264465, 'total_duration': 4800.07418346405, 'accumulated_submission_time': 4379.5926213264465, 'accumulated_eval_time': 418.3355646133423, 'accumulated_logging_time': 1.5043630599975586}
I0204 12:31:59.135123 140397011515136 logging_writer.py:48] [18376] accumulated_eval_time=418.335565, accumulated_logging_time=1.504363, accumulated_submission_time=4379.592621, global_step=18376, preemption_count=0, score=4379.592621, test/loss=0.286952, test/num_examples=3581, test/ssim=0.741925, total_duration=4800.074183, train/loss=0.258459, train/ssim=0.751982, validation/loss=0.285658, validation/num_examples=3554, validation/ssim=0.724625
I0204 12:32:02.862297 140397019907840 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.12613612413406372, loss=0.2855621874332428
I0204 12:32:27.143350 140397011515136 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.10520677268505096, loss=0.2305830419063568
I0204 12:32:50.386567 140397019907840 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.06439784169197083, loss=0.29419976472854614
I0204 12:33:14.320091 140397011515136 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.19369752705097198, loss=0.30332237482070923
I0204 12:33:19.195310 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:33:20.578915 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:33:21.907208 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:33:23.236282 140584300062528 submission_runner.py:408] Time since start: 4884.19s, 	Step: 18722, 	{'train/ssim': 0.7529837744576591, 'train/loss': 0.25822533879961285, 'validation/ssim': 0.7253613061427265, 'validation/loss': 0.2858288045270294, 'validation/num_examples': 3554, 'test/ssim': 0.7424981128700083, 'test/loss': 0.2871849488293249, 'test/num_examples': 3581, 'score': 4459.631384849548, 'total_duration': 4884.19443488121, 'accumulated_submission_time': 4459.631384849548, 'accumulated_eval_time': 422.3765048980713, 'accumulated_logging_time': 1.5328974723815918}
I0204 12:33:23.255313 140397019907840 logging_writer.py:48] [18722] accumulated_eval_time=422.376505, accumulated_logging_time=1.532897, accumulated_submission_time=4459.631385, global_step=18722, preemption_count=0, score=4459.631385, test/loss=0.287185, test/num_examples=3581, test/ssim=0.742498, total_duration=4884.194435, train/loss=0.258225, train/ssim=0.752984, validation/loss=0.285829, validation/num_examples=3554, validation/ssim=0.725361
I0204 12:33:39.831576 140397011515136 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.11394109576940536, loss=0.25981947779655457
I0204 12:34:03.683773 140397019907840 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.105024553835392, loss=0.2786184549331665
I0204 12:34:27.726177 140397011515136 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.1550077199935913, loss=0.2927599847316742
I0204 12:34:43.495361 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:34:44.876339 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:34:46.208529 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:34:47.540427 140584300062528 submission_runner.py:408] Time since start: 4968.50s, 	Step: 19067, 	{'train/ssim': 0.7525200843811035, 'train/loss': 0.25815859862736296, 'validation/ssim': 0.7251618857053672, 'validation/loss': 0.2855097696092871, 'validation/num_examples': 3554, 'test/ssim': 0.7424585704063111, 'test/loss': 0.2868095340425161, 'test/num_examples': 3581, 'score': 4539.849860191345, 'total_duration': 4968.498574972153, 'accumulated_submission_time': 4539.849860191345, 'accumulated_eval_time': 426.42155289649963, 'accumulated_logging_time': 1.5613839626312256}
I0204 12:34:47.559891 140397019907840 logging_writer.py:48] [19067] accumulated_eval_time=426.421553, accumulated_logging_time=1.561384, accumulated_submission_time=4539.849860, global_step=19067, preemption_count=0, score=4539.849860, test/loss=0.286810, test/num_examples=3581, test/ssim=0.742459, total_duration=4968.498575, train/loss=0.258159, train/ssim=0.752520, validation/loss=0.285510, validation/num_examples=3554, validation/ssim=0.725162
I0204 12:34:53.363604 140397011515136 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.12565703690052032, loss=0.36349165439605713
I0204 12:35:17.148264 140397019907840 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.09559684246778488, loss=0.3516877591609955
I0204 12:35:40.832909 140397011515136 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.10302568972110748, loss=0.31618738174438477
I0204 12:36:05.429844 140397019907840 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.1221112534403801, loss=0.20231908559799194
I0204 12:36:07.561438 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:36:08.942098 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:36:10.272235 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:36:11.606189 140584300062528 submission_runner.py:408] Time since start: 5052.56s, 	Step: 19410, 	{'train/ssim': 0.7519347327096122, 'train/loss': 0.25834107398986816, 'validation/ssim': 0.7246815043349043, 'validation/loss': 0.28554320670811056, 'validation/num_examples': 3554, 'test/ssim': 0.7419808565388509, 'test/loss': 0.28683131648588034, 'test/num_examples': 3581, 'score': 4619.828453540802, 'total_duration': 5052.564338922501, 'accumulated_submission_time': 4619.828453540802, 'accumulated_eval_time': 430.4662718772888, 'accumulated_logging_time': 1.592024326324463}
I0204 12:36:11.625749 140397011515136 logging_writer.py:48] [19410] accumulated_eval_time=430.466272, accumulated_logging_time=1.592024, accumulated_submission_time=4619.828454, global_step=19410, preemption_count=0, score=4619.828454, test/loss=0.286831, test/num_examples=3581, test/ssim=0.741981, total_duration=5052.564339, train/loss=0.258341, train/ssim=0.751935, validation/loss=0.285543, validation/num_examples=3554, validation/ssim=0.724682
I0204 12:36:30.927301 140397019907840 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.2508275508880615, loss=0.3108255863189697
I0204 12:36:54.924633 140397011515136 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.22047491371631622, loss=0.25866883993148804
I0204 12:37:18.641963 140397019907840 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.22389549016952515, loss=0.247919961810112
I0204 12:37:31.819537 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:37:33.200411 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:37:34.530615 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:37:35.860601 140584300062528 submission_runner.py:408] Time since start: 5136.82s, 	Step: 19757, 	{'train/ssim': 0.7540554319109235, 'train/loss': 0.25782649857657297, 'validation/ssim': 0.7263243358056064, 'validation/loss': 0.2855517076654386, 'validation/num_examples': 3554, 'test/ssim': 0.7435532148841106, 'test/loss': 0.28688728952501047, 'test/num_examples': 3581, 'score': 4700.001065015793, 'total_duration': 5136.818740844727, 'accumulated_submission_time': 4700.001065015793, 'accumulated_eval_time': 434.50729513168335, 'accumulated_logging_time': 1.6206250190734863}
I0204 12:37:35.880463 140397011515136 logging_writer.py:48] [19757] accumulated_eval_time=434.507295, accumulated_logging_time=1.620625, accumulated_submission_time=4700.001065, global_step=19757, preemption_count=0, score=4700.001065, test/loss=0.286887, test/num_examples=3581, test/ssim=0.743553, total_duration=5136.818741, train/loss=0.257826, train/ssim=0.754055, validation/loss=0.285552, validation/num_examples=3554, validation/ssim=0.726324
I0204 12:37:44.140085 140397019907840 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.14260581135749817, loss=0.28456512093544006
I0204 12:38:07.844551 140397011515136 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.09463491290807724, loss=0.2757933735847473
I0204 12:38:31.440079 140397019907840 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.09009623527526855, loss=0.3484763503074646
I0204 12:38:55.300357 140397011515136 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.12947094440460205, loss=0.4164179563522339
I0204 12:38:55.936599 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:38:57.315049 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:38:58.644219 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:38:59.975162 140584300062528 submission_runner.py:408] Time since start: 5220.93s, 	Step: 20104, 	{'train/ssim': 0.752790996006557, 'train/loss': 0.2582331725529262, 'validation/ssim': 0.7253982638400394, 'validation/loss': 0.2855855912791925, 'validation/num_examples': 3554, 'test/ssim': 0.7426360342563181, 'test/loss': 0.286899697677412, 'test/num_examples': 3581, 'score': 4780.03605055809, 'total_duration': 5220.933315753937, 'accumulated_submission_time': 4780.03605055809, 'accumulated_eval_time': 438.54583048820496, 'accumulated_logging_time': 1.6494874954223633}
I0204 12:38:59.994088 140397019907840 logging_writer.py:48] [20104] accumulated_eval_time=438.545830, accumulated_logging_time=1.649487, accumulated_submission_time=4780.036051, global_step=20104, preemption_count=0, score=4780.036051, test/loss=0.286900, test/num_examples=3581, test/ssim=0.742636, total_duration=5220.933316, train/loss=0.258233, train/ssim=0.752791, validation/loss=0.285586, validation/num_examples=3554, validation/ssim=0.725398
I0204 12:39:20.957495 140397011515136 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.24575354158878326, loss=0.2803319990634918
I0204 12:39:44.914454 140397019907840 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.18891914188861847, loss=0.24186086654663086
I0204 12:40:09.064521 140397011515136 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.0897422805428505, loss=0.23690059781074524
I0204 12:40:20.215519 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:40:21.596592 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:40:22.926818 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:40:24.260248 140584300062528 submission_runner.py:408] Time since start: 5305.22s, 	Step: 20447, 	{'train/ssim': 0.7531872476850238, 'train/loss': 0.2581703151975359, 'validation/ssim': 0.7259412259953574, 'validation/loss': 0.28545850626055147, 'validation/num_examples': 3554, 'test/ssim': 0.7431528815275062, 'test/loss': 0.2867745594151424, 'test/num_examples': 3581, 'score': 4860.2350742816925, 'total_duration': 5305.218400716782, 'accumulated_submission_time': 4860.2350742816925, 'accumulated_eval_time': 442.5905215740204, 'accumulated_logging_time': 1.6790635585784912}
I0204 12:40:24.279837 140397019907840 logging_writer.py:48] [20447] accumulated_eval_time=442.590522, accumulated_logging_time=1.679064, accumulated_submission_time=4860.235074, global_step=20447, preemption_count=0, score=4860.235074, test/loss=0.286775, test/num_examples=3581, test/ssim=0.743153, total_duration=5305.218401, train/loss=0.258170, train/ssim=0.753187, validation/loss=0.285459, validation/num_examples=3554, validation/ssim=0.725941
I0204 12:40:35.087636 140397011515136 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.4824344515800476, loss=0.29702597856521606
I0204 12:40:58.972229 140397019907840 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.1959170699119568, loss=0.24106527864933014
I0204 12:41:22.962444 140397011515136 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.08420815318822861, loss=0.23039361834526062
I0204 12:41:44.494563 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:41:45.878155 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:41:47.210685 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:41:48.545835 140584300062528 submission_runner.py:408] Time since start: 5389.50s, 	Step: 20791, 	{'train/ssim': 0.753039973122733, 'train/loss': 0.25777106625693186, 'validation/ssim': 0.7251662821600662, 'validation/loss': 0.2855243843864308, 'validation/num_examples': 3554, 'test/ssim': 0.7424073697334892, 'test/loss': 0.28690133391728917, 'test/num_examples': 3581, 'score': 4940.427654981613, 'total_duration': 5389.503933191299, 'accumulated_submission_time': 4940.427654981613, 'accumulated_eval_time': 446.64170718193054, 'accumulated_logging_time': 1.7088754177093506}
I0204 12:41:48.569460 140397019907840 logging_writer.py:48] [20791] accumulated_eval_time=446.641707, accumulated_logging_time=1.708875, accumulated_submission_time=4940.427655, global_step=20791, preemption_count=0, score=4940.427655, test/loss=0.286901, test/num_examples=3581, test/ssim=0.742407, total_duration=5389.503933, train/loss=0.257771, train/ssim=0.753040, validation/loss=0.285524, validation/num_examples=3554, validation/ssim=0.725166
I0204 12:41:49.319060 140397011515136 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.12115955352783203, loss=0.2709553837776184
I0204 12:42:12.385548 140397019907840 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.1443706750869751, loss=0.28532689809799194
I0204 12:42:36.208673 140397011515136 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.26146867871284485, loss=0.3906188905239105
I0204 12:42:59.678451 140397019907840 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.12693914771080017, loss=0.2833242416381836
I0204 12:43:08.597505 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:43:09.977879 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:43:11.309116 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:43:12.640265 140584300062528 submission_runner.py:408] Time since start: 5473.60s, 	Step: 21138, 	{'train/ssim': 0.7532409940447126, 'train/loss': 0.2579892703465053, 'validation/ssim': 0.7257597348498172, 'validation/loss': 0.285431011245032, 'validation/num_examples': 3554, 'test/ssim': 0.7429243533580006, 'test/loss': 0.2867768433333042, 'test/num_examples': 3581, 'score': 5020.432681083679, 'total_duration': 5473.598413228989, 'accumulated_submission_time': 5020.432681083679, 'accumulated_eval_time': 450.68442273139954, 'accumulated_logging_time': 1.743255853652954}
I0204 12:43:12.659916 140397011515136 logging_writer.py:48] [21138] accumulated_eval_time=450.684423, accumulated_logging_time=1.743256, accumulated_submission_time=5020.432681, global_step=21138, preemption_count=0, score=5020.432681, test/loss=0.286777, test/num_examples=3581, test/ssim=0.742924, total_duration=5473.598413, train/loss=0.257989, train/ssim=0.753241, validation/loss=0.285431, validation/num_examples=3554, validation/ssim=0.725760
I0204 12:43:25.558172 140397019907840 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.15074236690998077, loss=0.22081604599952698
I0204 12:43:49.415015 140397011515136 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.17947587370872498, loss=0.30308985710144043
I0204 12:44:13.169422 140397019907840 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.1028708815574646, loss=0.2549140453338623
I0204 12:44:32.640424 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:44:34.022980 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:44:35.353305 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:44:36.684617 140584300062528 submission_runner.py:408] Time since start: 5557.64s, 	Step: 21483, 	{'train/ssim': 0.7530279840741839, 'train/loss': 0.25805517605372835, 'validation/ssim': 0.7256322376635481, 'validation/loss': 0.2854780842228827, 'validation/num_examples': 3554, 'test/ssim': 0.742838178057805, 'test/loss': 0.28676242396938706, 'test/num_examples': 3581, 'score': 5100.391660451889, 'total_duration': 5557.642760276794, 'accumulated_submission_time': 5100.391660451889, 'accumulated_eval_time': 454.7285809516907, 'accumulated_logging_time': 1.772273302078247}
I0204 12:44:36.704710 140397011515136 logging_writer.py:48] [21483] accumulated_eval_time=454.728581, accumulated_logging_time=1.772273, accumulated_submission_time=5100.391660, global_step=21483, preemption_count=0, score=5100.391660, test/loss=0.286762, test/num_examples=3581, test/ssim=0.742838, total_duration=5557.642760, train/loss=0.258055, train/ssim=0.753028, validation/loss=0.285478, validation/num_examples=3554, validation/ssim=0.725632
I0204 12:44:38.749451 140397019907840 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.16017530858516693, loss=0.2528844475746155
I0204 12:45:03.163006 140397011515136 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.14180772006511688, loss=0.2352907359600067
I0204 12:45:27.209523 140397019907840 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.1454474925994873, loss=0.3973444402217865
I0204 12:45:51.178868 140397011515136 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.31464892625808716, loss=0.1806565225124359
I0204 12:45:56.842907 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:45:58.224186 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:45:59.555655 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:46:00.889141 140584300062528 submission_runner.py:408] Time since start: 5641.85s, 	Step: 21825, 	{'train/ssim': 0.753004619053432, 'train/loss': 0.257967335837228, 'validation/ssim': 0.7253357517497889, 'validation/loss': 0.28570309340048183, 'validation/num_examples': 3554, 'test/ssim': 0.7424775916948827, 'test/loss': 0.2871336799798415, 'test/num_examples': 3581, 'score': 5180.50639796257, 'total_duration': 5641.847291946411, 'accumulated_submission_time': 5180.50639796257, 'accumulated_eval_time': 458.77478289604187, 'accumulated_logging_time': 1.8035430908203125}
I0204 12:46:00.909074 140397019907840 logging_writer.py:48] [21825] accumulated_eval_time=458.774783, accumulated_logging_time=1.803543, accumulated_submission_time=5180.506398, global_step=21825, preemption_count=0, score=5180.506398, test/loss=0.287134, test/num_examples=3581, test/ssim=0.742478, total_duration=5641.847292, train/loss=0.257967, train/ssim=0.753005, validation/loss=0.285703, validation/num_examples=3554, validation/ssim=0.725336
I0204 12:46:16.568025 140397011515136 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.21746940910816193, loss=0.2773013710975647
I0204 12:46:40.087526 140397019907840 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.12821060419082642, loss=0.3544059991836548
I0204 12:47:03.651169 140397011515136 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.08600261807441711, loss=0.291959673166275
I0204 12:47:21.098501 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:47:22.481943 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:47:23.813048 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:47:25.145045 140584300062528 submission_runner.py:408] Time since start: 5726.10s, 	Step: 22173, 	{'train/ssim': 0.7532924243382045, 'train/loss': 0.25779662813459125, 'validation/ssim': 0.7257460646234877, 'validation/loss': 0.2853456753723797, 'validation/num_examples': 3554, 'test/ssim': 0.7429429655866029, 'test/loss': 0.28666609034662105, 'test/num_examples': 3581, 'score': 5260.6730744838715, 'total_duration': 5726.103197097778, 'accumulated_submission_time': 5260.6730744838715, 'accumulated_eval_time': 462.82131361961365, 'accumulated_logging_time': 1.834075689315796}
I0204 12:47:25.165194 140397019907840 logging_writer.py:48] [22173] accumulated_eval_time=462.821314, accumulated_logging_time=1.834076, accumulated_submission_time=5260.673074, global_step=22173, preemption_count=0, score=5260.673074, test/loss=0.286666, test/num_examples=3581, test/ssim=0.742943, total_duration=5726.103197, train/loss=0.257797, train/ssim=0.753292, validation/loss=0.285346, validation/num_examples=3554, validation/ssim=0.725746
I0204 12:47:29.469708 140397011515136 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.17943258583545685, loss=0.27285319566726685
I0204 12:47:53.158279 140397019907840 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.21016518771648407, loss=0.2512896955013275
I0204 12:48:17.095781 140397011515136 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.13268542289733887, loss=0.28928500413894653
I0204 12:48:41.004038 140397019907840 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.41586828231811523, loss=0.24218954145908356
I0204 12:48:45.221588 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:48:46.603711 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:48:47.934106 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:48:49.264977 140584300062528 submission_runner.py:408] Time since start: 5810.22s, 	Step: 22519, 	{'train/ssim': 0.7536420822143555, 'train/loss': 0.2580252374921526, 'validation/ssim': 0.7262866224676421, 'validation/loss': 0.2855393769839002, 'validation/num_examples': 3554, 'test/ssim': 0.743415566204447, 'test/loss': 0.28686271183852274, 'test/num_examples': 3581, 'score': 5340.706670284271, 'total_duration': 5810.223093986511, 'accumulated_submission_time': 5340.706670284271, 'accumulated_eval_time': 466.86464047431946, 'accumulated_logging_time': 1.8650314807891846}
I0204 12:48:49.291063 140397011515136 logging_writer.py:48] [22519] accumulated_eval_time=466.864640, accumulated_logging_time=1.865031, accumulated_submission_time=5340.706670, global_step=22519, preemption_count=0, score=5340.706670, test/loss=0.286863, test/num_examples=3581, test/ssim=0.743416, total_duration=5810.223094, train/loss=0.258025, train/ssim=0.753642, validation/loss=0.285539, validation/num_examples=3554, validation/ssim=0.726287
I0204 12:49:06.974733 140397019907840 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.19271588325500488, loss=0.23839043080806732
I0204 12:49:31.135966 140397011515136 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.16167090833187103, loss=0.19511450827121735
I0204 12:49:55.460911 140397019907840 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.29338622093200684, loss=0.23501574993133545
I0204 12:50:09.435696 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:50:10.815903 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:50:12.147513 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:50:13.480951 140584300062528 submission_runner.py:408] Time since start: 5894.44s, 	Step: 22860, 	{'train/ssim': 0.7531393596104213, 'train/loss': 0.2581378732408796, 'validation/ssim': 0.7255267914453785, 'validation/loss': 0.2857794474535734, 'validation/num_examples': 3554, 'test/ssim': 0.7426878485190939, 'test/loss': 0.28715386027165946, 'test/num_examples': 3581, 'score': 5420.829624176025, 'total_duration': 5894.439101219177, 'accumulated_submission_time': 5420.829624176025, 'accumulated_eval_time': 470.9098572731018, 'accumulated_logging_time': 1.9009425640106201}
I0204 12:50:13.501114 140397011515136 logging_writer.py:48] [22860] accumulated_eval_time=470.909857, accumulated_logging_time=1.900943, accumulated_submission_time=5420.829624, global_step=22860, preemption_count=0, score=5420.829624, test/loss=0.287154, test/num_examples=3581, test/ssim=0.742688, total_duration=5894.439101, train/loss=0.258138, train/ssim=0.753139, validation/loss=0.285779, validation/num_examples=3554, validation/ssim=0.725527
I0204 12:50:21.029249 140397019907840 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.4333425760269165, loss=0.1957809031009674
I0204 12:50:44.908499 140397011515136 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.17954228818416595, loss=0.2695721983909607
I0204 12:51:08.544819 140397019907840 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.23342275619506836, loss=0.3020557165145874
I0204 12:51:32.128062 140397011515136 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.10647531598806381, loss=0.32791346311569214
I0204 12:51:33.524330 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:51:34.907533 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:51:36.243239 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:51:37.578629 140584300062528 submission_runner.py:408] Time since start: 5978.54s, 	Step: 23207, 	{'train/ssim': 0.7534748486110142, 'train/loss': 0.2577291897365025, 'validation/ssim': 0.7260389784178038, 'validation/loss': 0.2853734451663179, 'validation/num_examples': 3554, 'test/ssim': 0.7432383750610863, 'test/loss': 0.2866646586367286, 'test/num_examples': 3581, 'score': 5500.831784963608, 'total_duration': 5978.536752939224, 'accumulated_submission_time': 5500.831784963608, 'accumulated_eval_time': 474.96408867836, 'accumulated_logging_time': 1.9300155639648438}
I0204 12:51:37.601649 140397019907840 logging_writer.py:48] [23207] accumulated_eval_time=474.964089, accumulated_logging_time=1.930016, accumulated_submission_time=5500.831785, global_step=23207, preemption_count=0, score=5500.831785, test/loss=0.286665, test/num_examples=3581, test/ssim=0.743238, total_duration=5978.536753, train/loss=0.257729, train/ssim=0.753475, validation/loss=0.285373, validation/num_examples=3554, validation/ssim=0.726039
I0204 12:51:57.655075 140397011515136 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.22014646232128143, loss=0.2503282427787781
I0204 12:52:21.569377 140397019907840 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.09151190519332886, loss=0.3081105649471283
I0204 12:52:45.769987 140397011515136 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.30006006360054016, loss=0.2320803850889206
I0204 12:52:57.838499 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:52:59.220865 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:53:00.551485 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:53:01.882278 140584300062528 submission_runner.py:408] Time since start: 6062.84s, 	Step: 23552, 	{'train/ssim': 0.7532529830932617, 'train/loss': 0.25804788725716726, 'validation/ssim': 0.7259530414673607, 'validation/loss': 0.28554932052792625, 'validation/num_examples': 3554, 'test/ssim': 0.7430817050928512, 'test/loss': 0.28686687061487715, 'test/num_examples': 3581, 'score': 5581.046790122986, 'total_duration': 6062.840421676636, 'accumulated_submission_time': 5581.046790122986, 'accumulated_eval_time': 479.00782084465027, 'accumulated_logging_time': 1.9629197120666504}
I0204 12:53:01.920029 140397019907840 logging_writer.py:48] [23552] accumulated_eval_time=479.007821, accumulated_logging_time=1.962920, accumulated_submission_time=5581.046790, global_step=23552, preemption_count=0, score=5581.046790, test/loss=0.286867, test/num_examples=3581, test/ssim=0.743082, total_duration=6062.840422, train/loss=0.258048, train/ssim=0.753253, validation/loss=0.285549, validation/num_examples=3554, validation/ssim=0.725953
I0204 12:53:11.399212 140397011515136 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.11937060207128525, loss=0.23517127335071564
I0204 12:53:35.294803 140397019907840 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.1741655468940735, loss=0.2956705093383789
I0204 12:53:59.352177 140397011515136 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.11320631206035614, loss=0.23842009902000427
I0204 12:54:22.087379 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:54:23.466989 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:54:24.795586 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:54:26.128497 140584300062528 submission_runner.py:408] Time since start: 6147.09s, 	Step: 23896, 	{'train/ssim': 0.7521711758204869, 'train/loss': 0.25841634614127024, 'validation/ssim': 0.7247517102208779, 'validation/loss': 0.285952265905274, 'validation/num_examples': 3554, 'test/ssim': 0.7421021428197431, 'test/loss': 0.28722411632138367, 'test/num_examples': 3581, 'score': 5661.1857368946075, 'total_duration': 6147.086599349976, 'accumulated_submission_time': 5661.1857368946075, 'accumulated_eval_time': 483.0488519668579, 'accumulated_logging_time': 2.0170490741729736}
I0204 12:54:26.154240 140397019907840 logging_writer.py:48] [23896] accumulated_eval_time=483.048852, accumulated_logging_time=2.017049, accumulated_submission_time=5661.185737, global_step=23896, preemption_count=0, score=5661.185737, test/loss=0.287224, test/num_examples=3581, test/ssim=0.742102, total_duration=6147.086599, train/loss=0.258416, train/ssim=0.752171, validation/loss=0.285952, validation/num_examples=3554, validation/ssim=0.724752
I0204 12:54:26.540332 140397011515136 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.14839452505111694, loss=0.22177831828594208
I0204 12:54:48.598598 140397019907840 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.08863408118486404, loss=0.23812158405780792
I0204 12:55:12.473695 140397011515136 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.13158957660198212, loss=0.32700589299201965
I0204 12:55:36.211394 140397019907840 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.17631956934928894, loss=0.25998514890670776
I0204 12:55:46.154307 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:55:47.535714 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:55:48.870928 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:55:50.202697 140584300062528 submission_runner.py:408] Time since start: 6231.16s, 	Step: 24243, 	{'train/ssim': 0.7536928313119071, 'train/loss': 0.25732050623212543, 'validation/ssim': 0.7258101566896454, 'validation/loss': 0.28519540592466236, 'validation/num_examples': 3554, 'test/ssim': 0.7430396400926766, 'test/loss': 0.2865261918371265, 'test/num_examples': 3581, 'score': 5741.163243055344, 'total_duration': 6231.160847902298, 'accumulated_submission_time': 5741.163243055344, 'accumulated_eval_time': 487.0972065925598, 'accumulated_logging_time': 2.053084135055542}
I0204 12:55:50.223432 140397011515136 logging_writer.py:48] [24243] accumulated_eval_time=487.097207, accumulated_logging_time=2.053084, accumulated_submission_time=5741.163243, global_step=24243, preemption_count=0, score=5741.163243, test/loss=0.286526, test/num_examples=3581, test/ssim=0.743040, total_duration=6231.160848, train/loss=0.257321, train/ssim=0.753693, validation/loss=0.285195, validation/num_examples=3554, validation/ssim=0.725810
I0204 12:56:01.795767 140397019907840 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.19350644946098328, loss=0.23760823905467987
I0204 12:56:25.546534 140397011515136 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.3595467507839203, loss=0.18921250104904175
I0204 12:56:49.410933 140397019907840 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.07228561490774155, loss=0.29492267966270447
I0204 12:57:10.301167 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:57:11.683323 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:57:13.012480 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:57:14.344636 140584300062528 submission_runner.py:408] Time since start: 6315.30s, 	Step: 24588, 	{'train/ssim': 0.7535805021013532, 'train/loss': 0.2576057570321219, 'validation/ssim': 0.7259259070985158, 'validation/loss': 0.2853072407410664, 'validation/num_examples': 3554, 'test/ssim': 0.7431695848095853, 'test/loss': 0.28657827880654846, 'test/num_examples': 3581, 'score': 5821.219519615173, 'total_duration': 6315.30278635025, 'accumulated_submission_time': 5821.219519615173, 'accumulated_eval_time': 491.14065527915955, 'accumulated_logging_time': 2.083099126815796}
I0204 12:57:14.365573 140397011515136 logging_writer.py:48] [24588] accumulated_eval_time=491.140655, accumulated_logging_time=2.083099, accumulated_submission_time=5821.219520, global_step=24588, preemption_count=0, score=5821.219520, test/loss=0.286578, test/num_examples=3581, test/ssim=0.743170, total_duration=6315.302786, train/loss=0.257606, train/ssim=0.753581, validation/loss=0.285307, validation/num_examples=3554, validation/ssim=0.725926
I0204 12:57:15.332622 140397019907840 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.14132994413375854, loss=0.2846066653728485
I0204 12:57:39.113905 140397011515136 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.15099985897541046, loss=0.2529124915599823
I0204 12:58:03.271319 140397019907840 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.07193513214588165, loss=0.27222490310668945
I0204 12:58:27.278730 140397011515136 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.086028091609478, loss=0.2599999010562897
I0204 12:58:34.546177 140584300062528 spec.py:321] Evaluating on the training split.
I0204 12:58:35.928690 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 12:58:37.260984 140584300062528 spec.py:349] Evaluating on the test split.
I0204 12:58:38.594170 140584300062528 submission_runner.py:408] Time since start: 6399.55s, 	Step: 24932, 	{'train/ssim': 0.7523881367274693, 'train/loss': 0.25837341376713346, 'validation/ssim': 0.7248127110298256, 'validation/loss': 0.2859432840857133, 'validation/num_examples': 3554, 'test/ssim': 0.742053396506737, 'test/loss': 0.2873815021445651, 'test/num_examples': 3581, 'score': 5901.379008293152, 'total_duration': 6399.552320480347, 'accumulated_submission_time': 5901.379008293152, 'accumulated_eval_time': 495.18860507011414, 'accumulated_logging_time': 2.1133792400360107}
I0204 12:58:38.614718 140397019907840 logging_writer.py:48] [24932] accumulated_eval_time=495.188605, accumulated_logging_time=2.113379, accumulated_submission_time=5901.379008, global_step=24932, preemption_count=0, score=5901.379008, test/loss=0.287382, test/num_examples=3581, test/ssim=0.742053, total_duration=6399.552320, train/loss=0.258373, train/ssim=0.752388, validation/loss=0.285943, validation/num_examples=3554, validation/ssim=0.724813
I0204 12:58:52.911683 140397011515136 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.08608639985322952, loss=0.24882519245147705
I0204 12:59:17.227102 140397019907840 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.20513387024402618, loss=0.28222811222076416
I0204 12:59:40.643465 140397011515136 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.137693852186203, loss=0.22833245992660522
I0204 12:59:58.788909 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:00:00.170951 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:00:01.500854 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:00:02.829767 140584300062528 submission_runner.py:408] Time since start: 6483.79s, 	Step: 25277, 	{'train/ssim': 0.7541452135358538, 'train/loss': 0.2572070360183716, 'validation/ssim': 0.7261007348674029, 'validation/loss': 0.2851946331103598, 'validation/num_examples': 3554, 'test/ssim': 0.743282826244415, 'test/loss': 0.2865642685026005, 'test/num_examples': 3581, 'score': 5981.531459093094, 'total_duration': 6483.78791642189, 'accumulated_submission_time': 5981.531459093094, 'accumulated_eval_time': 499.2294337749481, 'accumulated_logging_time': 2.143554449081421}
I0204 13:00:02.850631 140397019907840 logging_writer.py:48] [25277] accumulated_eval_time=499.229434, accumulated_logging_time=2.143554, accumulated_submission_time=5981.531459, global_step=25277, preemption_count=0, score=5981.531459, test/loss=0.286564, test/num_examples=3581, test/ssim=0.743283, total_duration=6483.787916, train/loss=0.257207, train/ssim=0.754145, validation/loss=0.285195, validation/num_examples=3554, validation/ssim=0.726101
I0204 13:00:06.368807 140397011515136 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.15304376184940338, loss=0.20181503891944885
I0204 13:00:29.985748 140397019907840 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.1277286559343338, loss=0.21845151484012604
I0204 13:00:53.630966 140397011515136 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.10910943150520325, loss=0.2534704804420471
I0204 13:01:17.492111 140397019907840 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.06508452445268631, loss=0.3319680988788605
I0204 13:01:22.893301 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:01:24.276377 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:01:25.609068 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:01:26.940592 140584300062528 submission_runner.py:408] Time since start: 6567.90s, 	Step: 25624, 	{'train/ssim': 0.7540187154497419, 'train/loss': 0.2573329380580357, 'validation/ssim': 0.7261812449440771, 'validation/loss': 0.2851841400094963, 'validation/num_examples': 3554, 'test/ssim': 0.7433787508072117, 'test/loss': 0.28650106873734643, 'test/num_examples': 3581, 'score': 6061.55241727829, 'total_duration': 6567.898736476898, 'accumulated_submission_time': 6061.55241727829, 'accumulated_eval_time': 503.27667450904846, 'accumulated_logging_time': 2.1740894317626953}
I0204 13:01:26.961509 140397011515136 logging_writer.py:48] [25624] accumulated_eval_time=503.276675, accumulated_logging_time=2.174089, accumulated_submission_time=6061.552417, global_step=25624, preemption_count=0, score=6061.552417, test/loss=0.286501, test/num_examples=3581, test/ssim=0.743379, total_duration=6567.898736, train/loss=0.257333, train/ssim=0.754019, validation/loss=0.285184, validation/num_examples=3554, validation/ssim=0.726181
I0204 13:01:42.767591 140397019907840 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.11334095895290375, loss=0.4116714596748352
I0204 13:02:06.637533 140397011515136 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.07648608833551407, loss=0.2772819399833679
I0204 13:02:30.581561 140397019907840 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.17522838711738586, loss=0.24489907920360565
I0204 13:02:47.032127 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:02:48.415311 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:02:49.744925 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:02:51.078136 140584300062528 submission_runner.py:408] Time since start: 6652.04s, 	Step: 25968, 	{'train/ssim': 0.7539004598345075, 'train/loss': 0.2575019257409232, 'validation/ssim': 0.7261755432918894, 'validation/loss': 0.2853177166682787, 'validation/num_examples': 3554, 'test/ssim': 0.743403226228707, 'test/loss': 0.28662620699961605, 'test/num_examples': 3581, 'score': 6141.601917743683, 'total_duration': 6652.036284208298, 'accumulated_submission_time': 6141.601917743683, 'accumulated_eval_time': 507.32264375686646, 'accumulated_logging_time': 2.204224109649658}
I0204 13:02:51.100357 140397011515136 logging_writer.py:48] [25968] accumulated_eval_time=507.322644, accumulated_logging_time=2.204224, accumulated_submission_time=6141.601918, global_step=25968, preemption_count=0, score=6141.601918, test/loss=0.286626, test/num_examples=3581, test/ssim=0.743403, total_duration=6652.036284, train/loss=0.257502, train/ssim=0.753900, validation/loss=0.285318, validation/num_examples=3554, validation/ssim=0.726176
I0204 13:02:56.669953 140397019907840 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.11885684728622437, loss=0.29364970326423645
I0204 13:03:20.738724 140397011515136 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.1417185664176941, loss=0.27395445108413696
I0204 13:03:44.298902 140397019907840 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.086248978972435, loss=0.292465478181839
I0204 13:04:07.992331 140397011515136 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.08492407202720642, loss=0.36173292994499207
I0204 13:04:11.100306 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:04:12.481105 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:04:13.814032 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:04:15.145923 140584300062528 submission_runner.py:408] Time since start: 6736.10s, 	Step: 26314, 	{'train/ssim': 0.7539973258972168, 'train/loss': 0.25696046011788504, 'validation/ssim': 0.7257981351338281, 'validation/loss': 0.2851275356552476, 'validation/num_examples': 3554, 'test/ssim': 0.7430313907166294, 'test/loss': 0.2864493908278937, 'test/num_examples': 3581, 'score': 6221.579905986786, 'total_duration': 6736.1040687561035, 'accumulated_submission_time': 6221.579905986786, 'accumulated_eval_time': 511.3682265281677, 'accumulated_logging_time': 2.2362966537475586}
I0204 13:04:15.168198 140397019907840 logging_writer.py:48] [26314] accumulated_eval_time=511.368227, accumulated_logging_time=2.236297, accumulated_submission_time=6221.579906, global_step=26314, preemption_count=0, score=6221.579906, test/loss=0.286449, test/num_examples=3581, test/ssim=0.743031, total_duration=6736.104069, train/loss=0.256960, train/ssim=0.753997, validation/loss=0.285128, validation/num_examples=3554, validation/ssim=0.725798
I0204 13:04:33.924361 140397011515136 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.09218796342611313, loss=0.24907737970352173
I0204 13:04:58.084771 140397019907840 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.0945960059762001, loss=0.2512417435646057
I0204 13:05:22.184261 140397011515136 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.14953728020191193, loss=0.26433369517326355
I0204 13:05:35.158462 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:05:36.541570 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:05:37.871322 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:05:39.202441 140584300062528 submission_runner.py:408] Time since start: 6820.16s, 	Step: 26656, 	{'train/ssim': 0.7542306355067662, 'train/loss': 0.25713210446493967, 'validation/ssim': 0.7263142376987197, 'validation/loss': 0.2851001436816351, 'validation/num_examples': 3554, 'test/ssim': 0.7435331709456158, 'test/loss': 0.28639771291844107, 'test/num_examples': 3581, 'score': 6301.547380447388, 'total_duration': 6820.160589933395, 'accumulated_submission_time': 6301.547380447388, 'accumulated_eval_time': 515.4121625423431, 'accumulated_logging_time': 2.269528865814209}
I0204 13:05:39.225307 140397019907840 logging_writer.py:48] [26656] accumulated_eval_time=515.412163, accumulated_logging_time=2.269529, accumulated_submission_time=6301.547380, global_step=26656, preemption_count=0, score=6301.547380, test/loss=0.286398, test/num_examples=3581, test/ssim=0.743533, total_duration=6820.160590, train/loss=0.257132, train/ssim=0.754231, validation/loss=0.285100, validation/num_examples=3554, validation/ssim=0.726314
I0204 13:05:47.696052 140397011515136 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.12166000157594681, loss=0.34156352281570435
I0204 13:06:11.669478 140397019907840 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.15525192022323608, loss=0.17803563177585602
I0204 13:06:35.326531 140397011515136 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.11388431489467621, loss=0.2128073275089264
I0204 13:06:59.481766 140397019907840 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.13725584745407104, loss=0.2120750993490219
I0204 13:06:59.486874 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:07:00.815762 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:07:02.145864 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:07:03.473562 140584300062528 submission_runner.py:408] Time since start: 6904.43s, 	Step: 27001, 	{'train/ssim': 0.7542601994105748, 'train/loss': 0.25726778166634695, 'validation/ssim': 0.726429163772334, 'validation/loss': 0.28517127694477173, 'validation/num_examples': 3554, 'test/ssim': 0.7436299136283511, 'test/loss': 0.28646081041870286, 'test/num_examples': 3581, 'score': 6381.7876925468445, 'total_duration': 6904.431702852249, 'accumulated_submission_time': 6381.7876925468445, 'accumulated_eval_time': 519.3987793922424, 'accumulated_logging_time': 2.301710605621338}
I0204 13:07:03.494199 140397011515136 logging_writer.py:48] [27001] accumulated_eval_time=519.398779, accumulated_logging_time=2.301711, accumulated_submission_time=6381.787693, global_step=27001, preemption_count=0, score=6381.787693, test/loss=0.286461, test/num_examples=3581, test/ssim=0.743630, total_duration=6904.431703, train/loss=0.257268, train/ssim=0.754260, validation/loss=0.285171, validation/num_examples=3554, validation/ssim=0.726429
I0204 13:07:25.115641 140397019907840 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.11043992638587952, loss=0.2462921142578125
I0204 13:07:49.171092 140397011515136 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.1250678300857544, loss=0.31052809953689575
I0204 13:08:13.133689 140397019907840 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.052206993103027344, loss=0.24066859483718872
I0204 13:08:23.591943 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:08:24.973081 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:08:26.304445 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:08:27.635987 140584300062528 submission_runner.py:408] Time since start: 6988.59s, 	Step: 27345, 	{'train/ssim': 0.7543474606105259, 'train/loss': 0.25676616600581575, 'validation/ssim': 0.7260194691500774, 'validation/loss': 0.28503510706466306, 'validation/num_examples': 3554, 'test/ssim': 0.7432553510498116, 'test/loss': 0.28634238755759567, 'test/num_examples': 3581, 'score': 6461.864283800125, 'total_duration': 6988.59413766861, 'accumulated_submission_time': 6461.864283800125, 'accumulated_eval_time': 523.4427843093872, 'accumulated_logging_time': 2.3316047191619873}
I0204 13:08:27.657143 140397011515136 logging_writer.py:48] [27345] accumulated_eval_time=523.442784, accumulated_logging_time=2.331605, accumulated_submission_time=6461.864284, global_step=27345, preemption_count=0, score=6461.864284, test/loss=0.286342, test/num_examples=3581, test/ssim=0.743255, total_duration=6988.594138, train/loss=0.256766, train/ssim=0.754347, validation/loss=0.285035, validation/num_examples=3554, validation/ssim=0.726019
I0204 13:08:38.913621 140397019907840 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.27675047516822815, loss=0.3048292398452759
I0204 13:09:02.582086 140397011515136 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.07872708886861801, loss=0.2356129288673401
I0204 13:09:26.422753 140397019907840 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.10696349292993546, loss=0.2445181906223297
I0204 13:09:47.818633 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:09:49.199149 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:09:50.529357 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:09:51.858826 140584300062528 submission_runner.py:408] Time since start: 7072.82s, 	Step: 27691, 	{'train/ssim': 0.7541309084211077, 'train/loss': 0.25700863770076204, 'validation/ssim': 0.7260204995691475, 'validation/loss': 0.2850820254796532, 'validation/num_examples': 3554, 'test/ssim': 0.743281462711184, 'test/loss': 0.2863778394216001, 'test/num_examples': 3581, 'score': 6542.003179073334, 'total_duration': 7072.816970825195, 'accumulated_submission_time': 6542.003179073334, 'accumulated_eval_time': 527.4829468727112, 'accumulated_logging_time': 2.3632917404174805}
I0204 13:09:51.881277 140397011515136 logging_writer.py:48] [27691] accumulated_eval_time=527.482947, accumulated_logging_time=2.363292, accumulated_submission_time=6542.003179, global_step=27691, preemption_count=0, score=6542.003179, test/loss=0.286378, test/num_examples=3581, test/ssim=0.743281, total_duration=7072.816971, train/loss=0.257009, train/ssim=0.754131, validation/loss=0.285082, validation/num_examples=3554, validation/ssim=0.726020
I0204 13:09:52.633211 140397019907840 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.10649670660495758, loss=0.29070204496383667
I0204 13:10:15.958893 140397011515136 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.06987319886684418, loss=0.31194981932640076
I0204 13:10:39.612575 140397019907840 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.14677460491657257, loss=0.26913556456565857
I0204 13:11:03.105683 140397011515136 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.08185240626335144, loss=0.23416587710380554
I0204 13:11:11.894147 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:11:13.275779 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:11:14.603954 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:11:15.935686 140584300062528 submission_runner.py:408] Time since start: 7156.89s, 	Step: 28038, 	{'train/ssim': 0.7536019597734723, 'train/loss': 0.257212621825082, 'validation/ssim': 0.7257375464925084, 'validation/loss': 0.28518925775754433, 'validation/num_examples': 3554, 'test/ssim': 0.7429226489414619, 'test/loss': 0.2865027390655543, 'test/num_examples': 3581, 'score': 6621.994435787201, 'total_duration': 7156.893805742264, 'accumulated_submission_time': 6621.994435787201, 'accumulated_eval_time': 531.5244166851044, 'accumulated_logging_time': 2.395188331604004}
I0204 13:11:15.960899 140397019907840 logging_writer.py:48] [28038] accumulated_eval_time=531.524417, accumulated_logging_time=2.395188, accumulated_submission_time=6621.994436, global_step=28038, preemption_count=0, score=6621.994436, test/loss=0.286503, test/num_examples=3581, test/ssim=0.742923, total_duration=7156.893806, train/loss=0.257213, train/ssim=0.753602, validation/loss=0.285189, validation/num_examples=3554, validation/ssim=0.725738
I0204 13:11:28.915446 140397011515136 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.20858310163021088, loss=0.27330726385116577
I0204 13:11:52.621017 140397019907840 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.19302095472812653, loss=0.256168007850647
I0204 13:12:16.579502 140397011515136 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.17193840444087982, loss=0.23951305449008942
I0204 13:12:36.158228 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:12:37.539744 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:12:38.868537 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:12:40.200336 140584300062528 submission_runner.py:408] Time since start: 7241.16s, 	Step: 28384, 	{'train/ssim': 0.7541613578796387, 'train/loss': 0.25679961272648405, 'validation/ssim': 0.7257597348498172, 'validation/loss': 0.2850896334071205, 'validation/num_examples': 3554, 'test/ssim': 0.7429875531232547, 'test/loss': 0.2864661281983035, 'test/num_examples': 3581, 'score': 6702.170172929764, 'total_duration': 7241.158483028412, 'accumulated_submission_time': 6702.170172929764, 'accumulated_eval_time': 535.5664856433868, 'accumulated_logging_time': 2.4301555156707764}
I0204 13:12:40.222340 140397019907840 logging_writer.py:48] [28384] accumulated_eval_time=535.566486, accumulated_logging_time=2.430156, accumulated_submission_time=6702.170173, global_step=28384, preemption_count=0, score=6702.170173, test/loss=0.286466, test/num_examples=3581, test/ssim=0.742988, total_duration=7241.158483, train/loss=0.256800, train/ssim=0.754161, validation/loss=0.285090, validation/num_examples=3554, validation/ssim=0.725760
I0204 13:12:42.033762 140397011515136 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.1657843291759491, loss=0.2364843487739563
I0204 13:13:06.122359 140397019907840 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.140867680311203, loss=0.2944316864013672
I0204 13:13:29.948550 140397011515136 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.12605977058410645, loss=0.36066946387290955
I0204 13:13:53.473654 140397019907840 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.09150867164134979, loss=0.26582205295562744
I0204 13:14:00.225697 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:14:01.608143 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:14:02.940289 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:14:04.272576 140584300062528 submission_runner.py:408] Time since start: 7325.23s, 	Step: 28730, 	{'train/ssim': 0.7544137409755162, 'train/loss': 0.25688276972089497, 'validation/ssim': 0.7262156609410172, 'validation/loss': 0.28504685384206174, 'validation/num_examples': 3554, 'test/ssim': 0.7433747965608419, 'test/loss': 0.2863912020472633, 'test/num_examples': 3581, 'score': 6782.152277231216, 'total_duration': 7325.230720281601, 'accumulated_submission_time': 6782.152277231216, 'accumulated_eval_time': 539.6133246421814, 'accumulated_logging_time': 2.461496353149414}
I0204 13:14:04.293494 140397011515136 logging_writer.py:48] [28730] accumulated_eval_time=539.613325, accumulated_logging_time=2.461496, accumulated_submission_time=6782.152277, global_step=28730, preemption_count=0, score=6782.152277, test/loss=0.286391, test/num_examples=3581, test/ssim=0.743375, total_duration=7325.230720, train/loss=0.256883, train/ssim=0.754414, validation/loss=0.285047, validation/num_examples=3554, validation/ssim=0.726216
I0204 13:14:18.962217 140397019907840 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.14172032475471497, loss=0.20619416236877441
I0204 13:14:42.451843 140397011515136 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.07263442128896713, loss=0.3396005630493164
I0204 13:15:06.429260 140397019907840 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.06664153933525085, loss=0.26095569133758545
I0204 13:15:24.467616 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:15:25.850596 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:15:27.183107 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:15:28.518185 140584300062528 submission_runner.py:408] Time since start: 7409.48s, 	Step: 29077, 	{'train/ssim': 0.7544715063912528, 'train/loss': 0.2570457458496094, 'validation/ssim': 0.7264549242490855, 'validation/loss': 0.2851410513187166, 'validation/num_examples': 3554, 'test/ssim': 0.7436050291468863, 'test/loss': 0.286466060021642, 'test/num_examples': 3581, 'score': 6862.30401468277, 'total_duration': 7409.476336956024, 'accumulated_submission_time': 6862.30401468277, 'accumulated_eval_time': 543.6638793945312, 'accumulated_logging_time': 2.492823839187622}
I0204 13:15:28.541712 140397011515136 logging_writer.py:48] [29077] accumulated_eval_time=543.663879, accumulated_logging_time=2.492824, accumulated_submission_time=6862.304015, global_step=29077, preemption_count=0, score=6862.304015, test/loss=0.286466, test/num_examples=3581, test/ssim=0.743605, total_duration=7409.476337, train/loss=0.257046, train/ssim=0.754472, validation/loss=0.285141, validation/num_examples=3554, validation/ssim=0.726455
I0204 13:15:32.109007 140397019907840 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.1430588662624359, loss=0.2530297636985779
I0204 13:15:55.941933 140397011515136 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.0804232582449913, loss=0.3307841718196869
I0204 13:16:20.175932 140397019907840 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.4099622070789337, loss=0.3424568474292755
I0204 13:16:44.084685 140397011515136 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.19988299906253815, loss=0.1878848671913147
I0204 13:16:48.565983 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:16:49.946061 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:16:51.275649 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:16:52.606068 140584300062528 submission_runner.py:408] Time since start: 7493.56s, 	Step: 29420, 	{'train/ssim': 0.7544336318969727, 'train/loss': 0.25658464431762695, 'validation/ssim': 0.7259691846994584, 'validation/loss': 0.2850145330305642, 'validation/num_examples': 3554, 'test/ssim': 0.7431189977267174, 'test/loss': 0.2863644767959369, 'test/num_examples': 3581, 'score': 6942.3070504665375, 'total_duration': 7493.5642166137695, 'accumulated_submission_time': 6942.3070504665375, 'accumulated_eval_time': 547.7039232254028, 'accumulated_logging_time': 2.525808572769165}
I0204 13:16:52.627976 140397019907840 logging_writer.py:48] [29420] accumulated_eval_time=547.703923, accumulated_logging_time=2.525809, accumulated_submission_time=6942.307050, global_step=29420, preemption_count=0, score=6942.307050, test/loss=0.286364, test/num_examples=3581, test/ssim=0.743119, total_duration=7493.564217, train/loss=0.256585, train/ssim=0.754434, validation/loss=0.285015, validation/num_examples=3554, validation/ssim=0.725969
I0204 13:17:09.836653 140397011515136 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.13401716947555542, loss=0.22390395402908325
I0204 13:17:33.437032 140397019907840 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.11233709007501602, loss=0.20476514101028442
I0204 13:17:57.134134 140397011515136 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.06581909209489822, loss=0.3086792528629303
I0204 13:18:12.675022 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:18:14.056106 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:18:15.387833 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:18:16.715637 140584300062528 submission_runner.py:408] Time since start: 7577.67s, 	Step: 29767, 	{'train/ssim': 0.7546213694981166, 'train/loss': 0.2567110913140433, 'validation/ssim': 0.7263272209790025, 'validation/loss': 0.2850071827078644, 'validation/num_examples': 3554, 'test/ssim': 0.7435238307429838, 'test/loss': 0.2863429670592188, 'test/num_examples': 3581, 'score': 7022.33305644989, 'total_duration': 7577.673763036728, 'accumulated_submission_time': 7022.33305644989, 'accumulated_eval_time': 551.7444829940796, 'accumulated_logging_time': 2.5568244457244873}
I0204 13:18:16.737782 140397019907840 logging_writer.py:48] [29767] accumulated_eval_time=551.744483, accumulated_logging_time=2.556824, accumulated_submission_time=7022.333056, global_step=29767, preemption_count=0, score=7022.333056, test/loss=0.286343, test/num_examples=3581, test/ssim=0.743524, total_duration=7577.673763, train/loss=0.256711, train/ssim=0.754621, validation/loss=0.285007, validation/num_examples=3554, validation/ssim=0.726327
I0204 13:18:22.466916 140397011515136 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.10206679999828339, loss=0.35652244091033936
I0204 13:18:46.414564 140397019907840 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.09681075811386108, loss=0.26299890875816345
I0204 13:19:10.282694 140397011515136 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.0665082037448883, loss=0.321597695350647
I0204 13:19:34.134654 140397019907840 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.10933823138475418, loss=0.22511057555675507
I0204 13:19:36.966262 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:19:38.348964 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:19:39.679026 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:19:41.015142 140584300062528 submission_runner.py:408] Time since start: 7661.97s, 	Step: 30113, 	{'train/ssim': 0.7546024322509766, 'train/loss': 0.2568695545196533, 'validation/ssim': 0.7264716857326252, 'validation/loss': 0.28509057795793474, 'validation/num_examples': 3554, 'test/ssim': 0.7436164828260262, 'test/loss': 0.2864089279792656, 'test/num_examples': 3581, 'score': 7102.540855884552, 'total_duration': 7661.973260879517, 'accumulated_submission_time': 7102.540855884552, 'accumulated_eval_time': 555.7933006286621, 'accumulated_logging_time': 2.587928295135498}
I0204 13:19:41.042370 140397011515136 logging_writer.py:48] [30113] accumulated_eval_time=555.793301, accumulated_logging_time=2.587928, accumulated_submission_time=7102.540856, global_step=30113, preemption_count=0, score=7102.540856, test/loss=0.286409, test/num_examples=3581, test/ssim=0.743616, total_duration=7661.973261, train/loss=0.256870, train/ssim=0.754602, validation/loss=0.285091, validation/num_examples=3554, validation/ssim=0.726472
I0204 13:20:00.124411 140397019907840 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.10458976775407791, loss=0.2799188196659088
I0204 13:20:24.446777 140397011515136 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.11065302789211273, loss=0.29697149991989136
I0204 13:20:48.314172 140397019907840 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.16687819361686707, loss=0.2842712998390198
I0204 13:21:01.106121 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:21:02.488232 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:21:03.819825 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:21:05.155234 140584300062528 submission_runner.py:408] Time since start: 7746.11s, 	Step: 30456, 	{'train/ssim': 0.7543889454432896, 'train/loss': 0.2566305569240025, 'validation/ssim': 0.7259818245067178, 'validation/loss': 0.28501262675528455, 'validation/num_examples': 3554, 'test/ssim': 0.7431831519652332, 'test/loss': 0.28636096569786723, 'test/num_examples': 3581, 'score': 7182.582946300507, 'total_duration': 7746.113355398178, 'accumulated_submission_time': 7182.582946300507, 'accumulated_eval_time': 559.842346906662, 'accumulated_logging_time': 2.6249148845672607}
I0204 13:21:05.181771 140397011515136 logging_writer.py:48] [30456] accumulated_eval_time=559.842347, accumulated_logging_time=2.624915, accumulated_submission_time=7182.582946, global_step=30456, preemption_count=0, score=7182.582946, test/loss=0.286361, test/num_examples=3581, test/ssim=0.743183, total_duration=7746.113355, train/loss=0.256631, train/ssim=0.754389, validation/loss=0.285013, validation/num_examples=3554, validation/ssim=0.725982
I0204 13:21:13.770539 140397019907840 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.09461440145969391, loss=0.22899405658245087
I0204 13:21:37.634401 140397011515136 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.11265291273593903, loss=0.2808793783187866
I0204 13:22:01.459751 140397019907840 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.0856364518404007, loss=0.2906661927700043
I0204 13:22:25.407621 140397011515136 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.05865326151251793, loss=0.2826555371284485
I0204 13:22:25.412853 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:22:26.738106 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:22:28.067804 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:22:29.401997 140584300062528 submission_runner.py:408] Time since start: 7830.36s, 	Step: 30801, 	{'train/ssim': 0.7546736172267369, 'train/loss': 0.25655325821467806, 'validation/ssim': 0.7262378492983258, 'validation/loss': 0.2849770601237162, 'validation/num_examples': 3554, 'test/ssim': 0.7434223156939402, 'test/loss': 0.2863411944660186, 'test/num_examples': 3581, 'score': 7262.79195356369, 'total_duration': 7830.360119819641, 'accumulated_submission_time': 7262.79195356369, 'accumulated_eval_time': 563.8314032554626, 'accumulated_logging_time': 2.66121768951416}
I0204 13:22:29.428436 140397019907840 logging_writer.py:48] [30801] accumulated_eval_time=563.831403, accumulated_logging_time=2.661218, accumulated_submission_time=7262.791954, global_step=30801, preemption_count=0, score=7262.791954, test/loss=0.286341, test/num_examples=3581, test/ssim=0.743422, total_duration=7830.360120, train/loss=0.256553, train/ssim=0.754674, validation/loss=0.284977, validation/num_examples=3554, validation/ssim=0.726238
I0204 13:22:50.966349 140397011515136 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.119240403175354, loss=0.21614840626716614
I0204 13:23:14.582641 140397019907840 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.06536560505628586, loss=0.2576638460159302
I0204 13:23:38.349108 140397011515136 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.08152548223733902, loss=0.21233658492565155
I0204 13:23:49.460824 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:23:50.842767 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:23:52.175684 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:23:53.506565 140584300062528 submission_runner.py:408] Time since start: 7914.46s, 	Step: 31148, 	{'train/ssim': 0.7548414639064244, 'train/loss': 0.2566737788064139, 'validation/ssim': 0.7265923134584271, 'validation/loss': 0.2850077322647017, 'validation/num_examples': 3554, 'test/ssim': 0.743772607380969, 'test/loss': 0.2863343086232023, 'test/num_examples': 3581, 'score': 7342.801480770111, 'total_duration': 7914.464708566666, 'accumulated_submission_time': 7342.801480770111, 'accumulated_eval_time': 567.8771078586578, 'accumulated_logging_time': 2.698338508605957}
I0204 13:23:53.528928 140397019907840 logging_writer.py:48] [31148] accumulated_eval_time=567.877108, accumulated_logging_time=2.698339, accumulated_submission_time=7342.801481, global_step=31148, preemption_count=0, score=7342.801481, test/loss=0.286334, test/num_examples=3581, test/ssim=0.743773, total_duration=7914.464709, train/loss=0.256674, train/ssim=0.754841, validation/loss=0.285008, validation/num_examples=3554, validation/ssim=0.726592
I0204 13:24:04.102727 140397011515136 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.09931092709302902, loss=0.23862385749816895
I0204 13:24:28.067623 140397019907840 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.09747937321662903, loss=0.2573270797729492
I0204 13:24:52.505430 140397011515136 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.10552092641592026, loss=0.298527330160141
I0204 13:25:13.637516 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:25:15.018332 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:25:16.353657 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:25:17.683815 140584300062528 submission_runner.py:408] Time since start: 7998.64s, 	Step: 31490, 	{'train/ssim': 0.7542413302830288, 'train/loss': 0.256832412311009, 'validation/ssim': 0.7259741307109947, 'validation/loss': 0.2851721356273301, 'validation/num_examples': 3554, 'test/ssim': 0.7431318149390882, 'test/loss': 0.286525510070511, 'test/num_examples': 3581, 'score': 7422.888996124268, 'total_duration': 7998.641962766647, 'accumulated_submission_time': 7422.888996124268, 'accumulated_eval_time': 571.9233648777008, 'accumulated_logging_time': 2.7299087047576904}
I0204 13:25:17.706902 140397019907840 logging_writer.py:48] [31490] accumulated_eval_time=571.923365, accumulated_logging_time=2.729909, accumulated_submission_time=7422.888996, global_step=31490, preemption_count=0, score=7422.888996, test/loss=0.286526, test/num_examples=3581, test/ssim=0.743132, total_duration=7998.641963, train/loss=0.256832, train/ssim=0.754241, validation/loss=0.285172, validation/num_examples=3554, validation/ssim=0.725974
I0204 13:25:18.528109 140397011515136 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.06467500329017639, loss=0.310208261013031
I0204 13:25:41.530813 140397019907840 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.07067275792360306, loss=0.2267303168773651
I0204 13:26:05.079083 140397011515136 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.07043010741472244, loss=0.25904524326324463
I0204 13:26:29.287255 140397019907840 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.16026794910430908, loss=0.2768986225128174
I0204 13:26:37.737312 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:26:39.120283 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:26:40.449706 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:26:41.781108 140584300062528 submission_runner.py:408] Time since start: 8082.74s, 	Step: 31837, 	{'train/ssim': 0.7548629896981376, 'train/loss': 0.25643043858664377, 'validation/ssim': 0.7264253168744724, 'validation/loss': 0.28492979823570275, 'validation/num_examples': 3554, 'test/ssim': 0.7436150511161338, 'test/loss': 0.28627744928747206, 'test/num_examples': 3581, 'score': 7502.898470878601, 'total_duration': 8082.73925280571, 'accumulated_submission_time': 7502.898470878601, 'accumulated_eval_time': 575.9671130180359, 'accumulated_logging_time': 2.762040376663208}
I0204 13:26:41.803511 140397011515136 logging_writer.py:48] [31837] accumulated_eval_time=575.967113, accumulated_logging_time=2.762040, accumulated_submission_time=7502.898471, global_step=31837, preemption_count=0, score=7502.898471, test/loss=0.286277, test/num_examples=3581, test/ssim=0.743615, total_duration=8082.739253, train/loss=0.256430, train/ssim=0.754863, validation/loss=0.284930, validation/num_examples=3554, validation/ssim=0.726425
I0204 13:26:54.823466 140397019907840 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.11526376008987427, loss=0.3403695821762085
I0204 13:27:18.814737 140397011515136 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.18143746256828308, loss=0.17100948095321655
I0204 13:27:42.640804 140397019907840 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.05061126872897148, loss=0.26947537064552307
I0204 13:28:01.834905 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:28:03.216832 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:28:04.546785 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:28:05.876715 140584300062528 submission_runner.py:408] Time since start: 8166.83s, 	Step: 32181, 	{'train/ssim': 0.7551521573747907, 'train/loss': 0.2565772703715733, 'validation/ssim': 0.7268253255574705, 'validation/loss': 0.2849779703272281, 'validation/num_examples': 3554, 'test/ssim': 0.7439609794968235, 'test/loss': 0.28631160579490716, 'test/num_examples': 3581, 'score': 7582.90892624855, 'total_duration': 8166.83486032486, 'accumulated_submission_time': 7582.90892624855, 'accumulated_eval_time': 580.0088977813721, 'accumulated_logging_time': 2.793639659881592}
I0204 13:28:05.899441 140397011515136 logging_writer.py:48] [32181] accumulated_eval_time=580.008898, accumulated_logging_time=2.793640, accumulated_submission_time=7582.908926, global_step=32181, preemption_count=0, score=7582.908926, test/loss=0.286312, test/num_examples=3581, test/ssim=0.743961, total_duration=8166.834860, train/loss=0.256577, train/ssim=0.755152, validation/loss=0.284978, validation/num_examples=3554, validation/ssim=0.726825
I0204 13:28:08.290995 140397019907840 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.07111147046089172, loss=0.2660662531852722
I0204 13:28:32.338576 140397011515136 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.15662264823913574, loss=0.2720596492290497
I0204 13:28:56.607191 140397019907840 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.11411826312541962, loss=0.245483860373497
I0204 13:29:20.928160 140397011515136 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.09221708029508591, loss=0.22888720035552979
I0204 13:29:26.148389 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:29:27.531536 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:29:28.860498 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:29:30.191520 140584300062528 submission_runner.py:408] Time since start: 8251.15s, 	Step: 32523, 	{'train/ssim': 0.754964964730399, 'train/loss': 0.2566173417227609, 'validation/ssim': 0.7266737852595667, 'validation/loss': 0.28501209437209835, 'validation/num_examples': 3554, 'test/ssim': 0.7437946284426487, 'test/loss': 0.28639761065344876, 'test/num_examples': 3581, 'score': 7663.136118888855, 'total_duration': 8251.14967083931, 'accumulated_submission_time': 7663.136118888855, 'accumulated_eval_time': 584.0519845485687, 'accumulated_logging_time': 2.8262457847595215}
I0204 13:29:30.213870 140397019907840 logging_writer.py:48] [32523] accumulated_eval_time=584.051985, accumulated_logging_time=2.826246, accumulated_submission_time=7663.136119, global_step=32523, preemption_count=0, score=7663.136119, test/loss=0.286398, test/num_examples=3581, test/ssim=0.743795, total_duration=8251.149671, train/loss=0.256617, train/ssim=0.754965, validation/loss=0.285012, validation/num_examples=3554, validation/ssim=0.726674
I0204 13:29:46.915102 140397011515136 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.07710393518209457, loss=0.3346456289291382
I0204 13:30:10.779208 140397019907840 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.0690467357635498, loss=0.2753191888332367
I0204 13:30:34.678576 140397011515136 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.08406699448823929, loss=0.25509199500083923
I0204 13:30:50.218026 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:30:51.599224 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:30:52.929539 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:30:54.264055 140584300062528 submission_runner.py:408] Time since start: 8335.22s, 	Step: 32867, 	{'train/ssim': 0.7552356038774762, 'train/loss': 0.2563023567199707, 'validation/ssim': 0.726623226030529, 'validation/loss': 0.28491727864400146, 'validation/num_examples': 3554, 'test/ssim': 0.7437910150795867, 'test/loss': 0.28627475630934096, 'test/num_examples': 3581, 'score': 7743.118954181671, 'total_duration': 8335.222202539444, 'accumulated_submission_time': 7743.118954181671, 'accumulated_eval_time': 588.0979740619659, 'accumulated_logging_time': 2.8580024242401123}
I0204 13:30:54.287317 140397019907840 logging_writer.py:48] [32867] accumulated_eval_time=588.097974, accumulated_logging_time=2.858002, accumulated_submission_time=7743.118954, global_step=32867, preemption_count=0, score=7743.118954, test/loss=0.286275, test/num_examples=3581, test/ssim=0.743791, total_duration=8335.222203, train/loss=0.256302, train/ssim=0.755236, validation/loss=0.284917, validation/num_examples=3554, validation/ssim=0.726623
I0204 13:31:00.091080 140397011515136 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.08308767527341843, loss=0.21017548441886902
I0204 13:31:24.140337 140397019907840 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.06180032342672348, loss=0.330099880695343
I0204 13:31:48.075271 140397011515136 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.06706555932760239, loss=0.22376315295696259
I0204 13:32:12.028033 140397019907840 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.09706132858991623, loss=0.3523184061050415
I0204 13:32:14.330958 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:32:15.713490 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:32:17.047318 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:32:18.378564 140584300062528 submission_runner.py:408] Time since start: 8419.34s, 	Step: 33211, 	{'train/ssim': 0.7552266120910645, 'train/loss': 0.25639571462358746, 'validation/ssim': 0.726784520962296, 'validation/loss': 0.28490773009395226, 'validation/num_examples': 3554, 'test/ssim': 0.7439368449586359, 'test/loss': 0.2862539624275691, 'test/num_examples': 3581, 'score': 7823.141031265259, 'total_duration': 8419.336717128754, 'accumulated_submission_time': 7823.141031265259, 'accumulated_eval_time': 592.1455419063568, 'accumulated_logging_time': 2.890659809112549}
I0204 13:32:18.401386 140397011515136 logging_writer.py:48] [33211] accumulated_eval_time=592.145542, accumulated_logging_time=2.890660, accumulated_submission_time=7823.141031, global_step=33211, preemption_count=0, score=7823.141031, test/loss=0.286254, test/num_examples=3581, test/ssim=0.743937, total_duration=8419.336717, train/loss=0.256396, train/ssim=0.755227, validation/loss=0.284908, validation/num_examples=3554, validation/ssim=0.726785
I0204 13:32:37.808314 140397019907840 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.06707581877708435, loss=0.31480082869529724
I0204 13:33:01.724402 140397011515136 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.06754276901483536, loss=0.2535097002983093
I0204 13:33:25.787439 140397019907840 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.058861829340457916, loss=0.2641230523586273
I0204 13:33:38.471056 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:33:39.851719 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:33:41.182645 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:33:42.515850 140584300062528 submission_runner.py:408] Time since start: 8503.47s, 	Step: 33554, 	{'train/ssim': 0.7550900323050362, 'train/loss': 0.2564103603363037, 'validation/ssim': 0.7266263859823439, 'validation/loss': 0.2848932183587155, 'validation/num_examples': 3554, 'test/ssim': 0.743793673969387, 'test/loss': 0.28623770229379014, 'test/num_examples': 3581, 'score': 7902.981092453003, 'total_duration': 8503.473998785019, 'accumulated_submission_time': 7902.981092453003, 'accumulated_eval_time': 596.1902956962585, 'accumulated_logging_time': 3.1312170028686523}
I0204 13:33:42.539167 140397011515136 logging_writer.py:48] [33554] accumulated_eval_time=596.190296, accumulated_logging_time=3.131217, accumulated_submission_time=7902.981092, global_step=33554, preemption_count=0, score=7902.981092, test/loss=0.286238, test/num_examples=3581, test/ssim=0.743794, total_duration=8503.473999, train/loss=0.256410, train/ssim=0.755090, validation/loss=0.284893, validation/num_examples=3554, validation/ssim=0.726626
I0204 13:33:51.345795 140397019907840 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.07655911147594452, loss=0.2945643663406372
I0204 13:34:15.527780 140397011515136 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.09205262362957001, loss=0.2557659447193146
I0204 13:34:39.507974 140397019907840 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.053706277161836624, loss=0.2402719110250473
I0204 13:35:02.754567 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:35:04.137476 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:35:05.468344 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:35:06.801245 140584300062528 submission_runner.py:408] Time since start: 8587.76s, 	Step: 33899, 	{'train/ssim': 0.7554918016706195, 'train/loss': 0.2561522551945278, 'validation/ssim': 0.7268479947770118, 'validation/loss': 0.2848349138130012, 'validation/num_examples': 3554, 'test/ssim': 0.7439810916119799, 'test/loss': 0.28618285416957556, 'test/num_examples': 3581, 'score': 7983.175691604614, 'total_duration': 8587.75936126709, 'accumulated_submission_time': 7983.175691604614, 'accumulated_eval_time': 600.2369115352631, 'accumulated_logging_time': 3.1636295318603516}
I0204 13:35:06.830046 140397011515136 logging_writer.py:48] [33899] accumulated_eval_time=600.236912, accumulated_logging_time=3.163630, accumulated_submission_time=7983.175692, global_step=33899, preemption_count=0, score=7983.175692, test/loss=0.286183, test/num_examples=3581, test/ssim=0.743981, total_duration=8587.759361, train/loss=0.256152, train/ssim=0.755492, validation/loss=0.284835, validation/num_examples=3554, validation/ssim=0.726848
I0204 13:35:06.994921 140397019907840 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.05122002586722374, loss=0.2837464511394501
I0204 13:35:28.807485 140397011515136 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.05398613214492798, loss=0.2779918313026428
I0204 13:35:52.527074 140397019907840 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.0682053491473198, loss=0.2571626901626587
I0204 13:36:16.489619 140397011515136 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.07040698826313019, loss=0.2661977708339691
I0204 13:36:26.953077 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:36:28.333438 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:36:29.663634 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:36:30.993204 140584300062528 submission_runner.py:408] Time since start: 8671.95s, 	Step: 34245, 	{'train/ssim': 0.7550997052873883, 'train/loss': 0.25624210493905203, 'validation/ssim': 0.7265252675242684, 'validation/loss': 0.28484891033870285, 'validation/num_examples': 3554, 'test/ssim': 0.7437081122591455, 'test/loss': 0.2861913080756074, 'test/num_examples': 3581, 'score': 8063.2761261463165, 'total_duration': 8671.951352119446, 'accumulated_submission_time': 8063.2761261463165, 'accumulated_eval_time': 604.2770035266876, 'accumulated_logging_time': 3.2029614448547363}
I0204 13:36:31.017514 140397019907840 logging_writer.py:48] [34245] accumulated_eval_time=604.277004, accumulated_logging_time=3.202961, accumulated_submission_time=8063.276126, global_step=34245, preemption_count=0, score=8063.276126, test/loss=0.286191, test/num_examples=3581, test/ssim=0.743708, total_duration=8671.951352, train/loss=0.256242, train/ssim=0.755100, validation/loss=0.284849, validation/num_examples=3554, validation/ssim=0.726525
I0204 13:36:41.930636 140397011515136 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.07531189173460007, loss=0.22458858788013458
I0204 13:37:05.714535 140397019907840 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.04041839763522148, loss=0.33199945092201233
I0204 13:37:29.246283 140397011515136 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.08378328382968903, loss=0.22029021382331848
I0204 13:37:51.252354 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:37:52.635325 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:37:53.967136 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:37:55.298947 140584300062528 submission_runner.py:408] Time since start: 8756.26s, 	Step: 34591, 	{'train/ssim': 0.7553950037275042, 'train/loss': 0.2562501089913504, 'validation/ssim': 0.7269252075126618, 'validation/loss': 0.2848210890238112, 'validation/num_examples': 3554, 'test/ssim': 0.744058131239528, 'test/loss': 0.28614266402759353, 'test/num_examples': 3581, 'score': 8143.4895124435425, 'total_duration': 8756.257097244263, 'accumulated_submission_time': 8143.4895124435425, 'accumulated_eval_time': 608.3235597610474, 'accumulated_logging_time': 3.236752986907959}
I0204 13:37:55.323063 140397019907840 logging_writer.py:48] [34591] accumulated_eval_time=608.323560, accumulated_logging_time=3.236753, accumulated_submission_time=8143.489512, global_step=34591, preemption_count=0, score=8143.489512, test/loss=0.286143, test/num_examples=3581, test/ssim=0.744058, total_duration=8756.257097, train/loss=0.256250, train/ssim=0.755395, validation/loss=0.284821, validation/num_examples=3554, validation/ssim=0.726925
I0204 13:37:56.070124 140397011515136 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.08561229705810547, loss=0.2568660080432892
I0204 13:38:19.128565 140397019907840 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.07838549464941025, loss=0.24376367032527924
I0204 13:38:43.032074 140397011515136 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.07253792136907578, loss=0.22741176187992096
I0204 13:39:07.052704 140397019907840 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.07856892794370651, loss=0.2975967526435852
I0204 13:39:15.302061 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:39:16.682947 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:39:18.008588 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:39:19.336843 140584300062528 submission_runner.py:408] Time since start: 8840.29s, 	Step: 34936, 	{'train/ssim': 0.7556241580418178, 'train/loss': 0.2561021532331194, 'validation/ssim': 0.7270647262547482, 'validation/loss': 0.28473819180962473, 'validation/num_examples': 3554, 'test/ssim': 0.7441798265803895, 'test/loss': 0.28608563425020944, 'test/num_examples': 3581, 'score': 8223.44726896286, 'total_duration': 8840.294992685318, 'accumulated_submission_time': 8223.44726896286, 'accumulated_eval_time': 612.3583030700684, 'accumulated_logging_time': 3.270219087600708}
I0204 13:39:19.360265 140397011515136 logging_writer.py:48] [34936] accumulated_eval_time=612.358303, accumulated_logging_time=3.270219, accumulated_submission_time=8223.447269, global_step=34936, preemption_count=0, score=8223.447269, test/loss=0.286086, test/num_examples=3581, test/ssim=0.744180, total_duration=8840.294993, train/loss=0.256102, train/ssim=0.755624, validation/loss=0.284738, validation/num_examples=3554, validation/ssim=0.727065
I0204 13:39:32.390658 140397019907840 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.08954600989818573, loss=0.24856239557266235
I0204 13:39:56.495442 140397011515136 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.07124383747577667, loss=0.30074644088745117
I0204 13:40:20.354451 140397019907840 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.04609539359807968, loss=0.2311224490404129
I0204 13:40:39.575027 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:40:40.953704 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:40:42.283808 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:40:43.618476 140584300062528 submission_runner.py:408] Time since start: 8924.58s, 	Step: 35281, 	{'train/ssim': 0.755319322858538, 'train/loss': 0.2561110258102417, 'validation/ssim': 0.7267110177352982, 'validation/loss': 0.28473875854011327, 'validation/num_examples': 3554, 'test/ssim': 0.7438649185807037, 'test/loss': 0.2860812709438704, 'test/num_examples': 3581, 'score': 8303.64076423645, 'total_duration': 8924.576595306396, 'accumulated_submission_time': 8303.64076423645, 'accumulated_eval_time': 616.4016833305359, 'accumulated_logging_time': 3.3031046390533447}
I0204 13:40:43.646980 140397011515136 logging_writer.py:48] [35281] accumulated_eval_time=616.401683, accumulated_logging_time=3.303105, accumulated_submission_time=8303.640764, global_step=35281, preemption_count=0, score=8303.640764, test/loss=0.286081, test/num_examples=3581, test/ssim=0.743865, total_duration=8924.576595, train/loss=0.256111, train/ssim=0.755319, validation/loss=0.284739, validation/num_examples=3554, validation/ssim=0.726711
I0204 13:40:46.137657 140397019907840 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.047688521444797516, loss=0.2783889174461365
I0204 13:41:10.021661 140397011515136 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.06203094869852066, loss=0.32130172848701477
I0204 13:41:33.960097 140397019907840 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.05289487913250923, loss=0.3151463270187378
I0204 13:41:58.037084 140397011515136 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.09324460476636887, loss=0.2108902633190155
I0204 13:42:03.858359 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:42:05.240077 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:42:06.569139 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:42:07.901273 140584300062528 submission_runner.py:408] Time since start: 9008.86s, 	Step: 35625, 	{'train/ssim': 0.755361693246024, 'train/loss': 0.25613798413957867, 'validation/ssim': 0.7268043050084412, 'validation/loss': 0.28477454842914673, 'validation/num_examples': 3554, 'test/ssim': 0.7439365722519896, 'test/loss': 0.28610237162061924, 'test/num_examples': 3581, 'score': 8383.82935500145, 'total_duration': 9008.859397649765, 'accumulated_submission_time': 8383.82935500145, 'accumulated_eval_time': 620.4445323944092, 'accumulated_logging_time': 3.3424787521362305}
I0204 13:42:07.929751 140397019907840 logging_writer.py:48] [35625] accumulated_eval_time=620.444532, accumulated_logging_time=3.342479, accumulated_submission_time=8383.829355, global_step=35625, preemption_count=0, score=8383.829355, test/loss=0.286102, test/num_examples=3581, test/ssim=0.743937, total_duration=9008.859398, train/loss=0.256138, train/ssim=0.755362, validation/loss=0.284775, validation/num_examples=3554, validation/ssim=0.726804
I0204 13:42:24.284032 140397011515136 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.07694302499294281, loss=0.21043016016483307
I0204 13:42:48.304842 140397019907840 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.05210842937231064, loss=0.24361129105091095
I0204 13:43:12.410912 140397011515136 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.06472887098789215, loss=0.21994316577911377
I0204 13:43:27.931568 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:43:29.311145 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:43:30.638658 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:43:31.967585 140584300062528 submission_runner.py:408] Time since start: 9092.93s, 	Step: 35966, 	{'train/ssim': 0.7553381238664899, 'train/loss': 0.25610211917332243, 'validation/ssim': 0.7267506545221933, 'validation/loss': 0.2847349975105075, 'validation/num_examples': 3554, 'test/ssim': 0.743905824577632, 'test/loss': 0.28607237388953854, 'test/num_examples': 3581, 'score': 8463.80910038948, 'total_duration': 9092.92571401596, 'accumulated_submission_time': 8463.80910038948, 'accumulated_eval_time': 624.4805216789246, 'accumulated_logging_time': 3.3811798095703125}
I0204 13:43:31.991237 140397019907840 logging_writer.py:48] [35966] accumulated_eval_time=624.480522, accumulated_logging_time=3.381180, accumulated_submission_time=8463.809100, global_step=35966, preemption_count=0, score=8463.809100, test/loss=0.286072, test/num_examples=3581, test/ssim=0.743906, total_duration=9092.925714, train/loss=0.256102, train/ssim=0.755338, validation/loss=0.284735, validation/num_examples=3554, validation/ssim=0.726751
I0204 13:43:37.966402 140397011515136 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.05174382030963898, loss=0.2355947196483612
I0204 13:44:01.535249 140397019907840 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.04849770665168762, loss=0.3720398247241974
I0204 13:44:22.314601 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:44:23.694139 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:44:25.023574 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:44:26.354221 140584300062528 submission_runner.py:408] Time since start: 9147.31s, 	Step: 36189, 	{'train/ssim': 0.755429880959647, 'train/loss': 0.25610746656145367, 'validation/ssim': 0.7268578181054798, 'validation/loss': 0.28473779681564787, 'validation/num_examples': 3554, 'test/ssim': 0.744003658086952, 'test/loss': 0.2860763281359083, 'test/num_examples': 3581, 'score': 8514.113553285599, 'total_duration': 9147.31237244606, 'accumulated_submission_time': 8514.113553285599, 'accumulated_eval_time': 628.5201015472412, 'accumulated_logging_time': 3.4160211086273193}
I0204 13:44:26.377893 140397011515136 logging_writer.py:48] [36189] accumulated_eval_time=628.520102, accumulated_logging_time=3.416021, accumulated_submission_time=8514.113553, global_step=36189, preemption_count=0, score=8514.113553, test/loss=0.286076, test/num_examples=3581, test/ssim=0.744004, total_duration=9147.312372, train/loss=0.256107, train/ssim=0.755430, validation/loss=0.284738, validation/num_examples=3554, validation/ssim=0.726858
I0204 13:44:26.398987 140397019907840 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8514.113553
I0204 13:44:26.453691 140584300062528 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 13:44:26.698649 140584300062528 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1/checkpoint_36189
I0204 13:44:26.699976 140584300062528 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_1/checkpoint_36189.
I0204 13:44:27.237110 140584300062528 submission_runner.py:583] Tuning trial 1/5
I0204 13:44:27.237337 140584300062528 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.1, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0204 13:44:27.243999 140584300062528 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 55.57856774330139, 'total_duration': 255.28697657585144, 'accumulated_submission_time': 55.57856774330139, 'accumulated_eval_time': 199.7080636024475, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (340, {'train/ssim': 0.6899064608982631, 'train/loss': 0.31449713025774273, 'validation/ssim': 0.663529567256964, 'validation/loss': 0.34306793127022367, 'validation/num_examples': 3554, 'test/ssim': 0.6827848339107442, 'test/loss': 0.3440740777606639, 'test/num_examples': 3581, 'score': 135.91773223876953, 'total_duration': 340.1038362979889, 'accumulated_submission_time': 135.91773223876953, 'accumulated_eval_time': 204.1460680961609, 'accumulated_logging_time': 0.0274045467376709, 'global_step': 340, 'preemption_count': 0}), (584, {'train/ssim': 0.712254456111363, 'train/loss': 0.29293731280735563, 'validation/ssim': 0.6871440245585959, 'validation/loss': 0.31990369840760413, 'validation/num_examples': 3554, 'test/ssim': 0.7052362266781276, 'test/loss': 0.3218626327535954, 'test/num_examples': 3581, 'score': 215.98555970191956, 'total_duration': 424.25503969192505, 'accumulated_submission_time': 215.98555970191956, 'accumulated_eval_time': 208.18507623672485, 'accumulated_logging_time': 0.06345915794372559, 'global_step': 584, 'preemption_count': 0}), (831, {'train/ssim': 0.7251592363630023, 'train/loss': 0.28260299137660433, 'validation/ssim': 0.699622742970069, 'validation/loss': 0.30940015596423043, 'validation/num_examples': 3554, 'test/ssim': 0.7169947918484711, 'test/loss': 0.31175755615575257, 'test/num_examples': 3581, 'score': 296.20644450187683, 'total_duration': 508.56253838539124, 'accumulated_submission_time': 296.20644450187683, 'accumulated_eval_time': 212.22860860824585, 'accumulated_logging_time': 0.09788990020751953, 'global_step': 831, 'preemption_count': 0}), (1123, {'train/ssim': 0.7318246705191476, 'train/loss': 0.2763338940484183, 'validation/ssim': 0.7060530388294879, 'validation/loss': 0.3028629369526414, 'validation/num_examples': 3554, 'test/ssim': 0.7230841949045309, 'test/loss': 0.3051949388918947, 'test/num_examples': 3581, 'score': 376.2559127807617, 'total_duration': 592.7049720287323, 'accumulated_submission_time': 376.2559127807617, 'accumulated_eval_time': 216.27203941345215, 'accumulated_logging_time': 0.1372833251953125, 'global_step': 1123, 'preemption_count': 0}), (1468, {'train/ssim': 0.7371740341186523, 'train/loss': 0.2721036502293178, 'validation/ssim': 0.7114779891495498, 'validation/loss': 0.298528376092519, 'validation/num_examples': 3554, 'test/ssim': 0.7285530539871893, 'test/loss': 0.30065812294924604, 'test/num_examples': 3581, 'score': 456.3312237262726, 'total_duration': 676.8577456474304, 'accumulated_submission_time': 456.3312237262726, 'accumulated_eval_time': 220.31062197685242, 'accumulated_logging_time': 0.1638650894165039, 'global_step': 1468, 'preemption_count': 0}), (1814, {'train/ssim': 0.739152022770473, 'train/loss': 0.2694324425288609, 'validation/ssim': 0.7133444902530599, 'validation/loss': 0.29575022889042274, 'validation/num_examples': 3554, 'test/ssim': 0.7304791128525552, 'test/loss': 0.2976562704529985, 'test/num_examples': 3581, 'score': 536.3904583454132, 'total_duration': 760.9892885684967, 'accumulated_submission_time': 536.3904583454132, 'accumulated_eval_time': 224.34614849090576, 'accumulated_logging_time': 0.18819332122802734, 'global_step': 1814, 'preemption_count': 0}), (2158, {'train/ssim': 0.7400693893432617, 'train/loss': 0.2681713615145002, 'validation/ssim': 0.7146711891530669, 'validation/loss': 0.29411821681995637, 'validation/num_examples': 3554, 'test/ssim': 0.7317220415692195, 'test/loss': 0.2959929985295658, 'test/num_examples': 3581, 'score': 616.4971573352814, 'total_duration': 845.1751751899719, 'accumulated_submission_time': 616.4971573352814, 'accumulated_eval_time': 228.38849234580994, 'accumulated_logging_time': 0.21284890174865723, 'global_step': 2158, 'preemption_count': 0}), (2503, {'train/ssim': 0.7419065747942243, 'train/loss': 0.26662564277648926, 'validation/ssim': 0.7160875345121693, 'validation/loss': 0.2928775579122995, 'validation/num_examples': 3554, 'test/ssim': 0.7332659702466141, 'test/loss': 0.29462564740557806, 'test/num_examples': 3581, 'score': 696.509119272232, 'total_duration': 929.2663757801056, 'accumulated_submission_time': 696.509119272232, 'accumulated_eval_time': 232.4296793937683, 'accumulated_logging_time': 0.2388749122619629, 'global_step': 2503, 'preemption_count': 0}), (2848, {'train/ssim': 0.7424797330583844, 'train/loss': 0.26656499930790495, 'validation/ssim': 0.7164755903339547, 'validation/loss': 0.29284032543656796, 'validation/num_examples': 3554, 'test/ssim': 0.7336256703129364, 'test/loss': 0.29447092047219703, 'test/num_examples': 3581, 'score': 776.5994248390198, 'total_duration': 1013.4373586177826, 'accumulated_submission_time': 776.5994248390198, 'accumulated_eval_time': 236.4725306034088, 'accumulated_logging_time': 0.26478075981140137, 'global_step': 2848, 'preemption_count': 0}), (3190, {'train/ssim': 0.744572503226144, 'train/loss': 0.2646067312785557, 'validation/ssim': 0.7181011794588844, 'validation/loss': 0.2909685691958005, 'validation/num_examples': 3554, 'test/ssim': 0.7353150879860724, 'test/loss': 0.2926284121055571, 'test/num_examples': 3581, 'score': 856.7893908023834, 'total_duration': 1097.7059400081635, 'accumulated_submission_time': 856.7893908023834, 'accumulated_eval_time': 240.51452016830444, 'accumulated_logging_time': 0.28966665267944336, 'global_step': 3190, 'preemption_count': 0}), (3538, {'train/ssim': 0.7460277421133858, 'train/loss': 0.2635725566319057, 'validation/ssim': 0.7194483493510833, 'validation/loss': 0.2902894199867227, 'validation/num_examples': 3554, 'test/ssim': 0.7366975061522619, 'test/loss': 0.2918307451654566, 'test/num_examples': 3581, 'score': 936.8239948749542, 'total_duration': 1181.8276615142822, 'accumulated_submission_time': 936.8239948749542, 'accumulated_eval_time': 244.56147742271423, 'accumulated_logging_time': 0.31770825386047363, 'global_step': 3538, 'preemption_count': 0}), (3884, {'train/ssim': 0.7463890484401158, 'train/loss': 0.2633559022630964, 'validation/ssim': 0.7203027728439786, 'validation/loss': 0.28958004515158975, 'validation/num_examples': 3554, 'test/ssim': 0.7373969305230732, 'test/loss': 0.2911783626911128, 'test/num_examples': 3581, 'score': 1016.8996806144714, 'total_duration': 1265.9849543571472, 'accumulated_submission_time': 1016.8996806144714, 'accumulated_eval_time': 248.6039776802063, 'accumulated_logging_time': 0.34499454498291016, 'global_step': 3884, 'preemption_count': 0}), (4230, {'train/ssim': 0.745875494820731, 'train/loss': 0.26375818252563477, 'validation/ssim': 0.7200002418050084, 'validation/loss': 0.28997397436207445, 'validation/num_examples': 3554, 'test/ssim': 0.7372028315676487, 'test/loss': 0.2914835555165282, 'test/num_examples': 3581, 'score': 1096.9104199409485, 'total_duration': 1350.0770933628082, 'accumulated_submission_time': 1096.9104199409485, 'accumulated_eval_time': 252.64858031272888, 'accumulated_logging_time': 0.36988353729248047, 'global_step': 4230, 'preemption_count': 0}), (4576, {'train/ssim': 0.7481837953839984, 'train/loss': 0.2624566214425223, 'validation/ssim': 0.7213690504976786, 'validation/loss': 0.2893379997120322, 'validation/num_examples': 3554, 'test/ssim': 0.7384671677560388, 'test/loss': 0.2909181323739877, 'test/num_examples': 3581, 'score': 1176.9021356105804, 'total_duration': 1434.1509294509888, 'accumulated_submission_time': 1176.9021356105804, 'accumulated_eval_time': 256.6939928531647, 'accumulated_logging_time': 0.39466309547424316, 'global_step': 4576, 'preemption_count': 0}), (4922, {'train/ssim': 0.7474816186087472, 'train/loss': 0.26262130056108746, 'validation/ssim': 0.7212315925937324, 'validation/loss': 0.2890369799543648, 'validation/num_examples': 3554, 'test/ssim': 0.7384208758028483, 'test/loss': 0.2905407063756632, 'test/num_examples': 3581, 'score': 1256.8783206939697, 'total_duration': 1518.2038979530334, 'accumulated_submission_time': 1256.8783206939697, 'accumulated_eval_time': 260.7339150905609, 'accumulated_logging_time': 0.4196033477783203, 'global_step': 4922, 'preemption_count': 0}), (5268, {'train/ssim': 0.7481545039585659, 'train/loss': 0.262041585786002, 'validation/ssim': 0.7215776073174592, 'validation/loss': 0.28865782008388435, 'validation/num_examples': 3554, 'test/ssim': 0.7387660542402611, 'test/loss': 0.29012179487878736, 'test/num_examples': 3581, 'score': 1336.9380061626434, 'total_duration': 1602.3376910686493, 'accumulated_submission_time': 1336.9380061626434, 'accumulated_eval_time': 264.77026534080505, 'accumulated_logging_time': 0.44515347480773926, 'global_step': 5268, 'preemption_count': 0}), (5615, {'train/ssim': 0.7481823648725238, 'train/loss': 0.2613209826605661, 'validation/ssim': 0.7214367146832794, 'validation/loss': 0.2880889772362567, 'validation/num_examples': 3554, 'test/ssim': 0.7386184517680118, 'test/loss': 0.2896329341271642, 'test/num_examples': 3581, 'score': 1416.9430875778198, 'total_duration': 1686.421659231186, 'accumulated_submission_time': 1416.9430875778198, 'accumulated_eval_time': 268.809974193573, 'accumulated_logging_time': 0.47231531143188477, 'global_step': 5615, 'preemption_count': 0}), (5961, {'train/ssim': 0.7485959189278739, 'train/loss': 0.2613769769668579, 'validation/ssim': 0.7219383226865855, 'validation/loss': 0.2880452015994302, 'validation/num_examples': 3554, 'test/ssim': 0.7390884616727171, 'test/loss': 0.28950298941025554, 'test/num_examples': 3581, 'score': 1496.9353461265564, 'total_duration': 1770.4920568466187, 'accumulated_submission_time': 1496.9353461265564, 'accumulated_eval_time': 272.85027623176575, 'accumulated_logging_time': 0.4980456829071045, 'global_step': 5961, 'preemption_count': 0}), (6303, {'train/ssim': 0.7485676492963519, 'train/loss': 0.2616139990942819, 'validation/ssim': 0.7227368287712789, 'validation/loss': 0.288008621722443, 'validation/num_examples': 3554, 'test/ssim': 0.7398391548930118, 'test/loss': 0.28943055170736176, 'test/num_examples': 3581, 'score': 1576.922093629837, 'total_duration': 1854.556218624115, 'accumulated_submission_time': 1576.922093629837, 'accumulated_eval_time': 276.8902978897095, 'accumulated_logging_time': 0.5235202312469482, 'global_step': 6303, 'preemption_count': 0}), (6646, {'train/ssim': 0.7496201651436942, 'train/loss': 0.260679977280753, 'validation/ssim': 0.7227002145469893, 'validation/loss': 0.2876082523927705, 'validation/num_examples': 3554, 'test/ssim': 0.7399165354038676, 'test/loss': 0.2890858164182491, 'test/num_examples': 3581, 'score': 1656.9838755130768, 'total_duration': 1938.7012684345245, 'accumulated_submission_time': 1656.9838755130768, 'accumulated_eval_time': 280.935923576355, 'accumulated_logging_time': 0.5493738651275635, 'global_step': 6646, 'preemption_count': 0}), (6991, {'train/ssim': 0.7485895838056292, 'train/loss': 0.2608584335872105, 'validation/ssim': 0.7222806279016601, 'validation/loss': 0.28743989909037354, 'validation/num_examples': 3554, 'test/ssim': 0.7394819091865051, 'test/loss': 0.288878116218846, 'test/num_examples': 3581, 'score': 1737.0378777980804, 'total_duration': 2022.8351304531097, 'accumulated_submission_time': 1737.0378777980804, 'accumulated_eval_time': 284.97637605667114, 'accumulated_logging_time': 0.5766260623931885, 'global_step': 6991, 'preemption_count': 0}), (7338, {'train/ssim': 0.7492905344281878, 'train/loss': 0.2608873333249773, 'validation/ssim': 0.7231078483311058, 'validation/loss': 0.28731879050233894, 'validation/num_examples': 3554, 'test/ssim': 0.7403037106647934, 'test/loss': 0.28873088871823516, 'test/num_examples': 3581, 'score': 1817.0663664340973, 'total_duration': 2106.940655231476, 'accumulated_submission_time': 1817.0663664340973, 'accumulated_eval_time': 289.0156946182251, 'accumulated_logging_time': 0.6023619174957275, 'global_step': 7338, 'preemption_count': 0}), (7683, {'train/ssim': 0.7503745215279716, 'train/loss': 0.26090713909694124, 'validation/ssim': 0.7233539810996412, 'validation/loss': 0.28783700542632423, 'validation/num_examples': 3554, 'test/ssim': 0.7404244515323932, 'test/loss': 0.2893348316745497, 'test/num_examples': 3581, 'score': 1897.189120054245, 'total_duration': 2191.1428146362305, 'accumulated_submission_time': 1897.189120054245, 'accumulated_eval_time': 293.05683064460754, 'accumulated_logging_time': 0.6286115646362305, 'global_step': 7683, 'preemption_count': 0}), (8027, {'train/ssim': 0.7490619250706264, 'train/loss': 0.2611512967518398, 'validation/ssim': 0.7230151106148002, 'validation/loss': 0.2876697168902997, 'validation/num_examples': 3554, 'test/ssim': 0.740137905023911, 'test/loss': 0.28910221290535115, 'test/num_examples': 3581, 'score': 1977.1989560127258, 'total_duration': 2275.2364633083344, 'accumulated_submission_time': 1977.1989560127258, 'accumulated_eval_time': 297.0999720096588, 'accumulated_logging_time': 0.6573379039764404, 'global_step': 8027, 'preemption_count': 0}), (8373, {'train/ssim': 0.7492820194789341, 'train/loss': 0.2605456454413278, 'validation/ssim': 0.722934188370498, 'validation/loss': 0.2869772581015669, 'validation/num_examples': 3554, 'test/ssim': 0.7401876739868403, 'test/loss': 0.2883704387086359, 'test/num_examples': 3581, 'score': 2057.3637301921844, 'total_duration': 2359.4793276786804, 'accumulated_submission_time': 2057.3637301921844, 'accumulated_eval_time': 301.13877034187317, 'accumulated_logging_time': 0.68442702293396, 'global_step': 8373, 'preemption_count': 0}), (8715, {'train/ssim': 0.7499177796500069, 'train/loss': 0.2602596623556955, 'validation/ssim': 0.723055022180114, 'validation/loss': 0.28704102386835256, 'validation/num_examples': 3554, 'test/ssim': 0.7403200048869031, 'test/loss': 0.28843138864405893, 'test/num_examples': 3581, 'score': 2137.3297839164734, 'total_duration': 2443.523314476013, 'accumulated_submission_time': 2137.3297839164734, 'accumulated_eval_time': 305.17865443229675, 'accumulated_logging_time': 0.7108016014099121, 'global_step': 8715, 'preemption_count': 0}), (9061, {'train/ssim': 0.750847407749721, 'train/loss': 0.26009057249341694, 'validation/ssim': 0.7241669817459201, 'validation/loss': 0.2869474618167909, 'validation/num_examples': 3554, 'test/ssim': 0.7413580627356186, 'test/loss': 0.2883768132264905, 'test/num_examples': 3581, 'score': 2217.4914298057556, 'total_duration': 2527.769276380539, 'accumulated_submission_time': 2217.4914298057556, 'accumulated_eval_time': 309.2239181995392, 'accumulated_logging_time': 0.7377052307128906, 'global_step': 9061, 'preemption_count': 0}), (9408, {'train/ssim': 0.7499944823128837, 'train/loss': 0.2610064574650356, 'validation/ssim': 0.7235614388057471, 'validation/loss': 0.2875855488259268, 'validation/num_examples': 3554, 'test/ssim': 0.7408017411773946, 'test/loss': 0.28887542324071486, 'test/num_examples': 3581, 'score': 2297.5060591697693, 'total_duration': 2611.8630299568176, 'accumulated_submission_time': 2297.5060591697693, 'accumulated_eval_time': 313.26463556289673, 'accumulated_logging_time': 0.7639820575714111, 'global_step': 9408, 'preemption_count': 0}), (9751, {'train/ssim': 0.7508278574262347, 'train/loss': 0.2601182460784912, 'validation/ssim': 0.7241959708690912, 'validation/loss': 0.28678190781953433, 'validation/num_examples': 3554, 'test/ssim': 0.7413401322736317, 'test/loss': 0.2882359943320651, 'test/num_examples': 3581, 'score': 2377.5569076538086, 'total_duration': 2695.998062610626, 'accumulated_submission_time': 2377.5569076538086, 'accumulated_eval_time': 317.30930352211, 'accumulated_logging_time': 0.7913625240325928, 'global_step': 9751, 'preemption_count': 0}), (10099, {'train/ssim': 0.7506995882306781, 'train/loss': 0.2599021536963327, 'validation/ssim': 0.723881967831141, 'validation/loss': 0.2867163731666784, 'validation/num_examples': 3554, 'test/ssim': 0.7411026729614633, 'test/loss': 0.28817647610653446, 'test/num_examples': 3581, 'score': 2457.756463766098, 'total_duration': 2780.274495124817, 'accumulated_submission_time': 2457.756463766098, 'accumulated_eval_time': 321.34729051589966, 'accumulated_logging_time': 0.818218469619751, 'global_step': 10099, 'preemption_count': 0}), (10445, {'train/ssim': 0.7509869847978864, 'train/loss': 0.25971748147692, 'validation/ssim': 0.7240853038609665, 'validation/loss': 0.2866183803131155, 'validation/num_examples': 3554, 'test/ssim': 0.7414004686191008, 'test/loss': 0.28797797975644024, 'test/num_examples': 3581, 'score': 2537.771735906601, 'total_duration': 2864.37513422966, 'accumulated_submission_time': 2537.771735906601, 'accumulated_eval_time': 325.3895990848541, 'accumulated_logging_time': 0.8493859767913818, 'global_step': 10445, 'preemption_count': 0}), (10790, {'train/ssim': 0.7511575562613351, 'train/loss': 0.25957843235560824, 'validation/ssim': 0.7242304555606359, 'validation/loss': 0.286358319713483, 'validation/num_examples': 3554, 'test/ssim': 0.741495575061959, 'test/loss': 0.28772633969867006, 'test/num_examples': 3581, 'score': 2617.872266769409, 'total_duration': 2948.560939311981, 'accumulated_submission_time': 2617.872266769409, 'accumulated_eval_time': 329.43454337120056, 'accumulated_logging_time': 0.8776884078979492, 'global_step': 10790, 'preemption_count': 0}), (11134, {'train/ssim': 0.7513892310006278, 'train/loss': 0.25928807258605957, 'validation/ssim': 0.7243891400974254, 'validation/loss': 0.2863875320941193, 'validation/num_examples': 3554, 'test/ssim': 0.7416386778745462, 'test/loss': 0.28777788125479964, 'test/num_examples': 3581, 'score': 2697.8649265766144, 'total_duration': 3032.638692140579, 'accumulated_submission_time': 2697.8649265766144, 'accumulated_eval_time': 333.47989439964294, 'accumulated_logging_time': 0.9055733680725098, 'global_step': 11134, 'preemption_count': 0}), (11480, {'train/ssim': 0.7506914819989886, 'train/loss': 0.2594648599624634, 'validation/ssim': 0.7240741066404052, 'validation/loss': 0.2862425177836593, 'validation/num_examples': 3554, 'test/ssim': 0.74135724461568, 'test/loss': 0.28759359973863796, 'test/num_examples': 3581, 'score': 2777.8663704395294, 'total_duration': 3116.7184529304504, 'accumulated_submission_time': 2777.8663704395294, 'accumulated_eval_time': 337.51908659935, 'accumulated_logging_time': 0.9325578212738037, 'global_step': 11480, 'preemption_count': 0}), (11824, {'train/ssim': 0.7505995886666434, 'train/loss': 0.26008808612823486, 'validation/ssim': 0.723615913627251, 'validation/loss': 0.2868656121953257, 'validation/num_examples': 3554, 'test/ssim': 0.7408781672149888, 'test/loss': 0.28832871459176906, 'test/num_examples': 3581, 'score': 2857.9913415908813, 'total_duration': 3200.917214870453, 'accumulated_submission_time': 2857.9913415908813, 'accumulated_eval_time': 341.55452609062195, 'accumulated_logging_time': 0.9591963291168213, 'global_step': 11824, 'preemption_count': 0}), (12169, {'train/ssim': 0.7514924321855817, 'train/loss': 0.25900142533438547, 'validation/ssim': 0.7240672371799382, 'validation/loss': 0.28626415658413057, 'validation/num_examples': 3554, 'test/ssim': 0.7413234289915527, 'test/loss': 0.28767036665953993, 'test/num_examples': 3581, 'score': 2938.1020641326904, 'total_duration': 3285.1103279590607, 'accumulated_submission_time': 2938.1020641326904, 'accumulated_eval_time': 345.5973918437958, 'accumulated_logging_time': 0.9867033958435059, 'global_step': 12169, 'preemption_count': 0}), (12514, {'train/ssim': 0.7499089922223773, 'train/loss': 0.2597200189317976, 'validation/ssim': 0.7233776807382527, 'validation/loss': 0.286492978312289, 'validation/num_examples': 3554, 'test/ssim': 0.7406686603340548, 'test/loss': 0.2878473532729161, 'test/num_examples': 3581, 'score': 3018.1377742290497, 'total_duration': 3369.2264947891235, 'accumulated_submission_time': 3018.1377742290497, 'accumulated_eval_time': 349.6387412548065, 'accumulated_logging_time': 1.0136513710021973, 'global_step': 12514, 'preemption_count': 0}), (12859, {'train/ssim': 0.7517422948564801, 'train/loss': 0.2592545918055943, 'validation/ssim': 0.7250731322761326, 'validation/loss': 0.2861169783936234, 'validation/num_examples': 3554, 'test/ssim': 0.7423111724640463, 'test/loss': 0.2875071517317963, 'test/num_examples': 3581, 'score': 3098.17995595932, 'total_duration': 3453.3531222343445, 'accumulated_submission_time': 3098.17995595932, 'accumulated_eval_time': 353.6803197860718, 'accumulated_logging_time': 1.04435133934021, 'global_step': 12859, 'preemption_count': 0}), (13201, {'train/ssim': 0.751594066619873, 'train/loss': 0.2592260496956961, 'validation/ssim': 0.7241303675216305, 'validation/loss': 0.28647570161921426, 'validation/num_examples': 3554, 'test/ssim': 0.7413691073547891, 'test/loss': 0.2878732944926347, 'test/num_examples': 3581, 'score': 3178.1596059799194, 'total_duration': 3537.362501144409, 'accumulated_submission_time': 3178.1596059799194, 'accumulated_eval_time': 357.6665780544281, 'accumulated_logging_time': 1.0757217407226562, 'global_step': 13201, 'preemption_count': 0}), (13548, {'train/ssim': 0.7518584387642997, 'train/loss': 0.25964949812207905, 'validation/ssim': 0.7249348500369303, 'validation/loss': 0.28665308826212543, 'validation/num_examples': 3554, 'test/ssim': 0.7420486923170903, 'test/loss': 0.2880651095298974, 'test/num_examples': 3581, 'score': 3258.367030143738, 'total_duration': 3621.6565403938293, 'accumulated_submission_time': 3258.367030143738, 'accumulated_eval_time': 361.71016097068787, 'accumulated_logging_time': 1.1067495346069336, 'global_step': 13548, 'preemption_count': 0}), (13893, {'train/ssim': 0.7509762900216239, 'train/loss': 0.2593644346509661, 'validation/ssim': 0.7240757553109173, 'validation/loss': 0.28617347970596513, 'validation/num_examples': 3554, 'test/ssim': 0.7411973703443522, 'test/loss': 0.287589679580599, 'test/num_examples': 3581, 'score': 3338.5711925029755, 'total_duration': 3705.9466314315796, 'accumulated_submission_time': 3338.5711925029755, 'accumulated_eval_time': 365.75594544410706, 'accumulated_logging_time': 1.1348917484283447, 'global_step': 13893, 'preemption_count': 0}), (14237, {'train/ssim': 0.7518370492117745, 'train/loss': 0.2589819261005947, 'validation/ssim': 0.7242094350116066, 'validation/loss': 0.28632993166810283, 'validation/num_examples': 3554, 'test/ssim': 0.7414800989597877, 'test/loss': 0.28768618364501886, 'test/num_examples': 3581, 'score': 3418.6912846565247, 'total_duration': 3790.152283668518, 'accumulated_submission_time': 3418.6912846565247, 'accumulated_eval_time': 369.80122470855713, 'accumulated_logging_time': 1.1632394790649414, 'global_step': 14237, 'preemption_count': 0}), (14583, {'train/ssim': 0.7517756053379604, 'train/loss': 0.25908333914620535, 'validation/ssim': 0.7246804739158342, 'validation/loss': 0.28622031225269945, 'validation/num_examples': 3554, 'test/ssim': 0.7419205201933817, 'test/loss': 0.28753363836480733, 'test/num_examples': 3581, 'score': 3498.888443470001, 'total_duration': 3874.429375886917, 'accumulated_submission_time': 3498.888443470001, 'accumulated_eval_time': 373.8409984111786, 'accumulated_logging_time': 1.191213607788086, 'global_step': 14583, 'preemption_count': 0}), (14930, {'train/ssim': 0.7516927719116211, 'train/loss': 0.25924532754080637, 'validation/ssim': 0.7247757533325127, 'validation/loss': 0.2861635533355902, 'validation/num_examples': 3554, 'test/ssim': 0.7419288377460905, 'test/loss': 0.287559579584526, 'test/num_examples': 3581, 'score': 3578.980725288391, 'total_duration': 3958.6055693626404, 'accumulated_submission_time': 3578.980725288391, 'accumulated_eval_time': 377.8848206996918, 'accumulated_logging_time': 1.2186510562896729, 'global_step': 14930, 'preemption_count': 0}), (15274, {'train/ssim': 0.7525625228881836, 'train/loss': 0.25946458748408724, 'validation/ssim': 0.7252395106086452, 'validation/loss': 0.28695113697814084, 'validation/num_examples': 3554, 'test/ssim': 0.7423833715486247, 'test/loss': 0.28831855626919856, 'test/num_examples': 3581, 'score': 3658.9713571071625, 'total_duration': 4042.6870880126953, 'accumulated_submission_time': 3658.9713571071625, 'accumulated_eval_time': 381.9346296787262, 'accumulated_logging_time': 1.2474379539489746, 'global_step': 15274, 'preemption_count': 0}), (15618, {'train/ssim': 0.7516856874738421, 'train/loss': 0.2591737338474819, 'validation/ssim': 0.7246266173457724, 'validation/loss': 0.28634938941487587, 'validation/num_examples': 3554, 'test/ssim': 0.741825345573862, 'test/loss': 0.287680593158772, 'test/num_examples': 3581, 'score': 3739.1749410629272, 'total_duration': 4126.983177185059, 'accumulated_submission_time': 3739.1749410629272, 'accumulated_eval_time': 385.9861137866974, 'accumulated_logging_time': 1.276132583618164, 'global_step': 15618, 'preemption_count': 0}), (15962, {'train/ssim': 0.7520236968994141, 'train/loss': 0.2588274819510324, 'validation/ssim': 0.7249162337990644, 'validation/loss': 0.28589688088025816, 'validation/num_examples': 3554, 'test/ssim': 0.7421772735007679, 'test/loss': 0.28714755393046637, 'test/num_examples': 3581, 'score': 3819.2066938877106, 'total_duration': 4211.104909896851, 'accumulated_submission_time': 3819.2066938877106, 'accumulated_eval_time': 390.03538823127747, 'accumulated_logging_time': 1.3046724796295166, 'global_step': 15962, 'preemption_count': 0}), (16305, {'train/ssim': 0.7516825539725167, 'train/loss': 0.2592099905014038, 'validation/ssim': 0.72449877668648, 'validation/loss': 0.28637911700504715, 'validation/num_examples': 3554, 'test/ssim': 0.7417084907759705, 'test/loss': 0.28774069088592574, 'test/num_examples': 3581, 'score': 3899.3228511810303, 'total_duration': 4295.300581455231, 'accumulated_submission_time': 3899.3228511810303, 'accumulated_eval_time': 394.0746328830719, 'accumulated_logging_time': 1.3331573009490967, 'global_step': 16305, 'preemption_count': 0}), (16653, {'train/ssim': 0.7520562580653599, 'train/loss': 0.2589167526790074, 'validation/ssim': 0.7248071467668472, 'validation/loss': 0.2861561686655881, 'validation/num_examples': 3554, 'test/ssim': 0.7420754175684167, 'test/loss': 0.2875004022423031, 'test/num_examples': 3581, 'score': 3979.487622022629, 'total_duration': 4379.550000429153, 'accumulated_submission_time': 3979.487622022629, 'accumulated_eval_time': 398.1184675693512, 'accumulated_logging_time': 1.3620598316192627, 'global_step': 16653, 'preemption_count': 0}), (16997, {'train/ssim': 0.7524524416242327, 'train/loss': 0.25853409085954937, 'validation/ssim': 0.7252197952571047, 'validation/loss': 0.2857100659028559, 'validation/num_examples': 3554, 'test/ssim': 0.7424610929427883, 'test/loss': 0.287021767989912, 'test/num_examples': 3581, 'score': 4059.4647312164307, 'total_duration': 4463.610082149506, 'accumulated_submission_time': 4059.4647312164307, 'accumulated_eval_time': 402.1616246700287, 'accumulated_logging_time': 1.389885425567627, 'global_step': 16997, 'preemption_count': 0}), (17340, {'train/ssim': 0.7515924998692104, 'train/loss': 0.2602828230176653, 'validation/ssim': 0.7249902178882949, 'validation/loss': 0.2872200420081246, 'validation/num_examples': 3554, 'test/ssim': 0.7420885756640953, 'test/loss': 0.28857786620139275, 'test/num_examples': 3581, 'score': 4139.484055280685, 'total_duration': 4547.71174955368, 'accumulated_submission_time': 4139.484055280685, 'accumulated_eval_time': 406.2029480934143, 'accumulated_logging_time': 1.4190490245819092, 'global_step': 17340, 'preemption_count': 0}), (17687, {'train/ssim': 0.7524777821132115, 'train/loss': 0.25873615060533794, 'validation/ssim': 0.725357871412493, 'validation/loss': 0.2860411052027645, 'validation/num_examples': 3554, 'test/ssim': 0.7425334965573513, 'test/loss': 0.28743795242032605, 'test/num_examples': 3581, 'score': 4219.586560964584, 'total_duration': 4631.894050359726, 'accumulated_submission_time': 4219.586560964584, 'accumulated_eval_time': 410.2422773838043, 'accumulated_logging_time': 1.4473683834075928, 'global_step': 17687, 'preemption_count': 0}), (18031, {'train/ssim': 0.7531301634652274, 'train/loss': 0.2585129737854004, 'validation/ssim': 0.7258307650710467, 'validation/loss': 0.28590819831637765, 'validation/num_examples': 3554, 'test/ssim': 0.743022118690659, 'test/loss': 0.28725223919427184, 'test/num_examples': 3581, 'score': 4299.56721663475, 'total_duration': 4715.960064649582, 'accumulated_submission_time': 4299.56721663475, 'accumulated_eval_time': 414.28659558296204, 'accumulated_logging_time': 1.4766151905059814, 'global_step': 18031, 'preemption_count': 0}), (18376, {'train/ssim': 0.7519820758274623, 'train/loss': 0.25845859731946674, 'validation/ssim': 0.7246246938968416, 'validation/loss': 0.2856576690931433, 'validation/num_examples': 3554, 'test/ssim': 0.7419246789697361, 'test/loss': 0.28695168238184166, 'test/num_examples': 3581, 'score': 4379.5926213264465, 'total_duration': 4800.07418346405, 'accumulated_submission_time': 4379.5926213264465, 'accumulated_eval_time': 418.3355646133423, 'accumulated_logging_time': 1.5043630599975586, 'global_step': 18376, 'preemption_count': 0}), (18722, {'train/ssim': 0.7529837744576591, 'train/loss': 0.25822533879961285, 'validation/ssim': 0.7253613061427265, 'validation/loss': 0.2858288045270294, 'validation/num_examples': 3554, 'test/ssim': 0.7424981128700083, 'test/loss': 0.2871849488293249, 'test/num_examples': 3581, 'score': 4459.631384849548, 'total_duration': 4884.19443488121, 'accumulated_submission_time': 4459.631384849548, 'accumulated_eval_time': 422.3765048980713, 'accumulated_logging_time': 1.5328974723815918, 'global_step': 18722, 'preemption_count': 0}), (19067, {'train/ssim': 0.7525200843811035, 'train/loss': 0.25815859862736296, 'validation/ssim': 0.7251618857053672, 'validation/loss': 0.2855097696092871, 'validation/num_examples': 3554, 'test/ssim': 0.7424585704063111, 'test/loss': 0.2868095340425161, 'test/num_examples': 3581, 'score': 4539.849860191345, 'total_duration': 4968.498574972153, 'accumulated_submission_time': 4539.849860191345, 'accumulated_eval_time': 426.42155289649963, 'accumulated_logging_time': 1.5613839626312256, 'global_step': 19067, 'preemption_count': 0}), (19410, {'train/ssim': 0.7519347327096122, 'train/loss': 0.25834107398986816, 'validation/ssim': 0.7246815043349043, 'validation/loss': 0.28554320670811056, 'validation/num_examples': 3554, 'test/ssim': 0.7419808565388509, 'test/loss': 0.28683131648588034, 'test/num_examples': 3581, 'score': 4619.828453540802, 'total_duration': 5052.564338922501, 'accumulated_submission_time': 4619.828453540802, 'accumulated_eval_time': 430.4662718772888, 'accumulated_logging_time': 1.592024326324463, 'global_step': 19410, 'preemption_count': 0}), (19757, {'train/ssim': 0.7540554319109235, 'train/loss': 0.25782649857657297, 'validation/ssim': 0.7263243358056064, 'validation/loss': 0.2855517076654386, 'validation/num_examples': 3554, 'test/ssim': 0.7435532148841106, 'test/loss': 0.28688728952501047, 'test/num_examples': 3581, 'score': 4700.001065015793, 'total_duration': 5136.818740844727, 'accumulated_submission_time': 4700.001065015793, 'accumulated_eval_time': 434.50729513168335, 'accumulated_logging_time': 1.6206250190734863, 'global_step': 19757, 'preemption_count': 0}), (20104, {'train/ssim': 0.752790996006557, 'train/loss': 0.2582331725529262, 'validation/ssim': 0.7253982638400394, 'validation/loss': 0.2855855912791925, 'validation/num_examples': 3554, 'test/ssim': 0.7426360342563181, 'test/loss': 0.286899697677412, 'test/num_examples': 3581, 'score': 4780.03605055809, 'total_duration': 5220.933315753937, 'accumulated_submission_time': 4780.03605055809, 'accumulated_eval_time': 438.54583048820496, 'accumulated_logging_time': 1.6494874954223633, 'global_step': 20104, 'preemption_count': 0}), (20447, {'train/ssim': 0.7531872476850238, 'train/loss': 0.2581703151975359, 'validation/ssim': 0.7259412259953574, 'validation/loss': 0.28545850626055147, 'validation/num_examples': 3554, 'test/ssim': 0.7431528815275062, 'test/loss': 0.2867745594151424, 'test/num_examples': 3581, 'score': 4860.2350742816925, 'total_duration': 5305.218400716782, 'accumulated_submission_time': 4860.2350742816925, 'accumulated_eval_time': 442.5905215740204, 'accumulated_logging_time': 1.6790635585784912, 'global_step': 20447, 'preemption_count': 0}), (20791, {'train/ssim': 0.753039973122733, 'train/loss': 0.25777106625693186, 'validation/ssim': 0.7251662821600662, 'validation/loss': 0.2855243843864308, 'validation/num_examples': 3554, 'test/ssim': 0.7424073697334892, 'test/loss': 0.28690133391728917, 'test/num_examples': 3581, 'score': 4940.427654981613, 'total_duration': 5389.503933191299, 'accumulated_submission_time': 4940.427654981613, 'accumulated_eval_time': 446.64170718193054, 'accumulated_logging_time': 1.7088754177093506, 'global_step': 20791, 'preemption_count': 0}), (21138, {'train/ssim': 0.7532409940447126, 'train/loss': 0.2579892703465053, 'validation/ssim': 0.7257597348498172, 'validation/loss': 0.285431011245032, 'validation/num_examples': 3554, 'test/ssim': 0.7429243533580006, 'test/loss': 0.2867768433333042, 'test/num_examples': 3581, 'score': 5020.432681083679, 'total_duration': 5473.598413228989, 'accumulated_submission_time': 5020.432681083679, 'accumulated_eval_time': 450.68442273139954, 'accumulated_logging_time': 1.743255853652954, 'global_step': 21138, 'preemption_count': 0}), (21483, {'train/ssim': 0.7530279840741839, 'train/loss': 0.25805517605372835, 'validation/ssim': 0.7256322376635481, 'validation/loss': 0.2854780842228827, 'validation/num_examples': 3554, 'test/ssim': 0.742838178057805, 'test/loss': 0.28676242396938706, 'test/num_examples': 3581, 'score': 5100.391660451889, 'total_duration': 5557.642760276794, 'accumulated_submission_time': 5100.391660451889, 'accumulated_eval_time': 454.7285809516907, 'accumulated_logging_time': 1.772273302078247, 'global_step': 21483, 'preemption_count': 0}), (21825, {'train/ssim': 0.753004619053432, 'train/loss': 0.257967335837228, 'validation/ssim': 0.7253357517497889, 'validation/loss': 0.28570309340048183, 'validation/num_examples': 3554, 'test/ssim': 0.7424775916948827, 'test/loss': 0.2871336799798415, 'test/num_examples': 3581, 'score': 5180.50639796257, 'total_duration': 5641.847291946411, 'accumulated_submission_time': 5180.50639796257, 'accumulated_eval_time': 458.77478289604187, 'accumulated_logging_time': 1.8035430908203125, 'global_step': 21825, 'preemption_count': 0}), (22173, {'train/ssim': 0.7532924243382045, 'train/loss': 0.25779662813459125, 'validation/ssim': 0.7257460646234877, 'validation/loss': 0.2853456753723797, 'validation/num_examples': 3554, 'test/ssim': 0.7429429655866029, 'test/loss': 0.28666609034662105, 'test/num_examples': 3581, 'score': 5260.6730744838715, 'total_duration': 5726.103197097778, 'accumulated_submission_time': 5260.6730744838715, 'accumulated_eval_time': 462.82131361961365, 'accumulated_logging_time': 1.834075689315796, 'global_step': 22173, 'preemption_count': 0}), (22519, {'train/ssim': 0.7536420822143555, 'train/loss': 0.2580252374921526, 'validation/ssim': 0.7262866224676421, 'validation/loss': 0.2855393769839002, 'validation/num_examples': 3554, 'test/ssim': 0.743415566204447, 'test/loss': 0.28686271183852274, 'test/num_examples': 3581, 'score': 5340.706670284271, 'total_duration': 5810.223093986511, 'accumulated_submission_time': 5340.706670284271, 'accumulated_eval_time': 466.86464047431946, 'accumulated_logging_time': 1.8650314807891846, 'global_step': 22519, 'preemption_count': 0}), (22860, {'train/ssim': 0.7531393596104213, 'train/loss': 0.2581378732408796, 'validation/ssim': 0.7255267914453785, 'validation/loss': 0.2857794474535734, 'validation/num_examples': 3554, 'test/ssim': 0.7426878485190939, 'test/loss': 0.28715386027165946, 'test/num_examples': 3581, 'score': 5420.829624176025, 'total_duration': 5894.439101219177, 'accumulated_submission_time': 5420.829624176025, 'accumulated_eval_time': 470.9098572731018, 'accumulated_logging_time': 1.9009425640106201, 'global_step': 22860, 'preemption_count': 0}), (23207, {'train/ssim': 0.7534748486110142, 'train/loss': 0.2577291897365025, 'validation/ssim': 0.7260389784178038, 'validation/loss': 0.2853734451663179, 'validation/num_examples': 3554, 'test/ssim': 0.7432383750610863, 'test/loss': 0.2866646586367286, 'test/num_examples': 3581, 'score': 5500.831784963608, 'total_duration': 5978.536752939224, 'accumulated_submission_time': 5500.831784963608, 'accumulated_eval_time': 474.96408867836, 'accumulated_logging_time': 1.9300155639648438, 'global_step': 23207, 'preemption_count': 0}), (23552, {'train/ssim': 0.7532529830932617, 'train/loss': 0.25804788725716726, 'validation/ssim': 0.7259530414673607, 'validation/loss': 0.28554932052792625, 'validation/num_examples': 3554, 'test/ssim': 0.7430817050928512, 'test/loss': 0.28686687061487715, 'test/num_examples': 3581, 'score': 5581.046790122986, 'total_duration': 6062.840421676636, 'accumulated_submission_time': 5581.046790122986, 'accumulated_eval_time': 479.00782084465027, 'accumulated_logging_time': 1.9629197120666504, 'global_step': 23552, 'preemption_count': 0}), (23896, {'train/ssim': 0.7521711758204869, 'train/loss': 0.25841634614127024, 'validation/ssim': 0.7247517102208779, 'validation/loss': 0.285952265905274, 'validation/num_examples': 3554, 'test/ssim': 0.7421021428197431, 'test/loss': 0.28722411632138367, 'test/num_examples': 3581, 'score': 5661.1857368946075, 'total_duration': 6147.086599349976, 'accumulated_submission_time': 5661.1857368946075, 'accumulated_eval_time': 483.0488519668579, 'accumulated_logging_time': 2.0170490741729736, 'global_step': 23896, 'preemption_count': 0}), (24243, {'train/ssim': 0.7536928313119071, 'train/loss': 0.25732050623212543, 'validation/ssim': 0.7258101566896454, 'validation/loss': 0.28519540592466236, 'validation/num_examples': 3554, 'test/ssim': 0.7430396400926766, 'test/loss': 0.2865261918371265, 'test/num_examples': 3581, 'score': 5741.163243055344, 'total_duration': 6231.160847902298, 'accumulated_submission_time': 5741.163243055344, 'accumulated_eval_time': 487.0972065925598, 'accumulated_logging_time': 2.053084135055542, 'global_step': 24243, 'preemption_count': 0}), (24588, {'train/ssim': 0.7535805021013532, 'train/loss': 0.2576057570321219, 'validation/ssim': 0.7259259070985158, 'validation/loss': 0.2853072407410664, 'validation/num_examples': 3554, 'test/ssim': 0.7431695848095853, 'test/loss': 0.28657827880654846, 'test/num_examples': 3581, 'score': 5821.219519615173, 'total_duration': 6315.30278635025, 'accumulated_submission_time': 5821.219519615173, 'accumulated_eval_time': 491.14065527915955, 'accumulated_logging_time': 2.083099126815796, 'global_step': 24588, 'preemption_count': 0}), (24932, {'train/ssim': 0.7523881367274693, 'train/loss': 0.25837341376713346, 'validation/ssim': 0.7248127110298256, 'validation/loss': 0.2859432840857133, 'validation/num_examples': 3554, 'test/ssim': 0.742053396506737, 'test/loss': 0.2873815021445651, 'test/num_examples': 3581, 'score': 5901.379008293152, 'total_duration': 6399.552320480347, 'accumulated_submission_time': 5901.379008293152, 'accumulated_eval_time': 495.18860507011414, 'accumulated_logging_time': 2.1133792400360107, 'global_step': 24932, 'preemption_count': 0}), (25277, {'train/ssim': 0.7541452135358538, 'train/loss': 0.2572070360183716, 'validation/ssim': 0.7261007348674029, 'validation/loss': 0.2851946331103598, 'validation/num_examples': 3554, 'test/ssim': 0.743282826244415, 'test/loss': 0.2865642685026005, 'test/num_examples': 3581, 'score': 5981.531459093094, 'total_duration': 6483.78791642189, 'accumulated_submission_time': 5981.531459093094, 'accumulated_eval_time': 499.2294337749481, 'accumulated_logging_time': 2.143554449081421, 'global_step': 25277, 'preemption_count': 0}), (25624, {'train/ssim': 0.7540187154497419, 'train/loss': 0.2573329380580357, 'validation/ssim': 0.7261812449440771, 'validation/loss': 0.2851841400094963, 'validation/num_examples': 3554, 'test/ssim': 0.7433787508072117, 'test/loss': 0.28650106873734643, 'test/num_examples': 3581, 'score': 6061.55241727829, 'total_duration': 6567.898736476898, 'accumulated_submission_time': 6061.55241727829, 'accumulated_eval_time': 503.27667450904846, 'accumulated_logging_time': 2.1740894317626953, 'global_step': 25624, 'preemption_count': 0}), (25968, {'train/ssim': 0.7539004598345075, 'train/loss': 0.2575019257409232, 'validation/ssim': 0.7261755432918894, 'validation/loss': 0.2853177166682787, 'validation/num_examples': 3554, 'test/ssim': 0.743403226228707, 'test/loss': 0.28662620699961605, 'test/num_examples': 3581, 'score': 6141.601917743683, 'total_duration': 6652.036284208298, 'accumulated_submission_time': 6141.601917743683, 'accumulated_eval_time': 507.32264375686646, 'accumulated_logging_time': 2.204224109649658, 'global_step': 25968, 'preemption_count': 0}), (26314, {'train/ssim': 0.7539973258972168, 'train/loss': 0.25696046011788504, 'validation/ssim': 0.7257981351338281, 'validation/loss': 0.2851275356552476, 'validation/num_examples': 3554, 'test/ssim': 0.7430313907166294, 'test/loss': 0.2864493908278937, 'test/num_examples': 3581, 'score': 6221.579905986786, 'total_duration': 6736.1040687561035, 'accumulated_submission_time': 6221.579905986786, 'accumulated_eval_time': 511.3682265281677, 'accumulated_logging_time': 2.2362966537475586, 'global_step': 26314, 'preemption_count': 0}), (26656, {'train/ssim': 0.7542306355067662, 'train/loss': 0.25713210446493967, 'validation/ssim': 0.7263142376987197, 'validation/loss': 0.2851001436816351, 'validation/num_examples': 3554, 'test/ssim': 0.7435331709456158, 'test/loss': 0.28639771291844107, 'test/num_examples': 3581, 'score': 6301.547380447388, 'total_duration': 6820.160589933395, 'accumulated_submission_time': 6301.547380447388, 'accumulated_eval_time': 515.4121625423431, 'accumulated_logging_time': 2.269528865814209, 'global_step': 26656, 'preemption_count': 0}), (27001, {'train/ssim': 0.7542601994105748, 'train/loss': 0.25726778166634695, 'validation/ssim': 0.726429163772334, 'validation/loss': 0.28517127694477173, 'validation/num_examples': 3554, 'test/ssim': 0.7436299136283511, 'test/loss': 0.28646081041870286, 'test/num_examples': 3581, 'score': 6381.7876925468445, 'total_duration': 6904.431702852249, 'accumulated_submission_time': 6381.7876925468445, 'accumulated_eval_time': 519.3987793922424, 'accumulated_logging_time': 2.301710605621338, 'global_step': 27001, 'preemption_count': 0}), (27345, {'train/ssim': 0.7543474606105259, 'train/loss': 0.25676616600581575, 'validation/ssim': 0.7260194691500774, 'validation/loss': 0.28503510706466306, 'validation/num_examples': 3554, 'test/ssim': 0.7432553510498116, 'test/loss': 0.28634238755759567, 'test/num_examples': 3581, 'score': 6461.864283800125, 'total_duration': 6988.59413766861, 'accumulated_submission_time': 6461.864283800125, 'accumulated_eval_time': 523.4427843093872, 'accumulated_logging_time': 2.3316047191619873, 'global_step': 27345, 'preemption_count': 0}), (27691, {'train/ssim': 0.7541309084211077, 'train/loss': 0.25700863770076204, 'validation/ssim': 0.7260204995691475, 'validation/loss': 0.2850820254796532, 'validation/num_examples': 3554, 'test/ssim': 0.743281462711184, 'test/loss': 0.2863778394216001, 'test/num_examples': 3581, 'score': 6542.003179073334, 'total_duration': 7072.816970825195, 'accumulated_submission_time': 6542.003179073334, 'accumulated_eval_time': 527.4829468727112, 'accumulated_logging_time': 2.3632917404174805, 'global_step': 27691, 'preemption_count': 0}), (28038, {'train/ssim': 0.7536019597734723, 'train/loss': 0.257212621825082, 'validation/ssim': 0.7257375464925084, 'validation/loss': 0.28518925775754433, 'validation/num_examples': 3554, 'test/ssim': 0.7429226489414619, 'test/loss': 0.2865027390655543, 'test/num_examples': 3581, 'score': 6621.994435787201, 'total_duration': 7156.893805742264, 'accumulated_submission_time': 6621.994435787201, 'accumulated_eval_time': 531.5244166851044, 'accumulated_logging_time': 2.395188331604004, 'global_step': 28038, 'preemption_count': 0}), (28384, {'train/ssim': 0.7541613578796387, 'train/loss': 0.25679961272648405, 'validation/ssim': 0.7257597348498172, 'validation/loss': 0.2850896334071205, 'validation/num_examples': 3554, 'test/ssim': 0.7429875531232547, 'test/loss': 0.2864661281983035, 'test/num_examples': 3581, 'score': 6702.170172929764, 'total_duration': 7241.158483028412, 'accumulated_submission_time': 6702.170172929764, 'accumulated_eval_time': 535.5664856433868, 'accumulated_logging_time': 2.4301555156707764, 'global_step': 28384, 'preemption_count': 0}), (28730, {'train/ssim': 0.7544137409755162, 'train/loss': 0.25688276972089497, 'validation/ssim': 0.7262156609410172, 'validation/loss': 0.28504685384206174, 'validation/num_examples': 3554, 'test/ssim': 0.7433747965608419, 'test/loss': 0.2863912020472633, 'test/num_examples': 3581, 'score': 6782.152277231216, 'total_duration': 7325.230720281601, 'accumulated_submission_time': 6782.152277231216, 'accumulated_eval_time': 539.6133246421814, 'accumulated_logging_time': 2.461496353149414, 'global_step': 28730, 'preemption_count': 0}), (29077, {'train/ssim': 0.7544715063912528, 'train/loss': 0.2570457458496094, 'validation/ssim': 0.7264549242490855, 'validation/loss': 0.2851410513187166, 'validation/num_examples': 3554, 'test/ssim': 0.7436050291468863, 'test/loss': 0.286466060021642, 'test/num_examples': 3581, 'score': 6862.30401468277, 'total_duration': 7409.476336956024, 'accumulated_submission_time': 6862.30401468277, 'accumulated_eval_time': 543.6638793945312, 'accumulated_logging_time': 2.492823839187622, 'global_step': 29077, 'preemption_count': 0}), (29420, {'train/ssim': 0.7544336318969727, 'train/loss': 0.25658464431762695, 'validation/ssim': 0.7259691846994584, 'validation/loss': 0.2850145330305642, 'validation/num_examples': 3554, 'test/ssim': 0.7431189977267174, 'test/loss': 0.2863644767959369, 'test/num_examples': 3581, 'score': 6942.3070504665375, 'total_duration': 7493.5642166137695, 'accumulated_submission_time': 6942.3070504665375, 'accumulated_eval_time': 547.7039232254028, 'accumulated_logging_time': 2.525808572769165, 'global_step': 29420, 'preemption_count': 0}), (29767, {'train/ssim': 0.7546213694981166, 'train/loss': 0.2567110913140433, 'validation/ssim': 0.7263272209790025, 'validation/loss': 0.2850071827078644, 'validation/num_examples': 3554, 'test/ssim': 0.7435238307429838, 'test/loss': 0.2863429670592188, 'test/num_examples': 3581, 'score': 7022.33305644989, 'total_duration': 7577.673763036728, 'accumulated_submission_time': 7022.33305644989, 'accumulated_eval_time': 551.7444829940796, 'accumulated_logging_time': 2.5568244457244873, 'global_step': 29767, 'preemption_count': 0}), (30113, {'train/ssim': 0.7546024322509766, 'train/loss': 0.2568695545196533, 'validation/ssim': 0.7264716857326252, 'validation/loss': 0.28509057795793474, 'validation/num_examples': 3554, 'test/ssim': 0.7436164828260262, 'test/loss': 0.2864089279792656, 'test/num_examples': 3581, 'score': 7102.540855884552, 'total_duration': 7661.973260879517, 'accumulated_submission_time': 7102.540855884552, 'accumulated_eval_time': 555.7933006286621, 'accumulated_logging_time': 2.587928295135498, 'global_step': 30113, 'preemption_count': 0}), (30456, {'train/ssim': 0.7543889454432896, 'train/loss': 0.2566305569240025, 'validation/ssim': 0.7259818245067178, 'validation/loss': 0.28501262675528455, 'validation/num_examples': 3554, 'test/ssim': 0.7431831519652332, 'test/loss': 0.28636096569786723, 'test/num_examples': 3581, 'score': 7182.582946300507, 'total_duration': 7746.113355398178, 'accumulated_submission_time': 7182.582946300507, 'accumulated_eval_time': 559.842346906662, 'accumulated_logging_time': 2.6249148845672607, 'global_step': 30456, 'preemption_count': 0}), (30801, {'train/ssim': 0.7546736172267369, 'train/loss': 0.25655325821467806, 'validation/ssim': 0.7262378492983258, 'validation/loss': 0.2849770601237162, 'validation/num_examples': 3554, 'test/ssim': 0.7434223156939402, 'test/loss': 0.2863411944660186, 'test/num_examples': 3581, 'score': 7262.79195356369, 'total_duration': 7830.360119819641, 'accumulated_submission_time': 7262.79195356369, 'accumulated_eval_time': 563.8314032554626, 'accumulated_logging_time': 2.66121768951416, 'global_step': 30801, 'preemption_count': 0}), (31148, {'train/ssim': 0.7548414639064244, 'train/loss': 0.2566737788064139, 'validation/ssim': 0.7265923134584271, 'validation/loss': 0.2850077322647017, 'validation/num_examples': 3554, 'test/ssim': 0.743772607380969, 'test/loss': 0.2863343086232023, 'test/num_examples': 3581, 'score': 7342.801480770111, 'total_duration': 7914.464708566666, 'accumulated_submission_time': 7342.801480770111, 'accumulated_eval_time': 567.8771078586578, 'accumulated_logging_time': 2.698338508605957, 'global_step': 31148, 'preemption_count': 0}), (31490, {'train/ssim': 0.7542413302830288, 'train/loss': 0.256832412311009, 'validation/ssim': 0.7259741307109947, 'validation/loss': 0.2851721356273301, 'validation/num_examples': 3554, 'test/ssim': 0.7431318149390882, 'test/loss': 0.286525510070511, 'test/num_examples': 3581, 'score': 7422.888996124268, 'total_duration': 7998.641962766647, 'accumulated_submission_time': 7422.888996124268, 'accumulated_eval_time': 571.9233648777008, 'accumulated_logging_time': 2.7299087047576904, 'global_step': 31490, 'preemption_count': 0}), (31837, {'train/ssim': 0.7548629896981376, 'train/loss': 0.25643043858664377, 'validation/ssim': 0.7264253168744724, 'validation/loss': 0.28492979823570275, 'validation/num_examples': 3554, 'test/ssim': 0.7436150511161338, 'test/loss': 0.28627744928747206, 'test/num_examples': 3581, 'score': 7502.898470878601, 'total_duration': 8082.73925280571, 'accumulated_submission_time': 7502.898470878601, 'accumulated_eval_time': 575.9671130180359, 'accumulated_logging_time': 2.762040376663208, 'global_step': 31837, 'preemption_count': 0}), (32181, {'train/ssim': 0.7551521573747907, 'train/loss': 0.2565772703715733, 'validation/ssim': 0.7268253255574705, 'validation/loss': 0.2849779703272281, 'validation/num_examples': 3554, 'test/ssim': 0.7439609794968235, 'test/loss': 0.28631160579490716, 'test/num_examples': 3581, 'score': 7582.90892624855, 'total_duration': 8166.83486032486, 'accumulated_submission_time': 7582.90892624855, 'accumulated_eval_time': 580.0088977813721, 'accumulated_logging_time': 2.793639659881592, 'global_step': 32181, 'preemption_count': 0}), (32523, {'train/ssim': 0.754964964730399, 'train/loss': 0.2566173417227609, 'validation/ssim': 0.7266737852595667, 'validation/loss': 0.28501209437209835, 'validation/num_examples': 3554, 'test/ssim': 0.7437946284426487, 'test/loss': 0.28639761065344876, 'test/num_examples': 3581, 'score': 7663.136118888855, 'total_duration': 8251.14967083931, 'accumulated_submission_time': 7663.136118888855, 'accumulated_eval_time': 584.0519845485687, 'accumulated_logging_time': 2.8262457847595215, 'global_step': 32523, 'preemption_count': 0}), (32867, {'train/ssim': 0.7552356038774762, 'train/loss': 0.2563023567199707, 'validation/ssim': 0.726623226030529, 'validation/loss': 0.28491727864400146, 'validation/num_examples': 3554, 'test/ssim': 0.7437910150795867, 'test/loss': 0.28627475630934096, 'test/num_examples': 3581, 'score': 7743.118954181671, 'total_duration': 8335.222202539444, 'accumulated_submission_time': 7743.118954181671, 'accumulated_eval_time': 588.0979740619659, 'accumulated_logging_time': 2.8580024242401123, 'global_step': 32867, 'preemption_count': 0}), (33211, {'train/ssim': 0.7552266120910645, 'train/loss': 0.25639571462358746, 'validation/ssim': 0.726784520962296, 'validation/loss': 0.28490773009395226, 'validation/num_examples': 3554, 'test/ssim': 0.7439368449586359, 'test/loss': 0.2862539624275691, 'test/num_examples': 3581, 'score': 7823.141031265259, 'total_duration': 8419.336717128754, 'accumulated_submission_time': 7823.141031265259, 'accumulated_eval_time': 592.1455419063568, 'accumulated_logging_time': 2.890659809112549, 'global_step': 33211, 'preemption_count': 0}), (33554, {'train/ssim': 0.7550900323050362, 'train/loss': 0.2564103603363037, 'validation/ssim': 0.7266263859823439, 'validation/loss': 0.2848932183587155, 'validation/num_examples': 3554, 'test/ssim': 0.743793673969387, 'test/loss': 0.28623770229379014, 'test/num_examples': 3581, 'score': 7902.981092453003, 'total_duration': 8503.473998785019, 'accumulated_submission_time': 7902.981092453003, 'accumulated_eval_time': 596.1902956962585, 'accumulated_logging_time': 3.1312170028686523, 'global_step': 33554, 'preemption_count': 0}), (33899, {'train/ssim': 0.7554918016706195, 'train/loss': 0.2561522551945278, 'validation/ssim': 0.7268479947770118, 'validation/loss': 0.2848349138130012, 'validation/num_examples': 3554, 'test/ssim': 0.7439810916119799, 'test/loss': 0.28618285416957556, 'test/num_examples': 3581, 'score': 7983.175691604614, 'total_duration': 8587.75936126709, 'accumulated_submission_time': 7983.175691604614, 'accumulated_eval_time': 600.2369115352631, 'accumulated_logging_time': 3.1636295318603516, 'global_step': 33899, 'preemption_count': 0}), (34245, {'train/ssim': 0.7550997052873883, 'train/loss': 0.25624210493905203, 'validation/ssim': 0.7265252675242684, 'validation/loss': 0.28484891033870285, 'validation/num_examples': 3554, 'test/ssim': 0.7437081122591455, 'test/loss': 0.2861913080756074, 'test/num_examples': 3581, 'score': 8063.2761261463165, 'total_duration': 8671.951352119446, 'accumulated_submission_time': 8063.2761261463165, 'accumulated_eval_time': 604.2770035266876, 'accumulated_logging_time': 3.2029614448547363, 'global_step': 34245, 'preemption_count': 0}), (34591, {'train/ssim': 0.7553950037275042, 'train/loss': 0.2562501089913504, 'validation/ssim': 0.7269252075126618, 'validation/loss': 0.2848210890238112, 'validation/num_examples': 3554, 'test/ssim': 0.744058131239528, 'test/loss': 0.28614266402759353, 'test/num_examples': 3581, 'score': 8143.4895124435425, 'total_duration': 8756.257097244263, 'accumulated_submission_time': 8143.4895124435425, 'accumulated_eval_time': 608.3235597610474, 'accumulated_logging_time': 3.236752986907959, 'global_step': 34591, 'preemption_count': 0}), (34936, {'train/ssim': 0.7556241580418178, 'train/loss': 0.2561021532331194, 'validation/ssim': 0.7270647262547482, 'validation/loss': 0.28473819180962473, 'validation/num_examples': 3554, 'test/ssim': 0.7441798265803895, 'test/loss': 0.28608563425020944, 'test/num_examples': 3581, 'score': 8223.44726896286, 'total_duration': 8840.294992685318, 'accumulated_submission_time': 8223.44726896286, 'accumulated_eval_time': 612.3583030700684, 'accumulated_logging_time': 3.270219087600708, 'global_step': 34936, 'preemption_count': 0}), (35281, {'train/ssim': 0.755319322858538, 'train/loss': 0.2561110258102417, 'validation/ssim': 0.7267110177352982, 'validation/loss': 0.28473875854011327, 'validation/num_examples': 3554, 'test/ssim': 0.7438649185807037, 'test/loss': 0.2860812709438704, 'test/num_examples': 3581, 'score': 8303.64076423645, 'total_duration': 8924.576595306396, 'accumulated_submission_time': 8303.64076423645, 'accumulated_eval_time': 616.4016833305359, 'accumulated_logging_time': 3.3031046390533447, 'global_step': 35281, 'preemption_count': 0}), (35625, {'train/ssim': 0.755361693246024, 'train/loss': 0.25613798413957867, 'validation/ssim': 0.7268043050084412, 'validation/loss': 0.28477454842914673, 'validation/num_examples': 3554, 'test/ssim': 0.7439365722519896, 'test/loss': 0.28610237162061924, 'test/num_examples': 3581, 'score': 8383.82935500145, 'total_duration': 9008.859397649765, 'accumulated_submission_time': 8383.82935500145, 'accumulated_eval_time': 620.4445323944092, 'accumulated_logging_time': 3.3424787521362305, 'global_step': 35625, 'preemption_count': 0}), (35966, {'train/ssim': 0.7553381238664899, 'train/loss': 0.25610211917332243, 'validation/ssim': 0.7267506545221933, 'validation/loss': 0.2847349975105075, 'validation/num_examples': 3554, 'test/ssim': 0.743905824577632, 'test/loss': 0.28607237388953854, 'test/num_examples': 3581, 'score': 8463.80910038948, 'total_duration': 9092.92571401596, 'accumulated_submission_time': 8463.80910038948, 'accumulated_eval_time': 624.4805216789246, 'accumulated_logging_time': 3.3811798095703125, 'global_step': 35966, 'preemption_count': 0}), (36189, {'train/ssim': 0.755429880959647, 'train/loss': 0.25610746656145367, 'validation/ssim': 0.7268578181054798, 'validation/loss': 0.28473779681564787, 'validation/num_examples': 3554, 'test/ssim': 0.744003658086952, 'test/loss': 0.2860763281359083, 'test/num_examples': 3581, 'score': 8514.113553285599, 'total_duration': 9147.31237244606, 'accumulated_submission_time': 8514.113553285599, 'accumulated_eval_time': 628.5201015472412, 'accumulated_logging_time': 3.4160211086273193, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 13:44:27.244255 140584300062528 submission_runner.py:586] Timing: 8514.113553285599
I0204 13:44:27.244324 140584300062528 submission_runner.py:588] Total number of evals: 107
I0204 13:44:27.244365 140584300062528 submission_runner.py:589] ====================
I0204 13:44:27.244410 140584300062528 submission_runner.py:542] Using RNG seed 3907440050
I0204 13:44:27.246104 140584300062528 submission_runner.py:551] --- Tuning run 2/5 ---
I0204 13:44:27.246220 140584300062528 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2.
I0204 13:44:27.246654 140584300062528 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2/hparams.json.
I0204 13:44:27.247496 140584300062528 submission_runner.py:206] Initializing dataset.
I0204 13:44:27.551237 140584300062528 submission_runner.py:213] Initializing model.
I0204 13:44:29.558069 140584300062528 submission_runner.py:255] Initializing optimizer.
I0204 13:44:29.623810 140584300062528 submission_runner.py:262] Initializing metrics bundle.
I0204 13:44:29.623939 140584300062528 submission_runner.py:280] Initializing checkpoint and logger.
I0204 13:44:29.624558 140584300062528 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2 with prefix checkpoint_
I0204 13:44:29.624686 140584300062528 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2/meta_data_0.json.
I0204 13:44:29.624889 140584300062528 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 13:44:29.624963 140584300062528 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 13:44:33.268232 140584300062528 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 13:44:36.775672 140584300062528 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2/flags_0.json.
I0204 13:44:36.782711 140584300062528 submission_runner.py:314] Starting training loop.
I0204 13:45:06.204052 140379563415296 logging_writer.py:48] [0] global_step=0, grad_norm=4.385186672210693, loss=0.9066542387008667
I0204 13:45:06.209270 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:45:07.537034 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:45:08.865300 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:45:10.192422 140584300062528 submission_runner.py:408] Time since start: 33.41s, 	Step: 1, 	{'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 29.42645001411438, 'total_duration': 33.40965127944946, 'accumulated_submission_time': 29.42645001411438, 'accumulated_eval_time': 3.983088254928589, 'accumulated_logging_time': 0}
I0204 13:45:10.201979 140379571808000 logging_writer.py:48] [1] accumulated_eval_time=3.983088, accumulated_logging_time=0, accumulated_submission_time=29.426450, global_step=1, preemption_count=0, score=29.426450, test/loss=0.912514, test/num_examples=3581, test/ssim=0.282943, total_duration=33.409651, train/loss=0.903264, train/ssim=0.267076, validation/loss=0.915262, validation/num_examples=3554, validation/ssim=0.258797
I0204 13:45:32.020270 140379563415296 logging_writer.py:48] [100] global_step=100, grad_norm=0.4267200827598572, loss=0.2690105438232422
I0204 13:45:56.144855 140379571808000 logging_writer.py:48] [200] global_step=200, grad_norm=0.1256190985441208, loss=0.3316742777824402
I0204 13:46:20.516478 140379563415296 logging_writer.py:48] [300] global_step=300, grad_norm=0.141892209649086, loss=0.3502269685268402
I0204 13:46:30.350585 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:46:31.731976 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:46:33.063352 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:46:34.392008 140584300062528 submission_runner.py:408] Time since start: 117.61s, 	Step: 342, 	{'train/ssim': 0.700493403843471, 'train/loss': 0.3026022570473807, 'validation/ssim': 0.674353982198755, 'validation/loss': 0.33048029756304514, 'validation/num_examples': 3554, 'test/ssim': 0.6928078258080843, 'test/loss': 0.332435537602974, 'test/num_examples': 3581, 'score': 109.55331134796143, 'total_duration': 117.60923790931702, 'accumulated_submission_time': 109.55331134796143, 'accumulated_eval_time': 8.024477005004883, 'accumulated_logging_time': 0.018388986587524414}
I0204 13:46:34.406190 140379571808000 logging_writer.py:48] [342] accumulated_eval_time=8.024477, accumulated_logging_time=0.018389, accumulated_submission_time=109.553311, global_step=342, preemption_count=0, score=109.553311, test/loss=0.332436, test/num_examples=3581, test/ssim=0.692808, total_duration=117.609238, train/loss=0.302602, train/ssim=0.700493, validation/loss=0.330480, validation/num_examples=3554, validation/ssim=0.674354
I0204 13:46:46.364856 140379563415296 logging_writer.py:48] [400] global_step=400, grad_norm=0.12475129961967468, loss=0.3397989273071289
I0204 13:47:10.682559 140379571808000 logging_writer.py:48] [500] global_step=500, grad_norm=0.21623949706554413, loss=0.27751946449279785
I0204 13:47:35.074793 140379563415296 logging_writer.py:48] [600] global_step=600, grad_norm=0.15152187645435333, loss=0.27548080682754517
I0204 13:47:54.485362 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:47:55.864605 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:47:57.195576 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:47:58.527280 140584300062528 submission_runner.py:408] Time since start: 201.74s, 	Step: 681, 	{'train/ssim': 0.7177139009748187, 'train/loss': 0.28852694375174387, 'validation/ssim': 0.6936591582547833, 'validation/loss': 0.3146172364105585, 'validation/num_examples': 3554, 'test/ssim': 0.7106981999179698, 'test/loss': 0.3170286688315938, 'test/num_examples': 3581, 'score': 189.61023998260498, 'total_duration': 201.74451231956482, 'accumulated_submission_time': 189.61023998260498, 'accumulated_eval_time': 12.066364765167236, 'accumulated_logging_time': 0.04221749305725098}
I0204 13:47:58.541946 140379571808000 logging_writer.py:48] [681] accumulated_eval_time=12.066365, accumulated_logging_time=0.042217, accumulated_submission_time=189.610240, global_step=681, preemption_count=0, score=189.610240, test/loss=0.317029, test/num_examples=3581, test/ssim=0.710698, total_duration=201.744512, train/loss=0.288527, train/ssim=0.717714, validation/loss=0.314617, validation/num_examples=3554, validation/ssim=0.693659
I0204 13:48:01.092474 140379563415296 logging_writer.py:48] [700] global_step=700, grad_norm=0.2531600594520569, loss=0.27461791038513184
I0204 13:48:25.405736 140379571808000 logging_writer.py:48] [800] global_step=800, grad_norm=0.13362330198287964, loss=0.229026198387146
I0204 13:48:49.731699 140379563415296 logging_writer.py:48] [900] global_step=900, grad_norm=0.15606726706027985, loss=0.33747345209121704
I0204 13:49:14.348081 140379571808000 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.10170214623212814, loss=0.232418954372406
I0204 13:49:18.701966 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:49:20.083002 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:49:21.411260 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:49:22.739689 140584300062528 submission_runner.py:408] Time since start: 285.96s, 	Step: 1020, 	{'train/ssim': 0.7317164966038295, 'train/loss': 0.2770050082887922, 'validation/ssim': 0.7062299274365152, 'validation/loss': 0.3035240881752954, 'validation/num_examples': 3554, 'test/ssim': 0.7232667720041539, 'test/loss': 0.30580181344465585, 'test/num_examples': 3581, 'score': 269.74872303009033, 'total_duration': 285.9569094181061, 'accumulated_submission_time': 269.74872303009033, 'accumulated_eval_time': 16.104042291641235, 'accumulated_logging_time': 0.06609296798706055}
I0204 13:49:22.753730 140379563415296 logging_writer.py:48] [1020] accumulated_eval_time=16.104042, accumulated_logging_time=0.066093, accumulated_submission_time=269.748723, global_step=1020, preemption_count=0, score=269.748723, test/loss=0.305802, test/num_examples=3581, test/ssim=0.723267, total_duration=285.956909, train/loss=0.277005, train/ssim=0.731716, validation/loss=0.303524, validation/num_examples=3554, validation/ssim=0.706230
I0204 13:49:39.965167 140379571808000 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.44829970598220825, loss=0.36047276854515076
I0204 13:50:03.975062 140379563415296 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.17211344838142395, loss=0.22778618335723877
I0204 13:50:27.713996 140379571808000 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.34357839822769165, loss=0.3175037205219269
I0204 13:50:42.786974 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:50:44.170398 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:50:45.500314 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:50:46.831632 140584300062528 submission_runner.py:408] Time since start: 370.05s, 	Step: 1365, 	{'train/ssim': 0.7347615105765206, 'train/loss': 0.273283737046378, 'validation/ssim': 0.709127740639948, 'validation/loss': 0.2994085944094682, 'validation/num_examples': 3554, 'test/ssim': 0.7263307675274016, 'test/loss': 0.3015255005257784, 'test/num_examples': 3581, 'score': 349.75937604904175, 'total_duration': 370.048823595047, 'accumulated_submission_time': 349.75937604904175, 'accumulated_eval_time': 20.1486337184906, 'accumulated_logging_time': 0.08972287178039551}
I0204 13:50:46.849514 140379563415296 logging_writer.py:48] [1365] accumulated_eval_time=20.148634, accumulated_logging_time=0.089723, accumulated_submission_time=349.759376, global_step=1365, preemption_count=0, score=349.759376, test/loss=0.301526, test/num_examples=3581, test/ssim=0.726331, total_duration=370.048824, train/loss=0.273284, train/ssim=0.734762, validation/loss=0.299409, validation/num_examples=3554, validation/ssim=0.709128
I0204 13:50:53.133811 140379571808000 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.47753602266311646, loss=0.30047231912612915
I0204 13:51:17.172126 140379563415296 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.44040805101394653, loss=0.40553009510040283
I0204 13:51:41.026456 140379571808000 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.37284696102142334, loss=0.2334344983100891
I0204 13:52:05.000554 140379563415296 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1430777907371521, loss=0.3313249349594116
I0204 13:52:06.932546 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:52:08.309691 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:52:09.643646 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:52:10.972976 140584300062528 submission_runner.py:408] Time since start: 454.19s, 	Step: 1709, 	{'train/ssim': 0.7332886287144252, 'train/loss': 0.2724383217947824, 'validation/ssim': 0.7087479968653277, 'validation/loss': 0.2982055114505663, 'validation/num_examples': 3554, 'test/ssim': 0.7256882024923206, 'test/loss': 0.3000804961842886, 'test/num_examples': 3581, 'score': 429.81904101371765, 'total_duration': 454.1902050971985, 'accumulated_submission_time': 429.81904101371765, 'accumulated_eval_time': 24.189027786254883, 'accumulated_logging_time': 0.11821460723876953}
I0204 13:52:10.989583 140379571808000 logging_writer.py:48] [1709] accumulated_eval_time=24.189028, accumulated_logging_time=0.118215, accumulated_submission_time=429.819041, global_step=1709, preemption_count=0, score=429.819041, test/loss=0.300080, test/num_examples=3581, test/ssim=0.725688, total_duration=454.190205, train/loss=0.272438, train/ssim=0.733289, validation/loss=0.298206, validation/num_examples=3554, validation/ssim=0.708748
I0204 13:52:30.409340 140379563415296 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.2682027220726013, loss=0.267500102519989
I0204 13:52:54.264519 140379571808000 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.09804657846689224, loss=0.26044410467147827
I0204 13:53:18.299962 140379563415296 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.12076444178819656, loss=0.24474087357521057
I0204 13:53:31.004479 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:53:32.385750 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:53:33.713246 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:53:35.042573 140584300062528 submission_runner.py:408] Time since start: 538.26s, 	Step: 2053, 	{'train/ssim': 0.7409915242876325, 'train/loss': 0.26877427101135254, 'validation/ssim': 0.7151846126283765, 'validation/loss': 0.2948922676253869, 'validation/num_examples': 3554, 'test/ssim': 0.7322903622198758, 'test/loss': 0.2967952673943207, 'test/num_examples': 3581, 'score': 509.81245160102844, 'total_duration': 538.2597918510437, 'accumulated_submission_time': 509.81245160102844, 'accumulated_eval_time': 28.227068662643433, 'accumulated_logging_time': 0.14400959014892578}
I0204 13:53:35.058693 140379571808000 logging_writer.py:48] [2053] accumulated_eval_time=28.227069, accumulated_logging_time=0.144010, accumulated_submission_time=509.812452, global_step=2053, preemption_count=0, score=509.812452, test/loss=0.296795, test/num_examples=3581, test/ssim=0.732290, total_duration=538.259792, train/loss=0.268774, train/ssim=0.740992, validation/loss=0.294892, validation/num_examples=3554, validation/ssim=0.715185
I0204 13:53:44.133162 140379563415296 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.09084055572748184, loss=0.3314131498336792
I0204 13:54:08.420539 140379571808000 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.0983176901936531, loss=0.2541640102863312
I0204 13:54:32.444476 140379563415296 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.060459017753601074, loss=0.2494664490222931
I0204 13:54:55.139895 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:54:56.520333 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:54:57.850245 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:54:59.182259 140584300062528 submission_runner.py:408] Time since start: 622.40s, 	Step: 2396, 	{'train/ssim': 0.7421709469386509, 'train/loss': 0.26690559727805, 'validation/ssim': 0.7165991719277575, 'validation/loss': 0.2932297551504467, 'validation/num_examples': 3554, 'test/ssim': 0.7335974451750559, 'test/loss': 0.2949343172407323, 'test/num_examples': 3581, 'score': 589.8710687160492, 'total_duration': 622.399489402771, 'accumulated_submission_time': 589.8710687160492, 'accumulated_eval_time': 32.26940202713013, 'accumulated_logging_time': 0.1705169677734375}
I0204 13:54:59.196824 140379571808000 logging_writer.py:48] [2396] accumulated_eval_time=32.269402, accumulated_logging_time=0.170517, accumulated_submission_time=589.871069, global_step=2396, preemption_count=0, score=589.871069, test/loss=0.294934, test/num_examples=3581, test/ssim=0.733597, total_duration=622.399489, train/loss=0.266906, train/ssim=0.742171, validation/loss=0.293230, validation/num_examples=3554, validation/ssim=0.716599
I0204 13:54:59.581137 140379563415296 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.10424129664897919, loss=0.3549502193927765
I0204 13:55:22.031854 140379571808000 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.1681649088859558, loss=0.2737429141998291
I0204 13:55:45.878099 140379563415296 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1468246728181839, loss=0.2788068950176239
I0204 13:56:10.164983 140379571808000 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.07608003914356232, loss=0.26123884320259094
I0204 13:56:19.365792 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:56:20.745152 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:56:22.077742 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:56:23.410663 140584300062528 submission_runner.py:408] Time since start: 706.63s, 	Step: 2739, 	{'train/ssim': 0.7418599809919085, 'train/loss': 0.26654790128980366, 'validation/ssim': 0.7161163862461312, 'validation/loss': 0.2926901246834553, 'validation/num_examples': 3554, 'test/ssim': 0.7333299199551452, 'test/loss': 0.2943898243332868, 'test/num_examples': 3581, 'score': 670.0183191299438, 'total_duration': 706.627876996994, 'accumulated_submission_time': 670.0183191299438, 'accumulated_eval_time': 36.31421685218811, 'accumulated_logging_time': 0.194258451461792}
I0204 13:56:23.425970 140379563415296 logging_writer.py:48] [2739] accumulated_eval_time=36.314217, accumulated_logging_time=0.194258, accumulated_submission_time=670.018319, global_step=2739, preemption_count=0, score=670.018319, test/loss=0.294390, test/num_examples=3581, test/ssim=0.733330, total_duration=706.627877, train/loss=0.266548, train/ssim=0.741860, validation/loss=0.292690, validation/num_examples=3554, validation/ssim=0.716116
I0204 13:56:36.024693 140379571808000 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.09569043666124344, loss=0.3143744468688965
I0204 13:56:59.870450 140379563415296 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.1035056859254837, loss=0.2361690104007721
I0204 13:57:23.673858 140379571808000 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.07655917853116989, loss=0.26726990938186646
I0204 13:57:43.451789 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:57:44.831721 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:57:46.163430 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:57:47.493650 140584300062528 submission_runner.py:408] Time since start: 790.71s, 	Step: 3083, 	{'train/ssim': 0.7423411096845355, 'train/loss': 0.26642050061907085, 'validation/ssim': 0.7173274034318725, 'validation/loss': 0.29222087183894907, 'validation/num_examples': 3554, 'test/ssim': 0.7344748106325049, 'test/loss': 0.29378121127565626, 'test/num_examples': 3581, 'score': 750.0226106643677, 'total_duration': 790.7108700275421, 'accumulated_submission_time': 750.0226106643677, 'accumulated_eval_time': 40.35602593421936, 'accumulated_logging_time': 0.2186872959136963}
I0204 13:57:47.509375 140379563415296 logging_writer.py:48] [3083] accumulated_eval_time=40.356026, accumulated_logging_time=0.218687, accumulated_submission_time=750.022611, global_step=3083, preemption_count=0, score=750.022611, test/loss=0.293781, test/num_examples=3581, test/ssim=0.734475, total_duration=790.710870, train/loss=0.266421, train/ssim=0.742341, validation/loss=0.292221, validation/num_examples=3554, validation/ssim=0.717327
I0204 13:57:49.442894 140379571808000 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.3175320029258728, loss=0.26104477047920227
I0204 13:58:13.644623 140379563415296 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.246840700507164, loss=0.37439239025115967
I0204 13:58:37.725513 140379571808000 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.07888398319482803, loss=0.3061716556549072
I0204 13:59:02.046728 140379563415296 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.13401542603969574, loss=0.28603214025497437
I0204 13:59:07.719833 140584300062528 spec.py:321] Evaluating on the training split.
I0204 13:59:09.097224 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 13:59:10.427724 140584300062528 spec.py:349] Evaluating on the test split.
I0204 13:59:11.756278 140584300062528 submission_runner.py:408] Time since start: 874.97s, 	Step: 3425, 	{'train/ssim': 0.7441543170383998, 'train/loss': 0.26480283055986675, 'validation/ssim': 0.7175930454681345, 'validation/loss': 0.2914524883384039, 'validation/num_examples': 3554, 'test/ssim': 0.7348356015254119, 'test/loss': 0.29307531012199806, 'test/num_examples': 3581, 'score': 830.2108571529388, 'total_duration': 874.9735074043274, 'accumulated_submission_time': 830.2108571529388, 'accumulated_eval_time': 44.39246344566345, 'accumulated_logging_time': 0.24354028701782227}
I0204 13:59:11.771288 140379571808000 logging_writer.py:48] [3425] accumulated_eval_time=44.392463, accumulated_logging_time=0.243540, accumulated_submission_time=830.210857, global_step=3425, preemption_count=0, score=830.210857, test/loss=0.293075, test/num_examples=3581, test/ssim=0.734836, total_duration=874.973507, train/loss=0.264803, train/ssim=0.744154, validation/loss=0.291452, validation/num_examples=3554, validation/ssim=0.717593
I0204 13:59:27.447732 140379563415296 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.0658915787935257, loss=0.26100754737854004
I0204 13:59:51.560898 140379571808000 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.13384626805782318, loss=0.29226672649383545
I0204 14:00:15.563505 140379563415296 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.3700524568557739, loss=0.28552037477493286
I0204 14:00:31.831711 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:00:33.209534 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:00:34.539676 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:00:35.871242 140584300062528 submission_runner.py:408] Time since start: 959.09s, 	Step: 3770, 	{'train/ssim': 0.7439109938485282, 'train/loss': 0.2662832736968994, 'validation/ssim': 0.7177881381453995, 'validation/loss': 0.2921615883951182, 'validation/num_examples': 3554, 'test/ssim': 0.7350305867774365, 'test/loss': 0.2938836467096307, 'test/num_examples': 3581, 'score': 910.250020980835, 'total_duration': 959.0884766578674, 'accumulated_submission_time': 910.250020980835, 'accumulated_eval_time': 48.43196511268616, 'accumulated_logging_time': 0.2675139904022217}
I0204 14:00:35.886962 140379571808000 logging_writer.py:48] [3770] accumulated_eval_time=48.431965, accumulated_logging_time=0.267514, accumulated_submission_time=910.250021, global_step=3770, preemption_count=0, score=910.250021, test/loss=0.293884, test/num_examples=3581, test/ssim=0.735031, total_duration=959.088477, train/loss=0.266283, train/ssim=0.743911, validation/loss=0.292162, validation/num_examples=3554, validation/ssim=0.717788
I0204 14:00:41.104318 140379563415296 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.08493080735206604, loss=0.27160507440567017
I0204 14:01:05.445104 140379571808000 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.1505993753671646, loss=0.2670181393623352
I0204 14:01:29.572597 140379563415296 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.30463698506355286, loss=0.2984433174133301
I0204 14:01:53.428210 140379571808000 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.08640483766794205, loss=0.26895081996917725
I0204 14:01:55.976097 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:01:57.356721 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:01:58.687476 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:02:00.015528 140584300062528 submission_runner.py:408] Time since start: 1043.23s, 	Step: 4112, 	{'train/ssim': 0.7449028151375907, 'train/loss': 0.2645629644393921, 'validation/ssim': 0.7190284192327308, 'validation/loss': 0.2907478877782956, 'validation/num_examples': 3554, 'test/ssim': 0.7360385105417481, 'test/loss': 0.29238474871718795, 'test/num_examples': 3581, 'score': 990.3172655105591, 'total_duration': 1043.2327580451965, 'accumulated_submission_time': 990.3172655105591, 'accumulated_eval_time': 52.47136425971985, 'accumulated_logging_time': 0.29250311851501465}
I0204 14:02:00.031477 140379563415296 logging_writer.py:48] [4112] accumulated_eval_time=52.471364, accumulated_logging_time=0.292503, accumulated_submission_time=990.317266, global_step=4112, preemption_count=0, score=990.317266, test/loss=0.292385, test/num_examples=3581, test/ssim=0.736039, total_duration=1043.232758, train/loss=0.264563, train/ssim=0.744903, validation/loss=0.290748, validation/num_examples=3554, validation/ssim=0.719028
I0204 14:02:19.703240 140379571808000 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.19368484616279602, loss=0.24502500891685486
I0204 14:02:43.242311 140379563415296 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.16803772747516632, loss=0.2877187728881836
I0204 14:03:07.306340 140379571808000 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.06938735395669937, loss=0.2941994071006775
I0204 14:03:20.175494 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:03:21.555508 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:03:22.884698 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:03:24.215938 140584300062528 submission_runner.py:408] Time since start: 1127.43s, 	Step: 4455, 	{'train/ssim': 0.745528153010777, 'train/loss': 0.26326089245932444, 'validation/ssim': 0.7188410203511888, 'validation/loss': 0.2899452256700197, 'validation/num_examples': 3554, 'test/ssim': 0.7361167773492041, 'test/loss': 0.2916109095202981, 'test/num_examples': 3581, 'score': 1070.4398555755615, 'total_duration': 1127.4331729412079, 'accumulated_submission_time': 1070.4398555755615, 'accumulated_eval_time': 56.51176953315735, 'accumulated_logging_time': 0.3179206848144531}
I0204 14:03:24.231227 140379563415296 logging_writer.py:48] [4455] accumulated_eval_time=56.511770, accumulated_logging_time=0.317921, accumulated_submission_time=1070.439856, global_step=4455, preemption_count=0, score=1070.439856, test/loss=0.291611, test/num_examples=3581, test/ssim=0.736117, total_duration=1127.433173, train/loss=0.263261, train/ssim=0.745528, validation/loss=0.289945, validation/num_examples=3554, validation/ssim=0.718841
I0204 14:03:33.058189 140379571808000 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.07240993529558182, loss=0.20194461941719055
I0204 14:03:56.810663 140379563415296 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1415153592824936, loss=0.20685046911239624
I0204 14:04:20.619938 140379571808000 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.15375392138957977, loss=0.22029787302017212
I0204 14:04:44.331980 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:04:45.715096 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:04:47.046065 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:04:48.375144 140584300062528 submission_runner.py:408] Time since start: 1211.59s, 	Step: 4800, 	{'train/ssim': 0.7455744062151227, 'train/loss': 0.2641662529536656, 'validation/ssim': 0.7195378584209693, 'validation/loss': 0.2902841648494654, 'validation/num_examples': 3554, 'test/ssim': 0.7369595772392488, 'test/loss': 0.29179021414016687, 'test/num_examples': 3581, 'score': 1150.5182836055756, 'total_duration': 1211.5923788547516, 'accumulated_submission_time': 1150.5182836055756, 'accumulated_eval_time': 60.554898500442505, 'accumulated_logging_time': 0.3427619934082031}
I0204 14:04:48.390958 140379563415296 logging_writer.py:48] [4800] accumulated_eval_time=60.554899, accumulated_logging_time=0.342762, accumulated_submission_time=1150.518284, global_step=4800, preemption_count=0, score=1150.518284, test/loss=0.291790, test/num_examples=3581, test/ssim=0.736960, total_duration=1211.592379, train/loss=0.264166, train/ssim=0.745574, validation/loss=0.290284, validation/num_examples=3554, validation/ssim=0.719538
I0204 14:04:48.481575 140379571808000 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.23907174170017242, loss=0.31470733880996704
I0204 14:05:10.216838 140379563415296 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.0504237562417984, loss=0.2890279293060303
I0204 14:05:34.348441 140379571808000 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.23855160176753998, loss=0.36911433935165405
I0204 14:05:57.985803 140379563415296 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.0803169533610344, loss=0.32920023798942566
I0204 14:06:08.604141 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:06:09.982963 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:06:11.314263 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:06:12.645909 140584300062528 submission_runner.py:408] Time since start: 1295.86s, 	Step: 5145, 	{'train/ssim': 0.7470813478742327, 'train/loss': 0.2624162094933646, 'validation/ssim': 0.7207821237953714, 'validation/loss': 0.288812829459324, 'validation/num_examples': 3554, 'test/ssim': 0.7380477449342013, 'test/loss': 0.2903629016423485, 'test/num_examples': 3581, 'score': 1230.709332704544, 'total_duration': 1295.8631434440613, 'accumulated_submission_time': 1230.709332704544, 'accumulated_eval_time': 64.59666466712952, 'accumulated_logging_time': 0.3678746223449707}
I0204 14:06:12.664788 140379571808000 logging_writer.py:48] [5145] accumulated_eval_time=64.596665, accumulated_logging_time=0.367875, accumulated_submission_time=1230.709333, global_step=5145, preemption_count=0, score=1230.709333, test/loss=0.290363, test/num_examples=3581, test/ssim=0.738048, total_duration=1295.863143, train/loss=0.262416, train/ssim=0.747081, validation/loss=0.288813, validation/num_examples=3554, validation/ssim=0.720782
I0204 14:06:23.815715 140379563415296 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.10497944802045822, loss=0.23799940943717957
I0204 14:06:48.349607 140379571808000 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.18251022696495056, loss=0.22133617103099823
I0204 14:07:12.316369 140379563415296 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.0916316881775856, loss=0.3427869975566864
I0204 14:07:32.835793 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:07:34.215842 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:07:35.547964 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:07:36.878335 140584300062528 submission_runner.py:408] Time since start: 1380.10s, 	Step: 5487, 	{'train/ssim': 0.7463224955967495, 'train/loss': 0.2628247056688581, 'validation/ssim': 0.7197903797877392, 'validation/loss': 0.2894811249208638, 'validation/num_examples': 3554, 'test/ssim': 0.737104043585067, 'test/loss': 0.29098160484588803, 'test/num_examples': 3581, 'score': 1310.8590772151947, 'total_duration': 1380.0955708026886, 'accumulated_submission_time': 1310.8590772151947, 'accumulated_eval_time': 68.63917136192322, 'accumulated_logging_time': 0.39591407775878906}
I0204 14:07:36.894019 140379571808000 logging_writer.py:48] [5487] accumulated_eval_time=68.639171, accumulated_logging_time=0.395914, accumulated_submission_time=1310.859077, global_step=5487, preemption_count=0, score=1310.859077, test/loss=0.290982, test/num_examples=3581, test/ssim=0.737104, total_duration=1380.095571, train/loss=0.262825, train/ssim=0.746322, validation/loss=0.289481, validation/num_examples=3554, validation/ssim=0.719790
I0204 14:07:37.937767 140379563415296 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.13105298578739166, loss=0.28052955865859985
I0204 14:08:01.875147 140379571808000 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.036234404891729355, loss=0.2557055354118347
I0204 14:08:25.686991 140379563415296 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.10873246937990189, loss=0.2960818111896515
I0204 14:08:49.519618 140379571808000 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.08718820661306381, loss=0.2939615249633789
I0204 14:08:56.880861 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:08:58.260054 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:08:59.591861 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:09:00.924046 140584300062528 submission_runner.py:408] Time since start: 1464.14s, 	Step: 5832, 	{'train/ssim': 0.746668951851981, 'train/loss': 0.2629751477922712, 'validation/ssim': 0.7207214664594471, 'validation/loss': 0.2891875585278032, 'validation/num_examples': 3554, 'test/ssim': 0.7379295266030788, 'test/loss': 0.2907189883456088, 'test/num_examples': 3581, 'score': 1390.823716878891, 'total_duration': 1464.1412785053253, 'accumulated_submission_time': 1390.823716878891, 'accumulated_eval_time': 72.6823296546936, 'accumulated_logging_time': 0.42113780975341797}
I0204 14:09:00.939972 140379563415296 logging_writer.py:48] [5832] accumulated_eval_time=72.682330, accumulated_logging_time=0.421138, accumulated_submission_time=1390.823717, global_step=5832, preemption_count=0, score=1390.823717, test/loss=0.290719, test/num_examples=3581, test/ssim=0.737930, total_duration=1464.141279, train/loss=0.262975, train/ssim=0.746669, validation/loss=0.289188, validation/num_examples=3554, validation/ssim=0.720721
I0204 14:09:14.990182 140379571808000 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.19880421459674835, loss=0.3010190725326538
I0204 14:09:38.915173 140379563415296 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.10113830119371414, loss=0.2113661766052246
I0204 14:10:03.103720 140379571808000 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.11642525345087051, loss=0.322027325630188
I0204 14:10:21.098733 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:10:22.484486 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:10:23.815745 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:10:25.144411 140584300062528 submission_runner.py:408] Time since start: 1548.36s, 	Step: 6176, 	{'train/ssim': 0.7470532144818988, 'train/loss': 0.2630742447716849, 'validation/ssim': 0.7212173728105655, 'validation/loss': 0.28917158703221724, 'validation/num_examples': 3554, 'test/ssim': 0.7384506690039444, 'test/loss': 0.290686297636397, 'test/num_examples': 3581, 'score': 1470.9608535766602, 'total_duration': 1548.361647605896, 'accumulated_submission_time': 1470.9608535766602, 'accumulated_eval_time': 76.7279725074768, 'accumulated_logging_time': 0.4464681148529053}
I0204 14:10:25.160449 140379563415296 logging_writer.py:48] [6176] accumulated_eval_time=76.727973, accumulated_logging_time=0.446468, accumulated_submission_time=1470.960854, global_step=6176, preemption_count=0, score=1470.960854, test/loss=0.290686, test/num_examples=3581, test/ssim=0.738451, total_duration=1548.361648, train/loss=0.263074, train/ssim=0.747053, validation/loss=0.289172, validation/num_examples=3554, validation/ssim=0.721217
I0204 14:10:28.907745 140379571808000 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.10742293298244476, loss=0.29438653588294983
I0204 14:10:52.982604 140379563415296 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.2086401730775833, loss=0.23873037099838257
I0204 14:11:17.354585 140379571808000 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.10908719152212143, loss=0.23276373744010925
I0204 14:11:41.520380 140379563415296 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.11626022309064865, loss=0.25663673877716064
I0204 14:11:45.328278 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:11:46.707846 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:11:48.039049 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:11:49.368885 140584300062528 submission_runner.py:408] Time since start: 1632.59s, 	Step: 6517, 	{'train/ssim': 0.7485293660845075, 'train/loss': 0.26226443903786795, 'validation/ssim': 0.7220091468240011, 'validation/loss': 0.2888351208585397, 'validation/num_examples': 3554, 'test/ssim': 0.739124458950014, 'test/loss': 0.2903405056090303, 'test/num_examples': 3581, 'score': 1551.1067745685577, 'total_duration': 1632.5861072540283, 'accumulated_submission_time': 1551.1067745685577, 'accumulated_eval_time': 80.76854872703552, 'accumulated_logging_time': 0.47170019149780273}
I0204 14:11:49.384794 140379571808000 logging_writer.py:48] [6517] accumulated_eval_time=80.768549, accumulated_logging_time=0.471700, accumulated_submission_time=1551.106775, global_step=6517, preemption_count=0, score=1551.106775, test/loss=0.290341, test/num_examples=3581, test/ssim=0.739124, total_duration=1632.586107, train/loss=0.262264, train/ssim=0.748529, validation/loss=0.288835, validation/num_examples=3554, validation/ssim=0.722009
I0204 14:12:07.022139 140379563415296 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.13942082226276398, loss=0.3016948401927948
I0204 14:12:30.985488 140379571808000 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.04453692585229874, loss=0.28890758752822876
I0204 14:12:54.744932 140379563415296 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.10118045657873154, loss=0.30786973237991333
I0204 14:13:09.433880 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:13:10.811815 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:13:12.139672 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:13:13.468264 140584300062528 submission_runner.py:408] Time since start: 1716.69s, 	Step: 6862, 	{'train/ssim': 0.7489062036786761, 'train/loss': 0.26138101305280415, 'validation/ssim': 0.7224099798422552, 'validation/loss': 0.28804355292891815, 'validation/num_examples': 3554, 'test/ssim': 0.7395610622905613, 'test/loss': 0.2895691207719562, 'test/num_examples': 3581, 'score': 1631.1339271068573, 'total_duration': 1716.6855008602142, 'accumulated_submission_time': 1631.1339271068573, 'accumulated_eval_time': 84.80290365219116, 'accumulated_logging_time': 0.4968986511230469}
I0204 14:13:13.484219 140379571808000 logging_writer.py:48] [6862] accumulated_eval_time=84.802904, accumulated_logging_time=0.496899, accumulated_submission_time=1631.133927, global_step=6862, preemption_count=0, score=1631.133927, test/loss=0.289569, test/num_examples=3581, test/ssim=0.739561, total_duration=1716.685501, train/loss=0.261381, train/ssim=0.748906, validation/loss=0.288044, validation/num_examples=3554, validation/ssim=0.722410
I0204 14:13:20.377711 140379563415296 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.03252964839339256, loss=0.35139358043670654
I0204 14:13:44.285519 140379571808000 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.22056829929351807, loss=0.2441921830177307
I0204 14:14:08.416695 140379563415296 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.08523809909820557, loss=0.2461320161819458
I0204 14:14:32.418776 140379571808000 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.11636317521333694, loss=0.2752963602542877
I0204 14:14:33.490811 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:14:34.874572 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:14:36.203787 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:14:37.534309 140584300062528 submission_runner.py:408] Time since start: 1800.75s, 	Step: 7206, 	{'train/ssim': 0.7486821583339146, 'train/loss': 0.26164140020098003, 'validation/ssim': 0.7226811174468908, 'validation/loss': 0.2881173137606834, 'validation/num_examples': 3554, 'test/ssim': 0.7398471315624128, 'test/loss': 0.289598198118106, 'test/num_examples': 3581, 'score': 1711.1187720298767, 'total_duration': 1800.7515134811401, 'accumulated_submission_time': 1711.1187720298767, 'accumulated_eval_time': 88.84633111953735, 'accumulated_logging_time': 0.5218157768249512}
I0204 14:14:37.553598 140379563415296 logging_writer.py:48] [7206] accumulated_eval_time=88.846331, accumulated_logging_time=0.521816, accumulated_submission_time=1711.118772, global_step=7206, preemption_count=0, score=1711.118772, test/loss=0.289598, test/num_examples=3581, test/ssim=0.739847, total_duration=1800.751513, train/loss=0.261641, train/ssim=0.748682, validation/loss=0.288117, validation/num_examples=3554, validation/ssim=0.722681
I0204 14:14:57.893740 140379571808000 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.11946406960487366, loss=0.27699828147888184
I0204 14:15:21.676517 140379563415296 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.19457991421222687, loss=0.26036375761032104
I0204 14:15:46.164058 140379571808000 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.0673603042960167, loss=0.20437291264533997
I0204 14:15:57.637044 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:15:59.015490 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:16:00.346086 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:16:01.680430 140584300062528 submission_runner.py:408] Time since start: 1884.90s, 	Step: 7549, 	{'train/ssim': 0.750164372580392, 'train/loss': 0.26114661352975027, 'validation/ssim': 0.7235968165271525, 'validation/loss': 0.28792357780186056, 'validation/num_examples': 3554, 'test/ssim': 0.7407856514852694, 'test/loss': 0.289402974247766, 'test/num_examples': 3581, 'score': 1791.1784365177155, 'total_duration': 1884.8976328372955, 'accumulated_submission_time': 1791.1784365177155, 'accumulated_eval_time': 92.88967680931091, 'accumulated_logging_time': 0.5519485473632812}
I0204 14:16:01.701089 140379563415296 logging_writer.py:48] [7549] accumulated_eval_time=92.889677, accumulated_logging_time=0.551949, accumulated_submission_time=1791.178437, global_step=7549, preemption_count=0, score=1791.178437, test/loss=0.289403, test/num_examples=3581, test/ssim=0.740786, total_duration=1884.897633, train/loss=0.261147, train/ssim=0.750164, validation/loss=0.287924, validation/num_examples=3554, validation/ssim=0.723597
I0204 14:16:12.025219 140379571808000 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.08609896153211594, loss=0.26300540566444397
I0204 14:16:35.807800 140379563415296 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.3714589476585388, loss=0.26786014437675476
I0204 14:16:59.829792 140379571808000 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.05577600747346878, loss=0.28004640340805054
I0204 14:17:21.751116 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:17:23.132038 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:17:24.461941 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:17:25.790248 140584300062528 submission_runner.py:408] Time since start: 1969.01s, 	Step: 7892, 	{'train/ssim': 0.748753547668457, 'train/loss': 0.26151558331080843, 'validation/ssim': 0.7221031210431907, 'validation/loss': 0.2880484130721986, 'validation/num_examples': 3554, 'test/ssim': 0.7394183003612818, 'test/loss': 0.2894897290495846, 'test/num_examples': 3581, 'score': 1871.2054042816162, 'total_duration': 1969.0074808597565, 'accumulated_submission_time': 1871.2054042816162, 'accumulated_eval_time': 96.92876887321472, 'accumulated_logging_time': 0.5830910205841064}
I0204 14:17:25.807446 140379563415296 logging_writer.py:48] [7892] accumulated_eval_time=96.928769, accumulated_logging_time=0.583091, accumulated_submission_time=1871.205404, global_step=7892, preemption_count=0, score=1871.205404, test/loss=0.289490, test/num_examples=3581, test/ssim=0.739418, total_duration=1969.007481, train/loss=0.261516, train/ssim=0.748754, validation/loss=0.288048, validation/num_examples=3554, validation/ssim=0.722103
I0204 14:17:26.480480 140379571808000 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.3748163878917694, loss=0.2689443528652191
I0204 14:17:49.503353 140379563415296 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.07799696922302246, loss=0.299560010433197
I0204 14:18:13.451465 140379571808000 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.23378001153469086, loss=0.2203567624092102
I0204 14:18:37.267324 140379563415296 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.028602659702301025, loss=0.27461645007133484
I0204 14:18:45.861544 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:18:47.242205 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:18:48.573989 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:18:49.905844 140584300062528 submission_runner.py:408] Time since start: 2053.12s, 	Step: 8237, 	{'train/ssim': 0.7499610355922154, 'train/loss': 0.26050329208374023, 'validation/ssim': 0.7234105167592854, 'validation/loss': 0.28720492919509705, 'validation/num_examples': 3554, 'test/ssim': 0.740555282545902, 'test/loss': 0.288724582377042, 'test/num_examples': 3581, 'score': 1951.2375724315643, 'total_duration': 2053.123046398163, 'accumulated_submission_time': 1951.2375724315643, 'accumulated_eval_time': 100.9730007648468, 'accumulated_logging_time': 0.609849214553833}
I0204 14:18:49.922574 140379571808000 logging_writer.py:48] [8237] accumulated_eval_time=100.973001, accumulated_logging_time=0.609849, accumulated_submission_time=1951.237572, global_step=8237, preemption_count=0, score=1951.237572, test/loss=0.288725, test/num_examples=3581, test/ssim=0.740555, total_duration=2053.123046, train/loss=0.260503, train/ssim=0.749961, validation/loss=0.287205, validation/num_examples=3554, validation/ssim=0.723411
I0204 14:19:02.917611 140379563415296 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.12162625789642334, loss=0.2485450953245163
I0204 14:19:26.966978 140379571808000 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.059292640537023544, loss=0.26824602484703064
I0204 14:19:51.463603 140379563415296 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.137819305062294, loss=0.35173001885414124
I0204 14:20:10.087377 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:20:11.472779 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:20:12.801558 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:20:14.131870 140584300062528 submission_runner.py:408] Time since start: 2137.35s, 	Step: 8578, 	{'train/ssim': 0.7500072887965611, 'train/loss': 0.26074894836970736, 'validation/ssim': 0.7232730588553391, 'validation/loss': 0.2874911624391091, 'validation/num_examples': 3554, 'test/ssim': 0.7405435561601159, 'test/loss': 0.28888728597982405, 'test/num_examples': 3581, 'score': 2031.3805038928986, 'total_duration': 2137.3491065502167, 'accumulated_submission_time': 2031.3805038928986, 'accumulated_eval_time': 105.01745820045471, 'accumulated_logging_time': 0.6357917785644531}
I0204 14:20:14.148827 140379571808000 logging_writer.py:48] [8578] accumulated_eval_time=105.017458, accumulated_logging_time=0.635792, accumulated_submission_time=2031.380504, global_step=8578, preemption_count=0, score=2031.380504, test/loss=0.288887, test/num_examples=3581, test/ssim=0.740544, total_duration=2137.349107, train/loss=0.260749, train/ssim=0.750007, validation/loss=0.287491, validation/num_examples=3554, validation/ssim=0.723273
I0204 14:20:17.327101 140379563415296 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.06925543397665024, loss=0.3438970446586609
I0204 14:20:41.492395 140379571808000 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.3985844552516937, loss=0.2075113207101822
I0204 14:21:05.436550 140379563415296 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.059651438146829605, loss=0.20334047079086304
I0204 14:21:28.913718 140379571808000 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.06179647147655487, loss=0.23277322947978973
I0204 14:21:34.255817 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:21:35.638058 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:21:36.966511 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:21:38.295933 140584300062528 submission_runner.py:408] Time since start: 2221.51s, 	Step: 8924, 	{'train/ssim': 0.7499869891575405, 'train/loss': 0.26059075764247347, 'validation/ssim': 0.7225968978615644, 'validation/loss': 0.2881504417337859, 'validation/num_examples': 3554, 'test/ssim': 0.7398159748280857, 'test/loss': 0.2895903237136973, 'test/num_examples': 3581, 'score': 2111.464605331421, 'total_duration': 2221.5131690502167, 'accumulated_submission_time': 2111.464605331421, 'accumulated_eval_time': 109.05753564834595, 'accumulated_logging_time': 0.6633491516113281}
I0204 14:21:38.313794 140379563415296 logging_writer.py:48] [8924] accumulated_eval_time=109.057536, accumulated_logging_time=0.663349, accumulated_submission_time=2111.464605, global_step=8924, preemption_count=0, score=2111.464605, test/loss=0.289590, test/num_examples=3581, test/ssim=0.739816, total_duration=2221.513169, train/loss=0.260591, train/ssim=0.749987, validation/loss=0.288150, validation/num_examples=3554, validation/ssim=0.722597
I0204 14:21:54.505543 140379571808000 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.1001337319612503, loss=0.19800865650177002
I0204 14:22:18.438224 140379563415296 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.10209795832633972, loss=0.30307769775390625
I0204 14:22:42.518169 140379571808000 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.3168380558490753, loss=0.21172353625297546
I0204 14:22:58.434144 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:22:59.816931 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:23:01.147226 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:23:02.475848 140584300062528 submission_runner.py:408] Time since start: 2305.69s, 	Step: 9268, 	{'train/ssim': 0.7488860402788434, 'train/loss': 0.26120117732456755, 'validation/ssim': 0.7222374876899268, 'validation/loss': 0.2878062989380364, 'validation/num_examples': 3554, 'test/ssim': 0.739492612922368, 'test/loss': 0.28924732692945404, 'test/num_examples': 3581, 'score': 2191.5632648468018, 'total_duration': 2305.6930689811707, 'accumulated_submission_time': 2191.5632648468018, 'accumulated_eval_time': 113.09919476509094, 'accumulated_logging_time': 0.690230131149292}
I0204 14:23:02.493674 140379563415296 logging_writer.py:48] [9268] accumulated_eval_time=113.099195, accumulated_logging_time=0.690230, accumulated_submission_time=2191.563265, global_step=9268, preemption_count=0, score=2191.563265, test/loss=0.289247, test/num_examples=3581, test/ssim=0.739493, total_duration=2305.693069, train/loss=0.261201, train/ssim=0.748886, validation/loss=0.287806, validation/num_examples=3554, validation/ssim=0.722237
I0204 14:23:08.035320 140379571808000 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.02563346177339554, loss=0.31837862730026245
I0204 14:23:32.131373 140379563415296 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.08818219602108002, loss=0.2306411862373352
I0204 14:23:55.845839 140379571808000 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.08976060152053833, loss=0.26884016394615173
I0204 14:24:20.099079 140379563415296 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.09734170883893967, loss=0.27047884464263916
I0204 14:24:22.673892 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:24:24.052371 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:24:25.382903 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:24:26.713602 140584300062528 submission_runner.py:408] Time since start: 2389.93s, 	Step: 9612, 	{'train/ssim': 0.7509616443089077, 'train/loss': 0.26031036036355154, 'validation/ssim': 0.7241491898433103, 'validation/loss': 0.2872652087106957, 'validation/num_examples': 3554, 'test/ssim': 0.7413944008962231, 'test/loss': 0.28867382485252024, 'test/num_examples': 3581, 'score': 2271.7214958667755, 'total_duration': 2389.9308273792267, 'accumulated_submission_time': 2271.7214958667755, 'accumulated_eval_time': 117.13886761665344, 'accumulated_logging_time': 0.7173893451690674}
I0204 14:24:26.730072 140379571808000 logging_writer.py:48] [9612] accumulated_eval_time=117.138868, accumulated_logging_time=0.717389, accumulated_submission_time=2271.721496, global_step=9612, preemption_count=0, score=2271.721496, test/loss=0.288674, test/num_examples=3581, test/ssim=0.741394, total_duration=2389.930827, train/loss=0.260310, train/ssim=0.750962, validation/loss=0.287265, validation/num_examples=3554, validation/ssim=0.724149
I0204 14:24:45.805492 140379563415296 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.05272297188639641, loss=0.24734215438365936
I0204 14:25:10.145084 140379571808000 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.2876608967781067, loss=0.263855516910553
I0204 14:25:33.858560 140379563415296 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.05664810538291931, loss=0.25250542163848877
I0204 14:25:47.031799 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:25:48.414428 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:25:49.748197 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:25:51.076045 140584300062528 submission_runner.py:408] Time since start: 2474.29s, 	Step: 9956, 	{'train/ssim': 0.7515387535095215, 'train/loss': 0.2596092053822109, 'validation/ssim': 0.7244041155212436, 'validation/loss': 0.28693614438067144, 'validation/num_examples': 3554, 'test/ssim': 0.741594158514556, 'test/loss': 0.28842941152087404, 'test/num_examples': 3581, 'score': 2352.0011718273163, 'total_duration': 2474.2932760715485, 'accumulated_submission_time': 2352.0011718273163, 'accumulated_eval_time': 121.1830849647522, 'accumulated_logging_time': 0.7429046630859375}
I0204 14:25:51.093379 140379571808000 logging_writer.py:48] [9956] accumulated_eval_time=121.183085, accumulated_logging_time=0.742905, accumulated_submission_time=2352.001172, global_step=9956, preemption_count=0, score=2352.001172, test/loss=0.288429, test/num_examples=3581, test/ssim=0.741594, total_duration=2474.293276, train/loss=0.259609, train/ssim=0.751539, validation/loss=0.286936, validation/num_examples=3554, validation/ssim=0.724404
I0204 14:25:59.573180 140379563415296 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.06342380493879318, loss=0.24911269545555115
I0204 14:26:23.499383 140379571808000 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.09591902047395706, loss=0.28624528646469116
I0204 14:26:47.635051 140379563415296 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.07503651082515717, loss=0.3518267869949341
I0204 14:27:11.214093 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:27:12.595226 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:27:13.924768 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:27:15.252860 140584300062528 submission_runner.py:408] Time since start: 2558.47s, 	Step: 10299, 	{'train/ssim': 0.7496851512363979, 'train/loss': 0.2598560537610735, 'validation/ssim': 0.7228082711601365, 'validation/loss': 0.28672064940581915, 'validation/num_examples': 3554, 'test/ssim': 0.7400625698129014, 'test/loss': 0.28818404371596623, 'test/num_examples': 3581, 'score': 2432.098387002945, 'total_duration': 2558.470093727112, 'accumulated_submission_time': 2432.098387002945, 'accumulated_eval_time': 125.2218165397644, 'accumulated_logging_time': 0.7710072994232178}
I0204 14:27:15.270853 140379571808000 logging_writer.py:48] [10299] accumulated_eval_time=125.221817, accumulated_logging_time=0.771007, accumulated_submission_time=2432.098387, global_step=10299, preemption_count=0, score=2432.098387, test/loss=0.288184, test/num_examples=3581, test/ssim=0.740063, total_duration=2558.470094, train/loss=0.259856, train/ssim=0.749685, validation/loss=0.286721, validation/num_examples=3554, validation/ssim=0.722808
I0204 14:27:15.436837 140379563415296 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.07012811303138733, loss=0.2442665696144104
I0204 14:27:37.315540 140379571808000 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.10046528279781342, loss=0.3072574734687805
I0204 14:28:01.104800 140379563415296 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.09183568507432938, loss=0.2147493064403534
I0204 14:28:24.604402 140379571808000 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.04553038999438286, loss=0.2543348968029022
I0204 14:28:35.306402 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:28:36.684667 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:28:38.015375 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:28:39.345702 140584300062528 submission_runner.py:408] Time since start: 2642.56s, 	Step: 10645, 	{'train/ssim': 0.7517651149204799, 'train/loss': 0.2603922741753714, 'validation/ssim': 0.7249827301763858, 'validation/loss': 0.2872193894093803, 'validation/num_examples': 3554, 'test/ssim': 0.7421747509642908, 'test/loss': 0.288655042182264, 'test/num_examples': 3581, 'score': 2512.111428976059, 'total_duration': 2642.562907934189, 'accumulated_submission_time': 2512.111428976059, 'accumulated_eval_time': 129.26106452941895, 'accumulated_logging_time': 0.798546552658081}
I0204 14:28:39.367437 140379563415296 logging_writer.py:48] [10645] accumulated_eval_time=129.261065, accumulated_logging_time=0.798547, accumulated_submission_time=2512.111429, global_step=10645, preemption_count=0, score=2512.111429, test/loss=0.288655, test/num_examples=3581, test/ssim=0.742175, total_duration=2642.562908, train/loss=0.260392, train/ssim=0.751765, validation/loss=0.287219, validation/num_examples=3554, validation/ssim=0.724983
I0204 14:28:50.763046 140379571808000 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.08314728736877441, loss=0.3158392906188965
I0204 14:29:15.038618 140379563415296 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.05942162126302719, loss=0.19556427001953125
I0204 14:29:39.119422 140379571808000 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.08514242619276047, loss=0.25646740198135376
I0204 14:29:59.457942 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:30:00.835744 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:30:02.167485 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:30:03.498206 140584300062528 submission_runner.py:408] Time since start: 2726.72s, 	Step: 10985, 	{'train/ssim': 0.7508465221949986, 'train/loss': 0.2591175522123064, 'validation/ssim': 0.7235672091525394, 'validation/loss': 0.2865561430012838, 'validation/num_examples': 3554, 'test/ssim': 0.7408287391353672, 'test/loss': 0.2879923309436959, 'test/num_examples': 3581, 'score': 2592.179505586624, 'total_duration': 2726.715437889099, 'accumulated_submission_time': 2592.179505586624, 'accumulated_eval_time': 133.30129551887512, 'accumulated_logging_time': 0.8306035995483398}
I0204 14:30:03.516375 140379563415296 logging_writer.py:48] [10985] accumulated_eval_time=133.301296, accumulated_logging_time=0.830604, accumulated_submission_time=2592.179506, global_step=10985, preemption_count=0, score=2592.179506, test/loss=0.287992, test/num_examples=3581, test/ssim=0.740829, total_duration=2726.715438, train/loss=0.259118, train/ssim=0.750847, validation/loss=0.286556, validation/num_examples=3554, validation/ssim=0.723567
I0204 14:30:04.979012 140379571808000 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.06403479725122452, loss=0.3320580720901489
I0204 14:30:28.846657 140379563415296 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.2291315644979477, loss=0.25102469325065613
I0204 14:30:52.829550 140379571808000 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.0513916090130806, loss=0.24601563811302185
I0204 14:31:16.720213 140379563415296 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.18360918760299683, loss=0.3008563220500946
I0204 14:31:23.586502 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:31:24.967849 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:31:26.299124 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:31:27.627698 140584300062528 submission_runner.py:408] Time since start: 2810.84s, 	Step: 11330, 	{'train/ssim': 0.7511290822710309, 'train/loss': 0.2594335079193115, 'validation/ssim': 0.7241735077333639, 'validation/loss': 0.2865808902326164, 'validation/num_examples': 3554, 'test/ssim': 0.7414312844701201, 'test/loss': 0.28802597612616937, 'test/num_examples': 3581, 'score': 2672.226739883423, 'total_duration': 2810.844916820526, 'accumulated_submission_time': 2672.226739883423, 'accumulated_eval_time': 137.34243512153625, 'accumulated_logging_time': 0.8594722747802734}
I0204 14:31:27.646172 140379571808000 logging_writer.py:48] [11330] accumulated_eval_time=137.342435, accumulated_logging_time=0.859472, accumulated_submission_time=2672.226740, global_step=11330, preemption_count=0, score=2672.226740, test/loss=0.288026, test/num_examples=3581, test/ssim=0.741431, total_duration=2810.844917, train/loss=0.259434, train/ssim=0.751129, validation/loss=0.286581, validation/num_examples=3554, validation/ssim=0.724174
I0204 14:31:42.272815 140379563415296 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.04196331277489662, loss=0.2591584324836731
I0204 14:32:06.228534 140379571808000 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.03588910028338432, loss=0.2897090017795563
I0204 14:32:30.465822 140379563415296 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.33488959074020386, loss=0.24704855680465698
I0204 14:32:47.817376 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:32:49.198351 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:32:50.530059 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:32:51.861808 140584300062528 submission_runner.py:408] Time since start: 2895.08s, 	Step: 11674, 	{'train/ssim': 0.750849860055106, 'train/loss': 0.26001875741141184, 'validation/ssim': 0.7243757446495146, 'validation/loss': 0.2867924696150025, 'validation/num_examples': 3554, 'test/ssim': 0.7415087331576375, 'test/loss': 0.2882127801788083, 'test/num_examples': 3581, 'score': 2752.375296831131, 'total_duration': 2895.079016685486, 'accumulated_submission_time': 2752.375296831131, 'accumulated_eval_time': 141.38680863380432, 'accumulated_logging_time': 0.8880980014801025}
I0204 14:32:51.882366 140379571808000 logging_writer.py:48] [11674] accumulated_eval_time=141.386809, accumulated_logging_time=0.888098, accumulated_submission_time=2752.375297, global_step=11674, preemption_count=0, score=2752.375297, test/loss=0.288213, test/num_examples=3581, test/ssim=0.741509, total_duration=2895.079017, train/loss=0.260019, train/ssim=0.750850, validation/loss=0.286792, validation/num_examples=3554, validation/ssim=0.724376
I0204 14:32:55.899571 140379563415296 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.049481771886348724, loss=0.24105559289455414
I0204 14:33:20.317414 140379571808000 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.08552631735801697, loss=0.2785781919956207
I0204 14:33:44.166107 140379563415296 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.1396895796060562, loss=0.3495975732803345
I0204 14:34:08.445549 140379571808000 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.05328107997775078, loss=0.32415929436683655
I0204 14:34:11.933074 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:34:13.318851 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:34:14.650141 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:34:15.980333 140584300062528 submission_runner.py:408] Time since start: 2979.20s, 	Step: 12016, 	{'train/ssim': 0.7508232252938407, 'train/loss': 0.2597970792225429, 'validation/ssim': 0.7236260117341375, 'validation/loss': 0.28707080297947735, 'validation/num_examples': 3554, 'test/ssim': 0.740762539597005, 'test/loss': 0.288554652048136, 'test/num_examples': 3581, 'score': 2832.403507232666, 'total_duration': 2979.1975667476654, 'accumulated_submission_time': 2832.403507232666, 'accumulated_eval_time': 145.4340295791626, 'accumulated_logging_time': 0.9185914993286133}
I0204 14:34:15.997996 140379563415296 logging_writer.py:48] [12016] accumulated_eval_time=145.434030, accumulated_logging_time=0.918591, accumulated_submission_time=2832.403507, global_step=12016, preemption_count=0, score=2832.403507, test/loss=0.288555, test/num_examples=3581, test/ssim=0.740763, total_duration=2979.197567, train/loss=0.259797, train/ssim=0.750823, validation/loss=0.287071, validation/num_examples=3554, validation/ssim=0.723626
I0204 14:34:33.973793 140379571808000 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.11797219514846802, loss=0.21890106797218323
I0204 14:34:58.052299 140379563415296 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.12834365665912628, loss=0.27058175206184387
I0204 14:35:21.904943 140379571808000 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.0609777458012104, loss=0.2793123722076416
I0204 14:35:36.090291 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:35:37.470346 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:35:38.800514 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:35:40.132323 140584300062528 submission_runner.py:408] Time since start: 3063.35s, 	Step: 12361, 	{'train/ssim': 0.7515483583722796, 'train/loss': 0.2597310883658273, 'validation/ssim': 0.7247749976918613, 'validation/loss': 0.28688409104398216, 'validation/num_examples': 3554, 'test/ssim': 0.7418716375270525, 'test/loss': 0.28835036068181025, 'test/num_examples': 3581, 'score': 2912.47318983078, 'total_duration': 3063.34952712059, 'accumulated_submission_time': 2912.47318983078, 'accumulated_eval_time': 149.47599267959595, 'accumulated_logging_time': 0.9461815357208252}
I0204 14:35:40.150528 140379563415296 logging_writer.py:48] [12361] accumulated_eval_time=149.475993, accumulated_logging_time=0.946182, accumulated_submission_time=2912.473190, global_step=12361, preemption_count=0, score=2912.473190, test/loss=0.288350, test/num_examples=3581, test/ssim=0.741872, total_duration=3063.349527, train/loss=0.259731, train/ssim=0.751548, validation/loss=0.286884, validation/num_examples=3554, validation/ssim=0.724775
I0204 14:35:47.337562 140379571808000 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.08236117660999298, loss=0.25127360224723816
I0204 14:36:11.343745 140379563415296 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.16813090443611145, loss=0.33244919776916504
I0204 14:36:35.412982 140379571808000 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.06874120980501175, loss=0.37100863456726074
I0204 14:36:59.246144 140379563415296 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.053779762238264084, loss=0.2892405092716217
I0204 14:37:00.335075 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:37:01.716808 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:37:03.043945 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:37:04.373620 140584300062528 submission_runner.py:408] Time since start: 3147.59s, 	Step: 12706, 	{'train/ssim': 0.75163391658238, 'train/loss': 0.25952419212886263, 'validation/ssim': 0.7246345172253095, 'validation/loss': 0.2866389199999121, 'validation/num_examples': 3554, 'test/ssim': 0.7418361174863864, 'test/loss': 0.2879713666202702, 'test/num_examples': 3581, 'score': 2992.6348898410797, 'total_duration': 3147.590842962265, 'accumulated_submission_time': 2992.6348898410797, 'accumulated_eval_time': 153.514493227005, 'accumulated_logging_time': 0.9745748043060303}
I0204 14:37:04.392490 140379571808000 logging_writer.py:48] [12706] accumulated_eval_time=153.514493, accumulated_logging_time=0.974575, accumulated_submission_time=2992.634890, global_step=12706, preemption_count=0, score=2992.634890, test/loss=0.287971, test/num_examples=3581, test/ssim=0.741836, total_duration=3147.590843, train/loss=0.259524, train/ssim=0.751634, validation/loss=0.286639, validation/num_examples=3554, validation/ssim=0.724635
I0204 14:37:24.734237 140379563415296 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.11054123938083649, loss=0.2489703893661499
I0204 14:37:49.321757 140379571808000 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.02600536122918129, loss=0.21756520867347717
I0204 14:38:13.389849 140379563415296 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.056527648121118546, loss=0.2831706404685974
I0204 14:38:24.589557 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:38:25.972178 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:38:27.303968 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:38:28.633175 140584300062528 submission_runner.py:408] Time since start: 3231.85s, 	Step: 13047, 	{'train/ssim': 0.7500644411359515, 'train/loss': 0.26224068232945036, 'validation/ssim': 0.7231141682347355, 'validation/loss': 0.28903618996641106, 'validation/num_examples': 3554, 'test/ssim': 0.7402398291329237, 'test/loss': 0.29055839821933466, 'test/num_examples': 3581, 'score': 3072.810255050659, 'total_duration': 3231.8504090309143, 'accumulated_submission_time': 3072.810255050659, 'accumulated_eval_time': 157.55807256698608, 'accumulated_logging_time': 1.0025804042816162}
I0204 14:38:28.650821 140379571808000 logging_writer.py:48] [13047] accumulated_eval_time=157.558073, accumulated_logging_time=1.002580, accumulated_submission_time=3072.810255, global_step=13047, preemption_count=0, score=3072.810255, test/loss=0.290558, test/num_examples=3581, test/ssim=0.740240, total_duration=3231.850409, train/loss=0.262241, train/ssim=0.750064, validation/loss=0.289036, validation/num_examples=3554, validation/ssim=0.723114
I0204 14:38:39.192337 140379563415296 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.026719070971012115, loss=0.23940879106521606
I0204 14:39:02.984388 140379571808000 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.08534795045852661, loss=0.19020676612854004
I0204 14:39:26.744314 140379563415296 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.08097044378519058, loss=0.25442296266555786
I0204 14:39:48.685190 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:39:50.065056 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:39:51.394682 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:39:52.727224 140584300062528 submission_runner.py:408] Time since start: 3315.94s, 	Step: 13393, 	{'train/ssim': 0.7512751306806292, 'train/loss': 0.2590423311505999, 'validation/ssim': 0.7241309857730726, 'validation/loss': 0.2862096474153243, 'validation/num_examples': 3554, 'test/ssim': 0.7413110208391511, 'test/loss': 0.2877308734466629, 'test/num_examples': 3581, 'score': 3152.822122335434, 'total_duration': 3315.9444572925568, 'accumulated_submission_time': 3152.822122335434, 'accumulated_eval_time': 161.60008311271667, 'accumulated_logging_time': 1.0305194854736328}
I0204 14:39:52.745508 140379571808000 logging_writer.py:48] [13393] accumulated_eval_time=161.600083, accumulated_logging_time=1.030519, accumulated_submission_time=3152.822122, global_step=13393, preemption_count=0, score=3152.822122, test/loss=0.287731, test/num_examples=3581, test/ssim=0.741311, total_duration=3315.944457, train/loss=0.259042, train/ssim=0.751275, validation/loss=0.286210, validation/num_examples=3554, validation/ssim=0.724131
I0204 14:39:53.346409 140379563415296 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.0906427651643753, loss=0.28648701310157776
I0204 14:40:16.578628 140379571808000 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.08063770085573196, loss=0.26833948493003845
I0204 14:40:40.413835 140379563415296 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.10915334522724152, loss=0.21626392006874084
I0204 14:41:04.590704 140379571808000 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.08190987259149551, loss=0.3267500698566437
I0204 14:41:12.858987 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:41:14.237903 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:41:15.566674 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:41:16.897077 140584300062528 submission_runner.py:408] Time since start: 3400.11s, 	Step: 13736, 	{'train/ssim': 0.7505890301295689, 'train/loss': 0.2599429743630545, 'validation/ssim': 0.7239430373346933, 'validation/loss': 0.28687146841037386, 'validation/num_examples': 3554, 'test/ssim': 0.7411356022889906, 'test/loss': 0.28825896986700644, 'test/num_examples': 3581, 'score': 3232.913407802582, 'total_duration': 3400.114282131195, 'accumulated_submission_time': 3232.913407802582, 'accumulated_eval_time': 165.63811612129211, 'accumulated_logging_time': 1.0580720901489258}
I0204 14:41:16.918104 140379563415296 logging_writer.py:48] [13736] accumulated_eval_time=165.638116, accumulated_logging_time=1.058072, accumulated_submission_time=3232.913408, global_step=13736, preemption_count=0, score=3232.913408, test/loss=0.288259, test/num_examples=3581, test/ssim=0.741136, total_duration=3400.114282, train/loss=0.259943, train/ssim=0.750589, validation/loss=0.286871, validation/num_examples=3554, validation/ssim=0.723943
I0204 14:41:30.007212 140379571808000 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.10110587626695633, loss=0.2149701714515686
I0204 14:41:53.983289 140379563415296 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.2756817936897278, loss=0.23535990715026855
I0204 14:42:18.246644 140379571808000 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.12361287325620651, loss=0.33026251196861267
I0204 14:42:37.137641 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:42:38.517266 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:42:39.850253 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:42:41.180724 140584300062528 submission_runner.py:408] Time since start: 3484.40s, 	Step: 14081, 	{'train/ssim': 0.7513887541634696, 'train/loss': 0.2593295063291277, 'validation/ssim': 0.7242169914181205, 'validation/loss': 0.28648032133137835, 'validation/num_examples': 3554, 'test/ssim': 0.7414687134573094, 'test/loss': 0.2879141664012322, 'test/num_examples': 3581, 'score': 3313.1099050045013, 'total_duration': 3484.3979263305664, 'accumulated_submission_time': 3313.1099050045013, 'accumulated_eval_time': 169.68113112449646, 'accumulated_logging_time': 1.0890719890594482}
I0204 14:42:41.201828 140379563415296 logging_writer.py:48] [14081] accumulated_eval_time=169.681131, accumulated_logging_time=1.089072, accumulated_submission_time=3313.109905, global_step=14081, preemption_count=0, score=3313.109905, test/loss=0.287914, test/num_examples=3581, test/ssim=0.741469, total_duration=3484.397926, train/loss=0.259330, train/ssim=0.751389, validation/loss=0.286480, validation/num_examples=3554, validation/ssim=0.724217
I0204 14:42:43.815725 140379571808000 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.07388024777173996, loss=0.2772257924079895
I0204 14:43:07.713330 140379563415296 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.11826890707015991, loss=0.2365952879190445
I0204 14:43:31.867776 140379571808000 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.10998852550983429, loss=0.287321537733078
I0204 14:43:55.401073 140379563415296 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.0533401295542717, loss=0.22761012613773346
I0204 14:44:01.282706 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:44:02.664669 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:44:03.999140 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:44:05.329901 140584300062528 submission_runner.py:408] Time since start: 3568.55s, 	Step: 14426, 	{'train/ssim': 0.7521964481898716, 'train/loss': 0.2591852971485683, 'validation/ssim': 0.7246845268975098, 'validation/loss': 0.28662739647997854, 'validation/num_examples': 3554, 'test/ssim': 0.7418051652820441, 'test/loss': 0.28811777600094246, 'test/num_examples': 3581, 'score': 3393.1668939590454, 'total_duration': 3568.5471363067627, 'accumulated_submission_time': 3393.1668939590454, 'accumulated_eval_time': 173.728289604187, 'accumulated_logging_time': 1.1212973594665527}
I0204 14:44:05.347906 140379571808000 logging_writer.py:48] [14426] accumulated_eval_time=173.728290, accumulated_logging_time=1.121297, accumulated_submission_time=3393.166894, global_step=14426, preemption_count=0, score=3393.166894, test/loss=0.288118, test/num_examples=3581, test/ssim=0.741805, total_duration=3568.547136, train/loss=0.259185, train/ssim=0.752196, validation/loss=0.286627, validation/num_examples=3554, validation/ssim=0.724685
I0204 14:44:21.023963 140379563415296 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.031210454180836678, loss=0.36489149928092957
I0204 14:44:44.877464 140379571808000 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.2002633959054947, loss=0.20383714139461517
I0204 14:45:09.258312 140379563415296 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.06328973174095154, loss=0.2230386734008789
I0204 14:45:25.391845 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:45:26.772623 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:45:28.103051 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:45:29.434931 140584300062528 submission_runner.py:408] Time since start: 3652.65s, 	Step: 14769, 	{'train/ssim': 0.7512100083487374, 'train/loss': 0.2590839522225516, 'validation/ssim': 0.7241107208646947, 'validation/loss': 0.2862400447778911, 'validation/num_examples': 3554, 'test/ssim': 0.7413695164147585, 'test/loss': 0.2876715938394478, 'test/num_examples': 3581, 'score': 3473.188450574875, 'total_duration': 3652.6521632671356, 'accumulated_submission_time': 3473.188450574875, 'accumulated_eval_time': 177.77133631706238, 'accumulated_logging_time': 1.1494691371917725}
I0204 14:45:29.453694 140379571808000 logging_writer.py:48] [14769] accumulated_eval_time=177.771336, accumulated_logging_time=1.149469, accumulated_submission_time=3473.188451, global_step=14769, preemption_count=0, score=3473.188451, test/loss=0.287672, test/num_examples=3581, test/ssim=0.741370, total_duration=3652.652163, train/loss=0.259084, train/ssim=0.751210, validation/loss=0.286240, validation/num_examples=3554, validation/ssim=0.724111
I0204 14:45:34.756875 140379563415296 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.071265310049057, loss=0.26595526933670044
I0204 14:45:58.596217 140379571808000 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.14993415772914886, loss=0.23491229116916656
I0204 14:46:22.826001 140379563415296 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.07208359986543655, loss=0.22661858797073364
I0204 14:46:47.022199 140379571808000 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.06182090565562248, loss=0.20694126188755035
I0204 14:46:49.613896 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:46:50.997905 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:46:52.328010 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:46:53.659948 140584300062528 submission_runner.py:408] Time since start: 3736.88s, 	Step: 15112, 	{'train/ssim': 0.751319340297154, 'train/loss': 0.2589912414550781, 'validation/ssim': 0.7240003286349888, 'validation/loss': 0.28620248600278736, 'validation/num_examples': 3554, 'test/ssim': 0.7413103390725356, 'test/loss': 0.2875662608973576, 'test/num_examples': 3581, 'score': 3553.326792240143, 'total_duration': 3736.8771603107452, 'accumulated_submission_time': 3553.326792240143, 'accumulated_eval_time': 181.81732654571533, 'accumulated_logging_time': 1.1774797439575195}
I0204 14:46:53.680590 140379563415296 logging_writer.py:48] [15112] accumulated_eval_time=181.817327, accumulated_logging_time=1.177480, accumulated_submission_time=3553.326792, global_step=15112, preemption_count=0, score=3553.326792, test/loss=0.287566, test/num_examples=3581, test/ssim=0.741310, total_duration=3736.877160, train/loss=0.258991, train/ssim=0.751319, validation/loss=0.286202, validation/num_examples=3554, validation/ssim=0.724000
I0204 14:47:12.827030 140379571808000 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.07245480269193649, loss=0.2438851296901703
I0204 14:47:36.695731 140379563415296 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.1163216307759285, loss=0.24117723107337952
I0204 14:48:00.517598 140379571808000 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.06081594154238701, loss=0.234043151140213
I0204 14:48:13.903673 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:48:15.279505 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:48:16.611052 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:48:17.941781 140584300062528 submission_runner.py:408] Time since start: 3821.16s, 	Step: 15457, 	{'train/ssim': 0.7521231515066964, 'train/loss': 0.2582509858267648, 'validation/ssim': 0.7244947237048045, 'validation/loss': 0.28593206969150076, 'validation/num_examples': 3554, 'test/ssim': 0.7416795156948129, 'test/loss': 0.2873466638705145, 'test/num_examples': 3581, 'score': 3633.5277137756348, 'total_duration': 3821.1590161323547, 'accumulated_submission_time': 3633.5277137756348, 'accumulated_eval_time': 185.85540199279785, 'accumulated_logging_time': 1.2082180976867676}
I0204 14:48:17.959897 140379563415296 logging_writer.py:48] [15457] accumulated_eval_time=185.855402, accumulated_logging_time=1.208218, accumulated_submission_time=3633.527714, global_step=15457, preemption_count=0, score=3633.527714, test/loss=0.287347, test/num_examples=3581, test/ssim=0.741680, total_duration=3821.159016, train/loss=0.258251, train/ssim=0.752123, validation/loss=0.285932, validation/num_examples=3554, validation/ssim=0.724495
I0204 14:48:26.066606 140379571808000 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.10914289206266403, loss=0.34608012437820435
I0204 14:48:50.083591 140379563415296 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.07634870707988739, loss=0.3037400245666504
I0204 14:49:13.932021 140379571808000 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.10948239266872406, loss=0.24520017206668854
I0204 14:49:38.094964 140379563415296 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.04903307557106018, loss=0.3027482330799103
I0204 14:49:38.101741 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:49:39.428324 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:49:40.759573 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:49:42.091852 140584300062528 submission_runner.py:408] Time since start: 3905.31s, 	Step: 15801, 	{'train/ssim': 0.7514749254499163, 'train/loss': 0.25869577271597727, 'validation/ssim': 0.7243029283685636, 'validation/loss': 0.28592387785989376, 'validation/num_examples': 3554, 'test/ssim': 0.7415334131091176, 'test/loss': 0.2873067805235095, 'test/num_examples': 3581, 'score': 3713.646933078766, 'total_duration': 3905.3090555667877, 'accumulated_submission_time': 3713.646933078766, 'accumulated_eval_time': 189.84543323516846, 'accumulated_logging_time': 1.2363996505737305}
I0204 14:49:42.114379 140379571808000 logging_writer.py:48] [15801] accumulated_eval_time=189.845433, accumulated_logging_time=1.236400, accumulated_submission_time=3713.646933, global_step=15801, preemption_count=0, score=3713.646933, test/loss=0.287307, test/num_examples=3581, test/ssim=0.741533, total_duration=3905.309056, train/loss=0.258696, train/ssim=0.751475, validation/loss=0.285924, validation/num_examples=3554, validation/ssim=0.724303
I0204 14:50:03.883331 140379563415296 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.12692385911941528, loss=0.29775214195251465
I0204 14:50:27.660568 140379571808000 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.12192635238170624, loss=0.22394728660583496
I0204 14:50:51.700739 140379563415296 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.051522623747587204, loss=0.2758297920227051
I0204 14:51:02.150718 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:51:03.532768 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:51:04.860969 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:51:06.191118 140584300062528 submission_runner.py:408] Time since start: 3989.41s, 	Step: 16143, 	{'train/ssim': 0.7512297630310059, 'train/loss': 0.25882807799748014, 'validation/ssim': 0.7240081598199212, 'validation/loss': 0.2860556512853035, 'validation/num_examples': 3554, 'test/ssim': 0.74123561745148, 'test/loss': 0.28744903112782744, 'test/num_examples': 3581, 'score': 3793.65927529335, 'total_duration': 3989.4083540439606, 'accumulated_submission_time': 3793.65927529335, 'accumulated_eval_time': 193.8857979774475, 'accumulated_logging_time': 1.270770788192749}
I0204 14:51:06.209655 140379571808000 logging_writer.py:48] [16143] accumulated_eval_time=193.885798, accumulated_logging_time=1.270771, accumulated_submission_time=3793.659275, global_step=16143, preemption_count=0, score=3793.659275, test/loss=0.287449, test/num_examples=3581, test/ssim=0.741236, total_duration=3989.408354, train/loss=0.258828, train/ssim=0.751230, validation/loss=0.286056, validation/num_examples=3554, validation/ssim=0.724008
I0204 14:51:17.702033 140379563415296 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.025270145386457443, loss=0.2576855719089508
I0204 14:51:41.638852 140379571808000 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.1253654658794403, loss=0.2212926745414734
I0204 14:52:05.470851 140379563415296 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.09100998938083649, loss=0.24057821929454803
I0204 14:52:26.237350 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:52:27.619644 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:52:28.950898 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:52:30.284317 140584300062528 submission_runner.py:408] Time since start: 4073.50s, 	Step: 16488, 	{'train/ssim': 0.7530438559395927, 'train/loss': 0.2580648149762835, 'validation/ssim': 0.7251870966252814, 'validation/loss': 0.28587718270236884, 'validation/num_examples': 3554, 'test/ssim': 0.7423863713217328, 'test/loss': 0.28728680476167623, 'test/num_examples': 3581, 'score': 3873.663761138916, 'total_duration': 4073.5015137195587, 'accumulated_submission_time': 3873.663761138916, 'accumulated_eval_time': 197.93269228935242, 'accumulated_logging_time': 1.299825668334961}
I0204 14:52:30.307723 140379571808000 logging_writer.py:48] [16488] accumulated_eval_time=197.932692, accumulated_logging_time=1.299826, accumulated_submission_time=3873.663761, global_step=16488, preemption_count=0, score=3873.663761, test/loss=0.287287, test/num_examples=3581, test/ssim=0.742386, total_duration=4073.501514, train/loss=0.258065, train/ssim=0.753044, validation/loss=0.285877, validation/num_examples=3554, validation/ssim=0.725187
I0204 14:52:31.278601 140379563415296 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.05996950343251228, loss=0.20746806263923645
I0204 14:52:54.914222 140379571808000 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.11110775172710419, loss=0.18800944089889526
I0204 14:53:19.065283 140379563415296 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.19850854575634003, loss=0.2657470703125
I0204 14:53:42.982698 140379571808000 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.14920955896377563, loss=0.23685996234416962
I0204 14:53:50.510372 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:53:51.893681 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:53:53.226376 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:53:54.554348 140584300062528 submission_runner.py:408] Time since start: 4157.77s, 	Step: 16833, 	{'train/ssim': 0.7522469248090472, 'train/loss': 0.258419258253915, 'validation/ssim': 0.7247790506735369, 'validation/loss': 0.2858986154190261, 'validation/num_examples': 3554, 'test/ssim': 0.7419785385323583, 'test/loss': 0.2872385356853009, 'test/num_examples': 3581, 'score': 3953.843817949295, 'total_duration': 4157.771581888199, 'accumulated_submission_time': 3953.843817949295, 'accumulated_eval_time': 201.97663283348083, 'accumulated_logging_time': 1.3333888053894043}
I0204 14:53:54.574641 140379563415296 logging_writer.py:48] [16833] accumulated_eval_time=201.976633, accumulated_logging_time=1.333389, accumulated_submission_time=3953.843818, global_step=16833, preemption_count=0, score=3953.843818, test/loss=0.287239, test/num_examples=3581, test/ssim=0.741979, total_duration=4157.771582, train/loss=0.258419, train/ssim=0.752247, validation/loss=0.285899, validation/num_examples=3554, validation/ssim=0.724779
I0204 14:54:08.757944 140379571808000 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.05018937960267067, loss=0.3538505434989929
I0204 14:54:32.575036 140379563415296 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.043724387884140015, loss=0.2388535737991333
I0204 14:54:56.505807 140379571808000 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.15510958433151245, loss=0.27472853660583496
I0204 14:55:14.753520 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:55:16.133518 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:55:17.462919 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:55:18.792095 140584300062528 submission_runner.py:408] Time since start: 4242.01s, 	Step: 17177, 	{'train/ssim': 0.7513459750584194, 'train/loss': 0.25871615750449045, 'validation/ssim': 0.724141770826006, 'validation/loss': 0.2860677587093768, 'validation/num_examples': 3554, 'test/ssim': 0.7413751069010053, 'test/loss': 0.28739568289016687, 'test/num_examples': 3581, 'score': 4033.999075651169, 'total_duration': 4242.0093314647675, 'accumulated_submission_time': 4033.999075651169, 'accumulated_eval_time': 206.0151960849762, 'accumulated_logging_time': 1.3643596172332764}
I0204 14:55:18.811048 140379563415296 logging_writer.py:48] [17177] accumulated_eval_time=206.015196, accumulated_logging_time=1.364360, accumulated_submission_time=4033.999076, global_step=17177, preemption_count=0, score=4033.999076, test/loss=0.287396, test/num_examples=3581, test/ssim=0.741375, total_duration=4242.009331, train/loss=0.258716, train/ssim=0.751346, validation/loss=0.286068, validation/num_examples=3554, validation/ssim=0.724142
I0204 14:55:22.100464 140379571808000 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.13549746572971344, loss=0.3436736464500427
I0204 14:55:46.351594 140379563415296 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.04459669440984726, loss=0.30665212869644165
I0204 14:56:10.471733 140379571808000 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.04917890951037407, loss=0.2582922577857971
I0204 14:56:34.071826 140379563415296 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.04396747425198555, loss=0.301471471786499
I0204 14:56:39.001882 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:56:40.385025 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:56:41.716104 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:56:43.048745 140584300062528 submission_runner.py:408] Time since start: 4326.27s, 	Step: 17522, 	{'train/ssim': 0.7527370452880859, 'train/loss': 0.2583299194063459, 'validation/ssim': 0.7250032698631823, 'validation/loss': 0.28616877412554514, 'validation/num_examples': 3554, 'test/ssim': 0.742186750056723, 'test/loss': 0.2876077123075782, 'test/num_examples': 3581, 'score': 4114.166547060013, 'total_duration': 4326.265980958939, 'accumulated_submission_time': 4114.166547060013, 'accumulated_eval_time': 210.06202054023743, 'accumulated_logging_time': 1.3937888145446777}
I0204 14:56:43.067631 140379571808000 logging_writer.py:48] [17522] accumulated_eval_time=210.062021, accumulated_logging_time=1.393789, accumulated_submission_time=4114.166547, global_step=17522, preemption_count=0, score=4114.166547, test/loss=0.287608, test/num_examples=3581, test/ssim=0.742187, total_duration=4326.265981, train/loss=0.258330, train/ssim=0.752737, validation/loss=0.286169, validation/num_examples=3554, validation/ssim=0.725003
I0204 14:56:59.537362 140379563415296 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.10801030695438385, loss=0.25722768902778625
I0204 14:57:23.301899 140379571808000 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.08107709884643555, loss=0.28532636165618896
I0204 14:57:47.040374 140379563415296 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.10232324153184891, loss=0.3611118793487549
I0204 14:58:03.248343 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:58:04.628717 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:58:05.959110 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:58:07.290361 140584300062528 submission_runner.py:408] Time since start: 4410.51s, 	Step: 17869, 	{'train/ssim': 0.752519062587193, 'train/loss': 0.25849527972085135, 'validation/ssim': 0.725203858108821, 'validation/loss': 0.2860077539721968, 'validation/num_examples': 3554, 'test/ssim': 0.7423210580799707, 'test/loss': 0.2874424179916574, 'test/num_examples': 3581, 'score': 4194.325728654861, 'total_duration': 4410.5075969696045, 'accumulated_submission_time': 4194.325728654861, 'accumulated_eval_time': 214.1040050983429, 'accumulated_logging_time': 1.4217588901519775}
I0204 14:58:07.310344 140379571808000 logging_writer.py:48] [17869] accumulated_eval_time=214.104005, accumulated_logging_time=1.421759, accumulated_submission_time=4194.325729, global_step=17869, preemption_count=0, score=4194.325729, test/loss=0.287442, test/num_examples=3581, test/ssim=0.742321, total_duration=4410.507597, train/loss=0.258495, train/ssim=0.752519, validation/loss=0.286008, validation/num_examples=3554, validation/ssim=0.725204
I0204 14:58:12.621007 140379563415296 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.0839240700006485, loss=0.3196542263031006
I0204 14:58:36.586158 140379571808000 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.053652405738830566, loss=0.3673110604286194
I0204 14:59:00.532927 140379563415296 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.06054295226931572, loss=0.2285550832748413
I0204 14:59:24.642186 140379571808000 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.04928846284747124, loss=0.3577454090118408
I0204 14:59:27.370465 140584300062528 spec.py:321] Evaluating on the training split.
I0204 14:59:28.750824 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 14:59:30.080233 140584300062528 spec.py:349] Evaluating on the test split.
I0204 14:59:31.412578 140584300062528 submission_runner.py:408] Time since start: 4494.63s, 	Step: 18213, 	{'train/ssim': 0.7517549651009696, 'train/loss': 0.2586789812360491, 'validation/ssim': 0.7244219074238534, 'validation/loss': 0.2860423760529509, 'validation/num_examples': 3554, 'test/ssim': 0.7415589111805362, 'test/loss': 0.28744234981499583, 'test/num_examples': 3581, 'score': 4274.364299535751, 'total_duration': 4494.629780292511, 'accumulated_submission_time': 4274.364299535751, 'accumulated_eval_time': 218.1460461616516, 'accumulated_logging_time': 1.4510364532470703}
I0204 14:59:31.434974 140379563415296 logging_writer.py:48] [18213] accumulated_eval_time=218.146046, accumulated_logging_time=1.451036, accumulated_submission_time=4274.364300, global_step=18213, preemption_count=0, score=4274.364300, test/loss=0.287442, test/num_examples=3581, test/ssim=0.741559, total_duration=4494.629780, train/loss=0.258679, train/ssim=0.751755, validation/loss=0.286042, validation/num_examples=3554, validation/ssim=0.724422
I0204 14:59:53.751051 140379571808000 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.2888915538787842, loss=0.2019110918045044
I0204 15:00:17.935308 140379563415296 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.03665170818567276, loss=0.2851923704147339
I0204 15:00:42.047064 140379571808000 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.03450464457273483, loss=0.2299109250307083
I0204 15:00:51.547214 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:00:52.926470 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:00:54.256737 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:00:55.586720 140584300062528 submission_runner.py:408] Time since start: 4578.80s, 	Step: 18541, 	{'train/ssim': 0.7444351060049874, 'train/loss': 0.26171806880405973, 'validation/ssim': 0.7190021091991418, 'validation/loss': 0.2888652090953855, 'validation/num_examples': 3554, 'test/ssim': 0.7355785226062902, 'test/loss': 0.290273419774068, 'test/num_examples': 3581, 'score': 4351.388922452927, 'total_duration': 4578.803955078125, 'accumulated_submission_time': 4351.388922452927, 'accumulated_eval_time': 222.18551421165466, 'accumulated_logging_time': 4.549318790435791}
I0204 15:00:55.606061 140379563415296 logging_writer.py:48] [18541] accumulated_eval_time=222.185514, accumulated_logging_time=4.549319, accumulated_submission_time=4351.388922, global_step=18541, preemption_count=0, score=4351.388922, test/loss=0.290273, test/num_examples=3581, test/ssim=0.735579, total_duration=4578.803955, train/loss=0.261718, train/ssim=0.744435, validation/loss=0.288865, validation/num_examples=3554, validation/ssim=0.719002
I0204 15:01:07.816896 140379571808000 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.03832363337278366, loss=0.2931402623653412
I0204 15:01:31.756402 140379563415296 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.09303827583789825, loss=0.3028735816478729
I0204 15:01:55.668477 140379571808000 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.028866207227110863, loss=0.258996844291687
I0204 15:02:15.724850 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:02:17.106829 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:02:18.440253 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:02:19.770536 140584300062528 submission_runner.py:408] Time since start: 4662.99s, 	Step: 18885, 	{'train/ssim': 0.7527740342276437, 'train/loss': 0.25812794481004986, 'validation/ssim': 0.7252524251943233, 'validation/loss': 0.28576132925159153, 'validation/num_examples': 3554, 'test/ssim': 0.7424356630480313, 'test/loss': 0.28716350726926837, 'test/num_examples': 3581, 'score': 4431.485432386398, 'total_duration': 4662.9877717494965, 'accumulated_submission_time': 4431.485432386398, 'accumulated_eval_time': 226.23116660118103, 'accumulated_logging_time': 4.578796863555908}
I0204 15:02:19.790178 140379563415296 logging_writer.py:48] [18885] accumulated_eval_time=226.231167, accumulated_logging_time=4.578797, accumulated_submission_time=4431.485432, global_step=18885, preemption_count=0, score=4431.485432, test/loss=0.287164, test/num_examples=3581, test/ssim=0.742436, total_duration=4662.987772, train/loss=0.258128, train/ssim=0.752774, validation/loss=0.285761, validation/num_examples=3554, validation/ssim=0.725252
I0204 15:02:21.360853 140379571808000 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.07157999277114868, loss=0.27785661816596985
I0204 15:02:45.329435 140379563415296 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.05996914952993393, loss=0.29240113496780396
I0204 15:03:09.181174 140379571808000 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.05381537973880768, loss=0.3623200058937073
I0204 15:03:33.091909 140379563415296 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.09110977500677109, loss=0.3508816957473755
I0204 15:03:39.943423 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:03:41.322317 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:03:42.653513 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:03:43.984150 140584300062528 submission_runner.py:408] Time since start: 4747.20s, 	Step: 19230, 	{'train/ssim': 0.752542359488351, 'train/loss': 0.2582859822681972, 'validation/ssim': 0.7250183826762099, 'validation/loss': 0.28583660136465955, 'validation/num_examples': 3554, 'test/ssim': 0.7422182476743577, 'test/loss': 0.2871925846154182, 'test/num_examples': 3581, 'score': 4511.616227388382, 'total_duration': 4747.201381921768, 'accumulated_submission_time': 4511.616227388382, 'accumulated_eval_time': 230.27187418937683, 'accumulated_logging_time': 4.607800006866455}
I0204 15:03:44.003711 140379571808000 logging_writer.py:48] [19230] accumulated_eval_time=230.271874, accumulated_logging_time=4.607800, accumulated_submission_time=4511.616227, global_step=19230, preemption_count=0, score=4511.616227, test/loss=0.287193, test/num_examples=3581, test/ssim=0.742218, total_duration=4747.201382, train/loss=0.258286, train/ssim=0.752542, validation/loss=0.285837, validation/num_examples=3554, validation/ssim=0.725018
I0204 15:03:58.782175 140379563415296 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.05092836171388626, loss=0.31539881229400635
I0204 15:04:23.370344 140379571808000 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.11610615998506546, loss=0.20194657146930695
I0204 15:04:47.382254 140379563415296 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.05188746750354767, loss=0.31007063388824463
I0204 15:05:04.162920 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:05:05.544736 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:05:06.872646 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:05:08.201428 140584300062528 submission_runner.py:408] Time since start: 4831.42s, 	Step: 19570, 	{'train/ssim': 0.7528716496058873, 'train/loss': 0.25794635500226704, 'validation/ssim': 0.7250105514912775, 'validation/loss': 0.28573562029579347, 'validation/num_examples': 3554, 'test/ssim': 0.742229496823513, 'test/loss': 0.2871527694450747, 'test/num_examples': 3581, 'score': 4591.7536997795105, 'total_duration': 4831.418623209, 'accumulated_submission_time': 4591.7536997795105, 'accumulated_eval_time': 234.31031441688538, 'accumulated_logging_time': 4.636163949966431}
I0204 15:05:08.225064 140379571808000 logging_writer.py:48] [19570] accumulated_eval_time=234.310314, accumulated_logging_time=4.636164, accumulated_submission_time=4591.753700, global_step=19570, preemption_count=0, score=4591.753700, test/loss=0.287153, test/num_examples=3581, test/ssim=0.742229, total_duration=4831.418623, train/loss=0.257946, train/ssim=0.752872, validation/loss=0.285736, validation/num_examples=3554, validation/ssim=0.725011
I0204 15:05:13.397143 140379563415296 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.07573361694812775, loss=0.25779226422309875
I0204 15:05:37.117541 140379571808000 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.10706301778554916, loss=0.2472599297761917
I0204 15:06:00.950869 140379563415296 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.08864396065473557, loss=0.2840481698513031
I0204 15:06:24.816430 140379571808000 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.02936638705432415, loss=0.2751759886741638
I0204 15:06:28.313267 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:06:29.693702 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:06:31.025349 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:06:32.356413 140584300062528 submission_runner.py:408] Time since start: 4915.57s, 	Step: 19916, 	{'train/ssim': 0.7501134191240583, 'train/loss': 0.2603518622262137, 'validation/ssim': 0.723229231697559, 'validation/loss': 0.2876773763387205, 'validation/num_examples': 3554, 'test/ssim': 0.7400381625680675, 'test/loss': 0.2893246733519792, 'test/num_examples': 3581, 'score': 4671.819234609604, 'total_duration': 4915.573646783829, 'accumulated_submission_time': 4671.819234609604, 'accumulated_eval_time': 238.3534197807312, 'accumulated_logging_time': 4.670209646224976}
I0204 15:06:32.375866 140379563415296 logging_writer.py:48] [19916] accumulated_eval_time=238.353420, accumulated_logging_time=4.670210, accumulated_submission_time=4671.819235, global_step=19916, preemption_count=0, score=4671.819235, test/loss=0.289325, test/num_examples=3581, test/ssim=0.740038, total_duration=4915.573647, train/loss=0.260352, train/ssim=0.750113, validation/loss=0.287677, validation/num_examples=3554, validation/ssim=0.723229
I0204 15:06:50.329352 140379571808000 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.10595696419477463, loss=0.34773707389831543
I0204 15:07:14.541919 140379563415296 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.05082842335104942, loss=0.4155305027961731
I0204 15:07:38.385407 140379571808000 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.10842518508434296, loss=0.2797960638999939
I0204 15:07:52.474431 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:07:53.856864 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:07:55.187266 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:07:56.518615 140584300062528 submission_runner.py:408] Time since start: 4999.74s, 	Step: 20260, 	{'train/ssim': 0.7525191988263812, 'train/loss': 0.2582253898893084, 'validation/ssim': 0.7247402382218978, 'validation/loss': 0.2858264689104706, 'validation/num_examples': 3554, 'test/ssim': 0.7419907421547752, 'test/loss': 0.28716814328225354, 'test/num_examples': 3581, 'score': 4751.896664619446, 'total_duration': 4999.735841989517, 'accumulated_submission_time': 4751.896664619446, 'accumulated_eval_time': 242.39756178855896, 'accumulated_logging_time': 4.698517560958862}
I0204 15:07:56.538702 140379563415296 logging_writer.py:48] [20260] accumulated_eval_time=242.397562, accumulated_logging_time=4.698518, accumulated_submission_time=4751.896665, global_step=20260, preemption_count=0, score=4751.896665, test/loss=0.287168, test/num_examples=3581, test/ssim=0.741991, total_duration=4999.735842, train/loss=0.258225, train/ssim=0.752519, validation/loss=0.285826, validation/num_examples=3554, validation/ssim=0.724740
I0204 15:08:03.905707 140379571808000 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.10933444648981094, loss=0.24167202413082123
I0204 15:08:27.914334 140379563415296 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.10640541464090347, loss=0.23643004894256592
I0204 15:08:52.351520 140379571808000 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.32325899600982666, loss=0.2968289852142334
I0204 15:09:16.540757 140379563415296 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.08019053190946579, loss=0.2402621954679489
I0204 15:09:16.545741 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:09:17.873787 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:09:19.204447 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:09:20.538353 140584300062528 submission_runner.py:408] Time since start: 5083.76s, 	Step: 20601, 	{'train/ssim': 0.7524471964154925, 'train/loss': 0.2585275002888271, 'validation/ssim': 0.7248305029324353, 'validation/loss': 0.2860808793788689, 'validation/num_examples': 3554, 'test/ssim': 0.742039692997766, 'test/loss': 0.2874492697461428, 'test/num_examples': 3581, 'score': 4831.882543325424, 'total_duration': 5083.755587100983, 'accumulated_submission_time': 4831.882543325424, 'accumulated_eval_time': 246.3901126384735, 'accumulated_logging_time': 4.727694749832153}
I0204 15:09:20.558854 140379571808000 logging_writer.py:48] [20601] accumulated_eval_time=246.390113, accumulated_logging_time=4.727695, accumulated_submission_time=4831.882543, global_step=20601, preemption_count=0, score=4831.882543, test/loss=0.287449, test/num_examples=3581, test/ssim=0.742040, total_duration=5083.755587, train/loss=0.258528, train/ssim=0.752447, validation/loss=0.286081, validation/num_examples=3554, validation/ssim=0.724831
I0204 15:09:42.362713 140379563415296 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.04864291101694107, loss=0.2297464907169342
I0204 15:10:06.539182 140379571808000 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.06716106832027435, loss=0.2698937952518463
I0204 15:10:30.594674 140379563415296 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.056477345526218414, loss=0.2843441665172577
I0204 15:10:40.696073 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:10:42.078705 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:10:43.408194 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:10:44.738593 140584300062528 submission_runner.py:408] Time since start: 5167.96s, 	Step: 20944, 	{'train/ssim': 0.7533929007393974, 'train/loss': 0.2577303307397025, 'validation/ssim': 0.7254286955499085, 'validation/loss': 0.28577096366989657, 'validation/num_examples': 3554, 'test/ssim': 0.7425531314358769, 'test/loss': 0.28725748879721097, 'test/num_examples': 3581, 'score': 4911.99870967865, 'total_duration': 5167.955820322037, 'accumulated_submission_time': 4911.99870967865, 'accumulated_eval_time': 250.43258547782898, 'accumulated_logging_time': 4.757020711898804}
I0204 15:10:44.762712 140379571808000 logging_writer.py:48] [20944] accumulated_eval_time=250.432585, accumulated_logging_time=4.757021, accumulated_submission_time=4911.998710, global_step=20944, preemption_count=0, score=4911.998710, test/loss=0.287257, test/num_examples=3581, test/ssim=0.742553, total_duration=5167.955820, train/loss=0.257730, train/ssim=0.753393, validation/loss=0.285771, validation/num_examples=3554, validation/ssim=0.725429
I0204 15:10:55.922215 140379563415296 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.08552788943052292, loss=0.39030200242996216
I0204 15:11:19.813855 140379571808000 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.026578880846500397, loss=0.2826370298862457
I0204 15:11:43.890933 140379563415296 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.052235592156648636, loss=0.22000214457511902
I0204 15:12:04.812083 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:12:06.192214 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:12:07.524328 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:12:08.854390 140584300062528 submission_runner.py:408] Time since start: 5252.07s, 	Step: 21288, 	{'train/ssim': 0.7532256671360561, 'train/loss': 0.25794497558048796, 'validation/ssim': 0.7253845249191052, 'validation/loss': 0.2858033360023477, 'validation/num_examples': 3554, 'test/ssim': 0.7425597445720469, 'test/loss': 0.2872337633189926, 'test/num_examples': 3581, 'score': 4992.026699781418, 'total_duration': 5252.0716252326965, 'accumulated_submission_time': 4992.026699781418, 'accumulated_eval_time': 254.47485995292664, 'accumulated_logging_time': 4.789958953857422}
I0204 15:12:08.875512 140379571808000 logging_writer.py:48] [21288] accumulated_eval_time=254.474860, accumulated_logging_time=4.789959, accumulated_submission_time=4992.026700, global_step=21288, preemption_count=0, score=4992.026700, test/loss=0.287234, test/num_examples=3581, test/ssim=0.742560, total_duration=5252.071625, train/loss=0.257945, train/ssim=0.753226, validation/loss=0.285803, validation/num_examples=3554, validation/ssim=0.725385
I0204 15:12:09.843045 140379563415296 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.062300946563482285, loss=0.3017633855342865
I0204 15:12:33.516971 140379571808000 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.11461783200502396, loss=0.25404301285743713
I0204 15:12:57.488279 140379563415296 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.041020091623067856, loss=0.2520858645439148
I0204 15:13:21.973647 140379571808000 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.07486920803785324, loss=0.23506692051887512
I0204 15:13:28.862098 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:13:30.242326 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:13:31.573470 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:13:32.901321 140584300062528 submission_runner.py:408] Time since start: 5336.12s, 	Step: 21630, 	{'train/ssim': 0.7525844573974609, 'train/loss': 0.25794517993927, 'validation/ssim': 0.7247651056687887, 'validation/loss': 0.28567051498421675, 'validation/num_examples': 3554, 'test/ssim': 0.7420083999101159, 'test/loss': 0.2870563335573164, 'test/num_examples': 3581, 'score': 5071.9920909404755, 'total_duration': 5336.118559122086, 'accumulated_submission_time': 5071.9920909404755, 'accumulated_eval_time': 258.51404643058777, 'accumulated_logging_time': 4.820429563522339}
I0204 15:13:32.921564 140379563415296 logging_writer.py:48] [21630] accumulated_eval_time=258.514046, accumulated_logging_time=4.820430, accumulated_submission_time=5071.992091, global_step=21630, preemption_count=0, score=5071.992091, test/loss=0.287056, test/num_examples=3581, test/ssim=0.742008, total_duration=5336.118559, train/loss=0.257945, train/ssim=0.752584, validation/loss=0.285671, validation/num_examples=3554, validation/ssim=0.724765
I0204 15:13:47.803381 140379571808000 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.03238966688513756, loss=0.3958963453769684
I0204 15:14:11.701259 140379563415296 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.08975128084421158, loss=0.17993009090423584
I0204 15:14:35.588706 140379571808000 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.08510870486497879, loss=0.2758735716342926
I0204 15:14:52.905336 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:14:54.286384 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:14:55.619458 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:14:56.948764 140584300062528 submission_runner.py:408] Time since start: 5420.17s, 	Step: 21973, 	{'train/ssim': 0.7536664690290179, 'train/loss': 0.2574006829942976, 'validation/ssim': 0.7253517575926772, 'validation/loss': 0.2856152501747591, 'validation/num_examples': 3554, 'test/ssim': 0.7425326102607512, 'test/loss': 0.28703267625575957, 'test/num_examples': 3581, 'score': 5151.954606056213, 'total_duration': 5420.165975809097, 'accumulated_submission_time': 5151.954606056213, 'accumulated_eval_time': 262.5574164390564, 'accumulated_logging_time': 4.8497161865234375}
I0204 15:14:56.972346 140379563415296 logging_writer.py:48] [21973] accumulated_eval_time=262.557416, accumulated_logging_time=4.849716, accumulated_submission_time=5151.954606, global_step=21973, preemption_count=0, score=5151.954606, test/loss=0.287033, test/num_examples=3581, test/ssim=0.742533, total_duration=5420.165976, train/loss=0.257401, train/ssim=0.753666, validation/loss=0.285615, validation/num_examples=3554, validation/ssim=0.725352
I0204 15:15:01.498844 140379571808000 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.04532726854085922, loss=0.35371729731559753
I0204 15:15:25.339685 140379563415296 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.018996581435203552, loss=0.2908321022987366
I0204 15:15:49.203010 140379571808000 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.08681335300207138, loss=0.2716154456138611
I0204 15:16:13.418221 140379563415296 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.12186918407678604, loss=0.25076058506965637
I0204 15:16:16.960437 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:16:18.342431 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:16:19.673363 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:16:21.004562 140584300062528 submission_runner.py:408] Time since start: 5504.22s, 	Step: 22316, 	{'train/ssim': 0.7529209681919643, 'train/loss': 0.25769971098218647, 'validation/ssim': 0.724979776308385, 'validation/loss': 0.28566709742763435, 'validation/num_examples': 3554, 'test/ssim': 0.7421553206157497, 'test/loss': 0.28708084306714254, 'test/num_examples': 3581, 'score': 5231.9191353321075, 'total_duration': 5504.221770524979, 'accumulated_submission_time': 5231.9191353321075, 'accumulated_eval_time': 266.60148763656616, 'accumulated_logging_time': 4.884214401245117}
I0204 15:16:21.029490 140379571808000 logging_writer.py:48] [22316] accumulated_eval_time=266.601488, accumulated_logging_time=4.884214, accumulated_submission_time=5231.919135, global_step=22316, preemption_count=0, score=5231.919135, test/loss=0.287081, test/num_examples=3581, test/ssim=0.742155, total_duration=5504.221771, train/loss=0.257700, train/ssim=0.752921, validation/loss=0.285667, validation/num_examples=3554, validation/ssim=0.724980
I0204 15:16:39.093057 140379563415296 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.03437488526105881, loss=0.28882065415382385
I0204 15:17:03.093034 140379571808000 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.14552414417266846, loss=0.24128229916095734
I0204 15:17:26.849529 140379563415296 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.15806730091571808, loss=0.23827677965164185
I0204 15:17:41.056970 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:17:42.437370 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:17:43.767077 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:17:45.100453 140584300062528 submission_runner.py:408] Time since start: 5588.32s, 	Step: 22658, 	{'train/ssim': 0.7528862953186035, 'train/loss': 0.2577470200402396, 'validation/ssim': 0.7251463607247116, 'validation/loss': 0.28557077041823475, 'validation/num_examples': 3554, 'test/ssim': 0.7423250805030019, 'test/loss': 0.28694200129590197, 'test/num_examples': 3581, 'score': 5311.92449259758, 'total_duration': 5588.317686080933, 'accumulated_submission_time': 5311.92449259758, 'accumulated_eval_time': 270.6449613571167, 'accumulated_logging_time': 4.9190685749053955}
I0204 15:17:45.121452 140379571808000 logging_writer.py:48] [22658] accumulated_eval_time=270.644961, accumulated_logging_time=4.919069, accumulated_submission_time=5311.924493, global_step=22658, preemption_count=0, score=5311.924493, test/loss=0.286942, test/num_examples=3581, test/ssim=0.742325, total_duration=5588.317686, train/loss=0.257747, train/ssim=0.752886, validation/loss=0.285571, validation/num_examples=3554, validation/ssim=0.725146
I0204 15:17:53.290990 140379563415296 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.10080407559871674, loss=0.1938764452934265
I0204 15:18:17.258791 140379571808000 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.04723837599158287, loss=0.2335258424282074
I0204 15:18:41.252063 140379563415296 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.08122500777244568, loss=0.19374307990074158
I0204 15:19:05.196018 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:19:06.576121 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:19:07.904957 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:19:09.235047 140584300062528 submission_runner.py:408] Time since start: 5672.45s, 	Step: 23000, 	{'train/ssim': 0.7542593819754464, 'train/loss': 0.2572645630155291, 'validation/ssim': 0.7257499115213492, 'validation/loss': 0.28568277697115046, 'validation/num_examples': 3554, 'test/ssim': 0.7428951737468584, 'test/loss': 0.2871562123664828, 'test/num_examples': 3581, 'score': 5391.978044509888, 'total_duration': 5672.452279090881, 'accumulated_submission_time': 5391.978044509888, 'accumulated_eval_time': 274.68395590782166, 'accumulated_logging_time': 4.949132919311523}
I0204 15:19:09.257083 140379571808000 logging_writer.py:48] [23000] accumulated_eval_time=274.683956, accumulated_logging_time=4.949133, accumulated_submission_time=5391.978045, global_step=23000, preemption_count=0, score=5391.978045, test/loss=0.287156, test/num_examples=3581, test/ssim=0.742895, total_duration=5672.452279, train/loss=0.257265, train/ssim=0.754259, validation/loss=0.285683, validation/num_examples=3554, validation/ssim=0.725750
I0204 15:19:09.349700 140379563415296 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.038111403584480286, loss=0.26869717240333557
I0204 15:19:31.056570 140379571808000 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.11992159485816956, loss=0.3014759421348572
I0204 15:19:55.282973 140379563415296 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.04614463075995445, loss=0.32689768075942993
I0204 15:20:19.133244 140379571808000 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.20606954395771027, loss=0.25028833746910095
I0204 15:20:29.421933 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:20:30.803077 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:20:32.132751 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:20:33.462290 140584300062528 submission_runner.py:408] Time since start: 5756.68s, 	Step: 23344, 	{'train/ssim': 0.7536674227033343, 'train/loss': 0.2575033562523978, 'validation/ssim': 0.725452189104706, 'validation/loss': 0.2856114376241998, 'validation/num_examples': 3554, 'test/ssim': 0.7426551918982128, 'test/loss': 0.2870301878076131, 'test/num_examples': 3581, 'score': 5472.120784044266, 'total_duration': 5756.679520845413, 'accumulated_submission_time': 5472.120784044266, 'accumulated_eval_time': 278.72428584098816, 'accumulated_logging_time': 4.980362415313721}
I0204 15:20:33.482787 140379563415296 logging_writer.py:48] [23344] accumulated_eval_time=278.724286, accumulated_logging_time=4.980362, accumulated_submission_time=5472.120784, global_step=23344, preemption_count=0, score=5472.120784, test/loss=0.287030, test/num_examples=3581, test/ssim=0.742655, total_duration=5756.679521, train/loss=0.257503, train/ssim=0.753667, validation/loss=0.285611, validation/num_examples=3554, validation/ssim=0.725452
I0204 15:20:44.762241 140379571808000 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.024539444595575333, loss=0.30716320872306824
I0204 15:21:08.698813 140379563415296 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.06233412027359009, loss=0.23100611567497253
I0204 15:21:32.486964 140379571808000 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.059316832572221756, loss=0.2344859540462494
I0204 15:21:53.548069 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:21:54.926862 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:21:56.256653 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:21:57.586408 140584300062528 submission_runner.py:408] Time since start: 5840.80s, 	Step: 23689, 	{'train/ssim': 0.7536218506949288, 'train/loss': 0.2578081062861851, 'validation/ssim': 0.7255891661464196, 'validation/loss': 0.28583452335286824, 'validation/num_examples': 3554, 'test/ssim': 0.7427696605129503, 'test/loss': 0.2871937095303337, 'test/num_examples': 3581, 'score': 5552.1640820503235, 'total_duration': 5840.803641319275, 'accumulated_submission_time': 5552.1640820503235, 'accumulated_eval_time': 282.7625916004181, 'accumulated_logging_time': 5.010173559188843}
I0204 15:21:57.608698 140379563415296 logging_writer.py:48] [23689] accumulated_eval_time=282.762592, accumulated_logging_time=5.010174, accumulated_submission_time=5552.164082, global_step=23689, preemption_count=0, score=5552.164082, test/loss=0.287194, test/num_examples=3581, test/ssim=0.742770, total_duration=5840.803641, train/loss=0.257808, train/ssim=0.753622, validation/loss=0.285835, validation/num_examples=3554, validation/ssim=0.725589
I0204 15:21:58.501141 140379571808000 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.03078499808907509, loss=0.2943528890609741
I0204 15:22:22.604106 140379563415296 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.05248018354177475, loss=0.23775742948055267
I0204 15:22:46.956428 140379571808000 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.08173137903213501, loss=0.2207329422235489
I0204 15:23:10.791741 140379563415296 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.028877807781100273, loss=0.23691122233867645
I0204 15:23:17.669208 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:23:19.049838 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:23:20.379643 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:23:21.708866 140584300062528 submission_runner.py:408] Time since start: 5924.93s, 	Step: 24030, 	{'train/ssim': 0.7539426939828056, 'train/loss': 0.2571692637034825, 'validation/ssim': 0.7254523264939153, 'validation/loss': 0.28561801513259705, 'validation/num_examples': 3554, 'test/ssim': 0.7426042639320372, 'test/loss': 0.28708009312386557, 'test/num_examples': 3581, 'score': 5632.201220989227, 'total_duration': 5924.926100969315, 'accumulated_submission_time': 5632.201220989227, 'accumulated_eval_time': 286.80222272872925, 'accumulated_logging_time': 5.042935132980347}
I0204 15:23:21.730974 140379571808000 logging_writer.py:48] [24030] accumulated_eval_time=286.802223, accumulated_logging_time=5.042935, accumulated_submission_time=5632.201221, global_step=24030, preemption_count=0, score=5632.201221, test/loss=0.287080, test/num_examples=3581, test/ssim=0.742604, total_duration=5924.926101, train/loss=0.257169, train/ssim=0.753943, validation/loss=0.285618, validation/num_examples=3554, validation/ssim=0.725452
I0204 15:23:36.388985 140379563415296 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.07290339469909668, loss=0.3263024091720581
I0204 15:23:59.948593 140379571808000 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.12322182208299637, loss=0.25942420959472656
I0204 15:24:24.186237 140379563415296 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.06768202036619186, loss=0.23642903566360474
I0204 15:24:41.780569 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:24:43.163425 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:24:44.491990 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:24:45.821903 140584300062528 submission_runner.py:408] Time since start: 6009.04s, 	Step: 24375, 	{'train/ssim': 0.7535826819283622, 'train/loss': 0.2576377051217215, 'validation/ssim': 0.7253617870049592, 'validation/loss': 0.285717347530951, 'validation/num_examples': 3554, 'test/ssim': 0.7425559266790003, 'test/loss': 0.2871609165561296, 'test/num_examples': 3581, 'score': 5712.229027509689, 'total_duration': 6009.039095878601, 'accumulated_submission_time': 5712.229027509689, 'accumulated_eval_time': 290.84347701072693, 'accumulated_logging_time': 5.074441194534302}
I0204 15:24:45.849075 140379571808000 logging_writer.py:48] [24375] accumulated_eval_time=290.843477, accumulated_logging_time=5.074441, accumulated_submission_time=5712.229028, global_step=24375, preemption_count=0, score=5712.229028, test/loss=0.287161, test/num_examples=3581, test/ssim=0.742556, total_duration=6009.039096, train/loss=0.257638, train/ssim=0.753583, validation/loss=0.285717, validation/num_examples=3554, validation/ssim=0.725362
I0204 15:24:49.830620 140379563415296 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.11790543794631958, loss=0.1885099560022354
I0204 15:25:13.829402 140379571808000 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.01914256624877453, loss=0.2941807508468628
I0204 15:25:37.983472 140379563415296 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.07015593349933624, loss=0.2837866544723511
I0204 15:26:01.995089 140379571808000 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.05308617651462555, loss=0.25206053256988525
I0204 15:26:05.997067 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:26:07.377992 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:26:08.711537 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:26:10.042263 140584300062528 submission_runner.py:408] Time since start: 6093.26s, 	Step: 24718, 	{'train/ssim': 0.7533001899719238, 'train/loss': 0.2575099127633231, 'validation/ssim': 0.7252187648380346, 'validation/loss': 0.28556371204760483, 'validation/num_examples': 3554, 'test/ssim': 0.7423800308922088, 'test/loss': 0.28695106879188775, 'test/num_examples': 3581, 'score': 5792.354554653168, 'total_duration': 6093.25949716568, 'accumulated_submission_time': 5792.354554653168, 'accumulated_eval_time': 294.8886339664459, 'accumulated_logging_time': 5.111849069595337}
I0204 15:26:10.063544 140379563415296 logging_writer.py:48] [24718] accumulated_eval_time=294.888634, accumulated_logging_time=5.111849, accumulated_submission_time=5792.354555, global_step=24718, preemption_count=0, score=5792.354555, test/loss=0.286951, test/num_examples=3581, test/ssim=0.742380, total_duration=6093.259497, train/loss=0.257510, train/ssim=0.753300, validation/loss=0.285564, validation/num_examples=3554, validation/ssim=0.725219
I0204 15:26:28.020622 140379571808000 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.027102874591946602, loss=0.27186158299446106
I0204 15:26:52.559529 140379563415296 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.04029078781604767, loss=0.25941699743270874
I0204 15:27:16.841466 140379571808000 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.04378746449947357, loss=0.24807524681091309
I0204 15:27:30.204339 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:27:31.587097 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:27:32.918615 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:27:34.248167 140584300062528 submission_runner.py:408] Time since start: 6177.47s, 	Step: 25057, 	{'train/ssim': 0.7541554995945522, 'train/loss': 0.2570937190737043, 'validation/ssim': 0.7256698136123031, 'validation/loss': 0.28562282375492404, 'validation/num_examples': 3554, 'test/ssim': 0.7427837730818906, 'test/loss': 0.28709458066444427, 'test/num_examples': 3581, 'score': 5872.473770856857, 'total_duration': 6177.465390920639, 'accumulated_submission_time': 5872.473770856857, 'accumulated_eval_time': 298.93243408203125, 'accumulated_logging_time': 5.142282724380493}
I0204 15:27:34.270254 140379563415296 logging_writer.py:48] [25057] accumulated_eval_time=298.932434, accumulated_logging_time=5.142283, accumulated_submission_time=5872.473771, global_step=25057, preemption_count=0, score=5872.473771, test/loss=0.287095, test/num_examples=3581, test/ssim=0.742784, total_duration=6177.465391, train/loss=0.257094, train/ssim=0.754155, validation/loss=0.285623, validation/num_examples=3554, validation/ssim=0.725670
I0204 15:27:42.479465 140379571808000 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.05067994445562363, loss=0.281077116727829
I0204 15:28:06.331963 140379563415296 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.04275890439748764, loss=0.22778163850307465
I0204 15:28:30.215241 140379571808000 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.06670551002025604, loss=0.2011829912662506
I0204 15:28:53.925384 140379563415296 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.036435578018426895, loss=0.2175299972295761
I0204 15:28:54.325628 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:28:55.706855 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:28:57.036628 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:28:58.368105 140584300062528 submission_runner.py:408] Time since start: 6261.59s, 	Step: 25403, 	{'train/ssim': 0.7537097930908203, 'train/loss': 0.25731371130262104, 'validation/ssim': 0.7254681949475943, 'validation/loss': 0.28553020625417663, 'validation/num_examples': 3554, 'test/ssim': 0.7426374659662106, 'test/loss': 0.2869819187312378, 'test/num_examples': 3581, 'score': 5952.507550954819, 'total_duration': 6261.5853390693665, 'accumulated_submission_time': 5952.507550954819, 'accumulated_eval_time': 302.9748706817627, 'accumulated_logging_time': 5.173599481582642}
I0204 15:28:58.389219 140379571808000 logging_writer.py:48] [25403] accumulated_eval_time=302.974871, accumulated_logging_time=5.173599, accumulated_submission_time=5952.507551, global_step=25403, preemption_count=0, score=5952.507551, test/loss=0.286982, test/num_examples=3581, test/ssim=0.742637, total_duration=6261.585339, train/loss=0.257314, train/ssim=0.753710, validation/loss=0.285530, validation/num_examples=3554, validation/ssim=0.725468
I0204 15:29:19.545872 140379563415296 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.04171782359480858, loss=0.25257620215415955
I0204 15:29:43.577489 140379571808000 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.030352866277098656, loss=0.33112919330596924
I0204 15:30:07.618822 140379563415296 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.03998618945479393, loss=0.41094276309013367
I0204 15:30:18.430288 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:30:19.811777 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:30:21.142903 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:30:22.475033 140584300062528 submission_runner.py:408] Time since start: 6345.69s, 	Step: 25746, 	{'train/ssim': 0.7538211005074638, 'train/loss': 0.257412246295384, 'validation/ssim': 0.7256960549512873, 'validation/loss': 0.28562861127536754, 'validation/num_examples': 3554, 'test/ssim': 0.7428361327579587, 'test/loss': 0.28704351634494557, 'test/num_examples': 3581, 'score': 6032.525489091873, 'total_duration': 6345.692269086838, 'accumulated_submission_time': 6032.525489091873, 'accumulated_eval_time': 307.01959562301636, 'accumulated_logging_time': 5.20525050163269}
I0204 15:30:22.496710 140379571808000 logging_writer.py:48] [25746] accumulated_eval_time=307.019596, accumulated_logging_time=5.205251, accumulated_submission_time=6032.525489, global_step=25746, preemption_count=0, score=6032.525489, test/loss=0.287044, test/num_examples=3581, test/ssim=0.742836, total_duration=6345.692269, train/loss=0.257412, train/ssim=0.753821, validation/loss=0.285629, validation/num_examples=3554, validation/ssim=0.725696
I0204 15:30:33.406158 140379563415296 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.02620306983590126, loss=0.27668648958206177
I0204 15:30:57.713702 140379571808000 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.051166877150535583, loss=0.24456150829792023
I0204 15:31:22.040347 140379563415296 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.022095592692494392, loss=0.29315587878227234
I0204 15:31:42.563213 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:31:43.941954 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:31:45.268517 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:31:46.598683 140584300062528 submission_runner.py:408] Time since start: 6429.82s, 	Step: 26088, 	{'train/ssim': 0.7538996423993792, 'train/loss': 0.25713941029139925, 'validation/ssim': 0.725426497322559, 'validation/loss': 0.285577863136167, 'validation/num_examples': 3554, 'test/ssim': 0.7425881060632505, 'test/loss': 0.2870197908667272, 'test/num_examples': 3581, 'score': 6112.56943154335, 'total_duration': 6429.8159165382385, 'accumulated_submission_time': 6112.56943154335, 'accumulated_eval_time': 311.0550262928009, 'accumulated_logging_time': 5.23749852180481}
I0204 15:31:46.620137 140379571808000 logging_writer.py:48] [26088] accumulated_eval_time=311.055026, accumulated_logging_time=5.237499, accumulated_submission_time=6112.569432, global_step=26088, preemption_count=0, score=6112.569432, test/loss=0.287020, test/num_examples=3581, test/ssim=0.742588, total_duration=6429.815917, train/loss=0.257139, train/ssim=0.753900, validation/loss=0.285578, validation/num_examples=3554, validation/ssim=0.725426
I0204 15:31:47.584265 140379563415296 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.054678067564964294, loss=0.2725317180156708
I0204 15:32:11.539572 140379571808000 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.0300885159522295, loss=0.2918681502342224
I0204 15:32:35.270206 140379563415296 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.030793447047472, loss=0.36123114824295044
I0204 15:32:59.036943 140379571808000 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.028835678473114967, loss=0.2484959065914154
I0204 15:33:06.652685 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:33:08.031644 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:33:09.360144 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:33:10.688486 140584300062528 submission_runner.py:408] Time since start: 6513.91s, 	Step: 26433, 	{'train/ssim': 0.7542871747698102, 'train/loss': 0.25722943033490864, 'validation/ssim': 0.7257701077351224, 'validation/loss': 0.2856593177636554, 'validation/num_examples': 3554, 'test/ssim': 0.7429105134957065, 'test/loss': 0.2871216467990785, 'test/num_examples': 3581, 'score': 6192.580571889877, 'total_duration': 6513.905717372894, 'accumulated_submission_time': 6192.580571889877, 'accumulated_eval_time': 315.09079217910767, 'accumulated_logging_time': 5.267976999282837}
I0204 15:33:10.710777 140379563415296 logging_writer.py:48] [26433] accumulated_eval_time=315.090792, accumulated_logging_time=5.267977, accumulated_submission_time=6192.580572, global_step=26433, preemption_count=0, score=6192.580572, test/loss=0.287122, test/num_examples=3581, test/ssim=0.742911, total_duration=6513.905717, train/loss=0.257229, train/ssim=0.754287, validation/loss=0.285659, validation/num_examples=3554, validation/ssim=0.725770
I0204 15:33:24.857144 140379571808000 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.06738318502902985, loss=0.2506468594074249
I0204 15:33:48.895688 140379563415296 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.04599883407354355, loss=0.2633349597454071
I0204 15:34:12.752028 140379571808000 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.05605502426624298, loss=0.3408944010734558
I0204 15:34:30.771909 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:34:32.153423 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:34:33.484359 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:34:34.816262 140584300062528 submission_runner.py:408] Time since start: 6598.03s, 	Step: 26776, 	{'train/ssim': 0.7540904453822544, 'train/loss': 0.25733167784554617, 'validation/ssim': 0.7257306770320414, 'validation/loss': 0.2856416460766038, 'validation/num_examples': 3554, 'test/ssim': 0.7429086727258447, 'test/loss': 0.287038334918668, 'test/num_examples': 3581, 'score': 6272.620399475098, 'total_duration': 6598.033495903015, 'accumulated_submission_time': 6272.620399475098, 'accumulated_eval_time': 319.1351087093353, 'accumulated_logging_time': 5.299068212509155}
I0204 15:34:34.837831 140379563415296 logging_writer.py:48] [26776] accumulated_eval_time=319.135109, accumulated_logging_time=5.299068, accumulated_submission_time=6272.620399, global_step=26776, preemption_count=0, score=6272.620399, test/loss=0.287038, test/num_examples=3581, test/ssim=0.742909, total_duration=6598.033496, train/loss=0.257332, train/ssim=0.754090, validation/loss=0.285642, validation/num_examples=3554, validation/ssim=0.725731
I0204 15:34:38.512392 140379571808000 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.04246363043785095, loss=0.1774122267961502
I0204 15:35:02.284281 140379563415296 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.03494248539209366, loss=0.2118704468011856
I0204 15:35:26.574657 140379571808000 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.0559319444000721, loss=0.21150970458984375
I0204 15:35:50.431057 140379563415296 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.06662345677614212, loss=0.245841383934021
I0204 15:35:54.968557 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:35:56.351613 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:35:57.679839 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:35:59.011482 140584300062528 submission_runner.py:408] Time since start: 6682.23s, 	Step: 27120, 	{'train/ssim': 0.7539983476911273, 'train/loss': 0.2578939199447632, 'validation/ssim': 0.7256790186893289, 'validation/loss': 0.2862922011564874, 'validation/num_examples': 3554, 'test/ssim': 0.7427011429680955, 'test/loss': 0.2878444898531311, 'test/num_examples': 3581, 'score': 6352.729802370071, 'total_duration': 6682.2287175655365, 'accumulated_submission_time': 6352.729802370071, 'accumulated_eval_time': 323.1779954433441, 'accumulated_logging_time': 5.3297858238220215}
I0204 15:35:59.033737 140379571808000 logging_writer.py:48] [27120] accumulated_eval_time=323.177995, accumulated_logging_time=5.329786, accumulated_submission_time=6352.729802, global_step=27120, preemption_count=0, score=6352.729802, test/loss=0.287844, test/num_examples=3581, test/ssim=0.742701, total_duration=6682.228718, train/loss=0.257894, train/ssim=0.753998, validation/loss=0.286292, validation/num_examples=3554, validation/ssim=0.725679
I0204 15:36:16.128987 140379563415296 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.028577761724591255, loss=0.30970847606658936
I0204 15:36:40.178187 140379571808000 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.03847068175673485, loss=0.23996210098266602
I0204 15:37:04.049439 140379563415296 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.08558118343353271, loss=0.30441978573799133
I0204 15:37:19.176632 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:37:20.561076 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:37:21.890157 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:37:23.221614 140584300062528 submission_runner.py:408] Time since start: 6766.44s, 	Step: 27465, 	{'train/ssim': 0.7527961730957031, 'train/loss': 0.2573528460093907, 'validation/ssim': 0.7244910828907569, 'validation/loss': 0.28572626065590706, 'validation/num_examples': 3554, 'test/ssim': 0.7416571537498254, 'test/loss': 0.2871871645708252, 'test/num_examples': 3581, 'score': 6432.850472688675, 'total_duration': 6766.438841342926, 'accumulated_submission_time': 6432.850472688675, 'accumulated_eval_time': 327.2229354381561, 'accumulated_logging_time': 5.361184120178223}
I0204 15:37:23.243938 140379571808000 logging_writer.py:48] [27465] accumulated_eval_time=327.222935, accumulated_logging_time=5.361184, accumulated_submission_time=6432.850473, global_step=27465, preemption_count=0, score=6432.850473, test/loss=0.287187, test/num_examples=3581, test/ssim=0.741657, total_duration=6766.438841, train/loss=0.257353, train/ssim=0.752796, validation/loss=0.285726, validation/num_examples=3554, validation/ssim=0.724491
I0204 15:37:29.586833 140379563415296 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.03942808136343956, loss=0.2351510375738144
I0204 15:37:53.779488 140379571808000 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.019579797983169556, loss=0.2439190298318863
I0204 15:38:17.923179 140379563415296 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.04571178928017616, loss=0.2900768518447876
I0204 15:38:42.029687 140379571808000 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.04413940757513046, loss=0.3115634024143219
I0204 15:38:43.446082 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:38:44.825139 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:38:46.155866 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:38:47.487070 140584300062528 submission_runner.py:408] Time since start: 6850.70s, 	Step: 27807, 	{'train/ssim': 0.754103592463902, 'train/loss': 0.2571893760136196, 'validation/ssim': 0.7257026496333356, 'validation/loss': 0.285555331305835, 'validation/num_examples': 3554, 'test/ssim': 0.7428482000270525, 'test/loss': 0.2869928951737469, 'test/num_examples': 3581, 'score': 6513.029781341553, 'total_duration': 6850.704304218292, 'accumulated_submission_time': 6513.029781341553, 'accumulated_eval_time': 331.2638852596283, 'accumulated_logging_time': 5.393904447555542}
I0204 15:38:47.509166 140379563415296 logging_writer.py:48] [27807] accumulated_eval_time=331.263885, accumulated_logging_time=5.393904, accumulated_submission_time=6513.029781, global_step=27807, preemption_count=0, score=6513.029781, test/loss=0.286993, test/num_examples=3581, test/ssim=0.742848, total_duration=6850.704304, train/loss=0.257189, train/ssim=0.754104, validation/loss=0.285555, validation/num_examples=3554, validation/ssim=0.725703
I0204 15:39:07.888532 140379571808000 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.0507952906191349, loss=0.26863300800323486
I0204 15:39:31.861697 140379563415296 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.038412515074014664, loss=0.23380973935127258
I0204 15:39:56.515225 140379571808000 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.0377655103802681, loss=0.2726483643054962
I0204 15:40:07.556450 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:40:08.935400 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:40:10.266310 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:40:11.596457 140584300062528 submission_runner.py:408] Time since start: 6934.81s, 	Step: 28147, 	{'train/ssim': 0.7540349960327148, 'train/loss': 0.257232666015625, 'validation/ssim': 0.7256720118396525, 'validation/loss': 0.2855900736021472, 'validation/num_examples': 3554, 'test/ssim': 0.7427993855373848, 'test/loss': 0.2870455957331227, 'test/num_examples': 3581, 'score': 6593.055602550507, 'total_duration': 6934.813687324524, 'accumulated_submission_time': 6593.055602550507, 'accumulated_eval_time': 335.303875207901, 'accumulated_logging_time': 5.425286054611206}
I0204 15:40:11.619001 140379563415296 logging_writer.py:48] [28147] accumulated_eval_time=335.303875, accumulated_logging_time=5.425286, accumulated_submission_time=6593.055603, global_step=28147, preemption_count=0, score=6593.055603, test/loss=0.287046, test/num_examples=3581, test/ssim=0.742799, total_duration=6934.813687, train/loss=0.257233, train/ssim=0.754035, validation/loss=0.285590, validation/num_examples=3554, validation/ssim=0.725672
I0204 15:40:22.264647 140379571808000 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.06157030165195465, loss=0.2545124590396881
I0204 15:40:46.204075 140379563415296 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.03830543905496597, loss=0.2382219284772873
I0204 15:41:09.994826 140379571808000 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.03620254993438721, loss=0.23550604283809662
I0204 15:41:31.802926 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:41:33.181945 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:41:34.511306 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:41:35.845794 140584300062528 submission_runner.py:408] Time since start: 7019.06s, 	Step: 28493, 	{'train/ssim': 0.7544220515659877, 'train/loss': 0.2567970412118094, 'validation/ssim': 0.7256915898019837, 'validation/loss': 0.28546022362566825, 'validation/num_examples': 3554, 'test/ssim': 0.7428325193948967, 'test/loss': 0.2869222641523841, 'test/num_examples': 3581, 'score': 6673.217515468597, 'total_duration': 7019.063020467758, 'accumulated_submission_time': 6673.217515468597, 'accumulated_eval_time': 339.34671092033386, 'accumulated_logging_time': 5.456988573074341}
I0204 15:41:35.867724 140379563415296 logging_writer.py:48] [28493] accumulated_eval_time=339.346711, accumulated_logging_time=5.456989, accumulated_submission_time=6673.217515, global_step=28493, preemption_count=0, score=6673.217515, test/loss=0.286922, test/num_examples=3581, test/ssim=0.742833, total_duration=7019.063020, train/loss=0.256797, train/ssim=0.754422, validation/loss=0.285460, validation/num_examples=3554, validation/ssim=0.725692
I0204 15:41:36.470004 140379571808000 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.04152015224099159, loss=0.29372942447662354
I0204 15:41:59.545944 140379563415296 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.03622787445783615, loss=0.3602914810180664
I0204 15:42:23.390624 140379571808000 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.033783555030822754, loss=0.2652330994606018
I0204 15:42:47.559370 140379563415296 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.04113463684916496, loss=0.20532456040382385
I0204 15:42:55.998534 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:42:57.378700 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:42:58.709436 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:43:00.040610 140584300062528 submission_runner.py:408] Time since start: 7103.26s, 	Step: 28837, 	{'train/ssim': 0.7540216445922852, 'train/loss': 0.2571344716208322, 'validation/ssim': 0.7254533569129854, 'validation/loss': 0.2856393791546497, 'validation/num_examples': 3554, 'test/ssim': 0.7426146949612539, 'test/loss': 0.28710644340355346, 'test/num_examples': 3581, 'score': 6753.32670044899, 'total_duration': 7103.257844209671, 'accumulated_submission_time': 6753.32670044899, 'accumulated_eval_time': 343.3887577056885, 'accumulated_logging_time': 5.488369941711426}
I0204 15:43:00.062784 140379571808000 logging_writer.py:48] [28837] accumulated_eval_time=343.388758, accumulated_logging_time=5.488370, accumulated_submission_time=6753.326700, global_step=28837, preemption_count=0, score=6753.326700, test/loss=0.287106, test/num_examples=3581, test/ssim=0.742615, total_duration=7103.257844, train/loss=0.257134, train/ssim=0.754022, validation/loss=0.285639, validation/num_examples=3554, validation/ssim=0.725453
I0204 15:43:13.124986 140379563415296 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.02820415422320366, loss=0.3393303453922272
I0204 15:43:36.839143 140379571808000 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.03840476647019386, loss=0.2604258060455322
I0204 15:44:00.830835 140379563415296 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.028927786275744438, loss=0.25242823362350464
I0204 15:44:20.207670 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:44:21.590198 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:44:22.923430 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:44:24.251597 140584300062528 submission_runner.py:408] Time since start: 7187.47s, 	Step: 29179, 	{'train/ssim': 0.7539787292480469, 'train/loss': 0.2571410962513515, 'validation/ssim': 0.7254288329391179, 'validation/loss': 0.28560760789998946, 'validation/num_examples': 3554, 'test/ssim': 0.742586060763404, 'test/loss': 0.28704464125986107, 'test/num_examples': 3581, 'score': 6833.4487562179565, 'total_duration': 7187.468809604645, 'accumulated_submission_time': 6833.4487562179565, 'accumulated_eval_time': 347.432626247406, 'accumulated_logging_time': 5.521002531051636}
I0204 15:44:24.273688 140379571808000 logging_writer.py:48] [29179] accumulated_eval_time=347.432626, accumulated_logging_time=5.521003, accumulated_submission_time=6833.448756, global_step=29179, preemption_count=0, score=6833.448756, test/loss=0.287045, test/num_examples=3581, test/ssim=0.742586, total_duration=7187.468810, train/loss=0.257141, train/ssim=0.753979, validation/loss=0.285608, validation/num_examples=3554, validation/ssim=0.725429
I0204 15:44:27.233903 140379563415296 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.025623133406043053, loss=0.3304762542247772
I0204 15:44:51.227637 140379571808000 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.08293215185403824, loss=0.3429946303367615
I0204 15:45:15.252046 140379563415296 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.07978840917348862, loss=0.18733114004135132
I0204 15:45:39.215840 140379571808000 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.02183934673666954, loss=0.2231495976448059
I0204 15:45:44.293829 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:45:45.673412 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:45:47.003924 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:45:48.335877 140584300062528 submission_runner.py:408] Time since start: 7271.55s, 	Step: 29523, 	{'train/ssim': 0.7546099935259137, 'train/loss': 0.256743107523237, 'validation/ssim': 0.7256827968925859, 'validation/loss': 0.2855766266332829, 'validation/num_examples': 3554, 'test/ssim': 0.7428071576768012, 'test/loss': 0.28706952574132577, 'test/num_examples': 3581, 'score': 6913.447591543198, 'total_duration': 7271.553107976913, 'accumulated_submission_time': 6913.447591543198, 'accumulated_eval_time': 351.4746322631836, 'accumulated_logging_time': 5.552271842956543}
I0204 15:45:48.358542 140379563415296 logging_writer.py:48] [29523] accumulated_eval_time=351.474632, accumulated_logging_time=5.552272, accumulated_submission_time=6913.447592, global_step=29523, preemption_count=0, score=6913.447592, test/loss=0.287070, test/num_examples=3581, test/ssim=0.742807, total_duration=7271.553108, train/loss=0.256743, train/ssim=0.754610, validation/loss=0.285577, validation/num_examples=3554, validation/ssim=0.725683
I0204 15:46:04.629384 140379571808000 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.055594656616449356, loss=0.20449648797512054
I0204 15:46:28.583995 140379563415296 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.02023026905953884, loss=0.3082881569862366
I0204 15:46:52.417566 140379571808000 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.025719746947288513, loss=0.3562244772911072
I0204 15:47:08.422902 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:47:09.801824 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:47:11.129264 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:47:12.462598 140584300062528 submission_runner.py:408] Time since start: 7355.68s, 	Step: 29867, 	{'train/ssim': 0.7541588374546596, 'train/loss': 0.25702978883470806, 'validation/ssim': 0.7254314433340954, 'validation/loss': 0.2856062511815472, 'validation/num_examples': 3554, 'test/ssim': 0.7425986734457903, 'test/loss': 0.28707157104117215, 'test/num_examples': 3581, 'score': 6993.4892337322235, 'total_duration': 7355.679824829102, 'accumulated_submission_time': 6993.4892337322235, 'accumulated_eval_time': 355.5142960548401, 'accumulated_logging_time': 5.584680080413818}
I0204 15:47:12.485807 140379563415296 logging_writer.py:48] [29867] accumulated_eval_time=355.514296, accumulated_logging_time=5.584680, accumulated_submission_time=6993.489234, global_step=29867, preemption_count=0, score=6993.489234, test/loss=0.287072, test/num_examples=3581, test/ssim=0.742599, total_duration=7355.679825, train/loss=0.257030, train/ssim=0.754159, validation/loss=0.285606, validation/num_examples=3554, validation/ssim=0.725431
I0204 15:47:18.336434 140379571808000 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.03185432404279709, loss=0.2625591456890106
I0204 15:47:42.032906 140379563415296 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.01582360453903675, loss=0.3210859000682831
I0204 15:48:06.303596 140379571808000 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.02234172448515892, loss=0.22492274641990662
I0204 15:48:30.384451 140379563415296 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.031782589852809906, loss=0.27936694025993347
I0204 15:48:32.697438 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:48:34.080889 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:48:35.410130 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:48:36.740493 140584300062528 submission_runner.py:408] Time since start: 7439.96s, 	Step: 30211, 	{'train/ssim': 0.7540692601885114, 'train/loss': 0.2571203368050711, 'validation/ssim': 0.7255136707758864, 'validation/loss': 0.2856606573084465, 'validation/num_examples': 3554, 'test/ssim': 0.7426834170360933, 'test/loss': 0.2870932512195441, 'test/num_examples': 3581, 'score': 7073.679226160049, 'total_duration': 7439.95772767067, 'accumulated_submission_time': 7073.679226160049, 'accumulated_eval_time': 359.5573136806488, 'accumulated_logging_time': 5.617060422897339}
I0204 15:48:36.762921 140379571808000 logging_writer.py:48] [30211] accumulated_eval_time=359.557314, accumulated_logging_time=5.617060, accumulated_submission_time=7073.679226, global_step=30211, preemption_count=0, score=7073.679226, test/loss=0.287093, test/num_examples=3581, test/ssim=0.742683, total_duration=7439.957728, train/loss=0.257120, train/ssim=0.754069, validation/loss=0.285661, validation/num_examples=3554, validation/ssim=0.725514
I0204 15:48:56.085240 140379563415296 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.027623018249869347, loss=0.29668721556663513
I0204 15:49:20.274763 140379571808000 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.030298950150609016, loss=0.28349894285202026
I0204 15:49:44.680712 140379563415296 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.0316222608089447, loss=0.2282383143901825
I0204 15:49:56.972785 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:49:58.352498 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:49:59.681645 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:50:01.012566 140584300062528 submission_runner.py:408] Time since start: 7524.23s, 	Step: 30552, 	{'train/ssim': 0.7548450742449079, 'train/loss': 0.25674610478537424, 'validation/ssim': 0.7258831103598059, 'validation/loss': 0.28564487472302336, 'validation/num_examples': 3554, 'test/ssim': 0.7429972342091944, 'test/loss': 0.2871223285656939, 'test/num_examples': 3581, 'score': 7153.867946386337, 'total_duration': 7524.22979927063, 'accumulated_submission_time': 7153.867946386337, 'accumulated_eval_time': 363.59706449508667, 'accumulated_logging_time': 5.648396730422974}
I0204 15:50:01.035251 140379571808000 logging_writer.py:48] [30552] accumulated_eval_time=363.597064, accumulated_logging_time=5.648397, accumulated_submission_time=7153.867946, global_step=30552, preemption_count=0, score=7153.867946, test/loss=0.287122, test/num_examples=3581, test/ssim=0.742997, total_duration=7524.229799, train/loss=0.256746, train/ssim=0.754845, validation/loss=0.285645, validation/num_examples=3554, validation/ssim=0.725883
I0204 15:50:10.613788 140379563415296 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.027417073026299477, loss=0.28040197491645813
I0204 15:50:34.436080 140379571808000 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.02585800178349018, loss=0.2904834747314453
I0204 15:50:58.303662 140379563415296 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.02009039930999279, loss=0.2819465696811676
I0204 15:51:21.101519 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:51:22.479073 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:51:23.806560 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:51:25.137505 140584300062528 submission_runner.py:408] Time since start: 7608.35s, 	Step: 30896, 	{'train/ssim': 0.7542660576956612, 'train/loss': 0.25690986428942, 'validation/ssim': 0.7255811975722777, 'validation/loss': 0.2855315114516654, 'validation/num_examples': 3554, 'test/ssim': 0.7427162100102974, 'test/loss': 0.2870102120457798, 'test/num_examples': 3581, 'score': 7233.912236690521, 'total_duration': 7608.354736804962, 'accumulated_submission_time': 7233.912236690521, 'accumulated_eval_time': 367.6330301761627, 'accumulated_logging_time': 5.680180311203003}
I0204 15:51:25.161160 140379571808000 logging_writer.py:48] [30896] accumulated_eval_time=367.633030, accumulated_logging_time=5.680180, accumulated_submission_time=7233.912237, global_step=30896, preemption_count=0, score=7233.912237, test/loss=0.287010, test/num_examples=3581, test/ssim=0.742716, total_duration=7608.354737, train/loss=0.256910, train/ssim=0.754266, validation/loss=0.285532, validation/num_examples=3554, validation/ssim=0.725581
I0204 15:51:25.542698 140379563415296 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.05272328108549118, loss=0.2156979888677597
I0204 15:51:47.873736 140379571808000 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.02315574139356613, loss=0.2573167085647583
I0204 15:52:12.072264 140379563415296 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.01898747682571411, loss=0.21193534135818481
I0204 15:52:35.828809 140379571808000 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.024071626365184784, loss=0.23830756545066833
I0204 15:52:45.343373 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:52:46.725855 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:52:48.057111 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:52:49.387434 140584300062528 submission_runner.py:408] Time since start: 7692.60s, 	Step: 31241, 	{'train/ssim': 0.754291330065046, 'train/loss': 0.2570479597364153, 'validation/ssim': 0.7256142396771244, 'validation/loss': 0.2856827082765458, 'validation/num_examples': 3554, 'test/ssim': 0.742731617935807, 'test/loss': 0.28712280580232474, 'test/num_examples': 3581, 'score': 7314.072935581207, 'total_duration': 7692.6046686172485, 'accumulated_submission_time': 7314.072935581207, 'accumulated_eval_time': 371.6770513057709, 'accumulated_logging_time': 5.712636709213257}
I0204 15:52:49.410606 140379563415296 logging_writer.py:48] [31241] accumulated_eval_time=371.677051, accumulated_logging_time=5.712637, accumulated_submission_time=7314.072936, global_step=31241, preemption_count=0, score=7314.072936, test/loss=0.287123, test/num_examples=3581, test/ssim=0.742732, total_duration=7692.604669, train/loss=0.257048, train/ssim=0.754291, validation/loss=0.285683, validation/num_examples=3554, validation/ssim=0.725614
I0204 15:53:01.854464 140379571808000 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.03130703046917915, loss=0.2569682002067566
I0204 15:53:26.232119 140379563415296 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.028919531032443047, loss=0.29839277267456055
I0204 15:53:50.264791 140379571808000 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.04221723973751068, loss=0.3099342882633209
I0204 15:54:09.574608 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:54:10.957130 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:54:12.287164 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:54:13.618017 140584300062528 submission_runner.py:408] Time since start: 7776.84s, 	Step: 31581, 	{'train/ssim': 0.7546959604535785, 'train/loss': 0.25669734818594797, 'validation/ssim': 0.725824445167417, 'validation/loss': 0.2855513126714617, 'validation/num_examples': 3554, 'test/ssim': 0.742917058455215, 'test/loss': 0.28703809630035254, 'test/num_examples': 3581, 'score': 7394.21529507637, 'total_duration': 7776.835196018219, 'accumulated_submission_time': 7394.21529507637, 'accumulated_eval_time': 375.7203893661499, 'accumulated_logging_time': 5.745257377624512}
I0204 15:54:13.644234 140379563415296 logging_writer.py:48] [31581] accumulated_eval_time=375.720389, accumulated_logging_time=5.745257, accumulated_submission_time=7394.215295, global_step=31581, preemption_count=0, score=7394.215295, test/loss=0.287038, test/num_examples=3581, test/ssim=0.742917, total_duration=7776.835196, train/loss=0.256697, train/ssim=0.754696, validation/loss=0.285551, validation/num_examples=3554, validation/ssim=0.725824
I0204 15:54:16.075732 140379571808000 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.024257861077785492, loss=0.22664234042167664
I0204 15:54:39.841568 140379563415296 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.017768634483218193, loss=0.25878962874412537
I0204 15:55:03.678898 140379571808000 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.049413051456213, loss=0.2767126262187958
I0204 15:55:27.473219 140379563415296 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.017751678824424744, loss=0.3402593731880188
I0204 15:55:33.826574 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:55:35.207664 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:55:36.538124 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:55:37.866073 140584300062528 submission_runner.py:408] Time since start: 7861.08s, 	Step: 31928, 	{'train/ssim': 0.7544897624424526, 'train/loss': 0.25679435048784527, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.28549537808960856, 'validation/num_examples': 3554, 'test/ssim': 0.7428276788519268, 'test/loss': 0.28697680548162174, 'test/num_examples': 3581, 'score': 7474.3756783008575, 'total_duration': 7861.083312034607, 'accumulated_submission_time': 7474.3756783008575, 'accumulated_eval_time': 379.75985383987427, 'accumulated_logging_time': 5.78111457824707}
I0204 15:55:37.889342 140379571808000 logging_writer.py:48] [31928] accumulated_eval_time=379.759854, accumulated_logging_time=5.781115, accumulated_submission_time=7474.375678, global_step=31928, preemption_count=0, score=7474.375678, test/loss=0.286977, test/num_examples=3581, test/ssim=0.742828, total_duration=7861.083312, train/loss=0.256794, train/ssim=0.754490, validation/loss=0.285495, validation/num_examples=3554, validation/ssim=0.725719
I0204 15:55:53.083621 140379563415296 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.046931684017181396, loss=0.17072129249572754
I0204 15:56:17.036483 140379571808000 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.016861997544765472, loss=0.26930588483810425
I0204 15:56:40.682837 140379563415296 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.02779429219663143, loss=0.2659352421760559
I0204 15:56:57.915298 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:56:59.294364 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:57:00.626482 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:57:01.956977 140584300062528 submission_runner.py:408] Time since start: 7945.17s, 	Step: 32273, 	{'train/ssim': 0.754249095916748, 'train/loss': 0.2569260426930019, 'validation/ssim': 0.7255921887090251, 'validation/loss': 0.285591790967264, 'validation/num_examples': 3554, 'test/ssim': 0.7427074833976194, 'test/loss': 0.28705142483768503, 'test/num_examples': 3581, 'score': 7554.379847288132, 'total_duration': 7945.174165248871, 'accumulated_submission_time': 7554.379847288132, 'accumulated_eval_time': 383.8014781475067, 'accumulated_logging_time': 5.81369686126709}
I0204 15:57:01.985812 140379571808000 logging_writer.py:48] [32273] accumulated_eval_time=383.801478, accumulated_logging_time=5.813697, accumulated_submission_time=7554.379847, global_step=32273, preemption_count=0, score=7554.379847, test/loss=0.287051, test/num_examples=3581, test/ssim=0.742707, total_duration=7945.174165, train/loss=0.256926, train/ssim=0.754249, validation/loss=0.285592, validation/num_examples=3554, validation/ssim=0.725592
I0204 15:57:06.499717 140379563415296 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.025723548606038094, loss=0.271951287984848
I0204 15:57:30.642619 140379571808000 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.03224971517920494, loss=0.2452903836965561
I0204 15:57:54.990684 140379563415296 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.02680254355072975, loss=0.2290085405111313
I0204 15:58:19.394610 140379571808000 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.023349730297923088, loss=0.33461105823516846
I0204 15:58:21.976255 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:58:23.356629 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:58:24.686422 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:58:26.015468 140584300062528 submission_runner.py:408] Time since start: 8029.23s, 	Step: 32612, 	{'train/ssim': 0.7544171469552177, 'train/loss': 0.25674491269247873, 'validation/ssim': 0.7255723359682752, 'validation/loss': 0.2855080694178215, 'validation/num_examples': 3554, 'test/ssim': 0.7427035973279112, 'test/loss': 0.2869986561016476, 'test/num_examples': 3581, 'score': 7634.347116231918, 'total_duration': 8029.232703924179, 'accumulated_submission_time': 7634.347116231918, 'accumulated_eval_time': 387.8406648635864, 'accumulated_logging_time': 5.852944374084473}
I0204 15:58:26.038398 140379563415296 logging_writer.py:48] [32612] accumulated_eval_time=387.840665, accumulated_logging_time=5.852944, accumulated_submission_time=7634.347116, global_step=32612, preemption_count=0, score=7634.347116, test/loss=0.286999, test/num_examples=3581, test/ssim=0.742704, total_duration=8029.232704, train/loss=0.256745, train/ssim=0.754417, validation/loss=0.285508, validation/num_examples=3554, validation/ssim=0.725572
I0204 15:58:45.044199 140379571808000 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.02749098464846611, loss=0.2750691771507263
I0204 15:59:09.100543 140379563415296 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.02235039882361889, loss=0.2548621594905853
I0204 15:59:33.039137 140379571808000 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.015398520976305008, loss=0.21013310551643372
I0204 15:59:46.092847 140584300062528 spec.py:321] Evaluating on the training split.
I0204 15:59:47.472255 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 15:59:48.801114 140584300062528 spec.py:349] Evaluating on the test split.
I0204 15:59:50.134934 140584300062528 submission_runner.py:408] Time since start: 8113.35s, 	Step: 32956, 	{'train/ssim': 0.7545514106750488, 'train/loss': 0.25672997747148785, 'validation/ssim': 0.7256814916950971, 'validation/loss': 0.28550841289084483, 'validation/num_examples': 3554, 'test/ssim': 0.7428032034304315, 'test/loss': 0.28699586085852413, 'test/num_examples': 3581, 'score': 7714.379668951035, 'total_duration': 8113.352165699005, 'accumulated_submission_time': 7714.379668951035, 'accumulated_eval_time': 391.8827121257782, 'accumulated_logging_time': 5.8849639892578125}
I0204 15:59:50.157985 140379563415296 logging_writer.py:48] [32956] accumulated_eval_time=391.882712, accumulated_logging_time=5.884964, accumulated_submission_time=7714.379669, global_step=32956, preemption_count=0, score=7714.379669, test/loss=0.286996, test/num_examples=3581, test/ssim=0.742803, total_duration=8113.352166, train/loss=0.256730, train/ssim=0.754551, validation/loss=0.285508, validation/num_examples=3554, validation/ssim=0.725681
I0204 15:59:58.594624 140379571808000 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.020909488201141357, loss=0.33004066348075867
I0204 16:00:22.904224 140379563415296 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.020687023177742958, loss=0.22367285192012787
I0204 16:00:46.797423 140379571808000 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.02080281637609005, loss=0.3524007499217987
I0204 16:01:10.350209 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:01:11.730566 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:01:13.059974 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:01:14.391457 140584300062528 submission_runner.py:408] Time since start: 8197.61s, 	Step: 33299, 	{'train/ssim': 0.754565920148577, 'train/loss': 0.256818277495248, 'validation/ssim': 0.7257891361406162, 'validation/loss': 0.28551468127352103, 'validation/num_examples': 3554, 'test/ssim': 0.7429174675151843, 'test/loss': 0.28698607750759214, 'test/num_examples': 3581, 'score': 7794.549304008484, 'total_duration': 8197.608664512634, 'accumulated_submission_time': 7794.549304008484, 'accumulated_eval_time': 395.9238955974579, 'accumulated_logging_time': 5.918242931365967}
I0204 16:01:14.419019 140379563415296 logging_writer.py:48] [33299] accumulated_eval_time=395.923896, accumulated_logging_time=5.918243, accumulated_submission_time=7794.549304, global_step=33299, preemption_count=0, score=7794.549304, test/loss=0.286986, test/num_examples=3581, test/ssim=0.742917, total_duration=8197.608665, train/loss=0.256818, train/ssim=0.754566, validation/loss=0.285515, validation/num_examples=3554, validation/ssim=0.725789
I0204 16:01:14.584344 140379571808000 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.025737985968589783, loss=0.31474193930625916
I0204 16:01:36.484006 140379563415296 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.017450865358114243, loss=0.2534072995185852
I0204 16:02:00.673393 140379571808000 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.0174633227288723, loss=0.26415935158729553
I0204 16:02:24.992813 140379563415296 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.022754790261387825, loss=0.29457855224609375
I0204 16:02:34.687533 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:02:36.070350 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:02:37.400813 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:02:38.727455 140584300062528 submission_runner.py:408] Time since start: 8281.94s, 	Step: 33641, 	{'train/ssim': 0.7544005257742745, 'train/loss': 0.2568733351571219, 'validation/ssim': 0.725658547697137, 'validation/loss': 0.28560537532533764, 'validation/num_examples': 3554, 'test/ssim': 0.7427757964124895, 'test/loss': 0.2871052844003072, 'test/num_examples': 3581, 'score': 7874.795213460922, 'total_duration': 8281.944691896439, 'accumulated_submission_time': 7874.795213460922, 'accumulated_eval_time': 399.9638068675995, 'accumulated_logging_time': 5.955785274505615}
I0204 16:02:38.750255 140379571808000 logging_writer.py:48] [33641] accumulated_eval_time=399.963807, accumulated_logging_time=5.955785, accumulated_submission_time=7874.795213, global_step=33641, preemption_count=0, score=7874.795213, test/loss=0.287105, test/num_examples=3581, test/ssim=0.742776, total_duration=8281.944692, train/loss=0.256873, train/ssim=0.754401, validation/loss=0.285605, validation/num_examples=3554, validation/ssim=0.725659
I0204 16:02:50.927122 140379563415296 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.02002590149641037, loss=0.25544577836990356
I0204 16:03:15.028372 140379571808000 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.02028951421380043, loss=0.24009215831756592
I0204 16:03:38.858341 140379563415296 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.0185667984187603, loss=0.2836131751537323
I0204 16:03:58.802741 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:04:00.186005 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:04:01.519901 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:04:02.850215 140584300062528 submission_runner.py:408] Time since start: 8366.07s, 	Step: 33984, 	{'train/ssim': 0.7547591754368373, 'train/loss': 0.25668695994785856, 'validation/ssim': 0.7258627767568233, 'validation/loss': 0.28552361157212824, 'validation/num_examples': 3554, 'test/ssim': 0.7429784856272689, 'test/loss': 0.28701941589508867, 'test/num_examples': 3581, 'score': 7954.826099395752, 'total_duration': 8366.067419290543, 'accumulated_submission_time': 7954.826099395752, 'accumulated_eval_time': 404.01122069358826, 'accumulated_logging_time': 5.9875712394714355}
I0204 16:04:02.877129 140379571808000 logging_writer.py:48] [33984] accumulated_eval_time=404.011221, accumulated_logging_time=5.987571, accumulated_submission_time=7954.826099, global_step=33984, preemption_count=0, score=7954.826099, test/loss=0.287019, test/num_examples=3581, test/ssim=0.742978, total_duration=8366.067419, train/loss=0.256687, train/ssim=0.754759, validation/loss=0.285524, validation/num_examples=3554, validation/ssim=0.725863
I0204 16:04:04.575059 140379563415296 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.023955168202519417, loss=0.27786362171173096
I0204 16:04:28.399125 140379571808000 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.01796700432896614, loss=0.25710591673851013
I0204 16:04:52.371796 140379563415296 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.021846115589141846, loss=0.26612383127212524
I0204 16:05:16.258788 140379571808000 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.02019473724067211, loss=0.2244790643453598
I0204 16:05:22.924296 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:05:24.306774 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:05:25.638551 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:05:26.968255 140584300062528 submission_runner.py:408] Time since start: 8450.19s, 	Step: 34329, 	{'train/ssim': 0.7546742303030831, 'train/loss': 0.2567040579659598, 'validation/ssim': 0.7258765843723621, 'validation/loss': 0.2854583688713421, 'validation/num_examples': 3554, 'test/ssim': 0.7429921891362399, 'test/loss': 0.2869331042415701, 'test/num_examples': 3581, 'score': 8034.8506779670715, 'total_duration': 8450.185488700867, 'accumulated_submission_time': 8034.8506779670715, 'accumulated_eval_time': 408.0551481246948, 'accumulated_logging_time': 6.024341106414795}
I0204 16:05:26.991348 140379563415296 logging_writer.py:48] [34329] accumulated_eval_time=408.055148, accumulated_logging_time=6.024341, accumulated_submission_time=8034.850678, global_step=34329, preemption_count=0, score=8034.850678, test/loss=0.286933, test/num_examples=3581, test/ssim=0.742992, total_duration=8450.185489, train/loss=0.256704, train/ssim=0.754674, validation/loss=0.285458, validation/num_examples=3554, validation/ssim=0.725877
I0204 16:05:42.032145 140379571808000 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.017800824716687202, loss=0.3319406509399414
I0204 16:06:06.068327 140379563415296 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.022690923884510994, loss=0.22038903832435608
I0204 16:06:30.509549 140379571808000 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.028577441349625587, loss=0.2570561170578003
I0204 16:06:47.128112 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:06:48.509600 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:06:49.839926 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:06:51.171086 140584300062528 submission_runner.py:408] Time since start: 8534.39s, 	Step: 34672, 	{'train/ssim': 0.7546633311680385, 'train/loss': 0.2567169666290283, 'validation/ssim': 0.7258422370700267, 'validation/loss': 0.28547949246227844, 'validation/num_examples': 3554, 'test/ssim': 0.7429690772479755, 'test/loss': 0.28694322847580983, 'test/num_examples': 3581, 'score': 8114.963846206665, 'total_duration': 8534.388310909271, 'accumulated_submission_time': 8114.963846206665, 'accumulated_eval_time': 412.0980794429779, 'accumulated_logging_time': 6.058527708053589}
I0204 16:06:51.194425 140379563415296 logging_writer.py:48] [34672] accumulated_eval_time=412.098079, accumulated_logging_time=6.058528, accumulated_submission_time=8114.963846, global_step=34672, preemption_count=0, score=8114.963846, test/loss=0.286943, test/num_examples=3581, test/ssim=0.742969, total_duration=8534.388311, train/loss=0.256717, train/ssim=0.754663, validation/loss=0.285479, validation/num_examples=3554, validation/ssim=0.725842
I0204 16:06:55.910753 140379571808000 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.02533489093184471, loss=0.2438664734363556
I0204 16:07:20.058271 140379563415296 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.0189144778996706, loss=0.22742271423339844
I0204 16:07:44.095902 140379571808000 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.017052287235856056, loss=0.2978193461894989
I0204 16:08:08.077292 140379563415296 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.021086618304252625, loss=0.24869316816329956
I0204 16:08:11.343815 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:08:12.728251 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:08:14.061362 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:08:15.392693 140584300062528 submission_runner.py:408] Time since start: 8618.61s, 	Step: 35015, 	{'train/ssim': 0.7547167369297573, 'train/loss': 0.25660886083330425, 'validation/ssim': 0.7258234147483469, 'validation/loss': 0.2854470342615715, 'validation/num_examples': 3554, 'test/ssim': 0.7429394204002024, 'test/loss': 0.2869227413890149, 'test/num_examples': 3581, 'score': 8195.090363264084, 'total_duration': 8618.609902381897, 'accumulated_submission_time': 8195.090363264084, 'accumulated_eval_time': 416.14691257476807, 'accumulated_logging_time': 6.092074155807495}
I0204 16:08:15.420511 140379571808000 logging_writer.py:48] [35015] accumulated_eval_time=416.146913, accumulated_logging_time=6.092074, accumulated_submission_time=8195.090363, global_step=35015, preemption_count=0, score=8195.090363, test/loss=0.286923, test/num_examples=3581, test/ssim=0.742939, total_duration=8618.609902, train/loss=0.256609, train/ssim=0.754717, validation/loss=0.285447, validation/num_examples=3554, validation/ssim=0.725823
I0204 16:08:33.648099 140379563415296 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.021406501531600952, loss=0.30080878734588623
I0204 16:08:57.450794 140379571808000 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.015460953116416931, loss=0.2311326265335083
I0204 16:09:21.415278 140379563415296 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.01651066169142723, loss=0.2785053849220276
I0204 16:09:35.462511 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:09:36.840981 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:09:38.171398 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:09:39.503576 140584300062528 submission_runner.py:408] Time since start: 8702.72s, 	Step: 35360, 	{'train/ssim': 0.7546516145978656, 'train/loss': 0.2566218546458653, 'validation/ssim': 0.725779999758195, 'validation/loss': 0.2854279715087753, 'validation/num_examples': 3554, 'test/ssim': 0.7429039003595365, 'test/loss': 0.28690225430222005, 'test/num_examples': 3581, 'score': 8275.109664440155, 'total_duration': 8702.720784902573, 'accumulated_submission_time': 8275.109664440155, 'accumulated_eval_time': 420.1879172325134, 'accumulated_logging_time': 6.129887580871582}
I0204 16:09:39.527525 140379571808000 logging_writer.py:48] [35360] accumulated_eval_time=420.187917, accumulated_logging_time=6.129888, accumulated_submission_time=8275.109664, global_step=35360, preemption_count=0, score=8275.109664, test/loss=0.286902, test/num_examples=3581, test/ssim=0.742904, total_duration=8702.720785, train/loss=0.256622, train/ssim=0.754652, validation/loss=0.285428, validation/num_examples=3554, validation/ssim=0.725780
I0204 16:09:47.028696 140379563415296 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.018342984840273857, loss=0.3212434649467468
I0204 16:10:10.961310 140379571808000 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.026686256751418114, loss=0.3153298795223236
I0204 16:10:34.883109 140379563415296 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.017462851479649544, loss=0.21078787744045258
I0204 16:10:59.522016 140379571808000 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.019896486774086952, loss=0.21061116456985474
I0204 16:10:59.527359 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:11:00.856558 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:11:02.185064 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:11:03.513527 140584300062528 submission_runner.py:408] Time since start: 8786.73s, 	Step: 35701, 	{'train/ssim': 0.7548180307660785, 'train/loss': 0.2566397019795009, 'validation/ssim': 0.7259626587120146, 'validation/loss': 0.28544598666885024, 'validation/num_examples': 3554, 'test/ssim': 0.7430810915028973, 'test/loss': 0.28691271941976754, 'test/num_examples': 3581, 'score': 8355.086299180984, 'total_duration': 8786.73073220253, 'accumulated_submission_time': 8355.086299180984, 'accumulated_eval_time': 424.1739959716797, 'accumulated_logging_time': 6.164317607879639}
I0204 16:11:03.542207 140379563415296 logging_writer.py:48] [35701] accumulated_eval_time=424.173996, accumulated_logging_time=6.164318, accumulated_submission_time=8355.086299, global_step=35701, preemption_count=0, score=8355.086299, test/loss=0.286913, test/num_examples=3581, test/ssim=0.743081, total_duration=8786.730732, train/loss=0.256640, train/ssim=0.754818, validation/loss=0.285446, validation/num_examples=3554, validation/ssim=0.725963
I0204 16:11:25.153272 140379571808000 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.020069485530257225, loss=0.24375547468662262
I0204 16:11:48.933591 140379563415296 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.01638093777000904, loss=0.21986883878707886
I0204 16:12:13.184709 140379571808000 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.01659427396953106, loss=0.23557230830192566
I0204 16:12:23.613090 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:12:24.992128 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:12:26.324415 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:12:27.652243 140584300062528 submission_runner.py:408] Time since start: 8870.87s, 	Step: 36044, 	{'train/ssim': 0.7547200066702706, 'train/loss': 0.2566244431904384, 'validation/ssim': 0.7258568690208216, 'validation/loss': 0.28543083950852033, 'validation/num_examples': 3554, 'test/ssim': 0.742981485400377, 'test/loss': 0.28690187933058153, 'test/num_examples': 3581, 'score': 8435.13413977623, 'total_duration': 8870.86947607994, 'accumulated_submission_time': 8435.13413977623, 'accumulated_eval_time': 428.2131233215332, 'accumulated_logging_time': 6.202942609786987}
I0204 16:12:27.675675 140379563415296 logging_writer.py:48] [36044] accumulated_eval_time=428.213123, accumulated_logging_time=6.202943, accumulated_submission_time=8435.134140, global_step=36044, preemption_count=0, score=8435.134140, test/loss=0.286902, test/num_examples=3581, test/ssim=0.742981, total_duration=8870.869476, train/loss=0.256624, train/ssim=0.754720, validation/loss=0.285431, validation/num_examples=3554, validation/ssim=0.725857
I0204 16:12:38.952061 140379571808000 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.016567129641771317, loss=0.3720356822013855
I0204 16:13:00.202240 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:13:01.583947 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:13:02.914150 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:13:04.244239 140584300062528 submission_runner.py:408] Time since start: 8907.46s, 	Step: 36189, 	{'train/ssim': 0.7547260693141392, 'train/loss': 0.25662572043282644, 'validation/ssim': 0.7258640132597074, 'validation/loss': 0.2854322477479161, 'validation/num_examples': 3554, 'test/ssim': 0.7429876212999162, 'test/loss': 0.28690365192378176, 'test/num_examples': 3581, 'score': 8467.644447088242, 'total_duration': 8907.461469173431, 'accumulated_submission_time': 8467.644447088242, 'accumulated_eval_time': 432.25509095191956, 'accumulated_logging_time': 6.2368481159210205}
I0204 16:13:04.269172 140379563415296 logging_writer.py:48] [36189] accumulated_eval_time=432.255091, accumulated_logging_time=6.236848, accumulated_submission_time=8467.644447, global_step=36189, preemption_count=0, score=8467.644447, test/loss=0.286904, test/num_examples=3581, test/ssim=0.742988, total_duration=8907.461469, train/loss=0.256626, train/ssim=0.754726, validation/loss=0.285432, validation/num_examples=3554, validation/ssim=0.725864
I0204 16:13:04.290280 140379571808000 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8467.644447
I0204 16:13:04.338224 140584300062528 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 16:13:04.536845 140584300062528 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2/checkpoint_36189
I0204 16:13:04.537526 140584300062528 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_2/checkpoint_36189.
I0204 16:13:05.098286 140584300062528 submission_runner.py:583] Tuning trial 2/5
I0204 16:13:05.098521 140584300062528 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.2, learning_rate=0.0008445074561975979, one_minus_beta1=0.11042418465, beta2=0.9978504782314613, weight_decay=0.08135402759553023, warmup_factor=0.05)
I0204 16:13:05.104461 140584300062528 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 29.42645001411438, 'total_duration': 33.40965127944946, 'accumulated_submission_time': 29.42645001411438, 'accumulated_eval_time': 3.983088254928589, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (342, {'train/ssim': 0.700493403843471, 'train/loss': 0.3026022570473807, 'validation/ssim': 0.674353982198755, 'validation/loss': 0.33048029756304514, 'validation/num_examples': 3554, 'test/ssim': 0.6928078258080843, 'test/loss': 0.332435537602974, 'test/num_examples': 3581, 'score': 109.55331134796143, 'total_duration': 117.60923790931702, 'accumulated_submission_time': 109.55331134796143, 'accumulated_eval_time': 8.024477005004883, 'accumulated_logging_time': 0.018388986587524414, 'global_step': 342, 'preemption_count': 0}), (681, {'train/ssim': 0.7177139009748187, 'train/loss': 0.28852694375174387, 'validation/ssim': 0.6936591582547833, 'validation/loss': 0.3146172364105585, 'validation/num_examples': 3554, 'test/ssim': 0.7106981999179698, 'test/loss': 0.3170286688315938, 'test/num_examples': 3581, 'score': 189.61023998260498, 'total_duration': 201.74451231956482, 'accumulated_submission_time': 189.61023998260498, 'accumulated_eval_time': 12.066364765167236, 'accumulated_logging_time': 0.04221749305725098, 'global_step': 681, 'preemption_count': 0}), (1020, {'train/ssim': 0.7317164966038295, 'train/loss': 0.2770050082887922, 'validation/ssim': 0.7062299274365152, 'validation/loss': 0.3035240881752954, 'validation/num_examples': 3554, 'test/ssim': 0.7232667720041539, 'test/loss': 0.30580181344465585, 'test/num_examples': 3581, 'score': 269.74872303009033, 'total_duration': 285.9569094181061, 'accumulated_submission_time': 269.74872303009033, 'accumulated_eval_time': 16.104042291641235, 'accumulated_logging_time': 0.06609296798706055, 'global_step': 1020, 'preemption_count': 0}), (1365, {'train/ssim': 0.7347615105765206, 'train/loss': 0.273283737046378, 'validation/ssim': 0.709127740639948, 'validation/loss': 0.2994085944094682, 'validation/num_examples': 3554, 'test/ssim': 0.7263307675274016, 'test/loss': 0.3015255005257784, 'test/num_examples': 3581, 'score': 349.75937604904175, 'total_duration': 370.048823595047, 'accumulated_submission_time': 349.75937604904175, 'accumulated_eval_time': 20.1486337184906, 'accumulated_logging_time': 0.08972287178039551, 'global_step': 1365, 'preemption_count': 0}), (1709, {'train/ssim': 0.7332886287144252, 'train/loss': 0.2724383217947824, 'validation/ssim': 0.7087479968653277, 'validation/loss': 0.2982055114505663, 'validation/num_examples': 3554, 'test/ssim': 0.7256882024923206, 'test/loss': 0.3000804961842886, 'test/num_examples': 3581, 'score': 429.81904101371765, 'total_duration': 454.1902050971985, 'accumulated_submission_time': 429.81904101371765, 'accumulated_eval_time': 24.189027786254883, 'accumulated_logging_time': 0.11821460723876953, 'global_step': 1709, 'preemption_count': 0}), (2053, {'train/ssim': 0.7409915242876325, 'train/loss': 0.26877427101135254, 'validation/ssim': 0.7151846126283765, 'validation/loss': 0.2948922676253869, 'validation/num_examples': 3554, 'test/ssim': 0.7322903622198758, 'test/loss': 0.2967952673943207, 'test/num_examples': 3581, 'score': 509.81245160102844, 'total_duration': 538.2597918510437, 'accumulated_submission_time': 509.81245160102844, 'accumulated_eval_time': 28.227068662643433, 'accumulated_logging_time': 0.14400959014892578, 'global_step': 2053, 'preemption_count': 0}), (2396, {'train/ssim': 0.7421709469386509, 'train/loss': 0.26690559727805, 'validation/ssim': 0.7165991719277575, 'validation/loss': 0.2932297551504467, 'validation/num_examples': 3554, 'test/ssim': 0.7335974451750559, 'test/loss': 0.2949343172407323, 'test/num_examples': 3581, 'score': 589.8710687160492, 'total_duration': 622.399489402771, 'accumulated_submission_time': 589.8710687160492, 'accumulated_eval_time': 32.26940202713013, 'accumulated_logging_time': 0.1705169677734375, 'global_step': 2396, 'preemption_count': 0}), (2739, {'train/ssim': 0.7418599809919085, 'train/loss': 0.26654790128980366, 'validation/ssim': 0.7161163862461312, 'validation/loss': 0.2926901246834553, 'validation/num_examples': 3554, 'test/ssim': 0.7333299199551452, 'test/loss': 0.2943898243332868, 'test/num_examples': 3581, 'score': 670.0183191299438, 'total_duration': 706.627876996994, 'accumulated_submission_time': 670.0183191299438, 'accumulated_eval_time': 36.31421685218811, 'accumulated_logging_time': 0.194258451461792, 'global_step': 2739, 'preemption_count': 0}), (3083, {'train/ssim': 0.7423411096845355, 'train/loss': 0.26642050061907085, 'validation/ssim': 0.7173274034318725, 'validation/loss': 0.29222087183894907, 'validation/num_examples': 3554, 'test/ssim': 0.7344748106325049, 'test/loss': 0.29378121127565626, 'test/num_examples': 3581, 'score': 750.0226106643677, 'total_duration': 790.7108700275421, 'accumulated_submission_time': 750.0226106643677, 'accumulated_eval_time': 40.35602593421936, 'accumulated_logging_time': 0.2186872959136963, 'global_step': 3083, 'preemption_count': 0}), (3425, {'train/ssim': 0.7441543170383998, 'train/loss': 0.26480283055986675, 'validation/ssim': 0.7175930454681345, 'validation/loss': 0.2914524883384039, 'validation/num_examples': 3554, 'test/ssim': 0.7348356015254119, 'test/loss': 0.29307531012199806, 'test/num_examples': 3581, 'score': 830.2108571529388, 'total_duration': 874.9735074043274, 'accumulated_submission_time': 830.2108571529388, 'accumulated_eval_time': 44.39246344566345, 'accumulated_logging_time': 0.24354028701782227, 'global_step': 3425, 'preemption_count': 0}), (3770, {'train/ssim': 0.7439109938485282, 'train/loss': 0.2662832736968994, 'validation/ssim': 0.7177881381453995, 'validation/loss': 0.2921615883951182, 'validation/num_examples': 3554, 'test/ssim': 0.7350305867774365, 'test/loss': 0.2938836467096307, 'test/num_examples': 3581, 'score': 910.250020980835, 'total_duration': 959.0884766578674, 'accumulated_submission_time': 910.250020980835, 'accumulated_eval_time': 48.43196511268616, 'accumulated_logging_time': 0.2675139904022217, 'global_step': 3770, 'preemption_count': 0}), (4112, {'train/ssim': 0.7449028151375907, 'train/loss': 0.2645629644393921, 'validation/ssim': 0.7190284192327308, 'validation/loss': 0.2907478877782956, 'validation/num_examples': 3554, 'test/ssim': 0.7360385105417481, 'test/loss': 0.29238474871718795, 'test/num_examples': 3581, 'score': 990.3172655105591, 'total_duration': 1043.2327580451965, 'accumulated_submission_time': 990.3172655105591, 'accumulated_eval_time': 52.47136425971985, 'accumulated_logging_time': 0.29250311851501465, 'global_step': 4112, 'preemption_count': 0}), (4455, {'train/ssim': 0.745528153010777, 'train/loss': 0.26326089245932444, 'validation/ssim': 0.7188410203511888, 'validation/loss': 0.2899452256700197, 'validation/num_examples': 3554, 'test/ssim': 0.7361167773492041, 'test/loss': 0.2916109095202981, 'test/num_examples': 3581, 'score': 1070.4398555755615, 'total_duration': 1127.4331729412079, 'accumulated_submission_time': 1070.4398555755615, 'accumulated_eval_time': 56.51176953315735, 'accumulated_logging_time': 0.3179206848144531, 'global_step': 4455, 'preemption_count': 0}), (4800, {'train/ssim': 0.7455744062151227, 'train/loss': 0.2641662529536656, 'validation/ssim': 0.7195378584209693, 'validation/loss': 0.2902841648494654, 'validation/num_examples': 3554, 'test/ssim': 0.7369595772392488, 'test/loss': 0.29179021414016687, 'test/num_examples': 3581, 'score': 1150.5182836055756, 'total_duration': 1211.5923788547516, 'accumulated_submission_time': 1150.5182836055756, 'accumulated_eval_time': 60.554898500442505, 'accumulated_logging_time': 0.3427619934082031, 'global_step': 4800, 'preemption_count': 0}), (5145, {'train/ssim': 0.7470813478742327, 'train/loss': 0.2624162094933646, 'validation/ssim': 0.7207821237953714, 'validation/loss': 0.288812829459324, 'validation/num_examples': 3554, 'test/ssim': 0.7380477449342013, 'test/loss': 0.2903629016423485, 'test/num_examples': 3581, 'score': 1230.709332704544, 'total_duration': 1295.8631434440613, 'accumulated_submission_time': 1230.709332704544, 'accumulated_eval_time': 64.59666466712952, 'accumulated_logging_time': 0.3678746223449707, 'global_step': 5145, 'preemption_count': 0}), (5487, {'train/ssim': 0.7463224955967495, 'train/loss': 0.2628247056688581, 'validation/ssim': 0.7197903797877392, 'validation/loss': 0.2894811249208638, 'validation/num_examples': 3554, 'test/ssim': 0.737104043585067, 'test/loss': 0.29098160484588803, 'test/num_examples': 3581, 'score': 1310.8590772151947, 'total_duration': 1380.0955708026886, 'accumulated_submission_time': 1310.8590772151947, 'accumulated_eval_time': 68.63917136192322, 'accumulated_logging_time': 0.39591407775878906, 'global_step': 5487, 'preemption_count': 0}), (5832, {'train/ssim': 0.746668951851981, 'train/loss': 0.2629751477922712, 'validation/ssim': 0.7207214664594471, 'validation/loss': 0.2891875585278032, 'validation/num_examples': 3554, 'test/ssim': 0.7379295266030788, 'test/loss': 0.2907189883456088, 'test/num_examples': 3581, 'score': 1390.823716878891, 'total_duration': 1464.1412785053253, 'accumulated_submission_time': 1390.823716878891, 'accumulated_eval_time': 72.6823296546936, 'accumulated_logging_time': 0.42113780975341797, 'global_step': 5832, 'preemption_count': 0}), (6176, {'train/ssim': 0.7470532144818988, 'train/loss': 0.2630742447716849, 'validation/ssim': 0.7212173728105655, 'validation/loss': 0.28917158703221724, 'validation/num_examples': 3554, 'test/ssim': 0.7384506690039444, 'test/loss': 0.290686297636397, 'test/num_examples': 3581, 'score': 1470.9608535766602, 'total_duration': 1548.361647605896, 'accumulated_submission_time': 1470.9608535766602, 'accumulated_eval_time': 76.7279725074768, 'accumulated_logging_time': 0.4464681148529053, 'global_step': 6176, 'preemption_count': 0}), (6517, {'train/ssim': 0.7485293660845075, 'train/loss': 0.26226443903786795, 'validation/ssim': 0.7220091468240011, 'validation/loss': 0.2888351208585397, 'validation/num_examples': 3554, 'test/ssim': 0.739124458950014, 'test/loss': 0.2903405056090303, 'test/num_examples': 3581, 'score': 1551.1067745685577, 'total_duration': 1632.5861072540283, 'accumulated_submission_time': 1551.1067745685577, 'accumulated_eval_time': 80.76854872703552, 'accumulated_logging_time': 0.47170019149780273, 'global_step': 6517, 'preemption_count': 0}), (6862, {'train/ssim': 0.7489062036786761, 'train/loss': 0.26138101305280415, 'validation/ssim': 0.7224099798422552, 'validation/loss': 0.28804355292891815, 'validation/num_examples': 3554, 'test/ssim': 0.7395610622905613, 'test/loss': 0.2895691207719562, 'test/num_examples': 3581, 'score': 1631.1339271068573, 'total_duration': 1716.6855008602142, 'accumulated_submission_time': 1631.1339271068573, 'accumulated_eval_time': 84.80290365219116, 'accumulated_logging_time': 0.4968986511230469, 'global_step': 6862, 'preemption_count': 0}), (7206, {'train/ssim': 0.7486821583339146, 'train/loss': 0.26164140020098003, 'validation/ssim': 0.7226811174468908, 'validation/loss': 0.2881173137606834, 'validation/num_examples': 3554, 'test/ssim': 0.7398471315624128, 'test/loss': 0.289598198118106, 'test/num_examples': 3581, 'score': 1711.1187720298767, 'total_duration': 1800.7515134811401, 'accumulated_submission_time': 1711.1187720298767, 'accumulated_eval_time': 88.84633111953735, 'accumulated_logging_time': 0.5218157768249512, 'global_step': 7206, 'preemption_count': 0}), (7549, {'train/ssim': 0.750164372580392, 'train/loss': 0.26114661352975027, 'validation/ssim': 0.7235968165271525, 'validation/loss': 0.28792357780186056, 'validation/num_examples': 3554, 'test/ssim': 0.7407856514852694, 'test/loss': 0.289402974247766, 'test/num_examples': 3581, 'score': 1791.1784365177155, 'total_duration': 1884.8976328372955, 'accumulated_submission_time': 1791.1784365177155, 'accumulated_eval_time': 92.88967680931091, 'accumulated_logging_time': 0.5519485473632812, 'global_step': 7549, 'preemption_count': 0}), (7892, {'train/ssim': 0.748753547668457, 'train/loss': 0.26151558331080843, 'validation/ssim': 0.7221031210431907, 'validation/loss': 0.2880484130721986, 'validation/num_examples': 3554, 'test/ssim': 0.7394183003612818, 'test/loss': 0.2894897290495846, 'test/num_examples': 3581, 'score': 1871.2054042816162, 'total_duration': 1969.0074808597565, 'accumulated_submission_time': 1871.2054042816162, 'accumulated_eval_time': 96.92876887321472, 'accumulated_logging_time': 0.5830910205841064, 'global_step': 7892, 'preemption_count': 0}), (8237, {'train/ssim': 0.7499610355922154, 'train/loss': 0.26050329208374023, 'validation/ssim': 0.7234105167592854, 'validation/loss': 0.28720492919509705, 'validation/num_examples': 3554, 'test/ssim': 0.740555282545902, 'test/loss': 0.288724582377042, 'test/num_examples': 3581, 'score': 1951.2375724315643, 'total_duration': 2053.123046398163, 'accumulated_submission_time': 1951.2375724315643, 'accumulated_eval_time': 100.9730007648468, 'accumulated_logging_time': 0.609849214553833, 'global_step': 8237, 'preemption_count': 0}), (8578, {'train/ssim': 0.7500072887965611, 'train/loss': 0.26074894836970736, 'validation/ssim': 0.7232730588553391, 'validation/loss': 0.2874911624391091, 'validation/num_examples': 3554, 'test/ssim': 0.7405435561601159, 'test/loss': 0.28888728597982405, 'test/num_examples': 3581, 'score': 2031.3805038928986, 'total_duration': 2137.3491065502167, 'accumulated_submission_time': 2031.3805038928986, 'accumulated_eval_time': 105.01745820045471, 'accumulated_logging_time': 0.6357917785644531, 'global_step': 8578, 'preemption_count': 0}), (8924, {'train/ssim': 0.7499869891575405, 'train/loss': 0.26059075764247347, 'validation/ssim': 0.7225968978615644, 'validation/loss': 0.2881504417337859, 'validation/num_examples': 3554, 'test/ssim': 0.7398159748280857, 'test/loss': 0.2895903237136973, 'test/num_examples': 3581, 'score': 2111.464605331421, 'total_duration': 2221.5131690502167, 'accumulated_submission_time': 2111.464605331421, 'accumulated_eval_time': 109.05753564834595, 'accumulated_logging_time': 0.6633491516113281, 'global_step': 8924, 'preemption_count': 0}), (9268, {'train/ssim': 0.7488860402788434, 'train/loss': 0.26120117732456755, 'validation/ssim': 0.7222374876899268, 'validation/loss': 0.2878062989380364, 'validation/num_examples': 3554, 'test/ssim': 0.739492612922368, 'test/loss': 0.28924732692945404, 'test/num_examples': 3581, 'score': 2191.5632648468018, 'total_duration': 2305.6930689811707, 'accumulated_submission_time': 2191.5632648468018, 'accumulated_eval_time': 113.09919476509094, 'accumulated_logging_time': 0.690230131149292, 'global_step': 9268, 'preemption_count': 0}), (9612, {'train/ssim': 0.7509616443089077, 'train/loss': 0.26031036036355154, 'validation/ssim': 0.7241491898433103, 'validation/loss': 0.2872652087106957, 'validation/num_examples': 3554, 'test/ssim': 0.7413944008962231, 'test/loss': 0.28867382485252024, 'test/num_examples': 3581, 'score': 2271.7214958667755, 'total_duration': 2389.9308273792267, 'accumulated_submission_time': 2271.7214958667755, 'accumulated_eval_time': 117.13886761665344, 'accumulated_logging_time': 0.7173893451690674, 'global_step': 9612, 'preemption_count': 0}), (9956, {'train/ssim': 0.7515387535095215, 'train/loss': 0.2596092053822109, 'validation/ssim': 0.7244041155212436, 'validation/loss': 0.28693614438067144, 'validation/num_examples': 3554, 'test/ssim': 0.741594158514556, 'test/loss': 0.28842941152087404, 'test/num_examples': 3581, 'score': 2352.0011718273163, 'total_duration': 2474.2932760715485, 'accumulated_submission_time': 2352.0011718273163, 'accumulated_eval_time': 121.1830849647522, 'accumulated_logging_time': 0.7429046630859375, 'global_step': 9956, 'preemption_count': 0}), (10299, {'train/ssim': 0.7496851512363979, 'train/loss': 0.2598560537610735, 'validation/ssim': 0.7228082711601365, 'validation/loss': 0.28672064940581915, 'validation/num_examples': 3554, 'test/ssim': 0.7400625698129014, 'test/loss': 0.28818404371596623, 'test/num_examples': 3581, 'score': 2432.098387002945, 'total_duration': 2558.470093727112, 'accumulated_submission_time': 2432.098387002945, 'accumulated_eval_time': 125.2218165397644, 'accumulated_logging_time': 0.7710072994232178, 'global_step': 10299, 'preemption_count': 0}), (10645, {'train/ssim': 0.7517651149204799, 'train/loss': 0.2603922741753714, 'validation/ssim': 0.7249827301763858, 'validation/loss': 0.2872193894093803, 'validation/num_examples': 3554, 'test/ssim': 0.7421747509642908, 'test/loss': 0.288655042182264, 'test/num_examples': 3581, 'score': 2512.111428976059, 'total_duration': 2642.562907934189, 'accumulated_submission_time': 2512.111428976059, 'accumulated_eval_time': 129.26106452941895, 'accumulated_logging_time': 0.798546552658081, 'global_step': 10645, 'preemption_count': 0}), (10985, {'train/ssim': 0.7508465221949986, 'train/loss': 0.2591175522123064, 'validation/ssim': 0.7235672091525394, 'validation/loss': 0.2865561430012838, 'validation/num_examples': 3554, 'test/ssim': 0.7408287391353672, 'test/loss': 0.2879923309436959, 'test/num_examples': 3581, 'score': 2592.179505586624, 'total_duration': 2726.715437889099, 'accumulated_submission_time': 2592.179505586624, 'accumulated_eval_time': 133.30129551887512, 'accumulated_logging_time': 0.8306035995483398, 'global_step': 10985, 'preemption_count': 0}), (11330, {'train/ssim': 0.7511290822710309, 'train/loss': 0.2594335079193115, 'validation/ssim': 0.7241735077333639, 'validation/loss': 0.2865808902326164, 'validation/num_examples': 3554, 'test/ssim': 0.7414312844701201, 'test/loss': 0.28802597612616937, 'test/num_examples': 3581, 'score': 2672.226739883423, 'total_duration': 2810.844916820526, 'accumulated_submission_time': 2672.226739883423, 'accumulated_eval_time': 137.34243512153625, 'accumulated_logging_time': 0.8594722747802734, 'global_step': 11330, 'preemption_count': 0}), (11674, {'train/ssim': 0.750849860055106, 'train/loss': 0.26001875741141184, 'validation/ssim': 0.7243757446495146, 'validation/loss': 0.2867924696150025, 'validation/num_examples': 3554, 'test/ssim': 0.7415087331576375, 'test/loss': 0.2882127801788083, 'test/num_examples': 3581, 'score': 2752.375296831131, 'total_duration': 2895.079016685486, 'accumulated_submission_time': 2752.375296831131, 'accumulated_eval_time': 141.38680863380432, 'accumulated_logging_time': 0.8880980014801025, 'global_step': 11674, 'preemption_count': 0}), (12016, {'train/ssim': 0.7508232252938407, 'train/loss': 0.2597970792225429, 'validation/ssim': 0.7236260117341375, 'validation/loss': 0.28707080297947735, 'validation/num_examples': 3554, 'test/ssim': 0.740762539597005, 'test/loss': 0.288554652048136, 'test/num_examples': 3581, 'score': 2832.403507232666, 'total_duration': 2979.1975667476654, 'accumulated_submission_time': 2832.403507232666, 'accumulated_eval_time': 145.4340295791626, 'accumulated_logging_time': 0.9185914993286133, 'global_step': 12016, 'preemption_count': 0}), (12361, {'train/ssim': 0.7515483583722796, 'train/loss': 0.2597310883658273, 'validation/ssim': 0.7247749976918613, 'validation/loss': 0.28688409104398216, 'validation/num_examples': 3554, 'test/ssim': 0.7418716375270525, 'test/loss': 0.28835036068181025, 'test/num_examples': 3581, 'score': 2912.47318983078, 'total_duration': 3063.34952712059, 'accumulated_submission_time': 2912.47318983078, 'accumulated_eval_time': 149.47599267959595, 'accumulated_logging_time': 0.9461815357208252, 'global_step': 12361, 'preemption_count': 0}), (12706, {'train/ssim': 0.75163391658238, 'train/loss': 0.25952419212886263, 'validation/ssim': 0.7246345172253095, 'validation/loss': 0.2866389199999121, 'validation/num_examples': 3554, 'test/ssim': 0.7418361174863864, 'test/loss': 0.2879713666202702, 'test/num_examples': 3581, 'score': 2992.6348898410797, 'total_duration': 3147.590842962265, 'accumulated_submission_time': 2992.6348898410797, 'accumulated_eval_time': 153.514493227005, 'accumulated_logging_time': 0.9745748043060303, 'global_step': 12706, 'preemption_count': 0}), (13047, {'train/ssim': 0.7500644411359515, 'train/loss': 0.26224068232945036, 'validation/ssim': 0.7231141682347355, 'validation/loss': 0.28903618996641106, 'validation/num_examples': 3554, 'test/ssim': 0.7402398291329237, 'test/loss': 0.29055839821933466, 'test/num_examples': 3581, 'score': 3072.810255050659, 'total_duration': 3231.8504090309143, 'accumulated_submission_time': 3072.810255050659, 'accumulated_eval_time': 157.55807256698608, 'accumulated_logging_time': 1.0025804042816162, 'global_step': 13047, 'preemption_count': 0}), (13393, {'train/ssim': 0.7512751306806292, 'train/loss': 0.2590423311505999, 'validation/ssim': 0.7241309857730726, 'validation/loss': 0.2862096474153243, 'validation/num_examples': 3554, 'test/ssim': 0.7413110208391511, 'test/loss': 0.2877308734466629, 'test/num_examples': 3581, 'score': 3152.822122335434, 'total_duration': 3315.9444572925568, 'accumulated_submission_time': 3152.822122335434, 'accumulated_eval_time': 161.60008311271667, 'accumulated_logging_time': 1.0305194854736328, 'global_step': 13393, 'preemption_count': 0}), (13736, {'train/ssim': 0.7505890301295689, 'train/loss': 0.2599429743630545, 'validation/ssim': 0.7239430373346933, 'validation/loss': 0.28687146841037386, 'validation/num_examples': 3554, 'test/ssim': 0.7411356022889906, 'test/loss': 0.28825896986700644, 'test/num_examples': 3581, 'score': 3232.913407802582, 'total_duration': 3400.114282131195, 'accumulated_submission_time': 3232.913407802582, 'accumulated_eval_time': 165.63811612129211, 'accumulated_logging_time': 1.0580720901489258, 'global_step': 13736, 'preemption_count': 0}), (14081, {'train/ssim': 0.7513887541634696, 'train/loss': 0.2593295063291277, 'validation/ssim': 0.7242169914181205, 'validation/loss': 0.28648032133137835, 'validation/num_examples': 3554, 'test/ssim': 0.7414687134573094, 'test/loss': 0.2879141664012322, 'test/num_examples': 3581, 'score': 3313.1099050045013, 'total_duration': 3484.3979263305664, 'accumulated_submission_time': 3313.1099050045013, 'accumulated_eval_time': 169.68113112449646, 'accumulated_logging_time': 1.0890719890594482, 'global_step': 14081, 'preemption_count': 0}), (14426, {'train/ssim': 0.7521964481898716, 'train/loss': 0.2591852971485683, 'validation/ssim': 0.7246845268975098, 'validation/loss': 0.28662739647997854, 'validation/num_examples': 3554, 'test/ssim': 0.7418051652820441, 'test/loss': 0.28811777600094246, 'test/num_examples': 3581, 'score': 3393.1668939590454, 'total_duration': 3568.5471363067627, 'accumulated_submission_time': 3393.1668939590454, 'accumulated_eval_time': 173.728289604187, 'accumulated_logging_time': 1.1212973594665527, 'global_step': 14426, 'preemption_count': 0}), (14769, {'train/ssim': 0.7512100083487374, 'train/loss': 0.2590839522225516, 'validation/ssim': 0.7241107208646947, 'validation/loss': 0.2862400447778911, 'validation/num_examples': 3554, 'test/ssim': 0.7413695164147585, 'test/loss': 0.2876715938394478, 'test/num_examples': 3581, 'score': 3473.188450574875, 'total_duration': 3652.6521632671356, 'accumulated_submission_time': 3473.188450574875, 'accumulated_eval_time': 177.77133631706238, 'accumulated_logging_time': 1.1494691371917725, 'global_step': 14769, 'preemption_count': 0}), (15112, {'train/ssim': 0.751319340297154, 'train/loss': 0.2589912414550781, 'validation/ssim': 0.7240003286349888, 'validation/loss': 0.28620248600278736, 'validation/num_examples': 3554, 'test/ssim': 0.7413103390725356, 'test/loss': 0.2875662608973576, 'test/num_examples': 3581, 'score': 3553.326792240143, 'total_duration': 3736.8771603107452, 'accumulated_submission_time': 3553.326792240143, 'accumulated_eval_time': 181.81732654571533, 'accumulated_logging_time': 1.1774797439575195, 'global_step': 15112, 'preemption_count': 0}), (15457, {'train/ssim': 0.7521231515066964, 'train/loss': 0.2582509858267648, 'validation/ssim': 0.7244947237048045, 'validation/loss': 0.28593206969150076, 'validation/num_examples': 3554, 'test/ssim': 0.7416795156948129, 'test/loss': 0.2873466638705145, 'test/num_examples': 3581, 'score': 3633.5277137756348, 'total_duration': 3821.1590161323547, 'accumulated_submission_time': 3633.5277137756348, 'accumulated_eval_time': 185.85540199279785, 'accumulated_logging_time': 1.2082180976867676, 'global_step': 15457, 'preemption_count': 0}), (15801, {'train/ssim': 0.7514749254499163, 'train/loss': 0.25869577271597727, 'validation/ssim': 0.7243029283685636, 'validation/loss': 0.28592387785989376, 'validation/num_examples': 3554, 'test/ssim': 0.7415334131091176, 'test/loss': 0.2873067805235095, 'test/num_examples': 3581, 'score': 3713.646933078766, 'total_duration': 3905.3090555667877, 'accumulated_submission_time': 3713.646933078766, 'accumulated_eval_time': 189.84543323516846, 'accumulated_logging_time': 1.2363996505737305, 'global_step': 15801, 'preemption_count': 0}), (16143, {'train/ssim': 0.7512297630310059, 'train/loss': 0.25882807799748014, 'validation/ssim': 0.7240081598199212, 'validation/loss': 0.2860556512853035, 'validation/num_examples': 3554, 'test/ssim': 0.74123561745148, 'test/loss': 0.28744903112782744, 'test/num_examples': 3581, 'score': 3793.65927529335, 'total_duration': 3989.4083540439606, 'accumulated_submission_time': 3793.65927529335, 'accumulated_eval_time': 193.8857979774475, 'accumulated_logging_time': 1.270770788192749, 'global_step': 16143, 'preemption_count': 0}), (16488, {'train/ssim': 0.7530438559395927, 'train/loss': 0.2580648149762835, 'validation/ssim': 0.7251870966252814, 'validation/loss': 0.28587718270236884, 'validation/num_examples': 3554, 'test/ssim': 0.7423863713217328, 'test/loss': 0.28728680476167623, 'test/num_examples': 3581, 'score': 3873.663761138916, 'total_duration': 4073.5015137195587, 'accumulated_submission_time': 3873.663761138916, 'accumulated_eval_time': 197.93269228935242, 'accumulated_logging_time': 1.299825668334961, 'global_step': 16488, 'preemption_count': 0}), (16833, {'train/ssim': 0.7522469248090472, 'train/loss': 0.258419258253915, 'validation/ssim': 0.7247790506735369, 'validation/loss': 0.2858986154190261, 'validation/num_examples': 3554, 'test/ssim': 0.7419785385323583, 'test/loss': 0.2872385356853009, 'test/num_examples': 3581, 'score': 3953.843817949295, 'total_duration': 4157.771581888199, 'accumulated_submission_time': 3953.843817949295, 'accumulated_eval_time': 201.97663283348083, 'accumulated_logging_time': 1.3333888053894043, 'global_step': 16833, 'preemption_count': 0}), (17177, {'train/ssim': 0.7513459750584194, 'train/loss': 0.25871615750449045, 'validation/ssim': 0.724141770826006, 'validation/loss': 0.2860677587093768, 'validation/num_examples': 3554, 'test/ssim': 0.7413751069010053, 'test/loss': 0.28739568289016687, 'test/num_examples': 3581, 'score': 4033.999075651169, 'total_duration': 4242.0093314647675, 'accumulated_submission_time': 4033.999075651169, 'accumulated_eval_time': 206.0151960849762, 'accumulated_logging_time': 1.3643596172332764, 'global_step': 17177, 'preemption_count': 0}), (17522, {'train/ssim': 0.7527370452880859, 'train/loss': 0.2583299194063459, 'validation/ssim': 0.7250032698631823, 'validation/loss': 0.28616877412554514, 'validation/num_examples': 3554, 'test/ssim': 0.742186750056723, 'test/loss': 0.2876077123075782, 'test/num_examples': 3581, 'score': 4114.166547060013, 'total_duration': 4326.265980958939, 'accumulated_submission_time': 4114.166547060013, 'accumulated_eval_time': 210.06202054023743, 'accumulated_logging_time': 1.3937888145446777, 'global_step': 17522, 'preemption_count': 0}), (17869, {'train/ssim': 0.752519062587193, 'train/loss': 0.25849527972085135, 'validation/ssim': 0.725203858108821, 'validation/loss': 0.2860077539721968, 'validation/num_examples': 3554, 'test/ssim': 0.7423210580799707, 'test/loss': 0.2874424179916574, 'test/num_examples': 3581, 'score': 4194.325728654861, 'total_duration': 4410.5075969696045, 'accumulated_submission_time': 4194.325728654861, 'accumulated_eval_time': 214.1040050983429, 'accumulated_logging_time': 1.4217588901519775, 'global_step': 17869, 'preemption_count': 0}), (18213, {'train/ssim': 0.7517549651009696, 'train/loss': 0.2586789812360491, 'validation/ssim': 0.7244219074238534, 'validation/loss': 0.2860423760529509, 'validation/num_examples': 3554, 'test/ssim': 0.7415589111805362, 'test/loss': 0.28744234981499583, 'test/num_examples': 3581, 'score': 4274.364299535751, 'total_duration': 4494.629780292511, 'accumulated_submission_time': 4274.364299535751, 'accumulated_eval_time': 218.1460461616516, 'accumulated_logging_time': 1.4510364532470703, 'global_step': 18213, 'preemption_count': 0}), (18541, {'train/ssim': 0.7444351060049874, 'train/loss': 0.26171806880405973, 'validation/ssim': 0.7190021091991418, 'validation/loss': 0.2888652090953855, 'validation/num_examples': 3554, 'test/ssim': 0.7355785226062902, 'test/loss': 0.290273419774068, 'test/num_examples': 3581, 'score': 4351.388922452927, 'total_duration': 4578.803955078125, 'accumulated_submission_time': 4351.388922452927, 'accumulated_eval_time': 222.18551421165466, 'accumulated_logging_time': 4.549318790435791, 'global_step': 18541, 'preemption_count': 0}), (18885, {'train/ssim': 0.7527740342276437, 'train/loss': 0.25812794481004986, 'validation/ssim': 0.7252524251943233, 'validation/loss': 0.28576132925159153, 'validation/num_examples': 3554, 'test/ssim': 0.7424356630480313, 'test/loss': 0.28716350726926837, 'test/num_examples': 3581, 'score': 4431.485432386398, 'total_duration': 4662.9877717494965, 'accumulated_submission_time': 4431.485432386398, 'accumulated_eval_time': 226.23116660118103, 'accumulated_logging_time': 4.578796863555908, 'global_step': 18885, 'preemption_count': 0}), (19230, {'train/ssim': 0.752542359488351, 'train/loss': 0.2582859822681972, 'validation/ssim': 0.7250183826762099, 'validation/loss': 0.28583660136465955, 'validation/num_examples': 3554, 'test/ssim': 0.7422182476743577, 'test/loss': 0.2871925846154182, 'test/num_examples': 3581, 'score': 4511.616227388382, 'total_duration': 4747.201381921768, 'accumulated_submission_time': 4511.616227388382, 'accumulated_eval_time': 230.27187418937683, 'accumulated_logging_time': 4.607800006866455, 'global_step': 19230, 'preemption_count': 0}), (19570, {'train/ssim': 0.7528716496058873, 'train/loss': 0.25794635500226704, 'validation/ssim': 0.7250105514912775, 'validation/loss': 0.28573562029579347, 'validation/num_examples': 3554, 'test/ssim': 0.742229496823513, 'test/loss': 0.2871527694450747, 'test/num_examples': 3581, 'score': 4591.7536997795105, 'total_duration': 4831.418623209, 'accumulated_submission_time': 4591.7536997795105, 'accumulated_eval_time': 234.31031441688538, 'accumulated_logging_time': 4.636163949966431, 'global_step': 19570, 'preemption_count': 0}), (19916, {'train/ssim': 0.7501134191240583, 'train/loss': 0.2603518622262137, 'validation/ssim': 0.723229231697559, 'validation/loss': 0.2876773763387205, 'validation/num_examples': 3554, 'test/ssim': 0.7400381625680675, 'test/loss': 0.2893246733519792, 'test/num_examples': 3581, 'score': 4671.819234609604, 'total_duration': 4915.573646783829, 'accumulated_submission_time': 4671.819234609604, 'accumulated_eval_time': 238.3534197807312, 'accumulated_logging_time': 4.670209646224976, 'global_step': 19916, 'preemption_count': 0}), (20260, {'train/ssim': 0.7525191988263812, 'train/loss': 0.2582253898893084, 'validation/ssim': 0.7247402382218978, 'validation/loss': 0.2858264689104706, 'validation/num_examples': 3554, 'test/ssim': 0.7419907421547752, 'test/loss': 0.28716814328225354, 'test/num_examples': 3581, 'score': 4751.896664619446, 'total_duration': 4999.735841989517, 'accumulated_submission_time': 4751.896664619446, 'accumulated_eval_time': 242.39756178855896, 'accumulated_logging_time': 4.698517560958862, 'global_step': 20260, 'preemption_count': 0}), (20601, {'train/ssim': 0.7524471964154925, 'train/loss': 0.2585275002888271, 'validation/ssim': 0.7248305029324353, 'validation/loss': 0.2860808793788689, 'validation/num_examples': 3554, 'test/ssim': 0.742039692997766, 'test/loss': 0.2874492697461428, 'test/num_examples': 3581, 'score': 4831.882543325424, 'total_duration': 5083.755587100983, 'accumulated_submission_time': 4831.882543325424, 'accumulated_eval_time': 246.3901126384735, 'accumulated_logging_time': 4.727694749832153, 'global_step': 20601, 'preemption_count': 0}), (20944, {'train/ssim': 0.7533929007393974, 'train/loss': 0.2577303307397025, 'validation/ssim': 0.7254286955499085, 'validation/loss': 0.28577096366989657, 'validation/num_examples': 3554, 'test/ssim': 0.7425531314358769, 'test/loss': 0.28725748879721097, 'test/num_examples': 3581, 'score': 4911.99870967865, 'total_duration': 5167.955820322037, 'accumulated_submission_time': 4911.99870967865, 'accumulated_eval_time': 250.43258547782898, 'accumulated_logging_time': 4.757020711898804, 'global_step': 20944, 'preemption_count': 0}), (21288, {'train/ssim': 0.7532256671360561, 'train/loss': 0.25794497558048796, 'validation/ssim': 0.7253845249191052, 'validation/loss': 0.2858033360023477, 'validation/num_examples': 3554, 'test/ssim': 0.7425597445720469, 'test/loss': 0.2872337633189926, 'test/num_examples': 3581, 'score': 4992.026699781418, 'total_duration': 5252.0716252326965, 'accumulated_submission_time': 4992.026699781418, 'accumulated_eval_time': 254.47485995292664, 'accumulated_logging_time': 4.789958953857422, 'global_step': 21288, 'preemption_count': 0}), (21630, {'train/ssim': 0.7525844573974609, 'train/loss': 0.25794517993927, 'validation/ssim': 0.7247651056687887, 'validation/loss': 0.28567051498421675, 'validation/num_examples': 3554, 'test/ssim': 0.7420083999101159, 'test/loss': 0.2870563335573164, 'test/num_examples': 3581, 'score': 5071.9920909404755, 'total_duration': 5336.118559122086, 'accumulated_submission_time': 5071.9920909404755, 'accumulated_eval_time': 258.51404643058777, 'accumulated_logging_time': 4.820429563522339, 'global_step': 21630, 'preemption_count': 0}), (21973, {'train/ssim': 0.7536664690290179, 'train/loss': 0.2574006829942976, 'validation/ssim': 0.7253517575926772, 'validation/loss': 0.2856152501747591, 'validation/num_examples': 3554, 'test/ssim': 0.7425326102607512, 'test/loss': 0.28703267625575957, 'test/num_examples': 3581, 'score': 5151.954606056213, 'total_duration': 5420.165975809097, 'accumulated_submission_time': 5151.954606056213, 'accumulated_eval_time': 262.5574164390564, 'accumulated_logging_time': 4.8497161865234375, 'global_step': 21973, 'preemption_count': 0}), (22316, {'train/ssim': 0.7529209681919643, 'train/loss': 0.25769971098218647, 'validation/ssim': 0.724979776308385, 'validation/loss': 0.28566709742763435, 'validation/num_examples': 3554, 'test/ssim': 0.7421553206157497, 'test/loss': 0.28708084306714254, 'test/num_examples': 3581, 'score': 5231.9191353321075, 'total_duration': 5504.221770524979, 'accumulated_submission_time': 5231.9191353321075, 'accumulated_eval_time': 266.60148763656616, 'accumulated_logging_time': 4.884214401245117, 'global_step': 22316, 'preemption_count': 0}), (22658, {'train/ssim': 0.7528862953186035, 'train/loss': 0.2577470200402396, 'validation/ssim': 0.7251463607247116, 'validation/loss': 0.28557077041823475, 'validation/num_examples': 3554, 'test/ssim': 0.7423250805030019, 'test/loss': 0.28694200129590197, 'test/num_examples': 3581, 'score': 5311.92449259758, 'total_duration': 5588.317686080933, 'accumulated_submission_time': 5311.92449259758, 'accumulated_eval_time': 270.6449613571167, 'accumulated_logging_time': 4.9190685749053955, 'global_step': 22658, 'preemption_count': 0}), (23000, {'train/ssim': 0.7542593819754464, 'train/loss': 0.2572645630155291, 'validation/ssim': 0.7257499115213492, 'validation/loss': 0.28568277697115046, 'validation/num_examples': 3554, 'test/ssim': 0.7428951737468584, 'test/loss': 0.2871562123664828, 'test/num_examples': 3581, 'score': 5391.978044509888, 'total_duration': 5672.452279090881, 'accumulated_submission_time': 5391.978044509888, 'accumulated_eval_time': 274.68395590782166, 'accumulated_logging_time': 4.949132919311523, 'global_step': 23000, 'preemption_count': 0}), (23344, {'train/ssim': 0.7536674227033343, 'train/loss': 0.2575033562523978, 'validation/ssim': 0.725452189104706, 'validation/loss': 0.2856114376241998, 'validation/num_examples': 3554, 'test/ssim': 0.7426551918982128, 'test/loss': 0.2870301878076131, 'test/num_examples': 3581, 'score': 5472.120784044266, 'total_duration': 5756.679520845413, 'accumulated_submission_time': 5472.120784044266, 'accumulated_eval_time': 278.72428584098816, 'accumulated_logging_time': 4.980362415313721, 'global_step': 23344, 'preemption_count': 0}), (23689, {'train/ssim': 0.7536218506949288, 'train/loss': 0.2578081062861851, 'validation/ssim': 0.7255891661464196, 'validation/loss': 0.28583452335286824, 'validation/num_examples': 3554, 'test/ssim': 0.7427696605129503, 'test/loss': 0.2871937095303337, 'test/num_examples': 3581, 'score': 5552.1640820503235, 'total_duration': 5840.803641319275, 'accumulated_submission_time': 5552.1640820503235, 'accumulated_eval_time': 282.7625916004181, 'accumulated_logging_time': 5.010173559188843, 'global_step': 23689, 'preemption_count': 0}), (24030, {'train/ssim': 0.7539426939828056, 'train/loss': 0.2571692637034825, 'validation/ssim': 0.7254523264939153, 'validation/loss': 0.28561801513259705, 'validation/num_examples': 3554, 'test/ssim': 0.7426042639320372, 'test/loss': 0.28708009312386557, 'test/num_examples': 3581, 'score': 5632.201220989227, 'total_duration': 5924.926100969315, 'accumulated_submission_time': 5632.201220989227, 'accumulated_eval_time': 286.80222272872925, 'accumulated_logging_time': 5.042935132980347, 'global_step': 24030, 'preemption_count': 0}), (24375, {'train/ssim': 0.7535826819283622, 'train/loss': 0.2576377051217215, 'validation/ssim': 0.7253617870049592, 'validation/loss': 0.285717347530951, 'validation/num_examples': 3554, 'test/ssim': 0.7425559266790003, 'test/loss': 0.2871609165561296, 'test/num_examples': 3581, 'score': 5712.229027509689, 'total_duration': 6009.039095878601, 'accumulated_submission_time': 5712.229027509689, 'accumulated_eval_time': 290.84347701072693, 'accumulated_logging_time': 5.074441194534302, 'global_step': 24375, 'preemption_count': 0}), (24718, {'train/ssim': 0.7533001899719238, 'train/loss': 0.2575099127633231, 'validation/ssim': 0.7252187648380346, 'validation/loss': 0.28556371204760483, 'validation/num_examples': 3554, 'test/ssim': 0.7423800308922088, 'test/loss': 0.28695106879188775, 'test/num_examples': 3581, 'score': 5792.354554653168, 'total_duration': 6093.25949716568, 'accumulated_submission_time': 5792.354554653168, 'accumulated_eval_time': 294.8886339664459, 'accumulated_logging_time': 5.111849069595337, 'global_step': 24718, 'preemption_count': 0}), (25057, {'train/ssim': 0.7541554995945522, 'train/loss': 0.2570937190737043, 'validation/ssim': 0.7256698136123031, 'validation/loss': 0.28562282375492404, 'validation/num_examples': 3554, 'test/ssim': 0.7427837730818906, 'test/loss': 0.28709458066444427, 'test/num_examples': 3581, 'score': 5872.473770856857, 'total_duration': 6177.465390920639, 'accumulated_submission_time': 5872.473770856857, 'accumulated_eval_time': 298.93243408203125, 'accumulated_logging_time': 5.142282724380493, 'global_step': 25057, 'preemption_count': 0}), (25403, {'train/ssim': 0.7537097930908203, 'train/loss': 0.25731371130262104, 'validation/ssim': 0.7254681949475943, 'validation/loss': 0.28553020625417663, 'validation/num_examples': 3554, 'test/ssim': 0.7426374659662106, 'test/loss': 0.2869819187312378, 'test/num_examples': 3581, 'score': 5952.507550954819, 'total_duration': 6261.5853390693665, 'accumulated_submission_time': 5952.507550954819, 'accumulated_eval_time': 302.9748706817627, 'accumulated_logging_time': 5.173599481582642, 'global_step': 25403, 'preemption_count': 0}), (25746, {'train/ssim': 0.7538211005074638, 'train/loss': 0.257412246295384, 'validation/ssim': 0.7256960549512873, 'validation/loss': 0.28562861127536754, 'validation/num_examples': 3554, 'test/ssim': 0.7428361327579587, 'test/loss': 0.28704351634494557, 'test/num_examples': 3581, 'score': 6032.525489091873, 'total_duration': 6345.692269086838, 'accumulated_submission_time': 6032.525489091873, 'accumulated_eval_time': 307.01959562301636, 'accumulated_logging_time': 5.20525050163269, 'global_step': 25746, 'preemption_count': 0}), (26088, {'train/ssim': 0.7538996423993792, 'train/loss': 0.25713941029139925, 'validation/ssim': 0.725426497322559, 'validation/loss': 0.285577863136167, 'validation/num_examples': 3554, 'test/ssim': 0.7425881060632505, 'test/loss': 0.2870197908667272, 'test/num_examples': 3581, 'score': 6112.56943154335, 'total_duration': 6429.8159165382385, 'accumulated_submission_time': 6112.56943154335, 'accumulated_eval_time': 311.0550262928009, 'accumulated_logging_time': 5.23749852180481, 'global_step': 26088, 'preemption_count': 0}), (26433, {'train/ssim': 0.7542871747698102, 'train/loss': 0.25722943033490864, 'validation/ssim': 0.7257701077351224, 'validation/loss': 0.2856593177636554, 'validation/num_examples': 3554, 'test/ssim': 0.7429105134957065, 'test/loss': 0.2871216467990785, 'test/num_examples': 3581, 'score': 6192.580571889877, 'total_duration': 6513.905717372894, 'accumulated_submission_time': 6192.580571889877, 'accumulated_eval_time': 315.09079217910767, 'accumulated_logging_time': 5.267976999282837, 'global_step': 26433, 'preemption_count': 0}), (26776, {'train/ssim': 0.7540904453822544, 'train/loss': 0.25733167784554617, 'validation/ssim': 0.7257306770320414, 'validation/loss': 0.2856416460766038, 'validation/num_examples': 3554, 'test/ssim': 0.7429086727258447, 'test/loss': 0.287038334918668, 'test/num_examples': 3581, 'score': 6272.620399475098, 'total_duration': 6598.033495903015, 'accumulated_submission_time': 6272.620399475098, 'accumulated_eval_time': 319.1351087093353, 'accumulated_logging_time': 5.299068212509155, 'global_step': 26776, 'preemption_count': 0}), (27120, {'train/ssim': 0.7539983476911273, 'train/loss': 0.2578939199447632, 'validation/ssim': 0.7256790186893289, 'validation/loss': 0.2862922011564874, 'validation/num_examples': 3554, 'test/ssim': 0.7427011429680955, 'test/loss': 0.2878444898531311, 'test/num_examples': 3581, 'score': 6352.729802370071, 'total_duration': 6682.2287175655365, 'accumulated_submission_time': 6352.729802370071, 'accumulated_eval_time': 323.1779954433441, 'accumulated_logging_time': 5.3297858238220215, 'global_step': 27120, 'preemption_count': 0}), (27465, {'train/ssim': 0.7527961730957031, 'train/loss': 0.2573528460093907, 'validation/ssim': 0.7244910828907569, 'validation/loss': 0.28572626065590706, 'validation/num_examples': 3554, 'test/ssim': 0.7416571537498254, 'test/loss': 0.2871871645708252, 'test/num_examples': 3581, 'score': 6432.850472688675, 'total_duration': 6766.438841342926, 'accumulated_submission_time': 6432.850472688675, 'accumulated_eval_time': 327.2229354381561, 'accumulated_logging_time': 5.361184120178223, 'global_step': 27465, 'preemption_count': 0}), (27807, {'train/ssim': 0.754103592463902, 'train/loss': 0.2571893760136196, 'validation/ssim': 0.7257026496333356, 'validation/loss': 0.285555331305835, 'validation/num_examples': 3554, 'test/ssim': 0.7428482000270525, 'test/loss': 0.2869928951737469, 'test/num_examples': 3581, 'score': 6513.029781341553, 'total_duration': 6850.704304218292, 'accumulated_submission_time': 6513.029781341553, 'accumulated_eval_time': 331.2638852596283, 'accumulated_logging_time': 5.393904447555542, 'global_step': 27807, 'preemption_count': 0}), (28147, {'train/ssim': 0.7540349960327148, 'train/loss': 0.257232666015625, 'validation/ssim': 0.7256720118396525, 'validation/loss': 0.2855900736021472, 'validation/num_examples': 3554, 'test/ssim': 0.7427993855373848, 'test/loss': 0.2870455957331227, 'test/num_examples': 3581, 'score': 6593.055602550507, 'total_duration': 6934.813687324524, 'accumulated_submission_time': 6593.055602550507, 'accumulated_eval_time': 335.303875207901, 'accumulated_logging_time': 5.425286054611206, 'global_step': 28147, 'preemption_count': 0}), (28493, {'train/ssim': 0.7544220515659877, 'train/loss': 0.2567970412118094, 'validation/ssim': 0.7256915898019837, 'validation/loss': 0.28546022362566825, 'validation/num_examples': 3554, 'test/ssim': 0.7428325193948967, 'test/loss': 0.2869222641523841, 'test/num_examples': 3581, 'score': 6673.217515468597, 'total_duration': 7019.063020467758, 'accumulated_submission_time': 6673.217515468597, 'accumulated_eval_time': 339.34671092033386, 'accumulated_logging_time': 5.456988573074341, 'global_step': 28493, 'preemption_count': 0}), (28837, {'train/ssim': 0.7540216445922852, 'train/loss': 0.2571344716208322, 'validation/ssim': 0.7254533569129854, 'validation/loss': 0.2856393791546497, 'validation/num_examples': 3554, 'test/ssim': 0.7426146949612539, 'test/loss': 0.28710644340355346, 'test/num_examples': 3581, 'score': 6753.32670044899, 'total_duration': 7103.257844209671, 'accumulated_submission_time': 6753.32670044899, 'accumulated_eval_time': 343.3887577056885, 'accumulated_logging_time': 5.488369941711426, 'global_step': 28837, 'preemption_count': 0}), (29179, {'train/ssim': 0.7539787292480469, 'train/loss': 0.2571410962513515, 'validation/ssim': 0.7254288329391179, 'validation/loss': 0.28560760789998946, 'validation/num_examples': 3554, 'test/ssim': 0.742586060763404, 'test/loss': 0.28704464125986107, 'test/num_examples': 3581, 'score': 6833.4487562179565, 'total_duration': 7187.468809604645, 'accumulated_submission_time': 6833.4487562179565, 'accumulated_eval_time': 347.432626247406, 'accumulated_logging_time': 5.521002531051636, 'global_step': 29179, 'preemption_count': 0}), (29523, {'train/ssim': 0.7546099935259137, 'train/loss': 0.256743107523237, 'validation/ssim': 0.7256827968925859, 'validation/loss': 0.2855766266332829, 'validation/num_examples': 3554, 'test/ssim': 0.7428071576768012, 'test/loss': 0.28706952574132577, 'test/num_examples': 3581, 'score': 6913.447591543198, 'total_duration': 7271.553107976913, 'accumulated_submission_time': 6913.447591543198, 'accumulated_eval_time': 351.4746322631836, 'accumulated_logging_time': 5.552271842956543, 'global_step': 29523, 'preemption_count': 0}), (29867, {'train/ssim': 0.7541588374546596, 'train/loss': 0.25702978883470806, 'validation/ssim': 0.7254314433340954, 'validation/loss': 0.2856062511815472, 'validation/num_examples': 3554, 'test/ssim': 0.7425986734457903, 'test/loss': 0.28707157104117215, 'test/num_examples': 3581, 'score': 6993.4892337322235, 'total_duration': 7355.679824829102, 'accumulated_submission_time': 6993.4892337322235, 'accumulated_eval_time': 355.5142960548401, 'accumulated_logging_time': 5.584680080413818, 'global_step': 29867, 'preemption_count': 0}), (30211, {'train/ssim': 0.7540692601885114, 'train/loss': 0.2571203368050711, 'validation/ssim': 0.7255136707758864, 'validation/loss': 0.2856606573084465, 'validation/num_examples': 3554, 'test/ssim': 0.7426834170360933, 'test/loss': 0.2870932512195441, 'test/num_examples': 3581, 'score': 7073.679226160049, 'total_duration': 7439.95772767067, 'accumulated_submission_time': 7073.679226160049, 'accumulated_eval_time': 359.5573136806488, 'accumulated_logging_time': 5.617060422897339, 'global_step': 30211, 'preemption_count': 0}), (30552, {'train/ssim': 0.7548450742449079, 'train/loss': 0.25674610478537424, 'validation/ssim': 0.7258831103598059, 'validation/loss': 0.28564487472302336, 'validation/num_examples': 3554, 'test/ssim': 0.7429972342091944, 'test/loss': 0.2871223285656939, 'test/num_examples': 3581, 'score': 7153.867946386337, 'total_duration': 7524.22979927063, 'accumulated_submission_time': 7153.867946386337, 'accumulated_eval_time': 363.59706449508667, 'accumulated_logging_time': 5.648396730422974, 'global_step': 30552, 'preemption_count': 0}), (30896, {'train/ssim': 0.7542660576956612, 'train/loss': 0.25690986428942, 'validation/ssim': 0.7255811975722777, 'validation/loss': 0.2855315114516654, 'validation/num_examples': 3554, 'test/ssim': 0.7427162100102974, 'test/loss': 0.2870102120457798, 'test/num_examples': 3581, 'score': 7233.912236690521, 'total_duration': 7608.354736804962, 'accumulated_submission_time': 7233.912236690521, 'accumulated_eval_time': 367.6330301761627, 'accumulated_logging_time': 5.680180311203003, 'global_step': 30896, 'preemption_count': 0}), (31241, {'train/ssim': 0.754291330065046, 'train/loss': 0.2570479597364153, 'validation/ssim': 0.7256142396771244, 'validation/loss': 0.2856827082765458, 'validation/num_examples': 3554, 'test/ssim': 0.742731617935807, 'test/loss': 0.28712280580232474, 'test/num_examples': 3581, 'score': 7314.072935581207, 'total_duration': 7692.6046686172485, 'accumulated_submission_time': 7314.072935581207, 'accumulated_eval_time': 371.6770513057709, 'accumulated_logging_time': 5.712636709213257, 'global_step': 31241, 'preemption_count': 0}), (31581, {'train/ssim': 0.7546959604535785, 'train/loss': 0.25669734818594797, 'validation/ssim': 0.725824445167417, 'validation/loss': 0.2855513126714617, 'validation/num_examples': 3554, 'test/ssim': 0.742917058455215, 'test/loss': 0.28703809630035254, 'test/num_examples': 3581, 'score': 7394.21529507637, 'total_duration': 7776.835196018219, 'accumulated_submission_time': 7394.21529507637, 'accumulated_eval_time': 375.7203893661499, 'accumulated_logging_time': 5.745257377624512, 'global_step': 31581, 'preemption_count': 0}), (31928, {'train/ssim': 0.7544897624424526, 'train/loss': 0.25679435048784527, 'validation/ssim': 0.7257194111168753, 'validation/loss': 0.28549537808960856, 'validation/num_examples': 3554, 'test/ssim': 0.7428276788519268, 'test/loss': 0.28697680548162174, 'test/num_examples': 3581, 'score': 7474.3756783008575, 'total_duration': 7861.083312034607, 'accumulated_submission_time': 7474.3756783008575, 'accumulated_eval_time': 379.75985383987427, 'accumulated_logging_time': 5.78111457824707, 'global_step': 31928, 'preemption_count': 0}), (32273, {'train/ssim': 0.754249095916748, 'train/loss': 0.2569260426930019, 'validation/ssim': 0.7255921887090251, 'validation/loss': 0.285591790967264, 'validation/num_examples': 3554, 'test/ssim': 0.7427074833976194, 'test/loss': 0.28705142483768503, 'test/num_examples': 3581, 'score': 7554.379847288132, 'total_duration': 7945.174165248871, 'accumulated_submission_time': 7554.379847288132, 'accumulated_eval_time': 383.8014781475067, 'accumulated_logging_time': 5.81369686126709, 'global_step': 32273, 'preemption_count': 0}), (32612, {'train/ssim': 0.7544171469552177, 'train/loss': 0.25674491269247873, 'validation/ssim': 0.7255723359682752, 'validation/loss': 0.2855080694178215, 'validation/num_examples': 3554, 'test/ssim': 0.7427035973279112, 'test/loss': 0.2869986561016476, 'test/num_examples': 3581, 'score': 7634.347116231918, 'total_duration': 8029.232703924179, 'accumulated_submission_time': 7634.347116231918, 'accumulated_eval_time': 387.8406648635864, 'accumulated_logging_time': 5.852944374084473, 'global_step': 32612, 'preemption_count': 0}), (32956, {'train/ssim': 0.7545514106750488, 'train/loss': 0.25672997747148785, 'validation/ssim': 0.7256814916950971, 'validation/loss': 0.28550841289084483, 'validation/num_examples': 3554, 'test/ssim': 0.7428032034304315, 'test/loss': 0.28699586085852413, 'test/num_examples': 3581, 'score': 7714.379668951035, 'total_duration': 8113.352165699005, 'accumulated_submission_time': 7714.379668951035, 'accumulated_eval_time': 391.8827121257782, 'accumulated_logging_time': 5.8849639892578125, 'global_step': 32956, 'preemption_count': 0}), (33299, {'train/ssim': 0.754565920148577, 'train/loss': 0.256818277495248, 'validation/ssim': 0.7257891361406162, 'validation/loss': 0.28551468127352103, 'validation/num_examples': 3554, 'test/ssim': 0.7429174675151843, 'test/loss': 0.28698607750759214, 'test/num_examples': 3581, 'score': 7794.549304008484, 'total_duration': 8197.608664512634, 'accumulated_submission_time': 7794.549304008484, 'accumulated_eval_time': 395.9238955974579, 'accumulated_logging_time': 5.918242931365967, 'global_step': 33299, 'preemption_count': 0}), (33641, {'train/ssim': 0.7544005257742745, 'train/loss': 0.2568733351571219, 'validation/ssim': 0.725658547697137, 'validation/loss': 0.28560537532533764, 'validation/num_examples': 3554, 'test/ssim': 0.7427757964124895, 'test/loss': 0.2871052844003072, 'test/num_examples': 3581, 'score': 7874.795213460922, 'total_duration': 8281.944691896439, 'accumulated_submission_time': 7874.795213460922, 'accumulated_eval_time': 399.9638068675995, 'accumulated_logging_time': 5.955785274505615, 'global_step': 33641, 'preemption_count': 0}), (33984, {'train/ssim': 0.7547591754368373, 'train/loss': 0.25668695994785856, 'validation/ssim': 0.7258627767568233, 'validation/loss': 0.28552361157212824, 'validation/num_examples': 3554, 'test/ssim': 0.7429784856272689, 'test/loss': 0.28701941589508867, 'test/num_examples': 3581, 'score': 7954.826099395752, 'total_duration': 8366.067419290543, 'accumulated_submission_time': 7954.826099395752, 'accumulated_eval_time': 404.01122069358826, 'accumulated_logging_time': 5.9875712394714355, 'global_step': 33984, 'preemption_count': 0}), (34329, {'train/ssim': 0.7546742303030831, 'train/loss': 0.2567040579659598, 'validation/ssim': 0.7258765843723621, 'validation/loss': 0.2854583688713421, 'validation/num_examples': 3554, 'test/ssim': 0.7429921891362399, 'test/loss': 0.2869331042415701, 'test/num_examples': 3581, 'score': 8034.8506779670715, 'total_duration': 8450.185488700867, 'accumulated_submission_time': 8034.8506779670715, 'accumulated_eval_time': 408.0551481246948, 'accumulated_logging_time': 6.024341106414795, 'global_step': 34329, 'preemption_count': 0}), (34672, {'train/ssim': 0.7546633311680385, 'train/loss': 0.2567169666290283, 'validation/ssim': 0.7258422370700267, 'validation/loss': 0.28547949246227844, 'validation/num_examples': 3554, 'test/ssim': 0.7429690772479755, 'test/loss': 0.28694322847580983, 'test/num_examples': 3581, 'score': 8114.963846206665, 'total_duration': 8534.388310909271, 'accumulated_submission_time': 8114.963846206665, 'accumulated_eval_time': 412.0980794429779, 'accumulated_logging_time': 6.058527708053589, 'global_step': 34672, 'preemption_count': 0}), (35015, {'train/ssim': 0.7547167369297573, 'train/loss': 0.25660886083330425, 'validation/ssim': 0.7258234147483469, 'validation/loss': 0.2854470342615715, 'validation/num_examples': 3554, 'test/ssim': 0.7429394204002024, 'test/loss': 0.2869227413890149, 'test/num_examples': 3581, 'score': 8195.090363264084, 'total_duration': 8618.609902381897, 'accumulated_submission_time': 8195.090363264084, 'accumulated_eval_time': 416.14691257476807, 'accumulated_logging_time': 6.092074155807495, 'global_step': 35015, 'preemption_count': 0}), (35360, {'train/ssim': 0.7546516145978656, 'train/loss': 0.2566218546458653, 'validation/ssim': 0.725779999758195, 'validation/loss': 0.2854279715087753, 'validation/num_examples': 3554, 'test/ssim': 0.7429039003595365, 'test/loss': 0.28690225430222005, 'test/num_examples': 3581, 'score': 8275.109664440155, 'total_duration': 8702.720784902573, 'accumulated_submission_time': 8275.109664440155, 'accumulated_eval_time': 420.1879172325134, 'accumulated_logging_time': 6.129887580871582, 'global_step': 35360, 'preemption_count': 0}), (35701, {'train/ssim': 0.7548180307660785, 'train/loss': 0.2566397019795009, 'validation/ssim': 0.7259626587120146, 'validation/loss': 0.28544598666885024, 'validation/num_examples': 3554, 'test/ssim': 0.7430810915028973, 'test/loss': 0.28691271941976754, 'test/num_examples': 3581, 'score': 8355.086299180984, 'total_duration': 8786.73073220253, 'accumulated_submission_time': 8355.086299180984, 'accumulated_eval_time': 424.1739959716797, 'accumulated_logging_time': 6.164317607879639, 'global_step': 35701, 'preemption_count': 0}), (36044, {'train/ssim': 0.7547200066702706, 'train/loss': 0.2566244431904384, 'validation/ssim': 0.7258568690208216, 'validation/loss': 0.28543083950852033, 'validation/num_examples': 3554, 'test/ssim': 0.742981485400377, 'test/loss': 0.28690187933058153, 'test/num_examples': 3581, 'score': 8435.13413977623, 'total_duration': 8870.86947607994, 'accumulated_submission_time': 8435.13413977623, 'accumulated_eval_time': 428.2131233215332, 'accumulated_logging_time': 6.202942609786987, 'global_step': 36044, 'preemption_count': 0}), (36189, {'train/ssim': 0.7547260693141392, 'train/loss': 0.25662572043282644, 'validation/ssim': 0.7258640132597074, 'validation/loss': 0.2854322477479161, 'validation/num_examples': 3554, 'test/ssim': 0.7429876212999162, 'test/loss': 0.28690365192378176, 'test/num_examples': 3581, 'score': 8467.644447088242, 'total_duration': 8907.461469173431, 'accumulated_submission_time': 8467.644447088242, 'accumulated_eval_time': 432.25509095191956, 'accumulated_logging_time': 6.2368481159210205, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 16:13:05.104675 140584300062528 submission_runner.py:586] Timing: 8467.644447088242
I0204 16:13:05.104727 140584300062528 submission_runner.py:588] Total number of evals: 107
I0204 16:13:05.104768 140584300062528 submission_runner.py:589] ====================
I0204 16:13:05.104812 140584300062528 submission_runner.py:542] Using RNG seed 3907440050
I0204 16:13:05.106448 140584300062528 submission_runner.py:551] --- Tuning run 3/5 ---
I0204 16:13:05.106561 140584300062528 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3.
I0204 16:13:05.107001 140584300062528 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3/hparams.json.
I0204 16:13:05.107856 140584300062528 submission_runner.py:206] Initializing dataset.
I0204 16:13:05.485137 140584300062528 submission_runner.py:213] Initializing model.
I0204 16:13:07.607267 140584300062528 submission_runner.py:255] Initializing optimizer.
I0204 16:13:07.674946 140584300062528 submission_runner.py:262] Initializing metrics bundle.
I0204 16:13:07.675082 140584300062528 submission_runner.py:280] Initializing checkpoint and logger.
I0204 16:13:07.675709 140584300062528 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3 with prefix checkpoint_
I0204 16:13:07.675831 140584300062528 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3/meta_data_0.json.
I0204 16:13:07.676040 140584300062528 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 16:13:07.676109 140584300062528 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 16:13:11.788730 140584300062528 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 16:13:15.815252 140584300062528 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3/flags_0.json.
I0204 16:13:15.818884 140584300062528 submission_runner.py:314] Starting training loop.
I0204 16:13:49.360126 140379596986112 logging_writer.py:48] [0] global_step=0, grad_norm=4.385186672210693, loss=0.9066542387008667
I0204 16:13:49.367973 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:13:50.698804 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:13:52.024795 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:13:53.352591 140584300062528 submission_runner.py:408] Time since start: 37.53s, 	Step: 1, 	{'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 33.548996925354004, 'total_duration': 37.53365206718445, 'accumulated_submission_time': 33.548996925354004, 'accumulated_eval_time': 3.984562873840332, 'accumulated_logging_time': 0}
I0204 16:13:53.362091 140383296210688 logging_writer.py:48] [1] accumulated_eval_time=3.984563, accumulated_logging_time=0, accumulated_submission_time=33.548997, global_step=1, preemption_count=0, score=33.548997, test/loss=0.912514, test/num_examples=3581, test/ssim=0.282943, total_duration=37.533652, train/loss=0.903264, train/ssim=0.267076, validation/loss=0.915262, validation/num_examples=3554, validation/ssim=0.258797
I0204 16:14:15.213404 140379596986112 logging_writer.py:48] [100] global_step=100, grad_norm=0.7346449494361877, loss=0.299555242061615
I0204 16:14:39.142743 140383296210688 logging_writer.py:48] [200] global_step=200, grad_norm=0.17185001075267792, loss=0.34124550223350525
I0204 16:15:03.357106 140379596986112 logging_writer.py:48] [300] global_step=300, grad_norm=0.1216900423169136, loss=0.3615771532058716
I0204 16:15:13.561373 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:15:14.942711 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:15:16.273727 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:15:17.601838 140584300062528 submission_runner.py:408] Time since start: 121.78s, 	Step: 343, 	{'train/ssim': 0.6902498517717633, 'train/loss': 0.3141788755144392, 'validation/ssim': 0.6638744141724113, 'validation/loss': 0.34272789297710327, 'validation/num_examples': 3554, 'test/ssim': 0.6831162406625244, 'test/loss': 0.3437465229902611, 'test/num_examples': 3581, 'score': 113.72720742225647, 'total_duration': 121.78289651870728, 'accumulated_submission_time': 113.72720742225647, 'accumulated_eval_time': 8.02499008178711, 'accumulated_logging_time': 0.0185849666595459}
I0204 16:15:17.615857 140383296210688 logging_writer.py:48] [343] accumulated_eval_time=8.024990, accumulated_logging_time=0.018585, accumulated_submission_time=113.727207, global_step=343, preemption_count=0, score=113.727207, test/loss=0.343747, test/num_examples=3581, test/ssim=0.683116, total_duration=121.782897, train/loss=0.314179, train/ssim=0.690250, validation/loss=0.342728, validation/num_examples=3554, validation/ssim=0.663874
I0204 16:15:29.219172 140379596986112 logging_writer.py:48] [400] global_step=400, grad_norm=0.11728069931268692, loss=0.3498474359512329
I0204 16:15:53.495375 140383296210688 logging_writer.py:48] [500] global_step=500, grad_norm=0.18207213282585144, loss=0.28638777136802673
I0204 16:16:17.837326 140379596986112 logging_writer.py:48] [600] global_step=600, grad_norm=0.13630564510822296, loss=0.2794577479362488
I0204 16:16:37.658553 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:16:39.039322 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:16:40.365570 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:16:41.696204 140584300062528 submission_runner.py:408] Time since start: 205.88s, 	Step: 683, 	{'train/ssim': 0.7197771753583636, 'train/loss': 0.2880679539271763, 'validation/ssim': 0.6944376055149127, 'validation/loss': 0.3150176572611846, 'validation/num_examples': 3554, 'test/ssim': 0.7118955866247207, 'test/loss': 0.3172561061745148, 'test/num_examples': 3581, 'score': 193.74862456321716, 'total_duration': 205.87726044654846, 'accumulated_submission_time': 193.74862456321716, 'accumulated_eval_time': 12.062600135803223, 'accumulated_logging_time': 0.04203295707702637}
I0204 16:16:41.710242 140383296210688 logging_writer.py:48] [683] accumulated_eval_time=12.062600, accumulated_logging_time=0.042033, accumulated_submission_time=193.748625, global_step=683, preemption_count=0, score=193.748625, test/loss=0.317256, test/num_examples=3581, test/ssim=0.711896, total_duration=205.877260, train/loss=0.288068, train/ssim=0.719777, validation/loss=0.315018, validation/num_examples=3554, validation/ssim=0.694438
I0204 16:16:43.706873 140379596986112 logging_writer.py:48] [700] global_step=700, grad_norm=0.1101423054933548, loss=0.27766236662864685
I0204 16:17:07.991029 140383296210688 logging_writer.py:48] [800] global_step=800, grad_norm=0.062039680778980255, loss=0.23101073503494263
I0204 16:17:32.550780 140379596986112 logging_writer.py:48] [900] global_step=900, grad_norm=0.23563706874847412, loss=0.3399854302406311
I0204 16:17:56.821486 140383296210688 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.09870360791683197, loss=0.2340320199728012
I0204 16:18:01.878548 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:18:03.258318 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:18:04.589108 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:18:05.917440 140584300062528 submission_runner.py:408] Time since start: 290.10s, 	Step: 1023, 	{'train/ssim': 0.7243311745779855, 'train/loss': 0.28095054626464844, 'validation/ssim': 0.6999504162343486, 'validation/loss': 0.307128803208093, 'validation/num_examples': 3554, 'test/ssim': 0.7172653850181514, 'test/loss': 0.30918978446357515, 'test/num_examples': 3581, 'score': 273.89558959007263, 'total_duration': 290.09849548339844, 'accumulated_submission_time': 273.89558959007263, 'accumulated_eval_time': 16.101449489593506, 'accumulated_logging_time': 0.06560516357421875}
I0204 16:18:05.931654 140379596986112 logging_writer.py:48] [1023] accumulated_eval_time=16.101449, accumulated_logging_time=0.065605, accumulated_submission_time=273.895590, global_step=1023, preemption_count=0, score=273.895590, test/loss=0.309190, test/num_examples=3581, test/ssim=0.717265, total_duration=290.098495, train/loss=0.280951, train/ssim=0.724331, validation/loss=0.307129, validation/num_examples=3554, validation/ssim=0.699950
I0204 16:18:22.414965 140383296210688 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.13454455137252808, loss=0.3583073019981384
I0204 16:18:46.120721 140379596986112 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.09045277535915375, loss=0.22705130279064178
I0204 16:19:09.700209 140383296210688 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.0970354676246643, loss=0.3151812255382538
I0204 16:19:26.145542 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:19:27.528089 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:19:28.858608 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:19:30.188126 140584300062528 submission_runner.py:408] Time since start: 374.37s, 	Step: 1370, 	{'train/ssim': 0.7353413445608956, 'train/loss': 0.27315076759883333, 'validation/ssim': 0.7095289171312253, 'validation/loss': 0.29964655252004785, 'validation/num_examples': 3554, 'test/ssim': 0.7265489328443522, 'test/loss': 0.3018685313983524, 'test/num_examples': 3581, 'score': 354.088178396225, 'total_duration': 374.368869304657, 'accumulated_submission_time': 354.088178396225, 'accumulated_eval_time': 20.14368963241577, 'accumulated_logging_time': 0.0890505313873291}
I0204 16:19:30.202730 140379596986112 logging_writer.py:48] [1370] accumulated_eval_time=20.143690, accumulated_logging_time=0.089051, accumulated_submission_time=354.088178, global_step=1370, preemption_count=0, score=354.088178, test/loss=0.301869, test/num_examples=3581, test/ssim=0.726549, total_duration=374.368869, train/loss=0.273151, train/ssim=0.735341, validation/loss=0.299647, validation/num_examples=3554, validation/ssim=0.709529
I0204 16:19:35.314349 140383296210688 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.40172120928764343, loss=0.298492431640625
I0204 16:19:59.228105 140379596986112 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.09853162616491318, loss=0.4021296501159668
I0204 16:20:23.320757 140383296210688 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.1156114861369133, loss=0.22936439514160156
I0204 16:20:47.405899 140379596986112 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.05383173003792763, loss=0.33089426159858704
I0204 16:20:50.214145 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:20:51.596173 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:20:52.923024 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:20:54.249592 140584300062528 submission_runner.py:408] Time since start: 458.43s, 	Step: 1713, 	{'train/ssim': 0.7381311144147601, 'train/loss': 0.27023257528032574, 'validation/ssim': 0.7123925204215321, 'validation/loss': 0.29638180708576606, 'validation/num_examples': 3554, 'test/ssim': 0.7295050728890324, 'test/loss': 0.2983961235841071, 'test/num_examples': 3581, 'score': 434.0783689022064, 'total_duration': 458.4306387901306, 'accumulated_submission_time': 434.0783689022064, 'accumulated_eval_time': 24.17908215522766, 'accumulated_logging_time': 0.1127169132232666}
I0204 16:20:54.265023 140383296210688 logging_writer.py:48] [1713] accumulated_eval_time=24.179082, accumulated_logging_time=0.112717, accumulated_submission_time=434.078369, global_step=1713, preemption_count=0, score=434.078369, test/loss=0.298396, test/num_examples=3581, test/ssim=0.729505, total_duration=458.430639, train/loss=0.270233, train/ssim=0.738131, validation/loss=0.296382, validation/num_examples=3554, validation/ssim=0.712393
I0204 16:21:13.193810 140379596986112 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.32512909173965454, loss=0.2642652690410614
I0204 16:21:36.950226 140383296210688 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.061252228915691376, loss=0.26045697927474976
I0204 16:22:01.098666 140379596986112 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.20731724798679352, loss=0.24566732347011566
I0204 16:22:14.429408 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:22:15.811028 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:22:17.139914 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:22:18.469809 140584300062528 submission_runner.py:408] Time since start: 542.65s, 	Step: 2055, 	{'train/ssim': 0.7401712962559291, 'train/loss': 0.26896728788103375, 'validation/ssim': 0.7145240453098621, 'validation/loss': 0.29493956386070275, 'validation/num_examples': 3554, 'test/ssim': 0.7316638187002583, 'test/loss': 0.29680184644216, 'test/num_examples': 3581, 'score': 514.2202973365784, 'total_duration': 542.6508350372314, 'accumulated_submission_time': 514.2202973365784, 'accumulated_eval_time': 28.21941351890564, 'accumulated_logging_time': 0.13882088661193848}
I0204 16:22:18.486802 140383296210688 logging_writer.py:48] [2055] accumulated_eval_time=28.219414, accumulated_logging_time=0.138821, accumulated_submission_time=514.220297, global_step=2055, preemption_count=0, score=514.220297, test/loss=0.296802, test/num_examples=3581, test/ssim=0.731664, total_duration=542.650835, train/loss=0.268967, train/ssim=0.740171, validation/loss=0.294940, validation/num_examples=3554, validation/ssim=0.714524
I0204 16:22:27.101352 140379596986112 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.06500661373138428, loss=0.331474632024765
I0204 16:22:51.195226 140383296210688 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.2969419062137604, loss=0.25515925884246826
I0204 16:23:14.838088 140379596986112 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.07403956353664398, loss=0.24973073601722717
I0204 16:23:38.543968 140383296210688 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.13143134117126465, loss=0.3539454936981201
I0204 16:23:38.550189 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:23:39.876761 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:23:41.208108 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:23:42.540722 140584300062528 submission_runner.py:408] Time since start: 626.72s, 	Step: 2401, 	{'train/ssim': 0.742351940699986, 'train/loss': 0.2663253034864153, 'validation/ssim': 0.7161404293577659, 'validation/loss': 0.2926883042764315, 'validation/num_examples': 3554, 'test/ssim': 0.7333096714866657, 'test/loss': 0.29443482092990786, 'test/num_examples': 3581, 'score': 594.2618770599365, 'total_duration': 626.7217772006989, 'accumulated_submission_time': 594.2618770599365, 'accumulated_eval_time': 32.20990490913391, 'accumulated_logging_time': 0.1659994125366211}
I0204 16:23:42.556113 140379596986112 logging_writer.py:48] [2401] accumulated_eval_time=32.209905, accumulated_logging_time=0.165999, accumulated_submission_time=594.261877, global_step=2401, preemption_count=0, score=594.261877, test/loss=0.294435, test/num_examples=3581, test/ssim=0.733310, total_duration=626.721777, train/loss=0.266325, train/ssim=0.742352, validation/loss=0.292688, validation/num_examples=3554, validation/ssim=0.716140
I0204 16:24:04.135645 140383296210688 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.20455774664878845, loss=0.2726295590400696
I0204 16:24:28.109150 140379596986112 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.13322222232818604, loss=0.2764289677143097
I0204 16:24:51.978080 140383296210688 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.08473213016986847, loss=0.2603744566440582
I0204 16:25:02.612141 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:25:03.991967 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:25:05.323498 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:25:06.654551 140584300062528 submission_runner.py:408] Time since start: 710.84s, 	Step: 2746, 	{'train/ssim': 0.7398902348109654, 'train/loss': 0.26844440187726704, 'validation/ssim': 0.7138087970860298, 'validation/loss': 0.29461463838060986, 'validation/num_examples': 3554, 'test/ssim': 0.7309620763229545, 'test/loss': 0.2963557324573269, 'test/num_examples': 3581, 'score': 674.29638504982, 'total_duration': 710.8356049060822, 'accumulated_submission_time': 674.29638504982, 'accumulated_eval_time': 36.25227451324463, 'accumulated_logging_time': 0.1907820701599121}
I0204 16:25:06.670041 140379596986112 logging_writer.py:48] [2746] accumulated_eval_time=36.252275, accumulated_logging_time=0.190782, accumulated_submission_time=674.296385, global_step=2746, preemption_count=0, score=674.296385, test/loss=0.296356, test/num_examples=3581, test/ssim=0.730962, total_duration=710.835605, train/loss=0.268444, train/ssim=0.739890, validation/loss=0.294615, validation/num_examples=3554, validation/ssim=0.713809
I0204 16:25:17.455764 140383296210688 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.08253321796655655, loss=0.3125131130218506
I0204 16:25:41.215974 140379596986112 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.18096768856048584, loss=0.23595258593559265
I0204 16:26:05.229336 140383296210688 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.11491389572620392, loss=0.26709944009780884
I0204 16:26:26.753250 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:26:28.134357 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:26:29.465567 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:26:30.795541 140584300062528 submission_runner.py:408] Time since start: 794.98s, 	Step: 3090, 	{'train/ssim': 0.7444577898297992, 'train/loss': 0.2649519273212978, 'validation/ssim': 0.7183651041300295, 'validation/loss': 0.29116345578925157, 'validation/num_examples': 3554, 'test/ssim': 0.7354993013255725, 'test/loss': 0.2928027739174637, 'test/num_examples': 3581, 'score': 754.3580448627472, 'total_duration': 794.9765889644623, 'accumulated_submission_time': 754.3580448627472, 'accumulated_eval_time': 40.29451560974121, 'accumulated_logging_time': 0.21582698822021484}
I0204 16:26:30.811003 140379596986112 logging_writer.py:48] [3090] accumulated_eval_time=40.294516, accumulated_logging_time=0.215827, accumulated_submission_time=754.358045, global_step=3090, preemption_count=0, score=754.358045, test/loss=0.292803, test/num_examples=3581, test/ssim=0.735499, total_duration=794.976589, train/loss=0.264952, train/ssim=0.744458, validation/loss=0.291163, validation/num_examples=3554, validation/ssim=0.718365
I0204 16:26:31.634542 140383296210688 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.33233147859573364, loss=0.25826767086982727
I0204 16:26:55.508460 140379596986112 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.2471703439950943, loss=0.36920714378356934
I0204 16:27:19.478929 140383296210688 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.054476622492074966, loss=0.30659472942352295
I0204 16:27:43.229591 140379596986112 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.1510818898677826, loss=0.2860932946205139
I0204 16:27:50.806392 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:27:52.191488 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:27:53.520871 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:27:54.848518 140584300062528 submission_runner.py:408] Time since start: 879.03s, 	Step: 3433, 	{'train/ssim': 0.7445534297398159, 'train/loss': 0.2641278845923288, 'validation/ssim': 0.7181353893720104, 'validation/loss': 0.2906195319094682, 'validation/num_examples': 3554, 'test/ssim': 0.7354296247774714, 'test/loss': 0.2922338396768535, 'test/num_examples': 3581, 'score': 834.3319246768951, 'total_duration': 879.0295767784119, 'accumulated_submission_time': 834.3319246768951, 'accumulated_eval_time': 44.33660364151001, 'accumulated_logging_time': 0.24074792861938477}
I0204 16:27:54.864215 140383296210688 logging_writer.py:48] [3433] accumulated_eval_time=44.336604, accumulated_logging_time=0.240748, accumulated_submission_time=834.331925, global_step=3433, preemption_count=0, score=834.331925, test/loss=0.292234, test/num_examples=3581, test/ssim=0.735430, total_duration=879.029577, train/loss=0.264128, train/ssim=0.744553, validation/loss=0.290620, validation/num_examples=3554, validation/ssim=0.718135
I0204 16:28:08.713133 140379596986112 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.1319129765033722, loss=0.26078611612319946
I0204 16:28:35.131971 140383296210688 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.07065319269895554, loss=0.29091644287109375
I0204 16:28:58.823291 140379596986112 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.21597683429718018, loss=0.28205516934394836
I0204 16:29:14.973641 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:29:16.354693 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:29:17.682209 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:29:19.011400 140584300062528 submission_runner.py:408] Time since start: 963.19s, 	Step: 3768, 	{'train/ssim': 0.7440680095127651, 'train/loss': 0.2646568502698626, 'validation/ssim': 0.7183314437737408, 'validation/loss': 0.29050391888980726, 'validation/num_examples': 3554, 'test/ssim': 0.7355386392592851, 'test/loss': 0.29211613267069253, 'test/num_examples': 3581, 'score': 914.4203317165375, 'total_duration': 963.192458152771, 'accumulated_submission_time': 914.4203317165375, 'accumulated_eval_time': 48.37433314323425, 'accumulated_logging_time': 0.26586484909057617}
I0204 16:29:19.026246 140383296210688 logging_writer.py:48] [3768] accumulated_eval_time=48.374333, accumulated_logging_time=0.265865, accumulated_submission_time=914.420332, global_step=3768, preemption_count=0, score=914.420332, test/loss=0.292116, test/num_examples=3581, test/ssim=0.735539, total_duration=963.192458, train/loss=0.264657, train/ssim=0.744068, validation/loss=0.290504, validation/num_examples=3554, validation/ssim=0.718331
I0204 16:29:24.689738 140379596986112 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.14812645316123962, loss=0.27104437351226807
I0204 16:29:48.718275 140383296210688 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.27396395802497864, loss=0.26730161905288696
I0204 16:30:12.793902 140379596986112 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.08955051749944687, loss=0.29607725143432617
I0204 16:30:36.702456 140383296210688 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.1130187064409256, loss=0.26864099502563477
I0204 16:30:39.188064 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:30:40.571928 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:30:41.903560 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:30:43.233557 140584300062528 submission_runner.py:408] Time since start: 1047.41s, 	Step: 4112, 	{'train/ssim': 0.7450623512268066, 'train/loss': 0.26390624046325684, 'validation/ssim': 0.7189520995269415, 'validation/loss': 0.29018246248725027, 'validation/num_examples': 3554, 'test/ssim': 0.7359028389852694, 'test/loss': 0.2918586294200293, 'test/num_examples': 3581, 'score': 994.5614778995514, 'total_duration': 1047.4146084785461, 'accumulated_submission_time': 994.5614778995514, 'accumulated_eval_time': 52.41978621482849, 'accumulated_logging_time': 0.2896695137023926}
I0204 16:30:43.248657 140379596986112 logging_writer.py:48] [4112] accumulated_eval_time=52.419786, accumulated_logging_time=0.289670, accumulated_submission_time=994.561478, global_step=4112, preemption_count=0, score=994.561478, test/loss=0.291859, test/num_examples=3581, test/ssim=0.735903, total_duration=1047.414608, train/loss=0.263906, train/ssim=0.745062, validation/loss=0.290182, validation/num_examples=3554, validation/ssim=0.718952
I0204 16:31:02.994412 140383296210688 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.33595022559165955, loss=0.24440191686153412
I0204 16:31:26.837701 140379596986112 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.14275209605693817, loss=0.2869094908237457
I0204 16:31:50.689480 140383296210688 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.09008625149726868, loss=0.2939123511314392
I0204 16:32:03.285166 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:32:04.668096 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:32:05.996862 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:32:07.326777 140584300062528 submission_runner.py:408] Time since start: 1131.51s, 	Step: 4454, 	{'train/ssim': 0.747828483581543, 'train/loss': 0.26266428402491976, 'validation/ssim': 0.7210435754607485, 'validation/loss': 0.28934847563924454, 'validation/num_examples': 3554, 'test/ssim': 0.7382009378926976, 'test/loss': 0.29097819601281066, 'test/num_examples': 3581, 'score': 1074.5751271247864, 'total_duration': 1131.507836341858, 'accumulated_submission_time': 1074.5751271247864, 'accumulated_eval_time': 56.46136999130249, 'accumulated_logging_time': 0.3157362937927246}
I0204 16:32:07.342595 140379596986112 logging_writer.py:48] [4454] accumulated_eval_time=56.461370, accumulated_logging_time=0.315736, accumulated_submission_time=1074.575127, global_step=4454, preemption_count=0, score=1074.575127, test/loss=0.290978, test/num_examples=3581, test/ssim=0.738201, total_duration=1131.507836, train/loss=0.262664, train/ssim=0.747828, validation/loss=0.289348, validation/num_examples=3554, validation/ssim=0.721044
I0204 16:32:16.110214 140383296210688 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.19494564831256866, loss=0.20190587639808655
I0204 16:32:39.943458 140379596986112 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.14666743576526642, loss=0.2067282795906067
I0204 16:33:03.784832 140383296210688 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.13488435745239258, loss=0.2200285792350769
I0204 16:33:27.409422 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:33:28.790616 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:33:30.122588 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:33:31.453399 140584300062528 submission_runner.py:408] Time since start: 1215.63s, 	Step: 4800, 	{'train/ssim': 0.7469865253993443, 'train/loss': 0.2625446149281093, 'validation/ssim': 0.7206881495761818, 'validation/loss': 0.28886486562236213, 'validation/num_examples': 3554, 'test/ssim': 0.7379298674863864, 'test/loss': 0.2904206131863481, 'test/num_examples': 3581, 'score': 1154.6210136413574, 'total_duration': 1215.6344573497772, 'accumulated_submission_time': 1154.6210136413574, 'accumulated_eval_time': 60.50531268119812, 'accumulated_logging_time': 0.34067821502685547}
I0204 16:33:31.468976 140379596986112 logging_writer.py:48] [4800] accumulated_eval_time=60.505313, accumulated_logging_time=0.340678, accumulated_submission_time=1154.621014, global_step=4800, preemption_count=0, score=1154.621014, test/loss=0.290421, test/num_examples=3581, test/ssim=0.737930, total_duration=1215.634457, train/loss=0.262545, train/ssim=0.746987, validation/loss=0.288865, validation/num_examples=3554, validation/ssim=0.720688
I0204 16:33:31.562095 140383296210688 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.12148929387331009, loss=0.31324002146720886
I0204 16:33:53.175511 140379596986112 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.0457070991396904, loss=0.2889482378959656
I0204 16:34:17.047514 140383296210688 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.3968093991279602, loss=0.37030261754989624
I0204 16:34:40.788714 140379596986112 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.14313945174217224, loss=0.32857781648635864
I0204 16:34:51.655290 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:34:53.035695 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:34:54.365082 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:34:55.695477 140584300062528 submission_runner.py:408] Time since start: 1299.88s, 	Step: 5147, 	{'train/ssim': 0.747349670955113, 'train/loss': 0.26216367312840055, 'validation/ssim': 0.7209261076867614, 'validation/loss': 0.2884935369368142, 'validation/num_examples': 3554, 'test/ssim': 0.738178439594387, 'test/loss': 0.2899860551456472, 'test/num_examples': 3581, 'score': 1234.7858142852783, 'total_duration': 1299.8765351772308, 'accumulated_submission_time': 1234.7858142852783, 'accumulated_eval_time': 64.54547190666199, 'accumulated_logging_time': 0.3658421039581299}
I0204 16:34:55.710779 140383296210688 logging_writer.py:48] [5147] accumulated_eval_time=64.545472, accumulated_logging_time=0.365842, accumulated_submission_time=1234.785814, global_step=5147, preemption_count=0, score=1234.785814, test/loss=0.289986, test/num_examples=3581, test/ssim=0.738178, total_duration=1299.876535, train/loss=0.262164, train/ssim=0.747350, validation/loss=0.288494, validation/num_examples=3554, validation/ssim=0.720926
I0204 16:35:06.430171 140379596986112 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.0777100920677185, loss=0.23700940608978271
I0204 16:35:30.998065 140383296210688 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.3296777307987213, loss=0.2212856113910675
I0204 16:35:54.585025 140379596986112 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.45909643173217773, loss=0.33424562215805054
I0204 16:36:15.796982 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:36:17.175827 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:36:18.506373 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:36:19.837159 140584300062528 submission_runner.py:408] Time since start: 1384.02s, 	Step: 5490, 	{'train/ssim': 0.7481654030936105, 'train/loss': 0.2623655114855085, 'validation/ssim': 0.7215267733100028, 'validation/loss': 0.28904683763013506, 'validation/num_examples': 3554, 'test/ssim': 0.7386932415657288, 'test/loss': 0.2906221093095504, 'test/num_examples': 3581, 'score': 1314.8512017726898, 'total_duration': 1384.0182185173035, 'accumulated_submission_time': 1314.8512017726898, 'accumulated_eval_time': 68.58561253547668, 'accumulated_logging_time': 0.3900299072265625}
I0204 16:36:19.852825 140383296210688 logging_writer.py:48] [5490] accumulated_eval_time=68.585613, accumulated_logging_time=0.390030, accumulated_submission_time=1314.851202, global_step=5490, preemption_count=0, score=1314.851202, test/loss=0.290622, test/num_examples=3581, test/ssim=0.738693, total_duration=1384.018219, train/loss=0.262366, train/ssim=0.748165, validation/loss=0.289047, validation/num_examples=3554, validation/ssim=0.721527
I0204 16:36:20.669821 140379596986112 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.038014885038137436, loss=0.27983546257019043
I0204 16:36:43.896533 140383296210688 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.1552763432264328, loss=0.2555100619792938
I0204 16:37:07.996026 140379596986112 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.14354850351810455, loss=0.2955576777458191
I0204 16:37:31.979055 140383296210688 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.05419810116291046, loss=0.29432880878448486
I0204 16:37:40.052854 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:37:41.434179 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:37:42.766224 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:37:44.097611 140584300062528 submission_runner.py:408] Time since start: 1468.28s, 	Step: 5835, 	{'train/ssim': 0.7441043172563825, 'train/loss': 0.2656274012156895, 'validation/ssim': 0.7176361169852631, 'validation/loss': 0.2921757738309827, 'validation/num_examples': 3554, 'test/ssim': 0.7345956878534278, 'test/loss': 0.29376570108515426, 'test/num_examples': 3581, 'score': 1395.0299680233002, 'total_duration': 1468.2786684036255, 'accumulated_submission_time': 1395.0299680233002, 'accumulated_eval_time': 72.6303391456604, 'accumulated_logging_time': 0.41507530212402344}
I0204 16:37:44.113694 140379596986112 logging_writer.py:48] [5835] accumulated_eval_time=72.630339, accumulated_logging_time=0.415075, accumulated_submission_time=1395.029968, global_step=5835, preemption_count=0, score=1395.029968, test/loss=0.293766, test/num_examples=3581, test/ssim=0.734596, total_duration=1468.278668, train/loss=0.265627, train/ssim=0.744104, validation/loss=0.292176, validation/num_examples=3554, validation/ssim=0.717636
I0204 16:37:57.633739 140383296210688 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.2655278146266937, loss=0.3000555634498596
I0204 16:38:21.594313 140379596986112 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.1406683325767517, loss=0.21130040287971497
I0204 16:38:45.426120 140383296210688 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.08896887302398682, loss=0.3216889202594757
I0204 16:39:04.257738 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:39:05.640029 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:39:06.971647 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:39:08.302132 140584300062528 submission_runner.py:408] Time since start: 1552.48s, 	Step: 6180, 	{'train/ssim': 0.7495601517813546, 'train/loss': 0.26161309650966097, 'validation/ssim': 0.7231619796795864, 'validation/loss': 0.2881927576102631, 'validation/num_examples': 3554, 'test/ssim': 0.7403823183555571, 'test/loss': 0.28964019494161897, 'test/num_examples': 3581, 'score': 1475.153118133545, 'total_duration': 1552.4831855297089, 'accumulated_submission_time': 1475.153118133545, 'accumulated_eval_time': 76.67470240592957, 'accumulated_logging_time': 0.4403700828552246}
I0204 16:39:08.320291 140379596986112 logging_writer.py:48] [6180] accumulated_eval_time=76.674702, accumulated_logging_time=0.440370, accumulated_submission_time=1475.153118, global_step=6180, preemption_count=0, score=1475.153118, test/loss=0.289640, test/num_examples=3581, test/ssim=0.740382, total_duration=1552.483186, train/loss=0.261613, train/ssim=0.749560, validation/loss=0.288193, validation/num_examples=3554, validation/ssim=0.723162
I0204 16:39:11.118702 140383296210688 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.17510896921157837, loss=0.2939462661743164
I0204 16:39:34.875890 140379596986112 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.2060452699661255, loss=0.23797734081745148
I0204 16:39:59.500316 140383296210688 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.2949642241001129, loss=0.23315925896167755
I0204 16:40:23.448166 140379596986112 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.20745454728603363, loss=0.2570681571960449
I0204 16:40:28.446018 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:40:29.831033 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:40:31.159753 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:40:32.488544 140584300062528 submission_runner.py:408] Time since start: 1636.67s, 	Step: 6522, 	{'train/ssim': 0.7479400634765625, 'train/loss': 0.26206294127873014, 'validation/ssim': 0.7214551935319359, 'validation/loss': 0.2886338800141566, 'validation/num_examples': 3554, 'test/ssim': 0.7387238528867635, 'test/loss': 0.29007737778378945, 'test/num_examples': 3581, 'score': 1555.2574756145477, 'total_duration': 1636.669602394104, 'accumulated_submission_time': 1555.2574756145477, 'accumulated_eval_time': 80.7171881198883, 'accumulated_logging_time': 0.4680335521697998}
I0204 16:40:32.504455 140383296210688 logging_writer.py:48] [6522] accumulated_eval_time=80.717188, accumulated_logging_time=0.468034, accumulated_submission_time=1555.257476, global_step=6522, preemption_count=0, score=1555.257476, test/loss=0.290077, test/num_examples=3581, test/ssim=0.738724, total_duration=1636.669602, train/loss=0.262063, train/ssim=0.747940, validation/loss=0.288634, validation/num_examples=3554, validation/ssim=0.721455
I0204 16:40:49.112732 140379596986112 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.1665397584438324, loss=0.3016951084136963
I0204 16:41:12.795458 140383296210688 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.10043349862098694, loss=0.288654625415802
I0204 16:41:36.391138 140379596986112 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.11278856545686722, loss=0.3078722059726715
I0204 16:41:52.566676 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:41:53.946233 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:41:55.277441 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:41:56.606334 140584300062528 submission_runner.py:408] Time since start: 1720.79s, 	Step: 6869, 	{'train/ssim': 0.749246529170445, 'train/loss': 0.260955878666469, 'validation/ssim': 0.7226707445615855, 'validation/loss': 0.28755456755922026, 'validation/num_examples': 3554, 'test/ssim': 0.7399360339290701, 'test/loss': 0.2890012091812692, 'test/num_examples': 3581, 'score': 1635.2986016273499, 'total_duration': 1720.7873928546906, 'accumulated_submission_time': 1635.2986016273499, 'accumulated_eval_time': 84.75681829452515, 'accumulated_logging_time': 0.4930555820465088}
I0204 16:41:56.622967 140383296210688 logging_writer.py:48] [6869] accumulated_eval_time=84.756818, accumulated_logging_time=0.493056, accumulated_submission_time=1635.298602, global_step=6869, preemption_count=0, score=1635.298602, test/loss=0.289001, test/num_examples=3581, test/ssim=0.739936, total_duration=1720.787393, train/loss=0.260956, train/ssim=0.749247, validation/loss=0.287555, validation/num_examples=3554, validation/ssim=0.722671
I0204 16:42:01.941094 140379596986112 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.09296740591526031, loss=0.35122767090797424
I0204 16:42:25.554864 140383296210688 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.17688708007335663, loss=0.24363049864768982
I0204 16:42:49.391117 140379596986112 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.2238093763589859, loss=0.24649719893932343
I0204 16:43:13.123351 140383296210688 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.15091902017593384, loss=0.2750968933105469
I0204 16:43:16.677472 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:43:18.058551 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:43:19.387739 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:43:20.720587 140584300062528 submission_runner.py:408] Time since start: 1804.90s, 	Step: 7216, 	{'train/ssim': 0.7487942150660923, 'train/loss': 0.26176336833408903, 'validation/ssim': 0.7220146423923748, 'validation/loss': 0.2888460433006823, 'validation/num_examples': 3554, 'test/ssim': 0.7392699479457554, 'test/loss': 0.2902471376710416, 'test/num_examples': 3581, 'score': 1715.3318283557892, 'total_duration': 1804.9016375541687, 'accumulated_submission_time': 1715.3318283557892, 'accumulated_eval_time': 88.79988646507263, 'accumulated_logging_time': 0.5191292762756348}
I0204 16:43:20.736389 140379596986112 logging_writer.py:48] [7216] accumulated_eval_time=88.799886, accumulated_logging_time=0.519129, accumulated_submission_time=1715.331828, global_step=7216, preemption_count=0, score=1715.331828, test/loss=0.290247, test/num_examples=3581, test/ssim=0.739270, total_duration=1804.901638, train/loss=0.261763, train/ssim=0.748794, validation/loss=0.288846, validation/num_examples=3554, validation/ssim=0.722015
I0204 16:43:38.733281 140383296210688 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.09910377115011215, loss=0.2764173448085785
I0204 16:44:02.660099 140379596986112 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.26290979981422424, loss=0.2587539851665497
I0204 16:44:26.688704 140383296210688 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.11242307722568512, loss=0.2036609947681427
I0204 16:44:40.919114 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:44:42.300227 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:44:43.634800 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:44:44.965549 140584300062528 submission_runner.py:408] Time since start: 1889.15s, 	Step: 7561, 	{'train/ssim': 0.7482390403747559, 'train/loss': 0.2618751525878906, 'validation/ssim': 0.7224570356464547, 'validation/loss': 0.2880615852626442, 'validation/num_examples': 3554, 'test/ssim': 0.7396165580930606, 'test/loss': 0.2895986071780753, 'test/num_examples': 3581, 'score': 1795.4933722019196, 'total_duration': 1889.1465952396393, 'accumulated_submission_time': 1795.4933722019196, 'accumulated_eval_time': 92.84628129005432, 'accumulated_logging_time': 0.5441994667053223}
I0204 16:44:44.982565 140379596986112 logging_writer.py:48] [7561] accumulated_eval_time=92.846281, accumulated_logging_time=0.544199, accumulated_submission_time=1795.493372, global_step=7561, preemption_count=0, score=1795.493372, test/loss=0.289599, test/num_examples=3581, test/ssim=0.739617, total_duration=1889.146595, train/loss=0.261875, train/ssim=0.748239, validation/loss=0.288062, validation/num_examples=3554, validation/ssim=0.722457
I0204 16:44:52.379048 140383296210688 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.12963706254959106, loss=0.26161423325538635
I0204 16:45:16.237379 140379596986112 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.14038200676441193, loss=0.26491275429725647
I0204 16:45:40.053004 140383296210688 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.08476831763982773, loss=0.28001099824905396
I0204 16:46:03.960038 140379596986112 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.4567793905735016, loss=0.2676587402820587
I0204 16:46:05.035326 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:46:06.417618 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:46:07.750245 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:46:09.080430 140584300062528 submission_runner.py:408] Time since start: 1973.26s, 	Step: 7906, 	{'train/ssim': 0.7501950945172992, 'train/loss': 0.26023820468357634, 'validation/ssim': 0.7236638624613112, 'validation/loss': 0.28703231682721053, 'validation/num_examples': 3554, 'test/ssim': 0.7408963022069603, 'test/loss': 0.28841284459211813, 'test/num_examples': 3581, 'score': 1875.5250089168549, 'total_duration': 1973.2614433765411, 'accumulated_submission_time': 1875.5250089168549, 'accumulated_eval_time': 96.89130020141602, 'accumulated_logging_time': 0.5703647136688232}
I0204 16:46:09.100378 140383296210688 logging_writer.py:48] [7906] accumulated_eval_time=96.891300, accumulated_logging_time=0.570365, accumulated_submission_time=1875.525009, global_step=7906, preemption_count=0, score=1875.525009, test/loss=0.288413, test/num_examples=3581, test/ssim=0.740896, total_duration=1973.261443, train/loss=0.260238, train/ssim=0.750195, validation/loss=0.287032, validation/num_examples=3554, validation/ssim=0.723664
I0204 16:46:29.483944 140379596986112 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.07655295729637146, loss=0.2989596426486969
I0204 16:46:53.464636 140383296210688 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.28882598876953125, loss=0.2185067981481552
I0204 16:47:17.509162 140379596986112 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.03941755369305611, loss=0.275004118680954
I0204 16:47:29.140088 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:47:30.522591 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:47:31.855857 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:47:33.189168 140584300062528 submission_runner.py:408] Time since start: 2057.37s, 	Step: 8250, 	{'train/ssim': 0.7495725495474679, 'train/loss': 0.2608766555786133, 'validation/ssim': 0.7226769957706106, 'validation/loss': 0.28767801176381363, 'validation/num_examples': 3554, 'test/ssim': 0.739940397235409, 'test/loss': 0.289103440085259, 'test/num_examples': 3581, 'score': 1955.5428388118744, 'total_duration': 2057.3702251911163, 'accumulated_submission_time': 1955.5428388118744, 'accumulated_eval_time': 100.94035053253174, 'accumulated_logging_time': 0.6000580787658691}
I0204 16:47:33.210009 140383296210688 logging_writer.py:48] [8250] accumulated_eval_time=100.940351, accumulated_logging_time=0.600058, accumulated_submission_time=1955.542839, global_step=8250, preemption_count=0, score=1955.542839, test/loss=0.289103, test/num_examples=3581, test/ssim=0.739940, total_duration=2057.370225, train/loss=0.260877, train/ssim=0.749573, validation/loss=0.287678, validation/num_examples=3554, validation/ssim=0.722677
I0204 16:47:43.036606 140379596986112 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.28032222390174866, loss=0.24848398566246033
I0204 16:48:07.086266 140383296210688 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.05198539420962334, loss=0.2678765058517456
I0204 16:48:31.149963 140379596986112 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.26837173104286194, loss=0.35159435868263245
I0204 16:48:53.201492 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:48:54.585949 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:48:55.914875 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:48:57.246501 140584300062528 submission_runner.py:408] Time since start: 2141.43s, 	Step: 8593, 	{'train/ssim': 0.750629220690046, 'train/loss': 0.2605338437216623, 'validation/ssim': 0.723893233746307, 'validation/loss': 0.2872329394201516, 'validation/num_examples': 3554, 'test/ssim': 0.7411272165596202, 'test/loss': 0.2886298168174916, 'test/num_examples': 3581, 'score': 2035.5123291015625, 'total_duration': 2141.427557706833, 'accumulated_submission_time': 2035.5123291015625, 'accumulated_eval_time': 104.98532390594482, 'accumulated_logging_time': 0.6310033798217773}
I0204 16:48:57.263623 140383296210688 logging_writer.py:48] [8593] accumulated_eval_time=104.985324, accumulated_logging_time=0.631003, accumulated_submission_time=2035.512329, global_step=8593, preemption_count=0, score=2035.512329, test/loss=0.288630, test/num_examples=3581, test/ssim=0.741127, total_duration=2141.427558, train/loss=0.260534, train/ssim=0.750629, validation/loss=0.287233, validation/num_examples=3554, validation/ssim=0.723893
I0204 16:48:57.866499 140379596986112 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.14119964838027954, loss=0.3433520793914795
I0204 16:49:21.124112 140383296210688 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.4643101692199707, loss=0.20633646845817566
I0204 16:49:44.948909 140379596986112 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.1028955951333046, loss=0.203299880027771
I0204 16:50:08.915203 140383296210688 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.0671599879860878, loss=0.2327549159526825
I0204 16:50:17.403294 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:50:18.785856 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:50:20.116453 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:50:21.447357 140584300062528 submission_runner.py:408] Time since start: 2225.63s, 	Step: 8936, 	{'train/ssim': 0.751429694039481, 'train/loss': 0.2599715845925467, 'validation/ssim': 0.7244846255979178, 'validation/loss': 0.2870964088933684, 'validation/num_examples': 3554, 'test/ssim': 0.741647745370532, 'test/loss': 0.28856300368917553, 'test/num_examples': 3581, 'score': 2115.628773212433, 'total_duration': 2225.6283581256866, 'accumulated_submission_time': 2115.628773212433, 'accumulated_eval_time': 109.029296875, 'accumulated_logging_time': 0.6593132019042969}
I0204 16:50:21.468135 140379596986112 logging_writer.py:48] [8936] accumulated_eval_time=109.029297, accumulated_logging_time=0.659313, accumulated_submission_time=2115.628773, global_step=8936, preemption_count=0, score=2115.628773, test/loss=0.288563, test/num_examples=3581, test/ssim=0.741648, total_duration=2225.628358, train/loss=0.259972, train/ssim=0.751430, validation/loss=0.287096, validation/num_examples=3554, validation/ssim=0.724485
I0204 16:50:34.697861 140383296210688 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.5706885457038879, loss=0.1999463438987732
I0204 16:50:58.397275 140379596986112 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.2604382038116455, loss=0.3039606809616089
I0204 16:51:22.219165 140383296210688 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.2923539876937866, loss=0.21030117571353912
I0204 16:51:41.625905 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:51:43.007488 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:51:44.338351 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:51:45.670873 140584300062528 submission_runner.py:408] Time since start: 2309.85s, 	Step: 9282, 	{'train/ssim': 0.7505640983581543, 'train/loss': 0.2599564790725708, 'validation/ssim': 0.7239608979319077, 'validation/loss': 0.2866972417192776, 'validation/num_examples': 3554, 'test/ssim': 0.7411813488288885, 'test/loss': 0.2881314113332519, 'test/num_examples': 3581, 'score': 2195.7629470825195, 'total_duration': 2309.8518760204315, 'accumulated_submission_time': 2195.7629470825195, 'accumulated_eval_time': 113.07417154312134, 'accumulated_logging_time': 0.6917684078216553}
I0204 16:51:45.690607 140379596986112 logging_writer.py:48] [9282] accumulated_eval_time=113.074172, accumulated_logging_time=0.691768, accumulated_submission_time=2195.762947, global_step=9282, preemption_count=0, score=2195.762947, test/loss=0.288131, test/num_examples=3581, test/ssim=0.741181, total_duration=2309.851876, train/loss=0.259956, train/ssim=0.750564, validation/loss=0.286697, validation/num_examples=3554, validation/ssim=0.723961
I0204 16:51:47.957458 140383296210688 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.03906414285302162, loss=0.3183261752128601
I0204 16:52:11.914813 140379596986112 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.10915757715702057, loss=0.23039191961288452
I0204 16:52:35.829259 140383296210688 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.16567648947238922, loss=0.2692430317401886
I0204 16:52:59.875606 140379596986112 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.0763002336025238, loss=0.2703649699687958
I0204 16:53:05.883328 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:53:07.266487 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:53:08.597435 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:53:09.927628 140584300062528 submission_runner.py:408] Time since start: 2394.11s, 	Step: 9625, 	{'train/ssim': 0.746929236820766, 'train/loss': 0.2619223764964512, 'validation/ssim': 0.7217569689302546, 'validation/loss': 0.2881119899288214, 'validation/num_examples': 3554, 'test/ssim': 0.7387132173275621, 'test/loss': 0.28945066382251816, 'test/num_examples': 3581, 'score': 2275.9334716796875, 'total_duration': 2394.1086626052856, 'accumulated_submission_time': 2275.9334716796875, 'accumulated_eval_time': 117.11841011047363, 'accumulated_logging_time': 0.7217345237731934}
I0204 16:53:09.944539 140383296210688 logging_writer.py:48] [9625] accumulated_eval_time=117.118410, accumulated_logging_time=0.721735, accumulated_submission_time=2275.933472, global_step=9625, preemption_count=0, score=2275.933472, test/loss=0.289451, test/num_examples=3581, test/ssim=0.738713, total_duration=2394.108663, train/loss=0.261922, train/ssim=0.746929, validation/loss=0.288112, validation/num_examples=3554, validation/ssim=0.721757
I0204 16:53:25.984522 140379596986112 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.06435208022594452, loss=0.24756287038326263
I0204 16:53:49.706502 140383296210688 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.3578377068042755, loss=0.2620740532875061
I0204 16:54:13.593301 140379596986112 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.12461721897125244, loss=0.2529437839984894
I0204 16:54:30.115762 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:54:31.496202 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:54:32.826717 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:54:34.155620 140584300062528 submission_runner.py:408] Time since start: 2478.34s, 	Step: 9971, 	{'train/ssim': 0.7508612360273089, 'train/loss': 0.2593847853796823, 'validation/ssim': 0.7234695941193022, 'validation/loss': 0.2865976001952026, 'validation/num_examples': 3554, 'test/ssim': 0.740755926460835, 'test/loss': 0.2880375320703016, 'test/num_examples': 3581, 'score': 2356.0825872421265, 'total_duration': 2478.336655139923, 'accumulated_submission_time': 2356.0825872421265, 'accumulated_eval_time': 121.1582088470459, 'accumulated_logging_time': 0.7490215301513672}
I0204 16:54:34.172485 140383296210688 logging_writer.py:48] [9971] accumulated_eval_time=121.158209, accumulated_logging_time=0.749022, accumulated_submission_time=2356.082587, global_step=9971, preemption_count=0, score=2356.082587, test/loss=0.288038, test/num_examples=3581, test/ssim=0.740756, total_duration=2478.336655, train/loss=0.259385, train/ssim=0.750861, validation/loss=0.286598, validation/num_examples=3554, validation/ssim=0.723470
I0204 16:54:38.983009 140379596986112 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.10553234815597534, loss=0.24950096011161804
I0204 16:55:02.576175 140383296210688 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.07191473990678787, loss=0.28603851795196533
I0204 16:55:26.402988 140379596986112 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.07080931961536407, loss=0.3514356017112732
I0204 16:55:50.159754 140383296210688 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.06299993395805359, loss=0.24443142116069794
I0204 16:55:54.194191 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:55:55.574424 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:55:56.906035 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:55:58.235101 140584300062528 submission_runner.py:408] Time since start: 2562.42s, 	Step: 10318, 	{'train/ssim': 0.7500311306544712, 'train/loss': 0.25987511021750315, 'validation/ssim': 0.7230898503446821, 'validation/loss': 0.2866478846458216, 'validation/num_examples': 3554, 'test/ssim': 0.740412725146607, 'test/loss': 0.2879811158828714, 'test/num_examples': 3581, 'score': 2436.082048892975, 'total_duration': 2562.416161775589, 'accumulated_submission_time': 2436.082048892975, 'accumulated_eval_time': 125.19908928871155, 'accumulated_logging_time': 0.7764010429382324}
I0204 16:55:58.252004 140379596986112 logging_writer.py:48] [10318] accumulated_eval_time=125.199089, accumulated_logging_time=0.776401, accumulated_submission_time=2436.082049, global_step=10318, preemption_count=0, score=2436.082049, test/loss=0.287981, test/num_examples=3581, test/ssim=0.740413, total_duration=2562.416162, train/loss=0.259875, train/ssim=0.750031, validation/loss=0.286648, validation/num_examples=3554, validation/ssim=0.723090
I0204 16:56:15.848220 140383296210688 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.24823613464832306, loss=0.3074711561203003
I0204 16:56:39.567201 140379596986112 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.18094190955162048, loss=0.21511578559875488
I0204 16:57:03.343384 140383296210688 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.11688609421253204, loss=0.25442445278167725
I0204 16:57:18.301218 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:57:19.679885 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:57:21.008992 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:57:22.339107 140584300062528 submission_runner.py:408] Time since start: 2646.52s, 	Step: 10663, 	{'train/ssim': 0.7506626674107143, 'train/loss': 0.25970894949776785, 'validation/ssim': 0.724038454140581, 'validation/loss': 0.2864253484739906, 'validation/num_examples': 3554, 'test/ssim': 0.7412570930998673, 'test/loss': 0.28777968793633063, 'test/num_examples': 3581, 'score': 2516.108592271805, 'total_duration': 2646.5201659202576, 'accumulated_submission_time': 2516.108592271805, 'accumulated_eval_time': 129.23694705963135, 'accumulated_logging_time': 0.8038809299468994}
I0204 16:57:22.356488 140379596986112 logging_writer.py:48] [10663] accumulated_eval_time=129.236947, accumulated_logging_time=0.803881, accumulated_submission_time=2516.108592, global_step=10663, preemption_count=0, score=2516.108592, test/loss=0.287780, test/num_examples=3581, test/ssim=0.741257, total_duration=2646.520166, train/loss=0.259709, train/ssim=0.750663, validation/loss=0.286425, validation/num_examples=3554, validation/ssim=0.724038
I0204 16:57:29.060155 140383296210688 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.1771421581506729, loss=0.31591594219207764
I0204 16:57:52.998518 140379596986112 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.15891258418560028, loss=0.1953672468662262
I0204 16:58:17.060742 140383296210688 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.1508340686559677, loss=0.25679850578308105
I0204 16:58:40.725888 140379596986112 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.20231276750564575, loss=0.33263537287712097
I0204 16:58:42.482100 140584300062528 spec.py:321] Evaluating on the training split.
I0204 16:58:43.862988 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 16:58:45.192507 140584300062528 spec.py:349] Evaluating on the test split.
I0204 16:58:46.521496 140584300062528 submission_runner.py:408] Time since start: 2730.70s, 	Step: 11009, 	{'train/ssim': 0.7513034003121513, 'train/loss': 0.25934513977595736, 'validation/ssim': 0.7240849603879431, 'validation/loss': 0.2865712901616137, 'validation/num_examples': 3554, 'test/ssim': 0.7412414806443731, 'test/loss': 0.2879982623132505, 'test/num_examples': 3581, 'score': 2596.211658477783, 'total_duration': 2730.7025558948517, 'accumulated_submission_time': 2596.211658477783, 'accumulated_eval_time': 133.27631831169128, 'accumulated_logging_time': 0.8316900730133057}
I0204 16:58:46.538800 140383296210688 logging_writer.py:48] [11009] accumulated_eval_time=133.276318, accumulated_logging_time=0.831690, accumulated_submission_time=2596.211658, global_step=11009, preemption_count=0, score=2596.211658, test/loss=0.287998, test/num_examples=3581, test/ssim=0.741241, total_duration=2730.702556, train/loss=0.259345, train/ssim=0.751303, validation/loss=0.286571, validation/num_examples=3554, validation/ssim=0.724085
I0204 16:59:06.073018 140379596986112 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.30856263637542725, loss=0.2503141760826111
I0204 16:59:29.933712 140383296210688 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.16355086863040924, loss=0.24660761654376984
I0204 16:59:53.857752 140379596986112 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.09664440900087357, loss=0.3001217842102051
I0204 17:00:06.670812 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:00:08.053262 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:00:09.385638 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:00:10.719365 140584300062528 submission_runner.py:408] Time since start: 2814.90s, 	Step: 11355, 	{'train/ssim': 0.7510937282017299, 'train/loss': 0.2594878673553467, 'validation/ssim': 0.72414403774796, 'validation/loss': 0.28635278979780704, 'validation/num_examples': 3554, 'test/ssim': 0.7413318828975844, 'test/loss': 0.28778125599954624, 'test/num_examples': 3581, 'score': 2676.3213658332825, 'total_duration': 2814.900425195694, 'accumulated_submission_time': 2676.3213658332825, 'accumulated_eval_time': 137.32483291625977, 'accumulated_logging_time': 0.8595569133758545}
I0204 17:00:10.736640 140383296210688 logging_writer.py:48] [11355] accumulated_eval_time=137.324833, accumulated_logging_time=0.859557, accumulated_submission_time=2676.321366, global_step=11355, preemption_count=0, score=2676.321366, test/loss=0.287781, test/num_examples=3581, test/ssim=0.741332, total_duration=2814.900425, train/loss=0.259488, train/ssim=0.751094, validation/loss=0.286353, validation/num_examples=3554, validation/ssim=0.724144
I0204 17:00:19.560110 140379596986112 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.11831540614366531, loss=0.25939613580703735
I0204 17:00:43.451030 140383296210688 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.1769580841064453, loss=0.2903779149055481
I0204 17:01:07.659595 140379596986112 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.5534124970436096, loss=0.2459430992603302
I0204 17:01:30.730947 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:01:32.111005 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:01:33.440943 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:01:34.775046 140584300062528 submission_runner.py:408] Time since start: 2898.96s, 	Step: 11698, 	{'train/ssim': 0.7509194101606097, 'train/loss': 0.2594446284430368, 'validation/ssim': 0.7242609559651098, 'validation/loss': 0.28615287132456385, 'validation/num_examples': 3554, 'test/ssim': 0.7414494876387532, 'test/loss': 0.2875438307757086, 'test/num_examples': 3581, 'score': 2756.2938911914825, 'total_duration': 2898.9560811519623, 'accumulated_submission_time': 2756.2938911914825, 'accumulated_eval_time': 141.3688714504242, 'accumulated_logging_time': 0.8870675563812256}
I0204 17:01:34.795776 140383296210688 logging_writer.py:48] [11698] accumulated_eval_time=141.368871, accumulated_logging_time=0.887068, accumulated_submission_time=2756.293891, global_step=11698, preemption_count=0, score=2756.293891, test/loss=0.287544, test/num_examples=3581, test/ssim=0.741449, total_duration=2898.956081, train/loss=0.259445, train/ssim=0.750919, validation/loss=0.286153, validation/num_examples=3554, validation/ssim=0.724261
I0204 17:01:35.035181 140379596986112 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.0833917185664177, loss=0.2415362149477005
I0204 17:01:57.597955 140383296210688 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.10746176540851593, loss=0.2782055735588074
I0204 17:02:21.607208 140379596986112 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.14062808454036713, loss=0.33839547634124756
I0204 17:02:45.689489 140383296210688 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.24930720031261444, loss=0.3252066671848297
I0204 17:02:54.950338 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:02:56.333137 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:02:57.663537 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:02:58.994136 140584300062528 submission_runner.py:408] Time since start: 2983.18s, 	Step: 12040, 	{'train/ssim': 0.7494462558201381, 'train/loss': 0.2613473790032523, 'validation/ssim': 0.7227448660400253, 'validation/loss': 0.28805358234120004, 'validation/num_examples': 3554, 'test/ssim': 0.7397514797062622, 'test/loss': 0.2896840325349937, 'test/num_examples': 3581, 'score': 2836.426928758621, 'total_duration': 2983.175198316574, 'accumulated_submission_time': 2836.426928758621, 'accumulated_eval_time': 145.4126329421997, 'accumulated_logging_time': 0.9173834323883057}
I0204 17:02:59.011247 140379596986112 logging_writer.py:48] [12040] accumulated_eval_time=145.412633, accumulated_logging_time=0.917383, accumulated_submission_time=2836.426929, global_step=12040, preemption_count=0, score=2836.426929, test/loss=0.289684, test/num_examples=3581, test/ssim=0.739751, total_duration=2983.175198, train/loss=0.261347, train/ssim=0.749446, validation/loss=0.288054, validation/num_examples=3554, validation/ssim=0.722745
I0204 17:03:11.434912 140383296210688 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.4791482388973236, loss=0.22050239145755768
I0204 17:03:35.246615 140379596986112 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.20570498704910278, loss=0.2713330090045929
I0204 17:03:58.875397 140383296210688 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.06469486653804779, loss=0.27972611784935
I0204 17:04:19.038014 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:04:20.419324 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:04:21.750311 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:04:23.078769 140584300062528 submission_runner.py:408] Time since start: 3067.26s, 	Step: 12386, 	{'train/ssim': 0.750204358782087, 'train/loss': 0.2600323813302176, 'validation/ssim': 0.7231275636826463, 'validation/loss': 0.28711978223260765, 'validation/num_examples': 3554, 'test/ssim': 0.7402833940196524, 'test/loss': 0.28856290142418317, 'test/num_examples': 3581, 'score': 2916.4312081336975, 'total_duration': 3067.2598235607147, 'accumulated_submission_time': 2916.4312081336975, 'accumulated_eval_time': 149.45334696769714, 'accumulated_logging_time': 0.9447588920593262}
I0204 17:04:23.097008 140379596986112 logging_writer.py:48] [12386] accumulated_eval_time=149.453347, accumulated_logging_time=0.944759, accumulated_submission_time=2916.431208, global_step=12386, preemption_count=0, score=2916.431208, test/loss=0.288563, test/num_examples=3581, test/ssim=0.740283, total_duration=3067.259824, train/loss=0.260032, train/ssim=0.750204, validation/loss=0.287120, validation/num_examples=3554, validation/ssim=0.723128
I0204 17:04:24.436789 140383296210688 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.18605609238147736, loss=0.2518245577812195
I0204 17:04:48.179514 140379596986112 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.22032597661018372, loss=0.3323739171028137
I0204 17:05:11.988702 140383296210688 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.0934281125664711, loss=0.37123751640319824
I0204 17:05:35.873365 140379596986112 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.06403831392526627, loss=0.289617121219635
I0204 17:05:43.265227 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:05:44.645992 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:05:45.975799 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:05:47.305796 140584300062528 submission_runner.py:408] Time since start: 3151.49s, 	Step: 12733, 	{'train/ssim': 0.7511591911315918, 'train/loss': 0.2594108922140939, 'validation/ssim': 0.7242919372318163, 'validation/loss': 0.2863031064249789, 'validation/num_examples': 3554, 'test/ssim': 0.7415381172987643, 'test/loss': 0.2877028869270979, 'test/num_examples': 3581, 'score': 2996.577868938446, 'total_duration': 3151.4868512153625, 'accumulated_submission_time': 2996.577868938446, 'accumulated_eval_time': 153.49388575553894, 'accumulated_logging_time': 0.9722623825073242}
I0204 17:05:47.323601 140383296210688 logging_writer.py:48] [12733] accumulated_eval_time=153.493886, accumulated_logging_time=0.972262, accumulated_submission_time=2996.577869, global_step=12733, preemption_count=0, score=2996.577869, test/loss=0.287703, test/num_examples=3581, test/ssim=0.741538, total_duration=3151.486851, train/loss=0.259411, train/ssim=0.751159, validation/loss=0.286303, validation/num_examples=3554, validation/ssim=0.724292
I0204 17:06:01.286065 140379596986112 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.15411019325256348, loss=0.24926869571208954
I0204 17:06:25.660733 140383296210688 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.16421590745449066, loss=0.21803002059459686
I0204 17:06:49.317939 140379596986112 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.07219181209802628, loss=0.28327545523643494
I0204 17:07:07.358262 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:07:08.740775 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:07:10.070395 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:07:11.400645 140584300062528 submission_runner.py:408] Time since start: 3235.58s, 	Step: 13076, 	{'train/ssim': 0.7509640284946987, 'train/loss': 0.25927363123212543, 'validation/ssim': 0.7234867677704699, 'validation/loss': 0.28640760809233434, 'validation/num_examples': 3554, 'test/ssim': 0.7408127857965652, 'test/loss': 0.2877901871422089, 'test/num_examples': 3581, 'score': 3076.590484857559, 'total_duration': 3235.581696033478, 'accumulated_submission_time': 3076.590484857559, 'accumulated_eval_time': 157.53622794151306, 'accumulated_logging_time': 1.0001962184906006}
I0204 17:07:11.418632 140383296210688 logging_writer.py:48] [13076] accumulated_eval_time=157.536228, accumulated_logging_time=1.000196, accumulated_submission_time=3076.590485, global_step=13076, preemption_count=0, score=3076.590485, test/loss=0.287790, test/num_examples=3581, test/ssim=0.740813, total_duration=3235.581696, train/loss=0.259274, train/ssim=0.750964, validation/loss=0.286408, validation/num_examples=3554, validation/ssim=0.723487
I0204 17:07:15.112105 140379596986112 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.21390576660633087, loss=0.24020253121852875
I0204 17:07:38.882803 140383296210688 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.2572171688079834, loss=0.19093705713748932
I0204 17:08:02.807826 140379596986112 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.14545167982578278, loss=0.25479644536972046
I0204 17:08:26.365622 140383296210688 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.1256699115037918, loss=0.28638872504234314
I0204 17:08:31.449071 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:08:32.830723 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:08:34.162107 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:08:35.494041 140584300062528 submission_runner.py:408] Time since start: 3319.68s, 	Step: 13423, 	{'train/ssim': 0.7516891615731376, 'train/loss': 0.2590251309531076, 'validation/ssim': 0.7246937319745357, 'validation/loss': 0.28610693180769026, 'validation/num_examples': 3554, 'test/ssim': 0.7419136343505655, 'test/loss': 0.2874563601189437, 'test/num_examples': 3581, 'score': 3156.599609851837, 'total_duration': 3319.675098657608, 'accumulated_submission_time': 3156.599609851837, 'accumulated_eval_time': 161.58116555213928, 'accumulated_logging_time': 1.027517318725586}
I0204 17:08:35.512450 140379596986112 logging_writer.py:48] [13423] accumulated_eval_time=161.581166, accumulated_logging_time=1.027517, accumulated_submission_time=3156.599610, global_step=13423, preemption_count=0, score=3156.599610, test/loss=0.287456, test/num_examples=3581, test/ssim=0.741914, total_duration=3319.675099, train/loss=0.259025, train/ssim=0.751689, validation/loss=0.286107, validation/num_examples=3554, validation/ssim=0.724694
I0204 17:08:51.806541 140383296210688 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.12567348778247833, loss=0.26871463656425476
I0204 17:09:15.709282 140379596986112 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.10883335769176483, loss=0.2163071632385254
I0204 17:09:39.441613 140383296210688 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.12799133360385895, loss=0.327178031206131
I0204 17:09:55.594477 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:09:56.975239 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:09:58.308830 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:09:59.639077 140584300062528 submission_runner.py:408] Time since start: 3403.82s, 	Step: 13767, 	{'train/ssim': 0.7525512150355748, 'train/loss': 0.2592755045209612, 'validation/ssim': 0.725603042456563, 'validation/loss': 0.28627118060745815, 'validation/num_examples': 3554, 'test/ssim': 0.7428037488437238, 'test/loss': 0.2875207529757749, 'test/num_examples': 3581, 'score': 3236.6604750156403, 'total_duration': 3403.820134162903, 'accumulated_submission_time': 3236.6604750156403, 'accumulated_eval_time': 165.62573671340942, 'accumulated_logging_time': 1.0552878379821777}
I0204 17:09:59.657071 140379596986112 logging_writer.py:48] [13767] accumulated_eval_time=165.625737, accumulated_logging_time=1.055288, accumulated_submission_time=3236.660475, global_step=13767, preemption_count=0, score=3236.660475, test/loss=0.287521, test/num_examples=3581, test/ssim=0.742804, total_duration=3403.820134, train/loss=0.259276, train/ssim=0.752551, validation/loss=0.286271, validation/num_examples=3554, validation/ssim=0.725603
I0204 17:10:05.484984 140383296210688 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.0960211455821991, loss=0.21552620828151703
I0204 17:10:29.748063 140379596986112 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.3776797652244568, loss=0.23470062017440796
I0204 17:10:53.810342 140383296210688 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.2612082362174988, loss=0.3308072090148926
I0204 17:11:17.800067 140379596986112 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.1943747103214264, loss=0.2771150469779968
I0204 17:11:19.698905 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:11:21.081225 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:11:22.411859 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:11:23.742907 140584300062528 submission_runner.py:408] Time since start: 3487.92s, 	Step: 14109, 	{'train/ssim': 0.751023496900286, 'train/loss': 0.2595189298902239, 'validation/ssim': 0.7241041261826463, 'validation/loss': 0.2864473479211364, 'validation/num_examples': 3554, 'test/ssim': 0.7413269060012916, 'test/loss': 0.28778118782288464, 'test/num_examples': 3581, 'score': 3316.681303024292, 'total_duration': 3487.92396235466, 'accumulated_submission_time': 3316.681303024292, 'accumulated_eval_time': 169.66971588134766, 'accumulated_logging_time': 1.0825152397155762}
I0204 17:11:23.761168 140383296210688 logging_writer.py:48] [14109] accumulated_eval_time=169.669716, accumulated_logging_time=1.082515, accumulated_submission_time=3316.681303, global_step=14109, preemption_count=0, score=3316.681303, test/loss=0.287781, test/num_examples=3581, test/ssim=0.741327, total_duration=3487.923962, train/loss=0.259519, train/ssim=0.751023, validation/loss=0.286447, validation/num_examples=3554, validation/ssim=0.724104
I0204 17:11:43.444017 140379596986112 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.20678046345710754, loss=0.23693478107452393
I0204 17:12:07.204975 140383296210688 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.1497049778699875, loss=0.28799301385879517
I0204 17:12:30.950152 140379596986112 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.1247350350022316, loss=0.2283029556274414
I0204 17:12:43.797683 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:12:45.179793 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:12:46.509719 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:12:47.840376 140584300062528 submission_runner.py:408] Time since start: 3572.02s, 	Step: 14455, 	{'train/ssim': 0.7515461785452706, 'train/loss': 0.25904996054513113, 'validation/ssim': 0.7243747142304445, 'validation/loss': 0.2861744070831282, 'validation/num_examples': 3554, 'test/ssim': 0.741536821942195, 'test/loss': 0.2875540231866099, 'test/num_examples': 3581, 'score': 3396.6965384483337, 'total_duration': 3572.0214359760284, 'accumulated_submission_time': 3396.6965384483337, 'accumulated_eval_time': 173.71239233016968, 'accumulated_logging_time': 1.1100866794586182}
I0204 17:12:47.858428 140383296210688 logging_writer.py:48] [14455] accumulated_eval_time=173.712392, accumulated_logging_time=1.110087, accumulated_submission_time=3396.696538, global_step=14455, preemption_count=0, score=3396.696538, test/loss=0.287554, test/num_examples=3581, test/ssim=0.741537, total_duration=3572.021436, train/loss=0.259050, train/ssim=0.751546, validation/loss=0.286174, validation/num_examples=3554, validation/ssim=0.724375
I0204 17:12:56.680892 140379596986112 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.1270321160554886, loss=0.36484551429748535
I0204 17:13:20.666047 140383296210688 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.24106822907924652, loss=0.20400479435920715
I0204 17:13:44.741562 140379596986112 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.09541106224060059, loss=0.2235914170742035
I0204 17:14:07.895366 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:14:09.277505 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:14:10.608394 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:14:11.940752 140584300062528 submission_runner.py:408] Time since start: 3656.12s, 	Step: 14798, 	{'train/ssim': 0.7518469265529087, 'train/loss': 0.2589538437979562, 'validation/ssim': 0.7248509052300225, 'validation/loss': 0.2859152223397053, 'validation/num_examples': 3554, 'test/ssim': 0.7420895983140184, 'test/loss': 0.28719541394687237, 'test/num_examples': 3581, 'score': 3476.7126338481903, 'total_duration': 3656.121811389923, 'accumulated_submission_time': 3476.7126338481903, 'accumulated_eval_time': 177.75773978233337, 'accumulated_logging_time': 1.1371407508850098}
I0204 17:14:11.958856 140383296210688 logging_writer.py:48] [14798] accumulated_eval_time=177.757740, accumulated_logging_time=1.137141, accumulated_submission_time=3476.712634, global_step=14798, preemption_count=0, score=3476.712634, test/loss=0.287195, test/num_examples=3581, test/ssim=0.742090, total_duration=3656.121811, train/loss=0.258954, train/ssim=0.751847, validation/loss=0.285915, validation/num_examples=3554, validation/ssim=0.724851
I0204 17:14:12.196213 140379596986112 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.07158663123846054, loss=0.2661955952644348
I0204 17:14:34.418109 140383296210688 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.10769904404878616, loss=0.23443366587162018
I0204 17:14:58.306527 140379596986112 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.2161187082529068, loss=0.2277635931968689
I0204 17:15:23.000261 140383296210688 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.1422358900308609, loss=0.2076391577720642
I0204 17:15:31.961297 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:15:33.342327 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:15:34.672047 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:15:36.002886 140584300062528 submission_runner.py:408] Time since start: 3740.18s, 	Step: 15139, 	{'train/ssim': 0.7508306503295898, 'train/loss': 0.2592305285590036, 'validation/ssim': 0.723704598361881, 'validation/loss': 0.2860429084361371, 'validation/num_examples': 3554, 'test/ssim': 0.7410505178153798, 'test/loss': 0.28736681007400167, 'test/num_examples': 3581, 'score': 3556.6941096782684, 'total_duration': 3740.1839442253113, 'accumulated_submission_time': 3556.6941096782684, 'accumulated_eval_time': 181.7992980480194, 'accumulated_logging_time': 1.1644668579101562}
I0204 17:15:36.021606 140379596986112 logging_writer.py:48] [15139] accumulated_eval_time=181.799298, accumulated_logging_time=1.164467, accumulated_submission_time=3556.694110, global_step=15139, preemption_count=0, score=3556.694110, test/loss=0.287367, test/num_examples=3581, test/ssim=0.741051, total_duration=3740.183944, train/loss=0.259231, train/ssim=0.750831, validation/loss=0.286043, validation/num_examples=3554, validation/ssim=0.723705
I0204 17:15:48.778024 140383296210688 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.11096229404211044, loss=0.24423617124557495
I0204 17:16:12.760888 140379596986112 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.12391598522663116, loss=0.2415536344051361
I0204 17:16:36.362726 140383296210688 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.14898331463336945, loss=0.2343919426202774
I0204 17:16:56.048497 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:16:57.428461 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:16:58.763081 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:17:00.093148 140584300062528 submission_runner.py:408] Time since start: 3824.27s, 	Step: 15484, 	{'train/ssim': 0.7520397731236049, 'train/loss': 0.258493321282523, 'validation/ssim': 0.7246311511896807, 'validation/loss': 0.2858670845954822, 'validation/num_examples': 3554, 'test/ssim': 0.7418912042289165, 'test/loss': 0.2872118104339744, 'test/num_examples': 3581, 'score': 3636.6995763778687, 'total_duration': 3824.274204969406, 'accumulated_submission_time': 3636.6995763778687, 'accumulated_eval_time': 185.84392023086548, 'accumulated_logging_time': 1.192673683166504}
I0204 17:17:00.111441 140379596986112 logging_writer.py:48] [15484] accumulated_eval_time=185.843920, accumulated_logging_time=1.192674, accumulated_submission_time=3636.699576, global_step=15484, preemption_count=0, score=3636.699576, test/loss=0.287212, test/num_examples=3581, test/ssim=0.741891, total_duration=3824.274205, train/loss=0.258493, train/ssim=0.752040, validation/loss=0.285867, validation/num_examples=3554, validation/ssim=0.724631
I0204 17:17:01.893968 140383296210688 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.25242891907691956, loss=0.34679797291755676
I0204 17:17:25.673317 140379596986112 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.09117434173822403, loss=0.30396318435668945
I0204 17:17:49.256880 140383296210688 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.17995648086071014, loss=0.2457503229379654
I0204 17:18:13.263413 140379596986112 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.08936984837055206, loss=0.3033101260662079
I0204 17:18:20.143329 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:18:21.526043 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:18:22.857505 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:18:24.188498 140584300062528 submission_runner.py:408] Time since start: 3908.37s, 	Step: 15830, 	{'train/ssim': 0.7524919509887695, 'train/loss': 0.2586504561560495, 'validation/ssim': 0.7252742700786086, 'validation/loss': 0.2858471803337788, 'validation/num_examples': 3554, 'test/ssim': 0.7425571538589081, 'test/loss': 0.2872363199438006, 'test/num_examples': 3581, 'score': 3716.708996295929, 'total_duration': 3908.3695607185364, 'accumulated_submission_time': 3716.708996295929, 'accumulated_eval_time': 189.8890540599823, 'accumulated_logging_time': 1.2215955257415771}
I0204 17:18:24.208074 140383296210688 logging_writer.py:48] [15830] accumulated_eval_time=189.889054, accumulated_logging_time=1.221596, accumulated_submission_time=3716.708996, global_step=15830, preemption_count=0, score=3716.708996, test/loss=0.287236, test/num_examples=3581, test/ssim=0.742557, total_duration=3908.369561, train/loss=0.258650, train/ssim=0.752492, validation/loss=0.285847, validation/num_examples=3554, validation/ssim=0.725274
I0204 17:18:39.012814 140379596986112 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.15948672592639923, loss=0.297931969165802
I0204 17:19:02.935862 140383296210688 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.23896563053131104, loss=0.2241085171699524
I0204 17:19:27.124416 140379596986112 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.14241740107536316, loss=0.27653902769088745
I0204 17:19:44.296515 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:19:45.673022 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:19:47.001918 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:19:48.333283 140584300062528 submission_runner.py:408] Time since start: 3992.51s, 	Step: 16172, 	{'train/ssim': 0.752331052507673, 'train/loss': 0.25889621462140766, 'validation/ssim': 0.7253598635560284, 'validation/loss': 0.2859032351311902, 'validation/num_examples': 3554, 'test/ssim': 0.7425735162576794, 'test/loss': 0.28724842130122524, 'test/num_examples': 3581, 'score': 3796.7763459682465, 'total_duration': 3992.514327287674, 'accumulated_submission_time': 3796.7763459682465, 'accumulated_eval_time': 193.92577123641968, 'accumulated_logging_time': 1.2505333423614502}
I0204 17:19:48.351510 140383296210688 logging_writer.py:48] [16172] accumulated_eval_time=193.925771, accumulated_logging_time=1.250533, accumulated_submission_time=3796.776346, global_step=16172, preemption_count=0, score=3796.776346, test/loss=0.287248, test/num_examples=3581, test/ssim=0.742574, total_duration=3992.514327, train/loss=0.258896, train/ssim=0.752331, validation/loss=0.285903, validation/num_examples=3554, validation/ssim=0.725360
I0204 17:19:52.886140 140379596986112 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.10758954286575317, loss=0.25830063223838806
I0204 17:20:16.942678 140383296210688 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.2875262200832367, loss=0.22188398241996765
I0204 17:20:40.859490 140379596986112 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.2800346314907074, loss=0.2411908209323883
I0204 17:21:04.504103 140383296210688 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.1264781504869461, loss=0.20794418454170227
I0204 17:21:08.562132 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:21:09.943846 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:21:11.274979 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:21:12.608559 140584300062528 submission_runner.py:408] Time since start: 4076.79s, 	Step: 16518, 	{'train/ssim': 0.7533513477870396, 'train/loss': 0.2581365278788975, 'validation/ssim': 0.7257867318294527, 'validation/loss': 0.28566886631370464, 'validation/num_examples': 3554, 'test/ssim': 0.7430086197116728, 'test/loss': 0.28703189222415176, 'test/num_examples': 3581, 'score': 3876.9645669460297, 'total_duration': 4076.7896065711975, 'accumulated_submission_time': 3876.9645669460297, 'accumulated_eval_time': 197.97216725349426, 'accumulated_logging_time': 1.2790398597717285}
I0204 17:21:12.628190 140379596986112 logging_writer.py:48] [16518] accumulated_eval_time=197.972167, accumulated_logging_time=1.279040, accumulated_submission_time=3876.964567, global_step=16518, preemption_count=0, score=3876.964567, test/loss=0.287032, test/num_examples=3581, test/ssim=0.743009, total_duration=4076.789607, train/loss=0.258137, train/ssim=0.753351, validation/loss=0.285669, validation/num_examples=3554, validation/ssim=0.725787
I0204 17:21:30.058793 140383296210688 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.2541649043560028, loss=0.1886911243200302
I0204 17:21:53.732083 140379596986112 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.29615792632102966, loss=0.2660437822341919
I0204 17:22:17.533523 140383296210688 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.14609107375144958, loss=0.23720620572566986
I0204 17:22:32.719014 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:22:34.104696 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:22:35.437127 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:22:36.768863 140584300062528 submission_runner.py:408] Time since start: 4160.95s, 	Step: 16865, 	{'train/ssim': 0.7501613753182548, 'train/loss': 0.26048595564705984, 'validation/ssim': 0.7228891934044387, 'validation/loss': 0.2876615250586927, 'validation/num_examples': 3554, 'test/ssim': 0.7400654332326864, 'test/loss': 0.28903325221219633, 'test/num_examples': 3581, 'score': 3957.033786058426, 'total_duration': 4160.949885845184, 'accumulated_submission_time': 3957.033786058426, 'accumulated_eval_time': 202.02194118499756, 'accumulated_logging_time': 1.3082997798919678}
I0204 17:22:36.790066 140379596986112 logging_writer.py:48] [16865] accumulated_eval_time=202.021941, accumulated_logging_time=1.308300, accumulated_submission_time=3957.033786, global_step=16865, preemption_count=0, score=3957.033786, test/loss=0.289033, test/num_examples=3581, test/ssim=0.740065, total_duration=4160.949886, train/loss=0.260486, train/ssim=0.750161, validation/loss=0.287662, validation/num_examples=3554, validation/ssim=0.722889
I0204 17:22:43.160426 140383296210688 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.07571279257535934, loss=0.3546035885810852
I0204 17:23:07.000325 140379596986112 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.08219218999147415, loss=0.23977993428707123
I0204 17:23:31.022523 140383296210688 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.35982999205589294, loss=0.27584007382392883
I0204 17:23:55.298335 140379596986112 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.27450746297836304, loss=0.34417834877967834
I0204 17:23:56.875088 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:23:58.255281 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:23:59.585170 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:24:00.917700 140584300062528 submission_runner.py:408] Time since start: 4245.10s, 	Step: 17208, 	{'train/ssim': 0.7530238287789481, 'train/loss': 0.2587417704718454, 'validation/ssim': 0.7258637384812887, 'validation/loss': 0.28596162554516036, 'validation/num_examples': 3554, 'test/ssim': 0.7430537526616169, 'test/loss': 0.2873627876509704, 'test/num_examples': 3581, 'score': 4037.09632229805, 'total_duration': 4245.098760128021, 'accumulated_submission_time': 4037.09632229805, 'accumulated_eval_time': 206.06452655792236, 'accumulated_logging_time': 1.340169906616211}
I0204 17:24:00.936482 140383296210688 logging_writer.py:48] [17208] accumulated_eval_time=206.064527, accumulated_logging_time=1.340170, accumulated_submission_time=4037.096322, global_step=17208, preemption_count=0, score=4037.096322, test/loss=0.287363, test/num_examples=3581, test/ssim=0.743054, total_duration=4245.098760, train/loss=0.258742, train/ssim=0.753024, validation/loss=0.285962, validation/num_examples=3554, validation/ssim=0.725864
I0204 17:24:21.029854 140379596986112 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.11540617048740387, loss=0.30723607540130615
I0204 17:24:44.948611 140383296210688 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.2135418951511383, loss=0.2584335207939148
I0204 17:25:09.032784 140379596986112 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.1372002214193344, loss=0.3019309937953949
I0204 17:25:21.026356 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:25:22.409847 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:25:23.738765 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:25:25.067986 140584300062528 submission_runner.py:408] Time since start: 4329.25s, 	Step: 17550, 	{'train/ssim': 0.7533447401864188, 'train/loss': 0.258039082799639, 'validation/ssim': 0.7255524832275253, 'validation/loss': 0.2857619303293824, 'validation/num_examples': 3554, 'test/ssim': 0.7427513209909942, 'test/loss': 0.2871518490601438, 'test/num_examples': 3581, 'score': 4117.163950681686, 'total_duration': 4329.249045372009, 'accumulated_submission_time': 4117.163950681686, 'accumulated_eval_time': 210.106116771698, 'accumulated_logging_time': 1.3692708015441895}
I0204 17:25:25.087018 140383296210688 logging_writer.py:48] [17550] accumulated_eval_time=210.106117, accumulated_logging_time=1.369271, accumulated_submission_time=4117.163951, global_step=17550, preemption_count=0, score=4117.163951, test/loss=0.287152, test/num_examples=3581, test/ssim=0.742751, total_duration=4329.249045, train/loss=0.258039, train/ssim=0.753345, validation/loss=0.285762, validation/num_examples=3554, validation/ssim=0.725552
I0204 17:25:35.049218 140379596986112 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.17844250798225403, loss=0.25719153881073
I0204 17:25:58.741482 140383296210688 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.15155592560768127, loss=0.28587600588798523
I0204 17:26:22.630266 140379596986112 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.1925138384103775, loss=0.3616653382778168
I0204 17:26:45.221498 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:26:46.601441 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:26:47.932790 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:26:49.264803 140584300062528 submission_runner.py:408] Time since start: 4413.45s, 	Step: 17896, 	{'train/ssim': 0.7520776476178851, 'train/loss': 0.2586672987256731, 'validation/ssim': 0.7246424857994513, 'validation/loss': 0.28585690062033975, 'validation/num_examples': 3554, 'test/ssim': 0.7418576613114354, 'test/loss': 0.2872524778125873, 'test/num_examples': 3581, 'score': 4197.277628183365, 'total_duration': 4413.445830821991, 'accumulated_submission_time': 4197.277628183365, 'accumulated_eval_time': 214.1493580341339, 'accumulated_logging_time': 1.3973166942596436}
I0204 17:26:49.286669 140383296210688 logging_writer.py:48] [17896] accumulated_eval_time=214.149358, accumulated_logging_time=1.397317, accumulated_submission_time=4197.277628, global_step=17896, preemption_count=0, score=4197.277628, test/loss=0.287252, test/num_examples=3581, test/ssim=0.741858, total_duration=4413.445831, train/loss=0.258667, train/ssim=0.752078, validation/loss=0.285857, validation/num_examples=3554, validation/ssim=0.724642
I0204 17:26:49.672594 140379596986112 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.07467257976531982, loss=0.31996607780456543
I0204 17:27:12.065642 140383296210688 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.06804510951042175, loss=0.3674589991569519
I0204 17:27:35.962114 140379596986112 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.17531532049179077, loss=0.2297661155462265
I0204 17:27:59.859797 140383296210688 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.10119536519050598, loss=0.3583058714866638
I0204 17:28:09.381226 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:28:10.760266 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:28:12.090427 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:28:13.423388 140584300062528 submission_runner.py:408] Time since start: 4497.60s, 	Step: 18240, 	{'train/ssim': 0.7529400416782924, 'train/loss': 0.25858713899339947, 'validation/ssim': 0.7257781450038688, 'validation/loss': 0.285744481899796, 'validation/num_examples': 3554, 'test/ssim': 0.7430021429288257, 'test/loss': 0.28705023174610794, 'test/num_examples': 3581, 'score': 4277.350579023361, 'total_duration': 4497.604445934296, 'accumulated_submission_time': 4277.350579023361, 'accumulated_eval_time': 218.1914882659912, 'accumulated_logging_time': 1.4288592338562012}
I0204 17:28:13.442490 140379596986112 logging_writer.py:48] [18240] accumulated_eval_time=218.191488, accumulated_logging_time=1.428859, accumulated_submission_time=4277.350579, global_step=18240, preemption_count=0, score=4277.350579, test/loss=0.287050, test/num_examples=3581, test/ssim=0.743002, total_duration=4497.604446, train/loss=0.258587, train/ssim=0.752940, validation/loss=0.285744, validation/num_examples=3554, validation/ssim=0.725778
I0204 17:28:25.891522 140383296210688 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.39243626594543457, loss=0.20115791261196136
I0204 17:28:50.023673 140379596986112 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.10797999054193497, loss=0.2855479419231415
I0204 17:29:13.947097 140383296210688 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.22513167560100555, loss=0.23100675642490387
I0204 17:29:33.481318 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:29:34.864041 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:29:36.195888 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:29:37.527164 140584300062528 submission_runner.py:408] Time since start: 4581.71s, 	Step: 18583, 	{'train/ssim': 0.7526175635201591, 'train/loss': 0.25831386021205355, 'validation/ssim': 0.724809276299592, 'validation/loss': 0.28603803111920545, 'validation/num_examples': 3554, 'test/ssim': 0.7419922420413292, 'test/loss': 0.287416579036931, 'test/num_examples': 3581, 'score': 4357.3684694767, 'total_duration': 4581.708220720291, 'accumulated_submission_time': 4357.3684694767, 'accumulated_eval_time': 222.23729467391968, 'accumulated_logging_time': 1.456954002380371}
I0204 17:29:37.546431 140379596986112 logging_writer.py:48] [18583] accumulated_eval_time=222.237295, accumulated_logging_time=1.456954, accumulated_submission_time=4357.368469, global_step=18583, preemption_count=0, score=4357.368469, test/loss=0.287417, test/num_examples=3581, test/ssim=0.741992, total_duration=4581.708221, train/loss=0.258314, train/ssim=0.752618, validation/loss=0.286038, validation/num_examples=3554, validation/ssim=0.724809
I0204 17:29:39.605779 140383296210688 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.09806689620018005, loss=0.294297456741333
I0204 17:30:03.631149 140379596986112 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.1833248734474182, loss=0.30317798256874084
I0204 17:30:27.502223 140383296210688 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.10352557897567749, loss=0.25969284772872925
I0204 17:30:51.240657 140379596986112 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.15047569572925568, loss=0.2785571813583374
I0204 17:30:57.645927 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:30:59.026504 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:31:00.356435 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:31:01.684414 140584300062528 submission_runner.py:408] Time since start: 4665.87s, 	Step: 18928, 	{'train/ssim': 0.7526444707598005, 'train/loss': 0.2583979368209839, 'validation/ssim': 0.7252818264851224, 'validation/loss': 0.2857613464252427, 'validation/num_examples': 3554, 'test/ssim': 0.742520133931688, 'test/loss': 0.2870654692299637, 'test/num_examples': 3581, 'score': 4437.445201873779, 'total_duration': 4665.86545753479, 'accumulated_submission_time': 4437.445201873779, 'accumulated_eval_time': 226.27573919296265, 'accumulated_logging_time': 1.4869132041931152}
I0204 17:31:01.704950 140383296210688 logging_writer.py:48] [18928] accumulated_eval_time=226.275739, accumulated_logging_time=1.486913, accumulated_submission_time=4437.445202, global_step=18928, preemption_count=0, score=4437.445202, test/loss=0.287065, test/num_examples=3581, test/ssim=0.742520, total_duration=4665.865458, train/loss=0.258398, train/ssim=0.752644, validation/loss=0.285761, validation/num_examples=3554, validation/ssim=0.725282
I0204 17:31:16.777853 140379596986112 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.14218902587890625, loss=0.2926602363586426
I0204 17:31:40.332838 140383296210688 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.12513507902622223, loss=0.36329832673072815
I0204 17:32:04.202468 140379596986112 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.1950378119945526, loss=0.35165920853614807
I0204 17:32:21.743401 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:32:23.124354 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:32:24.455786 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:32:25.786344 140584300062528 submission_runner.py:408] Time since start: 4749.97s, 	Step: 19275, 	{'train/ssim': 0.7517557144165039, 'train/loss': 0.25839885643550325, 'validation/ssim': 0.7244192283342712, 'validation/loss': 0.2855900220811937, 'validation/num_examples': 3554, 'test/ssim': 0.7416877650708601, 'test/loss': 0.2868797560039095, 'test/num_examples': 3581, 'score': 4517.462399482727, 'total_duration': 4749.96740436554, 'accumulated_submission_time': 4517.462399482727, 'accumulated_eval_time': 230.3186469078064, 'accumulated_logging_time': 1.516965389251709}
I0204 17:32:25.805771 140383296210688 logging_writer.py:48] [19275] accumulated_eval_time=230.318647, accumulated_logging_time=1.516965, accumulated_submission_time=4517.462399, global_step=19275, preemption_count=0, score=4517.462399, test/loss=0.286880, test/num_examples=3581, test/ssim=0.741688, total_duration=4749.967404, train/loss=0.258399, train/ssim=0.751756, validation/loss=0.285590, validation/num_examples=3554, validation/ssim=0.724419
I0204 17:32:29.578887 140379596986112 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.10850697010755539, loss=0.3162285089492798
I0204 17:32:53.814652 140383296210688 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.15476113557815552, loss=0.2023657262325287
I0204 17:33:17.838935 140379596986112 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.24238556623458862, loss=0.31090787053108215
I0204 17:33:42.106102 140383296210688 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.1404099464416504, loss=0.2582895755767822
I0204 17:33:45.860124 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:33:47.243875 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:33:48.575786 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:33:49.906997 140584300062528 submission_runner.py:408] Time since start: 4834.09s, 	Step: 19617, 	{'train/ssim': 0.7539084298270089, 'train/loss': 0.2587548664637974, 'validation/ssim': 0.7266995457363182, 'validation/loss': 0.2865791213465462, 'validation/num_examples': 3554, 'test/ssim': 0.7436792735313111, 'test/loss': 0.28803296423397795, 'test/num_examples': 3581, 'score': 4597.49485373497, 'total_duration': 4834.088021278381, 'accumulated_submission_time': 4597.49485373497, 'accumulated_eval_time': 234.36544585227966, 'accumulated_logging_time': 1.5466229915618896}
I0204 17:33:49.930200 140379596986112 logging_writer.py:48] [19617] accumulated_eval_time=234.365446, accumulated_logging_time=1.546623, accumulated_submission_time=4597.494854, global_step=19617, preemption_count=0, score=4597.494854, test/loss=0.288033, test/num_examples=3581, test/ssim=0.743679, total_duration=4834.088021, train/loss=0.258755, train/ssim=0.753908, validation/loss=0.286579, validation/num_examples=3554, validation/ssim=0.726700
I0204 17:34:07.767776 140383296210688 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.28899529576301575, loss=0.24820539355278015
I0204 17:34:31.864090 140379596986112 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.08322564512491226, loss=0.284451961517334
I0204 17:34:55.747678 140383296210688 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.10388807952404022, loss=0.2757599949836731
I0204 17:35:10.136557 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:35:11.520663 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:35:12.851743 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:35:14.182563 140584300062528 submission_runner.py:408] Time since start: 4918.36s, 	Step: 19961, 	{'train/ssim': 0.7524251937866211, 'train/loss': 0.2587899650846209, 'validation/ssim': 0.7250721705516672, 'validation/loss': 0.2861384798048853, 'validation/num_examples': 3554, 'test/ssim': 0.7423036048546147, 'test/loss': 0.28748291492861633, 'test/num_examples': 3581, 'score': 4677.679318904877, 'total_duration': 4918.363613605499, 'accumulated_submission_time': 4677.679318904877, 'accumulated_eval_time': 238.41141080856323, 'accumulated_logging_time': 1.579699993133545}
I0204 17:35:14.201982 140379596986112 logging_writer.py:48] [19961] accumulated_eval_time=238.411411, accumulated_logging_time=1.579700, accumulated_submission_time=4677.679319, global_step=19961, preemption_count=0, score=4677.679319, test/loss=0.287483, test/num_examples=3581, test/ssim=0.742304, total_duration=4918.363614, train/loss=0.258790, train/ssim=0.752425, validation/loss=0.286138, validation/num_examples=3554, validation/ssim=0.725072
I0204 17:35:21.421037 140383296210688 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.19897642731666565, loss=0.3486297130584717
I0204 17:35:45.129297 140379596986112 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.15512658655643463, loss=0.4156346917152405
I0204 17:36:09.089401 140383296210688 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.34415170550346375, loss=0.2803419232368469
I0204 17:36:32.897728 140379596986112 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.10269114375114441, loss=0.24206824600696564
I0204 17:36:34.339973 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:36:35.722187 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:36:37.051306 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:36:38.379648 140584300062528 submission_runner.py:408] Time since start: 5002.56s, 	Step: 20307, 	{'train/ssim': 0.7524850709097726, 'train/loss': 0.25830018520355225, 'validation/ssim': 0.7251725333690912, 'validation/loss': 0.2855643646463492, 'validation/num_examples': 3554, 'test/ssim': 0.7423865076750559, 'test/loss': 0.2868783583823478, 'test/num_examples': 3581, 'score': 4757.7959949970245, 'total_duration': 5002.560688257217, 'accumulated_submission_time': 4757.7959949970245, 'accumulated_eval_time': 242.4510452747345, 'accumulated_logging_time': 1.6081418991088867}
I0204 17:36:38.400228 140383296210688 logging_writer.py:48] [20307] accumulated_eval_time=242.451045, accumulated_logging_time=1.608142, accumulated_submission_time=4757.795995, global_step=20307, preemption_count=0, score=4757.795995, test/loss=0.286878, test/num_examples=3581, test/ssim=0.742387, total_duration=5002.560688, train/loss=0.258300, train/ssim=0.752485, validation/loss=0.285564, validation/num_examples=3554, validation/ssim=0.725173
I0204 17:36:58.253465 140379596986112 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.0982850193977356, loss=0.2368963062763214
I0204 17:37:22.619702 140383296210688 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.4779316186904907, loss=0.2970238924026489
I0204 17:37:46.366080 140379596986112 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.1477297842502594, loss=0.24054305255413055
I0204 17:37:58.384085 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:37:59.765397 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:38:01.098083 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:38:02.430565 140584300062528 submission_runner.py:408] Time since start: 5086.61s, 	Step: 20651, 	{'train/ssim': 0.7529078211103167, 'train/loss': 0.2586125305720738, 'validation/ssim': 0.7252262525499438, 'validation/loss': 0.28611390431006434, 'validation/num_examples': 3554, 'test/ssim': 0.7424755463950363, 'test/loss': 0.2873984440449595, 'test/num_examples': 3581, 'score': 4837.757677555084, 'total_duration': 5086.611615896225, 'accumulated_submission_time': 4837.757677555084, 'accumulated_eval_time': 246.49749064445496, 'accumulated_logging_time': 1.6389946937561035}
I0204 17:38:02.449888 140383296210688 logging_writer.py:48] [20651] accumulated_eval_time=246.497491, accumulated_logging_time=1.638995, accumulated_submission_time=4837.757678, global_step=20651, preemption_count=0, score=4837.757678, test/loss=0.287398, test/num_examples=3581, test/ssim=0.742476, total_duration=5086.611616, train/loss=0.258613, train/ssim=0.752908, validation/loss=0.286114, validation/num_examples=3554, validation/ssim=0.725226
I0204 17:38:11.973998 140379596986112 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.10625384747982025, loss=0.23040197789669037
I0204 17:38:35.695782 140383296210688 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.08460834622383118, loss=0.2707635462284088
I0204 17:38:59.527459 140379596986112 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.18877269327640533, loss=0.28524067997932434
I0204 17:39:22.588225 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:39:23.970098 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:39:25.297926 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:39:26.626220 140584300062528 submission_runner.py:408] Time since start: 5170.81s, 	Step: 20998, 	{'train/ssim': 0.7535805702209473, 'train/loss': 0.25805178710392546, 'validation/ssim': 0.72609613232889, 'validation/loss': 0.2855590923354407, 'validation/num_examples': 3554, 'test/ssim': 0.743132905765673, 'test/loss': 0.28694858034374127, 'test/num_examples': 3581, 'score': 4917.874920606613, 'total_duration': 5170.8072781562805, 'accumulated_submission_time': 4917.874920606613, 'accumulated_eval_time': 250.53546237945557, 'accumulated_logging_time': 1.667454719543457}
I0204 17:39:26.646275 140383296210688 logging_writer.py:48] [20998] accumulated_eval_time=250.535462, accumulated_logging_time=1.667455, accumulated_submission_time=4917.874921, global_step=20998, preemption_count=0, score=4917.874921, test/loss=0.286949, test/num_examples=3581, test/ssim=0.743133, total_duration=5170.807278, train/loss=0.258052, train/ssim=0.753581, validation/loss=0.285559, validation/num_examples=3554, validation/ssim=0.726096
I0204 17:39:26.888967 140379596986112 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.22462645173072815, loss=0.39059311151504517
I0204 17:39:49.077578 140383296210688 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.14898991584777832, loss=0.2834269404411316
I0204 17:40:13.241770 140379596986112 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.13445958495140076, loss=0.2206866592168808
I0204 17:40:37.201872 140383296210688 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.14676232635974884, loss=0.30273374915122986
I0204 17:40:46.861086 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:40:48.241104 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:40:49.569847 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:40:50.899233 140584300062528 submission_runner.py:408] Time since start: 5255.08s, 	Step: 21342, 	{'train/ssim': 0.7533642905099052, 'train/loss': 0.25808894634246826, 'validation/ssim': 0.7260072415104459, 'validation/loss': 0.28545465936268993, 'validation/num_examples': 3554, 'test/ssim': 0.7431851972650796, 'test/loss': 0.28677582068338103, 'test/num_examples': 3581, 'score': 4998.068671941757, 'total_duration': 5255.080285787582, 'accumulated_submission_time': 4998.068671941757, 'accumulated_eval_time': 254.57356691360474, 'accumulated_logging_time': 1.696807622909546}
I0204 17:40:50.919404 140379596986112 logging_writer.py:48] [21342] accumulated_eval_time=254.573567, accumulated_logging_time=1.696808, accumulated_submission_time=4998.068672, global_step=21342, preemption_count=0, score=4998.068672, test/loss=0.286776, test/num_examples=3581, test/ssim=0.743185, total_duration=5255.080286, train/loss=0.258089, train/ssim=0.753364, validation/loss=0.285455, validation/num_examples=3554, validation/ssim=0.726007
I0204 17:41:02.849240 140383296210688 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.16747280955314636, loss=0.25510475039482117
I0204 17:41:26.829545 140379596986112 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.11639337986707687, loss=0.25310707092285156
I0204 17:41:51.186826 140383296210688 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.13293607532978058, loss=0.23537437617778778
I0204 17:42:11.088143 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:42:12.468748 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:42:13.800513 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:42:15.132561 140584300062528 submission_runner.py:408] Time since start: 5339.31s, 	Step: 21685, 	{'train/ssim': 0.7526271683829171, 'train/loss': 0.2587615592139108, 'validation/ssim': 0.7254229252031162, 'validation/loss': 0.2861455725228176, 'validation/num_examples': 3554, 'test/ssim': 0.7425711300745252, 'test/loss': 0.28759192941043005, 'test/num_examples': 3581, 'score': 5078.216583013535, 'total_duration': 5339.313606500626, 'accumulated_submission_time': 5078.216583013535, 'accumulated_eval_time': 258.6179361343384, 'accumulated_logging_time': 1.7260563373565674}
I0204 17:42:15.153034 140379596986112 logging_writer.py:48] [21685] accumulated_eval_time=258.617936, accumulated_logging_time=1.726056, accumulated_submission_time=5078.216583, global_step=21685, preemption_count=0, score=5078.216583, test/loss=0.287592, test/num_examples=3581, test/ssim=0.742571, total_duration=5339.313607, train/loss=0.258762, train/ssim=0.752627, validation/loss=0.286146, validation/num_examples=3554, validation/ssim=0.725423
I0204 17:42:16.757889 140383296210688 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.06830861419439316, loss=0.39718905091285706
I0204 17:42:40.589483 140379596986112 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.312494158744812, loss=0.18065136671066284
I0204 17:43:04.220837 140383296210688 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.2097053974866867, loss=0.2771419584751129
I0204 17:43:28.013936 140379596986112 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.2346736639738083, loss=0.35481640696525574
I0204 17:43:35.215169 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:43:36.594090 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:43:37.924294 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:43:39.256192 140584300062528 submission_runner.py:408] Time since start: 5423.44s, 	Step: 22031, 	{'train/ssim': 0.7523194040570941, 'train/loss': 0.2580763101577759, 'validation/ssim': 0.7246382954285664, 'validation/loss': 0.2857501663783325, 'validation/num_examples': 3554, 'test/ssim': 0.7418408898526948, 'test/loss': 0.28712747590364074, 'test/num_examples': 3581, 'score': 5158.255975008011, 'total_duration': 5423.437246322632, 'accumulated_submission_time': 5158.255975008011, 'accumulated_eval_time': 262.6589164733887, 'accumulated_logging_time': 1.7574434280395508}
I0204 17:43:39.276563 140383296210688 logging_writer.py:48] [22031] accumulated_eval_time=262.658916, accumulated_logging_time=1.757443, accumulated_submission_time=5158.255975, global_step=22031, preemption_count=0, score=5158.255975, test/loss=0.287127, test/num_examples=3581, test/ssim=0.741841, total_duration=5423.437246, train/loss=0.258076, train/ssim=0.752319, validation/loss=0.285750, validation/num_examples=3554, validation/ssim=0.724638
I0204 17:43:53.673737 140379596986112 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.10015154629945755, loss=0.2921832203865051
I0204 17:44:17.647006 140383296210688 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.11988747119903564, loss=0.27281326055526733
I0204 17:44:41.526705 140379596986112 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.2856878638267517, loss=0.2515231668949127
I0204 17:44:59.410496 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:45:00.791652 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:45:02.122691 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:45:03.452815 140584300062528 submission_runner.py:408] Time since start: 5507.63s, 	Step: 22376, 	{'train/ssim': 0.7534683772495815, 'train/loss': 0.2578743355614798, 'validation/ssim': 0.7259059169685566, 'validation/loss': 0.2853841786982977, 'validation/num_examples': 3554, 'test/ssim': 0.743134405652227, 'test/loss': 0.2867114619148806, 'test/num_examples': 3581, 'score': 5238.368992090225, 'total_duration': 5507.633875846863, 'accumulated_submission_time': 5238.368992090225, 'accumulated_eval_time': 266.70121240615845, 'accumulated_logging_time': 1.7868409156799316}
I0204 17:45:03.472936 140383296210688 logging_writer.py:48] [22376] accumulated_eval_time=266.701212, accumulated_logging_time=1.786841, accumulated_submission_time=5238.368992, global_step=22376, preemption_count=0, score=5238.368992, test/loss=0.286711, test/num_examples=3581, test/ssim=0.743134, total_duration=5507.633876, train/loss=0.257874, train/ssim=0.753468, validation/loss=0.285384, validation/num_examples=3554, validation/ssim=0.725906
I0204 17:45:07.113333 140379596986112 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.17764528095722198, loss=0.28936246037483215
I0204 17:45:30.817194 140383296210688 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.3230321407318115, loss=0.241997629404068
I0204 17:45:54.869757 140379596986112 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.18032659590244293, loss=0.2384338676929474
I0204 17:46:19.247316 140383296210688 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.18101650476455688, loss=0.1952562779188156
I0204 17:46:23.481507 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:46:24.862882 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:46:26.194367 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:46:27.526824 140584300062528 submission_runner.py:408] Time since start: 5591.71s, 	Step: 22719, 	{'train/ssim': 0.753256116594587, 'train/loss': 0.25782101494925364, 'validation/ssim': 0.7257600096282358, 'validation/loss': 0.285283953270083, 'validation/num_examples': 3554, 'test/ssim': 0.7429689408946524, 'test/loss': 0.2866599544470818, 'test/num_examples': 3581, 'score': 5318.3560972213745, 'total_duration': 5591.70784330368, 'accumulated_submission_time': 5318.3560972213745, 'accumulated_eval_time': 270.7464687824249, 'accumulated_logging_time': 1.8165028095245361}
I0204 17:46:27.552402 140379596986112 logging_writer.py:48] [22719] accumulated_eval_time=270.746469, accumulated_logging_time=1.816503, accumulated_submission_time=5318.356097, global_step=22719, preemption_count=0, score=5318.356097, test/loss=0.286660, test/num_examples=3581, test/ssim=0.742969, total_duration=5591.707843, train/loss=0.257821, train/ssim=0.753256, validation/loss=0.285284, validation/num_examples=3554, validation/ssim=0.725760
I0204 17:46:45.004065 140383296210688 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.19999133050441742, loss=0.2347600758075714
I0204 17:47:08.785067 140379596986112 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.4409804940223694, loss=0.19523371756076813
I0204 17:47:32.593182 140383296210688 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.17151299118995667, loss=0.2697732448577881
I0204 17:47:47.622981 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:47:49.002069 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:47:50.329139 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:47:51.659185 140584300062528 submission_runner.py:408] Time since start: 5675.84s, 	Step: 23065, 	{'train/ssim': 0.7534429005214146, 'train/loss': 0.25738087722233366, 'validation/ssim': 0.7255944556309791, 'validation/loss': 0.2852384774417909, 'validation/num_examples': 3554, 'test/ssim': 0.7428008854239389, 'test/loss': 0.2866411376884948, 'test/num_examples': 3581, 'score': 5398.403444766998, 'total_duration': 5675.84022974968, 'accumulated_submission_time': 5398.403444766998, 'accumulated_eval_time': 274.7826302051544, 'accumulated_logging_time': 1.8535089492797852}
I0204 17:47:51.679908 140379596986112 logging_writer.py:48] [23065] accumulated_eval_time=274.782630, accumulated_logging_time=1.853509, accumulated_submission_time=5398.403445, global_step=23065, preemption_count=0, score=5398.403445, test/loss=0.286641, test/num_examples=3581, test/ssim=0.742801, total_duration=5675.840230, train/loss=0.257381, train/ssim=0.753443, validation/loss=0.285238, validation/num_examples=3554, validation/ssim=0.725594
I0204 17:47:58.041707 140383296210688 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.20393167436122894, loss=0.301768958568573
I0204 17:48:21.736920 140379596986112 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.14429296553134918, loss=0.32802391052246094
I0204 17:48:45.496577 140383296210688 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.2502698600292206, loss=0.25022801756858826
I0204 17:49:09.495536 140379596986112 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.1457185298204422, loss=0.3081863522529602
I0204 17:49:11.834076 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:49:13.215233 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:49:14.544616 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:49:15.877208 140584300062528 submission_runner.py:408] Time since start: 5760.06s, 	Step: 23411, 	{'train/ssim': 0.7532764162336077, 'train/loss': 0.25764104298182894, 'validation/ssim': 0.7255148385841658, 'validation/loss': 0.2853181631832091, 'validation/num_examples': 3554, 'test/ssim': 0.7427481166879014, 'test/loss': 0.28663442228733244, 'test/num_examples': 3581, 'score': 5478.536856174469, 'total_duration': 5760.058264970779, 'accumulated_submission_time': 5478.536856174469, 'accumulated_eval_time': 278.8257200717926, 'accumulated_logging_time': 1.882972240447998}
I0204 17:49:15.897819 140383296210688 logging_writer.py:48] [23411] accumulated_eval_time=278.825720, accumulated_logging_time=1.882972, accumulated_submission_time=5478.536856, global_step=23411, preemption_count=0, score=5478.536856, test/loss=0.286634, test/num_examples=3581, test/ssim=0.742748, total_duration=5760.058265, train/loss=0.257641, train/ssim=0.753276, validation/loss=0.285318, validation/num_examples=3554, validation/ssim=0.725515
I0204 17:49:35.164475 140379596986112 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.30623558163642883, loss=0.23183366656303406
I0204 17:49:59.166506 140383296210688 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.09434745460748672, loss=0.23493871092796326
I0204 17:50:23.393233 140379596986112 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.15310873091220856, loss=0.2954975366592407
I0204 17:50:35.922939 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:50:37.305727 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:50:38.637485 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:50:39.967000 140584300062528 submission_runner.py:408] Time since start: 5844.15s, 	Step: 23752, 	{'train/ssim': 0.7536858149937221, 'train/loss': 0.25762769154139925, 'validation/ssim': 0.7259083899743247, 'validation/loss': 0.2852405726272334, 'validation/num_examples': 3554, 'test/ssim': 0.7431360418921041, 'test/loss': 0.28656464347423904, 'test/num_examples': 3581, 'score': 5558.539285182953, 'total_duration': 5844.148059844971, 'accumulated_submission_time': 5558.539285182953, 'accumulated_eval_time': 282.8697578907013, 'accumulated_logging_time': 1.914400339126587}
I0204 17:50:39.987363 140383296210688 logging_writer.py:48] [23752] accumulated_eval_time=282.869758, accumulated_logging_time=1.914400, accumulated_submission_time=5558.539285, global_step=23752, preemption_count=0, score=5558.539285, test/loss=0.286565, test/num_examples=3581, test/ssim=0.743136, total_duration=5844.148060, train/loss=0.257628, train/ssim=0.753686, validation/loss=0.285241, validation/num_examples=3554, validation/ssim=0.725908
I0204 17:50:49.407961 140379596986112 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.19841258227825165, loss=0.23848949372768402
I0204 17:51:13.543054 140383296210688 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.21004851162433624, loss=0.2214076668024063
I0204 17:51:37.299126 140379596986112 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.14942948520183563, loss=0.2377491593360901
I0204 17:52:00.042042 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:52:01.420704 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:52:02.747369 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:52:04.077135 140584300062528 submission_runner.py:408] Time since start: 5928.26s, 	Step: 24097, 	{'train/ssim': 0.754117625100272, 'train/loss': 0.25708154269627165, 'validation/ssim': 0.7259977616550014, 'validation/loss': 0.2851191377398266, 'validation/num_examples': 3554, 'test/ssim': 0.7432274667952388, 'test/loss': 0.28648681981508306, 'test/num_examples': 3581, 'score': 5638.572496652603, 'total_duration': 5928.258192777634, 'accumulated_submission_time': 5638.572496652603, 'accumulated_eval_time': 286.9048192501068, 'accumulated_logging_time': 1.944274663925171}
I0204 17:52:04.097554 140383296210688 logging_writer.py:48] [24097] accumulated_eval_time=286.904819, accumulated_logging_time=1.944275, accumulated_submission_time=5638.572497, global_step=24097, preemption_count=0, score=5638.572497, test/loss=0.286487, test/num_examples=3581, test/ssim=0.743227, total_duration=5928.258193, train/loss=0.257082, train/ssim=0.754118, validation/loss=0.285119, validation/num_examples=3554, validation/ssim=0.725998
I0204 17:52:04.406552 140379596986112 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.15182283520698547, loss=0.32699722051620483
I0204 17:52:26.569309 140383296210688 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.14512999355793, loss=0.259987473487854
I0204 17:52:50.578482 140379596986112 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.11991868168115616, loss=0.2374071180820465
I0204 17:53:14.553217 140383296210688 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.3821457326412201, loss=0.18918141722679138
I0204 17:53:24.242174 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:53:25.624606 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:53:26.955198 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:53:28.285270 140584300062528 submission_runner.py:408] Time since start: 6012.47s, 	Step: 24442, 	{'train/ssim': 0.7537539345877511, 'train/loss': 0.25759732723236084, 'validation/ssim': 0.7259774280520188, 'validation/loss': 0.2854220294254713, 'validation/num_examples': 3554, 'test/ssim': 0.7431903105146956, 'test/loss': 0.28672366553729756, 'test/num_examples': 3581, 'score': 5718.696158885956, 'total_duration': 6012.466329336166, 'accumulated_submission_time': 5718.696158885956, 'accumulated_eval_time': 290.94787549972534, 'accumulated_logging_time': 1.973649024963379}
I0204 17:53:28.306139 140379596986112 logging_writer.py:48] [24442] accumulated_eval_time=290.947875, accumulated_logging_time=1.973649, accumulated_submission_time=5718.696159, global_step=24442, preemption_count=0, score=5718.696159, test/loss=0.286724, test/num_examples=3581, test/ssim=0.743190, total_duration=6012.466329, train/loss=0.257597, train/ssim=0.753754, validation/loss=0.285422, validation/num_examples=3554, validation/ssim=0.725977
I0204 17:53:40.176569 140383296210688 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.079170361161232, loss=0.29471951723098755
I0204 17:54:04.278519 140379596986112 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.12152273207902908, loss=0.2844741642475128
I0204 17:54:27.847933 140383296210688 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.18640649318695068, loss=0.25294074416160583
I0204 17:54:48.322770 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:54:49.705221 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:54:51.037604 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:54:52.369860 140584300062528 submission_runner.py:408] Time since start: 6096.55s, 	Step: 24786, 	{'train/ssim': 0.753805433000837, 'train/loss': 0.2577033042907715, 'validation/ssim': 0.7263403416484947, 'validation/loss': 0.28535196092870707, 'validation/num_examples': 3554, 'test/ssim': 0.7434939693652262, 'test/loss': 0.28660728797603674, 'test/num_examples': 3581, 'score': 5798.691824436188, 'total_duration': 6096.550888776779, 'accumulated_submission_time': 5798.691824436188, 'accumulated_eval_time': 294.99489879608154, 'accumulated_logging_time': 2.0035831928253174}
I0204 17:54:52.393846 140379596986112 logging_writer.py:48] [24786] accumulated_eval_time=294.994899, accumulated_logging_time=2.003583, accumulated_submission_time=5798.691824, global_step=24786, preemption_count=0, score=5798.691824, test/loss=0.286607, test/num_examples=3581, test/ssim=0.743494, total_duration=6096.550889, train/loss=0.257703, train/ssim=0.753805, validation/loss=0.285352, validation/num_examples=3554, validation/ssim=0.726340
I0204 17:54:53.596615 140383296210688 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.14307883381843567, loss=0.27247557044029236
I0204 17:55:17.762886 140379596986112 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.06076226010918617, loss=0.26005733013153076
I0204 17:55:42.089296 140383296210688 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.09037719666957855, loss=0.2486153393983841
I0204 17:56:05.976973 140379596986112 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.13222211599349976, loss=0.2822401523590088
I0204 17:56:12.379638 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:56:13.760631 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:56:15.089694 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:56:16.418426 140584300062528 submission_runner.py:408] Time since start: 6180.60s, 	Step: 25128, 	{'train/ssim': 0.7541419437953404, 'train/loss': 0.25712132453918457, 'validation/ssim': 0.725858655080543, 'validation/loss': 0.28531630842888295, 'validation/num_examples': 3554, 'test/ssim': 0.7430844321593131, 'test/loss': 0.28664308072334893, 'test/num_examples': 3581, 'score': 5878.656435251236, 'total_duration': 6180.59944486618, 'accumulated_submission_time': 5878.656435251236, 'accumulated_eval_time': 299.0336084365845, 'accumulated_logging_time': 2.036623239517212}
I0204 17:56:16.444670 140383296210688 logging_writer.py:48] [25128] accumulated_eval_time=299.033608, accumulated_logging_time=2.036623, accumulated_submission_time=5878.656435, global_step=25128, preemption_count=0, score=5878.656435, test/loss=0.286643, test/num_examples=3581, test/ssim=0.743084, total_duration=6180.599445, train/loss=0.257121, train/ssim=0.754142, validation/loss=0.285316, validation/num_examples=3554, validation/ssim=0.725859
I0204 17:56:31.611042 140379596986112 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.16117510199546814, loss=0.228404238820076
I0204 17:56:55.485673 140383296210688 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.10066944360733032, loss=0.20161478221416473
I0204 17:57:19.430999 140379596986112 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.16409596800804138, loss=0.21837174892425537
I0204 17:57:36.633121 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:57:38.011158 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:57:39.339837 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:57:40.668776 140584300062528 submission_runner.py:408] Time since start: 6264.85s, 	Step: 25473, 	{'train/ssim': 0.7536706243242536, 'train/loss': 0.25753794397626606, 'validation/ssim': 0.7256218647782429, 'validation/loss': 0.2854699439122292, 'validation/num_examples': 3554, 'test/ssim': 0.7428558358131457, 'test/loss': 0.2867858085642977, 'test/num_examples': 3581, 'score': 5958.823487281799, 'total_duration': 6264.849833726883, 'accumulated_submission_time': 5958.823487281799, 'accumulated_eval_time': 303.0692329406738, 'accumulated_logging_time': 2.072427272796631}
I0204 17:57:40.690025 140383296210688 logging_writer.py:48] [25473] accumulated_eval_time=303.069233, accumulated_logging_time=2.072427, accumulated_submission_time=5958.823487, global_step=25473, preemption_count=0, score=5958.823487, test/loss=0.286786, test/num_examples=3581, test/ssim=0.742856, total_duration=6264.849834, train/loss=0.257538, train/ssim=0.753671, validation/loss=0.285470, validation/num_examples=3554, validation/ssim=0.725622
I0204 17:57:45.057713 140379596986112 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.1396869421005249, loss=0.2534094452857971
I0204 17:58:08.988366 140383296210688 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.058779388666152954, loss=0.33187922835350037
I0204 17:58:32.730811 140379596986112 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.09589246660470963, loss=0.4117438495159149
I0204 17:58:56.477534 140383296210688 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.0697905495762825, loss=0.27733245491981506
I0204 17:59:00.873163 140584300062528 spec.py:321] Evaluating on the training split.
I0204 17:59:02.253698 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 17:59:03.584277 140584300062528 spec.py:349] Evaluating on the test split.
I0204 17:59:04.915315 140584300062528 submission_runner.py:408] Time since start: 6349.10s, 	Step: 25820, 	{'train/ssim': 0.7535369055611747, 'train/loss': 0.2573683943067278, 'validation/ssim': 0.7258339937174663, 'validation/loss': 0.28513771963039003, 'validation/num_examples': 3554, 'test/ssim': 0.7430077334150726, 'test/loss': 0.28644117554017734, 'test/num_examples': 3581, 'score': 6038.98579120636, 'total_duration': 6349.096369981766, 'accumulated_submission_time': 6038.98579120636, 'accumulated_eval_time': 307.11135363578796, 'accumulated_logging_time': 2.1028239727020264}
I0204 17:59:04.936427 140379596986112 logging_writer.py:48] [25820] accumulated_eval_time=307.111354, accumulated_logging_time=2.102824, accumulated_submission_time=6038.985791, global_step=25820, preemption_count=0, score=6038.985791, test/loss=0.286441, test/num_examples=3581, test/ssim=0.743008, total_duration=6349.096370, train/loss=0.257368, train/ssim=0.753537, validation/loss=0.285138, validation/num_examples=3554, validation/ssim=0.725834
I0204 17:59:22.317968 140383296210688 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.15770094096660614, loss=0.24492013454437256
I0204 17:59:46.878411 140379596986112 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.08302006870508194, loss=0.2935134768486023
I0204 18:00:11.138383 140383296210688 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.09217710793018341, loss=0.2735525965690613
I0204 18:00:24.922870 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:00:26.306656 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:00:27.639828 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:00:28.969348 140584300062528 submission_runner.py:408] Time since start: 6433.15s, 	Step: 26159, 	{'train/ssim': 0.7538965770176479, 'train/loss': 0.2571835517883301, 'validation/ssim': 0.7256854072875633, 'validation/loss': 0.28539213009878833, 'validation/num_examples': 3554, 'test/ssim': 0.7428385871177744, 'test/loss': 0.28681996507173274, 'test/num_examples': 3581, 'score': 6118.951326370239, 'total_duration': 6433.150407791138, 'accumulated_submission_time': 6118.951326370239, 'accumulated_eval_time': 311.15779757499695, 'accumulated_logging_time': 2.13295578956604}
I0204 18:00:28.990513 140379596986112 logging_writer.py:48] [26159] accumulated_eval_time=311.157798, accumulated_logging_time=2.132956, accumulated_submission_time=6118.951326, global_step=26159, preemption_count=0, score=6118.951326, test/loss=0.286820, test/num_examples=3581, test/ssim=0.742839, total_duration=6433.150408, train/loss=0.257184, train/ssim=0.753897, validation/loss=0.285392, validation/num_examples=3554, validation/ssim=0.725685
I0204 18:00:36.730632 140383296210688 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.1156139150261879, loss=0.2924552857875824
I0204 18:01:00.190874 140379596986112 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.09369122982025146, loss=0.36164504289627075
I0204 18:01:24.354805 140383296210688 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.10757222026586533, loss=0.24899645149707794
I0204 18:01:48.222861 140379596986112 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.1082720160484314, loss=0.25109416246414185
I0204 18:01:49.113655 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:01:50.494804 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:01:51.826495 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:01:53.157320 140584300062528 submission_runner.py:408] Time since start: 6517.34s, 	Step: 26505, 	{'train/ssim': 0.7541265487670898, 'train/loss': 0.25708443777901785, 'validation/ssim': 0.7260599989668332, 'validation/loss': 0.2851045401363341, 'validation/num_examples': 3554, 'test/ssim': 0.7432574645263195, 'test/loss': 0.28644874314960905, 'test/num_examples': 3581, 'score': 6199.053456783295, 'total_duration': 6517.338342905045, 'accumulated_submission_time': 6199.053456783295, 'accumulated_eval_time': 315.20138478279114, 'accumulated_logging_time': 2.1633517742156982}
I0204 18:01:53.182279 140383296210688 logging_writer.py:48] [26505] accumulated_eval_time=315.201385, accumulated_logging_time=2.163352, accumulated_submission_time=6199.053457, global_step=26505, preemption_count=0, score=6199.053457, test/loss=0.286449, test/num_examples=3581, test/ssim=0.743257, total_duration=6517.338343, train/loss=0.257084, train/ssim=0.754127, validation/loss=0.285105, validation/num_examples=3554, validation/ssim=0.726060
I0204 18:02:13.647591 140379596986112 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.11118011921644211, loss=0.26406845450401306
I0204 18:02:37.408443 140383296210688 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.16922527551651, loss=0.34152936935424805
I0204 18:03:01.599465 140379596986112 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.14586028456687927, loss=0.17785772681236267
I0204 18:03:13.276968 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:03:14.660867 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:03:15.991938 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:03:17.324071 140584300062528 submission_runner.py:408] Time since start: 6601.51s, 	Step: 26851, 	{'train/ssim': 0.7537615639822823, 'train/loss': 0.25740526403699604, 'validation/ssim': 0.7258054167619232, 'validation/loss': 0.2853107098186023, 'validation/num_examples': 3554, 'test/ssim': 0.7429794401005306, 'test/loss': 0.2866079356543214, 'test/num_examples': 3581, 'score': 6279.126361370087, 'total_duration': 6601.50510263443, 'accumulated_submission_time': 6279.126361370087, 'accumulated_eval_time': 319.24842977523804, 'accumulated_logging_time': 2.198110342025757}
I0204 18:03:17.347947 140383296210688 logging_writer.py:48] [26851] accumulated_eval_time=319.248430, accumulated_logging_time=2.198110, accumulated_submission_time=6279.126361, global_step=26851, preemption_count=0, score=6279.126361, test/loss=0.286608, test/num_examples=3581, test/ssim=0.742979, total_duration=6601.505103, train/loss=0.257405, train/ssim=0.753762, validation/loss=0.285311, validation/num_examples=3554, validation/ssim=0.725805
I0204 18:03:26.948215 140379596986112 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.15678934752941132, loss=0.2126322090625763
I0204 18:03:51.205434 140383296210688 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.17235584557056427, loss=0.2121204435825348
I0204 18:04:14.929344 140379596986112 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.14360353350639343, loss=0.2461511790752411
I0204 18:04:37.430705 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:04:38.810170 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:04:40.139227 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:04:41.467179 140584300062528 submission_runner.py:408] Time since start: 6685.65s, 	Step: 27195, 	{'train/ssim': 0.7544635363987514, 'train/loss': 0.2570823771612985, 'validation/ssim': 0.7263280453142585, 'validation/loss': 0.28524581059083953, 'validation/num_examples': 3554, 'test/ssim': 0.7434335648430955, 'test/loss': 0.2866400127735793, 'test/num_examples': 3581, 'score': 6359.1869966983795, 'total_duration': 6685.648197650909, 'accumulated_submission_time': 6359.1869966983795, 'accumulated_eval_time': 323.28483629226685, 'accumulated_logging_time': 2.2321996688842773}
I0204 18:04:41.492962 140383296210688 logging_writer.py:48] [27195] accumulated_eval_time=323.284836, accumulated_logging_time=2.232200, accumulated_submission_time=6359.186997, global_step=27195, preemption_count=0, score=6359.186997, test/loss=0.286640, test/num_examples=3581, test/ssim=0.743434, total_duration=6685.648198, train/loss=0.257082, train/ssim=0.754464, validation/loss=0.285246, validation/num_examples=3554, validation/ssim=0.726328
I0204 18:04:41.948331 140379596986112 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.09515771269798279, loss=0.3103114366531372
I0204 18:05:04.464406 140383296210688 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.1633705347776413, loss=0.24073660373687744
I0204 18:05:27.999673 140379596986112 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.21345992386341095, loss=0.3047662079334259
I0204 18:05:51.785825 140383296210688 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.08185965567827225, loss=0.23560099303722382
I0204 18:06:01.648868 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:06:03.030157 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:06:04.358914 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:06:05.690396 140584300062528 submission_runner.py:408] Time since start: 6769.87s, 	Step: 27543, 	{'train/ssim': 0.7543215751647949, 'train/loss': 0.2569711378642491, 'validation/ssim': 0.7262150426895752, 'validation/loss': 0.2850779381506753, 'validation/num_examples': 3554, 'test/ssim': 0.7433979084491064, 'test/loss': 0.2864332329591071, 'test/num_examples': 3581, 'score': 6439.320326805115, 'total_duration': 6769.8714554309845, 'accumulated_submission_time': 6439.320326805115, 'accumulated_eval_time': 327.3263280391693, 'accumulated_logging_time': 2.2685048580169678}
I0204 18:06:05.712392 140379596986112 logging_writer.py:48] [27543] accumulated_eval_time=327.326328, accumulated_logging_time=2.268505, accumulated_submission_time=6439.320327, global_step=27543, preemption_count=0, score=6439.320327, test/loss=0.286433, test/num_examples=3581, test/ssim=0.743398, total_duration=6769.871455, train/loss=0.256971, train/ssim=0.754322, validation/loss=0.285078, validation/num_examples=3554, validation/ssim=0.726215
I0204 18:06:17.349256 140383296210688 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.10843402147293091, loss=0.24445270001888275
I0204 18:06:41.433045 140379596986112 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.10543946176767349, loss=0.2905592918395996
I0204 18:07:05.336433 140383296210688 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.07286728918552399, loss=0.3118610382080078
I0204 18:07:25.782698 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:07:27.162248 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:07:28.491495 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:07:29.822896 140584300062528 submission_runner.py:408] Time since start: 6854.00s, 	Step: 27886, 	{'train/ssim': 0.754523481641497, 'train/loss': 0.25713930811200825, 'validation/ssim': 0.726480478642023, 'validation/loss': 0.28523335969374297, 'validation/num_examples': 3554, 'test/ssim': 0.743686363904112, 'test/loss': 0.28649776216926137, 'test/num_examples': 3581, 'score': 6519.368485689163, 'total_duration': 6854.003954172134, 'accumulated_submission_time': 6519.368485689163, 'accumulated_eval_time': 331.366498708725, 'accumulated_logging_time': 2.3007984161376953}
I0204 18:07:29.844075 140379596986112 logging_writer.py:48] [27886] accumulated_eval_time=331.366499, accumulated_logging_time=2.300798, accumulated_submission_time=6519.368486, global_step=27886, preemption_count=0, score=6519.368486, test/loss=0.286498, test/num_examples=3581, test/ssim=0.743686, total_duration=6854.003954, train/loss=0.257139, train/ssim=0.754523, validation/loss=0.285233, validation/num_examples=3554, validation/ssim=0.726480
I0204 18:07:31.049244 140383296210688 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.15804819762706757, loss=0.26897579431533813
I0204 18:07:54.969283 140379596986112 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.0977068617939949, loss=0.23415923118591309
I0204 18:08:19.310024 140383296210688 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.1338237076997757, loss=0.2731541395187378
I0204 18:08:43.240430 140379596986112 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.20735564827919006, loss=0.25606775283813477
I0204 18:08:50.036961 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:08:51.416998 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:08:52.748745 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:08:54.079394 140584300062528 submission_runner.py:408] Time since start: 6938.26s, 	Step: 28229, 	{'train/ssim': 0.7529176303318569, 'train/loss': 0.25762838976723806, 'validation/ssim': 0.7251205315533554, 'validation/loss': 0.28556697504132666, 'validation/num_examples': 3554, 'test/ssim': 0.7423255577396328, 'test/loss': 0.2869981788650168, 'test/num_examples': 3581, 'score': 6599.540381908417, 'total_duration': 6938.260453462601, 'accumulated_submission_time': 6599.540381908417, 'accumulated_eval_time': 335.408899307251, 'accumulated_logging_time': 2.330955982208252}
I0204 18:08:54.101491 140383296210688 logging_writer.py:48] [28229] accumulated_eval_time=335.408899, accumulated_logging_time=2.330956, accumulated_submission_time=6599.540382, global_step=28229, preemption_count=0, score=6599.540382, test/loss=0.286998, test/num_examples=3581, test/ssim=0.742326, total_duration=6938.260453, train/loss=0.257628, train/ssim=0.752918, validation/loss=0.285567, validation/num_examples=3554, validation/ssim=0.725121
I0204 18:09:09.120067 140379596986112 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.11494684219360352, loss=0.23906752467155457
I0204 18:09:33.106803 140383296210688 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.12312524765729904, loss=0.23623701930046082
I0204 18:09:57.298649 140379596986112 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.10937046259641647, loss=0.2943711578845978
I0204 18:10:14.263867 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:10:15.644868 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:10:16.975341 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:10:18.307780 140584300062528 submission_runner.py:408] Time since start: 7022.49s, 	Step: 28572, 	{'train/ssim': 0.7542286600385394, 'train/loss': 0.2567955596106393, 'validation/ssim': 0.7258950632210186, 'validation/loss': 0.28507307800739484, 'validation/num_examples': 3554, 'test/ssim': 0.7430802733829587, 'test/loss': 0.2864325852808224, 'test/num_examples': 3581, 'score': 6679.681492090225, 'total_duration': 7022.488809347153, 'accumulated_submission_time': 6679.681492090225, 'accumulated_eval_time': 339.4527425765991, 'accumulated_logging_time': 2.3624444007873535}
I0204 18:10:18.332790 140383296210688 logging_writer.py:48] [28572] accumulated_eval_time=339.452743, accumulated_logging_time=2.362444, accumulated_submission_time=6679.681492, global_step=28572, preemption_count=0, score=6679.681492, test/loss=0.286433, test/num_examples=3581, test/ssim=0.743080, total_duration=7022.488809, train/loss=0.256796, train/ssim=0.754229, validation/loss=0.285073, validation/num_examples=3554, validation/ssim=0.725895
I0204 18:10:22.930485 140379596986112 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.08473974466323853, loss=0.36050114035606384
I0204 18:10:46.658098 140383296210688 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.10564067959785461, loss=0.26583757996559143
I0204 18:11:10.467244 140379596986112 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.17897118628025055, loss=0.2059815227985382
I0204 18:11:34.479516 140383296210688 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.08121173083782196, loss=0.3396332263946533
I0204 18:11:38.334173 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:11:39.714438 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:11:41.045564 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:11:42.377238 140584300062528 submission_runner.py:408] Time since start: 7106.56s, 	Step: 28918, 	{'train/ssim': 0.7547598566327777, 'train/loss': 0.25696420669555664, 'validation/ssim': 0.7266376518975098, 'validation/loss': 0.2851225209491066, 'validation/num_examples': 3554, 'test/ssim': 0.7438062866517733, 'test/loss': 0.28641676829534346, 'test/num_examples': 3581, 'score': 6759.659672021866, 'total_duration': 7106.558267116547, 'accumulated_submission_time': 6759.659672021866, 'accumulated_eval_time': 343.49573826789856, 'accumulated_logging_time': 2.3988473415374756}
I0204 18:11:42.403895 140379596986112 logging_writer.py:48] [28918] accumulated_eval_time=343.495738, accumulated_logging_time=2.398847, accumulated_submission_time=6759.659672, global_step=28918, preemption_count=0, score=6759.659672, test/loss=0.286417, test/num_examples=3581, test/ssim=0.743806, total_duration=7106.558267, train/loss=0.256964, train/ssim=0.754760, validation/loss=0.285123, validation/num_examples=3554, validation/ssim=0.726638
I0204 18:11:59.552052 140383296210688 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.09406357258558273, loss=0.26083600521087646
I0204 18:12:23.506585 140379596986112 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.10185065865516663, loss=0.25296369194984436
I0204 18:12:47.624743 140383296210688 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.08189360797405243, loss=0.3309035301208496
I0204 18:13:02.583214 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:13:03.961561 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:13:05.292812 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:13:06.623020 140584300062528 submission_runner.py:408] Time since start: 7190.80s, 	Step: 29264, 	{'train/ssim': 0.7535268919808524, 'train/loss': 0.2571125200816563, 'validation/ssim': 0.7255190289550506, 'validation/loss': 0.28521125720469015, 'validation/num_examples': 3554, 'test/ssim': 0.7426680091105836, 'test/loss': 0.2865796082514486, 'test/num_examples': 3581, 'score': 6839.815808057785, 'total_duration': 7190.804083108902, 'accumulated_submission_time': 6839.815808057785, 'accumulated_eval_time': 347.5355215072632, 'accumulated_logging_time': 2.4366612434387207}
I0204 18:13:06.644892 140379596986112 logging_writer.py:48] [29264] accumulated_eval_time=347.535522, accumulated_logging_time=2.436661, accumulated_submission_time=6839.815808, global_step=29264, preemption_count=0, score=6839.815808, test/loss=0.286580, test/num_examples=3581, test/ssim=0.742668, total_duration=7190.804083, train/loss=0.257113, train/ssim=0.753527, validation/loss=0.285211, validation/num_examples=3554, validation/ssim=0.725519
I0204 18:13:13.371534 140383296210688 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.44111889600753784, loss=0.34249547123908997
I0204 18:13:37.246099 140379596986112 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.19783560931682587, loss=0.18784251809120178
I0204 18:14:00.932051 140383296210688 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.12305142730474472, loss=0.22372910380363464
I0204 18:14:24.979887 140379596986112 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.10958360880613327, loss=0.2045411467552185
I0204 18:14:26.855835 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:14:28.237542 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:14:29.566481 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:14:30.894587 140584300062528 submission_runner.py:408] Time since start: 7275.08s, 	Step: 29609, 	{'train/ssim': 0.7549184390476772, 'train/loss': 0.2566295181001936, 'validation/ssim': 0.7264830890370005, 'validation/loss': 0.28509165989795826, 'validation/num_examples': 3554, 'test/ssim': 0.74362766379852, 'test/loss': 0.2864999097341001, 'test/num_examples': 3581, 'score': 6920.005371332169, 'total_duration': 7275.075638055801, 'accumulated_submission_time': 6920.005371332169, 'accumulated_eval_time': 351.5742256641388, 'accumulated_logging_time': 2.4678423404693604}
I0204 18:14:30.916608 140383296210688 logging_writer.py:48] [29609] accumulated_eval_time=351.574226, accumulated_logging_time=2.467842, accumulated_submission_time=6920.005371, global_step=29609, preemption_count=0, score=6920.005371, test/loss=0.286500, test/num_examples=3581, test/ssim=0.743628, total_duration=7275.075638, train/loss=0.256630, train/ssim=0.754918, validation/loss=0.285092, validation/num_examples=3554, validation/ssim=0.726483
I0204 18:14:50.464895 140379596986112 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.06117340177297592, loss=0.3087766766548157
I0204 18:15:14.253374 140383296210688 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.0953722819685936, loss=0.3565446436405182
I0204 18:15:38.103725 140379596986112 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.08609422296285629, loss=0.26290133595466614
I0204 18:15:50.996522 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:15:52.379387 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:15:53.709561 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:15:55.040329 140584300062528 submission_runner.py:408] Time since start: 7359.22s, 	Step: 29956, 	{'train/ssim': 0.7546397617885044, 'train/loss': 0.2568075145993914, 'validation/ssim': 0.7264039528524198, 'validation/loss': 0.2850718758518131, 'validation/num_examples': 3554, 'test/ssim': 0.743571213522759, 'test/loss': 0.28639812197841036, 'test/num_examples': 3581, 'score': 7000.064207315445, 'total_duration': 7359.221385478973, 'accumulated_submission_time': 7000.064207315445, 'accumulated_eval_time': 355.6179938316345, 'accumulated_logging_time': 2.4991798400878906}
I0204 18:15:55.062431 140383296210688 logging_writer.py:48] [29956] accumulated_eval_time=355.617994, accumulated_logging_time=2.499180, accumulated_submission_time=7000.064207, global_step=29956, preemption_count=0, score=7000.064207, test/loss=0.286398, test/num_examples=3581, test/ssim=0.743571, total_duration=7359.221385, train/loss=0.256808, train/ssim=0.754640, validation/loss=0.285072, validation/num_examples=3554, validation/ssim=0.726404
I0204 18:16:03.450768 140379596986112 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.10408182442188263, loss=0.3215031325817108
I0204 18:16:27.333990 140383296210688 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.13392066955566406, loss=0.22496986389160156
I0204 18:16:51.229867 140379596986112 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.09865943342447281, loss=0.27998197078704834
I0204 18:17:15.201179 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:17:16.585581 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:17:17.915475 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:17:19.246883 140584300062528 submission_runner.py:408] Time since start: 7443.43s, 	Step: 30300, 	{'train/ssim': 0.7547033173697335, 'train/loss': 0.25691587584359304, 'validation/ssim': 0.7264863863780248, 'validation/loss': 0.285162192083304, 'validation/num_examples': 3554, 'test/ssim': 0.7436359131745671, 'test/loss': 0.2865445995357442, 'test/num_examples': 3581, 'score': 7080.1818997859955, 'total_duration': 7443.427941322327, 'accumulated_submission_time': 7080.1818997859955, 'accumulated_eval_time': 359.66366052627563, 'accumulated_logging_time': 2.530510187149048}
I0204 18:17:19.268895 140383296210688 logging_writer.py:48] [30300] accumulated_eval_time=359.663661, accumulated_logging_time=2.530510, accumulated_submission_time=7080.181900, global_step=30300, preemption_count=0, score=7080.181900, test/loss=0.286545, test/num_examples=3581, test/ssim=0.743636, total_duration=7443.427941, train/loss=0.256916, train/ssim=0.754703, validation/loss=0.285162, validation/num_examples=3554, validation/ssim=0.726486
I0204 18:17:19.361546 140379596986112 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.10068883001804352, loss=0.2968379259109497
I0204 18:17:41.169357 140383296210688 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.1316695511341095, loss=0.2839082181453705
I0204 18:18:05.118202 140379596986112 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.12737570703029633, loss=0.22865265607833862
I0204 18:18:28.796704 140383296210688 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.08856771141290665, loss=0.28080207109451294
I0204 18:18:39.378125 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:18:40.761422 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:18:42.092811 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:18:43.425103 140584300062528 submission_runner.py:408] Time since start: 7527.61s, 	Step: 30646, 	{'train/ssim': 0.755000250680106, 'train/loss': 0.2563994271414621, 'validation/ssim': 0.7263446694085889, 'validation/loss': 0.2850013264928162, 'validation/num_examples': 3554, 'test/ssim': 0.7435238307429838, 'test/loss': 0.28638847498080144, 'test/num_examples': 3581, 'score': 7160.268867731094, 'total_duration': 7527.606162309647, 'accumulated_submission_time': 7160.268867731094, 'accumulated_eval_time': 363.7105996608734, 'accumulated_logging_time': 2.5629425048828125}
I0204 18:18:43.447066 140379596986112 logging_writer.py:48] [30646] accumulated_eval_time=363.710600, accumulated_logging_time=2.562943, accumulated_submission_time=7160.268868, global_step=30646, preemption_count=0, score=7160.268868, test/loss=0.286388, test/num_examples=3581, test/ssim=0.743524, total_duration=7527.606162, train/loss=0.256399, train/ssim=0.755000, validation/loss=0.285001, validation/num_examples=3554, validation/ssim=0.726345
I0204 18:18:54.216423 140383296210688 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.07909179478883743, loss=0.29063814878463745
I0204 18:19:18.173563 140379596986112 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.07440180331468582, loss=0.2826750576496124
I0204 18:19:41.870966 140383296210688 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.13258861005306244, loss=0.21609576046466827
I0204 18:20:03.471916 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:20:04.854471 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:20:06.183252 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:20:07.516116 140584300062528 submission_runner.py:408] Time since start: 7611.70s, 	Step: 30990, 	{'train/ssim': 0.7543023654392788, 'train/loss': 0.2566179037094116, 'validation/ssim': 0.7258775460968275, 'validation/loss': 0.284997616984164, 'validation/num_examples': 3554, 'test/ssim': 0.7430925451820372, 'test/loss': 0.28634501235906523, 'test/num_examples': 3581, 'score': 7240.273091554642, 'total_duration': 7611.697166442871, 'accumulated_submission_time': 7240.273091554642, 'accumulated_eval_time': 367.7547652721405, 'accumulated_logging_time': 2.5936460494995117}
I0204 18:20:07.543679 140379596986112 logging_writer.py:48] [30990] accumulated_eval_time=367.754765, accumulated_logging_time=2.593646, accumulated_submission_time=7240.273092, global_step=30990, preemption_count=0, score=7240.273092, test/loss=0.286345, test/num_examples=3581, test/ssim=0.743093, total_duration=7611.697166, train/loss=0.256618, train/ssim=0.754302, validation/loss=0.284998, validation/num_examples=3554, validation/ssim=0.725878
I0204 18:20:08.368966 140383296210688 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.07959848642349243, loss=0.2576020359992981
I0204 18:20:31.923568 140379596986112 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.1035650447010994, loss=0.21219049394130707
I0204 18:20:55.670119 140383296210688 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.07839266210794449, loss=0.23862749338150024
I0204 18:21:19.525190 140379596986112 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.11292039602994919, loss=0.257310152053833
I0204 18:21:27.592073 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:21:28.972779 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:21:30.306055 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:21:31.637718 140584300062528 submission_runner.py:408] Time since start: 7695.82s, 	Step: 31334, 	{'train/ssim': 0.7549773624965123, 'train/loss': 0.25676192556108746, 'validation/ssim': 0.7266886919887803, 'validation/loss': 0.28507398821090674, 'validation/num_examples': 3554, 'test/ssim': 0.7438424202823932, 'test/loss': 0.28641179139905054, 'test/num_examples': 3581, 'score': 7320.299663305283, 'total_duration': 7695.818750143051, 'accumulated_submission_time': 7320.299663305283, 'accumulated_eval_time': 371.80034589767456, 'accumulated_logging_time': 2.63110613822937}
I0204 18:21:31.665574 140383296210688 logging_writer.py:48] [31334] accumulated_eval_time=371.800346, accumulated_logging_time=2.631106, accumulated_submission_time=7320.299663, global_step=31334, preemption_count=0, score=7320.299663, test/loss=0.286412, test/num_examples=3581, test/ssim=0.743842, total_duration=7695.818750, train/loss=0.256762, train/ssim=0.754977, validation/loss=0.285074, validation/num_examples=3554, validation/ssim=0.726689
I0204 18:21:45.236022 140379596986112 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.09858978539705276, loss=0.2985333502292633
I0204 18:22:09.244184 140383296210688 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.05805261805653572, loss=0.31009653210639954
I0204 18:22:33.023984 140379596986112 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.10898856818675995, loss=0.22654098272323608
I0204 18:22:51.842379 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:22:53.222325 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:22:54.547783 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:22:55.875541 140584300062528 submission_runner.py:408] Time since start: 7780.06s, 	Step: 31681, 	{'train/ssim': 0.7553375107901437, 'train/loss': 0.25625278268541607, 'validation/ssim': 0.7267150020223692, 'validation/loss': 0.2849354655405881, 'validation/num_examples': 3554, 'test/ssim': 0.7438221718139137, 'test/loss': 0.28629872040587473, 'test/num_examples': 3581, 'score': 7400.453884601593, 'total_duration': 7780.056601762772, 'accumulated_submission_time': 7400.453884601593, 'accumulated_eval_time': 375.8334729671478, 'accumulated_logging_time': 2.6695849895477295}
I0204 18:22:55.898102 140383296210688 logging_writer.py:48] [31681] accumulated_eval_time=375.833473, accumulated_logging_time=2.669585, accumulated_submission_time=7400.453885, global_step=31681, preemption_count=0, score=7400.453885, test/loss=0.286299, test/num_examples=3581, test/ssim=0.743822, total_duration=7780.056602, train/loss=0.256253, train/ssim=0.755338, validation/loss=0.284935, validation/num_examples=3554, validation/ssim=0.726715
I0204 18:22:58.394941 140379596986112 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.0675341933965683, loss=0.25895774364471436
I0204 18:23:22.324266 140383296210688 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.18913482129573822, loss=0.2768367528915405
I0204 18:23:46.301021 140379596986112 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.08526475727558136, loss=0.34034132957458496
I0204 18:24:10.026133 140383296210688 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.16004346311092377, loss=0.17074453830718994
I0204 18:24:15.909102 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:24:17.289067 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:24:18.619900 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:24:19.951528 140584300062528 submission_runner.py:408] Time since start: 7864.13s, 	Step: 32026, 	{'train/ssim': 0.7550763402666364, 'train/loss': 0.25651434489658903, 'validation/ssim': 0.726590046536473, 'validation/loss': 0.28498028877013576, 'validation/num_examples': 3554, 'test/ssim': 0.7437481319594736, 'test/loss': 0.2863594317229824, 'test/num_examples': 3581, 'score': 7480.44393825531, 'total_duration': 7864.1325850486755, 'accumulated_submission_time': 7480.44393825531, 'accumulated_eval_time': 379.8758656978607, 'accumulated_logging_time': 2.7011075019836426}
I0204 18:24:19.974165 140379596986112 logging_writer.py:48] [32026] accumulated_eval_time=379.875866, accumulated_logging_time=2.701108, accumulated_submission_time=7480.443938, global_step=32026, preemption_count=0, score=7480.443938, test/loss=0.286359, test/num_examples=3581, test/ssim=0.743748, total_duration=7864.132585, train/loss=0.256514, train/ssim=0.755076, validation/loss=0.284980, validation/num_examples=3554, validation/ssim=0.726590
I0204 18:24:35.712669 140383296210688 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.05249502509832382, loss=0.269375205039978
I0204 18:24:59.622705 140379596986112 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.06805171817541122, loss=0.2660146951675415
I0204 18:25:23.522997 140383296210688 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.10734347999095917, loss=0.2720043957233429
I0204 18:25:40.182332 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:25:41.563574 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:25:42.891362 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:25:44.218226 140584300062528 submission_runner.py:408] Time since start: 7948.40s, 	Step: 32370, 	{'train/ssim': 0.7548025676182338, 'train/loss': 0.25659542424338205, 'validation/ssim': 0.7264196839168894, 'validation/loss': 0.28502208943707796, 'validation/num_examples': 3554, 'test/ssim': 0.7435609870235269, 'test/loss': 0.2863833958195162, 'test/num_examples': 3581, 'score': 7560.630806207657, 'total_duration': 7948.39928150177, 'accumulated_submission_time': 7560.630806207657, 'accumulated_eval_time': 383.91172099113464, 'accumulated_logging_time': 2.7331085205078125}
I0204 18:25:44.241221 140379596986112 logging_writer.py:48] [32370] accumulated_eval_time=383.911721, accumulated_logging_time=2.733109, accumulated_submission_time=7560.630806, global_step=32370, preemption_count=0, score=7560.630806, test/loss=0.286383, test/num_examples=3581, test/ssim=0.743561, total_duration=7948.399282, train/loss=0.256595, train/ssim=0.754803, validation/loss=0.285022, validation/num_examples=3554, validation/ssim=0.726420
I0204 18:25:49.523610 140383296210688 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.13428275287151337, loss=0.24553045630455017
I0204 18:26:13.675091 140379596986112 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.0986056923866272, loss=0.22892563045024872
I0204 18:26:37.833388 140383296210688 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.06769244372844696, loss=0.3345412313938141
I0204 18:27:01.466716 140379596986112 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.08711591362953186, loss=0.27523377537727356
I0204 18:27:04.252917 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:27:05.636907 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:27:06.969903 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:27:08.299211 140584300062528 submission_runner.py:408] Time since start: 8032.48s, 	Step: 32712, 	{'train/ssim': 0.7553097861153739, 'train/loss': 0.25619190079825266, 'validation/ssim': 0.7266341484726716, 'validation/loss': 0.28489490137652995, 'validation/num_examples': 3554, 'test/ssim': 0.7437498363760123, 'test/loss': 0.28627284736281766, 'test/num_examples': 3581, 'score': 7640.62170624733, 'total_duration': 8032.480271816254, 'accumulated_submission_time': 7640.62170624733, 'accumulated_eval_time': 387.9579894542694, 'accumulated_logging_time': 2.765145778656006}
I0204 18:27:08.322438 140383296210688 logging_writer.py:48] [32712] accumulated_eval_time=387.957989, accumulated_logging_time=2.765146, accumulated_submission_time=7640.621706, global_step=32712, preemption_count=0, score=7640.621706, test/loss=0.286273, test/num_examples=3581, test/ssim=0.743750, total_duration=8032.480272, train/loss=0.256192, train/ssim=0.755310, validation/loss=0.284895, validation/num_examples=3554, validation/ssim=0.726634
I0204 18:27:27.307168 140379596986112 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.0608142726123333, loss=0.2549317479133606
I0204 18:27:51.216625 140383296210688 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.08439704775810242, loss=0.21009434759616852
I0204 18:28:14.985508 140379596986112 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.06582088768482208, loss=0.3300258219242096
I0204 18:28:28.330091 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:28:29.709510 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:28:31.038563 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:28:32.368144 140584300062528 submission_runner.py:408] Time since start: 8116.55s, 	Step: 33057, 	{'train/ssim': 0.7551392146519252, 'train/loss': 0.25631284713745117, 'validation/ssim': 0.7265522645039041, 'validation/loss': 0.2848909170894591, 'validation/num_examples': 3554, 'test/ssim': 0.743716770695162, 'test/loss': 0.28626282539357023, 'test/num_examples': 3581, 'score': 7720.608385562897, 'total_duration': 8116.549202203751, 'accumulated_submission_time': 7720.608385562897, 'accumulated_eval_time': 391.9960012435913, 'accumulated_logging_time': 2.797520399093628}
I0204 18:28:32.390809 140383296210688 logging_writer.py:48] [33057] accumulated_eval_time=391.996001, accumulated_logging_time=2.797520, accumulated_submission_time=7720.608386, global_step=33057, preemption_count=0, score=7720.608386, test/loss=0.286263, test/num_examples=3581, test/ssim=0.743717, total_duration=8116.549202, train/loss=0.256313, train/ssim=0.755139, validation/loss=0.284891, validation/num_examples=3554, validation/ssim=0.726552
I0204 18:28:40.662841 140379596986112 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.06375839561223984, loss=0.2235981971025467
I0204 18:29:04.575318 140383296210688 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.09719739854335785, loss=0.3522372543811798
I0204 18:29:28.460981 140379596986112 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.0854087844491005, loss=0.3147399127483368
I0204 18:29:52.705216 140383296210688 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.0715775117278099, loss=0.25349849462509155
I0204 18:29:52.710402 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:29:54.033900 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:29:55.364033 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:29:56.694993 140584300062528 submission_runner.py:408] Time since start: 8200.88s, 	Step: 33401, 	{'train/ssim': 0.7549631936209542, 'train/loss': 0.25641167163848877, 'validation/ssim': 0.7264295072453574, 'validation/loss': 0.2849628746878517, 'validation/num_examples': 3554, 'test/ssim': 0.7435593507836498, 'test/loss': 0.28630894690510683, 'test/num_examples': 3581, 'score': 7800.907135248184, 'total_duration': 8200.876027584076, 'accumulated_submission_time': 7800.907135248184, 'accumulated_eval_time': 395.98051714897156, 'accumulated_logging_time': 2.8293039798736572}
I0204 18:29:56.721782 140379596986112 logging_writer.py:48] [33401] accumulated_eval_time=395.980517, accumulated_logging_time=2.829304, accumulated_submission_time=7800.907135, global_step=33401, preemption_count=0, score=7800.907135, test/loss=0.286309, test/num_examples=3581, test/ssim=0.743559, total_duration=8200.876028, train/loss=0.256412, train/ssim=0.754963, validation/loss=0.284963, validation/num_examples=3554, validation/ssim=0.726430
I0204 18:30:18.271812 140383296210688 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.0652727410197258, loss=0.2641279995441437
I0204 18:30:42.300470 140379596986112 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.06737960129976273, loss=0.29456862807273865
I0204 18:31:06.189123 140383296210688 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.08998507261276245, loss=0.255571186542511
I0204 18:31:16.839281 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:31:18.218854 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:31:19.548358 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:31:20.878621 140584300062528 submission_runner.py:408] Time since start: 8285.06s, 	Step: 33746, 	{'train/ssim': 0.7553563117980957, 'train/loss': 0.25617592675345285, 'validation/ssim': 0.7267946190691826, 'validation/loss': 0.28483000214876725, 'validation/num_examples': 3554, 'test/ssim': 0.7438874168790143, 'test/loss': 0.28620262540142416, 'test/num_examples': 3581, 'score': 7881.002731561661, 'total_duration': 8285.059644460678, 'accumulated_submission_time': 7881.002731561661, 'accumulated_eval_time': 400.01979994773865, 'accumulated_logging_time': 2.8660295009613037}
I0204 18:31:20.909314 140379596986112 logging_writer.py:48] [33746] accumulated_eval_time=400.019800, accumulated_logging_time=2.866030, accumulated_submission_time=7881.002732, global_step=33746, preemption_count=0, score=7881.002732, test/loss=0.286203, test/num_examples=3581, test/ssim=0.743887, total_duration=8285.059644, train/loss=0.256176, train/ssim=0.755356, validation/loss=0.284830, validation/num_examples=3554, validation/ssim=0.726795
I0204 18:31:32.047947 140383296210688 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.05184965953230858, loss=0.24019472301006317
I0204 18:31:55.842974 140379596986112 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.05967298895120621, loss=0.28371408581733704
I0204 18:32:19.738326 140383296210688 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.05667275935411453, loss=0.2777618169784546
I0204 18:32:40.947804 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:32:42.324891 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:32:43.656198 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:32:44.989012 140584300062528 submission_runner.py:408] Time since start: 8369.17s, 	Step: 34090, 	{'train/ssim': 0.7552986826215472, 'train/loss': 0.25616354601723806, 'validation/ssim': 0.7266865624560355, 'validation/loss': 0.28479654787629255, 'validation/num_examples': 3554, 'test/ssim': 0.7438356707929, 'test/loss': 0.28616973016222774, 'test/num_examples': 3581, 'score': 7961.019174337387, 'total_duration': 8369.170066595078, 'accumulated_submission_time': 7961.019174337387, 'accumulated_eval_time': 404.0609667301178, 'accumulated_logging_time': 2.9068877696990967}
I0204 18:32:45.012834 140379596986112 logging_writer.py:48] [34090] accumulated_eval_time=404.060967, accumulated_logging_time=2.906888, accumulated_submission_time=7961.019174, global_step=34090, preemption_count=0, score=7961.019174, test/loss=0.286170, test/num_examples=3581, test/ssim=0.743836, total_duration=8369.170067, train/loss=0.256164, train/ssim=0.755299, validation/loss=0.284797, validation/num_examples=3554, validation/ssim=0.726687
I0204 18:32:45.830983 140383296210688 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.06867165863513947, loss=0.25712621212005615
I0204 18:33:09.142409 140379596986112 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.05729184299707413, loss=0.2661232650279999
I0204 18:33:32.753835 140383296210688 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.07250888645648956, loss=0.22440466284751892
I0204 18:33:56.515939 140379596986112 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.06780923902988434, loss=0.33200207352638245
I0204 18:34:05.154964 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:34:06.535430 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:34:07.868331 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:34:09.198010 140584300062528 submission_runner.py:408] Time since start: 8453.38s, 	Step: 34437, 	{'train/ssim': 0.7552531787327358, 'train/loss': 0.25623464584350586, 'validation/ssim': 0.7266829216419879, 'validation/loss': 0.2848477081831211, 'validation/num_examples': 3554, 'test/ssim': 0.7438358753228846, 'test/loss': 0.2862102270991867, 'test/num_examples': 3581, 'score': 8041.14001584053, 'total_duration': 8453.379067897797, 'accumulated_submission_time': 8041.14001584053, 'accumulated_eval_time': 408.10397386550903, 'accumulated_logging_time': 2.9399144649505615}
I0204 18:34:09.222035 140383296210688 logging_writer.py:48] [34437] accumulated_eval_time=408.103974, accumulated_logging_time=2.939914, accumulated_submission_time=8041.140016, global_step=34437, preemption_count=0, score=8041.140016, test/loss=0.286210, test/num_examples=3581, test/ssim=0.743836, total_duration=8453.379068, train/loss=0.256235, train/ssim=0.755253, validation/loss=0.284848, validation/num_examples=3554, validation/ssim=0.726683
I0204 18:34:22.258302 140379596986112 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.06440421938896179, loss=0.22024330496788025
I0204 18:34:46.515616 140383296210688 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.08208425343036652, loss=0.2570071518421173
I0204 18:35:10.509492 140379596986112 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.0803927406668663, loss=0.24379460513591766
I0204 18:35:29.265761 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:35:30.646096 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:35:31.975629 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:35:33.306265 140584300062528 submission_runner.py:408] Time since start: 8537.49s, 	Step: 34779, 	{'train/ssim': 0.7552689143589565, 'train/loss': 0.25617705072675434, 'validation/ssim': 0.7266373771190912, 'validation/loss': 0.2848144599944605, 'validation/num_examples': 3554, 'test/ssim': 0.7437871290098785, 'test/loss': 0.28617682053502863, 'test/num_examples': 3581, 'score': 8121.161528110504, 'total_duration': 8537.487291812897, 'accumulated_submission_time': 8121.161528110504, 'accumulated_eval_time': 412.1444194316864, 'accumulated_logging_time': 2.974390745162964}
I0204 18:35:33.338181 140383296210688 logging_writer.py:48] [34779] accumulated_eval_time=412.144419, accumulated_logging_time=2.974391, accumulated_submission_time=8121.161528, global_step=34779, preemption_count=0, score=8121.161528, test/loss=0.286177, test/num_examples=3581, test/ssim=0.743787, total_duration=8537.487292, train/loss=0.256177, train/ssim=0.755269, validation/loss=0.284814, validation/num_examples=3554, validation/ssim=0.726637
I0204 18:35:36.224314 140379596986112 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.07949429750442505, loss=0.22730867564678192
I0204 18:35:59.996862 140383296210688 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.0654788613319397, loss=0.2975829839706421
I0204 18:36:23.775772 140379596986112 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.07899061590433121, loss=0.24848785996437073
I0204 18:36:47.590161 140383296210688 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.07087444514036179, loss=0.3005785346031189
I0204 18:36:53.458349 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:36:54.839126 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:36:56.169158 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:36:57.498309 140584300062528 submission_runner.py:408] Time since start: 8621.68s, 	Step: 35125, 	{'train/ssim': 0.7554235458374023, 'train/loss': 0.2560735600335257, 'validation/ssim': 0.7267863757166221, 'validation/loss': 0.28474231348590495, 'validation/num_examples': 3554, 'test/ssim': 0.7439305727057736, 'test/loss': 0.2861144729780438, 'test/num_examples': 3581, 'score': 8201.258660793304, 'total_duration': 8621.679370641708, 'accumulated_submission_time': 8201.258660793304, 'accumulated_eval_time': 416.184344291687, 'accumulated_logging_time': 3.0172266960144043}
I0204 18:36:57.521182 140379596986112 logging_writer.py:48] [35125] accumulated_eval_time=416.184344, accumulated_logging_time=3.017227, accumulated_submission_time=8201.258661, global_step=35125, preemption_count=0, score=8201.258661, test/loss=0.286114, test/num_examples=3581, test/ssim=0.743931, total_duration=8621.679371, train/loss=0.256074, train/ssim=0.755424, validation/loss=0.284742, validation/num_examples=3554, validation/ssim=0.726786
I0204 18:37:13.397506 140383296210688 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.0469612255692482, loss=0.23105478286743164
I0204 18:37:37.153158 140379596986112 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.05701009929180145, loss=0.27834299206733704
I0204 18:38:00.813157 140383296210688 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.040614333003759384, loss=0.3212142586708069
I0204 18:38:17.594172 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:38:18.978657 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:38:20.308591 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:38:21.636664 140584300062528 submission_runner.py:408] Time since start: 8705.82s, 	Step: 35471, 	{'train/ssim': 0.7555623735700335, 'train/loss': 0.2561214140483311, 'validation/ssim': 0.7269094764481921, 'validation/loss': 0.28478588303891744, 'validation/num_examples': 3554, 'test/ssim': 0.744045791263788, 'test/loss': 0.28615408361840267, 'test/num_examples': 3581, 'score': 8281.31056690216, 'total_duration': 8705.81771326065, 'accumulated_submission_time': 8281.31056690216, 'accumulated_eval_time': 420.22679924964905, 'accumulated_logging_time': 3.0492374897003174}
I0204 18:38:21.660251 140379596986112 logging_writer.py:48] [35471] accumulated_eval_time=420.226799, accumulated_logging_time=3.049237, accumulated_submission_time=8281.310567, global_step=35471, preemption_count=0, score=8281.310567, test/loss=0.286154, test/num_examples=3581, test/ssim=0.744046, total_duration=8705.817713, train/loss=0.256121, train/ssim=0.755562, validation/loss=0.284786, validation/num_examples=3554, validation/ssim=0.726909
I0204 18:38:26.514167 140383296210688 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.055331651121377945, loss=0.31518232822418213
I0204 18:38:50.196437 140379596986112 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.08132793754339218, loss=0.21083776652812958
I0204 18:39:14.598773 140383296210688 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.06246936321258545, loss=0.21041280031204224
I0204 18:39:38.630998 140379596986112 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.0728674829006195, loss=0.24353677034378052
I0204 18:39:41.907115 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:39:43.290106 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:39:44.622356 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:39:45.952417 140584300062528 submission_runner.py:408] Time since start: 8790.13s, 	Step: 35814, 	{'train/ssim': 0.7554898943219867, 'train/loss': 0.2561060871396746, 'validation/ssim': 0.7268266307549592, 'validation/loss': 0.2847845778414287, 'validation/num_examples': 3554, 'test/ssim': 0.7439735240025481, 'test/loss': 0.28615077705031766, 'test/num_examples': 3581, 'score': 8361.536612510681, 'total_duration': 8790.133450984955, 'accumulated_submission_time': 8361.536612510681, 'accumulated_eval_time': 424.2720458507538, 'accumulated_logging_time': 3.081813335418701}
I0204 18:39:45.976727 140383296210688 logging_writer.py:48] [35814] accumulated_eval_time=424.272046, accumulated_logging_time=3.081813, accumulated_submission_time=8361.536613, global_step=35814, preemption_count=0, score=8361.536613, test/loss=0.286151, test/num_examples=3581, test/ssim=0.743974, total_duration=8790.133451, train/loss=0.256106, train/ssim=0.755490, validation/loss=0.284785, validation/num_examples=3554, validation/ssim=0.726827
I0204 18:40:04.748987 140379596986112 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.07631902396678925, loss=0.21980296075344086
I0204 18:40:28.459696 140383296210688 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.04989929124712944, loss=0.2355276644229889
I0204 18:40:52.249804 140379596986112 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.05023610219359398, loss=0.37189728021621704
I0204 18:41:06.037448 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:41:07.417975 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:41:08.749041 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:41:10.076127 140584300062528 submission_runner.py:408] Time since start: 8874.26s, 	Step: 36159, 	{'train/ssim': 0.7554442541939872, 'train/loss': 0.256074139050075, 'validation/ssim': 0.7268051980383019, 'validation/loss': 0.2847391707077413, 'validation/num_examples': 3554, 'test/ssim': 0.7439485713444219, 'test/loss': 0.28610356471219633, 'test/num_examples': 3581, 'score': 8441.574692964554, 'total_duration': 8874.257183551788, 'accumulated_submission_time': 8441.574692964554, 'accumulated_eval_time': 428.31070947647095, 'accumulated_logging_time': 3.1168370246887207}
I0204 18:41:10.099922 140383296210688 logging_writer.py:48] [36159] accumulated_eval_time=428.310709, accumulated_logging_time=3.116837, accumulated_submission_time=8441.574693, global_step=36159, preemption_count=0, score=8441.574693, test/loss=0.286104, test/num_examples=3581, test/ssim=0.743949, total_duration=8874.257184, train/loss=0.256074, train/ssim=0.755444, validation/loss=0.284739, validation/num_examples=3554, validation/ssim=0.726805
I0204 18:41:14.827303 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:41:16.209808 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:41:17.538806 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:41:18.870589 140584300062528 submission_runner.py:408] Time since start: 8883.05s, 	Step: 36189, 	{'train/ssim': 0.7554440498352051, 'train/loss': 0.2560740368706839, 'validation/ssim': 0.7268047858706739, 'validation/loss': 0.2847391020131366, 'validation/num_examples': 3554, 'test/ssim': 0.7439481622844527, 'test/loss': 0.28610349653553474, 'test/num_examples': 3581, 'score': 8446.291797876358, 'total_duration': 8883.051620006561, 'accumulated_submission_time': 8446.291797876358, 'accumulated_eval_time': 432.35393595695496, 'accumulated_logging_time': 3.1495649814605713}
I0204 18:41:18.893781 140379596986112 logging_writer.py:48] [36189] accumulated_eval_time=432.353936, accumulated_logging_time=3.149565, accumulated_submission_time=8446.291798, global_step=36189, preemption_count=0, score=8446.291798, test/loss=0.286103, test/num_examples=3581, test/ssim=0.743948, total_duration=8883.051620, train/loss=0.256074, train/ssim=0.755444, validation/loss=0.284739, validation/num_examples=3554, validation/ssim=0.726805
I0204 18:41:18.914729 140383296210688 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8446.291798
I0204 18:41:18.963279 140584300062528 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 18:41:19.423103 140584300062528 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3/checkpoint_36189
I0204 18:41:19.423889 140584300062528 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_3/checkpoint_36189.
I0204 18:41:20.304780 140584300062528 submission_runner.py:583] Tuning trial 3/5
I0204 18:41:20.305021 140584300062528 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.001308209823469072, one_minus_beta1=0.02686663061, beta2=0.9981232922116359, weight_decay=0.16375311233774334, warmup_factor=0.1)
I0204 18:41:20.314038 140584300062528 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 33.548996925354004, 'total_duration': 37.53365206718445, 'accumulated_submission_time': 33.548996925354004, 'accumulated_eval_time': 3.984562873840332, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (343, {'train/ssim': 0.6902498517717633, 'train/loss': 0.3141788755144392, 'validation/ssim': 0.6638744141724113, 'validation/loss': 0.34272789297710327, 'validation/num_examples': 3554, 'test/ssim': 0.6831162406625244, 'test/loss': 0.3437465229902611, 'test/num_examples': 3581, 'score': 113.72720742225647, 'total_duration': 121.78289651870728, 'accumulated_submission_time': 113.72720742225647, 'accumulated_eval_time': 8.02499008178711, 'accumulated_logging_time': 0.0185849666595459, 'global_step': 343, 'preemption_count': 0}), (683, {'train/ssim': 0.7197771753583636, 'train/loss': 0.2880679539271763, 'validation/ssim': 0.6944376055149127, 'validation/loss': 0.3150176572611846, 'validation/num_examples': 3554, 'test/ssim': 0.7118955866247207, 'test/loss': 0.3172561061745148, 'test/num_examples': 3581, 'score': 193.74862456321716, 'total_duration': 205.87726044654846, 'accumulated_submission_time': 193.74862456321716, 'accumulated_eval_time': 12.062600135803223, 'accumulated_logging_time': 0.04203295707702637, 'global_step': 683, 'preemption_count': 0}), (1023, {'train/ssim': 0.7243311745779855, 'train/loss': 0.28095054626464844, 'validation/ssim': 0.6999504162343486, 'validation/loss': 0.307128803208093, 'validation/num_examples': 3554, 'test/ssim': 0.7172653850181514, 'test/loss': 0.30918978446357515, 'test/num_examples': 3581, 'score': 273.89558959007263, 'total_duration': 290.09849548339844, 'accumulated_submission_time': 273.89558959007263, 'accumulated_eval_time': 16.101449489593506, 'accumulated_logging_time': 0.06560516357421875, 'global_step': 1023, 'preemption_count': 0}), (1370, {'train/ssim': 0.7353413445608956, 'train/loss': 0.27315076759883333, 'validation/ssim': 0.7095289171312253, 'validation/loss': 0.29964655252004785, 'validation/num_examples': 3554, 'test/ssim': 0.7265489328443522, 'test/loss': 0.3018685313983524, 'test/num_examples': 3581, 'score': 354.088178396225, 'total_duration': 374.368869304657, 'accumulated_submission_time': 354.088178396225, 'accumulated_eval_time': 20.14368963241577, 'accumulated_logging_time': 0.0890505313873291, 'global_step': 1370, 'preemption_count': 0}), (1713, {'train/ssim': 0.7381311144147601, 'train/loss': 0.27023257528032574, 'validation/ssim': 0.7123925204215321, 'validation/loss': 0.29638180708576606, 'validation/num_examples': 3554, 'test/ssim': 0.7295050728890324, 'test/loss': 0.2983961235841071, 'test/num_examples': 3581, 'score': 434.0783689022064, 'total_duration': 458.4306387901306, 'accumulated_submission_time': 434.0783689022064, 'accumulated_eval_time': 24.17908215522766, 'accumulated_logging_time': 0.1127169132232666, 'global_step': 1713, 'preemption_count': 0}), (2055, {'train/ssim': 0.7401712962559291, 'train/loss': 0.26896728788103375, 'validation/ssim': 0.7145240453098621, 'validation/loss': 0.29493956386070275, 'validation/num_examples': 3554, 'test/ssim': 0.7316638187002583, 'test/loss': 0.29680184644216, 'test/num_examples': 3581, 'score': 514.2202973365784, 'total_duration': 542.6508350372314, 'accumulated_submission_time': 514.2202973365784, 'accumulated_eval_time': 28.21941351890564, 'accumulated_logging_time': 0.13882088661193848, 'global_step': 2055, 'preemption_count': 0}), (2401, {'train/ssim': 0.742351940699986, 'train/loss': 0.2663253034864153, 'validation/ssim': 0.7161404293577659, 'validation/loss': 0.2926883042764315, 'validation/num_examples': 3554, 'test/ssim': 0.7333096714866657, 'test/loss': 0.29443482092990786, 'test/num_examples': 3581, 'score': 594.2618770599365, 'total_duration': 626.7217772006989, 'accumulated_submission_time': 594.2618770599365, 'accumulated_eval_time': 32.20990490913391, 'accumulated_logging_time': 0.1659994125366211, 'global_step': 2401, 'preemption_count': 0}), (2746, {'train/ssim': 0.7398902348109654, 'train/loss': 0.26844440187726704, 'validation/ssim': 0.7138087970860298, 'validation/loss': 0.29461463838060986, 'validation/num_examples': 3554, 'test/ssim': 0.7309620763229545, 'test/loss': 0.2963557324573269, 'test/num_examples': 3581, 'score': 674.29638504982, 'total_duration': 710.8356049060822, 'accumulated_submission_time': 674.29638504982, 'accumulated_eval_time': 36.25227451324463, 'accumulated_logging_time': 0.1907820701599121, 'global_step': 2746, 'preemption_count': 0}), (3090, {'train/ssim': 0.7444577898297992, 'train/loss': 0.2649519273212978, 'validation/ssim': 0.7183651041300295, 'validation/loss': 0.29116345578925157, 'validation/num_examples': 3554, 'test/ssim': 0.7354993013255725, 'test/loss': 0.2928027739174637, 'test/num_examples': 3581, 'score': 754.3580448627472, 'total_duration': 794.9765889644623, 'accumulated_submission_time': 754.3580448627472, 'accumulated_eval_time': 40.29451560974121, 'accumulated_logging_time': 0.21582698822021484, 'global_step': 3090, 'preemption_count': 0}), (3433, {'train/ssim': 0.7445534297398159, 'train/loss': 0.2641278845923288, 'validation/ssim': 0.7181353893720104, 'validation/loss': 0.2906195319094682, 'validation/num_examples': 3554, 'test/ssim': 0.7354296247774714, 'test/loss': 0.2922338396768535, 'test/num_examples': 3581, 'score': 834.3319246768951, 'total_duration': 879.0295767784119, 'accumulated_submission_time': 834.3319246768951, 'accumulated_eval_time': 44.33660364151001, 'accumulated_logging_time': 0.24074792861938477, 'global_step': 3433, 'preemption_count': 0}), (3768, {'train/ssim': 0.7440680095127651, 'train/loss': 0.2646568502698626, 'validation/ssim': 0.7183314437737408, 'validation/loss': 0.29050391888980726, 'validation/num_examples': 3554, 'test/ssim': 0.7355386392592851, 'test/loss': 0.29211613267069253, 'test/num_examples': 3581, 'score': 914.4203317165375, 'total_duration': 963.192458152771, 'accumulated_submission_time': 914.4203317165375, 'accumulated_eval_time': 48.37433314323425, 'accumulated_logging_time': 0.26586484909057617, 'global_step': 3768, 'preemption_count': 0}), (4112, {'train/ssim': 0.7450623512268066, 'train/loss': 0.26390624046325684, 'validation/ssim': 0.7189520995269415, 'validation/loss': 0.29018246248725027, 'validation/num_examples': 3554, 'test/ssim': 0.7359028389852694, 'test/loss': 0.2918586294200293, 'test/num_examples': 3581, 'score': 994.5614778995514, 'total_duration': 1047.4146084785461, 'accumulated_submission_time': 994.5614778995514, 'accumulated_eval_time': 52.41978621482849, 'accumulated_logging_time': 0.2896695137023926, 'global_step': 4112, 'preemption_count': 0}), (4454, {'train/ssim': 0.747828483581543, 'train/loss': 0.26266428402491976, 'validation/ssim': 0.7210435754607485, 'validation/loss': 0.28934847563924454, 'validation/num_examples': 3554, 'test/ssim': 0.7382009378926976, 'test/loss': 0.29097819601281066, 'test/num_examples': 3581, 'score': 1074.5751271247864, 'total_duration': 1131.507836341858, 'accumulated_submission_time': 1074.5751271247864, 'accumulated_eval_time': 56.46136999130249, 'accumulated_logging_time': 0.3157362937927246, 'global_step': 4454, 'preemption_count': 0}), (4800, {'train/ssim': 0.7469865253993443, 'train/loss': 0.2625446149281093, 'validation/ssim': 0.7206881495761818, 'validation/loss': 0.28886486562236213, 'validation/num_examples': 3554, 'test/ssim': 0.7379298674863864, 'test/loss': 0.2904206131863481, 'test/num_examples': 3581, 'score': 1154.6210136413574, 'total_duration': 1215.6344573497772, 'accumulated_submission_time': 1154.6210136413574, 'accumulated_eval_time': 60.50531268119812, 'accumulated_logging_time': 0.34067821502685547, 'global_step': 4800, 'preemption_count': 0}), (5147, {'train/ssim': 0.747349670955113, 'train/loss': 0.26216367312840055, 'validation/ssim': 0.7209261076867614, 'validation/loss': 0.2884935369368142, 'validation/num_examples': 3554, 'test/ssim': 0.738178439594387, 'test/loss': 0.2899860551456472, 'test/num_examples': 3581, 'score': 1234.7858142852783, 'total_duration': 1299.8765351772308, 'accumulated_submission_time': 1234.7858142852783, 'accumulated_eval_time': 64.54547190666199, 'accumulated_logging_time': 0.3658421039581299, 'global_step': 5147, 'preemption_count': 0}), (5490, {'train/ssim': 0.7481654030936105, 'train/loss': 0.2623655114855085, 'validation/ssim': 0.7215267733100028, 'validation/loss': 0.28904683763013506, 'validation/num_examples': 3554, 'test/ssim': 0.7386932415657288, 'test/loss': 0.2906221093095504, 'test/num_examples': 3581, 'score': 1314.8512017726898, 'total_duration': 1384.0182185173035, 'accumulated_submission_time': 1314.8512017726898, 'accumulated_eval_time': 68.58561253547668, 'accumulated_logging_time': 0.3900299072265625, 'global_step': 5490, 'preemption_count': 0}), (5835, {'train/ssim': 0.7441043172563825, 'train/loss': 0.2656274012156895, 'validation/ssim': 0.7176361169852631, 'validation/loss': 0.2921757738309827, 'validation/num_examples': 3554, 'test/ssim': 0.7345956878534278, 'test/loss': 0.29376570108515426, 'test/num_examples': 3581, 'score': 1395.0299680233002, 'total_duration': 1468.2786684036255, 'accumulated_submission_time': 1395.0299680233002, 'accumulated_eval_time': 72.6303391456604, 'accumulated_logging_time': 0.41507530212402344, 'global_step': 5835, 'preemption_count': 0}), (6180, {'train/ssim': 0.7495601517813546, 'train/loss': 0.26161309650966097, 'validation/ssim': 0.7231619796795864, 'validation/loss': 0.2881927576102631, 'validation/num_examples': 3554, 'test/ssim': 0.7403823183555571, 'test/loss': 0.28964019494161897, 'test/num_examples': 3581, 'score': 1475.153118133545, 'total_duration': 1552.4831855297089, 'accumulated_submission_time': 1475.153118133545, 'accumulated_eval_time': 76.67470240592957, 'accumulated_logging_time': 0.4403700828552246, 'global_step': 6180, 'preemption_count': 0}), (6522, {'train/ssim': 0.7479400634765625, 'train/loss': 0.26206294127873014, 'validation/ssim': 0.7214551935319359, 'validation/loss': 0.2886338800141566, 'validation/num_examples': 3554, 'test/ssim': 0.7387238528867635, 'test/loss': 0.29007737778378945, 'test/num_examples': 3581, 'score': 1555.2574756145477, 'total_duration': 1636.669602394104, 'accumulated_submission_time': 1555.2574756145477, 'accumulated_eval_time': 80.7171881198883, 'accumulated_logging_time': 0.4680335521697998, 'global_step': 6522, 'preemption_count': 0}), (6869, {'train/ssim': 0.749246529170445, 'train/loss': 0.260955878666469, 'validation/ssim': 0.7226707445615855, 'validation/loss': 0.28755456755922026, 'validation/num_examples': 3554, 'test/ssim': 0.7399360339290701, 'test/loss': 0.2890012091812692, 'test/num_examples': 3581, 'score': 1635.2986016273499, 'total_duration': 1720.7873928546906, 'accumulated_submission_time': 1635.2986016273499, 'accumulated_eval_time': 84.75681829452515, 'accumulated_logging_time': 0.4930555820465088, 'global_step': 6869, 'preemption_count': 0}), (7216, {'train/ssim': 0.7487942150660923, 'train/loss': 0.26176336833408903, 'validation/ssim': 0.7220146423923748, 'validation/loss': 0.2888460433006823, 'validation/num_examples': 3554, 'test/ssim': 0.7392699479457554, 'test/loss': 0.2902471376710416, 'test/num_examples': 3581, 'score': 1715.3318283557892, 'total_duration': 1804.9016375541687, 'accumulated_submission_time': 1715.3318283557892, 'accumulated_eval_time': 88.79988646507263, 'accumulated_logging_time': 0.5191292762756348, 'global_step': 7216, 'preemption_count': 0}), (7561, {'train/ssim': 0.7482390403747559, 'train/loss': 0.2618751525878906, 'validation/ssim': 0.7224570356464547, 'validation/loss': 0.2880615852626442, 'validation/num_examples': 3554, 'test/ssim': 0.7396165580930606, 'test/loss': 0.2895986071780753, 'test/num_examples': 3581, 'score': 1795.4933722019196, 'total_duration': 1889.1465952396393, 'accumulated_submission_time': 1795.4933722019196, 'accumulated_eval_time': 92.84628129005432, 'accumulated_logging_time': 0.5441994667053223, 'global_step': 7561, 'preemption_count': 0}), (7906, {'train/ssim': 0.7501950945172992, 'train/loss': 0.26023820468357634, 'validation/ssim': 0.7236638624613112, 'validation/loss': 0.28703231682721053, 'validation/num_examples': 3554, 'test/ssim': 0.7408963022069603, 'test/loss': 0.28841284459211813, 'test/num_examples': 3581, 'score': 1875.5250089168549, 'total_duration': 1973.2614433765411, 'accumulated_submission_time': 1875.5250089168549, 'accumulated_eval_time': 96.89130020141602, 'accumulated_logging_time': 0.5703647136688232, 'global_step': 7906, 'preemption_count': 0}), (8250, {'train/ssim': 0.7495725495474679, 'train/loss': 0.2608766555786133, 'validation/ssim': 0.7226769957706106, 'validation/loss': 0.28767801176381363, 'validation/num_examples': 3554, 'test/ssim': 0.739940397235409, 'test/loss': 0.289103440085259, 'test/num_examples': 3581, 'score': 1955.5428388118744, 'total_duration': 2057.3702251911163, 'accumulated_submission_time': 1955.5428388118744, 'accumulated_eval_time': 100.94035053253174, 'accumulated_logging_time': 0.6000580787658691, 'global_step': 8250, 'preemption_count': 0}), (8593, {'train/ssim': 0.750629220690046, 'train/loss': 0.2605338437216623, 'validation/ssim': 0.723893233746307, 'validation/loss': 0.2872329394201516, 'validation/num_examples': 3554, 'test/ssim': 0.7411272165596202, 'test/loss': 0.2886298168174916, 'test/num_examples': 3581, 'score': 2035.5123291015625, 'total_duration': 2141.427557706833, 'accumulated_submission_time': 2035.5123291015625, 'accumulated_eval_time': 104.98532390594482, 'accumulated_logging_time': 0.6310033798217773, 'global_step': 8593, 'preemption_count': 0}), (8936, {'train/ssim': 0.751429694039481, 'train/loss': 0.2599715845925467, 'validation/ssim': 0.7244846255979178, 'validation/loss': 0.2870964088933684, 'validation/num_examples': 3554, 'test/ssim': 0.741647745370532, 'test/loss': 0.28856300368917553, 'test/num_examples': 3581, 'score': 2115.628773212433, 'total_duration': 2225.6283581256866, 'accumulated_submission_time': 2115.628773212433, 'accumulated_eval_time': 109.029296875, 'accumulated_logging_time': 0.6593132019042969, 'global_step': 8936, 'preemption_count': 0}), (9282, {'train/ssim': 0.7505640983581543, 'train/loss': 0.2599564790725708, 'validation/ssim': 0.7239608979319077, 'validation/loss': 0.2866972417192776, 'validation/num_examples': 3554, 'test/ssim': 0.7411813488288885, 'test/loss': 0.2881314113332519, 'test/num_examples': 3581, 'score': 2195.7629470825195, 'total_duration': 2309.8518760204315, 'accumulated_submission_time': 2195.7629470825195, 'accumulated_eval_time': 113.07417154312134, 'accumulated_logging_time': 0.6917684078216553, 'global_step': 9282, 'preemption_count': 0}), (9625, {'train/ssim': 0.746929236820766, 'train/loss': 0.2619223764964512, 'validation/ssim': 0.7217569689302546, 'validation/loss': 0.2881119899288214, 'validation/num_examples': 3554, 'test/ssim': 0.7387132173275621, 'test/loss': 0.28945066382251816, 'test/num_examples': 3581, 'score': 2275.9334716796875, 'total_duration': 2394.1086626052856, 'accumulated_submission_time': 2275.9334716796875, 'accumulated_eval_time': 117.11841011047363, 'accumulated_logging_time': 0.7217345237731934, 'global_step': 9625, 'preemption_count': 0}), (9971, {'train/ssim': 0.7508612360273089, 'train/loss': 0.2593847853796823, 'validation/ssim': 0.7234695941193022, 'validation/loss': 0.2865976001952026, 'validation/num_examples': 3554, 'test/ssim': 0.740755926460835, 'test/loss': 0.2880375320703016, 'test/num_examples': 3581, 'score': 2356.0825872421265, 'total_duration': 2478.336655139923, 'accumulated_submission_time': 2356.0825872421265, 'accumulated_eval_time': 121.1582088470459, 'accumulated_logging_time': 0.7490215301513672, 'global_step': 9971, 'preemption_count': 0}), (10318, {'train/ssim': 0.7500311306544712, 'train/loss': 0.25987511021750315, 'validation/ssim': 0.7230898503446821, 'validation/loss': 0.2866478846458216, 'validation/num_examples': 3554, 'test/ssim': 0.740412725146607, 'test/loss': 0.2879811158828714, 'test/num_examples': 3581, 'score': 2436.082048892975, 'total_duration': 2562.416161775589, 'accumulated_submission_time': 2436.082048892975, 'accumulated_eval_time': 125.19908928871155, 'accumulated_logging_time': 0.7764010429382324, 'global_step': 10318, 'preemption_count': 0}), (10663, {'train/ssim': 0.7506626674107143, 'train/loss': 0.25970894949776785, 'validation/ssim': 0.724038454140581, 'validation/loss': 0.2864253484739906, 'validation/num_examples': 3554, 'test/ssim': 0.7412570930998673, 'test/loss': 0.28777968793633063, 'test/num_examples': 3581, 'score': 2516.108592271805, 'total_duration': 2646.5201659202576, 'accumulated_submission_time': 2516.108592271805, 'accumulated_eval_time': 129.23694705963135, 'accumulated_logging_time': 0.8038809299468994, 'global_step': 10663, 'preemption_count': 0}), (11009, {'train/ssim': 0.7513034003121513, 'train/loss': 0.25934513977595736, 'validation/ssim': 0.7240849603879431, 'validation/loss': 0.2865712901616137, 'validation/num_examples': 3554, 'test/ssim': 0.7412414806443731, 'test/loss': 0.2879982623132505, 'test/num_examples': 3581, 'score': 2596.211658477783, 'total_duration': 2730.7025558948517, 'accumulated_submission_time': 2596.211658477783, 'accumulated_eval_time': 133.27631831169128, 'accumulated_logging_time': 0.8316900730133057, 'global_step': 11009, 'preemption_count': 0}), (11355, {'train/ssim': 0.7510937282017299, 'train/loss': 0.2594878673553467, 'validation/ssim': 0.72414403774796, 'validation/loss': 0.28635278979780704, 'validation/num_examples': 3554, 'test/ssim': 0.7413318828975844, 'test/loss': 0.28778125599954624, 'test/num_examples': 3581, 'score': 2676.3213658332825, 'total_duration': 2814.900425195694, 'accumulated_submission_time': 2676.3213658332825, 'accumulated_eval_time': 137.32483291625977, 'accumulated_logging_time': 0.8595569133758545, 'global_step': 11355, 'preemption_count': 0}), (11698, {'train/ssim': 0.7509194101606097, 'train/loss': 0.2594446284430368, 'validation/ssim': 0.7242609559651098, 'validation/loss': 0.28615287132456385, 'validation/num_examples': 3554, 'test/ssim': 0.7414494876387532, 'test/loss': 0.2875438307757086, 'test/num_examples': 3581, 'score': 2756.2938911914825, 'total_duration': 2898.9560811519623, 'accumulated_submission_time': 2756.2938911914825, 'accumulated_eval_time': 141.3688714504242, 'accumulated_logging_time': 0.8870675563812256, 'global_step': 11698, 'preemption_count': 0}), (12040, {'train/ssim': 0.7494462558201381, 'train/loss': 0.2613473790032523, 'validation/ssim': 0.7227448660400253, 'validation/loss': 0.28805358234120004, 'validation/num_examples': 3554, 'test/ssim': 0.7397514797062622, 'test/loss': 0.2896840325349937, 'test/num_examples': 3581, 'score': 2836.426928758621, 'total_duration': 2983.175198316574, 'accumulated_submission_time': 2836.426928758621, 'accumulated_eval_time': 145.4126329421997, 'accumulated_logging_time': 0.9173834323883057, 'global_step': 12040, 'preemption_count': 0}), (12386, {'train/ssim': 0.750204358782087, 'train/loss': 0.2600323813302176, 'validation/ssim': 0.7231275636826463, 'validation/loss': 0.28711978223260765, 'validation/num_examples': 3554, 'test/ssim': 0.7402833940196524, 'test/loss': 0.28856290142418317, 'test/num_examples': 3581, 'score': 2916.4312081336975, 'total_duration': 3067.2598235607147, 'accumulated_submission_time': 2916.4312081336975, 'accumulated_eval_time': 149.45334696769714, 'accumulated_logging_time': 0.9447588920593262, 'global_step': 12386, 'preemption_count': 0}), (12733, {'train/ssim': 0.7511591911315918, 'train/loss': 0.2594108922140939, 'validation/ssim': 0.7242919372318163, 'validation/loss': 0.2863031064249789, 'validation/num_examples': 3554, 'test/ssim': 0.7415381172987643, 'test/loss': 0.2877028869270979, 'test/num_examples': 3581, 'score': 2996.577868938446, 'total_duration': 3151.4868512153625, 'accumulated_submission_time': 2996.577868938446, 'accumulated_eval_time': 153.49388575553894, 'accumulated_logging_time': 0.9722623825073242, 'global_step': 12733, 'preemption_count': 0}), (13076, {'train/ssim': 0.7509640284946987, 'train/loss': 0.25927363123212543, 'validation/ssim': 0.7234867677704699, 'validation/loss': 0.28640760809233434, 'validation/num_examples': 3554, 'test/ssim': 0.7408127857965652, 'test/loss': 0.2877901871422089, 'test/num_examples': 3581, 'score': 3076.590484857559, 'total_duration': 3235.581696033478, 'accumulated_submission_time': 3076.590484857559, 'accumulated_eval_time': 157.53622794151306, 'accumulated_logging_time': 1.0001962184906006, 'global_step': 13076, 'preemption_count': 0}), (13423, {'train/ssim': 0.7516891615731376, 'train/loss': 0.2590251309531076, 'validation/ssim': 0.7246937319745357, 'validation/loss': 0.28610693180769026, 'validation/num_examples': 3554, 'test/ssim': 0.7419136343505655, 'test/loss': 0.2874563601189437, 'test/num_examples': 3581, 'score': 3156.599609851837, 'total_duration': 3319.675098657608, 'accumulated_submission_time': 3156.599609851837, 'accumulated_eval_time': 161.58116555213928, 'accumulated_logging_time': 1.027517318725586, 'global_step': 13423, 'preemption_count': 0}), (13767, {'train/ssim': 0.7525512150355748, 'train/loss': 0.2592755045209612, 'validation/ssim': 0.725603042456563, 'validation/loss': 0.28627118060745815, 'validation/num_examples': 3554, 'test/ssim': 0.7428037488437238, 'test/loss': 0.2875207529757749, 'test/num_examples': 3581, 'score': 3236.6604750156403, 'total_duration': 3403.820134162903, 'accumulated_submission_time': 3236.6604750156403, 'accumulated_eval_time': 165.62573671340942, 'accumulated_logging_time': 1.0552878379821777, 'global_step': 13767, 'preemption_count': 0}), (14109, {'train/ssim': 0.751023496900286, 'train/loss': 0.2595189298902239, 'validation/ssim': 0.7241041261826463, 'validation/loss': 0.2864473479211364, 'validation/num_examples': 3554, 'test/ssim': 0.7413269060012916, 'test/loss': 0.28778118782288464, 'test/num_examples': 3581, 'score': 3316.681303024292, 'total_duration': 3487.92396235466, 'accumulated_submission_time': 3316.681303024292, 'accumulated_eval_time': 169.66971588134766, 'accumulated_logging_time': 1.0825152397155762, 'global_step': 14109, 'preemption_count': 0}), (14455, {'train/ssim': 0.7515461785452706, 'train/loss': 0.25904996054513113, 'validation/ssim': 0.7243747142304445, 'validation/loss': 0.2861744070831282, 'validation/num_examples': 3554, 'test/ssim': 0.741536821942195, 'test/loss': 0.2875540231866099, 'test/num_examples': 3581, 'score': 3396.6965384483337, 'total_duration': 3572.0214359760284, 'accumulated_submission_time': 3396.6965384483337, 'accumulated_eval_time': 173.71239233016968, 'accumulated_logging_time': 1.1100866794586182, 'global_step': 14455, 'preemption_count': 0}), (14798, {'train/ssim': 0.7518469265529087, 'train/loss': 0.2589538437979562, 'validation/ssim': 0.7248509052300225, 'validation/loss': 0.2859152223397053, 'validation/num_examples': 3554, 'test/ssim': 0.7420895983140184, 'test/loss': 0.28719541394687237, 'test/num_examples': 3581, 'score': 3476.7126338481903, 'total_duration': 3656.121811389923, 'accumulated_submission_time': 3476.7126338481903, 'accumulated_eval_time': 177.75773978233337, 'accumulated_logging_time': 1.1371407508850098, 'global_step': 14798, 'preemption_count': 0}), (15139, {'train/ssim': 0.7508306503295898, 'train/loss': 0.2592305285590036, 'validation/ssim': 0.723704598361881, 'validation/loss': 0.2860429084361371, 'validation/num_examples': 3554, 'test/ssim': 0.7410505178153798, 'test/loss': 0.28736681007400167, 'test/num_examples': 3581, 'score': 3556.6941096782684, 'total_duration': 3740.1839442253113, 'accumulated_submission_time': 3556.6941096782684, 'accumulated_eval_time': 181.7992980480194, 'accumulated_logging_time': 1.1644668579101562, 'global_step': 15139, 'preemption_count': 0}), (15484, {'train/ssim': 0.7520397731236049, 'train/loss': 0.258493321282523, 'validation/ssim': 0.7246311511896807, 'validation/loss': 0.2858670845954822, 'validation/num_examples': 3554, 'test/ssim': 0.7418912042289165, 'test/loss': 0.2872118104339744, 'test/num_examples': 3581, 'score': 3636.6995763778687, 'total_duration': 3824.274204969406, 'accumulated_submission_time': 3636.6995763778687, 'accumulated_eval_time': 185.84392023086548, 'accumulated_logging_time': 1.192673683166504, 'global_step': 15484, 'preemption_count': 0}), (15830, {'train/ssim': 0.7524919509887695, 'train/loss': 0.2586504561560495, 'validation/ssim': 0.7252742700786086, 'validation/loss': 0.2858471803337788, 'validation/num_examples': 3554, 'test/ssim': 0.7425571538589081, 'test/loss': 0.2872363199438006, 'test/num_examples': 3581, 'score': 3716.708996295929, 'total_duration': 3908.3695607185364, 'accumulated_submission_time': 3716.708996295929, 'accumulated_eval_time': 189.8890540599823, 'accumulated_logging_time': 1.2215955257415771, 'global_step': 15830, 'preemption_count': 0}), (16172, {'train/ssim': 0.752331052507673, 'train/loss': 0.25889621462140766, 'validation/ssim': 0.7253598635560284, 'validation/loss': 0.2859032351311902, 'validation/num_examples': 3554, 'test/ssim': 0.7425735162576794, 'test/loss': 0.28724842130122524, 'test/num_examples': 3581, 'score': 3796.7763459682465, 'total_duration': 3992.514327287674, 'accumulated_submission_time': 3796.7763459682465, 'accumulated_eval_time': 193.92577123641968, 'accumulated_logging_time': 1.2505333423614502, 'global_step': 16172, 'preemption_count': 0}), (16518, {'train/ssim': 0.7533513477870396, 'train/loss': 0.2581365278788975, 'validation/ssim': 0.7257867318294527, 'validation/loss': 0.28566886631370464, 'validation/num_examples': 3554, 'test/ssim': 0.7430086197116728, 'test/loss': 0.28703189222415176, 'test/num_examples': 3581, 'score': 3876.9645669460297, 'total_duration': 4076.7896065711975, 'accumulated_submission_time': 3876.9645669460297, 'accumulated_eval_time': 197.97216725349426, 'accumulated_logging_time': 1.2790398597717285, 'global_step': 16518, 'preemption_count': 0}), (16865, {'train/ssim': 0.7501613753182548, 'train/loss': 0.26048595564705984, 'validation/ssim': 0.7228891934044387, 'validation/loss': 0.2876615250586927, 'validation/num_examples': 3554, 'test/ssim': 0.7400654332326864, 'test/loss': 0.28903325221219633, 'test/num_examples': 3581, 'score': 3957.033786058426, 'total_duration': 4160.949885845184, 'accumulated_submission_time': 3957.033786058426, 'accumulated_eval_time': 202.02194118499756, 'accumulated_logging_time': 1.3082997798919678, 'global_step': 16865, 'preemption_count': 0}), (17208, {'train/ssim': 0.7530238287789481, 'train/loss': 0.2587417704718454, 'validation/ssim': 0.7258637384812887, 'validation/loss': 0.28596162554516036, 'validation/num_examples': 3554, 'test/ssim': 0.7430537526616169, 'test/loss': 0.2873627876509704, 'test/num_examples': 3581, 'score': 4037.09632229805, 'total_duration': 4245.098760128021, 'accumulated_submission_time': 4037.09632229805, 'accumulated_eval_time': 206.06452655792236, 'accumulated_logging_time': 1.340169906616211, 'global_step': 17208, 'preemption_count': 0}), (17550, {'train/ssim': 0.7533447401864188, 'train/loss': 0.258039082799639, 'validation/ssim': 0.7255524832275253, 'validation/loss': 0.2857619303293824, 'validation/num_examples': 3554, 'test/ssim': 0.7427513209909942, 'test/loss': 0.2871518490601438, 'test/num_examples': 3581, 'score': 4117.163950681686, 'total_duration': 4329.249045372009, 'accumulated_submission_time': 4117.163950681686, 'accumulated_eval_time': 210.106116771698, 'accumulated_logging_time': 1.3692708015441895, 'global_step': 17550, 'preemption_count': 0}), (17896, {'train/ssim': 0.7520776476178851, 'train/loss': 0.2586672987256731, 'validation/ssim': 0.7246424857994513, 'validation/loss': 0.28585690062033975, 'validation/num_examples': 3554, 'test/ssim': 0.7418576613114354, 'test/loss': 0.2872524778125873, 'test/num_examples': 3581, 'score': 4197.277628183365, 'total_duration': 4413.445830821991, 'accumulated_submission_time': 4197.277628183365, 'accumulated_eval_time': 214.1493580341339, 'accumulated_logging_time': 1.3973166942596436, 'global_step': 17896, 'preemption_count': 0}), (18240, {'train/ssim': 0.7529400416782924, 'train/loss': 0.25858713899339947, 'validation/ssim': 0.7257781450038688, 'validation/loss': 0.285744481899796, 'validation/num_examples': 3554, 'test/ssim': 0.7430021429288257, 'test/loss': 0.28705023174610794, 'test/num_examples': 3581, 'score': 4277.350579023361, 'total_duration': 4497.604445934296, 'accumulated_submission_time': 4277.350579023361, 'accumulated_eval_time': 218.1914882659912, 'accumulated_logging_time': 1.4288592338562012, 'global_step': 18240, 'preemption_count': 0}), (18583, {'train/ssim': 0.7526175635201591, 'train/loss': 0.25831386021205355, 'validation/ssim': 0.724809276299592, 'validation/loss': 0.28603803111920545, 'validation/num_examples': 3554, 'test/ssim': 0.7419922420413292, 'test/loss': 0.287416579036931, 'test/num_examples': 3581, 'score': 4357.3684694767, 'total_duration': 4581.708220720291, 'accumulated_submission_time': 4357.3684694767, 'accumulated_eval_time': 222.23729467391968, 'accumulated_logging_time': 1.456954002380371, 'global_step': 18583, 'preemption_count': 0}), (18928, {'train/ssim': 0.7526444707598005, 'train/loss': 0.2583979368209839, 'validation/ssim': 0.7252818264851224, 'validation/loss': 0.2857613464252427, 'validation/num_examples': 3554, 'test/ssim': 0.742520133931688, 'test/loss': 0.2870654692299637, 'test/num_examples': 3581, 'score': 4437.445201873779, 'total_duration': 4665.86545753479, 'accumulated_submission_time': 4437.445201873779, 'accumulated_eval_time': 226.27573919296265, 'accumulated_logging_time': 1.4869132041931152, 'global_step': 18928, 'preemption_count': 0}), (19275, {'train/ssim': 0.7517557144165039, 'train/loss': 0.25839885643550325, 'validation/ssim': 0.7244192283342712, 'validation/loss': 0.2855900220811937, 'validation/num_examples': 3554, 'test/ssim': 0.7416877650708601, 'test/loss': 0.2868797560039095, 'test/num_examples': 3581, 'score': 4517.462399482727, 'total_duration': 4749.96740436554, 'accumulated_submission_time': 4517.462399482727, 'accumulated_eval_time': 230.3186469078064, 'accumulated_logging_time': 1.516965389251709, 'global_step': 19275, 'preemption_count': 0}), (19617, {'train/ssim': 0.7539084298270089, 'train/loss': 0.2587548664637974, 'validation/ssim': 0.7266995457363182, 'validation/loss': 0.2865791213465462, 'validation/num_examples': 3554, 'test/ssim': 0.7436792735313111, 'test/loss': 0.28803296423397795, 'test/num_examples': 3581, 'score': 4597.49485373497, 'total_duration': 4834.088021278381, 'accumulated_submission_time': 4597.49485373497, 'accumulated_eval_time': 234.36544585227966, 'accumulated_logging_time': 1.5466229915618896, 'global_step': 19617, 'preemption_count': 0}), (19961, {'train/ssim': 0.7524251937866211, 'train/loss': 0.2587899650846209, 'validation/ssim': 0.7250721705516672, 'validation/loss': 0.2861384798048853, 'validation/num_examples': 3554, 'test/ssim': 0.7423036048546147, 'test/loss': 0.28748291492861633, 'test/num_examples': 3581, 'score': 4677.679318904877, 'total_duration': 4918.363613605499, 'accumulated_submission_time': 4677.679318904877, 'accumulated_eval_time': 238.41141080856323, 'accumulated_logging_time': 1.579699993133545, 'global_step': 19961, 'preemption_count': 0}), (20307, {'train/ssim': 0.7524850709097726, 'train/loss': 0.25830018520355225, 'validation/ssim': 0.7251725333690912, 'validation/loss': 0.2855643646463492, 'validation/num_examples': 3554, 'test/ssim': 0.7423865076750559, 'test/loss': 0.2868783583823478, 'test/num_examples': 3581, 'score': 4757.7959949970245, 'total_duration': 5002.560688257217, 'accumulated_submission_time': 4757.7959949970245, 'accumulated_eval_time': 242.4510452747345, 'accumulated_logging_time': 1.6081418991088867, 'global_step': 20307, 'preemption_count': 0}), (20651, {'train/ssim': 0.7529078211103167, 'train/loss': 0.2586125305720738, 'validation/ssim': 0.7252262525499438, 'validation/loss': 0.28611390431006434, 'validation/num_examples': 3554, 'test/ssim': 0.7424755463950363, 'test/loss': 0.2873984440449595, 'test/num_examples': 3581, 'score': 4837.757677555084, 'total_duration': 5086.611615896225, 'accumulated_submission_time': 4837.757677555084, 'accumulated_eval_time': 246.49749064445496, 'accumulated_logging_time': 1.6389946937561035, 'global_step': 20651, 'preemption_count': 0}), (20998, {'train/ssim': 0.7535805702209473, 'train/loss': 0.25805178710392546, 'validation/ssim': 0.72609613232889, 'validation/loss': 0.2855590923354407, 'validation/num_examples': 3554, 'test/ssim': 0.743132905765673, 'test/loss': 0.28694858034374127, 'test/num_examples': 3581, 'score': 4917.874920606613, 'total_duration': 5170.8072781562805, 'accumulated_submission_time': 4917.874920606613, 'accumulated_eval_time': 250.53546237945557, 'accumulated_logging_time': 1.667454719543457, 'global_step': 20998, 'preemption_count': 0}), (21342, {'train/ssim': 0.7533642905099052, 'train/loss': 0.25808894634246826, 'validation/ssim': 0.7260072415104459, 'validation/loss': 0.28545465936268993, 'validation/num_examples': 3554, 'test/ssim': 0.7431851972650796, 'test/loss': 0.28677582068338103, 'test/num_examples': 3581, 'score': 4998.068671941757, 'total_duration': 5255.080285787582, 'accumulated_submission_time': 4998.068671941757, 'accumulated_eval_time': 254.57356691360474, 'accumulated_logging_time': 1.696807622909546, 'global_step': 21342, 'preemption_count': 0}), (21685, {'train/ssim': 0.7526271683829171, 'train/loss': 0.2587615592139108, 'validation/ssim': 0.7254229252031162, 'validation/loss': 0.2861455725228176, 'validation/num_examples': 3554, 'test/ssim': 0.7425711300745252, 'test/loss': 0.28759192941043005, 'test/num_examples': 3581, 'score': 5078.216583013535, 'total_duration': 5339.313606500626, 'accumulated_submission_time': 5078.216583013535, 'accumulated_eval_time': 258.6179361343384, 'accumulated_logging_time': 1.7260563373565674, 'global_step': 21685, 'preemption_count': 0}), (22031, {'train/ssim': 0.7523194040570941, 'train/loss': 0.2580763101577759, 'validation/ssim': 0.7246382954285664, 'validation/loss': 0.2857501663783325, 'validation/num_examples': 3554, 'test/ssim': 0.7418408898526948, 'test/loss': 0.28712747590364074, 'test/num_examples': 3581, 'score': 5158.255975008011, 'total_duration': 5423.437246322632, 'accumulated_submission_time': 5158.255975008011, 'accumulated_eval_time': 262.6589164733887, 'accumulated_logging_time': 1.7574434280395508, 'global_step': 22031, 'preemption_count': 0}), (22376, {'train/ssim': 0.7534683772495815, 'train/loss': 0.2578743355614798, 'validation/ssim': 0.7259059169685566, 'validation/loss': 0.2853841786982977, 'validation/num_examples': 3554, 'test/ssim': 0.743134405652227, 'test/loss': 0.2867114619148806, 'test/num_examples': 3581, 'score': 5238.368992090225, 'total_duration': 5507.633875846863, 'accumulated_submission_time': 5238.368992090225, 'accumulated_eval_time': 266.70121240615845, 'accumulated_logging_time': 1.7868409156799316, 'global_step': 22376, 'preemption_count': 0}), (22719, {'train/ssim': 0.753256116594587, 'train/loss': 0.25782101494925364, 'validation/ssim': 0.7257600096282358, 'validation/loss': 0.285283953270083, 'validation/num_examples': 3554, 'test/ssim': 0.7429689408946524, 'test/loss': 0.2866599544470818, 'test/num_examples': 3581, 'score': 5318.3560972213745, 'total_duration': 5591.70784330368, 'accumulated_submission_time': 5318.3560972213745, 'accumulated_eval_time': 270.7464687824249, 'accumulated_logging_time': 1.8165028095245361, 'global_step': 22719, 'preemption_count': 0}), (23065, {'train/ssim': 0.7534429005214146, 'train/loss': 0.25738087722233366, 'validation/ssim': 0.7255944556309791, 'validation/loss': 0.2852384774417909, 'validation/num_examples': 3554, 'test/ssim': 0.7428008854239389, 'test/loss': 0.2866411376884948, 'test/num_examples': 3581, 'score': 5398.403444766998, 'total_duration': 5675.84022974968, 'accumulated_submission_time': 5398.403444766998, 'accumulated_eval_time': 274.7826302051544, 'accumulated_logging_time': 1.8535089492797852, 'global_step': 23065, 'preemption_count': 0}), (23411, {'train/ssim': 0.7532764162336077, 'train/loss': 0.25764104298182894, 'validation/ssim': 0.7255148385841658, 'validation/loss': 0.2853181631832091, 'validation/num_examples': 3554, 'test/ssim': 0.7427481166879014, 'test/loss': 0.28663442228733244, 'test/num_examples': 3581, 'score': 5478.536856174469, 'total_duration': 5760.058264970779, 'accumulated_submission_time': 5478.536856174469, 'accumulated_eval_time': 278.8257200717926, 'accumulated_logging_time': 1.882972240447998, 'global_step': 23411, 'preemption_count': 0}), (23752, {'train/ssim': 0.7536858149937221, 'train/loss': 0.25762769154139925, 'validation/ssim': 0.7259083899743247, 'validation/loss': 0.2852405726272334, 'validation/num_examples': 3554, 'test/ssim': 0.7431360418921041, 'test/loss': 0.28656464347423904, 'test/num_examples': 3581, 'score': 5558.539285182953, 'total_duration': 5844.148059844971, 'accumulated_submission_time': 5558.539285182953, 'accumulated_eval_time': 282.8697578907013, 'accumulated_logging_time': 1.914400339126587, 'global_step': 23752, 'preemption_count': 0}), (24097, {'train/ssim': 0.754117625100272, 'train/loss': 0.25708154269627165, 'validation/ssim': 0.7259977616550014, 'validation/loss': 0.2851191377398266, 'validation/num_examples': 3554, 'test/ssim': 0.7432274667952388, 'test/loss': 0.28648681981508306, 'test/num_examples': 3581, 'score': 5638.572496652603, 'total_duration': 5928.258192777634, 'accumulated_submission_time': 5638.572496652603, 'accumulated_eval_time': 286.9048192501068, 'accumulated_logging_time': 1.944274663925171, 'global_step': 24097, 'preemption_count': 0}), (24442, {'train/ssim': 0.7537539345877511, 'train/loss': 0.25759732723236084, 'validation/ssim': 0.7259774280520188, 'validation/loss': 0.2854220294254713, 'validation/num_examples': 3554, 'test/ssim': 0.7431903105146956, 'test/loss': 0.28672366553729756, 'test/num_examples': 3581, 'score': 5718.696158885956, 'total_duration': 6012.466329336166, 'accumulated_submission_time': 5718.696158885956, 'accumulated_eval_time': 290.94787549972534, 'accumulated_logging_time': 1.973649024963379, 'global_step': 24442, 'preemption_count': 0}), (24786, {'train/ssim': 0.753805433000837, 'train/loss': 0.2577033042907715, 'validation/ssim': 0.7263403416484947, 'validation/loss': 0.28535196092870707, 'validation/num_examples': 3554, 'test/ssim': 0.7434939693652262, 'test/loss': 0.28660728797603674, 'test/num_examples': 3581, 'score': 5798.691824436188, 'total_duration': 6096.550888776779, 'accumulated_submission_time': 5798.691824436188, 'accumulated_eval_time': 294.99489879608154, 'accumulated_logging_time': 2.0035831928253174, 'global_step': 24786, 'preemption_count': 0}), (25128, {'train/ssim': 0.7541419437953404, 'train/loss': 0.25712132453918457, 'validation/ssim': 0.725858655080543, 'validation/loss': 0.28531630842888295, 'validation/num_examples': 3554, 'test/ssim': 0.7430844321593131, 'test/loss': 0.28664308072334893, 'test/num_examples': 3581, 'score': 5878.656435251236, 'total_duration': 6180.59944486618, 'accumulated_submission_time': 5878.656435251236, 'accumulated_eval_time': 299.0336084365845, 'accumulated_logging_time': 2.036623239517212, 'global_step': 25128, 'preemption_count': 0}), (25473, {'train/ssim': 0.7536706243242536, 'train/loss': 0.25753794397626606, 'validation/ssim': 0.7256218647782429, 'validation/loss': 0.2854699439122292, 'validation/num_examples': 3554, 'test/ssim': 0.7428558358131457, 'test/loss': 0.2867858085642977, 'test/num_examples': 3581, 'score': 5958.823487281799, 'total_duration': 6264.849833726883, 'accumulated_submission_time': 5958.823487281799, 'accumulated_eval_time': 303.0692329406738, 'accumulated_logging_time': 2.072427272796631, 'global_step': 25473, 'preemption_count': 0}), (25820, {'train/ssim': 0.7535369055611747, 'train/loss': 0.2573683943067278, 'validation/ssim': 0.7258339937174663, 'validation/loss': 0.28513771963039003, 'validation/num_examples': 3554, 'test/ssim': 0.7430077334150726, 'test/loss': 0.28644117554017734, 'test/num_examples': 3581, 'score': 6038.98579120636, 'total_duration': 6349.096369981766, 'accumulated_submission_time': 6038.98579120636, 'accumulated_eval_time': 307.11135363578796, 'accumulated_logging_time': 2.1028239727020264, 'global_step': 25820, 'preemption_count': 0}), (26159, {'train/ssim': 0.7538965770176479, 'train/loss': 0.2571835517883301, 'validation/ssim': 0.7256854072875633, 'validation/loss': 0.28539213009878833, 'validation/num_examples': 3554, 'test/ssim': 0.7428385871177744, 'test/loss': 0.28681996507173274, 'test/num_examples': 3581, 'score': 6118.951326370239, 'total_duration': 6433.150407791138, 'accumulated_submission_time': 6118.951326370239, 'accumulated_eval_time': 311.15779757499695, 'accumulated_logging_time': 2.13295578956604, 'global_step': 26159, 'preemption_count': 0}), (26505, {'train/ssim': 0.7541265487670898, 'train/loss': 0.25708443777901785, 'validation/ssim': 0.7260599989668332, 'validation/loss': 0.2851045401363341, 'validation/num_examples': 3554, 'test/ssim': 0.7432574645263195, 'test/loss': 0.28644874314960905, 'test/num_examples': 3581, 'score': 6199.053456783295, 'total_duration': 6517.338342905045, 'accumulated_submission_time': 6199.053456783295, 'accumulated_eval_time': 315.20138478279114, 'accumulated_logging_time': 2.1633517742156982, 'global_step': 26505, 'preemption_count': 0}), (26851, {'train/ssim': 0.7537615639822823, 'train/loss': 0.25740526403699604, 'validation/ssim': 0.7258054167619232, 'validation/loss': 0.2853107098186023, 'validation/num_examples': 3554, 'test/ssim': 0.7429794401005306, 'test/loss': 0.2866079356543214, 'test/num_examples': 3581, 'score': 6279.126361370087, 'total_duration': 6601.50510263443, 'accumulated_submission_time': 6279.126361370087, 'accumulated_eval_time': 319.24842977523804, 'accumulated_logging_time': 2.198110342025757, 'global_step': 26851, 'preemption_count': 0}), (27195, {'train/ssim': 0.7544635363987514, 'train/loss': 0.2570823771612985, 'validation/ssim': 0.7263280453142585, 'validation/loss': 0.28524581059083953, 'validation/num_examples': 3554, 'test/ssim': 0.7434335648430955, 'test/loss': 0.2866400127735793, 'test/num_examples': 3581, 'score': 6359.1869966983795, 'total_duration': 6685.648197650909, 'accumulated_submission_time': 6359.1869966983795, 'accumulated_eval_time': 323.28483629226685, 'accumulated_logging_time': 2.2321996688842773, 'global_step': 27195, 'preemption_count': 0}), (27543, {'train/ssim': 0.7543215751647949, 'train/loss': 0.2569711378642491, 'validation/ssim': 0.7262150426895752, 'validation/loss': 0.2850779381506753, 'validation/num_examples': 3554, 'test/ssim': 0.7433979084491064, 'test/loss': 0.2864332329591071, 'test/num_examples': 3581, 'score': 6439.320326805115, 'total_duration': 6769.8714554309845, 'accumulated_submission_time': 6439.320326805115, 'accumulated_eval_time': 327.3263280391693, 'accumulated_logging_time': 2.2685048580169678, 'global_step': 27543, 'preemption_count': 0}), (27886, {'train/ssim': 0.754523481641497, 'train/loss': 0.25713930811200825, 'validation/ssim': 0.726480478642023, 'validation/loss': 0.28523335969374297, 'validation/num_examples': 3554, 'test/ssim': 0.743686363904112, 'test/loss': 0.28649776216926137, 'test/num_examples': 3581, 'score': 6519.368485689163, 'total_duration': 6854.003954172134, 'accumulated_submission_time': 6519.368485689163, 'accumulated_eval_time': 331.366498708725, 'accumulated_logging_time': 2.3007984161376953, 'global_step': 27886, 'preemption_count': 0}), (28229, {'train/ssim': 0.7529176303318569, 'train/loss': 0.25762838976723806, 'validation/ssim': 0.7251205315533554, 'validation/loss': 0.28556697504132666, 'validation/num_examples': 3554, 'test/ssim': 0.7423255577396328, 'test/loss': 0.2869981788650168, 'test/num_examples': 3581, 'score': 6599.540381908417, 'total_duration': 6938.260453462601, 'accumulated_submission_time': 6599.540381908417, 'accumulated_eval_time': 335.408899307251, 'accumulated_logging_time': 2.330955982208252, 'global_step': 28229, 'preemption_count': 0}), (28572, {'train/ssim': 0.7542286600385394, 'train/loss': 0.2567955596106393, 'validation/ssim': 0.7258950632210186, 'validation/loss': 0.28507307800739484, 'validation/num_examples': 3554, 'test/ssim': 0.7430802733829587, 'test/loss': 0.2864325852808224, 'test/num_examples': 3581, 'score': 6679.681492090225, 'total_duration': 7022.488809347153, 'accumulated_submission_time': 6679.681492090225, 'accumulated_eval_time': 339.4527425765991, 'accumulated_logging_time': 2.3624444007873535, 'global_step': 28572, 'preemption_count': 0}), (28918, {'train/ssim': 0.7547598566327777, 'train/loss': 0.25696420669555664, 'validation/ssim': 0.7266376518975098, 'validation/loss': 0.2851225209491066, 'validation/num_examples': 3554, 'test/ssim': 0.7438062866517733, 'test/loss': 0.28641676829534346, 'test/num_examples': 3581, 'score': 6759.659672021866, 'total_duration': 7106.558267116547, 'accumulated_submission_time': 6759.659672021866, 'accumulated_eval_time': 343.49573826789856, 'accumulated_logging_time': 2.3988473415374756, 'global_step': 28918, 'preemption_count': 0}), (29264, {'train/ssim': 0.7535268919808524, 'train/loss': 0.2571125200816563, 'validation/ssim': 0.7255190289550506, 'validation/loss': 0.28521125720469015, 'validation/num_examples': 3554, 'test/ssim': 0.7426680091105836, 'test/loss': 0.2865796082514486, 'test/num_examples': 3581, 'score': 6839.815808057785, 'total_duration': 7190.804083108902, 'accumulated_submission_time': 6839.815808057785, 'accumulated_eval_time': 347.5355215072632, 'accumulated_logging_time': 2.4366612434387207, 'global_step': 29264, 'preemption_count': 0}), (29609, {'train/ssim': 0.7549184390476772, 'train/loss': 0.2566295181001936, 'validation/ssim': 0.7264830890370005, 'validation/loss': 0.28509165989795826, 'validation/num_examples': 3554, 'test/ssim': 0.74362766379852, 'test/loss': 0.2864999097341001, 'test/num_examples': 3581, 'score': 6920.005371332169, 'total_duration': 7275.075638055801, 'accumulated_submission_time': 6920.005371332169, 'accumulated_eval_time': 351.5742256641388, 'accumulated_logging_time': 2.4678423404693604, 'global_step': 29609, 'preemption_count': 0}), (29956, {'train/ssim': 0.7546397617885044, 'train/loss': 0.2568075145993914, 'validation/ssim': 0.7264039528524198, 'validation/loss': 0.2850718758518131, 'validation/num_examples': 3554, 'test/ssim': 0.743571213522759, 'test/loss': 0.28639812197841036, 'test/num_examples': 3581, 'score': 7000.064207315445, 'total_duration': 7359.221385478973, 'accumulated_submission_time': 7000.064207315445, 'accumulated_eval_time': 355.6179938316345, 'accumulated_logging_time': 2.4991798400878906, 'global_step': 29956, 'preemption_count': 0}), (30300, {'train/ssim': 0.7547033173697335, 'train/loss': 0.25691587584359304, 'validation/ssim': 0.7264863863780248, 'validation/loss': 0.285162192083304, 'validation/num_examples': 3554, 'test/ssim': 0.7436359131745671, 'test/loss': 0.2865445995357442, 'test/num_examples': 3581, 'score': 7080.1818997859955, 'total_duration': 7443.427941322327, 'accumulated_submission_time': 7080.1818997859955, 'accumulated_eval_time': 359.66366052627563, 'accumulated_logging_time': 2.530510187149048, 'global_step': 30300, 'preemption_count': 0}), (30646, {'train/ssim': 0.755000250680106, 'train/loss': 0.2563994271414621, 'validation/ssim': 0.7263446694085889, 'validation/loss': 0.2850013264928162, 'validation/num_examples': 3554, 'test/ssim': 0.7435238307429838, 'test/loss': 0.28638847498080144, 'test/num_examples': 3581, 'score': 7160.268867731094, 'total_duration': 7527.606162309647, 'accumulated_submission_time': 7160.268867731094, 'accumulated_eval_time': 363.7105996608734, 'accumulated_logging_time': 2.5629425048828125, 'global_step': 30646, 'preemption_count': 0}), (30990, {'train/ssim': 0.7543023654392788, 'train/loss': 0.2566179037094116, 'validation/ssim': 0.7258775460968275, 'validation/loss': 0.284997616984164, 'validation/num_examples': 3554, 'test/ssim': 0.7430925451820372, 'test/loss': 0.28634501235906523, 'test/num_examples': 3581, 'score': 7240.273091554642, 'total_duration': 7611.697166442871, 'accumulated_submission_time': 7240.273091554642, 'accumulated_eval_time': 367.7547652721405, 'accumulated_logging_time': 2.5936460494995117, 'global_step': 30990, 'preemption_count': 0}), (31334, {'train/ssim': 0.7549773624965123, 'train/loss': 0.25676192556108746, 'validation/ssim': 0.7266886919887803, 'validation/loss': 0.28507398821090674, 'validation/num_examples': 3554, 'test/ssim': 0.7438424202823932, 'test/loss': 0.28641179139905054, 'test/num_examples': 3581, 'score': 7320.299663305283, 'total_duration': 7695.818750143051, 'accumulated_submission_time': 7320.299663305283, 'accumulated_eval_time': 371.80034589767456, 'accumulated_logging_time': 2.63110613822937, 'global_step': 31334, 'preemption_count': 0}), (31681, {'train/ssim': 0.7553375107901437, 'train/loss': 0.25625278268541607, 'validation/ssim': 0.7267150020223692, 'validation/loss': 0.2849354655405881, 'validation/num_examples': 3554, 'test/ssim': 0.7438221718139137, 'test/loss': 0.28629872040587473, 'test/num_examples': 3581, 'score': 7400.453884601593, 'total_duration': 7780.056601762772, 'accumulated_submission_time': 7400.453884601593, 'accumulated_eval_time': 375.8334729671478, 'accumulated_logging_time': 2.6695849895477295, 'global_step': 31681, 'preemption_count': 0}), (32026, {'train/ssim': 0.7550763402666364, 'train/loss': 0.25651434489658903, 'validation/ssim': 0.726590046536473, 'validation/loss': 0.28498028877013576, 'validation/num_examples': 3554, 'test/ssim': 0.7437481319594736, 'test/loss': 0.2863594317229824, 'test/num_examples': 3581, 'score': 7480.44393825531, 'total_duration': 7864.1325850486755, 'accumulated_submission_time': 7480.44393825531, 'accumulated_eval_time': 379.8758656978607, 'accumulated_logging_time': 2.7011075019836426, 'global_step': 32026, 'preemption_count': 0}), (32370, {'train/ssim': 0.7548025676182338, 'train/loss': 0.25659542424338205, 'validation/ssim': 0.7264196839168894, 'validation/loss': 0.28502208943707796, 'validation/num_examples': 3554, 'test/ssim': 0.7435609870235269, 'test/loss': 0.2863833958195162, 'test/num_examples': 3581, 'score': 7560.630806207657, 'total_duration': 7948.39928150177, 'accumulated_submission_time': 7560.630806207657, 'accumulated_eval_time': 383.91172099113464, 'accumulated_logging_time': 2.7331085205078125, 'global_step': 32370, 'preemption_count': 0}), (32712, {'train/ssim': 0.7553097861153739, 'train/loss': 0.25619190079825266, 'validation/ssim': 0.7266341484726716, 'validation/loss': 0.28489490137652995, 'validation/num_examples': 3554, 'test/ssim': 0.7437498363760123, 'test/loss': 0.28627284736281766, 'test/num_examples': 3581, 'score': 7640.62170624733, 'total_duration': 8032.480271816254, 'accumulated_submission_time': 7640.62170624733, 'accumulated_eval_time': 387.9579894542694, 'accumulated_logging_time': 2.765145778656006, 'global_step': 32712, 'preemption_count': 0}), (33057, {'train/ssim': 0.7551392146519252, 'train/loss': 0.25631284713745117, 'validation/ssim': 0.7265522645039041, 'validation/loss': 0.2848909170894591, 'validation/num_examples': 3554, 'test/ssim': 0.743716770695162, 'test/loss': 0.28626282539357023, 'test/num_examples': 3581, 'score': 7720.608385562897, 'total_duration': 8116.549202203751, 'accumulated_submission_time': 7720.608385562897, 'accumulated_eval_time': 391.9960012435913, 'accumulated_logging_time': 2.797520399093628, 'global_step': 33057, 'preemption_count': 0}), (33401, {'train/ssim': 0.7549631936209542, 'train/loss': 0.25641167163848877, 'validation/ssim': 0.7264295072453574, 'validation/loss': 0.2849628746878517, 'validation/num_examples': 3554, 'test/ssim': 0.7435593507836498, 'test/loss': 0.28630894690510683, 'test/num_examples': 3581, 'score': 7800.907135248184, 'total_duration': 8200.876027584076, 'accumulated_submission_time': 7800.907135248184, 'accumulated_eval_time': 395.98051714897156, 'accumulated_logging_time': 2.8293039798736572, 'global_step': 33401, 'preemption_count': 0}), (33746, {'train/ssim': 0.7553563117980957, 'train/loss': 0.25617592675345285, 'validation/ssim': 0.7267946190691826, 'validation/loss': 0.28483000214876725, 'validation/num_examples': 3554, 'test/ssim': 0.7438874168790143, 'test/loss': 0.28620262540142416, 'test/num_examples': 3581, 'score': 7881.002731561661, 'total_duration': 8285.059644460678, 'accumulated_submission_time': 7881.002731561661, 'accumulated_eval_time': 400.01979994773865, 'accumulated_logging_time': 2.8660295009613037, 'global_step': 33746, 'preemption_count': 0}), (34090, {'train/ssim': 0.7552986826215472, 'train/loss': 0.25616354601723806, 'validation/ssim': 0.7266865624560355, 'validation/loss': 0.28479654787629255, 'validation/num_examples': 3554, 'test/ssim': 0.7438356707929, 'test/loss': 0.28616973016222774, 'test/num_examples': 3581, 'score': 7961.019174337387, 'total_duration': 8369.170066595078, 'accumulated_submission_time': 7961.019174337387, 'accumulated_eval_time': 404.0609667301178, 'accumulated_logging_time': 2.9068877696990967, 'global_step': 34090, 'preemption_count': 0}), (34437, {'train/ssim': 0.7552531787327358, 'train/loss': 0.25623464584350586, 'validation/ssim': 0.7266829216419879, 'validation/loss': 0.2848477081831211, 'validation/num_examples': 3554, 'test/ssim': 0.7438358753228846, 'test/loss': 0.2862102270991867, 'test/num_examples': 3581, 'score': 8041.14001584053, 'total_duration': 8453.379067897797, 'accumulated_submission_time': 8041.14001584053, 'accumulated_eval_time': 408.10397386550903, 'accumulated_logging_time': 2.9399144649505615, 'global_step': 34437, 'preemption_count': 0}), (34779, {'train/ssim': 0.7552689143589565, 'train/loss': 0.25617705072675434, 'validation/ssim': 0.7266373771190912, 'validation/loss': 0.2848144599944605, 'validation/num_examples': 3554, 'test/ssim': 0.7437871290098785, 'test/loss': 0.28617682053502863, 'test/num_examples': 3581, 'score': 8121.161528110504, 'total_duration': 8537.487291812897, 'accumulated_submission_time': 8121.161528110504, 'accumulated_eval_time': 412.1444194316864, 'accumulated_logging_time': 2.974390745162964, 'global_step': 34779, 'preemption_count': 0}), (35125, {'train/ssim': 0.7554235458374023, 'train/loss': 0.2560735600335257, 'validation/ssim': 0.7267863757166221, 'validation/loss': 0.28474231348590495, 'validation/num_examples': 3554, 'test/ssim': 0.7439305727057736, 'test/loss': 0.2861144729780438, 'test/num_examples': 3581, 'score': 8201.258660793304, 'total_duration': 8621.679370641708, 'accumulated_submission_time': 8201.258660793304, 'accumulated_eval_time': 416.184344291687, 'accumulated_logging_time': 3.0172266960144043, 'global_step': 35125, 'preemption_count': 0}), (35471, {'train/ssim': 0.7555623735700335, 'train/loss': 0.2561214140483311, 'validation/ssim': 0.7269094764481921, 'validation/loss': 0.28478588303891744, 'validation/num_examples': 3554, 'test/ssim': 0.744045791263788, 'test/loss': 0.28615408361840267, 'test/num_examples': 3581, 'score': 8281.31056690216, 'total_duration': 8705.81771326065, 'accumulated_submission_time': 8281.31056690216, 'accumulated_eval_time': 420.22679924964905, 'accumulated_logging_time': 3.0492374897003174, 'global_step': 35471, 'preemption_count': 0}), (35814, {'train/ssim': 0.7554898943219867, 'train/loss': 0.2561060871396746, 'validation/ssim': 0.7268266307549592, 'validation/loss': 0.2847845778414287, 'validation/num_examples': 3554, 'test/ssim': 0.7439735240025481, 'test/loss': 0.28615077705031766, 'test/num_examples': 3581, 'score': 8361.536612510681, 'total_duration': 8790.133450984955, 'accumulated_submission_time': 8361.536612510681, 'accumulated_eval_time': 424.2720458507538, 'accumulated_logging_time': 3.081813335418701, 'global_step': 35814, 'preemption_count': 0}), (36159, {'train/ssim': 0.7554442541939872, 'train/loss': 0.256074139050075, 'validation/ssim': 0.7268051980383019, 'validation/loss': 0.2847391707077413, 'validation/num_examples': 3554, 'test/ssim': 0.7439485713444219, 'test/loss': 0.28610356471219633, 'test/num_examples': 3581, 'score': 8441.574692964554, 'total_duration': 8874.257183551788, 'accumulated_submission_time': 8441.574692964554, 'accumulated_eval_time': 428.31070947647095, 'accumulated_logging_time': 3.1168370246887207, 'global_step': 36159, 'preemption_count': 0}), (36189, {'train/ssim': 0.7554440498352051, 'train/loss': 0.2560740368706839, 'validation/ssim': 0.7268047858706739, 'validation/loss': 0.2847391020131366, 'validation/num_examples': 3554, 'test/ssim': 0.7439481622844527, 'test/loss': 0.28610349653553474, 'test/num_examples': 3581, 'score': 8446.291797876358, 'total_duration': 8883.051620006561, 'accumulated_submission_time': 8446.291797876358, 'accumulated_eval_time': 432.35393595695496, 'accumulated_logging_time': 3.1495649814605713, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 18:41:20.314253 140584300062528 submission_runner.py:586] Timing: 8446.291797876358
I0204 18:41:20.314308 140584300062528 submission_runner.py:588] Total number of evals: 107
I0204 18:41:20.314354 140584300062528 submission_runner.py:589] ====================
I0204 18:41:20.314404 140584300062528 submission_runner.py:542] Using RNG seed 3907440050
I0204 18:41:20.316162 140584300062528 submission_runner.py:551] --- Tuning run 4/5 ---
I0204 18:41:20.316278 140584300062528 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4.
I0204 18:41:20.316769 140584300062528 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4/hparams.json.
I0204 18:41:20.317739 140584300062528 submission_runner.py:206] Initializing dataset.
I0204 18:41:20.696827 140584300062528 submission_runner.py:213] Initializing model.
I0204 18:41:22.916856 140584300062528 submission_runner.py:255] Initializing optimizer.
I0204 18:41:22.985949 140584300062528 submission_runner.py:262] Initializing metrics bundle.
I0204 18:41:22.986083 140584300062528 submission_runner.py:280] Initializing checkpoint and logger.
I0204 18:41:22.986673 140584300062528 checkpoints.py:915] Found no checkpoint files in /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4 with prefix checkpoint_
I0204 18:41:22.986787 140584300062528 submission_runner.py:300] Saving meta data to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4/meta_data_0.json.
I0204 18:41:22.986985 140584300062528 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0204 18:41:22.987046 140584300062528 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0204 18:41:27.412509 140584300062528 logger_utils.py:220] Unable to record git information. Continuing without it.
I0204 18:41:31.698135 140584300062528 submission_runner.py:304] Saving flags to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4/flags_0.json.
I0204 18:41:31.701409 140584300062528 submission_runner.py:314] Starting training loop.
I0204 18:42:02.517482 140392884336384 logging_writer.py:48] [0] global_step=0, grad_norm=4.385186672210693, loss=0.9066542387008667
I0204 18:42:02.523669 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:42:03.853294 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:42:05.179321 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:42:06.504240 140584300062528 submission_runner.py:408] Time since start: 34.80s, 	Step: 1, 	{'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 30.822123527526855, 'total_duration': 34.802770137786865, 'accumulated_submission_time': 30.822123527526855, 'accumulated_eval_time': 3.9805192947387695, 'accumulated_logging_time': 0}
I0204 18:42:06.513221 140397011515136 logging_writer.py:48] [1] accumulated_eval_time=3.980519, accumulated_logging_time=0, accumulated_submission_time=30.822124, global_step=1, preemption_count=0, score=30.822124, test/loss=0.912514, test/num_examples=3581, test/ssim=0.282943, total_duration=34.802770, train/loss=0.903264, train/ssim=0.267076, validation/loss=0.915262, validation/num_examples=3554, validation/ssim=0.258797
I0204 18:42:28.218078 140392884336384 logging_writer.py:48] [100] global_step=100, grad_norm=0.5183088183403015, loss=0.20882700383663177
I0204 18:42:52.109258 140397011515136 logging_writer.py:48] [200] global_step=200, grad_norm=0.5754141211509705, loss=0.3086482286453247
I0204 18:43:16.153597 140392884336384 logging_writer.py:48] [300] global_step=300, grad_norm=0.2483792006969452, loss=0.3257443904876709
I0204 18:43:26.545936 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:43:27.926127 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:43:29.252914 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:43:30.582576 140584300062528 submission_runner.py:408] Time since start: 118.88s, 	Step: 344, 	{'train/ssim': 0.7226132665361676, 'train/loss': 0.28545098645346506, 'validation/ssim': 0.6983893313432048, 'validation/loss': 0.3115307191280951, 'validation/num_examples': 3554, 'test/ssim': 0.7153852090460067, 'test/loss': 0.3137289525010472, 'test/num_examples': 3581, 'score': 110.83161187171936, 'total_duration': 118.88110089302063, 'accumulated_submission_time': 110.83161187171936, 'accumulated_eval_time': 8.01711654663086, 'accumulated_logging_time': 0.020013809204101562}
I0204 18:43:30.597062 140397011515136 logging_writer.py:48] [344] accumulated_eval_time=8.017117, accumulated_logging_time=0.020014, accumulated_submission_time=110.831612, global_step=344, preemption_count=0, score=110.831612, test/loss=0.313729, test/num_examples=3581, test/ssim=0.715385, total_duration=118.881101, train/loss=0.285451, train/ssim=0.722613, validation/loss=0.311531, validation/num_examples=3554, validation/ssim=0.698389
I0204 18:43:42.158451 140392884336384 logging_writer.py:48] [400] global_step=400, grad_norm=0.22996185719966888, loss=0.3255270719528198
I0204 18:44:06.382746 140397011515136 logging_writer.py:48] [500] global_step=500, grad_norm=0.25526946783065796, loss=0.26604896783828735
I0204 18:44:30.724812 140392884336384 logging_writer.py:48] [600] global_step=600, grad_norm=0.23437729477882385, loss=0.2690424919128418
I0204 18:44:50.794221 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:44:52.176645 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:44:53.510582 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:44:54.843713 140584300062528 submission_runner.py:408] Time since start: 203.14s, 	Step: 684, 	{'train/ssim': 0.7282571792602539, 'train/loss': 0.27705117634364534, 'validation/ssim': 0.7044029944252954, 'validation/loss': 0.30230977364852984, 'validation/num_examples': 3554, 'test/ssim': 0.7213692791599763, 'test/loss': 0.30420893392427045, 'test/num_examples': 3581, 'score': 191.00679397583008, 'total_duration': 203.1422142982483, 'accumulated_submission_time': 191.00679397583008, 'accumulated_eval_time': 12.06654405593872, 'accumulated_logging_time': 0.044104576110839844}
I0204 18:44:54.861647 140397011515136 logging_writer.py:48] [684] accumulated_eval_time=12.066544, accumulated_logging_time=0.044105, accumulated_submission_time=191.006794, global_step=684, preemption_count=0, score=191.006794, test/loss=0.304209, test/num_examples=3581, test/ssim=0.721369, total_duration=203.142214, train/loss=0.277051, train/ssim=0.728257, validation/loss=0.302310, validation/num_examples=3554, validation/ssim=0.704403
I0204 18:44:56.643207 140392884336384 logging_writer.py:48] [700] global_step=700, grad_norm=0.2815154194831848, loss=0.2684286832809448
I0204 18:45:20.842326 140397011515136 logging_writer.py:48] [800] global_step=800, grad_norm=0.204985573887825, loss=0.2246263027191162
I0204 18:45:45.626693 140392884336384 logging_writer.py:48] [900] global_step=900, grad_norm=0.17692118883132935, loss=0.3295081555843353
I0204 18:46:10.465594 140397011515136 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.16468405723571777, loss=0.22835996747016907
I0204 18:46:14.901734 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:46:16.284948 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:46:17.613957 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:46:18.944319 140584300062528 submission_runner.py:408] Time since start: 287.24s, 	Step: 1020, 	{'train/ssim': 0.7370714460100446, 'train/loss': 0.2704525334494455, 'validation/ssim': 0.711497979279509, 'validation/loss': 0.29614340246025606, 'validation/num_examples': 3554, 'test/ssim': 0.728832305592886, 'test/loss': 0.29805687651624896, 'test/num_examples': 3581, 'score': 271.02345633506775, 'total_duration': 287.2428436279297, 'accumulated_submission_time': 271.02345633506775, 'accumulated_eval_time': 16.10910677909851, 'accumulated_logging_time': 0.07337832450866699}
I0204 18:46:18.959267 140392884336384 logging_writer.py:48] [1020] accumulated_eval_time=16.109107, accumulated_logging_time=0.073378, accumulated_submission_time=271.023456, global_step=1020, preemption_count=0, score=271.023456, test/loss=0.298057, test/num_examples=3581, test/ssim=0.728832, total_duration=287.242844, train/loss=0.270453, train/ssim=0.737071, validation/loss=0.296143, validation/num_examples=3554, validation/ssim=0.711498
I0204 18:46:36.122390 140397011515136 logging_writer.py:48] [1100] global_step=1100, grad_norm=0.18544787168502808, loss=0.34868958592414856
I0204 18:46:59.950837 140392884336384 logging_writer.py:48] [1200] global_step=1200, grad_norm=0.2847387194633484, loss=0.22882536053657532
I0204 18:47:23.818235 140397011515136 logging_writer.py:48] [1300] global_step=1300, grad_norm=0.2294388860464096, loss=0.3112304210662842
I0204 18:47:39.040113 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:47:40.420161 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:47:41.754137 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:47:43.086318 140584300062528 submission_runner.py:408] Time since start: 371.38s, 	Step: 1366, 	{'train/ssim': 0.7303394590105329, 'train/loss': 0.27141354765210834, 'validation/ssim': 0.7056676620972847, 'validation/loss': 0.2970385618537212, 'validation/num_examples': 3554, 'test/ssim': 0.7230863083810388, 'test/loss': 0.2986054941117181, 'test/num_examples': 3581, 'score': 351.08174562454224, 'total_duration': 371.3848412036896, 'accumulated_submission_time': 351.08174562454224, 'accumulated_eval_time': 20.15527033805847, 'accumulated_logging_time': 0.09859204292297363}
I0204 18:47:43.101946 140392884336384 logging_writer.py:48] [1366] accumulated_eval_time=20.155270, accumulated_logging_time=0.098592, accumulated_submission_time=351.081746, global_step=1366, preemption_count=0, score=351.081746, test/loss=0.298605, test/num_examples=3581, test/ssim=0.723086, total_duration=371.384841, train/loss=0.271414, train/ssim=0.730339, validation/loss=0.297039, validation/num_examples=3554, validation/ssim=0.705668
I0204 18:47:49.161195 140397011515136 logging_writer.py:48] [1400] global_step=1400, grad_norm=0.34338611364364624, loss=0.2920381426811218
I0204 18:48:13.057212 140392884336384 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.34107547998428345, loss=0.3960621953010559
I0204 18:48:36.823514 140397011515136 logging_writer.py:48] [1600] global_step=1600, grad_norm=0.27104800939559937, loss=0.22807727754116058
I0204 18:49:00.684598 140392884336384 logging_writer.py:48] [1700] global_step=1700, grad_norm=0.1633269041776657, loss=0.33050811290740967
I0204 18:49:03.093659 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:49:04.476738 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:49:05.805091 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:49:07.134095 140584300062528 submission_runner.py:408] Time since start: 455.43s, 	Step: 1711, 	{'train/ssim': 0.7415225846426827, 'train/loss': 0.26839728014809744, 'validation/ssim': 0.7163652667988534, 'validation/loss': 0.29413257399233256, 'validation/num_examples': 3554, 'test/ssim': 0.7334914986430118, 'test/loss': 0.29592369695310317, 'test/num_examples': 3581, 'score': 431.05223202705383, 'total_duration': 455.43262481689453, 'accumulated_submission_time': 431.05223202705383, 'accumulated_eval_time': 24.19566798210144, 'accumulated_logging_time': 0.12353253364562988}
I0204 18:49:07.148747 140397011515136 logging_writer.py:48] [1711] accumulated_eval_time=24.195668, accumulated_logging_time=0.123533, accumulated_submission_time=431.052232, global_step=1711, preemption_count=0, score=431.052232, test/loss=0.295924, test/num_examples=3581, test/ssim=0.733491, total_duration=455.432625, train/loss=0.268397, train/ssim=0.741523, validation/loss=0.294133, validation/num_examples=3554, validation/ssim=0.716365
I0204 18:49:26.272303 140392884336384 logging_writer.py:48] [1800] global_step=1800, grad_norm=0.32148638367652893, loss=0.2644323706626892
I0204 18:49:50.227994 140397011515136 logging_writer.py:48] [1900] global_step=1900, grad_norm=0.13831688463687897, loss=0.2586091160774231
I0204 18:50:14.207848 140392884336384 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.4394916892051697, loss=0.2472544014453888
I0204 18:50:27.304465 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:50:28.686895 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:50:30.017049 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:50:31.348305 140584300062528 submission_runner.py:408] Time since start: 539.65s, 	Step: 2055, 	{'train/ssim': 0.741027695792062, 'train/loss': 0.2685650076184954, 'validation/ssim': 0.71662994711065, 'validation/loss': 0.29432574322066685, 'validation/num_examples': 3554, 'test/ssim': 0.7336164664636274, 'test/loss': 0.29597431812430186, 'test/num_examples': 3581, 'score': 511.1865234375, 'total_duration': 539.6468026638031, 'accumulated_submission_time': 511.1865234375, 'accumulated_eval_time': 28.23944354057312, 'accumulated_logging_time': 0.14762616157531738}
I0204 18:50:31.365713 140397011515136 logging_writer.py:48] [2055] accumulated_eval_time=28.239444, accumulated_logging_time=0.147626, accumulated_submission_time=511.186523, global_step=2055, preemption_count=0, score=511.186523, test/loss=0.295974, test/num_examples=3581, test/ssim=0.733616, total_duration=539.646803, train/loss=0.268565, train/ssim=0.741028, validation/loss=0.294326, validation/num_examples=3554, validation/ssim=0.716630
I0204 18:50:40.047682 140392884336384 logging_writer.py:48] [2100] global_step=2100, grad_norm=0.29648399353027344, loss=0.3316043019294739
I0204 18:51:03.922930 140397011515136 logging_writer.py:48] [2200] global_step=2200, grad_norm=0.16740426421165466, loss=0.2531823515892029
I0204 18:51:28.094563 140392884336384 logging_writer.py:48] [2300] global_step=2300, grad_norm=0.24953509867191315, loss=0.2510645091533661
I0204 18:51:51.517598 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:51:52.900093 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:51:54.232658 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:51:55.567062 140584300062528 submission_runner.py:408] Time since start: 623.87s, 	Step: 2400, 	{'train/ssim': 0.7440621512276786, 'train/loss': 0.2670582021985735, 'validation/ssim': 0.7178861653462648, 'validation/loss': 0.2936223104688379, 'validation/num_examples': 3554, 'test/ssim': 0.735299339177255, 'test/loss': 0.29511058799916223, 'test/num_examples': 3581, 'score': 591.3152222633362, 'total_duration': 623.8655636310577, 'accumulated_submission_time': 591.3152222633362, 'accumulated_eval_time': 32.28887057304382, 'accumulated_logging_time': 0.17611455917358398}
I0204 18:51:55.585019 140397011515136 logging_writer.py:48] [2400] accumulated_eval_time=32.288871, accumulated_logging_time=0.176115, accumulated_submission_time=591.315222, global_step=2400, preemption_count=0, score=591.315222, test/loss=0.295111, test/num_examples=3581, test/ssim=0.735299, total_duration=623.865564, train/loss=0.267058, train/ssim=0.744062, validation/loss=0.293622, validation/num_examples=3554, validation/ssim=0.717886
I0204 18:51:55.680077 140392884336384 logging_writer.py:48] [2400] global_step=2400, grad_norm=0.1631157249212265, loss=0.35412347316741943
I0204 18:52:17.264644 140397011515136 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.0900399386882782, loss=0.27034175395965576
I0204 18:52:41.004249 140392884336384 logging_writer.py:48] [2600] global_step=2600, grad_norm=0.1808938831090927, loss=0.27625977993011475
I0204 18:53:04.923539 140397011515136 logging_writer.py:48] [2700] global_step=2700, grad_norm=0.09014642238616943, loss=0.26259270310401917
I0204 18:53:15.720795 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:53:17.103780 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:53:18.433615 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:53:19.761250 140584300062528 submission_runner.py:408] Time since start: 708.06s, 	Step: 2747, 	{'train/ssim': 0.7456315585545131, 'train/loss': 0.26643121242523193, 'validation/ssim': 0.7203574537492966, 'validation/loss': 0.29217999854916993, 'validation/num_examples': 3554, 'test/ssim': 0.7375439875820302, 'test/loss': 0.29371975001527156, 'test/num_examples': 3581, 'score': 671.4278931617737, 'total_duration': 708.0597774982452, 'accumulated_submission_time': 671.4278931617737, 'accumulated_eval_time': 36.32929086685181, 'accumulated_logging_time': 0.20500779151916504}
I0204 18:53:19.776050 140392884336384 logging_writer.py:48] [2747] accumulated_eval_time=36.329291, accumulated_logging_time=0.205008, accumulated_submission_time=671.427893, global_step=2747, preemption_count=0, score=671.427893, test/loss=0.293720, test/num_examples=3581, test/ssim=0.737544, total_duration=708.059777, train/loss=0.266431, train/ssim=0.745632, validation/loss=0.292180, validation/num_examples=3554, validation/ssim=0.720357
I0204 18:53:30.384670 140397011515136 logging_writer.py:48] [2800] global_step=2800, grad_norm=0.26694586873054504, loss=0.3159148097038269
I0204 18:53:53.904234 140392884336384 logging_writer.py:48] [2900] global_step=2900, grad_norm=0.28707966208457947, loss=0.23585596680641174
I0204 18:54:17.559068 140397011515136 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.27451178431510925, loss=0.2685912251472473
I0204 18:54:39.832484 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:54:41.212203 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:54:42.544366 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:54:43.877589 140584300062528 submission_runner.py:408] Time since start: 792.18s, 	Step: 3093, 	{'train/ssim': 0.7441027505057198, 'train/loss': 0.26529085636138916, 'validation/ssim': 0.7181291381629854, 'validation/loss': 0.2911974939658659, 'validation/num_examples': 3554, 'test/ssim': 0.735590589875384, 'test/loss': 0.292780752855784, 'test/num_examples': 3581, 'score': 751.4628582000732, 'total_duration': 792.1761124134064, 'accumulated_submission_time': 751.4628582000732, 'accumulated_eval_time': 40.37436270713806, 'accumulated_logging_time': 0.22905254364013672}
I0204 18:54:43.892891 140392884336384 logging_writer.py:48] [3093] accumulated_eval_time=40.374363, accumulated_logging_time=0.229053, accumulated_submission_time=751.462858, global_step=3093, preemption_count=0, score=751.462858, test/loss=0.292781, test/num_examples=3581, test/ssim=0.735591, total_duration=792.176112, train/loss=0.265291, train/ssim=0.744103, validation/loss=0.291197, validation/num_examples=3554, validation/ssim=0.718129
I0204 18:54:44.500744 140397011515136 logging_writer.py:48] [3100] global_step=3100, grad_norm=0.18120338022708893, loss=0.2608293890953064
I0204 18:55:07.436462 140392884336384 logging_writer.py:48] [3200] global_step=3200, grad_norm=0.23861609399318695, loss=0.37280261516571045
I0204 18:55:31.397496 140397011515136 logging_writer.py:48] [3300] global_step=3300, grad_norm=0.20327162742614746, loss=0.306598961353302
I0204 18:55:55.240474 140392884336384 logging_writer.py:48] [3400] global_step=3400, grad_norm=0.21754564344882965, loss=0.2871827483177185
I0204 18:56:03.925125 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:56:05.304518 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:56:06.636034 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:56:07.965864 140584300062528 submission_runner.py:408] Time since start: 876.26s, 	Step: 3438, 	{'train/ssim': 0.7385843821934291, 'train/loss': 0.268498352595738, 'validation/ssim': 0.7121779871711452, 'validation/loss': 0.295027252523565, 'validation/num_examples': 3554, 'test/ssim': 0.7294369644041468, 'test/loss': 0.2967027175762706, 'test/num_examples': 3581, 'score': 831.4726746082306, 'total_duration': 876.2643911838531, 'accumulated_submission_time': 831.4726746082306, 'accumulated_eval_time': 44.415067195892334, 'accumulated_logging_time': 0.25493645668029785}
I0204 18:56:07.981365 140397011515136 logging_writer.py:48] [3438] accumulated_eval_time=44.415067, accumulated_logging_time=0.254936, accumulated_submission_time=831.472675, global_step=3438, preemption_count=0, score=831.472675, test/loss=0.296703, test/num_examples=3581, test/ssim=0.729437, total_duration=876.264391, train/loss=0.268498, train/ssim=0.738584, validation/loss=0.295027, validation/num_examples=3554, validation/ssim=0.712178
I0204 18:56:20.639729 140392884336384 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.26038211584091187, loss=0.2627716660499573
I0204 18:56:44.583597 140397011515136 logging_writer.py:48] [3600] global_step=3600, grad_norm=0.1941910833120346, loss=0.2934499680995941
I0204 18:57:08.555203 140392884336384 logging_writer.py:48] [3700] global_step=3700, grad_norm=0.27145981788635254, loss=0.28370869159698486
I0204 18:57:28.152429 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:57:29.534372 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:57:30.865006 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:57:32.199592 140584300062528 submission_runner.py:408] Time since start: 960.50s, 	Step: 3783, 	{'train/ssim': 0.7476419040134975, 'train/loss': 0.2647112948553903, 'validation/ssim': 0.7219686170072454, 'validation/loss': 0.2910621999419668, 'validation/num_examples': 3554, 'test/ssim': 0.7389904236334125, 'test/loss': 0.29267153384398564, 'test/num_examples': 3581, 'score': 911.6228678226471, 'total_duration': 960.4981019496918, 'accumulated_submission_time': 911.6228678226471, 'accumulated_eval_time': 48.46218538284302, 'accumulated_logging_time': 0.2796492576599121}
I0204 18:57:32.215110 140397011515136 logging_writer.py:48] [3783] accumulated_eval_time=48.462185, accumulated_logging_time=0.279649, accumulated_submission_time=911.622868, global_step=3783, preemption_count=0, score=911.622868, test/loss=0.292672, test/num_examples=3581, test/ssim=0.738990, total_duration=960.498102, train/loss=0.264711, train/ssim=0.747642, validation/loss=0.291062, validation/num_examples=3554, validation/ssim=0.721969
I0204 18:57:34.161567 140392884336384 logging_writer.py:48] [3800] global_step=3800, grad_norm=0.22651121020317078, loss=0.2744653522968292
I0204 18:57:58.070344 140397011515136 logging_writer.py:48] [3900] global_step=3900, grad_norm=0.07120604813098907, loss=0.2671199440956116
I0204 18:58:21.994060 140392884336384 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.17651039361953735, loss=0.2989771068096161
I0204 18:58:45.611723 140397011515136 logging_writer.py:48] [4100] global_step=4100, grad_norm=0.07163335382938385, loss=0.26921743154525757
I0204 18:58:52.213430 140584300062528 spec.py:321] Evaluating on the training split.
I0204 18:58:53.596412 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 18:58:54.928313 140584300062528 spec.py:349] Evaluating on the test split.
I0204 18:58:56.260740 140584300062528 submission_runner.py:408] Time since start: 1044.56s, 	Step: 4130, 	{'train/ssim': 0.744476454598563, 'train/loss': 0.2648463419505528, 'validation/ssim': 0.7180813954127392, 'validation/loss': 0.29101665541907007, 'validation/num_examples': 3554, 'test/ssim': 0.7354596225085521, 'test/loss': 0.29265022863725215, 'test/num_examples': 3581, 'score': 991.5995440483093, 'total_duration': 1044.5592665672302, 'accumulated_submission_time': 991.5995440483093, 'accumulated_eval_time': 52.50946092605591, 'accumulated_logging_time': 0.30477356910705566}
I0204 18:58:56.276579 140392884336384 logging_writer.py:48] [4130] accumulated_eval_time=52.509461, accumulated_logging_time=0.304774, accumulated_submission_time=991.599544, global_step=4130, preemption_count=0, score=991.599544, test/loss=0.292650, test/num_examples=3581, test/ssim=0.735460, total_duration=1044.559267, train/loss=0.264846, train/ssim=0.744476, validation/loss=0.291017, validation/num_examples=3554, validation/ssim=0.718081
I0204 18:59:11.267355 140397011515136 logging_writer.py:48] [4200] global_step=4200, grad_norm=0.1662791222333908, loss=0.24641674757003784
I0204 18:59:34.969009 140392884336384 logging_writer.py:48] [4300] global_step=4300, grad_norm=0.42646825313568115, loss=0.2940996289253235
I0204 18:59:59.304227 140397011515136 logging_writer.py:48] [4400] global_step=4400, grad_norm=0.11373772472143173, loss=0.2947784960269928
I0204 19:00:16.356950 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:00:17.742175 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:00:19.073058 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:00:20.403152 140584300062528 submission_runner.py:408] Time since start: 1128.70s, 	Step: 4472, 	{'train/ssim': 0.7401151657104492, 'train/loss': 0.26571357250213623, 'validation/ssim': 0.7127527549284257, 'validation/loss': 0.29230749573543896, 'validation/num_examples': 3554, 'test/ssim': 0.7306974145228288, 'test/loss': 0.2937538042577143, 'test/num_examples': 3581, 'score': 1071.6571695804596, 'total_duration': 1128.7016820907593, 'accumulated_submission_time': 1071.6571695804596, 'accumulated_eval_time': 56.5556275844574, 'accumulated_logging_time': 0.33159756660461426}
I0204 19:00:20.419155 140392884336384 logging_writer.py:48] [4472] accumulated_eval_time=56.555628, accumulated_logging_time=0.331598, accumulated_submission_time=1071.657170, global_step=4472, preemption_count=0, score=1071.657170, test/loss=0.293754, test/num_examples=3581, test/ssim=0.730697, total_duration=1128.701682, train/loss=0.265714, train/ssim=0.740115, validation/loss=0.292307, validation/num_examples=3554, validation/ssim=0.712753
I0204 19:00:24.962241 140397011515136 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.07409469038248062, loss=0.20256023108959198
I0204 19:00:48.769503 140392884336384 logging_writer.py:48] [4600] global_step=4600, grad_norm=0.1649411916732788, loss=0.2080526202917099
I0204 19:01:12.530765 140397011515136 logging_writer.py:48] [4700] global_step=4700, grad_norm=0.10614151507616043, loss=0.22216752171516418
I0204 19:01:36.263800 140392884336384 logging_writer.py:48] [4800] global_step=4800, grad_norm=0.1566946655511856, loss=0.31604570150375366
I0204 19:01:40.411709 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:01:41.791581 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:01:43.123835 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:01:44.458578 140584300062528 submission_runner.py:408] Time since start: 1212.76s, 	Step: 4819, 	{'train/ssim': 0.7446002279009137, 'train/loss': 0.26479571206229074, 'validation/ssim': 0.7191272020742473, 'validation/loss': 0.290804663869056, 'validation/num_examples': 3554, 'test/ssim': 0.7363732579499441, 'test/loss': 0.29227501838042796, 'test/num_examples': 3581, 'score': 1151.6270997524261, 'total_duration': 1212.7570588588715, 'accumulated_submission_time': 1151.6270997524261, 'accumulated_eval_time': 60.60241341590881, 'accumulated_logging_time': 0.3582265377044678}
I0204 19:01:44.478267 140397011515136 logging_writer.py:48] [4819] accumulated_eval_time=60.602413, accumulated_logging_time=0.358227, accumulated_submission_time=1151.627100, global_step=4819, preemption_count=0, score=1151.627100, test/loss=0.292275, test/num_examples=3581, test/ssim=0.736373, total_duration=1212.757059, train/loss=0.264796, train/ssim=0.744600, validation/loss=0.290805, validation/num_examples=3554, validation/ssim=0.719127
I0204 19:02:01.927927 140392884336384 logging_writer.py:48] [4900] global_step=4900, grad_norm=0.1350192427635193, loss=0.2901531159877777
I0204 19:02:25.983921 140397011515136 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.15238025784492493, loss=0.3706262409687042
I0204 19:02:49.881435 140392884336384 logging_writer.py:48] [5100] global_step=5100, grad_norm=0.09732206165790558, loss=0.33068639039993286
I0204 19:03:04.478699 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:03:05.858689 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:03:07.190394 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:03:08.519847 140584300062528 submission_runner.py:408] Time since start: 1296.82s, 	Step: 5162, 	{'train/ssim': 0.7490038871765137, 'train/loss': 0.26482670647757395, 'validation/ssim': 0.7233019105893008, 'validation/loss': 0.2915698187231816, 'validation/num_examples': 3554, 'test/ssim': 0.7402641682010961, 'test/loss': 0.2931434867835451, 'test/num_examples': 3581, 'score': 1231.6058168411255, 'total_duration': 1296.8183772563934, 'accumulated_submission_time': 1231.6058168411255, 'accumulated_eval_time': 64.64353156089783, 'accumulated_logging_time': 0.3878440856933594}
I0204 19:03:08.535272 140397011515136 logging_writer.py:48] [5162] accumulated_eval_time=64.643532, accumulated_logging_time=0.387844, accumulated_submission_time=1231.605817, global_step=5162, preemption_count=0, score=1231.605817, test/loss=0.293143, test/num_examples=3581, test/ssim=0.740264, total_duration=1296.818377, train/loss=0.264827, train/ssim=0.749004, validation/loss=0.291570, validation/num_examples=3554, validation/ssim=0.723302
I0204 19:03:15.458133 140392884336384 logging_writer.py:48] [5200] global_step=5200, grad_norm=0.1920478194952011, loss=0.24084489047527313
I0204 19:03:39.708304 140397011515136 logging_writer.py:48] [5300] global_step=5300, grad_norm=0.3318624496459961, loss=0.22375664114952087
I0204 19:04:03.565426 140392884336384 logging_writer.py:48] [5400] global_step=5400, grad_norm=0.0919574722647667, loss=0.3321225345134735
I0204 19:04:27.697610 140397011515136 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.1861904263496399, loss=0.2824385166168213
I0204 19:04:28.600388 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:04:29.984582 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:04:31.314270 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:04:32.644368 140584300062528 submission_runner.py:408] Time since start: 1380.94s, 	Step: 5505, 	{'train/ssim': 0.7461484500340053, 'train/loss': 0.26515943663460867, 'validation/ssim': 0.7193948362540448, 'validation/loss': 0.29200328167865436, 'validation/num_examples': 3554, 'test/ssim': 0.7366458964194709, 'test/loss': 0.29348917654591944, 'test/num_examples': 3581, 'score': 1311.6497621536255, 'total_duration': 1380.9428961277008, 'accumulated_submission_time': 1311.6497621536255, 'accumulated_eval_time': 68.6874794960022, 'accumulated_logging_time': 0.4124460220336914}
I0204 19:04:32.660649 140392884336384 logging_writer.py:48] [5505] accumulated_eval_time=68.687479, accumulated_logging_time=0.412446, accumulated_submission_time=1311.649762, global_step=5505, preemption_count=0, score=1311.649762, test/loss=0.293489, test/num_examples=3581, test/ssim=0.736646, total_duration=1380.942896, train/loss=0.265159, train/ssim=0.746148, validation/loss=0.292003, validation/num_examples=3554, validation/ssim=0.719395
I0204 19:04:53.389791 140397011515136 logging_writer.py:48] [5600] global_step=5600, grad_norm=0.20270714163780212, loss=0.2575061321258545
I0204 19:05:17.356884 140392884336384 logging_writer.py:48] [5700] global_step=5700, grad_norm=0.15770196914672852, loss=0.2987287938594818
I0204 19:05:41.103036 140397011515136 logging_writer.py:48] [5800] global_step=5800, grad_norm=0.27156975865364075, loss=0.2981055676937103
I0204 19:05:52.840854 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:05:54.220549 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:05:55.553546 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:05:56.886662 140584300062528 submission_runner.py:408] Time since start: 1465.19s, 	Step: 5851, 	{'train/ssim': 0.7486353601728167, 'train/loss': 0.264972414289202, 'validation/ssim': 0.72320086082583, 'validation/loss': 0.2916949459455895, 'validation/num_examples': 3554, 'test/ssim': 0.7399766672193522, 'test/loss': 0.2933677880000349, 'test/num_examples': 3581, 'score': 1391.8070256710052, 'total_duration': 1465.185186624527, 'accumulated_submission_time': 1391.8070256710052, 'accumulated_eval_time': 72.73325824737549, 'accumulated_logging_time': 0.4397716522216797}
I0204 19:05:56.903199 140392884336384 logging_writer.py:48] [5851] accumulated_eval_time=72.733258, accumulated_logging_time=0.439772, accumulated_submission_time=1391.807026, global_step=5851, preemption_count=0, score=1391.807026, test/loss=0.293368, test/num_examples=3581, test/ssim=0.739977, total_duration=1465.185187, train/loss=0.264972, train/ssim=0.748635, validation/loss=0.291695, validation/num_examples=3554, validation/ssim=0.723201
I0204 19:06:06.791755 140397011515136 logging_writer.py:48] [5900] global_step=5900, grad_norm=0.21833202242851257, loss=0.30325639247894287
I0204 19:06:30.564370 140392884336384 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.23338641226291656, loss=0.21389223635196686
I0204 19:06:54.217063 140397011515136 logging_writer.py:48] [6100] global_step=6100, grad_norm=0.19286005198955536, loss=0.32426032423973083
I0204 19:07:17.075763 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:07:18.456983 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:07:19.788171 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:07:21.117025 140584300062528 submission_runner.py:408] Time since start: 1549.42s, 	Step: 6197, 	{'train/ssim': 0.7402887344360352, 'train/loss': 0.26532416684286936, 'validation/ssim': 0.7139138311365715, 'validation/loss': 0.2915773751296954, 'validation/num_examples': 3554, 'test/ssim': 0.7316704318364283, 'test/loss': 0.29291339055082377, 'test/num_examples': 3581, 'score': 1471.9566292762756, 'total_duration': 1549.4155497550964, 'accumulated_submission_time': 1471.9566292762756, 'accumulated_eval_time': 76.77447819709778, 'accumulated_logging_time': 0.467041015625}
I0204 19:07:21.133450 140392884336384 logging_writer.py:48] [6197] accumulated_eval_time=76.774478, accumulated_logging_time=0.467041, accumulated_submission_time=1471.956629, global_step=6197, preemption_count=0, score=1471.956629, test/loss=0.292913, test/num_examples=3581, test/ssim=0.731670, total_duration=1549.415550, train/loss=0.265324, train/ssim=0.740289, validation/loss=0.291577, validation/num_examples=3554, validation/ssim=0.713914
I0204 19:07:21.448974 140397011515136 logging_writer.py:48] [6200] global_step=6200, grad_norm=0.09763719141483307, loss=0.29494673013687134
I0204 19:07:43.805746 140392884336384 logging_writer.py:48] [6300] global_step=6300, grad_norm=0.1195792555809021, loss=0.24024949967861176
I0204 19:08:08.155603 140397011515136 logging_writer.py:48] [6400] global_step=6400, grad_norm=0.24177421629428864, loss=0.23509317636489868
I0204 19:08:31.900719 140392884336384 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.1371438056230545, loss=0.2595289349555969
I0204 19:08:41.148755 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:08:42.531130 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:08:43.861111 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:08:45.193103 140584300062528 submission_runner.py:408] Time since start: 1633.49s, 	Step: 6540, 	{'train/ssim': 0.7448414393833706, 'train/loss': 0.2647097281047276, 'validation/ssim': 0.7187118744944077, 'validation/loss': 0.29138722846396664, 'validation/num_examples': 3554, 'test/ssim': 0.7359811057927255, 'test/loss': 0.2928044101573408, 'test/num_examples': 3581, 'score': 1551.9505987167358, 'total_duration': 1633.491622209549, 'accumulated_submission_time': 1551.9505987167358, 'accumulated_eval_time': 80.81879162788391, 'accumulated_logging_time': 0.4929647445678711}
I0204 19:08:45.210421 140397011515136 logging_writer.py:48] [6540] accumulated_eval_time=80.818792, accumulated_logging_time=0.492965, accumulated_submission_time=1551.950599, global_step=6540, preemption_count=0, score=1551.950599, test/loss=0.292804, test/num_examples=3581, test/ssim=0.735981, total_duration=1633.491622, train/loss=0.264710, train/ssim=0.744841, validation/loss=0.291387, validation/num_examples=3554, validation/ssim=0.718712
I0204 19:08:57.473044 140392884336384 logging_writer.py:48] [6600] global_step=6600, grad_norm=0.19922886788845062, loss=0.30281442403793335
I0204 19:09:21.241790 140397011515136 logging_writer.py:48] [6700] global_step=6700, grad_norm=0.16811731457710266, loss=0.29247719049453735
I0204 19:09:45.167519 140392884336384 logging_writer.py:48] [6800] global_step=6800, grad_norm=0.12133973091840744, loss=0.3097086250782013
I0204 19:10:05.303230 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:10:06.682554 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:10:08.017418 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:10:09.349322 140584300062528 submission_runner.py:408] Time since start: 1717.65s, 	Step: 6885, 	{'train/ssim': 0.7436417170933315, 'train/loss': 0.2659179653440203, 'validation/ssim': 0.716956727345069, 'validation/loss': 0.2928763901040201, 'validation/num_examples': 3554, 'test/ssim': 0.7342648946916015, 'test/loss': 0.2944325029234153, 'test/num_examples': 3581, 'score': 1632.0223336219788, 'total_duration': 1717.647849559784, 'accumulated_submission_time': 1632.0223336219788, 'accumulated_eval_time': 84.86484432220459, 'accumulated_logging_time': 0.5194802284240723}
I0204 19:10:09.365486 140397011515136 logging_writer.py:48] [6885] accumulated_eval_time=84.864844, accumulated_logging_time=0.519480, accumulated_submission_time=1632.022334, global_step=6885, preemption_count=0, score=1632.022334, test/loss=0.294433, test/num_examples=3581, test/ssim=0.734265, total_duration=1717.647850, train/loss=0.265918, train/ssim=0.743642, validation/loss=0.292876, validation/num_examples=3554, validation/ssim=0.716957
I0204 19:10:10.864092 140392884336384 logging_writer.py:48] [6900] global_step=6900, grad_norm=0.13469621539115906, loss=0.3535551428794861
I0204 19:10:34.789295 140397011515136 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.38056445121765137, loss=0.24839171767234802
I0204 19:10:58.844446 140392884336384 logging_writer.py:48] [7100] global_step=7100, grad_norm=0.13453510403633118, loss=0.24820581078529358
I0204 19:11:22.610855 140397011515136 logging_writer.py:48] [7200] global_step=7200, grad_norm=0.19370464980602264, loss=0.2772764265537262
I0204 19:11:29.456366 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:11:30.837154 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:11:32.167292 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:11:33.500575 140584300062528 submission_runner.py:408] Time since start: 1801.80s, 	Step: 7230, 	{'train/ssim': 0.7429020064217704, 'train/loss': 0.2644589628492083, 'validation/ssim': 0.7165945693892445, 'validation/loss': 0.2905732660932224, 'validation/num_examples': 3554, 'test/ssim': 0.7341480398937098, 'test/loss': 0.2919725526214744, 'test/num_examples': 3581, 'score': 1712.0917258262634, 'total_duration': 1801.7990944385529, 'accumulated_submission_time': 1712.0917258262634, 'accumulated_eval_time': 88.90904879570007, 'accumulated_logging_time': 0.5449492931365967}
I0204 19:11:33.518158 140392884336384 logging_writer.py:48] [7230] accumulated_eval_time=88.909049, accumulated_logging_time=0.544949, accumulated_submission_time=1712.091726, global_step=7230, preemption_count=0, score=1712.091726, test/loss=0.291973, test/num_examples=3581, test/ssim=0.734148, total_duration=1801.799094, train/loss=0.264459, train/ssim=0.742902, validation/loss=0.290573, validation/num_examples=3554, validation/ssim=0.716595
I0204 19:11:48.233658 140397011515136 logging_writer.py:48] [7300] global_step=7300, grad_norm=0.0966375395655632, loss=0.2797114849090576
I0204 19:12:12.346209 140392884336384 logging_writer.py:48] [7400] global_step=7400, grad_norm=0.2445840835571289, loss=0.26218047738075256
I0204 19:12:36.530360 140397011515136 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.22025445103645325, loss=0.2072455734014511
I0204 19:12:53.583872 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:12:54.964593 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:12:56.296194 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:12:57.628990 140584300062528 submission_runner.py:408] Time since start: 1885.93s, 	Step: 7573, 	{'train/ssim': 0.7418189729963031, 'train/loss': 0.26454414640154156, 'validation/ssim': 0.7159344142383582, 'validation/loss': 0.29055258901721653, 'validation/num_examples': 3554, 'test/ssim': 0.7334203222083566, 'test/loss': 0.2919843130955913, 'test/num_examples': 3581, 'score': 1792.1360602378845, 'total_duration': 1885.9275164604187, 'accumulated_submission_time': 1792.1360602378845, 'accumulated_eval_time': 92.9541277885437, 'accumulated_logging_time': 0.572021484375}
I0204 19:12:57.645624 140392884336384 logging_writer.py:48] [7573] accumulated_eval_time=92.954128, accumulated_logging_time=0.572021, accumulated_submission_time=1792.136060, global_step=7573, preemption_count=0, score=1792.136060, test/loss=0.291984, test/num_examples=3581, test/ssim=0.733420, total_duration=1885.927516, train/loss=0.264544, train/ssim=0.741819, validation/loss=0.290553, validation/num_examples=3554, validation/ssim=0.715934
I0204 19:13:02.262983 140397011515136 logging_writer.py:48] [7600] global_step=7600, grad_norm=0.3042578399181366, loss=0.26711294054985046
I0204 19:13:26.009158 140392884336384 logging_writer.py:48] [7700] global_step=7700, grad_norm=0.33780384063720703, loss=0.2713746428489685
I0204 19:13:49.961024 140397011515136 logging_writer.py:48] [7800] global_step=7800, grad_norm=0.12768355011940002, loss=0.2823058068752289
I0204 19:14:13.744425 140392884336384 logging_writer.py:48] [7900] global_step=7900, grad_norm=0.16332684457302094, loss=0.26868709921836853
I0204 19:14:17.770410 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:14:19.153246 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:14:20.484151 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:14:21.815001 140584300062528 submission_runner.py:408] Time since start: 1970.11s, 	Step: 7918, 	{'train/ssim': 0.7490203039986747, 'train/loss': 0.2643026624407087, 'validation/ssim': 0.723283088267621, 'validation/loss': 0.290826577447946, 'validation/num_examples': 3554, 'test/ssim': 0.7403620698870776, 'test/loss': 0.2923499104431374, 'test/num_examples': 3581, 'score': 1872.2391254901886, 'total_duration': 1970.113526582718, 'accumulated_submission_time': 1872.2391254901886, 'accumulated_eval_time': 96.99868774414062, 'accumulated_logging_time': 0.5981225967407227}
I0204 19:14:21.831502 140397011515136 logging_writer.py:48] [7918] accumulated_eval_time=96.998688, accumulated_logging_time=0.598123, accumulated_submission_time=1872.239125, global_step=7918, preemption_count=0, score=1872.239125, test/loss=0.292350, test/num_examples=3581, test/ssim=0.740362, total_duration=1970.113527, train/loss=0.264303, train/ssim=0.749020, validation/loss=0.290827, validation/num_examples=3554, validation/ssim=0.723283
I0204 19:14:39.307729 140392884336384 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.13018083572387695, loss=0.3024964928627014
I0204 19:15:03.000967 140397011515136 logging_writer.py:48] [8100] global_step=8100, grad_norm=0.23168693482875824, loss=0.22293303906917572
I0204 19:15:26.859730 140392884336384 logging_writer.py:48] [8200] global_step=8200, grad_norm=0.16008642315864563, loss=0.27666565775871277
I0204 19:15:41.941744 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:15:43.325001 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:15:44.653960 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:15:45.986258 140584300062528 submission_runner.py:408] Time since start: 2054.28s, 	Step: 8265, 	{'train/ssim': 0.7482437406267438, 'train/loss': 0.26421332359313965, 'validation/ssim': 0.7220145736977701, 'validation/loss': 0.2909175291045301, 'validation/num_examples': 3554, 'test/ssim': 0.7392333370785046, 'test/loss': 0.29234858099823724, 'test/num_examples': 3581, 'score': 1952.3275845050812, 'total_duration': 2054.2847859859467, 'accumulated_submission_time': 1952.3275845050812, 'accumulated_eval_time': 101.04316473007202, 'accumulated_logging_time': 0.6242008209228516}
I0204 19:15:46.003086 140397011515136 logging_writer.py:48] [8265] accumulated_eval_time=101.043165, accumulated_logging_time=0.624201, accumulated_submission_time=1952.327585, global_step=8265, preemption_count=0, score=1952.327585, test/loss=0.292349, test/num_examples=3581, test/ssim=0.739233, total_duration=2054.284786, train/loss=0.264213, train/ssim=0.748244, validation/loss=0.290918, validation/num_examples=3554, validation/ssim=0.722015
I0204 19:15:52.243937 140392884336384 logging_writer.py:48] [8300] global_step=8300, grad_norm=0.20775827765464783, loss=0.2517766058444977
I0204 19:16:16.388448 140397011515136 logging_writer.py:48] [8400] global_step=8400, grad_norm=0.19357554614543915, loss=0.27097830176353455
I0204 19:16:40.455517 140392884336384 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.16942918300628662, loss=0.3550471067428589
I0204 19:17:04.916254 140397011515136 logging_writer.py:48] [8600] global_step=8600, grad_norm=0.09712766855955124, loss=0.34925317764282227
I0204 19:17:06.215469 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:17:07.596680 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:17:08.928609 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:17:10.256733 140584300062528 submission_runner.py:408] Time since start: 2138.56s, 	Step: 8607, 	{'train/ssim': 0.7464250155857631, 'train/loss': 0.26386570930480957, 'validation/ssim': 0.7195118918604038, 'validation/loss': 0.2906534326968732, 'validation/num_examples': 3554, 'test/ssim': 0.7369421921905543, 'test/loss': 0.2919754501295902, 'test/num_examples': 3581, 'score': 2032.5190379619598, 'total_duration': 2138.555235147476, 'accumulated_submission_time': 2032.5190379619598, 'accumulated_eval_time': 105.08436179161072, 'accumulated_logging_time': 0.6500787734985352}
I0204 19:17:10.276098 140392884336384 logging_writer.py:48] [8607] accumulated_eval_time=105.084362, accumulated_logging_time=0.650079, accumulated_submission_time=2032.519038, global_step=8607, preemption_count=0, score=2032.519038, test/loss=0.291975, test/num_examples=3581, test/ssim=0.736942, total_duration=2138.555235, train/loss=0.263866, train/ssim=0.746425, validation/loss=0.290653, validation/num_examples=3554, validation/ssim=0.719512
I0204 19:17:30.429992 140397011515136 logging_writer.py:48] [8700] global_step=8700, grad_norm=0.26023486256599426, loss=0.20907840132713318
I0204 19:17:54.577774 140392884336384 logging_writer.py:48] [8800] global_step=8800, grad_norm=0.18512581288814545, loss=0.20743677020072937
I0204 19:18:18.529491 140397011515136 logging_writer.py:48] [8900] global_step=8900, grad_norm=0.14496172964572906, loss=0.23596428334712982
I0204 19:18:30.349768 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:18:31.731990 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:18:33.064426 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:18:34.395941 140584300062528 submission_runner.py:408] Time since start: 2222.69s, 	Step: 8951, 	{'train/ssim': 0.7454898016793388, 'train/loss': 0.2632397242954799, 'validation/ssim': 0.7187876446433596, 'validation/loss': 0.2896331804283026, 'validation/num_examples': 3554, 'test/ssim': 0.736424458622766, 'test/loss': 0.29104221389800333, 'test/num_examples': 3581, 'score': 2112.5709660053253, 'total_duration': 2222.6944692134857, 'accumulated_submission_time': 2112.5709660053253, 'accumulated_eval_time': 109.13049507141113, 'accumulated_logging_time': 0.6793222427368164}
I0204 19:18:34.412361 140392884336384 logging_writer.py:48] [8951] accumulated_eval_time=109.130495, accumulated_logging_time=0.679322, accumulated_submission_time=2112.570966, global_step=8951, preemption_count=0, score=2112.570966, test/loss=0.291042, test/num_examples=3581, test/ssim=0.736424, total_duration=2222.694469, train/loss=0.263240, train/ssim=0.745490, validation/loss=0.289633, validation/num_examples=3554, validation/ssim=0.718788
I0204 19:18:44.009080 140397011515136 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.15062564611434937, loss=0.2009885162115097
I0204 19:19:08.100122 140392884336384 logging_writer.py:48] [9100] global_step=9100, grad_norm=0.19077952206134796, loss=0.30668357014656067
I0204 19:19:32.125033 140397011515136 logging_writer.py:48] [9200] global_step=9200, grad_norm=0.2737041115760803, loss=0.21293483674526215
I0204 19:19:54.432141 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:19:55.814833 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:19:57.144749 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:19:58.478580 140584300062528 submission_runner.py:408] Time since start: 2306.78s, 	Step: 9293, 	{'train/ssim': 0.7439816338675362, 'train/loss': 0.2630248410361154, 'validation/ssim': 0.7169932728747538, 'validation/loss': 0.289561634997538, 'validation/num_examples': 3554, 'test/ssim': 0.7345339197980661, 'test/loss': 0.2910244879660011, 'test/num_examples': 3581, 'score': 2192.5693085193634, 'total_duration': 2306.7771003246307, 'accumulated_submission_time': 2192.5693085193634, 'accumulated_eval_time': 113.17689657211304, 'accumulated_logging_time': 0.7051200866699219}
I0204 19:19:58.495328 140392884336384 logging_writer.py:48] [9293] accumulated_eval_time=113.176897, accumulated_logging_time=0.705120, accumulated_submission_time=2192.569309, global_step=9293, preemption_count=0, score=2192.569309, test/loss=0.291024, test/num_examples=3581, test/ssim=0.734534, total_duration=2306.777100, train/loss=0.263025, train/ssim=0.743982, validation/loss=0.289562, validation/num_examples=3554, validation/ssim=0.716993
I0204 19:19:59.100689 140397011515136 logging_writer.py:48] [9300] global_step=9300, grad_norm=0.13952691853046417, loss=0.3203144371509552
I0204 19:20:22.120320 140392884336384 logging_writer.py:48] [9400] global_step=9400, grad_norm=0.22150994837284088, loss=0.23315821588039398
I0204 19:20:45.973069 140397011515136 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.24534127116203308, loss=0.27206093072891235
I0204 19:21:09.947444 140392884336384 logging_writer.py:48] [9600] global_step=9600, grad_norm=0.2646944522857666, loss=0.2741169035434723
I0204 19:21:18.624552 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:21:20.007074 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:21:21.337946 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:21:22.666768 140584300062528 submission_runner.py:408] Time since start: 2390.97s, 	Step: 9636, 	{'train/ssim': 0.7478782790047782, 'train/loss': 0.2636504684175764, 'validation/ssim': 0.7215138587243247, 'validation/loss': 0.2900727915508934, 'validation/num_examples': 3554, 'test/ssim': 0.7388857042812762, 'test/loss': 0.2914541713754014, 'test/num_examples': 3581, 'score': 2272.6771895885468, 'total_duration': 2390.9652981758118, 'accumulated_submission_time': 2272.6771895885468, 'accumulated_eval_time': 117.2190728187561, 'accumulated_logging_time': 0.7311830520629883}
I0204 19:21:22.683434 140397011515136 logging_writer.py:48] [9636] accumulated_eval_time=117.219073, accumulated_logging_time=0.731183, accumulated_submission_time=2272.677190, global_step=9636, preemption_count=0, score=2272.677190, test/loss=0.291454, test/num_examples=3581, test/ssim=0.738886, total_duration=2390.965298, train/loss=0.263650, train/ssim=0.747878, validation/loss=0.290073, validation/num_examples=3554, validation/ssim=0.721514
I0204 19:21:35.818696 140392884336384 logging_writer.py:48] [9700] global_step=9700, grad_norm=0.1794583946466446, loss=0.2503249943256378
I0204 19:21:59.786571 140397011515136 logging_writer.py:48] [9800] global_step=9800, grad_norm=0.1710643172264099, loss=0.2641201913356781
I0204 19:22:23.925328 140392884336384 logging_writer.py:48] [9900] global_step=9900, grad_norm=0.2992926239967346, loss=0.2573479413986206
I0204 19:22:42.760063 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:22:44.143729 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:22:45.475211 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:22:46.806094 140584300062528 submission_runner.py:408] Time since start: 2475.10s, 	Step: 9980, 	{'train/ssim': 0.7397242954799107, 'train/loss': 0.26466682979038786, 'validation/ssim': 0.7141337225661227, 'validation/loss': 0.29100975161130066, 'validation/num_examples': 3554, 'test/ssim': 0.7312535997277296, 'test/loss': 0.2924467894791958, 'test/num_examples': 3581, 'score': 2352.732777118683, 'total_duration': 2475.1045954227448, 'accumulated_submission_time': 2352.732777118683, 'accumulated_eval_time': 121.26503705978394, 'accumulated_logging_time': 0.7569248676300049}
I0204 19:22:46.826758 140397011515136 logging_writer.py:48] [9980] accumulated_eval_time=121.265037, accumulated_logging_time=0.756925, accumulated_submission_time=2352.732777, global_step=9980, preemption_count=0, score=2352.732777, test/loss=0.292447, test/num_examples=3581, test/ssim=0.731254, total_duration=2475.104595, train/loss=0.264667, train/ssim=0.739724, validation/loss=0.291010, validation/num_examples=3554, validation/ssim=0.714134
I0204 19:22:49.521047 140392884336384 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.18900106847286224, loss=0.25272896885871887
I0204 19:23:13.553046 140397011515136 logging_writer.py:48] [10100] global_step=10100, grad_norm=0.07370398938655853, loss=0.2883695960044861
I0204 19:23:37.321871 140392884336384 logging_writer.py:48] [10200] global_step=10200, grad_norm=0.23822350800037384, loss=0.3553507626056671
I0204 19:24:01.211862 140397011515136 logging_writer.py:48] [10300] global_step=10300, grad_norm=0.14448417723178864, loss=0.24834761023521423
I0204 19:24:06.864954 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:24:08.246630 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:24:09.577383 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:24:10.906689 140584300062528 submission_runner.py:408] Time since start: 2559.21s, 	Step: 10325, 	{'train/ssim': 0.749014036996024, 'train/loss': 0.2629481383732387, 'validation/ssim': 0.7227236394071821, 'validation/loss': 0.2893752321877638, 'validation/num_examples': 3554, 'test/ssim': 0.7399639181836428, 'test/loss': 0.2908956340756772, 'test/num_examples': 3581, 'score': 2432.74764752388, 'total_duration': 2559.2052206993103, 'accumulated_submission_time': 2432.74764752388, 'accumulated_eval_time': 125.30674004554749, 'accumulated_logging_time': 0.7888193130493164}
I0204 19:24:10.924638 140392884336384 logging_writer.py:48] [10325] accumulated_eval_time=125.306740, accumulated_logging_time=0.788819, accumulated_submission_time=2432.747648, global_step=10325, preemption_count=0, score=2432.747648, test/loss=0.290896, test/num_examples=3581, test/ssim=0.739964, total_duration=2559.205221, train/loss=0.262948, train/ssim=0.749014, validation/loss=0.289375, validation/num_examples=3554, validation/ssim=0.722724
I0204 19:24:26.819839 140397011515136 logging_writer.py:48] [10400] global_step=10400, grad_norm=0.08347886800765991, loss=0.3106328845024109
I0204 19:24:50.945467 140392884336384 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.0603707879781723, loss=0.21706919372081757
I0204 19:25:14.853689 140397011515136 logging_writer.py:48] [10600] global_step=10600, grad_norm=0.3021710515022278, loss=0.26000261306762695
I0204 19:25:31.022605 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:25:32.404818 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:25:33.736639 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:25:35.071504 140584300062528 submission_runner.py:408] Time since start: 2643.37s, 	Step: 10669, 	{'train/ssim': 0.7450334003993443, 'train/loss': 0.2640965155192784, 'validation/ssim': 0.7185316885463562, 'validation/loss': 0.290682490514649, 'validation/num_examples': 3554, 'test/ssim': 0.7358866811164828, 'test/loss': 0.29215894761414407, 'test/num_examples': 3581, 'score': 2512.8242738246918, 'total_duration': 2643.370032787323, 'accumulated_submission_time': 2512.8242738246918, 'accumulated_eval_time': 129.35560011863708, 'accumulated_logging_time': 0.816091775894165}
I0204 19:25:35.090077 140392884336384 logging_writer.py:48] [10669] accumulated_eval_time=129.355600, accumulated_logging_time=0.816092, accumulated_submission_time=2512.824274, global_step=10669, preemption_count=0, score=2512.824274, test/loss=0.292159, test/num_examples=3581, test/ssim=0.735887, total_duration=2643.370033, train/loss=0.264097, train/ssim=0.745033, validation/loss=0.290682, validation/num_examples=3554, validation/ssim=0.718532
I0204 19:25:40.360977 140397011515136 logging_writer.py:48] [10700] global_step=10700, grad_norm=0.24106432497501373, loss=0.3231838345527649
I0204 19:26:04.662646 140392884336384 logging_writer.py:48] [10800] global_step=10800, grad_norm=0.12217337638139725, loss=0.1985146552324295
I0204 19:26:28.354986 140397011515136 logging_writer.py:48] [10900] global_step=10900, grad_norm=0.1834869235754013, loss=0.2587853968143463
I0204 19:26:52.126106 140392884336384 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.150232195854187, loss=0.33658039569854736
I0204 19:26:55.200087 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:26:56.583044 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:26:57.913944 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:26:59.243100 140584300062528 submission_runner.py:408] Time since start: 2727.54s, 	Step: 11014, 	{'train/ssim': 0.7504299027579171, 'train/loss': 0.26199814251491, 'validation/ssim': 0.7241798963315982, 'validation/loss': 0.2886156072493142, 'validation/num_examples': 3554, 'test/ssim': 0.7411439880183608, 'test/loss': 0.29017442726150167, 'test/num_examples': 3581, 'score': 2592.9127190113068, 'total_duration': 2727.5416226387024, 'accumulated_submission_time': 2592.9127190113068, 'accumulated_eval_time': 133.3985664844513, 'accumulated_logging_time': 0.8439867496490479}
I0204 19:26:59.260333 140397011515136 logging_writer.py:48] [11014] accumulated_eval_time=133.398566, accumulated_logging_time=0.843987, accumulated_submission_time=2592.912719, global_step=11014, preemption_count=0, score=2592.912719, test/loss=0.290174, test/num_examples=3581, test/ssim=0.741144, total_duration=2727.541623, train/loss=0.261998, train/ssim=0.750430, validation/loss=0.288616, validation/num_examples=3554, validation/ssim=0.724180
I0204 19:27:17.858586 140392884336384 logging_writer.py:48] [11100] global_step=11100, grad_norm=0.13380193710327148, loss=0.2542272210121155
I0204 19:27:41.707077 140397011515136 logging_writer.py:48] [11200] global_step=11200, grad_norm=0.09114306420087814, loss=0.24890950322151184
I0204 19:28:05.556726 140392884336384 logging_writer.py:48] [11300] global_step=11300, grad_norm=0.14448067545890808, loss=0.30363932251930237
I0204 19:28:19.339264 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:28:20.721684 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:28:22.054825 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:28:23.383895 140584300062528 submission_runner.py:408] Time since start: 2811.68s, 	Step: 11358, 	{'train/ssim': 0.7455850328717913, 'train/loss': 0.26415468965257916, 'validation/ssim': 0.7196553261949564, 'validation/loss': 0.29023429256647437, 'validation/num_examples': 3554, 'test/ssim': 0.7365518126265359, 'test/loss': 0.29191749996727523, 'test/num_examples': 3581, 'score': 2672.970718383789, 'total_duration': 2811.682421684265, 'accumulated_submission_time': 2672.970718383789, 'accumulated_eval_time': 137.44315481185913, 'accumulated_logging_time': 0.8700685501098633}
I0204 19:28:23.401626 140397011515136 logging_writer.py:48] [11358] accumulated_eval_time=137.443155, accumulated_logging_time=0.870069, accumulated_submission_time=2672.970718, global_step=11358, preemption_count=0, score=2672.970718, test/loss=0.291917, test/num_examples=3581, test/ssim=0.736552, total_duration=2811.682422, train/loss=0.264155, train/ssim=0.745585, validation/loss=0.290234, validation/num_examples=3554, validation/ssim=0.719655
I0204 19:28:31.404433 140392884336384 logging_writer.py:48] [11400] global_step=11400, grad_norm=0.1582002341747284, loss=0.262705534696579
I0204 19:28:55.224566 140397011515136 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.1255524456501007, loss=0.2919221520423889
I0204 19:29:19.217713 140392884336384 logging_writer.py:48] [11600] global_step=11600, grad_norm=0.19368650019168854, loss=0.24728019535541534
I0204 19:29:43.180169 140397011515136 logging_writer.py:48] [11700] global_step=11700, grad_norm=0.13515791296958923, loss=0.24457454681396484
I0204 19:29:43.397585 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:29:44.776205 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:29:46.106932 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:29:47.437676 140584300062528 submission_runner.py:408] Time since start: 2895.74s, 	Step: 11702, 	{'train/ssim': 0.7454074450901577, 'train/loss': 0.2641615867614746, 'validation/ssim': 0.7192417846748382, 'validation/loss': 0.2905541689931239, 'validation/num_examples': 3554, 'test/ssim': 0.7364029147977171, 'test/loss': 0.29208920288938145, 'test/num_examples': 3581, 'score': 2752.944223165512, 'total_duration': 2895.736180782318, 'accumulated_submission_time': 2752.944223165512, 'accumulated_eval_time': 141.48319029808044, 'accumulated_logging_time': 0.8981711864471436}
I0204 19:29:47.456104 140392884336384 logging_writer.py:48] [11702] accumulated_eval_time=141.483190, accumulated_logging_time=0.898171, accumulated_submission_time=2752.944223, global_step=11702, preemption_count=0, score=2752.944223, test/loss=0.292089, test/num_examples=3581, test/ssim=0.736403, total_duration=2895.736181, train/loss=0.264162, train/ssim=0.745407, validation/loss=0.290554, validation/num_examples=3554, validation/ssim=0.719242
I0204 19:30:09.523781 140397011515136 logging_writer.py:48] [11800] global_step=11800, grad_norm=0.13286596536636353, loss=0.28221216797828674
I0204 19:30:33.337179 140392884336384 logging_writer.py:48] [11900] global_step=11900, grad_norm=0.16925399005413055, loss=0.34361132979393005
I0204 19:30:57.154203 140397011515136 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.1403263658285141, loss=0.32747313380241394
I0204 19:31:07.482299 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:31:08.863181 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:31:10.197004 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:31:11.527431 140584300062528 submission_runner.py:408] Time since start: 2979.83s, 	Step: 12044, 	{'train/ssim': 0.7435768672398159, 'train/loss': 0.2633335930960519, 'validation/ssim': 0.7189717461838773, 'validation/loss': 0.28965354837858753, 'validation/num_examples': 3554, 'test/ssim': 0.7357157622259843, 'test/loss': 0.29123552882182, 'test/num_examples': 3581, 'score': 2832.9485371112823, 'total_duration': 2979.825961828232, 'accumulated_submission_time': 2832.9485371112823, 'accumulated_eval_time': 145.52828335762024, 'accumulated_logging_time': 0.9264392852783203}
I0204 19:31:11.544859 140392884336384 logging_writer.py:48] [12044] accumulated_eval_time=145.528283, accumulated_logging_time=0.926439, accumulated_submission_time=2832.948537, global_step=12044, preemption_count=0, score=2832.948537, test/loss=0.291236, test/num_examples=3581, test/ssim=0.735716, total_duration=2979.825962, train/loss=0.263334, train/ssim=0.743577, validation/loss=0.289654, validation/num_examples=3554, validation/ssim=0.718972
I0204 19:31:22.863058 140397011515136 logging_writer.py:48] [12100] global_step=12100, grad_norm=0.20275235176086426, loss=0.2227933555841446
I0204 19:31:46.705851 140392884336384 logging_writer.py:48] [12200] global_step=12200, grad_norm=0.09466090053319931, loss=0.27422037720680237
I0204 19:32:10.682485 140397011515136 logging_writer.py:48] [12300] global_step=12300, grad_norm=0.16818895936012268, loss=0.2827027440071106
I0204 19:32:31.761489 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:32:33.143591 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:32:34.474583 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:32:35.804381 140584300062528 submission_runner.py:408] Time since start: 3064.10s, 	Step: 12389, 	{'train/ssim': 0.7485134260995048, 'train/loss': 0.26198691981179373, 'validation/ssim': 0.7220078416265123, 'validation/loss': 0.2885388066812922, 'validation/num_examples': 3554, 'test/ssim': 0.7393814167873848, 'test/loss': 0.2899312751980941, 'test/num_examples': 3581, 'score': 2913.143745660782, 'total_duration': 3064.1029093265533, 'accumulated_submission_time': 2913.143745660782, 'accumulated_eval_time': 149.57113814353943, 'accumulated_logging_time': 0.9530577659606934}
I0204 19:32:35.822087 140392884336384 logging_writer.py:48] [12389] accumulated_eval_time=149.571138, accumulated_logging_time=0.953058, accumulated_submission_time=2913.143746, global_step=12389, preemption_count=0, score=2913.143746, test/loss=0.289931, test/num_examples=3581, test/ssim=0.739381, total_duration=3064.102909, train/loss=0.261987, train/ssim=0.748513, validation/loss=0.288539, validation/num_examples=3554, validation/ssim=0.722008
I0204 19:32:36.712014 140397011515136 logging_writer.py:48] [12400] global_step=12400, grad_norm=0.1897294670343399, loss=0.25529709458351135
I0204 19:33:00.153897 140392884336384 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.21288830041885376, loss=0.3360421061515808
I0204 19:33:23.887484 140397011515136 logging_writer.py:48] [12600] global_step=12600, grad_norm=0.16340786218643188, loss=0.3743113577365875
I0204 19:33:47.656295 140392884336384 logging_writer.py:48] [12700] global_step=12700, grad_norm=0.10239174216985703, loss=0.2915532886981964
I0204 19:33:55.892044 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:33:57.274281 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:33:58.606144 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:33:59.934063 140584300062528 submission_runner.py:408] Time since start: 3148.23s, 	Step: 12736, 	{'train/ssim': 0.7500293595450265, 'train/loss': 0.2616373130253383, 'validation/ssim': 0.723628003877673, 'validation/loss': 0.2881183270061023, 'validation/num_examples': 3554, 'test/ssim': 0.7409452530499512, 'test/loss': 0.2895676208854021, 'test/num_examples': 3581, 'score': 2993.192461490631, 'total_duration': 3148.232587814331, 'accumulated_submission_time': 2993.192461490631, 'accumulated_eval_time': 153.61311268806458, 'accumulated_logging_time': 0.9799468517303467}
I0204 19:33:59.952450 140397011515136 logging_writer.py:48] [12736] accumulated_eval_time=153.613113, accumulated_logging_time=0.979947, accumulated_submission_time=2993.192461, global_step=12736, preemption_count=0, score=2993.192461, test/loss=0.289568, test/num_examples=3581, test/ssim=0.740945, total_duration=3148.232588, train/loss=0.261637, train/ssim=0.750029, validation/loss=0.288118, validation/num_examples=3554, validation/ssim=0.723628
I0204 19:34:13.205634 140392884336384 logging_writer.py:48] [12800] global_step=12800, grad_norm=0.24272555112838745, loss=0.25384199619293213
I0204 19:34:37.538360 140397011515136 logging_writer.py:48] [12900] global_step=12900, grad_norm=0.1616794317960739, loss=0.2203953117132187
I0204 19:35:01.315374 140392884336384 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.16153240203857422, loss=0.28624507784843445
I0204 19:35:19.954048 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:35:21.336851 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:35:22.662897 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:35:23.993401 140584300062528 submission_runner.py:408] Time since start: 3232.29s, 	Step: 13078, 	{'train/ssim': 0.7514548982892718, 'train/loss': 0.26127948079790386, 'validation/ssim': 0.724869796246307, 'validation/loss': 0.2879144757667417, 'validation/num_examples': 3554, 'test/ssim': 0.742036215988027, 'test/loss': 0.28933868365592713, 'test/num_examples': 3581, 'score': 3073.1728444099426, 'total_duration': 3232.291928291321, 'accumulated_submission_time': 3073.1728444099426, 'accumulated_eval_time': 157.65242910385132, 'accumulated_logging_time': 1.0075263977050781}
I0204 19:35:24.012001 140397011515136 logging_writer.py:48] [13078] accumulated_eval_time=157.652429, accumulated_logging_time=1.007526, accumulated_submission_time=3073.172844, global_step=13078, preemption_count=0, score=3073.172844, test/loss=0.289339, test/num_examples=3581, test/ssim=0.742036, total_duration=3232.291928, train/loss=0.261279, train/ssim=0.751455, validation/loss=0.287914, validation/num_examples=3554, validation/ssim=0.724870
I0204 19:35:27.279534 140392884336384 logging_writer.py:48] [13100] global_step=13100, grad_norm=0.17160294950008392, loss=0.24313150346279144
I0204 19:35:51.065163 140397011515136 logging_writer.py:48] [13200] global_step=13200, grad_norm=0.20177912712097168, loss=0.19339808821678162
I0204 19:36:14.761266 140392884336384 logging_writer.py:48] [13300] global_step=13300, grad_norm=0.16829952597618103, loss=0.25871336460113525
I0204 19:36:38.681033 140397011515136 logging_writer.py:48] [13400] global_step=13400, grad_norm=0.17882637679576874, loss=0.29014530777931213
I0204 19:36:44.113214 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:36:45.495897 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:36:46.827686 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:36:48.160427 140584300062528 submission_runner.py:408] Time since start: 3316.46s, 	Step: 13424, 	{'train/ssim': 0.7457209995814732, 'train/loss': 0.26303158487592426, 'validation/ssim': 0.7189907058947664, 'validation/loss': 0.28933851492156726, 'validation/num_examples': 3554, 'test/ssim': 0.7365478583801661, 'test/loss': 0.2907379073691881, 'test/num_examples': 3581, 'score': 3153.252564430237, 'total_duration': 3316.4589569568634, 'accumulated_submission_time': 3153.252564430237, 'accumulated_eval_time': 161.69960498809814, 'accumulated_logging_time': 1.0354080200195312}
I0204 19:36:48.178556 140392884336384 logging_writer.py:48] [13424] accumulated_eval_time=161.699605, accumulated_logging_time=1.035408, accumulated_submission_time=3153.252564, global_step=13424, preemption_count=0, score=3153.252564, test/loss=0.290738, test/num_examples=3581, test/ssim=0.736548, total_duration=3316.458957, train/loss=0.263032, train/ssim=0.745721, validation/loss=0.289339, validation/num_examples=3554, validation/ssim=0.718991
I0204 19:37:04.305966 140397011515136 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.21115322411060333, loss=0.2725546360015869
I0204 19:37:27.952679 140392884336384 logging_writer.py:48] [13600] global_step=13600, grad_norm=0.2774185836315155, loss=0.22020116448402405
I0204 19:37:51.948626 140397011515136 logging_writer.py:48] [13700] global_step=13700, grad_norm=0.12848110496997833, loss=0.33059099316596985
I0204 19:38:08.405153 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:38:09.787739 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:38:11.122354 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:38:12.453289 140584300062528 submission_runner.py:408] Time since start: 3400.75s, 	Step: 13770, 	{'train/ssim': 0.7465126173836845, 'train/loss': 0.26222407817840576, 'validation/ssim': 0.7193183791590462, 'validation/loss': 0.28899566014965533, 'validation/num_examples': 3554, 'test/ssim': 0.7370009604728078, 'test/loss': 0.2902145492268221, 'test/num_examples': 3581, 'score': 3233.4567432403564, 'total_duration': 3400.75181722641, 'accumulated_submission_time': 3233.4567432403564, 'accumulated_eval_time': 165.74770259857178, 'accumulated_logging_time': 1.0637977123260498}
I0204 19:38:12.472010 140392884336384 logging_writer.py:48] [13770] accumulated_eval_time=165.747703, accumulated_logging_time=1.063798, accumulated_submission_time=3233.456743, global_step=13770, preemption_count=0, score=3233.456743, test/loss=0.290215, test/num_examples=3581, test/ssim=0.737001, total_duration=3400.751817, train/loss=0.262224, train/ssim=0.746513, validation/loss=0.288996, validation/num_examples=3554, validation/ssim=0.719318
I0204 19:38:17.518781 140397011515136 logging_writer.py:48] [13800] global_step=13800, grad_norm=0.15635910630226135, loss=0.21920005977153778
I0204 19:38:41.500858 140392884336384 logging_writer.py:48] [13900] global_step=13900, grad_norm=0.22180618345737457, loss=0.23742616176605225
I0204 19:39:06.055541 140397011515136 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.08059559017419815, loss=0.33523330092430115
I0204 19:39:30.184121 140392884336384 logging_writer.py:48] [14100] global_step=14100, grad_norm=0.15744873881340027, loss=0.28217238187789917
I0204 19:39:32.498807 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:39:33.881532 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:39:35.212884 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:39:36.544012 140584300062528 submission_runner.py:408] Time since start: 3484.84s, 	Step: 14111, 	{'train/ssim': 0.748753275190081, 'train/loss': 0.26196677344185965, 'validation/ssim': 0.7221636409899057, 'validation/loss': 0.28858569074898, 'validation/num_examples': 3554, 'test/ssim': 0.7393679178083985, 'test/loss': 0.2901376118642663, 'test/num_examples': 3581, 'score': 3313.4611835479736, 'total_duration': 3484.8425419330597, 'accumulated_submission_time': 3313.4611835479736, 'accumulated_eval_time': 169.79286742210388, 'accumulated_logging_time': 1.0930249691009521}
I0204 19:39:36.562461 140397011515136 logging_writer.py:48] [14111] accumulated_eval_time=169.792867, accumulated_logging_time=1.093025, accumulated_submission_time=3313.461184, global_step=14111, preemption_count=0, score=3313.461184, test/loss=0.290138, test/num_examples=3581, test/ssim=0.739368, total_duration=3484.842542, train/loss=0.261967, train/ssim=0.748753, validation/loss=0.288586, validation/num_examples=3554, validation/ssim=0.722164
I0204 19:39:55.893066 140392884336384 logging_writer.py:48] [14200] global_step=14200, grad_norm=0.05735554173588753, loss=0.23878420889377594
I0204 19:40:19.600393 140397011515136 logging_writer.py:48] [14300] global_step=14300, grad_norm=0.12530851364135742, loss=0.2921018898487091
I0204 19:40:43.442182 140392884336384 logging_writer.py:48] [14400] global_step=14400, grad_norm=0.1610375940799713, loss=0.23132620751857758
I0204 19:40:56.598461 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:40:57.976742 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:40:59.309323 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:41:00.639078 140584300062528 submission_runner.py:408] Time since start: 3568.94s, 	Step: 14457, 	{'train/ssim': 0.7506982939583915, 'train/loss': 0.26223320620400564, 'validation/ssim': 0.7246852825381612, 'validation/loss': 0.28878583247968836, 'validation/num_examples': 3554, 'test/ssim': 0.7417963704927045, 'test/loss': 0.2902302639473087, 'test/num_examples': 3581, 'score': 3393.4748725891113, 'total_duration': 3568.9376089572906, 'accumulated_submission_time': 3393.4748725891113, 'accumulated_eval_time': 173.83345460891724, 'accumulated_logging_time': 1.1216280460357666}
I0204 19:41:00.657423 140397011515136 logging_writer.py:48] [14457] accumulated_eval_time=173.833455, accumulated_logging_time=1.121628, accumulated_submission_time=3393.474873, global_step=14457, preemption_count=0, score=3393.474873, test/loss=0.290230, test/num_examples=3581, test/ssim=0.741796, total_duration=3568.937609, train/loss=0.262233, train/ssim=0.750698, validation/loss=0.288786, validation/num_examples=3554, validation/ssim=0.724685
I0204 19:41:08.933197 140392884336384 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.15076856315135956, loss=0.36921149492263794
I0204 19:41:32.554941 140397011515136 logging_writer.py:48] [14600] global_step=14600, grad_norm=0.08611507713794708, loss=0.20640544593334198
I0204 19:41:56.321041 140392884336384 logging_writer.py:48] [14700] global_step=14700, grad_norm=0.05546995997428894, loss=0.22543589770793915
I0204 19:42:20.078890 140397011515136 logging_writer.py:48] [14800] global_step=14800, grad_norm=0.1466534286737442, loss=0.26943808794021606
I0204 19:42:20.688175 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:42:22.070563 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:42:23.401826 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:42:24.735243 140584300062528 submission_runner.py:408] Time since start: 3653.03s, 	Step: 14804, 	{'train/ssim': 0.748584338596889, 'train/loss': 0.262541617665972, 'validation/ssim': 0.7220001478307893, 'validation/loss': 0.28889581254176633, 'validation/num_examples': 3554, 'test/ssim': 0.739383939323862, 'test/loss': 0.2902830667716769, 'test/num_examples': 3581, 'score': 3473.4844737052917, 'total_duration': 3653.0337414741516, 'accumulated_submission_time': 3473.4844737052917, 'accumulated_eval_time': 177.88046073913574, 'accumulated_logging_time': 1.1491503715515137}
I0204 19:42:24.756607 140392884336384 logging_writer.py:48] [14804] accumulated_eval_time=177.880461, accumulated_logging_time=1.149150, accumulated_submission_time=3473.484474, global_step=14804, preemption_count=0, score=3473.484474, test/loss=0.290283, test/num_examples=3581, test/ssim=0.739384, total_duration=3653.033741, train/loss=0.262542, train/ssim=0.748584, validation/loss=0.288896, validation/num_examples=3554, validation/ssim=0.722000
I0204 19:42:45.514002 140397011515136 logging_writer.py:48] [14900] global_step=14900, grad_norm=0.08624917268753052, loss=0.23731625080108643
I0204 19:43:09.518881 140392884336384 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.16576504707336426, loss=0.23146577179431915
I0204 19:43:33.638562 140397011515136 logging_writer.py:48] [15100] global_step=15100, grad_norm=0.12438615411520004, loss=0.21066482365131378
I0204 19:43:44.755315 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:43:46.135972 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:43:47.468394 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:43:48.801424 140584300062528 submission_runner.py:408] Time since start: 3737.10s, 	Step: 15148, 	{'train/ssim': 0.746781485421317, 'train/loss': 0.2616633006504604, 'validation/ssim': 0.7198642264877603, 'validation/loss': 0.28810388396547026, 'validation/num_examples': 3554, 'test/ssim': 0.7373965896397654, 'test/loss': 0.2894467436644792, 'test/num_examples': 3581, 'score': 3553.4609277248383, 'total_duration': 3737.0999524593353, 'accumulated_submission_time': 3553.4609277248383, 'accumulated_eval_time': 181.92653894424438, 'accumulated_logging_time': 1.1808226108551025}
I0204 19:43:48.819758 140392884336384 logging_writer.py:48] [15148] accumulated_eval_time=181.926539, accumulated_logging_time=1.180823, accumulated_submission_time=3553.460928, global_step=15148, preemption_count=0, score=3553.460928, test/loss=0.289447, test/num_examples=3581, test/ssim=0.737397, total_duration=3737.099952, train/loss=0.261663, train/ssim=0.746781, validation/loss=0.288104, validation/num_examples=3554, validation/ssim=0.719864
I0204 19:44:02.640949 140397011515136 logging_writer.py:48] [15200] global_step=15200, grad_norm=0.09537613391876221, loss=0.24700284004211426
I0204 19:44:26.492937 140392884336384 logging_writer.py:48] [15300] global_step=15300, grad_norm=0.11961473524570465, loss=0.2452249675989151
I0204 19:44:50.318665 140397011515136 logging_writer.py:48] [15400] global_step=15400, grad_norm=0.24416513741016388, loss=0.23749198019504547
I0204 19:45:08.967797 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:45:10.348589 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:45:11.678418 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:45:13.008452 140584300062528 submission_runner.py:408] Time since start: 3821.31s, 	Step: 15479, 	{'train/ssim': 0.7495412826538086, 'train/loss': 0.26138252871377127, 'validation/ssim': 0.7229363865978475, 'validation/loss': 0.2880535479938977, 'validation/num_examples': 3554, 'test/ssim': 0.7400738189620567, 'test/loss': 0.2894908880528309, 'test/num_examples': 3581, 'score': 3630.503707885742, 'total_duration': 3821.306978702545, 'accumulated_submission_time': 3630.503707885742, 'accumulated_eval_time': 185.9671552181244, 'accumulated_logging_time': 4.293005704879761}
I0204 19:45:13.028144 140392884336384 logging_writer.py:48] [15479] accumulated_eval_time=185.967155, accumulated_logging_time=4.293006, accumulated_submission_time=3630.503708, global_step=15479, preemption_count=0, score=3630.503708, test/loss=0.289491, test/num_examples=3581, test/ssim=0.740074, total_duration=3821.306979, train/loss=0.261383, train/ssim=0.749541, validation/loss=0.288054, validation/num_examples=3554, validation/ssim=0.722936
I0204 19:45:16.006107 140397011515136 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.083784319460392, loss=0.35040542483329773
I0204 19:45:39.734635 140392884336384 logging_writer.py:48] [15600] global_step=15600, grad_norm=0.20349718630313873, loss=0.30746373534202576
I0204 19:46:03.250817 140397011515136 logging_writer.py:48] [15700] global_step=15700, grad_norm=0.1371125429868698, loss=0.24839064478874207
I0204 19:46:26.959805 140392884336384 logging_writer.py:48] [15800] global_step=15800, grad_norm=0.11599330604076385, loss=0.30637606978416443
I0204 19:46:33.037998 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:46:34.421575 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:46:35.752873 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:46:37.083151 140584300062528 submission_runner.py:408] Time since start: 3905.38s, 	Step: 15827, 	{'train/ssim': 0.7468673161097935, 'train/loss': 0.26163523537772043, 'validation/ssim': 0.7202307808982836, 'validation/loss': 0.2881785721743986, 'validation/num_examples': 3554, 'test/ssim': 0.7377974002330006, 'test/loss': 0.2894689692561435, 'test/num_examples': 3581, 'score': 3710.4920921325684, 'total_duration': 3905.3816516399384, 'accumulated_submission_time': 3710.4920921325684, 'accumulated_eval_time': 190.01224875450134, 'accumulated_logging_time': 4.322009086608887}
I0204 19:46:37.102083 140397011515136 logging_writer.py:48] [15827] accumulated_eval_time=190.012249, accumulated_logging_time=4.322009, accumulated_submission_time=3710.492092, global_step=15827, preemption_count=0, score=3710.492092, test/loss=0.289469, test/num_examples=3581, test/ssim=0.737797, total_duration=3905.381652, train/loss=0.261635, train/ssim=0.746867, validation/loss=0.288179, validation/num_examples=3554, validation/ssim=0.720231
I0204 19:46:52.434969 140392884336384 logging_writer.py:48] [15900] global_step=15900, grad_norm=0.13345405459403992, loss=0.30136609077453613
I0204 19:47:16.240507 140397011515136 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.10176493227481842, loss=0.22638221085071564
I0204 19:47:40.463041 140392884336384 logging_writer.py:48] [16100] global_step=16100, grad_norm=0.1640244573354721, loss=0.27970561385154724
I0204 19:47:57.090116 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:47:58.472689 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:47:59.805075 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:48:01.139044 140584300062528 submission_runner.py:408] Time since start: 3989.44s, 	Step: 16170, 	{'train/ssim': 0.7493359701974052, 'train/loss': 0.261055520602635, 'validation/ssim': 0.7227794194261747, 'validation/loss': 0.287572565545644, 'validation/num_examples': 3554, 'test/ssim': 0.7401714479413921, 'test/loss': 0.2889514061300091, 'test/num_examples': 3581, 'score': 3790.4588992595673, 'total_duration': 3989.43754029274, 'accumulated_submission_time': 3790.4588992595673, 'accumulated_eval_time': 194.06110763549805, 'accumulated_logging_time': 4.35016131401062}
I0204 19:48:01.161817 140397011515136 logging_writer.py:48] [16170] accumulated_eval_time=194.061108, accumulated_logging_time=4.350161, accumulated_submission_time=3790.458899, global_step=16170, preemption_count=0, score=3790.458899, test/loss=0.288951, test/num_examples=3581, test/ssim=0.740171, total_duration=3989.437540, train/loss=0.261056, train/ssim=0.749336, validation/loss=0.287573, validation/num_examples=3554, validation/ssim=0.722779
I0204 19:48:06.362365 140392884336384 logging_writer.py:48] [16200] global_step=16200, grad_norm=0.11923154443502426, loss=0.26071086525917053
I0204 19:48:30.440493 140397011515136 logging_writer.py:48] [16300] global_step=16300, grad_norm=0.1758427768945694, loss=0.22421054542064667
I0204 19:48:54.392877 140392884336384 logging_writer.py:48] [16400] global_step=16400, grad_norm=0.24726909399032593, loss=0.24630261957645416
I0204 19:49:18.384861 140397011515136 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.1016072928905487, loss=0.2108483612537384
I0204 19:49:21.206244 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:49:22.586257 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:49:23.915588 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:49:25.250364 140584300062528 submission_runner.py:408] Time since start: 4073.55s, 	Step: 16513, 	{'train/ssim': 0.7490717342921666, 'train/loss': 0.2611632687704904, 'validation/ssim': 0.7222987632772931, 'validation/loss': 0.28795869791849854, 'validation/num_examples': 3554, 'test/ssim': 0.7395680844867006, 'test/loss': 0.28937713529303966, 'test/num_examples': 3581, 'score': 3870.4816830158234, 'total_duration': 4073.548889398575, 'accumulated_submission_time': 3870.4816830158234, 'accumulated_eval_time': 198.1052176952362, 'accumulated_logging_time': 4.3827149868011475}
I0204 19:49:25.270716 140392884336384 logging_writer.py:48] [16513] accumulated_eval_time=198.105218, accumulated_logging_time=4.382715, accumulated_submission_time=3870.481683, global_step=16513, preemption_count=0, score=3870.481683, test/loss=0.289377, test/num_examples=3581, test/ssim=0.739568, total_duration=4073.548889, train/loss=0.261163, train/ssim=0.749072, validation/loss=0.287959, validation/num_examples=3554, validation/ssim=0.722299
I0204 19:49:44.130791 140397011515136 logging_writer.py:48] [16600] global_step=16600, grad_norm=0.1435205489397049, loss=0.19101525843143463
I0204 19:50:08.159592 140392884336384 logging_writer.py:48] [16700] global_step=16700, grad_norm=0.09651152789592743, loss=0.2677917778491974
I0204 19:50:32.034244 140397011515136 logging_writer.py:48] [16800] global_step=16800, grad_norm=0.08135973662137985, loss=0.23929636180400848
I0204 19:50:45.343686 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:50:46.726618 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:50:48.057341 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:50:49.388919 140584300062528 submission_runner.py:408] Time since start: 4157.69s, 	Step: 16857, 	{'train/ssim': 0.7464184079851423, 'train/loss': 0.26241728237697054, 'validation/ssim': 0.719400606600837, 'validation/loss': 0.2888134820580684, 'validation/num_examples': 3554, 'test/ssim': 0.7370565244519687, 'test/loss': 0.2901986981530124, 'test/num_examples': 3581, 'score': 3950.5336406230927, 'total_duration': 4157.687446594238, 'accumulated_submission_time': 3950.5336406230927, 'accumulated_eval_time': 202.15042400360107, 'accumulated_logging_time': 4.412107944488525}
I0204 19:50:49.408297 140392884336384 logging_writer.py:48] [16857] accumulated_eval_time=202.150424, accumulated_logging_time=4.412108, accumulated_submission_time=3950.533641, global_step=16857, preemption_count=0, score=3950.533641, test/loss=0.290199, test/num_examples=3581, test/ssim=0.737057, total_duration=4157.687447, train/loss=0.262417, train/ssim=0.746418, validation/loss=0.288813, validation/num_examples=3554, validation/ssim=0.719401
I0204 19:50:57.427819 140397011515136 logging_writer.py:48] [16900] global_step=16900, grad_norm=0.10708152502775192, loss=0.35825324058532715
I0204 19:51:21.453676 140392884336384 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.12609708309173584, loss=0.2427252233028412
I0204 19:51:45.106881 140397011515136 logging_writer.py:48] [17100] global_step=17100, grad_norm=0.12747034430503845, loss=0.2776685655117035
I0204 19:52:09.295135 140392884336384 logging_writer.py:48] [17200] global_step=17200, grad_norm=0.2823115587234497, loss=0.3486553430557251
I0204 19:52:09.490919 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:52:10.873201 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:52:12.205807 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:52:13.537847 140584300062528 submission_runner.py:408] Time since start: 4241.84s, 	Step: 17202, 	{'train/ssim': 0.7484077726091657, 'train/loss': 0.26139157158987864, 'validation/ssim': 0.7219015023784819, 'validation/loss': 0.28783149268429936, 'validation/num_examples': 3554, 'test/ssim': 0.7391657740069115, 'test/loss': 0.2892383616984606, 'test/num_examples': 3581, 'score': 4030.5943059921265, 'total_duration': 4241.836377620697, 'accumulated_submission_time': 4030.5943059921265, 'accumulated_eval_time': 206.19731330871582, 'accumulated_logging_time': 4.441436052322388}
I0204 19:52:13.556786 140397011515136 logging_writer.py:48] [17202] accumulated_eval_time=206.197313, accumulated_logging_time=4.441436, accumulated_submission_time=4030.594306, global_step=17202, preemption_count=0, score=4030.594306, test/loss=0.289238, test/num_examples=3581, test/ssim=0.739166, total_duration=4241.836378, train/loss=0.261392, train/ssim=0.748408, validation/loss=0.287831, validation/num_examples=3554, validation/ssim=0.721902
I0204 19:52:35.068020 140392884336384 logging_writer.py:48] [17300] global_step=17300, grad_norm=0.12618012726306915, loss=0.31052830815315247
I0204 19:52:58.834368 140397011515136 logging_writer.py:48] [17400] global_step=17400, grad_norm=0.17054234445095062, loss=0.2595570683479309
I0204 19:53:22.785904 140392884336384 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.06510934233665466, loss=0.3041842579841614
I0204 19:53:33.751431 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:53:35.133703 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:53:36.465386 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:53:37.794975 140584300062528 submission_runner.py:408] Time since start: 4326.09s, 	Step: 17547, 	{'train/ssim': 0.7491188049316406, 'train/loss': 0.26074956144605366, 'validation/ssim': 0.7221773799108399, 'validation/loss': 0.287938776483144, 'validation/num_examples': 3554, 'test/ssim': 0.7394163914147585, 'test/loss': 0.28935753450284485, 'test/num_examples': 3581, 'score': 4110.767489433289, 'total_duration': 4326.0935044288635, 'accumulated_submission_time': 4110.767489433289, 'accumulated_eval_time': 210.24081873893738, 'accumulated_logging_time': 4.469689130783081}
I0204 19:53:37.814487 140397011515136 logging_writer.py:48] [17547] accumulated_eval_time=210.240819, accumulated_logging_time=4.469689, accumulated_submission_time=4110.767489, global_step=17547, preemption_count=0, score=4110.767489, test/loss=0.289358, test/num_examples=3581, test/ssim=0.739416, total_duration=4326.093504, train/loss=0.260750, train/ssim=0.749119, validation/loss=0.287939, validation/num_examples=3554, validation/ssim=0.722177
I0204 19:53:48.349359 140392884336384 logging_writer.py:48] [17600] global_step=17600, grad_norm=0.11750378459692001, loss=0.26013344526290894
I0204 19:54:12.029435 140397011515136 logging_writer.py:48] [17700] global_step=17700, grad_norm=0.1393686681985855, loss=0.29050126671791077
I0204 19:54:35.905367 140392884336384 logging_writer.py:48] [17800] global_step=17800, grad_norm=0.14498943090438843, loss=0.3651532232761383
I0204 19:54:57.881527 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:54:59.262994 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:55:00.593824 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:55:01.924032 140584300062528 submission_runner.py:408] Time since start: 4410.22s, 	Step: 17893, 	{'train/ssim': 0.7488366535731724, 'train/loss': 0.26106984274727957, 'validation/ssim': 0.7225361031364308, 'validation/loss': 0.2876933821816087, 'validation/num_examples': 3554, 'test/ssim': 0.7397306176478288, 'test/loss': 0.28906355673825396, 'test/num_examples': 3581, 'score': 4190.812663078308, 'total_duration': 4410.222549676895, 'accumulated_submission_time': 4190.812663078308, 'accumulated_eval_time': 214.28328132629395, 'accumulated_logging_time': 4.499216556549072}
I0204 19:55:01.945908 140397011515136 logging_writer.py:48] [17893] accumulated_eval_time=214.283281, accumulated_logging_time=4.499217, accumulated_submission_time=4190.812663, global_step=17893, preemption_count=0, score=4190.812663, test/loss=0.289064, test/num_examples=3581, test/ssim=0.739731, total_duration=4410.222550, train/loss=0.261070, train/ssim=0.748837, validation/loss=0.287693, validation/num_examples=3554, validation/ssim=0.722536
I0204 19:55:02.550890 140392884336384 logging_writer.py:48] [17900] global_step=17900, grad_norm=0.13724590837955475, loss=0.32324302196502686
I0204 19:55:25.216996 140397011515136 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.05880071967840195, loss=0.3708655834197998
I0204 19:55:49.100890 140392884336384 logging_writer.py:48] [18100] global_step=18100, grad_norm=0.16101640462875366, loss=0.23308531939983368
I0204 19:56:12.645237 140397011515136 logging_writer.py:48] [18200] global_step=18200, grad_norm=0.12037148326635361, loss=0.3624943792819977
I0204 19:56:22.079066 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:56:23.461512 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:56:24.792489 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:56:26.123222 140584300062528 submission_runner.py:408] Time since start: 4494.42s, 	Step: 18241, 	{'train/ssim': 0.7490247998918805, 'train/loss': 0.2612367698124477, 'validation/ssim': 0.7226962302599184, 'validation/loss': 0.28772268043050087, 'validation/num_examples': 3554, 'test/ssim': 0.7400820683381039, 'test/loss': 0.28903761551853535, 'test/num_examples': 3581, 'score': 4270.923578500748, 'total_duration': 4494.421721696854, 'accumulated_submission_time': 4270.923578500748, 'accumulated_eval_time': 218.32737565040588, 'accumulated_logging_time': 4.531201362609863}
I0204 19:56:26.146266 140392884336384 logging_writer.py:48] [18241] accumulated_eval_time=218.327376, accumulated_logging_time=4.531201, accumulated_submission_time=4270.923579, global_step=18241, preemption_count=0, score=4270.923579, test/loss=0.289038, test/num_examples=3581, test/ssim=0.740082, total_duration=4494.421722, train/loss=0.261237, train/ssim=0.749025, validation/loss=0.287723, validation/num_examples=3554, validation/ssim=0.722696
I0204 19:56:38.395656 140397011515136 logging_writer.py:48] [18300] global_step=18300, grad_norm=0.1625719517469406, loss=0.20318619906902313
I0204 19:57:02.671861 140392884336384 logging_writer.py:48] [18400] global_step=18400, grad_norm=0.24049265682697296, loss=0.28979194164276123
I0204 19:57:26.361804 140397011515136 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.1435907632112503, loss=0.2332344353199005
I0204 19:57:46.128534 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:57:47.512726 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:57:48.844590 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:57:50.177259 140584300062528 submission_runner.py:408] Time since start: 4578.48s, 	Step: 18584, 	{'train/ssim': 0.7490253448486328, 'train/loss': 0.26049625873565674, 'validation/ssim': 0.7227430799803038, 'validation/loss': 0.28743680783316333, 'validation/num_examples': 3554, 'test/ssim': 0.7397645014486177, 'test/loss': 0.2889587010327946, 'test/num_examples': 3581, 'score': 4350.883985042572, 'total_duration': 4578.475754737854, 'accumulated_submission_time': 4350.883985042572, 'accumulated_eval_time': 222.37603402137756, 'accumulated_logging_time': 4.564069509506226}
I0204 19:57:50.201391 140392884336384 logging_writer.py:48] [18584] accumulated_eval_time=222.376034, accumulated_logging_time=4.564070, accumulated_submission_time=4350.883985, global_step=18584, preemption_count=0, score=4350.883985, test/loss=0.288959, test/num_examples=3581, test/ssim=0.739765, total_duration=4578.475755, train/loss=0.260496, train/ssim=0.749025, validation/loss=0.287437, validation/num_examples=3554, validation/ssim=0.722743
I0204 19:57:51.908206 140397011515136 logging_writer.py:48] [18600] global_step=18600, grad_norm=0.06597962230443954, loss=0.2962450385093689
I0204 19:58:15.766166 140392884336384 logging_writer.py:48] [18700] global_step=18700, grad_norm=0.17905491590499878, loss=0.3062572181224823
I0204 19:58:39.648869 140397011515136 logging_writer.py:48] [18800] global_step=18800, grad_norm=0.11952821910381317, loss=0.2622694969177246
I0204 19:59:03.566308 140392884336384 logging_writer.py:48] [18900] global_step=18900, grad_norm=0.04473740980029106, loss=0.2818732261657715
I0204 19:59:10.297026 140584300062528 spec.py:321] Evaluating on the training split.
I0204 19:59:11.677672 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 19:59:13.007484 140584300062528 spec.py:349] Evaluating on the test split.
I0204 19:59:14.337832 140584300062528 submission_runner.py:408] Time since start: 4662.64s, 	Step: 18930, 	{'train/ssim': 0.746837956564767, 'train/loss': 0.26119305406297955, 'validation/ssim': 0.7200128129176632, 'validation/loss': 0.2878367134742544, 'validation/num_examples': 3554, 'test/ssim': 0.7375610317474169, 'test/loss': 0.289137153444394, 'test/num_examples': 3581, 'score': 4430.957304239273, 'total_duration': 4662.636361837387, 'accumulated_submission_time': 4430.957304239273, 'accumulated_eval_time': 226.41681051254272, 'accumulated_logging_time': 4.5984275341033936}
I0204 19:59:14.358007 140397011515136 logging_writer.py:48] [18930] accumulated_eval_time=226.416811, accumulated_logging_time=4.598428, accumulated_submission_time=4430.957304, global_step=18930, preemption_count=0, score=4430.957304, test/loss=0.289137, test/num_examples=3581, test/ssim=0.737561, total_duration=4662.636362, train/loss=0.261193, train/ssim=0.746838, validation/loss=0.287837, validation/num_examples=3554, validation/ssim=0.720013
I0204 19:59:28.935662 140392884336384 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.1763647049665451, loss=0.29579126834869385
I0204 19:59:53.086897 140397011515136 logging_writer.py:48] [19100] global_step=19100, grad_norm=0.11498627066612244, loss=0.36831676959991455
I0204 20:00:16.756072 140392884336384 logging_writer.py:48] [19200] global_step=19200, grad_norm=0.1172695979475975, loss=0.35542455315589905
I0204 20:00:34.521362 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:00:35.904310 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:00:37.234504 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:00:38.564435 140584300062528 submission_runner.py:408] Time since start: 4746.86s, 	Step: 19276, 	{'train/ssim': 0.7515696798052106, 'train/loss': 0.2613452843257359, 'validation/ssim': 0.7252221995682682, 'validation/loss': 0.2881080056417505, 'validation/num_examples': 3554, 'test/ssim': 0.742224383573897, 'test/loss': 0.2894971603056932, 'test/num_examples': 3581, 'score': 4511.09930229187, 'total_duration': 4746.862930059433, 'accumulated_submission_time': 4511.09930229187, 'accumulated_eval_time': 230.45980858802795, 'accumulated_logging_time': 4.627838373184204}
I0204 20:00:38.588084 140397011515136 logging_writer.py:48] [19276] accumulated_eval_time=230.459809, accumulated_logging_time=4.627838, accumulated_submission_time=4511.099302, global_step=19276, preemption_count=0, score=4511.099302, test/loss=0.289497, test/num_examples=3581, test/ssim=0.742224, total_duration=4746.862930, train/loss=0.261345, train/ssim=0.751570, validation/loss=0.288108, validation/num_examples=3554, validation/ssim=0.725222
I0204 20:00:42.129871 140392884336384 logging_writer.py:48] [19300] global_step=19300, grad_norm=0.059820421040058136, loss=0.31968873739242554
I0204 20:01:06.221666 140397011515136 logging_writer.py:48] [19400] global_step=19400, grad_norm=0.1623428612947464, loss=0.20483413338661194
I0204 20:01:30.124161 140392884336384 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.11943520605564117, loss=0.31206879019737244
I0204 20:01:54.178484 140397011515136 logging_writer.py:48] [19600] global_step=19600, grad_norm=0.10898199677467346, loss=0.26056569814682007
I0204 20:01:58.619083 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:02:00.000457 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:02:01.333002 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:02:02.665606 140584300062528 submission_runner.py:408] Time since start: 4830.96s, 	Step: 19620, 	{'train/ssim': 0.7509069442749023, 'train/loss': 0.2607353925704956, 'validation/ssim': 0.7235287401739238, 'validation/loss': 0.2882456868031619, 'validation/num_examples': 3554, 'test/ssim': 0.7407267468496929, 'test/loss': 0.28975834509608, 'test/num_examples': 3581, 'score': 4591.1084978580475, 'total_duration': 4830.964126110077, 'accumulated_submission_time': 4591.1084978580475, 'accumulated_eval_time': 234.50627899169922, 'accumulated_logging_time': 4.6616129875183105}
I0204 20:02:02.685628 140392884336384 logging_writer.py:48] [19620] accumulated_eval_time=234.506279, accumulated_logging_time=4.661613, accumulated_submission_time=4591.108498, global_step=19620, preemption_count=0, score=4591.108498, test/loss=0.289758, test/num_examples=3581, test/ssim=0.740727, total_duration=4830.964126, train/loss=0.260735, train/ssim=0.750907, validation/loss=0.288246, validation/num_examples=3554, validation/ssim=0.723529
I0204 20:02:19.490421 140397011515136 logging_writer.py:48] [19700] global_step=19700, grad_norm=0.14003506302833557, loss=0.25058698654174805
I0204 20:02:43.073473 140392884336384 logging_writer.py:48] [19800] global_step=19800, grad_norm=0.19401317834854126, loss=0.28692469000816345
I0204 20:03:06.755944 140397011515136 logging_writer.py:48] [19900] global_step=19900, grad_norm=0.07264985889196396, loss=0.27775952219963074
I0204 20:03:22.807320 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:03:24.187837 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:03:25.518768 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:03:26.848402 140584300062528 submission_runner.py:408] Time since start: 4915.15s, 	Step: 19969, 	{'train/ssim': 0.747917720249721, 'train/loss': 0.2605396509170532, 'validation/ssim': 0.7213956353096863, 'validation/loss': 0.2870852460201094, 'validation/num_examples': 3554, 'test/ssim': 0.7388614333897654, 'test/loss': 0.2884193213749651, 'test/num_examples': 3581, 'score': 4671.207195281982, 'total_duration': 4915.146928071976, 'accumulated_submission_time': 4671.207195281982, 'accumulated_eval_time': 238.5473177433014, 'accumulated_logging_time': 4.692481756210327}
I0204 20:03:26.868588 140392884336384 logging_writer.py:48] [19969] accumulated_eval_time=238.547318, accumulated_logging_time=4.692482, accumulated_submission_time=4671.207195, global_step=19969, preemption_count=0, score=4671.207195, test/loss=0.288419, test/num_examples=3581, test/ssim=0.738861, total_duration=4915.146928, train/loss=0.260540, train/ssim=0.747918, validation/loss=0.287085, validation/num_examples=3554, validation/ssim=0.721396
I0204 20:03:32.242376 140397011515136 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.08106865733861923, loss=0.35057780146598816
I0204 20:03:56.151131 140392884336384 logging_writer.py:48] [20100] global_step=20100, grad_norm=0.09809739142656326, loss=0.4185859262943268
I0204 20:04:19.788472 140397011515136 logging_writer.py:48] [20200] global_step=20200, grad_norm=0.148665189743042, loss=0.28266000747680664
I0204 20:04:43.643409 140392884336384 logging_writer.py:48] [20300] global_step=20300, grad_norm=0.10881093144416809, loss=0.24441303312778473
I0204 20:04:46.987523 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:04:48.369763 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:04:49.700657 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:04:51.031720 140584300062528 submission_runner.py:408] Time since start: 4999.33s, 	Step: 20315, 	{'train/ssim': 0.7510645730154855, 'train/loss': 0.2608891555241176, 'validation/ssim': 0.7249340257016742, 'validation/loss': 0.28743455808486035, 'validation/num_examples': 3554, 'test/ssim': 0.7419790157689891, 'test/loss': 0.2887872708173345, 'test/num_examples': 3581, 'score': 4751.304104089737, 'total_duration': 4999.330250740051, 'accumulated_submission_time': 4751.304104089737, 'accumulated_eval_time': 242.59148383140564, 'accumulated_logging_time': 4.722586393356323}
I0204 20:04:51.051632 140397011515136 logging_writer.py:48] [20315] accumulated_eval_time=242.591484, accumulated_logging_time=4.722586, accumulated_submission_time=4751.304104, global_step=20315, preemption_count=0, score=4751.304104, test/loss=0.288787, test/num_examples=3581, test/ssim=0.741979, total_duration=4999.330251, train/loss=0.260889, train/ssim=0.751065, validation/loss=0.287435, validation/num_examples=3554, validation/ssim=0.724934
I0204 20:05:09.467255 140392884336384 logging_writer.py:48] [20400] global_step=20400, grad_norm=0.11993204802274704, loss=0.23925723135471344
I0204 20:05:33.668928 140397011515136 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.10125777125358582, loss=0.2985532879829407
I0204 20:05:57.570146 140392884336384 logging_writer.py:48] [20600] global_step=20600, grad_norm=0.07604973763227463, loss=0.2423161268234253
I0204 20:06:11.194532 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:06:12.578969 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:06:13.911545 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:06:15.239946 140584300062528 submission_runner.py:408] Time since start: 5083.54s, 	Step: 20657, 	{'train/ssim': 0.750018664768764, 'train/loss': 0.2601903336388724, 'validation/ssim': 0.722571961720069, 'validation/loss': 0.28715443866066404, 'validation/num_examples': 3554, 'test/ssim': 0.7399350112791468, 'test/loss': 0.28854865250191986, 'test/num_examples': 3581, 'score': 4831.424298048019, 'total_duration': 5083.538475513458, 'accumulated_submission_time': 4831.424298048019, 'accumulated_eval_time': 246.63685989379883, 'accumulated_logging_time': 4.753290891647339}
I0204 20:06:15.260200 140397011515136 logging_writer.py:48] [20657] accumulated_eval_time=246.636860, accumulated_logging_time=4.753291, accumulated_submission_time=4831.424298, global_step=20657, preemption_count=0, score=4831.424298, test/loss=0.288549, test/num_examples=3581, test/ssim=0.739935, total_duration=5083.538476, train/loss=0.260190, train/ssim=0.750019, validation/loss=0.287154, validation/num_examples=3554, validation/ssim=0.722572
I0204 20:06:23.497248 140392884336384 logging_writer.py:48] [20700] global_step=20700, grad_norm=0.18210750818252563, loss=0.2328631728887558
I0204 20:06:47.383307 140397011515136 logging_writer.py:48] [20800] global_step=20800, grad_norm=0.07631734758615494, loss=0.27443796396255493
I0204 20:07:11.458517 140392884336384 logging_writer.py:48] [20900] global_step=20900, grad_norm=0.1409812867641449, loss=0.2891565263271332
I0204 20:07:35.018368 140397011515136 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.18335023522377014, loss=0.394010990858078
I0204 20:07:35.412150 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:07:36.794417 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:07:38.122198 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:07:39.453731 140584300062528 submission_runner.py:408] Time since start: 5167.75s, 	Step: 21003, 	{'train/ssim': 0.750136239188058, 'train/loss': 0.25977115971701487, 'validation/ssim': 0.7229999978017726, 'validation/loss': 0.28686987126081526, 'validation/num_examples': 3554, 'test/ssim': 0.7402386701296775, 'test/loss': 0.2883246921687378, 'test/num_examples': 3581, 'score': 4911.5534324646, 'total_duration': 5167.75226020813, 'accumulated_submission_time': 4911.5534324646, 'accumulated_eval_time': 250.6783995628357, 'accumulated_logging_time': 4.78401255607605}
I0204 20:07:39.473457 140392884336384 logging_writer.py:48] [21003] accumulated_eval_time=250.678400, accumulated_logging_time=4.784013, accumulated_submission_time=4911.553432, global_step=21003, preemption_count=0, score=4911.553432, test/loss=0.288325, test/num_examples=3581, test/ssim=0.740239, total_duration=5167.752260, train/loss=0.259771, train/ssim=0.750136, validation/loss=0.286870, validation/num_examples=3554, validation/ssim=0.723000
I0204 20:08:00.412664 140397011515136 logging_writer.py:48] [21100] global_step=21100, grad_norm=0.09016557782888412, loss=0.2856028378009796
I0204 20:08:24.342938 140392884336384 logging_writer.py:48] [21200] global_step=21200, grad_norm=0.20691032707691193, loss=0.22411829233169556
I0204 20:08:48.610939 140397011515136 logging_writer.py:48] [21300] global_step=21300, grad_norm=0.06756322085857391, loss=0.304939866065979
I0204 20:08:59.483636 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:09:00.868364 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:09:02.200206 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:09:03.529232 140584300062528 submission_runner.py:408] Time since start: 5251.83s, 	Step: 21347, 	{'train/ssim': 0.7508693422589984, 'train/loss': 0.25986060074397493, 'validation/ssim': 0.7238796322145822, 'validation/loss': 0.28688142912805115, 'validation/num_examples': 3554, 'test/ssim': 0.7412270953687866, 'test/loss': 0.2881120491613725, 'test/num_examples': 3581, 'score': 4991.542078495026, 'total_duration': 5251.82776093483, 'accumulated_submission_time': 4991.542078495026, 'accumulated_eval_time': 254.72396564483643, 'accumulated_logging_time': 4.8128838539123535}
I0204 20:09:03.549906 140392884336384 logging_writer.py:48] [21347] accumulated_eval_time=254.723966, accumulated_logging_time=4.812884, accumulated_submission_time=4991.542078, global_step=21347, preemption_count=0, score=4991.542078, test/loss=0.288112, test/num_examples=3581, test/ssim=0.741227, total_duration=5251.827761, train/loss=0.259861, train/ssim=0.750869, validation/loss=0.286881, validation/num_examples=3554, validation/ssim=0.723880
I0204 20:09:14.107887 140397011515136 logging_writer.py:48] [21400] global_step=21400, grad_norm=0.1199655681848526, loss=0.25764143466949463
I0204 20:09:38.021464 140392884336384 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.10567262768745422, loss=0.25577083230018616
I0204 20:10:02.541915 140397011515136 logging_writer.py:48] [21600] global_step=21600, grad_norm=0.059582509100437164, loss=0.23739948868751526
I0204 20:10:23.753558 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:10:25.133360 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:10:26.466607 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:10:27.796314 140584300062528 submission_runner.py:408] Time since start: 5336.09s, 	Step: 21690, 	{'train/ssim': 0.7507828984941755, 'train/loss': 0.2596160514014108, 'validation/ssim': 0.7240258830279263, 'validation/loss': 0.28636475983267096, 'validation/num_examples': 3554, 'test/ssim': 0.7412582521031137, 'test/loss': 0.28774577004721097, 'test/num_examples': 3581, 'score': 5071.724465370178, 'total_duration': 5336.094830274582, 'accumulated_submission_time': 5071.724465370178, 'accumulated_eval_time': 258.76667499542236, 'accumulated_logging_time': 4.8427369594573975}
I0204 20:10:27.816876 140392884336384 logging_writer.py:48] [21690] accumulated_eval_time=258.766675, accumulated_logging_time=4.842737, accumulated_submission_time=5071.724465, global_step=21690, preemption_count=0, score=5071.724465, test/loss=0.287746, test/num_examples=3581, test/ssim=0.741258, total_duration=5336.094830, train/loss=0.259616, train/ssim=0.750783, validation/loss=0.286365, validation/num_examples=3554, validation/ssim=0.724026
I0204 20:10:28.634768 140397011515136 logging_writer.py:48] [21700] global_step=21700, grad_norm=0.08264525979757309, loss=0.39965900778770447
I0204 20:10:51.910038 140392884336384 logging_writer.py:48] [21800] global_step=21800, grad_norm=0.07177191972732544, loss=0.1824328601360321
I0204 20:11:15.683337 140397011515136 logging_writer.py:48] [21900] global_step=21900, grad_norm=0.10952207446098328, loss=0.2818309962749481
I0204 20:11:39.318582 140392884336384 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.07240308076143265, loss=0.35709723830223083
I0204 20:11:47.902746 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:11:49.284514 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:11:50.614503 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:11:51.948284 140584300062528 submission_runner.py:408] Time since start: 5420.25s, 	Step: 22037, 	{'train/ssim': 0.7516030584062848, 'train/loss': 0.2595355340412685, 'validation/ssim': 0.7247510232748312, 'validation/loss': 0.28650192578454736, 'validation/num_examples': 3554, 'test/ssim': 0.7419090665142418, 'test/loss': 0.2878893500964291, 'test/num_examples': 3581, 'score': 5151.788769721985, 'total_duration': 5420.246787071228, 'accumulated_submission_time': 5151.788769721985, 'accumulated_eval_time': 262.81214714050293, 'accumulated_logging_time': 4.872639179229736}
I0204 20:11:51.972318 140397011515136 logging_writer.py:48] [22037] accumulated_eval_time=262.812147, accumulated_logging_time=4.872639, accumulated_submission_time=5151.788770, global_step=22037, preemption_count=0, score=5151.788770, test/loss=0.287889, test/num_examples=3581, test/ssim=0.741909, total_duration=5420.246787, train/loss=0.259536, train/ssim=0.751603, validation/loss=0.286502, validation/num_examples=3554, validation/ssim=0.724751
I0204 20:12:04.955017 140392884336384 logging_writer.py:48] [22100] global_step=22100, grad_norm=0.07683310657739639, loss=0.2937762439250946
I0204 20:12:28.470630 140397011515136 logging_writer.py:48] [22200] global_step=22200, grad_norm=0.14726214110851288, loss=0.27479439973831177
I0204 20:12:52.691992 140392884336384 logging_writer.py:48] [22300] global_step=22300, grad_norm=0.06417939066886902, loss=0.2526801824569702
I0204 20:13:12.206884 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:13:13.587975 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:13:14.919976 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:13:16.250801 140584300062528 submission_runner.py:408] Time since start: 5504.55s, 	Step: 22382, 	{'train/ssim': 0.7525712421962193, 'train/loss': 0.25947844982147217, 'validation/ssim': 0.7257786945607062, 'validation/loss': 0.2865110793406197, 'validation/num_examples': 3554, 'test/ssim': 0.742977122094038, 'test/loss': 0.2878808280137357, 'test/num_examples': 3581, 'score': 5232.000771999359, 'total_duration': 5504.5493080616, 'accumulated_submission_time': 5232.000771999359, 'accumulated_eval_time': 266.8560085296631, 'accumulated_logging_time': 4.907236814498901}
I0204 20:13:16.271141 140397011515136 logging_writer.py:48] [22382] accumulated_eval_time=266.856009, accumulated_logging_time=4.907237, accumulated_submission_time=5232.000772, global_step=22382, preemption_count=0, score=5232.000772, test/loss=0.287881, test/num_examples=3581, test/ssim=0.742977, total_duration=5504.549308, train/loss=0.259478, train/ssim=0.752571, validation/loss=0.286511, validation/num_examples=3554, validation/ssim=0.725779
I0204 20:13:18.507481 140392884336384 logging_writer.py:48] [22400] global_step=22400, grad_norm=0.07733938843011856, loss=0.2914425730705261
I0204 20:13:42.247652 140397011515136 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.19210954010486603, loss=0.24432122707366943
I0204 20:14:06.364018 140392884336384 logging_writer.py:48] [22600] global_step=22600, grad_norm=0.11748409271240234, loss=0.24149517714977264
I0204 20:14:30.310719 140397011515136 logging_writer.py:48] [22700] global_step=22700, grad_norm=0.08395966142416, loss=0.19758319854736328
I0204 20:14:36.398393 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:14:37.777472 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:14:39.106661 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:14:40.435271 140584300062528 submission_runner.py:408] Time since start: 5588.73s, 	Step: 22727, 	{'train/ssim': 0.7518329620361328, 'train/loss': 0.25960610594068256, 'validation/ssim': 0.7250375484709131, 'validation/loss': 0.28649084877954417, 'validation/num_examples': 3554, 'test/ssim': 0.7421773416774294, 'test/loss': 0.2878331725273143, 'test/num_examples': 3581, 'score': 5312.106199026108, 'total_duration': 5588.7337918281555, 'accumulated_submission_time': 5312.106199026108, 'accumulated_eval_time': 270.8928482532501, 'accumulated_logging_time': 4.937005043029785}
I0204 20:14:40.455389 140392884336384 logging_writer.py:48] [22727] accumulated_eval_time=270.892848, accumulated_logging_time=4.937005, accumulated_submission_time=5312.106199, global_step=22727, preemption_count=0, score=5312.106199, test/loss=0.287833, test/num_examples=3581, test/ssim=0.742177, total_duration=5588.733792, train/loss=0.259606, train/ssim=0.751833, validation/loss=0.286491, validation/num_examples=3554, validation/ssim=0.725038
I0204 20:14:56.197103 140397011515136 logging_writer.py:48] [22800] global_step=22800, grad_norm=0.12380234152078629, loss=0.23730309307575226
I0204 20:15:19.904969 140392884336384 logging_writer.py:48] [22900] global_step=22900, grad_norm=0.1165793314576149, loss=0.19616767764091492
I0204 20:15:43.621328 140397011515136 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.11322320252656937, loss=0.27179476618766785
I0204 20:16:00.592813 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:16:01.974417 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:16:03.304719 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:16:04.636574 140584300062528 submission_runner.py:408] Time since start: 5672.94s, 	Step: 23072, 	{'train/ssim': 0.7509150505065918, 'train/loss': 0.25893185819898334, 'validation/ssim': 0.7236573364738674, 'validation/loss': 0.2861938991772035, 'validation/num_examples': 3554, 'test/ssim': 0.741036337069778, 'test/loss': 0.2875140375746125, 'test/num_examples': 3581, 'score': 5392.222705602646, 'total_duration': 5672.93510222435, 'accumulated_submission_time': 5392.222705602646, 'accumulated_eval_time': 274.9365813732147, 'accumulated_logging_time': 4.966019153594971}
I0204 20:16:04.657541 140392884336384 logging_writer.py:48] [23072] accumulated_eval_time=274.936581, accumulated_logging_time=4.966019, accumulated_submission_time=5392.222706, global_step=23072, preemption_count=0, score=5392.222706, test/loss=0.287514, test/num_examples=3581, test/ssim=0.741036, total_duration=5672.935102, train/loss=0.258932, train/ssim=0.750915, validation/loss=0.286194, validation/num_examples=3554, validation/ssim=0.723657
I0204 20:16:09.321394 140397011515136 logging_writer.py:48] [23100] global_step=23100, grad_norm=0.12378489226102829, loss=0.3049560487270355
I0204 20:16:33.113753 140392884336384 logging_writer.py:48] [23200] global_step=23200, grad_norm=0.04743250459432602, loss=0.3297309875488281
I0204 20:16:56.725341 140397011515136 logging_writer.py:48] [23300] global_step=23300, grad_norm=0.0808257982134819, loss=0.25206467509269714
I0204 20:17:20.639681 140392884336384 logging_writer.py:48] [23400] global_step=23400, grad_norm=0.12160490453243256, loss=0.31113550066947937
I0204 20:17:24.746453 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:17:26.126848 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:17:27.457116 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:17:28.787835 140584300062528 submission_runner.py:408] Time since start: 5757.09s, 	Step: 23418, 	{'train/ssim': 0.7504358291625977, 'train/loss': 0.25956852095467703, 'validation/ssim': 0.723816433178285, 'validation/loss': 0.28646639350028136, 'validation/num_examples': 3554, 'test/ssim': 0.7411057409112329, 'test/loss': 0.2878223324381283, 'test/num_examples': 3581, 'score': 5472.2902681827545, 'total_duration': 5757.086367607117, 'accumulated_submission_time': 5472.2902681827545, 'accumulated_eval_time': 278.97792768478394, 'accumulated_logging_time': 4.996206760406494}
I0204 20:17:28.808331 140397011515136 logging_writer.py:48] [23418] accumulated_eval_time=278.977928, accumulated_logging_time=4.996207, accumulated_submission_time=5472.290268, global_step=23418, preemption_count=0, score=5472.290268, test/loss=0.287822, test/num_examples=3581, test/ssim=0.741106, total_duration=5757.086368, train/loss=0.259569, train/ssim=0.750436, validation/loss=0.286466, validation/num_examples=3554, validation/ssim=0.723816
I0204 20:17:46.415080 140392884336384 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.09840867668390274, loss=0.23451539874076843
I0204 20:18:10.552263 140397011515136 logging_writer.py:48] [23600] global_step=23600, grad_norm=0.056473344564437866, loss=0.2368260771036148
I0204 20:18:34.698534 140392884336384 logging_writer.py:48] [23700] global_step=23700, grad_norm=0.0979415625333786, loss=0.29895544052124023
I0204 20:18:48.972245 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:18:50.352362 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:18:51.682483 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:18:53.012856 140584300062528 submission_runner.py:408] Time since start: 5841.31s, 	Step: 23760, 	{'train/ssim': 0.7507174355643136, 'train/loss': 0.25983021940503803, 'validation/ssim': 0.7237039801104389, 'validation/loss': 0.28673414789563695, 'validation/num_examples': 3554, 'test/ssim': 0.7410613579045657, 'test/loss': 0.28804002051844807, 'test/num_examples': 3581, 'score': 5552.431335449219, 'total_duration': 5841.311386823654, 'accumulated_submission_time': 5552.431335449219, 'accumulated_eval_time': 283.0185122489929, 'accumulated_logging_time': 5.02751088142395}
I0204 20:18:53.033277 140397011515136 logging_writer.py:48] [23760] accumulated_eval_time=283.018512, accumulated_logging_time=5.027511, accumulated_submission_time=5552.431335, global_step=23760, preemption_count=0, score=5552.431335, test/loss=0.288040, test/num_examples=3581, test/ssim=0.741061, total_duration=5841.311387, train/loss=0.259830, train/ssim=0.750717, validation/loss=0.286734, validation/num_examples=3554, validation/ssim=0.723704
I0204 20:19:00.579734 140392884336384 logging_writer.py:48] [23800] global_step=23800, grad_norm=0.08772211521863937, loss=0.2410174310207367
I0204 20:19:24.634883 140397011515136 logging_writer.py:48] [23900] global_step=23900, grad_norm=0.09428323060274124, loss=0.2234378457069397
I0204 20:19:48.604216 140392884336384 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.15611368417739868, loss=0.2400047481060028
I0204 20:20:12.325657 140397011515136 logging_writer.py:48] [24100] global_step=24100, grad_norm=0.055518340319395065, loss=0.32853367924690247
I0204 20:20:13.216799 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:20:14.597715 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:20:15.929017 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:20:17.258842 140584300062528 submission_runner.py:408] Time since start: 5925.56s, 	Step: 24105, 	{'train/ssim': 0.7529386111668178, 'train/loss': 0.2583275181906564, 'validation/ssim': 0.7255741907226013, 'validation/loss': 0.2857426271454699, 'validation/num_examples': 3554, 'test/ssim': 0.7427400036651773, 'test/loss': 0.28713163467999514, 'test/num_examples': 3581, 'score': 5632.593497753143, 'total_duration': 5925.557373762131, 'accumulated_submission_time': 5632.593497753143, 'accumulated_eval_time': 287.06051874160767, 'accumulated_logging_time': 5.057190895080566}
I0204 20:20:17.280288 140392884336384 logging_writer.py:48] [24105] accumulated_eval_time=287.060519, accumulated_logging_time=5.057191, accumulated_submission_time=5632.593498, global_step=24105, preemption_count=0, score=5632.593498, test/loss=0.287132, test/num_examples=3581, test/ssim=0.742740, total_duration=5925.557374, train/loss=0.258328, train/ssim=0.752939, validation/loss=0.285743, validation/num_examples=3554, validation/ssim=0.725574
I0204 20:20:37.913148 140397011515136 logging_writer.py:48] [24200] global_step=24200, grad_norm=0.0854211375117302, loss=0.26240766048431396
I0204 20:21:02.110336 140392884336384 logging_writer.py:48] [24300] global_step=24300, grad_norm=0.15918917953968048, loss=0.23996329307556152
I0204 20:21:25.734648 140397011515136 logging_writer.py:48] [24400] global_step=24400, grad_norm=0.06942864507436752, loss=0.19025082886219025
I0204 20:21:37.440825 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:21:38.822983 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:21:40.154332 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:21:41.486010 140584300062528 submission_runner.py:408] Time since start: 6009.78s, 	Step: 24450, 	{'train/ssim': 0.7510510172162738, 'train/loss': 0.25918493952069965, 'validation/ssim': 0.7238414380143852, 'validation/loss': 0.286399175829611, 'validation/num_examples': 3554, 'test/ssim': 0.7411732358061645, 'test/loss': 0.28772906676513194, 'test/num_examples': 3581, 'score': 5712.731587409973, 'total_duration': 6009.784536600113, 'accumulated_submission_time': 5712.731587409973, 'accumulated_eval_time': 291.10566115379333, 'accumulated_logging_time': 5.088764429092407}
I0204 20:21:41.507084 140392884336384 logging_writer.py:48] [24450] accumulated_eval_time=291.105661, accumulated_logging_time=5.088764, accumulated_submission_time=5712.731587, global_step=24450, preemption_count=0, score=5712.731587, test/loss=0.287729, test/num_examples=3581, test/ssim=0.741173, total_duration=6009.784537, train/loss=0.259185, train/ssim=0.751051, validation/loss=0.286399, validation/num_examples=3554, validation/ssim=0.723841
I0204 20:21:51.515420 140397011515136 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.06115547567605972, loss=0.29643484950065613
I0204 20:22:15.538721 140392884336384 logging_writer.py:48] [24600] global_step=24600, grad_norm=0.06238661706447601, loss=0.2871764898300171
I0204 20:22:39.561021 140397011515136 logging_writer.py:48] [24700] global_step=24700, grad_norm=0.03193584084510803, loss=0.2548094093799591
I0204 20:23:01.627201 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:23:03.007941 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:23:04.335535 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:23:05.667578 140584300062528 submission_runner.py:408] Time since start: 6093.97s, 	Step: 24793, 	{'train/ssim': 0.7537099293300084, 'train/loss': 0.2592285360608782, 'validation/ssim': 0.7267622639103827, 'validation/loss': 0.2864781231040289, 'validation/num_examples': 3554, 'test/ssim': 0.7438580327378874, 'test/loss': 0.28780631092266473, 'test/num_examples': 3581, 'score': 5792.829498052597, 'total_duration': 6093.966063499451, 'accumulated_submission_time': 5792.829498052597, 'accumulated_eval_time': 295.145968914032, 'accumulated_logging_time': 5.1201136112213135}
I0204 20:23:05.692540 140392884336384 logging_writer.py:48] [24793] accumulated_eval_time=295.145969, accumulated_logging_time=5.120114, accumulated_submission_time=5792.829498, global_step=24793, preemption_count=0, score=5792.829498, test/loss=0.287806, test/num_examples=3581, test/ssim=0.743858, total_duration=6093.966063, train/loss=0.259229, train/ssim=0.753710, validation/loss=0.286478, validation/num_examples=3554, validation/ssim=0.726762
I0204 20:23:06.293261 140397011515136 logging_writer.py:48] [24800] global_step=24800, grad_norm=0.09043562412261963, loss=0.27385616302490234
I0204 20:23:29.347962 140392884336384 logging_writer.py:48] [24900] global_step=24900, grad_norm=0.10938052088022232, loss=0.2622201144695282
I0204 20:23:53.287505 140397011515136 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.15476693212985992, loss=0.25065621733665466
I0204 20:24:16.973801 140392884336384 logging_writer.py:48] [25100] global_step=25100, grad_norm=0.09838863462209702, loss=0.2838265299797058
I0204 20:24:25.739527 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:24:27.120658 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:24:28.451903 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:24:29.782335 140584300062528 submission_runner.py:408] Time since start: 6178.08s, 	Step: 25138, 	{'train/ssim': 0.7527525765555245, 'train/loss': 0.2580028772354126, 'validation/ssim': 0.7249790893623382, 'validation/loss': 0.28568267392924346, 'validation/num_examples': 3554, 'test/ssim': 0.7422174977310807, 'test/loss': 0.28705664035229334, 'test/num_examples': 3581, 'score': 5872.8541264534, 'total_duration': 6178.080864906311, 'accumulated_submission_time': 5872.8541264534, 'accumulated_eval_time': 299.18876028060913, 'accumulated_logging_time': 5.155481338500977}
I0204 20:24:29.803934 140397011515136 logging_writer.py:48] [25138] accumulated_eval_time=299.188760, accumulated_logging_time=5.155481, accumulated_submission_time=5872.854126, global_step=25138, preemption_count=0, score=5872.854126, test/loss=0.287057, test/num_examples=3581, test/ssim=0.742217, total_duration=6178.080865, train/loss=0.258003, train/ssim=0.752753, validation/loss=0.285683, validation/num_examples=3554, validation/ssim=0.724979
I0204 20:24:42.591089 140392884336384 logging_writer.py:48] [25200] global_step=25200, grad_norm=0.06178034096956253, loss=0.23001231253147125
I0204 20:25:06.367911 140397011515136 logging_writer.py:48] [25300] global_step=25300, grad_norm=0.1866092085838318, loss=0.20367124676704407
I0204 20:25:30.207214 140392884336384 logging_writer.py:48] [25400] global_step=25400, grad_norm=0.0633017048239708, loss=0.21989063918590546
I0204 20:25:49.840762 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:25:51.220540 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:25:52.552345 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:25:53.881950 140584300062528 submission_runner.py:408] Time since start: 6262.18s, 	Step: 25484, 	{'train/ssim': 0.751709120614188, 'train/loss': 0.25861358642578125, 'validation/ssim': 0.7240188761782499, 'validation/loss': 0.28610025125738603, 'validation/num_examples': 3554, 'test/ssim': 0.7413706754180047, 'test/loss': 0.2874117044056304, 'test/num_examples': 3581, 'score': 5952.869534730911, 'total_duration': 6262.180478811264, 'accumulated_submission_time': 5952.869534730911, 'accumulated_eval_time': 303.2299098968506, 'accumulated_logging_time': 5.186309576034546}
I0204 20:25:53.903090 140397011515136 logging_writer.py:48] [25484] accumulated_eval_time=303.229910, accumulated_logging_time=5.186310, accumulated_submission_time=5952.869535, global_step=25484, preemption_count=0, score=5952.869535, test/loss=0.287412, test/num_examples=3581, test/ssim=0.741371, total_duration=6262.180479, train/loss=0.258614, train/ssim=0.751709, validation/loss=0.286100, validation/num_examples=3554, validation/ssim=0.724019
I0204 20:25:55.642672 140392884336384 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.06569050252437592, loss=0.25516045093536377
I0204 20:26:19.225733 140397011515136 logging_writer.py:48] [25600] global_step=25600, grad_norm=0.08444333076477051, loss=0.3346514105796814
I0204 20:26:43.114136 140392884336384 logging_writer.py:48] [25700] global_step=25700, grad_norm=0.08873448520898819, loss=0.4141121506690979
I0204 20:27:07.143709 140397011515136 logging_writer.py:48] [25800] global_step=25800, grad_norm=0.11204879730939865, loss=0.27910488843917847
I0204 20:27:13.983067 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:27:15.366619 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:27:16.695069 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:27:18.025579 140584300062528 submission_runner.py:408] Time since start: 6346.32s, 	Step: 25830, 	{'train/ssim': 0.7517774445669991, 'train/loss': 0.2585456371307373, 'validation/ssim': 0.7246146644845597, 'validation/loss': 0.28572112573420794, 'validation/num_examples': 3554, 'test/ssim': 0.7417736676644093, 'test/loss': 0.2870886492948897, 'test/num_examples': 3581, 'score': 6032.928485393524, 'total_duration': 6346.324097394943, 'accumulated_submission_time': 6032.928485393524, 'accumulated_eval_time': 307.27237248420715, 'accumulated_logging_time': 5.216569900512695}
I0204 20:27:18.048966 140392884336384 logging_writer.py:48] [25830] accumulated_eval_time=307.272372, accumulated_logging_time=5.216570, accumulated_submission_time=6032.928485, global_step=25830, preemption_count=0, score=6032.928485, test/loss=0.287089, test/num_examples=3581, test/ssim=0.741774, total_duration=6346.324097, train/loss=0.258546, train/ssim=0.751777, validation/loss=0.285721, validation/num_examples=3554, validation/ssim=0.724615
I0204 20:27:33.167507 140397011515136 logging_writer.py:48] [25900] global_step=25900, grad_norm=0.08650524914264679, loss=0.24740958213806152
I0204 20:27:57.055694 140392884336384 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.08769768476486206, loss=0.2952987253665924
I0204 20:28:21.000650 140397011515136 logging_writer.py:48] [26100] global_step=26100, grad_norm=0.06197896972298622, loss=0.27475035190582275
I0204 20:28:38.197211 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:28:39.578971 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:28:40.908821 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:28:42.240805 140584300062528 submission_runner.py:408] Time since start: 6430.54s, 	Step: 26173, 	{'train/ssim': 0.7526977402823312, 'train/loss': 0.25808766910008024, 'validation/ssim': 0.7245964604143219, 'validation/loss': 0.2860090763433367, 'validation/num_examples': 3554, 'test/ssim': 0.7418254137505236, 'test/loss': 0.2873534133600077, 'test/num_examples': 3581, 'score': 6113.055310726166, 'total_duration': 6430.539331912994, 'accumulated_submission_time': 6113.055310726166, 'accumulated_eval_time': 311.31592655181885, 'accumulated_logging_time': 5.249204397201538}
I0204 20:28:42.262765 140392884336384 logging_writer.py:48] [26173] accumulated_eval_time=311.315927, accumulated_logging_time=5.249204, accumulated_submission_time=6113.055311, global_step=26173, preemption_count=0, score=6113.055311, test/loss=0.287353, test/num_examples=3581, test/ssim=0.741825, total_duration=6430.539332, train/loss=0.258088, train/ssim=0.752698, validation/loss=0.286009, validation/num_examples=3554, validation/ssim=0.724596
I0204 20:28:46.691044 140397011515136 logging_writer.py:48] [26200] global_step=26200, grad_norm=0.10443065315485, loss=0.29374396800994873
I0204 20:29:10.619983 140392884336384 logging_writer.py:48] [26300] global_step=26300, grad_norm=0.051424507051706314, loss=0.363008052110672
I0204 20:29:34.577335 140397011515136 logging_writer.py:48] [26400] global_step=26400, grad_norm=0.11359692364931107, loss=0.2506183385848999
I0204 20:29:59.010567 140392884336384 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.09029542654752731, loss=0.2525321841239929
I0204 20:30:02.250310 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:30:03.630208 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:30:04.964935 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:30:06.293820 140584300062528 submission_runner.py:408] Time since start: 6514.59s, 	Step: 26515, 	{'train/ssim': 0.753077507019043, 'train/loss': 0.2581151042665754, 'validation/ssim': 0.7256595094216024, 'validation/loss': 0.28554373909129677, 'validation/num_examples': 3554, 'test/ssim': 0.7428827655944569, 'test/loss': 0.28693831975617845, 'test/num_examples': 3581, 'score': 6193.021834373474, 'total_duration': 6514.592348814011, 'accumulated_submission_time': 6193.021834373474, 'accumulated_eval_time': 315.35939478874207, 'accumulated_logging_time': 5.28049635887146}
I0204 20:30:06.315658 140397011515136 logging_writer.py:48] [26515] accumulated_eval_time=315.359395, accumulated_logging_time=5.280496, accumulated_submission_time=6193.021834, global_step=26515, preemption_count=0, score=6193.021834, test/loss=0.286938, test/num_examples=3581, test/ssim=0.742883, total_duration=6514.592349, train/loss=0.258115, train/ssim=0.753078, validation/loss=0.285544, validation/num_examples=3554, validation/ssim=0.725660
I0204 20:30:24.446283 140392884336384 logging_writer.py:48] [26600] global_step=26600, grad_norm=0.06047606095671654, loss=0.2670600116252899
I0204 20:30:48.389965 140397011515136 logging_writer.py:48] [26700] global_step=26700, grad_norm=0.07467898726463318, loss=0.3434222638607025
I0204 20:31:12.213653 140392884336384 logging_writer.py:48] [26800] global_step=26800, grad_norm=0.05138939991593361, loss=0.1793760061264038
I0204 20:31:26.533995 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:31:27.915664 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:31:29.245785 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:31:30.577079 140584300062528 submission_runner.py:408] Time since start: 6598.88s, 	Step: 26861, 	{'train/ssim': 0.7530824797494071, 'train/loss': 0.25805459703717915, 'validation/ssim': 0.7258945136641812, 'validation/loss': 0.2853332416489343, 'validation/num_examples': 3554, 'test/ssim': 0.743087909169052, 'test/loss': 0.28664734176469564, 'test/num_examples': 3581, 'score': 6273.217540979385, 'total_duration': 6598.875570058823, 'accumulated_submission_time': 6273.217540979385, 'accumulated_eval_time': 319.4024076461792, 'accumulated_logging_time': 5.313000917434692}
I0204 20:31:30.599328 140397011515136 logging_writer.py:48] [26861] accumulated_eval_time=319.402408, accumulated_logging_time=5.313001, accumulated_submission_time=6273.217541, global_step=26861, preemption_count=0, score=6273.217541, test/loss=0.286647, test/num_examples=3581, test/ssim=0.743088, total_duration=6598.875570, train/loss=0.258055, train/ssim=0.753082, validation/loss=0.285333, validation/num_examples=3554, validation/ssim=0.725895
I0204 20:31:37.885544 140392884336384 logging_writer.py:48] [26900] global_step=26900, grad_norm=0.10522307455539703, loss=0.214725524187088
I0204 20:32:02.226155 140397011515136 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.0658627599477768, loss=0.21395699679851532
I0204 20:32:25.877338 140392884336384 logging_writer.py:48] [27100] global_step=27100, grad_norm=0.07370328158140182, loss=0.2478204220533371
I0204 20:32:49.899711 140397011515136 logging_writer.py:48] [27200] global_step=27200, grad_norm=0.039385899901390076, loss=0.31174302101135254
I0204 20:32:50.794051 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:32:52.173393 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:32:53.500306 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:32:54.829439 140584300062528 submission_runner.py:408] Time since start: 6683.13s, 	Step: 27205, 	{'train/ssim': 0.7533891541617257, 'train/loss': 0.2577869551522391, 'validation/ssim': 0.7262223243176702, 'validation/loss': 0.28546793459504255, 'validation/num_examples': 3554, 'test/ssim': 0.7432430110740715, 'test/loss': 0.286867041056531, 'test/num_examples': 3581, 'score': 6353.390656471252, 'total_duration': 6683.127971410751, 'accumulated_submission_time': 6353.390656471252, 'accumulated_eval_time': 323.43775701522827, 'accumulated_logging_time': 5.34488582611084}
I0204 20:32:54.851094 140392884336384 logging_writer.py:48] [27205] accumulated_eval_time=323.437757, accumulated_logging_time=5.344886, accumulated_submission_time=6353.390656, global_step=27205, preemption_count=0, score=6353.390656, test/loss=0.286867, test/num_examples=3581, test/ssim=0.743243, total_duration=6683.127971, train/loss=0.257787, train/ssim=0.753389, validation/loss=0.285468, validation/num_examples=3554, validation/ssim=0.726222
I0204 20:33:15.358961 140397011515136 logging_writer.py:48] [27300] global_step=27300, grad_norm=0.07222878187894821, loss=0.24213114380836487
I0204 20:33:39.446303 140392884336384 logging_writer.py:48] [27400] global_step=27400, grad_norm=0.06862223148345947, loss=0.3060837984085083
I0204 20:34:03.163425 140397011515136 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.10555972158908844, loss=0.23740309476852417
I0204 20:34:14.944738 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:34:16.327162 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:34:17.661622 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:34:18.993017 140584300062528 submission_runner.py:408] Time since start: 6767.29s, 	Step: 27551, 	{'train/ssim': 0.7539660590035575, 'train/loss': 0.25812089443206787, 'validation/ssim': 0.726424355150007, 'validation/loss': 0.28555339068325303, 'validation/num_examples': 3554, 'test/ssim': 0.7436233686688425, 'test/loss': 0.28697360117852905, 'test/num_examples': 3581, 'score': 6433.46320271492, 'total_duration': 6767.291547298431, 'accumulated_submission_time': 6433.46320271492, 'accumulated_eval_time': 327.4859962463379, 'accumulated_logging_time': 5.375718593597412}
I0204 20:34:19.014984 140392884336384 logging_writer.py:48] [27551] accumulated_eval_time=327.485996, accumulated_logging_time=5.375719, accumulated_submission_time=6433.463203, global_step=27551, preemption_count=0, score=6433.463203, test/loss=0.286974, test/num_examples=3581, test/ssim=0.743623, total_duration=6767.291547, train/loss=0.258121, train/ssim=0.753966, validation/loss=0.285553, validation/num_examples=3554, validation/ssim=0.726424
I0204 20:34:28.691544 140397011515136 logging_writer.py:48] [27600] global_step=27600, grad_norm=0.05684112757444382, loss=0.24599425494670868
I0204 20:34:52.955242 140392884336384 logging_writer.py:48] [27700] global_step=27700, grad_norm=0.14731474220752716, loss=0.29246747493743896
I0204 20:35:16.620283 140397011515136 logging_writer.py:48] [27800] global_step=27800, grad_norm=0.04129597544670105, loss=0.3135308027267456
I0204 20:35:39.216056 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:35:40.597081 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:35:41.927187 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:35:43.258133 140584300062528 submission_runner.py:408] Time since start: 6851.56s, 	Step: 27897, 	{'train/ssim': 0.7541084289550781, 'train/loss': 0.2578811134610857, 'validation/ssim': 0.7266418422683948, 'validation/loss': 0.28545539782969015, 'validation/num_examples': 3554, 'test/ssim': 0.7438512832483943, 'test/loss': 0.2867495385803546, 'test/num_examples': 3581, 'score': 6513.643239974976, 'total_duration': 6851.556659221649, 'accumulated_submission_time': 6513.643239974976, 'accumulated_eval_time': 331.52803587913513, 'accumulated_logging_time': 5.40687370300293}
I0204 20:35:43.281239 140392884336384 logging_writer.py:48] [27897] accumulated_eval_time=331.528036, accumulated_logging_time=5.406874, accumulated_submission_time=6513.643240, global_step=27897, preemption_count=0, score=6513.643240, test/loss=0.286750, test/num_examples=3581, test/ssim=0.743851, total_duration=6851.556659, train/loss=0.257881, train/ssim=0.754108, validation/loss=0.285455, validation/num_examples=3554, validation/ssim=0.726642
I0204 20:35:43.592876 140397011515136 logging_writer.py:48] [27900] global_step=27900, grad_norm=0.07166891545057297, loss=0.2708317041397095
I0204 20:36:05.601252 140392884336384 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.08042549341917038, loss=0.23571127653121948
I0204 20:36:29.975368 140397011515136 logging_writer.py:48] [28100] global_step=28100, grad_norm=0.07732325047254562, loss=0.27516642212867737
I0204 20:36:54.069685 140392884336384 logging_writer.py:48] [28200] global_step=28200, grad_norm=0.07069039344787598, loss=0.2564026415348053
I0204 20:37:03.425376 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:37:04.808543 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:37:06.138392 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:37:07.467211 140584300062528 submission_runner.py:408] Time since start: 6935.77s, 	Step: 28240, 	{'train/ssim': 0.7530191285269601, 'train/loss': 0.25813448429107666, 'validation/ssim': 0.7249559392805641, 'validation/loss': 0.286052113513163, 'validation/num_examples': 3554, 'test/ssim': 0.7422999233148911, 'test/loss': 0.28733681234292097, 'test/num_examples': 3581, 'score': 6593.765914440155, 'total_duration': 6935.765740871429, 'accumulated_submission_time': 6593.765914440155, 'accumulated_eval_time': 335.5698335170746, 'accumulated_logging_time': 5.439523696899414}
I0204 20:37:07.489415 140397011515136 logging_writer.py:48] [28240] accumulated_eval_time=335.569834, accumulated_logging_time=5.439524, accumulated_submission_time=6593.765914, global_step=28240, preemption_count=0, score=6593.765914, test/loss=0.287337, test/num_examples=3581, test/ssim=0.742300, total_duration=6935.765741, train/loss=0.258134, train/ssim=0.753019, validation/loss=0.286052, validation/num_examples=3554, validation/ssim=0.724956
I0204 20:37:19.677619 140392884336384 logging_writer.py:48] [28300] global_step=28300, grad_norm=0.0652121752500534, loss=0.2401694655418396
I0204 20:37:43.400746 140397011515136 logging_writer.py:48] [28400] global_step=28400, grad_norm=0.043036822229623795, loss=0.23763060569763184
I0204 20:38:07.058422 140392884336384 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.07674774527549744, loss=0.2957652807235718
I0204 20:38:27.473696 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:38:28.854850 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:38:30.185441 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:38:31.516134 140584300062528 submission_runner.py:408] Time since start: 7019.81s, 	Step: 28587, 	{'train/ssim': 0.753343037196568, 'train/loss': 0.25734414373125347, 'validation/ssim': 0.725530020091798, 'validation/loss': 0.28511778102138435, 'validation/num_examples': 3554, 'test/ssim': 0.7427766827090896, 'test/loss': 0.28647038923965024, 'test/num_examples': 3581, 'score': 6673.728529691696, 'total_duration': 7019.814661979675, 'accumulated_submission_time': 6673.728529691696, 'accumulated_eval_time': 339.61222982406616, 'accumulated_logging_time': 5.4713146686553955}
I0204 20:38:31.538809 140397011515136 logging_writer.py:48] [28587] accumulated_eval_time=339.612230, accumulated_logging_time=5.471315, accumulated_submission_time=6673.728530, global_step=28587, preemption_count=0, score=6673.728530, test/loss=0.286470, test/num_examples=3581, test/ssim=0.742777, total_duration=7019.814662, train/loss=0.257344, train/ssim=0.753343, validation/loss=0.285118, validation/num_examples=3554, validation/ssim=0.725530
I0204 20:38:32.591062 140392884336384 logging_writer.py:48] [28600] global_step=28600, grad_norm=0.07538031041622162, loss=0.3618277311325073
I0204 20:38:56.474510 140397011515136 logging_writer.py:48] [28700] global_step=28700, grad_norm=0.0540183000266552, loss=0.267611026763916
I0204 20:39:20.345935 140392884336384 logging_writer.py:48] [28800] global_step=28800, grad_norm=0.053733181208372116, loss=0.20790797472000122
I0204 20:39:44.236824 140397011515136 logging_writer.py:48] [28900] global_step=28900, grad_norm=0.056797463446855545, loss=0.34109383821487427
I0204 20:39:51.659827 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:39:53.042493 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:39:54.373033 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:39:55.705191 140584300062528 submission_runner.py:408] Time since start: 7104.00s, 	Step: 28932, 	{'train/ssim': 0.7535497801644462, 'train/loss': 0.2575488771711077, 'validation/ssim': 0.7259476832881964, 'validation/loss': 0.2851559752215813, 'validation/num_examples': 3554, 'test/ssim': 0.7432078319167132, 'test/loss': 0.2864604013587336, 'test/num_examples': 3581, 'score': 6753.82816696167, 'total_duration': 7104.003720521927, 'accumulated_submission_time': 6753.82816696167, 'accumulated_eval_time': 343.6575689315796, 'accumulated_logging_time': 5.5031914710998535}
I0204 20:39:55.726681 140392884336384 logging_writer.py:48] [28932] accumulated_eval_time=343.657569, accumulated_logging_time=5.503191, accumulated_submission_time=6753.828167, global_step=28932, preemption_count=0, score=6753.828167, test/loss=0.286460, test/num_examples=3581, test/ssim=0.743208, total_duration=7104.003721, train/loss=0.257549, train/ssim=0.753550, validation/loss=0.285156, validation/num_examples=3554, validation/ssim=0.725948
I0204 20:40:09.978524 140397011515136 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.04645668342709541, loss=0.26203832030296326
I0204 20:40:34.004994 140392884336384 logging_writer.py:48] [29100] global_step=29100, grad_norm=0.05727721378207207, loss=0.25509169697761536
I0204 20:40:58.554240 140397011515136 logging_writer.py:48] [29200] global_step=29200, grad_norm=0.06910813599824905, loss=0.3326593339443207
I0204 20:41:15.789961 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:41:17.169654 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:41:18.500590 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:41:19.830186 140584300062528 submission_runner.py:408] Time since start: 7188.13s, 	Step: 29273, 	{'train/ssim': 0.7527131353105817, 'train/loss': 0.2578637940543039, 'validation/ssim': 0.7251399034318725, 'validation/loss': 0.285449541614642, 'validation/num_examples': 3554, 'test/ssim': 0.7424719330319743, 'test/loss': 0.28681018172080075, 'test/num_examples': 3581, 'score': 6833.869222640991, 'total_duration': 7188.128715515137, 'accumulated_submission_time': 6833.869222640991, 'accumulated_eval_time': 347.69775676727295, 'accumulated_logging_time': 5.534913063049316}
I0204 20:41:19.852235 140392884336384 logging_writer.py:48] [29273] accumulated_eval_time=347.697757, accumulated_logging_time=5.534913, accumulated_submission_time=6833.869223, global_step=29273, preemption_count=0, score=6833.869223, test/loss=0.286810, test/num_examples=3581, test/ssim=0.742472, total_duration=7188.128716, train/loss=0.257864, train/ssim=0.752713, validation/loss=0.285450, validation/num_examples=3554, validation/ssim=0.725140
I0204 20:41:24.438927 140397011515136 logging_writer.py:48] [29300] global_step=29300, grad_norm=0.15950660407543182, loss=0.3541790246963501
I0204 20:41:47.972602 140392884336384 logging_writer.py:48] [29400] global_step=29400, grad_norm=0.1125829815864563, loss=0.18901093304157257
I0204 20:42:11.834844 140397011515136 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.06280785799026489, loss=0.2250807285308838
I0204 20:42:35.647269 140392884336384 logging_writer.py:48] [29600] global_step=29600, grad_norm=0.07151162624359131, loss=0.20614805817604065
I0204 20:42:39.856631 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:42:41.236022 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:42:42.566284 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:42:43.897367 140584300062528 submission_runner.py:408] Time since start: 7272.20s, 	Step: 29619, 	{'train/ssim': 0.7528404508318219, 'train/loss': 0.2572024720055716, 'validation/ssim': 0.7247044483328644, 'validation/loss': 0.2851512181202079, 'validation/num_examples': 3554, 'test/ssim': 0.742045556190659, 'test/loss': 0.2864549813141406, 'test/num_examples': 3581, 'score': 6913.852163553238, 'total_duration': 7272.19589304924, 'accumulated_submission_time': 6913.852163553238, 'accumulated_eval_time': 351.7384581565857, 'accumulated_logging_time': 5.566555500030518}
I0204 20:42:43.920501 140397011515136 logging_writer.py:48] [29619] accumulated_eval_time=351.738458, accumulated_logging_time=5.566556, accumulated_submission_time=6913.852164, global_step=29619, preemption_count=0, score=6913.852164, test/loss=0.286455, test/num_examples=3581, test/ssim=0.742046, total_duration=7272.195893, train/loss=0.257202, train/ssim=0.752840, validation/loss=0.285151, validation/num_examples=3554, validation/ssim=0.724704
I0204 20:43:01.177561 140392884336384 logging_writer.py:48] [29700] global_step=29700, grad_norm=0.035932280123233795, loss=0.31045350432395935
I0204 20:43:25.156121 140397011515136 logging_writer.py:48] [29800] global_step=29800, grad_norm=0.04976479336619377, loss=0.3587172329425812
I0204 20:43:49.019943 140392884336384 logging_writer.py:48] [29900] global_step=29900, grad_norm=0.06219407916069031, loss=0.2641417980194092
I0204 20:44:04.035643 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:44:05.414554 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:44:06.744614 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:44:08.073463 140584300062528 submission_runner.py:408] Time since start: 7356.37s, 	Step: 29964, 	{'train/ssim': 0.7542448725019183, 'train/loss': 0.2572521822793143, 'validation/ssim': 0.7264857681265827, 'validation/loss': 0.2851106367824986, 'validation/num_examples': 3554, 'test/ssim': 0.7436717740985409, 'test/loss': 0.28646960520804243, 'test/num_examples': 3581, 'score': 6993.946165800095, 'total_duration': 7356.371992826462, 'accumulated_submission_time': 6993.946165800095, 'accumulated_eval_time': 355.77624320983887, 'accumulated_logging_time': 5.598665475845337}
I0204 20:44:08.095965 140397011515136 logging_writer.py:48] [29964] accumulated_eval_time=355.776243, accumulated_logging_time=5.598665, accumulated_submission_time=6993.946166, global_step=29964, preemption_count=0, score=6993.946166, test/loss=0.286470, test/num_examples=3581, test/ssim=0.743672, total_duration=7356.371993, train/loss=0.257252, train/ssim=0.754245, validation/loss=0.285111, validation/num_examples=3554, validation/ssim=0.726486
I0204 20:44:14.739796 140392884336384 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.043752361088991165, loss=0.3227071762084961
I0204 20:44:38.323401 140397011515136 logging_writer.py:48] [30100] global_step=30100, grad_norm=0.05931573361158371, loss=0.22626855969429016
I0204 20:45:02.504550 140392884336384 logging_writer.py:48] [30200] global_step=30200, grad_norm=0.07411867380142212, loss=0.2820436358451843
I0204 20:45:26.609272 140397011515136 logging_writer.py:48] [30300] global_step=30300, grad_norm=0.04265187680721283, loss=0.2980745732784271
I0204 20:45:28.242908 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:45:29.622768 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:45:30.953940 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:45:32.282571 140584300062528 submission_runner.py:408] Time since start: 7440.58s, 	Step: 30308, 	{'train/ssim': 0.7539666720799038, 'train/loss': 0.2571421350751604, 'validation/ssim': 0.726212775767621, 'validation/loss': 0.2849134832670934, 'validation/num_examples': 3554, 'test/ssim': 0.7434445412856046, 'test/loss': 0.2862640184851473, 'test/num_examples': 3581, 'score': 7074.071465730667, 'total_duration': 7440.581089496613, 'accumulated_submission_time': 7074.071465730667, 'accumulated_eval_time': 359.8158543109894, 'accumulated_logging_time': 5.6307532787323}
I0204 20:45:32.305152 140392884336384 logging_writer.py:48] [30308] accumulated_eval_time=359.815854, accumulated_logging_time=5.630753, accumulated_submission_time=7074.071466, global_step=30308, preemption_count=0, score=7074.071466, test/loss=0.286264, test/num_examples=3581, test/ssim=0.743445, total_duration=7440.581089, train/loss=0.257142, train/ssim=0.753967, validation/loss=0.284913, validation/num_examples=3554, validation/ssim=0.726213
I0204 20:45:52.023443 140397011515136 logging_writer.py:48] [30400] global_step=30400, grad_norm=0.09918417781591415, loss=0.2850816249847412
I0204 20:46:16.261224 140392884336384 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.0632985532283783, loss=0.22965018451213837
I0204 20:46:40.012926 140397011515136 logging_writer.py:48] [30600] global_step=30600, grad_norm=0.03758087381720543, loss=0.28154295682907104
I0204 20:46:52.298916 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:46:53.680135 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:46:55.010082 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:46:56.338235 140584300062528 submission_runner.py:408] Time since start: 7524.64s, 	Step: 30653, 	{'train/ssim': 0.7541763441903251, 'train/loss': 0.2566960198538644, 'validation/ssim': 0.7259604604846651, 'validation/loss': 0.2849078674831616, 'validation/num_examples': 3554, 'test/ssim': 0.7432008778972354, 'test/loss': 0.2862637798668319, 'test/num_examples': 3581, 'score': 7154.043691635132, 'total_duration': 7524.636759996414, 'accumulated_submission_time': 7154.043691635132, 'accumulated_eval_time': 363.8551321029663, 'accumulated_logging_time': 5.6625776290893555}
I0204 20:46:56.361973 140392884336384 logging_writer.py:48] [30653] accumulated_eval_time=363.855132, accumulated_logging_time=5.662578, accumulated_submission_time=7154.043692, global_step=30653, preemption_count=0, score=7154.043692, test/loss=0.286264, test/num_examples=3581, test/ssim=0.743201, total_duration=7524.636760, train/loss=0.256696, train/ssim=0.754176, validation/loss=0.284908, validation/num_examples=3554, validation/ssim=0.725960
I0204 20:47:05.716536 140397011515136 logging_writer.py:48] [30700] global_step=30700, grad_norm=0.03676268458366394, loss=0.2915620803833008
I0204 20:47:29.578049 140392884336384 logging_writer.py:48] [30800] global_step=30800, grad_norm=0.034583646804094315, loss=0.28373080492019653
I0204 20:47:53.351485 140397011515136 logging_writer.py:48] [30900] global_step=30900, grad_norm=0.055349964648485184, loss=0.2173047959804535
I0204 20:48:16.484075 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:48:17.865017 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:48:19.194334 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:48:20.524162 140584300062528 submission_runner.py:408] Time since start: 7608.82s, 	Step: 30998, 	{'train/ssim': 0.7537750516619001, 'train/loss': 0.25694710867745535, 'validation/ssim': 0.7257893422244303, 'validation/loss': 0.28485844171510094, 'validation/num_examples': 3554, 'test/ssim': 0.7430420262758308, 'test/loss': 0.2861960122652541, 'test/num_examples': 3581, 'score': 7234.144478082657, 'total_duration': 7608.822690963745, 'accumulated_submission_time': 7234.144478082657, 'accumulated_eval_time': 367.8951904773712, 'accumulated_logging_time': 5.695420980453491}
I0204 20:48:20.547099 140392884336384 logging_writer.py:48] [30998] accumulated_eval_time=367.895190, accumulated_logging_time=5.695421, accumulated_submission_time=7234.144478, global_step=30998, preemption_count=0, score=7234.144478, test/loss=0.286196, test/num_examples=3581, test/ssim=0.743042, total_duration=7608.822691, train/loss=0.256947, train/ssim=0.753775, validation/loss=0.284858, validation/num_examples=3554, validation/ssim=0.725789
I0204 20:48:20.782878 140397011515136 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.034735679626464844, loss=0.2588072419166565
I0204 20:48:42.862904 140392884336384 logging_writer.py:48] [31100] global_step=31100, grad_norm=0.036318037658929825, loss=0.21340586245059967
I0204 20:49:06.657813 140397011515136 logging_writer.py:48] [31200] global_step=31200, grad_norm=0.039108023047447205, loss=0.23943820595741272
I0204 20:49:30.783543 140392884336384 logging_writer.py:48] [31300] global_step=31300, grad_norm=0.027126234024763107, loss=0.25832098722457886
I0204 20:49:40.599301 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:49:41.980077 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:49:43.311894 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:49:44.643305 140584300062528 submission_runner.py:408] Time since start: 7692.94s, 	Step: 31341, 	{'train/ssim': 0.7542284556797573, 'train/loss': 0.2569677489144461, 'validation/ssim': 0.7263002926939716, 'validation/loss': 0.2848178260300893, 'validation/num_examples': 3554, 'test/ssim': 0.7435245806862608, 'test/loss': 0.2861467205389556, 'test/num_examples': 3581, 'score': 7314.175801992416, 'total_duration': 7692.941826343536, 'accumulated_submission_time': 7314.175801992416, 'accumulated_eval_time': 371.93916368484497, 'accumulated_logging_time': 5.727295398712158}
I0204 20:49:44.667156 140397011515136 logging_writer.py:48] [31341] accumulated_eval_time=371.939164, accumulated_logging_time=5.727295, accumulated_submission_time=7314.175802, global_step=31341, preemption_count=0, score=7314.175802, test/loss=0.286147, test/num_examples=3581, test/ssim=0.743525, total_duration=7692.941826, train/loss=0.256968, train/ssim=0.754228, validation/loss=0.284818, validation/num_examples=3554, validation/ssim=0.726300
I0204 20:49:56.898160 140392884336384 logging_writer.py:48] [31400] global_step=31400, grad_norm=0.038759928196668625, loss=0.29959437251091003
I0204 20:50:20.783729 140397011515136 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.029610658064484596, loss=0.3105764389038086
I0204 20:50:44.886675 140392884336384 logging_writer.py:48] [31600] global_step=31600, grad_norm=0.023893559351563454, loss=0.22742919623851776
I0204 20:51:04.844708 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:51:06.225513 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:51:07.555037 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:51:08.885746 140584300062528 submission_runner.py:408] Time since start: 7777.18s, 	Step: 31686, 	{'train/ssim': 0.754953111921038, 'train/loss': 0.2564511299133301, 'validation/ssim': 0.7265166806986846, 'validation/loss': 0.28481026962357553, 'validation/num_examples': 3554, 'test/ssim': 0.743722633888055, 'test/loss': 0.2861874220058992, 'test/num_examples': 3581, 'score': 7394.33158826828, 'total_duration': 7777.184247970581, 'accumulated_submission_time': 7394.33158826828, 'accumulated_eval_time': 375.98014068603516, 'accumulated_logging_time': 5.7609148025512695}
I0204 20:51:08.913227 140397011515136 logging_writer.py:48] [31686] accumulated_eval_time=375.980141, accumulated_logging_time=5.760915, accumulated_submission_time=7394.331588, global_step=31686, preemption_count=0, score=7394.331588, test/loss=0.286187, test/num_examples=3581, test/ssim=0.743723, total_duration=7777.184248, train/loss=0.256451, train/ssim=0.754953, validation/loss=0.284810, validation/num_examples=3554, validation/ssim=0.726517
I0204 20:51:10.187778 140392884336384 logging_writer.py:48] [31700] global_step=31700, grad_norm=0.032804328948259354, loss=0.25988537073135376
I0204 20:51:33.668037 140397011515136 logging_writer.py:48] [31800] global_step=31800, grad_norm=0.06924338638782501, loss=0.2775837779045105
I0204 20:51:57.321604 140392884336384 logging_writer.py:48] [31900] global_step=31900, grad_norm=0.03911881148815155, loss=0.34083011746406555
I0204 20:52:21.047422 140397011515136 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.024830538779497147, loss=0.17149603366851807
I0204 20:52:28.912497 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:52:30.292787 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:52:31.627415 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:52:32.961959 140584300062528 submission_runner.py:408] Time since start: 7861.26s, 	Step: 32034, 	{'train/ssim': 0.7544609478541783, 'train/loss': 0.25668537616729736, 'validation/ssim': 0.7263270148951885, 'validation/loss': 0.28476922459728476, 'validation/num_examples': 3554, 'test/ssim': 0.743590030281346, 'test/loss': 0.28611085961498184, 'test/num_examples': 3581, 'score': 7474.308657169342, 'total_duration': 7861.260461330414, 'accumulated_submission_time': 7474.308657169342, 'accumulated_eval_time': 380.0295407772064, 'accumulated_logging_time': 5.798375606536865}
I0204 20:52:32.989104 140392884336384 logging_writer.py:48] [32034] accumulated_eval_time=380.029541, accumulated_logging_time=5.798376, accumulated_submission_time=7474.308657, global_step=32034, preemption_count=0, score=7474.308657, test/loss=0.286111, test/num_examples=3581, test/ssim=0.743590, total_duration=7861.260461, train/loss=0.256685, train/ssim=0.754461, validation/loss=0.284769, validation/num_examples=3554, validation/ssim=0.726327
I0204 20:52:46.609589 140397011515136 logging_writer.py:48] [32100] global_step=32100, grad_norm=0.02039622887969017, loss=0.2701379358768463
I0204 20:53:10.593713 140392884336384 logging_writer.py:48] [32200] global_step=32200, grad_norm=0.0451330840587616, loss=0.26711130142211914
I0204 20:53:34.493068 140397011515136 logging_writer.py:48] [32300] global_step=32300, grad_norm=0.018596718087792397, loss=0.2728397846221924
I0204 20:53:52.962248 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:53:54.348612 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:53:55.680141 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:53:57.010746 140584300062528 submission_runner.py:408] Time since start: 7945.31s, 	Step: 32378, 	{'train/ssim': 0.7543185779026577, 'train/loss': 0.2567593199866159, 'validation/ssim': 0.7262754252470808, 'validation/loss': 0.284801098893852, 'validation/num_examples': 3554, 'test/ssim': 0.7435266259861072, 'test/loss': 0.2861430049109013, 'test/num_examples': 3581, 'score': 7554.259472131729, 'total_duration': 7945.309270620346, 'accumulated_submission_time': 7554.259472131729, 'accumulated_eval_time': 384.07799434661865, 'accumulated_logging_time': 5.836031198501587}
I0204 20:53:57.033818 140392884336384 logging_writer.py:48] [32378] accumulated_eval_time=384.077994, accumulated_logging_time=5.836031, accumulated_submission_time=7554.259472, global_step=32378, preemption_count=0, score=7554.259472, test/loss=0.286143, test/num_examples=3581, test/ssim=0.743527, total_duration=7945.309271, train/loss=0.256759, train/ssim=0.754319, validation/loss=0.284801, validation/num_examples=3554, validation/ssim=0.726275
I0204 20:54:00.217677 140397011515136 logging_writer.py:48] [32400] global_step=32400, grad_norm=0.04400097578763962, loss=0.24630001187324524
I0204 20:54:24.552561 140392884336384 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.020057925954461098, loss=0.22943583130836487
I0204 20:54:48.317035 140397011515136 logging_writer.py:48] [32600] global_step=32600, grad_norm=0.03285827115178108, loss=0.33486226201057434
I0204 20:55:12.461525 140392884336384 logging_writer.py:48] [32700] global_step=32700, grad_norm=0.03103030100464821, loss=0.27565792202949524
I0204 20:55:17.143595 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:55:18.526292 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:55:19.855525 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:55:21.187112 140584300062528 submission_runner.py:408] Time since start: 8029.49s, 	Step: 32721, 	{'train/ssim': 0.7552104677472796, 'train/loss': 0.2563129663467407, 'validation/ssim': 0.7266483682558385, 'validation/loss': 0.28486709723528947, 'validation/num_examples': 3554, 'test/ssim': 0.7438551011414409, 'test/loss': 0.2862320777192125, 'test/num_examples': 3581, 'score': 7634.3465123176575, 'total_duration': 8029.485631227493, 'accumulated_submission_time': 7634.3465123176575, 'accumulated_eval_time': 388.12148785591125, 'accumulated_logging_time': 5.869813680648804}
I0204 20:55:21.210816 140397011515136 logging_writer.py:48] [32721] accumulated_eval_time=388.121488, accumulated_logging_time=5.869814, accumulated_submission_time=7634.346512, global_step=32721, preemption_count=0, score=7634.346512, test/loss=0.286232, test/num_examples=3581, test/ssim=0.743855, total_duration=8029.485631, train/loss=0.256313, train/ssim=0.755210, validation/loss=0.284867, validation/num_examples=3554, validation/ssim=0.726648
I0204 20:55:38.031174 140392884336384 logging_writer.py:48] [32800] global_step=32800, grad_norm=0.048695482313632965, loss=0.25540339946746826
I0204 20:56:01.704090 140397011515136 logging_writer.py:48] [32900] global_step=32900, grad_norm=0.029352398589253426, loss=0.21070793271064758
I0204 20:56:25.496074 140392884336384 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.07909319549798965, loss=0.3306107521057129
I0204 20:56:41.298024 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:56:42.681279 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:56:44.009824 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:56:45.338371 140584300062528 submission_runner.py:408] Time since start: 8113.64s, 	Step: 33067, 	{'train/ssim': 0.7548089027404785, 'train/loss': 0.2565027305058071, 'validation/ssim': 0.72650617042417, 'validation/loss': 0.28471876841015403, 'validation/num_examples': 3554, 'test/ssim': 0.7437527679724588, 'test/loss': 0.28608805452169433, 'test/num_examples': 3581, 'score': 7714.412069559097, 'total_duration': 8113.636897563934, 'accumulated_submission_time': 7714.412069559097, 'accumulated_eval_time': 392.1617946624756, 'accumulated_logging_time': 5.903012752532959}
I0204 20:56:45.362170 140397011515136 logging_writer.py:48] [33067] accumulated_eval_time=392.161795, accumulated_logging_time=5.903013, accumulated_submission_time=7714.412070, global_step=33067, preemption_count=0, score=7714.412070, test/loss=0.286088, test/num_examples=3581, test/ssim=0.743753, total_duration=8113.636898, train/loss=0.256503, train/ssim=0.754809, validation/loss=0.284719, validation/num_examples=3554, validation/ssim=0.726506
I0204 20:56:51.148909 140392884336384 logging_writer.py:48] [33100] global_step=33100, grad_norm=0.022363075986504555, loss=0.22419053316116333
I0204 20:57:14.820088 140397011515136 logging_writer.py:48] [33200] global_step=33200, grad_norm=0.02425290085375309, loss=0.3529825210571289
I0204 20:57:38.342407 140392884336384 logging_writer.py:48] [33300] global_step=33300, grad_norm=0.05258452892303467, loss=0.3153577744960785
I0204 20:58:02.354852 140397011515136 logging_writer.py:48] [33400] global_step=33400, grad_norm=0.025435294955968857, loss=0.25428611040115356
I0204 20:58:05.440330 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:58:06.823033 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:58:08.152184 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:58:09.485275 140584300062528 submission_runner.py:408] Time since start: 8197.78s, 	Step: 33414, 	{'train/ssim': 0.7544290678841727, 'train/loss': 0.2566244602203369, 'validation/ssim': 0.7261439437737408, 'validation/loss': 0.2848105444019942, 'validation/num_examples': 3554, 'test/ssim': 0.743361842995148, 'test/loss': 0.28615657206654915, 'test/num_examples': 3581, 'score': 7794.4692351818085, 'total_duration': 8197.783804655075, 'accumulated_submission_time': 7794.4692351818085, 'accumulated_eval_time': 396.20669984817505, 'accumulated_logging_time': 5.935891389846802}
I0204 20:58:09.508491 140392884336384 logging_writer.py:48] [33414] accumulated_eval_time=396.206700, accumulated_logging_time=5.935891, accumulated_submission_time=7794.469235, global_step=33414, preemption_count=0, score=7794.469235, test/loss=0.286157, test/num_examples=3581, test/ssim=0.743362, total_duration=8197.783805, train/loss=0.256624, train/ssim=0.754429, validation/loss=0.284811, validation/num_examples=3554, validation/ssim=0.726144
I0204 20:58:28.067435 140397011515136 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.026649046689271927, loss=0.2645103335380554
I0204 20:58:52.092975 140392884336384 logging_writer.py:48] [33600] global_step=33600, grad_norm=0.0242508202791214, loss=0.2953752279281616
I0204 20:59:15.986815 140397011515136 logging_writer.py:48] [33700] global_step=33700, grad_norm=0.01922551542520523, loss=0.2558728754520416
I0204 20:59:29.519346 140584300062528 spec.py:321] Evaluating on the training split.
I0204 20:59:30.901636 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 20:59:32.233621 140584300062528 spec.py:349] Evaluating on the test split.
I0204 20:59:33.563645 140584300062528 submission_runner.py:408] Time since start: 8281.86s, 	Step: 33758, 	{'train/ssim': 0.7553148950849261, 'train/loss': 0.25630225454057964, 'validation/ssim': 0.7268665423202729, 'validation/loss': 0.2847635572923994, 'validation/num_examples': 3554, 'test/ssim': 0.7440031808503211, 'test/loss': 0.28615149290526387, 'test/num_examples': 3581, 'score': 7874.45870757103, 'total_duration': 8281.86214709282, 'accumulated_submission_time': 7874.45870757103, 'accumulated_eval_time': 400.2509334087372, 'accumulated_logging_time': 5.968505382537842}
I0204 20:59:33.587450 140392884336384 logging_writer.py:48] [33758] accumulated_eval_time=400.250933, accumulated_logging_time=5.968505, accumulated_submission_time=7874.458708, global_step=33758, preemption_count=0, score=7874.458708, test/loss=0.286151, test/num_examples=3581, test/ssim=0.744003, total_duration=8281.862147, train/loss=0.256302, train/ssim=0.755315, validation/loss=0.284764, validation/num_examples=3554, validation/ssim=0.726867
I0204 20:59:41.596311 140397011515136 logging_writer.py:48] [33800] global_step=33800, grad_norm=0.019913723692297935, loss=0.2407132387161255
I0204 21:00:05.796635 140392884336384 logging_writer.py:48] [33900] global_step=33900, grad_norm=0.018066564574837685, loss=0.283951073884964
I0204 21:00:29.536591 140397011515136 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.015476938337087631, loss=0.27860286831855774
I0204 21:00:53.383792 140392884336384 logging_writer.py:48] [34100] global_step=34100, grad_norm=0.03885747119784355, loss=0.2577730417251587
I0204 21:00:53.577350 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:00:54.957920 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:00:56.286702 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:00:57.617776 140584300062528 submission_runner.py:408] Time since start: 8365.92s, 	Step: 34102, 	{'train/ssim': 0.7551569257463727, 'train/loss': 0.2563475711005075, 'validation/ssim': 0.7268275924794246, 'validation/loss': 0.2846378805131542, 'validation/num_examples': 3554, 'test/ssim': 0.7439999083705668, 'test/loss': 0.2860142191972389, 'test/num_examples': 3581, 'score': 7954.426274776459, 'total_duration': 8365.916305065155, 'accumulated_submission_time': 7954.426274776459, 'accumulated_eval_time': 404.29131865501404, 'accumulated_logging_time': 6.002583742141724}
I0204 21:00:57.641330 140397011515136 logging_writer.py:48] [34102] accumulated_eval_time=404.291319, accumulated_logging_time=6.002584, accumulated_submission_time=7954.426275, global_step=34102, preemption_count=0, score=7954.426275, test/loss=0.286014, test/num_examples=3581, test/ssim=0.744000, total_duration=8365.916305, train/loss=0.256348, train/ssim=0.755157, validation/loss=0.284638, validation/num_examples=3554, validation/ssim=0.726828
I0204 21:01:18.852015 140392884336384 logging_writer.py:48] [34200] global_step=34200, grad_norm=0.02114798128604889, loss=0.2667165994644165
I0204 21:01:42.893932 140397011515136 logging_writer.py:48] [34300] global_step=34300, grad_norm=0.027396759018301964, loss=0.22487258911132812
I0204 21:02:06.871256 140392884336384 logging_writer.py:48] [34400] global_step=34400, grad_norm=0.02476935274899006, loss=0.3325082063674927
I0204 21:02:17.748534 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:02:19.133839 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:02:20.464790 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:02:21.795048 140584300062528 submission_runner.py:408] Time since start: 8450.09s, 	Step: 34447, 	{'train/ssim': 0.7550387382507324, 'train/loss': 0.2563768284661429, 'validation/ssim': 0.7268162578696539, 'validation/loss': 0.28464365085994653, 'validation/num_examples': 3554, 'test/ssim': 0.7439937724710276, 'test/loss': 0.28599328896214393, 'test/num_examples': 3581, 'score': 8034.5121150016785, 'total_duration': 8450.093579769135, 'accumulated_submission_time': 8034.5121150016785, 'accumulated_eval_time': 408.3378036022186, 'accumulated_logging_time': 6.035517454147339}
I0204 21:02:21.818608 140397011515136 logging_writer.py:48] [34447] accumulated_eval_time=408.337804, accumulated_logging_time=6.035517, accumulated_submission_time=8034.512115, global_step=34447, preemption_count=0, score=8034.512115, test/loss=0.285993, test/num_examples=3581, test/ssim=0.743994, total_duration=8450.093580, train/loss=0.256377, train/ssim=0.755039, validation/loss=0.284644, validation/num_examples=3554, validation/ssim=0.726816
I0204 21:02:32.414300 140392884336384 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.019667452201247215, loss=0.2209576666355133
I0204 21:02:56.551983 140397011515136 logging_writer.py:48] [34600] global_step=34600, grad_norm=0.018169760704040527, loss=0.25742483139038086
I0204 21:03:20.370530 140392884336384 logging_writer.py:48] [34700] global_step=34700, grad_norm=0.026467936113476753, loss=0.24448123574256897
I0204 21:03:41.988286 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:03:43.368464 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:03:44.696904 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:03:46.030722 140584300062528 submission_runner.py:408] Time since start: 8534.33s, 	Step: 34791, 	{'train/ssim': 0.7547637394496373, 'train/loss': 0.25628459453582764, 'validation/ssim': 0.726274326133406, 'validation/loss': 0.28467222781548956, 'validation/num_examples': 3554, 'test/ssim': 0.7435064456942893, 'test/loss': 0.286050932329482, 'test/num_examples': 3581, 'score': 8114.659774541855, 'total_duration': 8534.329248189926, 'accumulated_submission_time': 8114.659774541855, 'accumulated_eval_time': 412.38020157814026, 'accumulated_logging_time': 6.069193363189697}
I0204 21:03:46.054320 140397011515136 logging_writer.py:48] [34791] accumulated_eval_time=412.380202, accumulated_logging_time=6.069193, accumulated_submission_time=8114.659775, global_step=34791, preemption_count=0, score=8114.659775, test/loss=0.286051, test/num_examples=3581, test/ssim=0.743506, total_duration=8534.329248, train/loss=0.256285, train/ssim=0.754764, validation/loss=0.284672, validation/num_examples=3554, validation/ssim=0.726274
I0204 21:03:46.802727 140392884336384 logging_writer.py:48] [34800] global_step=34800, grad_norm=0.017716029658913612, loss=0.2276580035686493
I0204 21:04:10.091165 140397011515136 logging_writer.py:48] [34900] global_step=34900, grad_norm=0.018547913059592247, loss=0.29812324047088623
I0204 21:04:34.037233 140392884336384 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.022560304030776024, loss=0.24880792200565338
I0204 21:04:57.860043 140397011515136 logging_writer.py:48] [35100] global_step=35100, grad_norm=0.017197584733366966, loss=0.3013339042663574
I0204 21:05:06.063493 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:05:07.447267 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:05:08.776518 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:05:10.107167 140584300062528 submission_runner.py:408] Time since start: 8618.41s, 	Step: 35135, 	{'train/ssim': 0.7552019527980259, 'train/loss': 0.25622529642922537, 'validation/ssim': 0.726717131555114, 'validation/loss': 0.28462024317340495, 'validation/num_examples': 3554, 'test/ssim': 0.7439281865226194, 'test/loss': 0.28600491308293774, 'test/num_examples': 3581, 'score': 8194.64580988884, 'total_duration': 8618.405655145645, 'accumulated_submission_time': 8194.64580988884, 'accumulated_eval_time': 416.4238030910492, 'accumulated_logging_time': 6.104076862335205}
I0204 21:05:10.135179 140392884336384 logging_writer.py:48] [35135] accumulated_eval_time=416.423803, accumulated_logging_time=6.104077, accumulated_submission_time=8194.645810, global_step=35135, preemption_count=0, score=8194.645810, test/loss=0.286005, test/num_examples=3581, test/ssim=0.743928, total_duration=8618.405655, train/loss=0.256225, train/ssim=0.755202, validation/loss=0.284620, validation/num_examples=3554, validation/ssim=0.726717
I0204 21:05:23.595239 140397011515136 logging_writer.py:48] [35200] global_step=35200, grad_norm=0.02349444292485714, loss=0.23139125108718872
I0204 21:05:47.661549 140392884336384 logging_writer.py:48] [35300] global_step=35300, grad_norm=0.012260757386684418, loss=0.27900049090385437
I0204 21:06:11.525836 140397011515136 logging_writer.py:48] [35400] global_step=35400, grad_norm=0.015578702092170715, loss=0.32163387537002563
I0204 21:06:30.118343 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:06:31.499187 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:06:32.831089 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:06:34.159754 140584300062528 submission_runner.py:408] Time since start: 8702.46s, 	Step: 35479, 	{'train/ssim': 0.755331311907087, 'train/loss': 0.2562356335776193, 'validation/ssim': 0.726912018148565, 'validation/loss': 0.2846041171149585, 'validation/num_examples': 3554, 'test/ssim': 0.7441111726822117, 'test/loss': 0.2859727677870183, 'test/num_examples': 3581, 'score': 8274.605695009232, 'total_duration': 8702.45828127861, 'accumulated_submission_time': 8274.605695009232, 'accumulated_eval_time': 420.46518874168396, 'accumulated_logging_time': 6.143252611160278}
I0204 21:06:34.185441 140392884336384 logging_writer.py:48] [35479] accumulated_eval_time=420.465189, accumulated_logging_time=6.143253, accumulated_submission_time=8274.605695, global_step=35479, preemption_count=0, score=8274.605695, test/loss=0.285973, test/num_examples=3581, test/ssim=0.744111, total_duration=8702.458281, train/loss=0.256236, train/ssim=0.755331, validation/loss=0.284604, validation/num_examples=3554, validation/ssim=0.726912
I0204 21:06:37.068268 140397011515136 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.022437386214733124, loss=0.31559881567955017
I0204 21:07:00.865952 140392884336384 logging_writer.py:48] [35600] global_step=35600, grad_norm=0.025732191279530525, loss=0.21167337894439697
I0204 21:07:25.502648 140397011515136 logging_writer.py:48] [35700] global_step=35700, grad_norm=0.01739603839814663, loss=0.2111513465642929
I0204 21:07:49.236056 140392884336384 logging_writer.py:48] [35800] global_step=35800, grad_norm=0.025833187624812126, loss=0.24394002556800842
I0204 21:07:54.301378 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:07:55.685126 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:07:57.015619 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:07:58.347778 140584300062528 submission_runner.py:408] Time since start: 8786.65s, 	Step: 35821, 	{'train/ssim': 0.7551850591387067, 'train/loss': 0.25622785091400146, 'validation/ssim': 0.7267806053698298, 'validation/loss': 0.28460700228835467, 'validation/num_examples': 3554, 'test/ssim': 0.7439823869685492, 'test/loss': 0.28597839236159595, 'test/num_examples': 3581, 'score': 8354.700634717941, 'total_duration': 8786.64630651474, 'accumulated_submission_time': 8354.700634717941, 'accumulated_eval_time': 424.51155495643616, 'accumulated_logging_time': 6.178053855895996}
I0204 21:07:58.371641 140397011515136 logging_writer.py:48] [35821] accumulated_eval_time=424.511555, accumulated_logging_time=6.178054, accumulated_submission_time=8354.700635, global_step=35821, preemption_count=0, score=8354.700635, test/loss=0.285978, test/num_examples=3581, test/ssim=0.743982, total_duration=8786.646307, train/loss=0.256228, train/ssim=0.755185, validation/loss=0.284607, validation/num_examples=3554, validation/ssim=0.726781
I0204 21:08:15.469684 140392884336384 logging_writer.py:48] [35900] global_step=35900, grad_norm=0.018384525552392006, loss=0.2201889157295227
I0204 21:08:39.303293 140397011515136 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.018143316730856895, loss=0.23600494861602783
I0204 21:09:03.185624 140392884336384 logging_writer.py:48] [36100] global_step=36100, grad_norm=0.018603671342134476, loss=0.3726367652416229
I0204 21:09:18.468627 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:09:19.848695 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:09:21.176131 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:09:22.507454 140584300062528 submission_runner.py:408] Time since start: 8870.81s, 	Step: 36165, 	{'train/ssim': 0.7552205494471959, 'train/loss': 0.25620695522853304, 'validation/ssim': 0.7267984659670442, 'validation/loss': 0.2845921470800946, 'validation/num_examples': 3554, 'test/ssim': 0.7439969767741204, 'test/loss': 0.2859633934960556, 'test/num_examples': 3581, 'score': 8434.776199579239, 'total_duration': 8870.805983543396, 'accumulated_submission_time': 8434.776199579239, 'accumulated_eval_time': 428.55034279823303, 'accumulated_logging_time': 6.211203336715698}
I0204 21:09:22.531735 140397011515136 logging_writer.py:48] [36165] accumulated_eval_time=428.550343, accumulated_logging_time=6.211203, accumulated_submission_time=8434.776200, global_step=36165, preemption_count=0, score=8434.776200, test/loss=0.285963, test/num_examples=3581, test/ssim=0.743997, total_duration=8870.805984, train/loss=0.256207, train/ssim=0.755221, validation/loss=0.284592, validation/num_examples=3554, validation/ssim=0.726798
I0204 21:09:25.803097 140584300062528 spec.py:321] Evaluating on the training split.
I0204 21:09:27.186062 140584300062528 spec.py:333] Evaluating on the validation split.
I0204 21:09:28.519263 140584300062528 spec.py:349] Evaluating on the test split.
I0204 21:09:29.846518 140584300062528 submission_runner.py:408] Time since start: 8878.15s, 	Step: 36189, 	{'train/ssim': 0.7552202088492257, 'train/loss': 0.256206887108939, 'validation/ssim': 0.7267981224940209, 'validation/loss': 0.28459212990644345, 'validation/num_examples': 3554, 'test/ssim': 0.7439967040674742, 'test/loss': 0.28596335940772477, 'test/num_examples': 3581, 'score': 8438.036951065063, 'total_duration': 8878.14504647255, 'accumulated_submission_time': 8438.036951065063, 'accumulated_eval_time': 432.59374141693115, 'accumulated_logging_time': 6.244928598403931}
I0204 21:09:29.870324 140392884336384 logging_writer.py:48] [36189] accumulated_eval_time=432.593741, accumulated_logging_time=6.244929, accumulated_submission_time=8438.036951, global_step=36189, preemption_count=0, score=8438.036951, test/loss=0.285963, test/num_examples=3581, test/ssim=0.743997, total_duration=8878.145046, train/loss=0.256207, train/ssim=0.755220, validation/loss=0.284592, validation/num_examples=3554, validation/ssim=0.726798
I0204 21:09:29.890962 140397011515136 logging_writer.py:48] [36189] global_step=36189, preemption_count=0, score=8438.036951
I0204 21:09:29.939045 140584300062528 checkpoints.py:490] Saving checkpoint at step: 36189
I0204 21:09:30.203128 140584300062528 checkpoints.py:422] Saved checkpoint at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4/checkpoint_36189
I0204 21:09:30.203851 140584300062528 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_4/checkpoint_36189.
I0204 21:09:30.843548 140584300062528 submission_runner.py:583] Tuning trial 4/5
I0204 21:09:30.843793 140584300062528 submission_runner.py:584] Hyperparameters: Hyperparameters(dropout_rate=0.0, label_smoothing=0.0, learning_rate=0.004958460849689891, one_minus_beta1=0.13625575743, beta2=0.6291854735396584, weight_decay=0.1147386261512052, warmup_factor=0.02)
I0204 21:09:30.850861 140584300062528 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/ssim': 0.2670762368610927, 'train/loss': 0.9032635007585798, 'validation/ssim': 0.2587972028106535, 'validation/loss': 0.915261701713738, 'validation/num_examples': 3554, 'test/ssim': 0.2829431162570249, 'test/loss': 0.9125136626029741, 'test/num_examples': 3581, 'score': 30.822123527526855, 'total_duration': 34.802770137786865, 'accumulated_submission_time': 30.822123527526855, 'accumulated_eval_time': 3.9805192947387695, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (344, {'train/ssim': 0.7226132665361676, 'train/loss': 0.28545098645346506, 'validation/ssim': 0.6983893313432048, 'validation/loss': 0.3115307191280951, 'validation/num_examples': 3554, 'test/ssim': 0.7153852090460067, 'test/loss': 0.3137289525010472, 'test/num_examples': 3581, 'score': 110.83161187171936, 'total_duration': 118.88110089302063, 'accumulated_submission_time': 110.83161187171936, 'accumulated_eval_time': 8.01711654663086, 'accumulated_logging_time': 0.020013809204101562, 'global_step': 344, 'preemption_count': 0}), (684, {'train/ssim': 0.7282571792602539, 'train/loss': 0.27705117634364534, 'validation/ssim': 0.7044029944252954, 'validation/loss': 0.30230977364852984, 'validation/num_examples': 3554, 'test/ssim': 0.7213692791599763, 'test/loss': 0.30420893392427045, 'test/num_examples': 3581, 'score': 191.00679397583008, 'total_duration': 203.1422142982483, 'accumulated_submission_time': 191.00679397583008, 'accumulated_eval_time': 12.06654405593872, 'accumulated_logging_time': 0.044104576110839844, 'global_step': 684, 'preemption_count': 0}), (1020, {'train/ssim': 0.7370714460100446, 'train/loss': 0.2704525334494455, 'validation/ssim': 0.711497979279509, 'validation/loss': 0.29614340246025606, 'validation/num_examples': 3554, 'test/ssim': 0.728832305592886, 'test/loss': 0.29805687651624896, 'test/num_examples': 3581, 'score': 271.02345633506775, 'total_duration': 287.2428436279297, 'accumulated_submission_time': 271.02345633506775, 'accumulated_eval_time': 16.10910677909851, 'accumulated_logging_time': 0.07337832450866699, 'global_step': 1020, 'preemption_count': 0}), (1366, {'train/ssim': 0.7303394590105329, 'train/loss': 0.27141354765210834, 'validation/ssim': 0.7056676620972847, 'validation/loss': 0.2970385618537212, 'validation/num_examples': 3554, 'test/ssim': 0.7230863083810388, 'test/loss': 0.2986054941117181, 'test/num_examples': 3581, 'score': 351.08174562454224, 'total_duration': 371.3848412036896, 'accumulated_submission_time': 351.08174562454224, 'accumulated_eval_time': 20.15527033805847, 'accumulated_logging_time': 0.09859204292297363, 'global_step': 1366, 'preemption_count': 0}), (1711, {'train/ssim': 0.7415225846426827, 'train/loss': 0.26839728014809744, 'validation/ssim': 0.7163652667988534, 'validation/loss': 0.29413257399233256, 'validation/num_examples': 3554, 'test/ssim': 0.7334914986430118, 'test/loss': 0.29592369695310317, 'test/num_examples': 3581, 'score': 431.05223202705383, 'total_duration': 455.43262481689453, 'accumulated_submission_time': 431.05223202705383, 'accumulated_eval_time': 24.19566798210144, 'accumulated_logging_time': 0.12353253364562988, 'global_step': 1711, 'preemption_count': 0}), (2055, {'train/ssim': 0.741027695792062, 'train/loss': 0.2685650076184954, 'validation/ssim': 0.71662994711065, 'validation/loss': 0.29432574322066685, 'validation/num_examples': 3554, 'test/ssim': 0.7336164664636274, 'test/loss': 0.29597431812430186, 'test/num_examples': 3581, 'score': 511.1865234375, 'total_duration': 539.6468026638031, 'accumulated_submission_time': 511.1865234375, 'accumulated_eval_time': 28.23944354057312, 'accumulated_logging_time': 0.14762616157531738, 'global_step': 2055, 'preemption_count': 0}), (2400, {'train/ssim': 0.7440621512276786, 'train/loss': 0.2670582021985735, 'validation/ssim': 0.7178861653462648, 'validation/loss': 0.2936223104688379, 'validation/num_examples': 3554, 'test/ssim': 0.735299339177255, 'test/loss': 0.29511058799916223, 'test/num_examples': 3581, 'score': 591.3152222633362, 'total_duration': 623.8655636310577, 'accumulated_submission_time': 591.3152222633362, 'accumulated_eval_time': 32.28887057304382, 'accumulated_logging_time': 0.17611455917358398, 'global_step': 2400, 'preemption_count': 0}), (2747, {'train/ssim': 0.7456315585545131, 'train/loss': 0.26643121242523193, 'validation/ssim': 0.7203574537492966, 'validation/loss': 0.29217999854916993, 'validation/num_examples': 3554, 'test/ssim': 0.7375439875820302, 'test/loss': 0.29371975001527156, 'test/num_examples': 3581, 'score': 671.4278931617737, 'total_duration': 708.0597774982452, 'accumulated_submission_time': 671.4278931617737, 'accumulated_eval_time': 36.32929086685181, 'accumulated_logging_time': 0.20500779151916504, 'global_step': 2747, 'preemption_count': 0}), (3093, {'train/ssim': 0.7441027505057198, 'train/loss': 0.26529085636138916, 'validation/ssim': 0.7181291381629854, 'validation/loss': 0.2911974939658659, 'validation/num_examples': 3554, 'test/ssim': 0.735590589875384, 'test/loss': 0.292780752855784, 'test/num_examples': 3581, 'score': 751.4628582000732, 'total_duration': 792.1761124134064, 'accumulated_submission_time': 751.4628582000732, 'accumulated_eval_time': 40.37436270713806, 'accumulated_logging_time': 0.22905254364013672, 'global_step': 3093, 'preemption_count': 0}), (3438, {'train/ssim': 0.7385843821934291, 'train/loss': 0.268498352595738, 'validation/ssim': 0.7121779871711452, 'validation/loss': 0.295027252523565, 'validation/num_examples': 3554, 'test/ssim': 0.7294369644041468, 'test/loss': 0.2967027175762706, 'test/num_examples': 3581, 'score': 831.4726746082306, 'total_duration': 876.2643911838531, 'accumulated_submission_time': 831.4726746082306, 'accumulated_eval_time': 44.415067195892334, 'accumulated_logging_time': 0.25493645668029785, 'global_step': 3438, 'preemption_count': 0}), (3783, {'train/ssim': 0.7476419040134975, 'train/loss': 0.2647112948553903, 'validation/ssim': 0.7219686170072454, 'validation/loss': 0.2910621999419668, 'validation/num_examples': 3554, 'test/ssim': 0.7389904236334125, 'test/loss': 0.29267153384398564, 'test/num_examples': 3581, 'score': 911.6228678226471, 'total_duration': 960.4981019496918, 'accumulated_submission_time': 911.6228678226471, 'accumulated_eval_time': 48.46218538284302, 'accumulated_logging_time': 0.2796492576599121, 'global_step': 3783, 'preemption_count': 0}), (4130, {'train/ssim': 0.744476454598563, 'train/loss': 0.2648463419505528, 'validation/ssim': 0.7180813954127392, 'validation/loss': 0.29101665541907007, 'validation/num_examples': 3554, 'test/ssim': 0.7354596225085521, 'test/loss': 0.29265022863725215, 'test/num_examples': 3581, 'score': 991.5995440483093, 'total_duration': 1044.5592665672302, 'accumulated_submission_time': 991.5995440483093, 'accumulated_eval_time': 52.50946092605591, 'accumulated_logging_time': 0.30477356910705566, 'global_step': 4130, 'preemption_count': 0}), (4472, {'train/ssim': 0.7401151657104492, 'train/loss': 0.26571357250213623, 'validation/ssim': 0.7127527549284257, 'validation/loss': 0.29230749573543896, 'validation/num_examples': 3554, 'test/ssim': 0.7306974145228288, 'test/loss': 0.2937538042577143, 'test/num_examples': 3581, 'score': 1071.6571695804596, 'total_duration': 1128.7016820907593, 'accumulated_submission_time': 1071.6571695804596, 'accumulated_eval_time': 56.5556275844574, 'accumulated_logging_time': 0.33159756660461426, 'global_step': 4472, 'preemption_count': 0}), (4819, {'train/ssim': 0.7446002279009137, 'train/loss': 0.26479571206229074, 'validation/ssim': 0.7191272020742473, 'validation/loss': 0.290804663869056, 'validation/num_examples': 3554, 'test/ssim': 0.7363732579499441, 'test/loss': 0.29227501838042796, 'test/num_examples': 3581, 'score': 1151.6270997524261, 'total_duration': 1212.7570588588715, 'accumulated_submission_time': 1151.6270997524261, 'accumulated_eval_time': 60.60241341590881, 'accumulated_logging_time': 0.3582265377044678, 'global_step': 4819, 'preemption_count': 0}), (5162, {'train/ssim': 0.7490038871765137, 'train/loss': 0.26482670647757395, 'validation/ssim': 0.7233019105893008, 'validation/loss': 0.2915698187231816, 'validation/num_examples': 3554, 'test/ssim': 0.7402641682010961, 'test/loss': 0.2931434867835451, 'test/num_examples': 3581, 'score': 1231.6058168411255, 'total_duration': 1296.8183772563934, 'accumulated_submission_time': 1231.6058168411255, 'accumulated_eval_time': 64.64353156089783, 'accumulated_logging_time': 0.3878440856933594, 'global_step': 5162, 'preemption_count': 0}), (5505, {'train/ssim': 0.7461484500340053, 'train/loss': 0.26515943663460867, 'validation/ssim': 0.7193948362540448, 'validation/loss': 0.29200328167865436, 'validation/num_examples': 3554, 'test/ssim': 0.7366458964194709, 'test/loss': 0.29348917654591944, 'test/num_examples': 3581, 'score': 1311.6497621536255, 'total_duration': 1380.9428961277008, 'accumulated_submission_time': 1311.6497621536255, 'accumulated_eval_time': 68.6874794960022, 'accumulated_logging_time': 0.4124460220336914, 'global_step': 5505, 'preemption_count': 0}), (5851, {'train/ssim': 0.7486353601728167, 'train/loss': 0.264972414289202, 'validation/ssim': 0.72320086082583, 'validation/loss': 0.2916949459455895, 'validation/num_examples': 3554, 'test/ssim': 0.7399766672193522, 'test/loss': 0.2933677880000349, 'test/num_examples': 3581, 'score': 1391.8070256710052, 'total_duration': 1465.185186624527, 'accumulated_submission_time': 1391.8070256710052, 'accumulated_eval_time': 72.73325824737549, 'accumulated_logging_time': 0.4397716522216797, 'global_step': 5851, 'preemption_count': 0}), (6197, {'train/ssim': 0.7402887344360352, 'train/loss': 0.26532416684286936, 'validation/ssim': 0.7139138311365715, 'validation/loss': 0.2915773751296954, 'validation/num_examples': 3554, 'test/ssim': 0.7316704318364283, 'test/loss': 0.29291339055082377, 'test/num_examples': 3581, 'score': 1471.9566292762756, 'total_duration': 1549.4155497550964, 'accumulated_submission_time': 1471.9566292762756, 'accumulated_eval_time': 76.77447819709778, 'accumulated_logging_time': 0.467041015625, 'global_step': 6197, 'preemption_count': 0}), (6540, {'train/ssim': 0.7448414393833706, 'train/loss': 0.2647097281047276, 'validation/ssim': 0.7187118744944077, 'validation/loss': 0.29138722846396664, 'validation/num_examples': 3554, 'test/ssim': 0.7359811057927255, 'test/loss': 0.2928044101573408, 'test/num_examples': 3581, 'score': 1551.9505987167358, 'total_duration': 1633.491622209549, 'accumulated_submission_time': 1551.9505987167358, 'accumulated_eval_time': 80.81879162788391, 'accumulated_logging_time': 0.4929647445678711, 'global_step': 6540, 'preemption_count': 0}), (6885, {'train/ssim': 0.7436417170933315, 'train/loss': 0.2659179653440203, 'validation/ssim': 0.716956727345069, 'validation/loss': 0.2928763901040201, 'validation/num_examples': 3554, 'test/ssim': 0.7342648946916015, 'test/loss': 0.2944325029234153, 'test/num_examples': 3581, 'score': 1632.0223336219788, 'total_duration': 1717.647849559784, 'accumulated_submission_time': 1632.0223336219788, 'accumulated_eval_time': 84.86484432220459, 'accumulated_logging_time': 0.5194802284240723, 'global_step': 6885, 'preemption_count': 0}), (7230, {'train/ssim': 0.7429020064217704, 'train/loss': 0.2644589628492083, 'validation/ssim': 0.7165945693892445, 'validation/loss': 0.2905732660932224, 'validation/num_examples': 3554, 'test/ssim': 0.7341480398937098, 'test/loss': 0.2919725526214744, 'test/num_examples': 3581, 'score': 1712.0917258262634, 'total_duration': 1801.7990944385529, 'accumulated_submission_time': 1712.0917258262634, 'accumulated_eval_time': 88.90904879570007, 'accumulated_logging_time': 0.5449492931365967, 'global_step': 7230, 'preemption_count': 0}), (7573, {'train/ssim': 0.7418189729963031, 'train/loss': 0.26454414640154156, 'validation/ssim': 0.7159344142383582, 'validation/loss': 0.29055258901721653, 'validation/num_examples': 3554, 'test/ssim': 0.7334203222083566, 'test/loss': 0.2919843130955913, 'test/num_examples': 3581, 'score': 1792.1360602378845, 'total_duration': 1885.9275164604187, 'accumulated_submission_time': 1792.1360602378845, 'accumulated_eval_time': 92.9541277885437, 'accumulated_logging_time': 0.572021484375, 'global_step': 7573, 'preemption_count': 0}), (7918, {'train/ssim': 0.7490203039986747, 'train/loss': 0.2643026624407087, 'validation/ssim': 0.723283088267621, 'validation/loss': 0.290826577447946, 'validation/num_examples': 3554, 'test/ssim': 0.7403620698870776, 'test/loss': 0.2923499104431374, 'test/num_examples': 3581, 'score': 1872.2391254901886, 'total_duration': 1970.113526582718, 'accumulated_submission_time': 1872.2391254901886, 'accumulated_eval_time': 96.99868774414062, 'accumulated_logging_time': 0.5981225967407227, 'global_step': 7918, 'preemption_count': 0}), (8265, {'train/ssim': 0.7482437406267438, 'train/loss': 0.26421332359313965, 'validation/ssim': 0.7220145736977701, 'validation/loss': 0.2909175291045301, 'validation/num_examples': 3554, 'test/ssim': 0.7392333370785046, 'test/loss': 0.29234858099823724, 'test/num_examples': 3581, 'score': 1952.3275845050812, 'total_duration': 2054.2847859859467, 'accumulated_submission_time': 1952.3275845050812, 'accumulated_eval_time': 101.04316473007202, 'accumulated_logging_time': 0.6242008209228516, 'global_step': 8265, 'preemption_count': 0}), (8607, {'train/ssim': 0.7464250155857631, 'train/loss': 0.26386570930480957, 'validation/ssim': 0.7195118918604038, 'validation/loss': 0.2906534326968732, 'validation/num_examples': 3554, 'test/ssim': 0.7369421921905543, 'test/loss': 0.2919754501295902, 'test/num_examples': 3581, 'score': 2032.5190379619598, 'total_duration': 2138.555235147476, 'accumulated_submission_time': 2032.5190379619598, 'accumulated_eval_time': 105.08436179161072, 'accumulated_logging_time': 0.6500787734985352, 'global_step': 8607, 'preemption_count': 0}), (8951, {'train/ssim': 0.7454898016793388, 'train/loss': 0.2632397242954799, 'validation/ssim': 0.7187876446433596, 'validation/loss': 0.2896331804283026, 'validation/num_examples': 3554, 'test/ssim': 0.736424458622766, 'test/loss': 0.29104221389800333, 'test/num_examples': 3581, 'score': 2112.5709660053253, 'total_duration': 2222.6944692134857, 'accumulated_submission_time': 2112.5709660053253, 'accumulated_eval_time': 109.13049507141113, 'accumulated_logging_time': 0.6793222427368164, 'global_step': 8951, 'preemption_count': 0}), (9293, {'train/ssim': 0.7439816338675362, 'train/loss': 0.2630248410361154, 'validation/ssim': 0.7169932728747538, 'validation/loss': 0.289561634997538, 'validation/num_examples': 3554, 'test/ssim': 0.7345339197980661, 'test/loss': 0.2910244879660011, 'test/num_examples': 3581, 'score': 2192.5693085193634, 'total_duration': 2306.7771003246307, 'accumulated_submission_time': 2192.5693085193634, 'accumulated_eval_time': 113.17689657211304, 'accumulated_logging_time': 0.7051200866699219, 'global_step': 9293, 'preemption_count': 0}), (9636, {'train/ssim': 0.7478782790047782, 'train/loss': 0.2636504684175764, 'validation/ssim': 0.7215138587243247, 'validation/loss': 0.2900727915508934, 'validation/num_examples': 3554, 'test/ssim': 0.7388857042812762, 'test/loss': 0.2914541713754014, 'test/num_examples': 3581, 'score': 2272.6771895885468, 'total_duration': 2390.9652981758118, 'accumulated_submission_time': 2272.6771895885468, 'accumulated_eval_time': 117.2190728187561, 'accumulated_logging_time': 0.7311830520629883, 'global_step': 9636, 'preemption_count': 0}), (9980, {'train/ssim': 0.7397242954799107, 'train/loss': 0.26466682979038786, 'validation/ssim': 0.7141337225661227, 'validation/loss': 0.29100975161130066, 'validation/num_examples': 3554, 'test/ssim': 0.7312535997277296, 'test/loss': 0.2924467894791958, 'test/num_examples': 3581, 'score': 2352.732777118683, 'total_duration': 2475.1045954227448, 'accumulated_submission_time': 2352.732777118683, 'accumulated_eval_time': 121.26503705978394, 'accumulated_logging_time': 0.7569248676300049, 'global_step': 9980, 'preemption_count': 0}), (10325, {'train/ssim': 0.749014036996024, 'train/loss': 0.2629481383732387, 'validation/ssim': 0.7227236394071821, 'validation/loss': 0.2893752321877638, 'validation/num_examples': 3554, 'test/ssim': 0.7399639181836428, 'test/loss': 0.2908956340756772, 'test/num_examples': 3581, 'score': 2432.74764752388, 'total_duration': 2559.2052206993103, 'accumulated_submission_time': 2432.74764752388, 'accumulated_eval_time': 125.30674004554749, 'accumulated_logging_time': 0.7888193130493164, 'global_step': 10325, 'preemption_count': 0}), (10669, {'train/ssim': 0.7450334003993443, 'train/loss': 0.2640965155192784, 'validation/ssim': 0.7185316885463562, 'validation/loss': 0.290682490514649, 'validation/num_examples': 3554, 'test/ssim': 0.7358866811164828, 'test/loss': 0.29215894761414407, 'test/num_examples': 3581, 'score': 2512.8242738246918, 'total_duration': 2643.370032787323, 'accumulated_submission_time': 2512.8242738246918, 'accumulated_eval_time': 129.35560011863708, 'accumulated_logging_time': 0.816091775894165, 'global_step': 10669, 'preemption_count': 0}), (11014, {'train/ssim': 0.7504299027579171, 'train/loss': 0.26199814251491, 'validation/ssim': 0.7241798963315982, 'validation/loss': 0.2886156072493142, 'validation/num_examples': 3554, 'test/ssim': 0.7411439880183608, 'test/loss': 0.29017442726150167, 'test/num_examples': 3581, 'score': 2592.9127190113068, 'total_duration': 2727.5416226387024, 'accumulated_submission_time': 2592.9127190113068, 'accumulated_eval_time': 133.3985664844513, 'accumulated_logging_time': 0.8439867496490479, 'global_step': 11014, 'preemption_count': 0}), (11358, {'train/ssim': 0.7455850328717913, 'train/loss': 0.26415468965257916, 'validation/ssim': 0.7196553261949564, 'validation/loss': 0.29023429256647437, 'validation/num_examples': 3554, 'test/ssim': 0.7365518126265359, 'test/loss': 0.29191749996727523, 'test/num_examples': 3581, 'score': 2672.970718383789, 'total_duration': 2811.682421684265, 'accumulated_submission_time': 2672.970718383789, 'accumulated_eval_time': 137.44315481185913, 'accumulated_logging_time': 0.8700685501098633, 'global_step': 11358, 'preemption_count': 0}), (11702, {'train/ssim': 0.7454074450901577, 'train/loss': 0.2641615867614746, 'validation/ssim': 0.7192417846748382, 'validation/loss': 0.2905541689931239, 'validation/num_examples': 3554, 'test/ssim': 0.7364029147977171, 'test/loss': 0.29208920288938145, 'test/num_examples': 3581, 'score': 2752.944223165512, 'total_duration': 2895.736180782318, 'accumulated_submission_time': 2752.944223165512, 'accumulated_eval_time': 141.48319029808044, 'accumulated_logging_time': 0.8981711864471436, 'global_step': 11702, 'preemption_count': 0}), (12044, {'train/ssim': 0.7435768672398159, 'train/loss': 0.2633335930960519, 'validation/ssim': 0.7189717461838773, 'validation/loss': 0.28965354837858753, 'validation/num_examples': 3554, 'test/ssim': 0.7357157622259843, 'test/loss': 0.29123552882182, 'test/num_examples': 3581, 'score': 2832.9485371112823, 'total_duration': 2979.825961828232, 'accumulated_submission_time': 2832.9485371112823, 'accumulated_eval_time': 145.52828335762024, 'accumulated_logging_time': 0.9264392852783203, 'global_step': 12044, 'preemption_count': 0}), (12389, {'train/ssim': 0.7485134260995048, 'train/loss': 0.26198691981179373, 'validation/ssim': 0.7220078416265123, 'validation/loss': 0.2885388066812922, 'validation/num_examples': 3554, 'test/ssim': 0.7393814167873848, 'test/loss': 0.2899312751980941, 'test/num_examples': 3581, 'score': 2913.143745660782, 'total_duration': 3064.1029093265533, 'accumulated_submission_time': 2913.143745660782, 'accumulated_eval_time': 149.57113814353943, 'accumulated_logging_time': 0.9530577659606934, 'global_step': 12389, 'preemption_count': 0}), (12736, {'train/ssim': 0.7500293595450265, 'train/loss': 0.2616373130253383, 'validation/ssim': 0.723628003877673, 'validation/loss': 0.2881183270061023, 'validation/num_examples': 3554, 'test/ssim': 0.7409452530499512, 'test/loss': 0.2895676208854021, 'test/num_examples': 3581, 'score': 2993.192461490631, 'total_duration': 3148.232587814331, 'accumulated_submission_time': 2993.192461490631, 'accumulated_eval_time': 153.61311268806458, 'accumulated_logging_time': 0.9799468517303467, 'global_step': 12736, 'preemption_count': 0}), (13078, {'train/ssim': 0.7514548982892718, 'train/loss': 0.26127948079790386, 'validation/ssim': 0.724869796246307, 'validation/loss': 0.2879144757667417, 'validation/num_examples': 3554, 'test/ssim': 0.742036215988027, 'test/loss': 0.28933868365592713, 'test/num_examples': 3581, 'score': 3073.1728444099426, 'total_duration': 3232.291928291321, 'accumulated_submission_time': 3073.1728444099426, 'accumulated_eval_time': 157.65242910385132, 'accumulated_logging_time': 1.0075263977050781, 'global_step': 13078, 'preemption_count': 0}), (13424, {'train/ssim': 0.7457209995814732, 'train/loss': 0.26303158487592426, 'validation/ssim': 0.7189907058947664, 'validation/loss': 0.28933851492156726, 'validation/num_examples': 3554, 'test/ssim': 0.7365478583801661, 'test/loss': 0.2907379073691881, 'test/num_examples': 3581, 'score': 3153.252564430237, 'total_duration': 3316.4589569568634, 'accumulated_submission_time': 3153.252564430237, 'accumulated_eval_time': 161.69960498809814, 'accumulated_logging_time': 1.0354080200195312, 'global_step': 13424, 'preemption_count': 0}), (13770, {'train/ssim': 0.7465126173836845, 'train/loss': 0.26222407817840576, 'validation/ssim': 0.7193183791590462, 'validation/loss': 0.28899566014965533, 'validation/num_examples': 3554, 'test/ssim': 0.7370009604728078, 'test/loss': 0.2902145492268221, 'test/num_examples': 3581, 'score': 3233.4567432403564, 'total_duration': 3400.75181722641, 'accumulated_submission_time': 3233.4567432403564, 'accumulated_eval_time': 165.74770259857178, 'accumulated_logging_time': 1.0637977123260498, 'global_step': 13770, 'preemption_count': 0}), (14111, {'train/ssim': 0.748753275190081, 'train/loss': 0.26196677344185965, 'validation/ssim': 0.7221636409899057, 'validation/loss': 0.28858569074898, 'validation/num_examples': 3554, 'test/ssim': 0.7393679178083985, 'test/loss': 0.2901376118642663, 'test/num_examples': 3581, 'score': 3313.4611835479736, 'total_duration': 3484.8425419330597, 'accumulated_submission_time': 3313.4611835479736, 'accumulated_eval_time': 169.79286742210388, 'accumulated_logging_time': 1.0930249691009521, 'global_step': 14111, 'preemption_count': 0}), (14457, {'train/ssim': 0.7506982939583915, 'train/loss': 0.26223320620400564, 'validation/ssim': 0.7246852825381612, 'validation/loss': 0.28878583247968836, 'validation/num_examples': 3554, 'test/ssim': 0.7417963704927045, 'test/loss': 0.2902302639473087, 'test/num_examples': 3581, 'score': 3393.4748725891113, 'total_duration': 3568.9376089572906, 'accumulated_submission_time': 3393.4748725891113, 'accumulated_eval_time': 173.83345460891724, 'accumulated_logging_time': 1.1216280460357666, 'global_step': 14457, 'preemption_count': 0}), (14804, {'train/ssim': 0.748584338596889, 'train/loss': 0.262541617665972, 'validation/ssim': 0.7220001478307893, 'validation/loss': 0.28889581254176633, 'validation/num_examples': 3554, 'test/ssim': 0.739383939323862, 'test/loss': 0.2902830667716769, 'test/num_examples': 3581, 'score': 3473.4844737052917, 'total_duration': 3653.0337414741516, 'accumulated_submission_time': 3473.4844737052917, 'accumulated_eval_time': 177.88046073913574, 'accumulated_logging_time': 1.1491503715515137, 'global_step': 14804, 'preemption_count': 0}), (15148, {'train/ssim': 0.746781485421317, 'train/loss': 0.2616633006504604, 'validation/ssim': 0.7198642264877603, 'validation/loss': 0.28810388396547026, 'validation/num_examples': 3554, 'test/ssim': 0.7373965896397654, 'test/loss': 0.2894467436644792, 'test/num_examples': 3581, 'score': 3553.4609277248383, 'total_duration': 3737.0999524593353, 'accumulated_submission_time': 3553.4609277248383, 'accumulated_eval_time': 181.92653894424438, 'accumulated_logging_time': 1.1808226108551025, 'global_step': 15148, 'preemption_count': 0}), (15479, {'train/ssim': 0.7495412826538086, 'train/loss': 0.26138252871377127, 'validation/ssim': 0.7229363865978475, 'validation/loss': 0.2880535479938977, 'validation/num_examples': 3554, 'test/ssim': 0.7400738189620567, 'test/loss': 0.2894908880528309, 'test/num_examples': 3581, 'score': 3630.503707885742, 'total_duration': 3821.306978702545, 'accumulated_submission_time': 3630.503707885742, 'accumulated_eval_time': 185.9671552181244, 'accumulated_logging_time': 4.293005704879761, 'global_step': 15479, 'preemption_count': 0}), (15827, {'train/ssim': 0.7468673161097935, 'train/loss': 0.26163523537772043, 'validation/ssim': 0.7202307808982836, 'validation/loss': 0.2881785721743986, 'validation/num_examples': 3554, 'test/ssim': 0.7377974002330006, 'test/loss': 0.2894689692561435, 'test/num_examples': 3581, 'score': 3710.4920921325684, 'total_duration': 3905.3816516399384, 'accumulated_submission_time': 3710.4920921325684, 'accumulated_eval_time': 190.01224875450134, 'accumulated_logging_time': 4.322009086608887, 'global_step': 15827, 'preemption_count': 0}), (16170, {'train/ssim': 0.7493359701974052, 'train/loss': 0.261055520602635, 'validation/ssim': 0.7227794194261747, 'validation/loss': 0.287572565545644, 'validation/num_examples': 3554, 'test/ssim': 0.7401714479413921, 'test/loss': 0.2889514061300091, 'test/num_examples': 3581, 'score': 3790.4588992595673, 'total_duration': 3989.43754029274, 'accumulated_submission_time': 3790.4588992595673, 'accumulated_eval_time': 194.06110763549805, 'accumulated_logging_time': 4.35016131401062, 'global_step': 16170, 'preemption_count': 0}), (16513, {'train/ssim': 0.7490717342921666, 'train/loss': 0.2611632687704904, 'validation/ssim': 0.7222987632772931, 'validation/loss': 0.28795869791849854, 'validation/num_examples': 3554, 'test/ssim': 0.7395680844867006, 'test/loss': 0.28937713529303966, 'test/num_examples': 3581, 'score': 3870.4816830158234, 'total_duration': 4073.548889398575, 'accumulated_submission_time': 3870.4816830158234, 'accumulated_eval_time': 198.1052176952362, 'accumulated_logging_time': 4.3827149868011475, 'global_step': 16513, 'preemption_count': 0}), (16857, {'train/ssim': 0.7464184079851423, 'train/loss': 0.26241728237697054, 'validation/ssim': 0.719400606600837, 'validation/loss': 0.2888134820580684, 'validation/num_examples': 3554, 'test/ssim': 0.7370565244519687, 'test/loss': 0.2901986981530124, 'test/num_examples': 3581, 'score': 3950.5336406230927, 'total_duration': 4157.687446594238, 'accumulated_submission_time': 3950.5336406230927, 'accumulated_eval_time': 202.15042400360107, 'accumulated_logging_time': 4.412107944488525, 'global_step': 16857, 'preemption_count': 0}), (17202, {'train/ssim': 0.7484077726091657, 'train/loss': 0.26139157158987864, 'validation/ssim': 0.7219015023784819, 'validation/loss': 0.28783149268429936, 'validation/num_examples': 3554, 'test/ssim': 0.7391657740069115, 'test/loss': 0.2892383616984606, 'test/num_examples': 3581, 'score': 4030.5943059921265, 'total_duration': 4241.836377620697, 'accumulated_submission_time': 4030.5943059921265, 'accumulated_eval_time': 206.19731330871582, 'accumulated_logging_time': 4.441436052322388, 'global_step': 17202, 'preemption_count': 0}), (17547, {'train/ssim': 0.7491188049316406, 'train/loss': 0.26074956144605366, 'validation/ssim': 0.7221773799108399, 'validation/loss': 0.287938776483144, 'validation/num_examples': 3554, 'test/ssim': 0.7394163914147585, 'test/loss': 0.28935753450284485, 'test/num_examples': 3581, 'score': 4110.767489433289, 'total_duration': 4326.0935044288635, 'accumulated_submission_time': 4110.767489433289, 'accumulated_eval_time': 210.24081873893738, 'accumulated_logging_time': 4.469689130783081, 'global_step': 17547, 'preemption_count': 0}), (17893, {'train/ssim': 0.7488366535731724, 'train/loss': 0.26106984274727957, 'validation/ssim': 0.7225361031364308, 'validation/loss': 0.2876933821816087, 'validation/num_examples': 3554, 'test/ssim': 0.7397306176478288, 'test/loss': 0.28906355673825396, 'test/num_examples': 3581, 'score': 4190.812663078308, 'total_duration': 4410.222549676895, 'accumulated_submission_time': 4190.812663078308, 'accumulated_eval_time': 214.28328132629395, 'accumulated_logging_time': 4.499216556549072, 'global_step': 17893, 'preemption_count': 0}), (18241, {'train/ssim': 0.7490247998918805, 'train/loss': 0.2612367698124477, 'validation/ssim': 0.7226962302599184, 'validation/loss': 0.28772268043050087, 'validation/num_examples': 3554, 'test/ssim': 0.7400820683381039, 'test/loss': 0.28903761551853535, 'test/num_examples': 3581, 'score': 4270.923578500748, 'total_duration': 4494.421721696854, 'accumulated_submission_time': 4270.923578500748, 'accumulated_eval_time': 218.32737565040588, 'accumulated_logging_time': 4.531201362609863, 'global_step': 18241, 'preemption_count': 0}), (18584, {'train/ssim': 0.7490253448486328, 'train/loss': 0.26049625873565674, 'validation/ssim': 0.7227430799803038, 'validation/loss': 0.28743680783316333, 'validation/num_examples': 3554, 'test/ssim': 0.7397645014486177, 'test/loss': 0.2889587010327946, 'test/num_examples': 3581, 'score': 4350.883985042572, 'total_duration': 4578.475754737854, 'accumulated_submission_time': 4350.883985042572, 'accumulated_eval_time': 222.37603402137756, 'accumulated_logging_time': 4.564069509506226, 'global_step': 18584, 'preemption_count': 0}), (18930, {'train/ssim': 0.746837956564767, 'train/loss': 0.26119305406297955, 'validation/ssim': 0.7200128129176632, 'validation/loss': 0.2878367134742544, 'validation/num_examples': 3554, 'test/ssim': 0.7375610317474169, 'test/loss': 0.289137153444394, 'test/num_examples': 3581, 'score': 4430.957304239273, 'total_duration': 4662.636361837387, 'accumulated_submission_time': 4430.957304239273, 'accumulated_eval_time': 226.41681051254272, 'accumulated_logging_time': 4.5984275341033936, 'global_step': 18930, 'preemption_count': 0}), (19276, {'train/ssim': 0.7515696798052106, 'train/loss': 0.2613452843257359, 'validation/ssim': 0.7252221995682682, 'validation/loss': 0.2881080056417505, 'validation/num_examples': 3554, 'test/ssim': 0.742224383573897, 'test/loss': 0.2894971603056932, 'test/num_examples': 3581, 'score': 4511.09930229187, 'total_duration': 4746.862930059433, 'accumulated_submission_time': 4511.09930229187, 'accumulated_eval_time': 230.45980858802795, 'accumulated_logging_time': 4.627838373184204, 'global_step': 19276, 'preemption_count': 0}), (19620, {'train/ssim': 0.7509069442749023, 'train/loss': 0.2607353925704956, 'validation/ssim': 0.7235287401739238, 'validation/loss': 0.2882456868031619, 'validation/num_examples': 3554, 'test/ssim': 0.7407267468496929, 'test/loss': 0.28975834509608, 'test/num_examples': 3581, 'score': 4591.1084978580475, 'total_duration': 4830.964126110077, 'accumulated_submission_time': 4591.1084978580475, 'accumulated_eval_time': 234.50627899169922, 'accumulated_logging_time': 4.6616129875183105, 'global_step': 19620, 'preemption_count': 0}), (19969, {'train/ssim': 0.747917720249721, 'train/loss': 0.2605396509170532, 'validation/ssim': 0.7213956353096863, 'validation/loss': 0.2870852460201094, 'validation/num_examples': 3554, 'test/ssim': 0.7388614333897654, 'test/loss': 0.2884193213749651, 'test/num_examples': 3581, 'score': 4671.207195281982, 'total_duration': 4915.146928071976, 'accumulated_submission_time': 4671.207195281982, 'accumulated_eval_time': 238.5473177433014, 'accumulated_logging_time': 4.692481756210327, 'global_step': 19969, 'preemption_count': 0}), (20315, {'train/ssim': 0.7510645730154855, 'train/loss': 0.2608891555241176, 'validation/ssim': 0.7249340257016742, 'validation/loss': 0.28743455808486035, 'validation/num_examples': 3554, 'test/ssim': 0.7419790157689891, 'test/loss': 0.2887872708173345, 'test/num_examples': 3581, 'score': 4751.304104089737, 'total_duration': 4999.330250740051, 'accumulated_submission_time': 4751.304104089737, 'accumulated_eval_time': 242.59148383140564, 'accumulated_logging_time': 4.722586393356323, 'global_step': 20315, 'preemption_count': 0}), (20657, {'train/ssim': 0.750018664768764, 'train/loss': 0.2601903336388724, 'validation/ssim': 0.722571961720069, 'validation/loss': 0.28715443866066404, 'validation/num_examples': 3554, 'test/ssim': 0.7399350112791468, 'test/loss': 0.28854865250191986, 'test/num_examples': 3581, 'score': 4831.424298048019, 'total_duration': 5083.538475513458, 'accumulated_submission_time': 4831.424298048019, 'accumulated_eval_time': 246.63685989379883, 'accumulated_logging_time': 4.753290891647339, 'global_step': 20657, 'preemption_count': 0}), (21003, {'train/ssim': 0.750136239188058, 'train/loss': 0.25977115971701487, 'validation/ssim': 0.7229999978017726, 'validation/loss': 0.28686987126081526, 'validation/num_examples': 3554, 'test/ssim': 0.7402386701296775, 'test/loss': 0.2883246921687378, 'test/num_examples': 3581, 'score': 4911.5534324646, 'total_duration': 5167.75226020813, 'accumulated_submission_time': 4911.5534324646, 'accumulated_eval_time': 250.6783995628357, 'accumulated_logging_time': 4.78401255607605, 'global_step': 21003, 'preemption_count': 0}), (21347, {'train/ssim': 0.7508693422589984, 'train/loss': 0.25986060074397493, 'validation/ssim': 0.7238796322145822, 'validation/loss': 0.28688142912805115, 'validation/num_examples': 3554, 'test/ssim': 0.7412270953687866, 'test/loss': 0.2881120491613725, 'test/num_examples': 3581, 'score': 4991.542078495026, 'total_duration': 5251.82776093483, 'accumulated_submission_time': 4991.542078495026, 'accumulated_eval_time': 254.72396564483643, 'accumulated_logging_time': 4.8128838539123535, 'global_step': 21347, 'preemption_count': 0}), (21690, {'train/ssim': 0.7507828984941755, 'train/loss': 0.2596160514014108, 'validation/ssim': 0.7240258830279263, 'validation/loss': 0.28636475983267096, 'validation/num_examples': 3554, 'test/ssim': 0.7412582521031137, 'test/loss': 0.28774577004721097, 'test/num_examples': 3581, 'score': 5071.724465370178, 'total_duration': 5336.094830274582, 'accumulated_submission_time': 5071.724465370178, 'accumulated_eval_time': 258.76667499542236, 'accumulated_logging_time': 4.8427369594573975, 'global_step': 21690, 'preemption_count': 0}), (22037, {'train/ssim': 0.7516030584062848, 'train/loss': 0.2595355340412685, 'validation/ssim': 0.7247510232748312, 'validation/loss': 0.28650192578454736, 'validation/num_examples': 3554, 'test/ssim': 0.7419090665142418, 'test/loss': 0.2878893500964291, 'test/num_examples': 3581, 'score': 5151.788769721985, 'total_duration': 5420.246787071228, 'accumulated_submission_time': 5151.788769721985, 'accumulated_eval_time': 262.81214714050293, 'accumulated_logging_time': 4.872639179229736, 'global_step': 22037, 'preemption_count': 0}), (22382, {'train/ssim': 0.7525712421962193, 'train/loss': 0.25947844982147217, 'validation/ssim': 0.7257786945607062, 'validation/loss': 0.2865110793406197, 'validation/num_examples': 3554, 'test/ssim': 0.742977122094038, 'test/loss': 0.2878808280137357, 'test/num_examples': 3581, 'score': 5232.000771999359, 'total_duration': 5504.5493080616, 'accumulated_submission_time': 5232.000771999359, 'accumulated_eval_time': 266.8560085296631, 'accumulated_logging_time': 4.907236814498901, 'global_step': 22382, 'preemption_count': 0}), (22727, {'train/ssim': 0.7518329620361328, 'train/loss': 0.25960610594068256, 'validation/ssim': 0.7250375484709131, 'validation/loss': 0.28649084877954417, 'validation/num_examples': 3554, 'test/ssim': 0.7421773416774294, 'test/loss': 0.2878331725273143, 'test/num_examples': 3581, 'score': 5312.106199026108, 'total_duration': 5588.7337918281555, 'accumulated_submission_time': 5312.106199026108, 'accumulated_eval_time': 270.8928482532501, 'accumulated_logging_time': 4.937005043029785, 'global_step': 22727, 'preemption_count': 0}), (23072, {'train/ssim': 0.7509150505065918, 'train/loss': 0.25893185819898334, 'validation/ssim': 0.7236573364738674, 'validation/loss': 0.2861938991772035, 'validation/num_examples': 3554, 'test/ssim': 0.741036337069778, 'test/loss': 0.2875140375746125, 'test/num_examples': 3581, 'score': 5392.222705602646, 'total_duration': 5672.93510222435, 'accumulated_submission_time': 5392.222705602646, 'accumulated_eval_time': 274.9365813732147, 'accumulated_logging_time': 4.966019153594971, 'global_step': 23072, 'preemption_count': 0}), (23418, {'train/ssim': 0.7504358291625977, 'train/loss': 0.25956852095467703, 'validation/ssim': 0.723816433178285, 'validation/loss': 0.28646639350028136, 'validation/num_examples': 3554, 'test/ssim': 0.7411057409112329, 'test/loss': 0.2878223324381283, 'test/num_examples': 3581, 'score': 5472.2902681827545, 'total_duration': 5757.086367607117, 'accumulated_submission_time': 5472.2902681827545, 'accumulated_eval_time': 278.97792768478394, 'accumulated_logging_time': 4.996206760406494, 'global_step': 23418, 'preemption_count': 0}), (23760, {'train/ssim': 0.7507174355643136, 'train/loss': 0.25983021940503803, 'validation/ssim': 0.7237039801104389, 'validation/loss': 0.28673414789563695, 'validation/num_examples': 3554, 'test/ssim': 0.7410613579045657, 'test/loss': 0.28804002051844807, 'test/num_examples': 3581, 'score': 5552.431335449219, 'total_duration': 5841.311386823654, 'accumulated_submission_time': 5552.431335449219, 'accumulated_eval_time': 283.0185122489929, 'accumulated_logging_time': 5.02751088142395, 'global_step': 23760, 'preemption_count': 0}), (24105, {'train/ssim': 0.7529386111668178, 'train/loss': 0.2583275181906564, 'validation/ssim': 0.7255741907226013, 'validation/loss': 0.2857426271454699, 'validation/num_examples': 3554, 'test/ssim': 0.7427400036651773, 'test/loss': 0.28713163467999514, 'test/num_examples': 3581, 'score': 5632.593497753143, 'total_duration': 5925.557373762131, 'accumulated_submission_time': 5632.593497753143, 'accumulated_eval_time': 287.06051874160767, 'accumulated_logging_time': 5.057190895080566, 'global_step': 24105, 'preemption_count': 0}), (24450, {'train/ssim': 0.7510510172162738, 'train/loss': 0.25918493952069965, 'validation/ssim': 0.7238414380143852, 'validation/loss': 0.286399175829611, 'validation/num_examples': 3554, 'test/ssim': 0.7411732358061645, 'test/loss': 0.28772906676513194, 'test/num_examples': 3581, 'score': 5712.731587409973, 'total_duration': 6009.784536600113, 'accumulated_submission_time': 5712.731587409973, 'accumulated_eval_time': 291.10566115379333, 'accumulated_logging_time': 5.088764429092407, 'global_step': 24450, 'preemption_count': 0}), (24793, {'train/ssim': 0.7537099293300084, 'train/loss': 0.2592285360608782, 'validation/ssim': 0.7267622639103827, 'validation/loss': 0.2864781231040289, 'validation/num_examples': 3554, 'test/ssim': 0.7438580327378874, 'test/loss': 0.28780631092266473, 'test/num_examples': 3581, 'score': 5792.829498052597, 'total_duration': 6093.966063499451, 'accumulated_submission_time': 5792.829498052597, 'accumulated_eval_time': 295.145968914032, 'accumulated_logging_time': 5.1201136112213135, 'global_step': 24793, 'preemption_count': 0}), (25138, {'train/ssim': 0.7527525765555245, 'train/loss': 0.2580028772354126, 'validation/ssim': 0.7249790893623382, 'validation/loss': 0.28568267392924346, 'validation/num_examples': 3554, 'test/ssim': 0.7422174977310807, 'test/loss': 0.28705664035229334, 'test/num_examples': 3581, 'score': 5872.8541264534, 'total_duration': 6178.080864906311, 'accumulated_submission_time': 5872.8541264534, 'accumulated_eval_time': 299.18876028060913, 'accumulated_logging_time': 5.155481338500977, 'global_step': 25138, 'preemption_count': 0}), (25484, {'train/ssim': 0.751709120614188, 'train/loss': 0.25861358642578125, 'validation/ssim': 0.7240188761782499, 'validation/loss': 0.28610025125738603, 'validation/num_examples': 3554, 'test/ssim': 0.7413706754180047, 'test/loss': 0.2874117044056304, 'test/num_examples': 3581, 'score': 5952.869534730911, 'total_duration': 6262.180478811264, 'accumulated_submission_time': 5952.869534730911, 'accumulated_eval_time': 303.2299098968506, 'accumulated_logging_time': 5.186309576034546, 'global_step': 25484, 'preemption_count': 0}), (25830, {'train/ssim': 0.7517774445669991, 'train/loss': 0.2585456371307373, 'validation/ssim': 0.7246146644845597, 'validation/loss': 0.28572112573420794, 'validation/num_examples': 3554, 'test/ssim': 0.7417736676644093, 'test/loss': 0.2870886492948897, 'test/num_examples': 3581, 'score': 6032.928485393524, 'total_duration': 6346.324097394943, 'accumulated_submission_time': 6032.928485393524, 'accumulated_eval_time': 307.27237248420715, 'accumulated_logging_time': 5.216569900512695, 'global_step': 25830, 'preemption_count': 0}), (26173, {'train/ssim': 0.7526977402823312, 'train/loss': 0.25808766910008024, 'validation/ssim': 0.7245964604143219, 'validation/loss': 0.2860090763433367, 'validation/num_examples': 3554, 'test/ssim': 0.7418254137505236, 'test/loss': 0.2873534133600077, 'test/num_examples': 3581, 'score': 6113.055310726166, 'total_duration': 6430.539331912994, 'accumulated_submission_time': 6113.055310726166, 'accumulated_eval_time': 311.31592655181885, 'accumulated_logging_time': 5.249204397201538, 'global_step': 26173, 'preemption_count': 0}), (26515, {'train/ssim': 0.753077507019043, 'train/loss': 0.2581151042665754, 'validation/ssim': 0.7256595094216024, 'validation/loss': 0.28554373909129677, 'validation/num_examples': 3554, 'test/ssim': 0.7428827655944569, 'test/loss': 0.28693831975617845, 'test/num_examples': 3581, 'score': 6193.021834373474, 'total_duration': 6514.592348814011, 'accumulated_submission_time': 6193.021834373474, 'accumulated_eval_time': 315.35939478874207, 'accumulated_logging_time': 5.28049635887146, 'global_step': 26515, 'preemption_count': 0}), (26861, {'train/ssim': 0.7530824797494071, 'train/loss': 0.25805459703717915, 'validation/ssim': 0.7258945136641812, 'validation/loss': 0.2853332416489343, 'validation/num_examples': 3554, 'test/ssim': 0.743087909169052, 'test/loss': 0.28664734176469564, 'test/num_examples': 3581, 'score': 6273.217540979385, 'total_duration': 6598.875570058823, 'accumulated_submission_time': 6273.217540979385, 'accumulated_eval_time': 319.4024076461792, 'accumulated_logging_time': 5.313000917434692, 'global_step': 26861, 'preemption_count': 0}), (27205, {'train/ssim': 0.7533891541617257, 'train/loss': 0.2577869551522391, 'validation/ssim': 0.7262223243176702, 'validation/loss': 0.28546793459504255, 'validation/num_examples': 3554, 'test/ssim': 0.7432430110740715, 'test/loss': 0.286867041056531, 'test/num_examples': 3581, 'score': 6353.390656471252, 'total_duration': 6683.127971410751, 'accumulated_submission_time': 6353.390656471252, 'accumulated_eval_time': 323.43775701522827, 'accumulated_logging_time': 5.34488582611084, 'global_step': 27205, 'preemption_count': 0}), (27551, {'train/ssim': 0.7539660590035575, 'train/loss': 0.25812089443206787, 'validation/ssim': 0.726424355150007, 'validation/loss': 0.28555339068325303, 'validation/num_examples': 3554, 'test/ssim': 0.7436233686688425, 'test/loss': 0.28697360117852905, 'test/num_examples': 3581, 'score': 6433.46320271492, 'total_duration': 6767.291547298431, 'accumulated_submission_time': 6433.46320271492, 'accumulated_eval_time': 327.4859962463379, 'accumulated_logging_time': 5.375718593597412, 'global_step': 27551, 'preemption_count': 0}), (27897, {'train/ssim': 0.7541084289550781, 'train/loss': 0.2578811134610857, 'validation/ssim': 0.7266418422683948, 'validation/loss': 0.28545539782969015, 'validation/num_examples': 3554, 'test/ssim': 0.7438512832483943, 'test/loss': 0.2867495385803546, 'test/num_examples': 3581, 'score': 6513.643239974976, 'total_duration': 6851.556659221649, 'accumulated_submission_time': 6513.643239974976, 'accumulated_eval_time': 331.52803587913513, 'accumulated_logging_time': 5.40687370300293, 'global_step': 27897, 'preemption_count': 0}), (28240, {'train/ssim': 0.7530191285269601, 'train/loss': 0.25813448429107666, 'validation/ssim': 0.7249559392805641, 'validation/loss': 0.286052113513163, 'validation/num_examples': 3554, 'test/ssim': 0.7422999233148911, 'test/loss': 0.28733681234292097, 'test/num_examples': 3581, 'score': 6593.765914440155, 'total_duration': 6935.765740871429, 'accumulated_submission_time': 6593.765914440155, 'accumulated_eval_time': 335.5698335170746, 'accumulated_logging_time': 5.439523696899414, 'global_step': 28240, 'preemption_count': 0}), (28587, {'train/ssim': 0.753343037196568, 'train/loss': 0.25734414373125347, 'validation/ssim': 0.725530020091798, 'validation/loss': 0.28511778102138435, 'validation/num_examples': 3554, 'test/ssim': 0.7427766827090896, 'test/loss': 0.28647038923965024, 'test/num_examples': 3581, 'score': 6673.728529691696, 'total_duration': 7019.814661979675, 'accumulated_submission_time': 6673.728529691696, 'accumulated_eval_time': 339.61222982406616, 'accumulated_logging_time': 5.4713146686553955, 'global_step': 28587, 'preemption_count': 0}), (28932, {'train/ssim': 0.7535497801644462, 'train/loss': 0.2575488771711077, 'validation/ssim': 0.7259476832881964, 'validation/loss': 0.2851559752215813, 'validation/num_examples': 3554, 'test/ssim': 0.7432078319167132, 'test/loss': 0.2864604013587336, 'test/num_examples': 3581, 'score': 6753.82816696167, 'total_duration': 7104.003720521927, 'accumulated_submission_time': 6753.82816696167, 'accumulated_eval_time': 343.6575689315796, 'accumulated_logging_time': 5.5031914710998535, 'global_step': 28932, 'preemption_count': 0}), (29273, {'train/ssim': 0.7527131353105817, 'train/loss': 0.2578637940543039, 'validation/ssim': 0.7251399034318725, 'validation/loss': 0.285449541614642, 'validation/num_examples': 3554, 'test/ssim': 0.7424719330319743, 'test/loss': 0.28681018172080075, 'test/num_examples': 3581, 'score': 6833.869222640991, 'total_duration': 7188.128715515137, 'accumulated_submission_time': 6833.869222640991, 'accumulated_eval_time': 347.69775676727295, 'accumulated_logging_time': 5.534913063049316, 'global_step': 29273, 'preemption_count': 0}), (29619, {'train/ssim': 0.7528404508318219, 'train/loss': 0.2572024720055716, 'validation/ssim': 0.7247044483328644, 'validation/loss': 0.2851512181202079, 'validation/num_examples': 3554, 'test/ssim': 0.742045556190659, 'test/loss': 0.2864549813141406, 'test/num_examples': 3581, 'score': 6913.852163553238, 'total_duration': 7272.19589304924, 'accumulated_submission_time': 6913.852163553238, 'accumulated_eval_time': 351.7384581565857, 'accumulated_logging_time': 5.566555500030518, 'global_step': 29619, 'preemption_count': 0}), (29964, {'train/ssim': 0.7542448725019183, 'train/loss': 0.2572521822793143, 'validation/ssim': 0.7264857681265827, 'validation/loss': 0.2851106367824986, 'validation/num_examples': 3554, 'test/ssim': 0.7436717740985409, 'test/loss': 0.28646960520804243, 'test/num_examples': 3581, 'score': 6993.946165800095, 'total_duration': 7356.371992826462, 'accumulated_submission_time': 6993.946165800095, 'accumulated_eval_time': 355.77624320983887, 'accumulated_logging_time': 5.598665475845337, 'global_step': 29964, 'preemption_count': 0}), (30308, {'train/ssim': 0.7539666720799038, 'train/loss': 0.2571421350751604, 'validation/ssim': 0.726212775767621, 'validation/loss': 0.2849134832670934, 'validation/num_examples': 3554, 'test/ssim': 0.7434445412856046, 'test/loss': 0.2862640184851473, 'test/num_examples': 3581, 'score': 7074.071465730667, 'total_duration': 7440.581089496613, 'accumulated_submission_time': 7074.071465730667, 'accumulated_eval_time': 359.8158543109894, 'accumulated_logging_time': 5.6307532787323, 'global_step': 30308, 'preemption_count': 0}), (30653, {'train/ssim': 0.7541763441903251, 'train/loss': 0.2566960198538644, 'validation/ssim': 0.7259604604846651, 'validation/loss': 0.2849078674831616, 'validation/num_examples': 3554, 'test/ssim': 0.7432008778972354, 'test/loss': 0.2862637798668319, 'test/num_examples': 3581, 'score': 7154.043691635132, 'total_duration': 7524.636759996414, 'accumulated_submission_time': 7154.043691635132, 'accumulated_eval_time': 363.8551321029663, 'accumulated_logging_time': 5.6625776290893555, 'global_step': 30653, 'preemption_count': 0}), (30998, {'train/ssim': 0.7537750516619001, 'train/loss': 0.25694710867745535, 'validation/ssim': 0.7257893422244303, 'validation/loss': 0.28485844171510094, 'validation/num_examples': 3554, 'test/ssim': 0.7430420262758308, 'test/loss': 0.2861960122652541, 'test/num_examples': 3581, 'score': 7234.144478082657, 'total_duration': 7608.822690963745, 'accumulated_submission_time': 7234.144478082657, 'accumulated_eval_time': 367.8951904773712, 'accumulated_logging_time': 5.695420980453491, 'global_step': 30998, 'preemption_count': 0}), (31341, {'train/ssim': 0.7542284556797573, 'train/loss': 0.2569677489144461, 'validation/ssim': 0.7263002926939716, 'validation/loss': 0.2848178260300893, 'validation/num_examples': 3554, 'test/ssim': 0.7435245806862608, 'test/loss': 0.2861467205389556, 'test/num_examples': 3581, 'score': 7314.175801992416, 'total_duration': 7692.941826343536, 'accumulated_submission_time': 7314.175801992416, 'accumulated_eval_time': 371.93916368484497, 'accumulated_logging_time': 5.727295398712158, 'global_step': 31341, 'preemption_count': 0}), (31686, {'train/ssim': 0.754953111921038, 'train/loss': 0.2564511299133301, 'validation/ssim': 0.7265166806986846, 'validation/loss': 0.28481026962357553, 'validation/num_examples': 3554, 'test/ssim': 0.743722633888055, 'test/loss': 0.2861874220058992, 'test/num_examples': 3581, 'score': 7394.33158826828, 'total_duration': 7777.184247970581, 'accumulated_submission_time': 7394.33158826828, 'accumulated_eval_time': 375.98014068603516, 'accumulated_logging_time': 5.7609148025512695, 'global_step': 31686, 'preemption_count': 0}), (32034, {'train/ssim': 0.7544609478541783, 'train/loss': 0.25668537616729736, 'validation/ssim': 0.7263270148951885, 'validation/loss': 0.28476922459728476, 'validation/num_examples': 3554, 'test/ssim': 0.743590030281346, 'test/loss': 0.28611085961498184, 'test/num_examples': 3581, 'score': 7474.308657169342, 'total_duration': 7861.260461330414, 'accumulated_submission_time': 7474.308657169342, 'accumulated_eval_time': 380.0295407772064, 'accumulated_logging_time': 5.798375606536865, 'global_step': 32034, 'preemption_count': 0}), (32378, {'train/ssim': 0.7543185779026577, 'train/loss': 0.2567593199866159, 'validation/ssim': 0.7262754252470808, 'validation/loss': 0.284801098893852, 'validation/num_examples': 3554, 'test/ssim': 0.7435266259861072, 'test/loss': 0.2861430049109013, 'test/num_examples': 3581, 'score': 7554.259472131729, 'total_duration': 7945.309270620346, 'accumulated_submission_time': 7554.259472131729, 'accumulated_eval_time': 384.07799434661865, 'accumulated_logging_time': 5.836031198501587, 'global_step': 32378, 'preemption_count': 0}), (32721, {'train/ssim': 0.7552104677472796, 'train/loss': 0.2563129663467407, 'validation/ssim': 0.7266483682558385, 'validation/loss': 0.28486709723528947, 'validation/num_examples': 3554, 'test/ssim': 0.7438551011414409, 'test/loss': 0.2862320777192125, 'test/num_examples': 3581, 'score': 7634.3465123176575, 'total_duration': 8029.485631227493, 'accumulated_submission_time': 7634.3465123176575, 'accumulated_eval_time': 388.12148785591125, 'accumulated_logging_time': 5.869813680648804, 'global_step': 32721, 'preemption_count': 0}), (33067, {'train/ssim': 0.7548089027404785, 'train/loss': 0.2565027305058071, 'validation/ssim': 0.72650617042417, 'validation/loss': 0.28471876841015403, 'validation/num_examples': 3554, 'test/ssim': 0.7437527679724588, 'test/loss': 0.28608805452169433, 'test/num_examples': 3581, 'score': 7714.412069559097, 'total_duration': 8113.636897563934, 'accumulated_submission_time': 7714.412069559097, 'accumulated_eval_time': 392.1617946624756, 'accumulated_logging_time': 5.903012752532959, 'global_step': 33067, 'preemption_count': 0}), (33414, {'train/ssim': 0.7544290678841727, 'train/loss': 0.2566244602203369, 'validation/ssim': 0.7261439437737408, 'validation/loss': 0.2848105444019942, 'validation/num_examples': 3554, 'test/ssim': 0.743361842995148, 'test/loss': 0.28615657206654915, 'test/num_examples': 3581, 'score': 7794.4692351818085, 'total_duration': 8197.783804655075, 'accumulated_submission_time': 7794.4692351818085, 'accumulated_eval_time': 396.20669984817505, 'accumulated_logging_time': 5.935891389846802, 'global_step': 33414, 'preemption_count': 0}), (33758, {'train/ssim': 0.7553148950849261, 'train/loss': 0.25630225454057964, 'validation/ssim': 0.7268665423202729, 'validation/loss': 0.2847635572923994, 'validation/num_examples': 3554, 'test/ssim': 0.7440031808503211, 'test/loss': 0.28615149290526387, 'test/num_examples': 3581, 'score': 7874.45870757103, 'total_duration': 8281.86214709282, 'accumulated_submission_time': 7874.45870757103, 'accumulated_eval_time': 400.2509334087372, 'accumulated_logging_time': 5.968505382537842, 'global_step': 33758, 'preemption_count': 0}), (34102, {'train/ssim': 0.7551569257463727, 'train/loss': 0.2563475711005075, 'validation/ssim': 0.7268275924794246, 'validation/loss': 0.2846378805131542, 'validation/num_examples': 3554, 'test/ssim': 0.7439999083705668, 'test/loss': 0.2860142191972389, 'test/num_examples': 3581, 'score': 7954.426274776459, 'total_duration': 8365.916305065155, 'accumulated_submission_time': 7954.426274776459, 'accumulated_eval_time': 404.29131865501404, 'accumulated_logging_time': 6.002583742141724, 'global_step': 34102, 'preemption_count': 0}), (34447, {'train/ssim': 0.7550387382507324, 'train/loss': 0.2563768284661429, 'validation/ssim': 0.7268162578696539, 'validation/loss': 0.28464365085994653, 'validation/num_examples': 3554, 'test/ssim': 0.7439937724710276, 'test/loss': 0.28599328896214393, 'test/num_examples': 3581, 'score': 8034.5121150016785, 'total_duration': 8450.093579769135, 'accumulated_submission_time': 8034.5121150016785, 'accumulated_eval_time': 408.3378036022186, 'accumulated_logging_time': 6.035517454147339, 'global_step': 34447, 'preemption_count': 0}), (34791, {'train/ssim': 0.7547637394496373, 'train/loss': 0.25628459453582764, 'validation/ssim': 0.726274326133406, 'validation/loss': 0.28467222781548956, 'validation/num_examples': 3554, 'test/ssim': 0.7435064456942893, 'test/loss': 0.286050932329482, 'test/num_examples': 3581, 'score': 8114.659774541855, 'total_duration': 8534.329248189926, 'accumulated_submission_time': 8114.659774541855, 'accumulated_eval_time': 412.38020157814026, 'accumulated_logging_time': 6.069193363189697, 'global_step': 34791, 'preemption_count': 0}), (35135, {'train/ssim': 0.7552019527980259, 'train/loss': 0.25622529642922537, 'validation/ssim': 0.726717131555114, 'validation/loss': 0.28462024317340495, 'validation/num_examples': 3554, 'test/ssim': 0.7439281865226194, 'test/loss': 0.28600491308293774, 'test/num_examples': 3581, 'score': 8194.64580988884, 'total_duration': 8618.405655145645, 'accumulated_submission_time': 8194.64580988884, 'accumulated_eval_time': 416.4238030910492, 'accumulated_logging_time': 6.104076862335205, 'global_step': 35135, 'preemption_count': 0}), (35479, {'train/ssim': 0.755331311907087, 'train/loss': 0.2562356335776193, 'validation/ssim': 0.726912018148565, 'validation/loss': 0.2846041171149585, 'validation/num_examples': 3554, 'test/ssim': 0.7441111726822117, 'test/loss': 0.2859727677870183, 'test/num_examples': 3581, 'score': 8274.605695009232, 'total_duration': 8702.45828127861, 'accumulated_submission_time': 8274.605695009232, 'accumulated_eval_time': 420.46518874168396, 'accumulated_logging_time': 6.143252611160278, 'global_step': 35479, 'preemption_count': 0}), (35821, {'train/ssim': 0.7551850591387067, 'train/loss': 0.25622785091400146, 'validation/ssim': 0.7267806053698298, 'validation/loss': 0.28460700228835467, 'validation/num_examples': 3554, 'test/ssim': 0.7439823869685492, 'test/loss': 0.28597839236159595, 'test/num_examples': 3581, 'score': 8354.700634717941, 'total_duration': 8786.64630651474, 'accumulated_submission_time': 8354.700634717941, 'accumulated_eval_time': 424.51155495643616, 'accumulated_logging_time': 6.178053855895996, 'global_step': 35821, 'preemption_count': 0}), (36165, {'train/ssim': 0.7552205494471959, 'train/loss': 0.25620695522853304, 'validation/ssim': 0.7267984659670442, 'validation/loss': 0.2845921470800946, 'validation/num_examples': 3554, 'test/ssim': 0.7439969767741204, 'test/loss': 0.2859633934960556, 'test/num_examples': 3581, 'score': 8434.776199579239, 'total_duration': 8870.805983543396, 'accumulated_submission_time': 8434.776199579239, 'accumulated_eval_time': 428.55034279823303, 'accumulated_logging_time': 6.211203336715698, 'global_step': 36165, 'preemption_count': 0}), (36189, {'train/ssim': 0.7552202088492257, 'train/loss': 0.256206887108939, 'validation/ssim': 0.7267981224940209, 'validation/loss': 0.28459212990644345, 'validation/num_examples': 3554, 'test/ssim': 0.7439967040674742, 'test/loss': 0.28596335940772477, 'test/num_examples': 3581, 'score': 8438.036951065063, 'total_duration': 8878.14504647255, 'accumulated_submission_time': 8438.036951065063, 'accumulated_eval_time': 432.59374141693115, 'accumulated_logging_time': 6.244928598403931, 'global_step': 36189, 'preemption_count': 0})], 'global_step': 36189}
I0204 21:09:30.851050 140584300062528 submission_runner.py:586] Timing: 8438.036951065063
I0204 21:09:30.851106 140584300062528 submission_runner.py:588] Total number of evals: 107
I0204 21:09:30.851148 140584300062528 submission_runner.py:589] ====================
I0204 21:09:30.851193 140584300062528 submission_runner.py:542] Using RNG seed 3907440050
I0204 21:09:30.852769 140584300062528 submission_runner.py:551] --- Tuning run 5/5 ---
I0204 21:09:30.852877 140584300062528 submission_runner.py:556] Creating tuning directory at /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_5.
I0204 21:09:30.853308 140584300062528 logger_utils.py:92] Saving hparams to /experiment_runs/prize_qualification/study_0/fastmri_jax/trial_5/hparams.json.
I0204 21:09:30.854180 140584300062528 submission_runner.py:206] Initializing dataset.
I0204 21:09:31.213996 140584300062528 submission_runner.py:213] Initializing model.
Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 208, in cache_miss
    outs, out_flat, out_tree, args_flat = _python_pjit_helper(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 150, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _ = infer_params_fn(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 301, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 474, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat = _pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 935, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 345, in memoized_fun
    ans = call(fun, *args)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/pjit.py", line 888, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 314, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2150, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/interpreters/partial_eval.py", line 2172, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/linear_util.py", line 188, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1640, in init
    _, v_out = self.init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 166, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1545, in init_with_output
    return init_with_output(
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 965, in wrapper
    return apply(fn, mutable=mutable, flags=init_flags)({}, *args, rngs=rngs,
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 933, in wrapper
    y = fn(root, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 2121, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 432, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 864, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1289, in make_rng
    return self.scope.make_rng(name)
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 711, in make_rng
    raise errors.InvalidRngError(f'{self.name} needs PRNG for "{name}"')
jax._src.traceback_util.UnfilteredStackTrace: flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)

The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.

--------------------

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "submission_runner.py", line 689, in <module>
    app.run(main)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/usr/local/lib/python3.8/dist-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "submission_runner.py", line 657, in main
    score = score_submission_on_workload(
  File "submission_runner.py", line 568, in score_submission_on_workload
    timing, metrics = train_once(workload, workload_name,
  File "submission_runner.py", line 221, in train_once
    model_params, model_state = workload.init_model_fn(
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/workload.py", line 37, in init_model_fn
    variables = jax.jit(self._model.init)({'params': rng}, fake_batch)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 103, in __call__
    output = layer(output, train)
  File "/algorithmic-efficiency/algorithmic_efficiency/workloads/fastmri/fastmri_jax/models.py", line 175, in __call__
    x = nn.Dropout(
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/stochastic.py", line 72, in __call__
    rng = self.make_rng(self.rng_collection)
flax.errors.InvalidRngError: Dropout_0 needs PRNG for "dropout" (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.InvalidRngError)
